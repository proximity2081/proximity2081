[{"title": "Michael Stevens: Vsauce | Lex Fridman Podcast #58", "id": "3qMemn__kK8", "quotes": [{"time": 355, "text": "When you say those states, the ones that contain memories of its past or ones that contain memories of its past and have degrees of consciousness."}, {"time": 365, "text": "Just the first part, because I think the consciousness then emerges from the fact that a state of the universe that contains fragments or memories of other states is one where you're going to feel like there's time."}, {"time": 382, "text": "You're going to feel like, yeah, things happened in the past."}, {"time": 386, "text": "And I don't know what'll happen in the future because these states don't contain information about the future."}, {"time": 390, "text": "For some reason, those kinds of states are either more common, more plentiful, or you could use the anthropic principle and just say, well, they're extremely rare, but until you are in one, or if you are in one, then you can ask questions, like you're asking me on this podcast."}, {"time": 409, "text": "Why questions?"}, {"time": 410, "text": "Yeah, it's like, why are we conscious?"}, {"time": 412, "text": "Well, because if we weren't, we wouldn't be asking why we were."}, {"time": 416, "text": "You've kind of implied that you have a sense, again, hypothesis, theorizing that the universe is deterministic."}, {"time": 425, "text": "What's your thoughts about free will?"}, {"time": 428, "text": "Do you think of the universe as deterministic in a sense that it's unrolling a particular, like there's a, it's operating under a specific set of physical laws."}, {"time": 437, "text": "And when you have to set the initial conditions, it will unroll in the exact same way in our particular line of the universe every time."}, {"time": 448, "text": "That is a very useful way to think about the universe."}, {"time": 451, "text": "It's done us well."}, {"time": 452, "text": "It's brought us to the moon."}, {"time": 453, "text": "It's brought us to where we are today, right?"}, {"time": 455, "text": "I would not say that I believe in determinism in that kind of an absolute form, or actually I just don't care."}, {"time": 465, "text": "Maybe it's true, but I'm not gonna live my life like it is."}, {"time": 469, "text": "What in your sense, cause you've studied kind of how we humans think of the world."}, {"time": 475, "text": "What's in your view is the difference between our perception, like how we think the world is and reality."}, {"time": 482, "text": "Do you think there's a huge gap there?"}, {"time": 484, "text": "Like we delude ourselves that the whole thing is an illusion."}, {"time": 487, "text": "Just everything about human psychology, the way we see things and how things actually are."}, {"time": 492, "text": "All the things you've studied, what's your sense?"}, {"time": 494, "text": "How big is the gap between reality and perception?"}, {"time": 496, "text": "Well, again, purely speculative."}, {"time": 498, "text": "I think that we will never know the answer."}, {"time": 500, "text": "We cannot know the answer."}, {"time": 502, "text": "There is no experiment to find an answer to that question."}, {"time": 506, "text": "Everything we experience is an event in our brain."}, {"time": 510, "text": "When I look at a cat, I'm not even, I can't prove that there's a cat there."}, {"time": 516, "text": "All I am experiencing is the perception of a cat inside my own brain."}, {"time": 523, "text": "I am only a witness to the events of my mind."}, {"time": 526, "text": "I think it is very useful to infer that if I witness the event of cat in my head, it's because I'm looking at a cat that is literally there and it has its own feelings and motivations and should be pet and given food and water and love."}, {"time": 543, "text": "I think that's the way you should live your life."}, {"time": 545, "text": "But whether or not we live in a simulation, I'm a brain in a vat, I don't know."}, {"time": 553, "text": "Do you care?"}, {"time": 554, "text": "I don't really."}, {"time": 556, "text": "Well, I care because it's a fascinating question."}, {"time": 559, "text": "And it's a fantastic way to get people excited about all kinds of topics, physics, psychology, consciousness, philosophy."}, {"time": 568, "text": "But at the end of the day, what would the difference be?"}, {"time": 571, "text": "If you..."}, {"time": 571, "text": "The cat needs to be fed at the end of the day, otherwise it'll be a dead cat."}, {"time": 575, "text": "Right, but if it's not even a real cat, then it's just like a video game cat."}, {"time": 580, "text": "And right, so what's the difference between killing a digital cat in a video game because of neglect versus a real cat?"}, {"time": 588, "text": "It seems very different to us psychologically."}, {"time": 590, "text": "Like I don't really feel bad about, oh my gosh, I forgot to feed my Tamagotchi, right?"}, {"time": 594, "text": "But I would feel terrible if I forgot to feed my actual cats."}, {"time": 598, "text": "So can you just touch on the topic of simulation?"}, {"time": 603, "text": "Do you find this thought experiment that we're living in a simulation useful, inspiring or constructive in any kind of way?"}, {"time": 611, "text": "Do you think it's ridiculous?"}, {"time": 612, "text": "Do you think it could be true?"}, {"time": 614, "text": "Or is it just a useful thought experiment?"}, {"time": 617, "text": "I think it is extremely useful as a thought experiment because it makes sense to everyone, especially as we see virtual reality and computer games getting more and more complex."}, {"time": 630, "text": "You're not talking to an audience in like Newton's time where you're like, imagine a clock that it has mechanics in it that are so complex that it can create love."}, {"time": 640, "text": "And everyone's like, no."}, {"time": 642, "text": "But today you really start to feel, man, at what point is this little robot friend of mine gonna be like someone I don't want to cancel plans with?"}, {"time": 653, "text": "And so it's a great, the thought experiment of do we live in a simulation?"}, {"time": 660, "text": "Am I a brain in a vat that is just being given electrical impulses from some nefarious other beings so that I believe that I live on earth and that I have a body and all of this?"}, {"time": 673, "text": "And the fact that you can't prove it either way is a fantastic way to introduce people to some of the deepest questions."}, {"time": 680, "text": "So you mentioned a little buddy that you would want to cancel an appointment with."}, {"time": 685, "text": "So that's a lot of our conversations."}, {"time": 687, "text": "That's what my research is, is artificial intelligence."}, {"time": 692, "text": "And I apologize, but you're such a fun person to ask these big questions with."}, {"time": 696, "text": "Well, I hope I can give some answers that are interesting."}, {"time": 700, "text": "Well, because of you've sharpened your brain's ability to explore some of the most, some of the questions that many scientists are actually afraid of even touching, which is fascinating."}, {"time": 712, "text": "I think you're in that sense ultimately a great scientist through this process of sharpening your brain."}, {"time": 718, "text": "Well, I don't know if I am a scientist."}, {"time": 721, "text": "I think science is a way of knowing and there are a lot of questions I investigate that are not scientific questions."}, {"time": 731, "text": "On like mind field, we have definitely done scientific experiments and studies that had hypotheses and all of that, but not to be too like precious about what does the word science mean?"}, {"time": 744, "text": "But I think I would just describe myself as curious and I hope that that curiosity is contagious."}, {"time": 749, "text": "So to you, the scientific method is deeply connected to science because your curiosity took you to asking questions."}, {"time": 758, "text": "To me, asking a good question, even if you feel, society feels that it's not a question within the reach of science currently."}, {"time": 767, "text": "To me, asking the question is the biggest step of the scientific process."}, {"time": 773, "text": "The scientific method is the second part and that may be what traditionally is called science, but to me, asking the questions, being brave enough to ask the questions, being curious and not constrained by what you're supposed to think is just true, what it means to be a scientist to me."}, {"time": 791, "text": "It's certainly a huge part of what it means to be a human."}, {"time": 796, "text": "If I were to say, you know what?"}, {"time": 797, "text": "I don't believe in forces."}, {"time": 799, "text": "I think that when I push on a massive object, a ghost leaves my body and enters the object I'm pushing and these ghosts happen to just get really lazy when they're around massive things and that's why F equals MA."}, {"time": 812, "text": "Oh, and by the way, the laziness of the ghost is in proportion to the mass of the object."}, {"time": 816, "text": "So boom, prove me wrong."}, {"time": 817, "text": "Every experiment, well, you can never find the ghost."}, {"time": 821, "text": "And so none of that theory is scientific, but once I start saying, can I see the ghost?"}, {"time": 829, "text": "Why should there be a ghost?"}, {"time": 830, "text": "And if there aren't ghosts, what might I expect?"}, {"time": 833, "text": "And I start to do different tests to see, is this falsifiable?"}, {"time": 839, "text": "Are there things that should happen if there are ghosts or are there things that shouldn't happen?"}, {"time": 842, "text": "And do they, you know, what do I observe?"}, {"time": 845, "text": "Now I'm thinking scientifically."}, {"time": 846, "text": "I don't think of science as, wow, a picture of a black hole."}, {"time": 850, "text": "That's just a photograph."}, {"time": 852, "text": "That's an image."}, {"time": 853, "text": "That's data."}, {"time": 853, "text": "That's a sensory and perception experience."}, {"time": 856, "text": "Science is how we got that and how we understand it and how we believe in it and how we reduce our uncertainty around what it means."}, {"time": 864, "text": "But I would say I'm deeply within the scientific community and I'm sometimes disheartened by the elitism of the thinking, sort of not allowing yourself to think outside the box."}, {"time": 876, "text": "So allowing the possibility of going against the conventions of science, I think is a beautiful part of some of the greatest scientists in history."}, {"time": 886, "text": "I don't know, I'm impressed by scientists every day and revolutions in our knowledge of the world occur only under very special circumstances."}, {"time": 900, "text": "It is very scary to challenge conventional thinking and risky because let's go back to elitism and ego, right?"}, {"time": 910, "text": "If you just say, you know what?"}, {"time": 911, "text": "I believe in the spirits of my body and all forces are actually created by invisible creatures that transfer themselves between objects."}, {"time": 922, "text": "If you ridicule every other theory and say that you're correct, then ego gets involved and you just don't go anywhere."}, {"time": 931, "text": "But fundamentally the question of well, what is a force is incredibly important."}, {"time": 938, "text": "We need to have that conversation, but it needs to be done in this very political way of like, let's be respectful of everyone and let's realize that we're all learning together and not shutting out other people."}, {"time": 949, "text": "And so when you look at a lot of revolutionary ideas, they were not accepted right away."}, {"time": 957, "text": "And, you know, Galileo had a couple of problems with the authorities and later thinkers, Descartes, was like, all right, look, I kind of agree with Galileo, but I'm gonna have to not say that."}, {"time": 971, "text": "I'll have to create and invent and write different things that keep me from being in trouble, but we still slowly made progress."}, {"time": 977, "text": "Revolutions are difficult in all forms and certainly in science."}, {"time": 980, "text": "Before we get to AI, on topic of revolutionary ideas, let me ask on a Reddit AMA, you said that is the earth flat is one of the favorite questions you've ever answered, speaking of revolutionary ideas."}, {"time": 993, "text": "So your video on that, people should definitely watch, is really fascinating."}, {"time": 999, "text": "Can you elaborate why you enjoyed answering this question so much?"}, {"time": 1003, "text": "Yeah, well, it's a long story."}, {"time": 1005, "text": "I remember a long time ago, I was living in New York at the time, so it had to have been like 2009 or something."}, {"time": 1014, "text": "I visited the Flat Earth forums and this was before the Flat Earth theories became as sort of mainstream as they are."}, {"time": 1023, "text": "Sorry to ask the dumb question, forums, online forums."}, {"time": 1026, "text": "Yeah, the Flat Earth Society, I don't know if it's.com or.org, but I went there and I was reading their ideas and how they responded to typical criticisms of, well, the earth isn't flat because what about this?"}, {"time": 1040, "text": "And I could not tell, and I mentioned this in my video, I couldn't tell how many of these community members actually believe the earth was flat or we're just trolling."}, {"time": 1052, "text": "And I realized that the fascinating thing is, how do we know anything?"}, {"time": 1058, "text": "And what makes for a good belief versus a maybe not so tenable or good belief?"}, {"time": 1065, "text": "And so that's really what my video about earth being flat is about."}, {"time": 1069, "text": "It's about, look, there are a lot of reasons that the earth is probably not flat, but a Flat Earth believer can respond to every single one of them, but it's all in an ad hoc way."}, {"time": 1084, "text": "And all of these, all of their rebuttals aren't necessarily gonna form a cohesive noncontradictory whole."}, {"time": 1090, "text": "And I believe that's the episode where I talk about Occam's razor and Newton's flaming laser sword."}, {"time": 1097, "text": "And then I say, well, you know what, wait a second."}, {"time": 1099, "text": "We know that space contracts as you move."}, {"time": 1105, "text": "And so to a particle moving near the speed of light towards earth, earth would be flattened in the direction of that particles travel."}, {"time": 1112, "text": "So to them, earth is flat."}, {"time": 1115, "text": "Like we need to be really generous to even wild ideas because they're all thinking, they're all the communication of ideas."}, {"time": 1125, "text": "And what else can it mean to be a human?"}, {"time": 1128, "text": "Yeah, and I think I'm a huge fan of the Flat Earth theory, quote unquote, in the sense that to me it feels harmless to explore some of the questions of what it means to believe something, what it means to explore the edge of science and so on."}, {"time": 1145, "text": "Cause it's a harm, it's a, to me, nobody gets hurt whether the earth is flat or round, not literally, but I mean intellectually when we're just having a conversation."}, {"time": 1153, "text": "That said, again, to elitism, I find that scientists roll their eyes way too fast on the Flat Earth."}, {"time": 1161, "text": "The kind of dismissal that I see to this even notion, they haven't like sat down and say, what are the arguments that are being proposed?"}, {"time": 1170, "text": "And this is why these arguments are incorrect."}, {"time": 1172, "text": "So that should be something that scientists should always do, even to the most sort of ideas that seem ridiculous."}, {"time": 1182, "text": "So I like this as almost, it's almost my test when I ask people what they think about Flat Earth theory, to see how quickly they roll their eyes."}, {"time": 1191, "text": "Well, yeah, I mean, let me go on record and say that the earth is not flat."}, {"time": 1198, "text": "It is a three dimensional spheroid."}, {"time": 1202, "text": "However, I don't know that and it has not been proven."}, {"time": 1207, "text": "Science doesn't prove anything."}, {"time": 1208, "text": "It just reduces uncertainty."}, {"time": 1210, "text": "Could the earth actually be flat?"}, {"time": 1213, "text": "Extremely unlikely, extremely unlikely."}, {"time": 1219, "text": "And so it is a ridiculous notion if we care about how probable and certain our ideas might be."}, {"time": 1226, "text": "But I think it's incredibly important to talk about science in that way and to not resort to, well, it's true."}, {"time": 1235, "text": "It's true in the same way that a mathematical theorem is true."}, {"time": 1241, "text": "And I think we're kind of like being pretty pedantic about defining this stuff."}, {"time": 1248, "text": "But like, sure, I could take a rocket ship out and I could orbit earth and look at it and it would look like a ball, right?"}, {"time": 1256, "text": "But I still can't prove that I'm not living in a simulation, that I'm not a brain in a vat, that this isn't all an elaborate ruse created by some technologically advanced extraterrestrial civilization."}, {"time": 1266, "text": "So there's always some doubt and that's fine."}, {"time": 1272, "text": "And I think that kind of doubt, practically speaking, is useful when you start talking about quantum mechanics or string theory, sort of, it helps."}, {"time": 1280, "text": "To me, that kind of adds a little spice into the thinking process of scientists."}, {"time": 1286, "text": "So, I mean, just as a thought experiment, your video kind of, okay, say the earth is flat."}, {"time": 1293, "text": "What would the forces when you walk about this flat earth feel like to the human?"}, {"time": 1298, "text": "That's a really nice thought experiment to think about."}, {"time": 1300, "text": "Right, because what's really nice about it is that it's a funny thought experiment, but you actually wind up accidentally learning a whole lot about gravity and about relativity and geometry."}, {"time": 1313, "text": "And I think that's really the goal of what I'm doing."}, {"time": 1316, "text": "I'm not trying to like convince people that the earth is round."}, {"time": 1318, "text": "I feel like you either believe that it is or you don't and like, that's, you know, how can I change that?"}, {"time": 1324, "text": "What I can do is change how you think and how you are introduced to important concepts."}, {"time": 1330, "text": "Like, well, how does gravity operate?"}, {"time": 1333, "text": "Oh, it's all about the center of mass of an object."}, {"time": 1336, "text": "So right, on a sphere, we're all pulled towards the middle, essentially the centroid geometrically, but on a disc, ooh, you're gonna be pulled at a weird angle if you're out near the edge."}, {"time": 1345, "text": "And that stuff's fascinating."}, {"time": 1348, "text": "Yeah, and to me, that was, that particular video opened my eyes even more to what gravity is."}, {"time": 1357, "text": "It's just a really nice visualization tool of, because you always imagine gravity with spheres, with masses that are spheres."}, {"time": 1365, "text": "And imagining gravity on masses that are not spherical, some other shape, but in here, a plate, a flat object, is really interesting."}, {"time": 1374, "text": "It makes you really kind of visualize in a three dimensional way the force of gravity."}, {"time": 1377, "text": "Yeah, even if a disc the size of Earth would be impossible, I think anything larger than like the moon basically needs to be a sphere because gravity will round it out."}, {"time": 1395, "text": "So you can't have a teacup the size of Jupiter, right?"}, {"time": 1398, "text": "There's a great book about the teacup in the universe that I highly recommend."}, {"time": 1402, "text": "I don't remember the author."}, {"time": 1404, "text": "I forget her name, but it's a wonderful book."}, {"time": 1406, "text": "So look it up."}, {"time": 1408, "text": "I think it's called Teacup in the Universe."}, {"time": 1410, "text": "Just to link on this point briefly, your videos are generally super, people love them, right?"}, {"time": 1417, "text": "If you look at the sort of number of likes versus dislikes is this measure of YouTube, right, is incredible."}, {"time": 1423, "text": "And as do I."}, {"time": 1425, "text": "But this particular flat Earth video has more dislikes than usual."}, {"time": 1431, "text": "What do you, on that topic in general, what's your sense, how big is the community, not just who believes in flat Earth, but sort of the anti scientific community that naturally distrust scientists in a way that's not an open minded way, like really just distrust scientists like they're bought by some kind of mechanism of some kind of bigger system that's trying to manipulate human beings."}, {"time": 1461, "text": "What's your sense of the size of that community?"}, {"time": 1464, "text": "You're one of the sort of great educators in the world that educates people on the exciting power of science."}, {"time": 1474, "text": "So you're kind of up against this community."}, {"time": 1478, "text": "What's your sense of it?"}, {"time": 1479, "text": "I really have no idea."}, {"time": 1481, "text": "I haven't looked at the likes and dislikes on the flat Earth video."}, {"time": 1485, "text": "And so I would wonder if it has a greater percentage of dislikes than usual, is that because of people disliking it because they think that it's a video about Earth being flat and they find that ridiculous and they dislike it without even really watching much?"}, {"time": 1504, "text": "Do they wish that I was more like dismissive of flat Earth theories?"}, {"time": 1509, "text": "That's possible too."}, {"time": 1510, "text": "I know there are a lot of response videos that kind of go through the episode and are pro flat Earth, but I don't know if there's a larger community of unorthodox thinkers today than there have been in the past."}, {"time": 1527, "text": "And I just wanna not lose them."}, {"time": 1529, "text": "I want them to keep listening and thinking and by calling them all idiots or something, that does no good because how idiotic are they really?"}, {"time": 1541, "text": "I mean, the Earth isn't a sphere at all."}, {"time": 1545, "text": "We know that it's an oblate spheroid and that in and of itself is really interesting."}, {"time": 1550, "text": "And I investigated that in which way is down where I'm like, really down does not point towards the center of the Earth."}, {"time": 1556, "text": "It points in different direction, depending on what's underneath you and what's above you and what's around you."}, {"time": 1562, "text": "The whole universe is tugging on me."}, {"time": 1566, "text": "And then you also show that gravity is non uniform across the globe."}, {"time": 1571, "text": "Like if you, there's this I guess thought experiment if you build a bridge all the way across the Earth and then just knock out its pillars, what would happen?"}, {"time": 1583, "text": "And you describe how it would be like a very chaotic, unstable thing that's happening because gravity is non uniform throughout the Earth."}, {"time": 1591, "text": "Yeah, in small spaces, like the ones we work in, we can essentially assume that gravity is uniform, but it's not."}, {"time": 1600, "text": "It is weaker the further you are from the Earth."}, {"time": 1603, "text": "And it also is going to be, it's radially pointed towards the middle of the Earth."}, {"time": 1610, "text": "So a really large object will feel tidal forces because of that non uniformness."}, {"time": 1615, "text": "And we can take advantage of that with satellites, right?"}, {"time": 1618, "text": "Gravitational induced torque."}, {"time": 1620, "text": "It's a great way to align your satellite without having to use fuel or any kind of engine."}, {"time": 1625, "text": "So let's jump back to it, artificial intelligence."}, {"time": 1628, "text": "What's your thought of the state of where we are at currently with artificial intelligence and what do you think it takes to build human level or superhuman level intelligence?"}, {"time": 1637, "text": "I don't know what intelligence means."}, {"time": 1640, "text": "That's my biggest question at the moment."}, {"time": 1642, "text": "And I think it's because my instinct is always to go, well, what are the foundations here of our discussion?"}, {"time": 1648, "text": "What does it mean to be intelligent?"}, {"time": 1651, "text": "How do we measure the intelligence of an artificial machine or a program or something?"}, {"time": 1657, "text": "Can we say that humans are intelligent?"}, {"time": 1659, "text": "Because there's also a fascinating field of how do you measure human intelligence."}, {"time": 1665, "text": "But if we just take that for granted, saying that whatever this fuzzy intelligence thing we're talking about, humans kind of have it."}, {"time": 1673, "text": "What would be a good test for you?"}, {"time": 1676, "text": "So during develop a test that's natural language conversation, would that impress you?"}, {"time": 1681, "text": "A chat bot that you'd want to hang out and have a beer with for a bunch of hours or have dinner plans with."}, {"time": 1688, "text": "Is that a good test, natural language conversation?"}, {"time": 1690, "text": "Is there something else that would impress you?"}, {"time": 1692, "text": "Or is that also too difficult to think about?"}, {"time": 1693, "text": "Oh yeah, I'm pretty much impressed by everything."}, {"time": 1696, "text": "I think that if there was a chat bot that was like incredibly, I don't know, really had a personality."}, {"time": 1704, "text": "And if I didn't be the Turing test, right?"}, {"time": 1707, "text": "Like if I'm unable to tell that it's not another person but then I was shown a bunch of wires and mechanical components."}, {"time": 1719, "text": "And it was like, that's actually what you're talking to."}, {"time": 1722, "text": "I don't know if I would feel that guilty destroying it."}, {"time": 1726, "text": "I would feel guilty because clearly it's well made and it's a really cool thing."}, {"time": 1731, "text": "It's like destroying a really cool car or something but I would not feel like I was a murderer."}, {"time": 1736, "text": "So yeah, at what point would I start to feel that way?"}, {"time": 1738, "text": "And this is such a subjective psychological question."}, {"time": 1742, "text": "If you give it movement or if you have it act as though or perhaps really feel pain as I destroy it and scream and resist, then I'd feel bad."}, {"time": 1755, "text": "Yeah, it's beautifully put."}, {"time": 1756, "text": "And let's just say act like it's a pain."}, {"time": 1760, "text": "So if you just have a robot that not screams, just like moans in pain if you kick it, that immediately just puts it in a class that we humans, it becomes, we anthropomorphize it."}, {"time": 1775, "text": "It almost immediately becomes human."}, {"time": 1777, "text": "So that's a psychology question as opposed to sort of a physics question."}, {"time": 1780, "text": "Right, I think that's a really good instinct to have."}, {"time": 1783, "text": "If the robot."}, {"time": 1785, "text": "Screams."}, {"time": 1786, "text": "Screams and moans, even if you don't believe that it has the mental experience, the qualia of pain and suffering, I think it's still a good instinct to say, you know what, I'd rather not hurt it."}, {"time": 1799, "text": "The problem is that instinct can get us in trouble because then robots can manipulate that."}, {"time": 1805, "text": "And there's different kinds of robots."}, {"time": 1808, "text": "There's robots like the Facebook and the YouTube algorithm that recommends the video, and they can manipulate in the same kind of way."}, {"time": 1814, "text": "Well, let me ask you just to stick on artificial intelligence for a second."}, {"time": 1817, "text": "Do you have worries about existential threats from AI or existential threats from other technologies like nuclear weapons that could potentially destroy life on earth or damage it to a very significant degree?"}, {"time": 1831, "text": "Yeah, of course I do."}, {"time": 1832, "text": "Especially the weapons that we create."}, {"time": 1835, "text": "There's all kinds of famous ways to think about this."}, {"time": 1838, "text": "And one is that, wow, what if we don't see advanced alien civilizations because of the danger of technology?"}, {"time": 1850, "text": "What if we reach a point, and I think there's a channel, Thoughty2, geez, I wish I remembered the name of the channel, but he delves into this kind of limit of maybe once you discover radioactivity and its power, you've reached this important hurdle."}, {"time": 1867, "text": "And the reason that the skies are so empty is that no one's ever managed to survive as a civilization once they have that destructive power."}, {"time": 1876, "text": "And when it comes to AI, I'm not really very worried because I think that there are plenty of other people that are already worried enough."}, {"time": 1886, "text": "And oftentimes these worries are just, they just get in the way of progress."}, {"time": 1892, "text": "And they're questions that we should address later."}, {"time": 1897, "text": "And I think I talk about this in my interview with the self driving autonomous vehicle guy, as I think it was a bonus scene from the trolley problem episode."}, {"time": 1912, "text": "And I'm like, wow, what should a car do if this really weird contrived scenario happens where it has to swerve and save the driver, but kill a kid?"}, {"time": 1920, "text": "And he's like, well, what would a human do?"}, {"time": 1923, "text": "And if we resist technological progress because we're worried about all of these little issues, then it gets in the way."}, {"time": 1931, "text": "And we shouldn't avoid those problems, but we shouldn't allow them to be stumbling blocks to advancement."}, {"time": 1938, "text": "So the folks like Sam Harris or Elon Musk are saying that we're not worried enough."}, {"time": 1944, "text": "So the worry should not paralyze technological progress, but we're sort of marching, technology is marching forward without the key scientists, the developing of technology, worrying about the overnight having some effects that would be very detrimental to society."}, {"time": 1965, "text": "So to push back on your thought of the idea that there's enough people worrying about it, Elon Musk says, there's not enough people worrying about it."}, {"time": 1974, "text": "That's the kind of balance is, it's like folks who are really focused on nuclear deterrence are saying there's not enough people worried about nuclear deterrence, right?"}, {"time": 1986, "text": "So it's an interesting question of what is a good threshold of people to worry about these?"}, {"time": 1992, "text": "And if it's too many people that are worried, you're right."}, {"time": 1995, "text": "It'll be like the press would over report on it and there'll be technological, halt technological progress."}, {"time": 2001, "text": "If not enough, then we can march straight ahead into that abyss that human beings might be destined for with the progress of technology."}, {"time": 2011, "text": "Yeah, I don't know what the right balance is of how many people should be worried and how worried should they be, but we're always worried about new technology."}, {"time": 2020, "text": "We know that Plato was worried about the written word."}, {"time": 2022, "text": "He was like, we shouldn't teach people to write because then they won't use their minds to remember things."}, {"time": 2028, "text": "There have been concerns over technology and its advancement since the beginning of recorded history."}, {"time": 2035, "text": "And so, I think, however, these conversations are really important to have because again, we learn a lot about ourselves."}, {"time": 2043, "text": "If we're really scared of some kind of AI like coming into being that is conscious or whatever and can self replicate, we already do that every day."}, {"time": 2053, "text": "It's called humans being born."}, {"time": 2054, "text": "They're not artificial, they're humans, but they're intelligent and I don't wanna live in a world where we're worried about babies being born because what if they become evil?"}, {"time": 2065, "text": "What if they become mean people?"}, {"time": 2065, "text": "What if they're thieves?"}, {"time": 2067, "text": "Maybe we should just like, what, not have babies born?"}, {"time": 2071, "text": "Like maybe we shouldn't create AI."}, {"time": 2073, "text": "It's like, we will want to have safeguards in place in the same way that we know, look, a kid could be born that becomes some kind of evil person, but we have laws, right?"}, {"time": 2087, "text": "And it's possible that with advanced genetics in general, be able to, it's a scary thought to say that, this, my child, if born would have an 83% chance of being a psychopath, right?"}, {"time": 2108, "text": "Like being able to, if it's something genetic, if there's some sort of, and what to use that information, what to do with that information is a difficult ethical thought."}, {"time": 2120, "text": "Yeah, and I'd like to find an answer that isn't, well, let's not have them live."}, {"time": 2124, "text": "You know, I'd like to find an answer that is, well, all human life is worthy."}, {"time": 2130, "text": "And if you have an 83% chance of becoming a psychopath, well, you still deserve dignity."}, {"time": 2138, "text": "And you still deserve to be treated well."}, {"time": 2142, "text": "You still have rights."}, {"time": 2143, "text": "At least at this part of the world, at least in America, there's a respect for individual life in that way."}, {"time": 2149, "text": "That's, well, to me, but again, I'm in this bubble, is a beautiful thing."}, {"time": 2155, "text": "But there's other cultures where individual human life is not that important, where a society, so I was born in the Soviet Union, where the strength of nation and society together is more important than any one particular individual."}, {"time": 2170, "text": "So it's an interesting also notion, the stories we tell ourselves."}, {"time": 2173, "text": "I like the one where individuals matter, but it's unclear that that was what the future holds."}, {"time": 2179, "text": "Well, yeah, and I mean, let me even throw this out."}, {"time": 2181, "text": "Like, what is artificial intelligence?"}, {"time": 2183, "text": "How can it be artificial?"}, {"time": 2185, "text": "I really think that we get pretty obsessed and stuck on the idea that there is some thing that is a wild human, a pure human organism without technology."}, {"time": 2195, "text": "But I don't think that's a real thing."}, {"time": 2197, "text": "I think that humans and human technology are one organism."}, {"time": 2202, "text": "Look at my glasses, okay?"}, {"time": 2204, "text": "If an alien came down and saw me, would they necessarily know that this is an invention, that I don't grow these organically from my body?"}, {"time": 2213, "text": "They wouldn't know that right away."}, {"time": 2215, "text": "And the written word, and spoons, and cups, these are all pieces of technology."}, {"time": 2222, "text": "We are not alone as an organism."}, {"time": 2226, "text": "And so the technology we create, whether it be video games or artificial intelligence that can self replicate and hate us, it's actually all the same organism."}, {"time": 2236, "text": "When you're in a car, where do you end in the car begin?"}, {"time": 2239, "text": "It seems like a really easy question to answer, but the more you think about it, the more you realize, wow, we are in this symbiotic relationship with our inventions."}, {"time": 2247, "text": "And there are plenty of people who are worried about it."}, {"time": 2250, "text": "And there should be, but it's inevitable."}, {"time": 2252, "text": "And I think that even just us think of ourselves as individual intelligences may be silly notion because it's much better to think of the entirety of human civilization."}, {"time": 2266, "text": "All living organisms on earth is a single living organism."}, {"time": 2270, "text": "As a single intelligent creature, because you're right, everything's intertwined."}, {"time": 2274, "text": "Everything is deeply connected."}, {"time": 2277, "text": "So we mentioned, you know, Musk, so you're a curious lover of science."}, {"time": 2283, "text": "What do you think of the efforts that Elon Musk is doing with space exploration, with electric vehicles, with autopilot, sort of getting into the space of autonomous vehicles, with boring under LA and a Neuralink trying to communicate brain machine interfaces, communicate between machines and human brains?"}, {"time": 2308, "text": "Well, it's really inspiring."}, {"time": 2310, "text": "I mean, look at the fandom that he's amassed."}, {"time": 2314, "text": "It's not common for someone like that to have such a following."}, {"time": 2320, "text": "And so it's... Engineering nerd."}, {"time": 2322, "text": "Yeah, so it's really exciting."}, {"time": 2324, "text": "But I also think that a lot of responsibility comes with that kind of power."}, {"time": 2327, "text": "So like if I met him, I would love to hear how he feels about the responsibility he has."}, {"time": 2333, "text": "When there are people who are such a fan of your ideas and your dreams and share them so closely with you, you have a lot of power."}, {"time": 2346, "text": "And he didn't always have that, you know?"}, {"time": 2349, "text": "He wasn't born as Elon Musk."}, {"time": 2351, "text": "Well, he was, but well, he was named that later."}, {"time": 2353, "text": "But the point is that I wanna know the psychology of becoming a figure like him."}, {"time": 2363, "text": "Well, I don't even know how to phrase the question right, but it's a question about what do you do when you're following, your fans become so large that it's almost bigger than you."}, {"time": 2377, "text": "And how do you responsibly manage that?"}, {"time": 2381, "text": "And maybe it doesn't worry him at all."}, {"time": 2382, "text": "And that's fine too."}, {"time": 2383, "text": "But I'd be really curious."}, {"time": 2385, "text": "And I think there are a lot of people that go through this when they realize, whoa, there are a lot of eyes on me."}, {"time": 2390, "text": "There are a lot of people who really take what I say very earnestly and take it to heart and will defend me."}, {"time": 2397, "text": "And whew, that's, that's, that can be dangerous."}, {"time": 2404, "text": "And you have to be responsible with it."}, {"time": 2407, "text": "Both in terms of impact on society and psychologically for the individual, just the burden psychologically on Elon?"}, {"time": 2415, "text": "Yeah, yeah, how does he think about that?"}, {"time": 2418, "text": "Part of his persona."}, {"time": 2421, "text": "Well, let me throw that right back at you because in some ways you're just a funny guy that gotten a humongous following, a funny guy with a curiosity."}, {"time": 2434, "text": "You've got a huge following."}, {"time": 2436, "text": "How do you psychologically deal with the responsibility?"}, {"time": 2440, "text": "In many ways you have a reach in many ways bigger than Elon Musk."}, {"time": 2444, "text": "What is your, what is the burden that you feel in educating being one of the biggest educators in the world where everybody's listening to you and actually everybody, like most of the world that's uses YouTube for educational material, trust you as a source of good, strong scientific thinking."}, {"time": 2467, "text": "It's a burden and I try to approach it with a lot of humility and sharing."}, {"time": 2476, "text": "Like I'm not out there doing a lot of scientific experiments."}, {"time": 2480, "text": "I am sharing the work of real scientists and I'm celebrating their work and the way that they think and the power of curiosity."}, {"time": 2489, "text": "But I wanna make it clear at all times that like, look, we don't know all the answers and I don't think we're ever going to reach a point where we're like, wow, and there you go."}, {"time": 2499, "text": "That's the universe."}, {"time": 2500, "text": "It's this equation, you plug in some conditions or whatever and you do the math and you know what's gonna happen tomorrow."}, {"time": 2506, "text": "I don't think we're ever gonna reach that point, but I think that there is a tendency to sometimes believe in science and become elitist and become, I don't know, hard when in reality it should humble you and make you feel smaller."}, {"time": 2521, "text": "I think there's something very beautiful about feeling very, very small and very weak and to feel that you need other people."}, {"time": 2530, "text": "So I try to keep that in mind and say, look, thanks for watching."}, {"time": 2534, "text": "Vsauce is not, I'm not Vsauce, you are."}, {"time": 2536, "text": "When I start the episodes, I say, hey, Vsauce, Michael here."}, {"time": 2540, "text": "Vsauce and Michael are actually a different thing in my mind."}, {"time": 2543, "text": "I don't know if that's always clear, but yeah, I have to approach it that way because it's not about me."}, {"time": 2550, "text": "Yeah, so it's not even, you're not feeling the responsibility."}, {"time": 2553, "text": "You're just sort of plugging into this big thing that is scientific exploration of our reality and you're a voice that represents a bunch, but you're just plugging into this big Vsauce ball that others, millions of others are plugged into."}, {"time": 2569, "text": "Yeah, and I'm just hoping to encourage curiosity and responsible thinking and an embracement of doubt and being okay with that."}, {"time": 2585, "text": "So I'm next week talking to Christos Gudrow."}, {"time": 2588, "text": "I'm not sure if you're familiar who he is, but he's the VP of engineering, head of the quote unquote YouTube algorithm or the search and discovery."}, {"time": 2596, "text": "So let me ask, first high level, do you have a question for him that if you can get an honest answer that you would ask, but more generally, how do you think about the YouTube algorithm that drives some of the motivation behind, no, some of the design decisions you make as you ask and answer some of the questions you do, how would you improve this algorithm in your mind in general?"}, {"time": 2625, "text": "So just what would you ask him?"}, {"time": 2627, "text": "And outside of that, how would you like to see the algorithm improve?"}, {"time": 2632, "text": "Well, I think of the algorithm as a mirror."}, {"time": 2636, "text": "It reflects what people put in and we don't always like what we see in that mirror."}, {"time": 2641, "text": "From the individual mirror to the individual mirror to the society."}, {"time": 2645, "text": "Both, in the aggregate, it's reflecting back what people on average want to watch."}, {"time": 2651, "text": "And when you see things being recommended to you, it's reflecting back what it thinks you want to see."}, {"time": 2659, "text": "And specifically, I would guess that it's not just what you want to see, but what you will click on and what you will watch some of and stay on YouTube because of."}, {"time": 2672, "text": "I don't think that, this is all me guessing, but I don't think that YouTube cares if you only watch like a second of a video, as long as the next thing you do is open another video."}, {"time": 2685, "text": "If you close the app or close the site, that's a problem for them because they're not a subscription platform."}, {"time": 2692, "text": "They're not like, look, you're giving us 20 bucks a month no matter what, so who cares?"}, {"time": 2697, "text": "They need you to watch and spend time there and see ads."}, {"time": 2702, "text": "So one of the things I'm curious about whether they do consider longer term sort of develop, your longer term development as a human being, which I think ultimately will make you feel better about using YouTube in the longterm and allowing you to stick with it for longer."}, {"time": 2719, "text": "Because even if you feed the dopamine rush in the short term and you keep clicking on cat videos, eventually you sort of wake up like from a drug and say, I need to quit this."}, {"time": 2730, "text": "So I wonder how much you're trying to optimize for the longterm because when I look at the, your videos aren't exactly sort of, no offense, but they're not the most clickable."}, {"time": 2741, "text": "They're both the most clickable and I feel I watched the entire thing and I feel a better human after I watched it, right?"}, {"time": 2749, "text": "So like they're not just optimizing for the clickability because I hope, so my thought is how do you think of it?"}, {"time": 2759, "text": "And does it affect your own content?"}, {"time": 2762, "text": "Like how deep you go, how profound you explore the directions and so on."}, {"time": 2767, "text": "I've been really lucky in that I don't worry too much about the algorithm."}, {"time": 2772, "text": "I mean, look at my thumbnails."}, {"time": 2773, "text": "I don't really go too wild with them."}, {"time": 2777, "text": "And with minefield where I'm in partnership with YouTube on the thumbnails, I'm often like, let's pull this back."}, {"time": 2782, "text": "Let's be mysterious."}, {"time": 2783, "text": "But usually I'm just trying to do what everyone else is not doing."}, {"time": 2787, "text": "So if everyone's doing crazy Photoshop kind of thumbnails, I'm like, what if the thumbnails just a line?"}, {"time": 2794, "text": "And what if the title is just a word?"}, {"time": 2797, "text": "And I kind of feel like all of the Vsauce channels have cultivated an audience that expects that."}, {"time": 2803, "text": "And so they would rather Jake make a video that's just called stains than one called, I explored stains, shocking."}, {"time": 2810, "text": "But there are other audiences out there that want that."}, {"time": 2813, "text": "And I think most people kind of want what you see the algorithm favoring, which is mainstream traditional celebrity and news kind of information."}, {"time": 2823, "text": "I mean, that's what makes YouTube really different than other streaming platforms."}, {"time": 2826, "text": "No one's like, what's going on in the world?"}, {"time": 2828, "text": "I'll open up Netflix to find out."}, {"time": 2830, "text": "But you do open up Twitter to find that out."}, {"time": 2832, "text": "You open up Facebook and you can open up YouTube because you'll see that the trending videos are like what happened amongst the traditional mainstream people in different industries."}, {"time": 2842, "text": "And that's what's being shown."}, {"time": 2844, "text": "And it's not necessarily YouTube saying, we want that to be what you see."}, {"time": 2849, "text": "It's that that's what people click on."}, {"time": 2851, "text": "When they see Ariana Grande, you know, reads a love letter from like her high school sweetheart, they're like, I wanna see that."}, {"time": 2858, "text": "And when they see a video from me that's got some lines in math and it's called law and causes they're like, well, I mean, I'm just on the bus."}, {"time": 2865, "text": "Like I don't have time to dive into a whole lesson."}, {"time": 2868, "text": "So, you know, before you get super mad at YouTube, you should say, really, they're just reflecting back human behavior."}, {"time": 2875, "text": "Is there something you would improve about the algorithm knowing of course, that as far as we're concerned, it's a black box, so we don't know how it works."}, {"time": 2884, "text": "Right, and I don't think that even anyone at YouTube really knows what it's doing."}, {"time": 2887, "text": "They know what they've tweaked, but then it learns."}, {"time": 2889, "text": "I think that it learns and it decides how to behave."}, {"time": 2893, "text": "And sometimes the YouTube employees are left going, I don't know."}, {"time": 2897, "text": "Maybe we should like change the value of how much it, you know, worries about watch time."}, {"time": 2902, "text": "And maybe it should worry more about something else."}, {"time": 2905, "text": "But I mean, I would like to see, I don't know what they're doing and not doing."}, {"time": 2910, "text": "Well, is there a conversation that you think they should be having just internally, whether they're having it or not?"}, {"time": 2917, "text": "Is there something, should they be thinking about the longterm future?"}, {"time": 2921, "text": "Should they be thinking about educational content and whether that's educating about what just happened in the world today, news or educational content, like what you're providing, which is asking big sort of timeless questions about how the way the world works."}, {"time": 2938, "text": "What should they think about?"}, {"time": 2939, "text": "Because it's called YouTube, not our tube."}, {"time": 2942, "text": "And that's why I think they have so many phenomenal educational creators."}, {"time": 2948, "text": "You don't have shows like Three Blue One Brown or Physics Girl or Looking Glass Universe or Up and Atom or Brain Scoop or, I mean, I could go on and on."}, {"time": 2958, "text": "They aren't on Amazon Prime and Netflix and they don't have commissioned shows from those platforms."}, {"time": 2964, "text": "It's all organically happening because there are people out there that want to share their passion for learning, that wanna share their curiosity."}, {"time": 2972, "text": "And YouTube could promote those kinds of shows more, but first of all, they probably wouldn't get as many clicks and YouTube needs to make sure that the average user is always clicking and staying on the site."}, {"time": 2987, "text": "They could still promote it more for the good of society, but then we're making some really weird claims about what's good for society because I think that cat videos are also an incredibly important part of what it means to be a human."}, {"time": 3000, "text": "I mentioned this quote before from Unumuno about, look, I've seen a cat like estimate distances and calculate a jump more often than I've seen a cat cry."}, {"time": 3009, "text": "And so things that play with our emotions and make us feel things can be cheesy and can feel cheap, but like, man, that's very human."}, {"time": 3018, "text": "And so even the dumbest vlog is still so important that I don't think I have a better claim to take its spot than it has to have that spot."}, {"time": 3029, "text": "It puts a mirror to us, the beautiful parts, the ugly parts, the shallow parts, the deep parts."}, {"time": 3036, "text": "What I would like to see is, I miss the days when engaging with content on YouTube helped push it into my subscribers timelines."}, {"time": 3047, "text": "It used to be that when I liked a video, say from Veritasium, it would show up in the feed on the front page of the app or the website of my subscribers."}, {"time": 3058, "text": "And I knew that if I liked a video, I could send it 100,000 views or more."}, {"time": 3063, "text": "That no longer is true, but I think that was a good user experience."}, {"time": 3067, "text": "When I subscribe to someone, when I'm following them, I want to see more of what they like."}, {"time": 3073, "text": "I want them to also curate the feed for me."}, {"time": 3075, "text": "And I think that Twitter and Facebook are doing that in also some ways that are kind of annoying, but I would like that to happen more."}, {"time": 3082, "text": "And I think we would see communities being stronger on YouTube if it was that way instead of YouTube going, well, technically Michael liked this Veritasium video, but people are way more likely to click on Carpool Karaoke."}, {"time": 3093, "text": "So I don't even care who they are, just give them that."}, {"time": 3096, "text": "Not saying anything against Carpool Karaoke, that is a extremely important part of our society, what it means to be a human on earth, you know, but."}, {"time": 3106, "text": "I'll say it sucks, but."}, {"time": 3108, "text": "Yeah, but a lot of people would disagree with you and they should be able to see as much of that as they want."}, {"time": 3113, "text": "And I think even people who don't think they like it should still be really aware of it because it's such an important thing."}, {"time": 3119, "text": "It's such an influential thing."}, {"time": 3120, "text": "But yeah, I just wish that like new channels I discover and that I subscribe to, I wish that my subscribers found out about that because especially in the education community, a rising tide floats all boats."}, {"time": 3131, "text": "If you watch a video from Numberphile, you're just more likely to want to watch an episode from me, whether it be on Vsauce1 or Ding."}, {"time": 3138, "text": "It's not competitive in the way that traditional TV was where it's like, well, if you tune into that show, it means you're not watching mine because they both air at the same time."}, {"time": 3146, "text": "So helping each other out through collaborations takes a lot of work, but just through engaging, commenting on their videos, liking their videos, subscribing to them, whatever, that I would love to see become easier and more powerful."}, {"time": 3161, "text": "So a quick and impossibly deep question, last question about mortality."}, {"time": 3168, "text": "You've spoken about death as an interesting topic."}, {"time": 3172, "text": "Do you think about your own mortality?"}, {"time": 3175, "text": "Yeah, every day, it's really scary."}, {"time": 3179, "text": "So what do you think is the meaning of life that mortality makes very explicit?"}, {"time": 3187, "text": "So why are you here on earth, Michael?"}, {"time": 3192, "text": "What's the point of this whole thing?"}, {"time": 3198, "text": "What does mortality in the context of the whole universe make you realize about yourself?"}]}]