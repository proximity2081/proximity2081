[{"title": "Steven Pinker: AI in the Age of Reason | Lex Fridman Podcast #3", "id": "epQxfSp-rdU", "quotes": [{"time": 412, "text": "That is, we're neural networks, natural selection did a kind of equivalent of engineering of our brains."}, {"time": 419, "text": "So I don't think there's anything mysterious in the sense that no system made out of silicon could ever do what a human brain can do."}, {"time": 424, "text": "I think it's possible in principle."}, {"time": 431, "text": "Whether it'll ever happen depends not only on how clever we are in engineering these systems, but whether we even want to, whether that's even a sensible goal."}, {"time": 442, "text": "That is, you can ask the question, is there any locomotion system that is as good as a human?"}, {"time": 449, "text": "Well, we kind of want to do better than a human ultimately in terms of legged locomotion."}, {"time": 455, "text": "There's no reason that humans should be our benchmark."}, {"time": 455, "text": "They're tools that might be better in some ways."}, {"time": 459, "text": "It may be that we can't duplicate a natural system because at some point it's so much cheaper to use a natural system that we're not going to invest more brainpower and resources."}, {"time": 474, "text": "So for example, we don't really have an exact substitute for wood."}, {"time": 474, "text": "We still build houses out of wood."}, {"time": 480, "text": "We still build furniture out of wood."}, {"time": 480, "text": "We like the look."}, {"time": 480, "text": "We like the feel."}, {"time": 480, "text": "It has certain properties that synthetics don't."}, {"time": 485, "text": "It's not that there's anything magical or mysterious about wood."}, {"time": 491, "text": "It's just that the extra steps of duplicating everything about wood is something we just haven't bothered because we have wood."}, {"time": 497, "text": "Likewise, say cotton."}, {"time": 497, "text": "I'm wearing cotton clothing now."}, {"time": 497, "text": "It feels much better than polyester."}, {"time": 501, "text": "It's not that cotton has something magic in it."}, {"time": 501, "text": "It's not that we couldn't ever synthesize something exactly like cotton, but at some point it's just not worth it."}, {"time": 509, "text": "We've got cotton."}, {"time": 515, "text": "Likewise, in the case of human intelligence, the goal of making an artificial system that is exactly like the human brain is a goal that we probably know is going to pursue to the bitter end, I suspect, because if you want tools that do things better than humans, you're not going to care whether it does something like humans."}, {"time": 533, "text": "So for example, diagnosing cancer or predicting the weather, why set humans as your benchmark?"}, {"time": 538, "text": "But in general, I suspect you also believe that even if the human should not be a benchmark and we don't want to imitate humans in their system, there's a lot to be learned about how to create an artificial intelligence system by studying the human."}, {"time": 555, "text": "Yeah, I think that's right."}, {"time": 555, "text": "In the same way that to build flying machines, we want to understand the laws of aerodynamics, including birds, but not mimic the birds, but they're the same laws."}, {"time": 567, "text": "You have a view on AI, artificial intelligence, and safety that, from my perspective, is refreshingly rational or perhaps more importantly, has elements of positivity to it, which I think can be inspiring and empowering as opposed to paralyzing."}, {"time": 593, "text": "For many people, including AI researchers, the eventual existential threat of AI is obvious, not only possible, but obvious."}, {"time": 599, "text": "And for many others, including AI researchers, the threat is not obvious."}, {"time": 605, "text": "So Elon Musk is famously in the highly concerned about AI camp, saying things like AI is far more dangerous than nuclear weapons, and that AI will likely destroy human civilization."}, {"time": 621, "text": "Human civilization."}, {"time": 621, "text": "So in February, he said that if Elon was really serious about AI, the threat of AI, he would stop building self driving cars that he's doing very successfully as part of Tesla."}, {"time": 635, "text": "Then he said, wow, if even Pinker doesn't understand the difference between narrow AI, like a car and general AI, when the latter literally has a million times more compute power and an open ended utility function, humanity is in deep trouble."}, {"time": 647, "text": "So first, what did you mean by the statement about Elon Musk should stop building self driving cars if he's deeply concerned?"}, {"time": 660, "text": "Not the last time that Elon Musk has fired off an intemperate tweet."}, {"time": 664, "text": "Well, we live in a world where Twitter has power."}, {"time": 667, "text": "Yeah, I think there are two kinds of existential threat that have been discussed in connection with artificial intelligence, and I think that they're both incoherent."}, {"time": 680, "text": "One of them is a vague fear of AI takeover, that just as we subjugated animals and less technologically advanced peoples, so if we build something that's more advanced than us, it will inevitably turn us into pets or slaves or domesticated animal equivalents."}, {"time": 728, "text": "There's no reason to think that sheer problem solving capability will set that as one of its goals."}, {"time": 733, "text": "Its goals will be whatever we set its goals as, and as long as someone isn't building a megalomaniacal artificial intelligence, then there's no reason to think that it would naturally evolve in that direction."}, {"time": 744, "text": "Now, you might say, well, what if we gave it the goal of maximizing its own power source?"}, {"time": 748, "text": "That's a pretty stupid goal to give an autonomous system."}, {"time": 748, "text": "You don't give it that goal."}, {"time": 754, "text": "I mean, that's just self evidently idiotic."}, {"time": 754, "text": "So if you look at the history of the world, there's been a lot of opportunities where engineers could instill in a system destructive power and they choose not to because that's the natural process of engineering."}, {"time": 769, "text": "Well, except for weapons."}, {"time": 769, "text": "I mean, if you're building a weapon, its goal is to destroy people, and so I think there are good reasons to not build certain kinds of weapons."}, {"time": 773, "text": "I think building nuclear weapons was a massive mistake."}, {"time": 778, "text": "So maybe pause on that because that is one of the serious threats."}, {"time": 786, "text": "Do you think that it was a mistake in a sense that it should have been stopped early on?"}, {"time": 792, "text": "Or do you think it's just an unfortunate event of invention that this was invented?"}, {"time": 799, "text": "Do you think it's possible to stop?"}, {"time": 799, "text": "I guess is the question."}, {"time": 799, "text": "It's hard to rewind the clock because of course it was invented in the context of World War II and the fear that the Nazis might develop one first."}, {"time": 808, "text": "Then once it was initiated for that reason, it was hard to turn off, especially since winning the war against the Japanese and the Nazis was such an overwhelming goal of every responsible person that there's just nothing that people wouldn't have done then to ensure victory."}, {"time": 827, "text": "It's quite possible if World War II hadn't happened that nuclear weapons wouldn't have been invented."}, {"time": 861, "text": "I think analogies between nuclear weapons and artificial intelligence are fundamentally misguided because the whole point of nuclear weapons is to destroy things."}, {"time": 865, "text": "The point of artificial intelligence is not to destroy things."}, {"time": 870, "text": "So the analogy is misleading."}, {"time": 876, "text": "So there's two artificial intelligence you mentioned."}, {"time": 876, "text": "The first one I guess is highly intelligent or power hungry."}, {"time": 882, "text": "Yeah, it's a system that we design ourselves where we give it the goals."}, {"time": 882, "text": "Goals are external to the means to attain the goals."}, {"time": 886, "text": "If we don't design an artificially intelligent system to maximize dominance, then it won't maximize dominance."}, {"time": 895, "text": "It's just that we're so familiar with homo sapiens where these two traits come bundled together, particularly in men, that we are apt to confuse high intelligence with a will to power, but that's just an error."}, {"time": 915, "text": "The other fear is that will be collateral damage that will give artificial intelligence a goal like make paper clips and it will pursue that goal so brilliantly that before we can stop it, it turns us into paper clips."}, {"time": 927, "text": "We'll give it the goal of curing cancer and it will turn us into guinea pigs for lethal experiments or give it the goal of world peace and its conception of world peace is no people, therefore no fighting and so it will kill us all."}, {"time": 938, "text": "Now I think these are utterly fanciful."}, {"time": 943, "text": "In fact, I think they're actually self defeating."}, {"time": 972, "text": "I think that the collateral damage scenario, the value alignment problem is also based on a misconception."}, {"time": 978, "text": "So one of the challenges, of course, we don't know how to build either system currently or are we even close to knowing?"}, {"time": 983, "text": "Of course, those things can change overnight, but at this time, theorizing about it is very challenging in either direction."}, {"time": 987, "text": "So that's probably at the core of the problem is without that ability to reason about the real engineering things here at hand is your imagination runs away with things."}, {"time": 999, "text": "But let me sort of ask, what do you think was the motivation, the thought process of Elon Musk?"}, {"time": 1005, "text": "I build autonomous vehicles, I study autonomous vehicles, I study Tesla autopilot."}, {"time": 1012, "text": "I think it is one of the greatest currently large scale application of artificial intelligence in the world."}, {"time": 1017, "text": "It has potentially a very positive impact on society."}, {"time": 1024, "text": "So how does a person who's creating this very good quote unquote narrow AI system also seem to be so concerned about this other general AI?"}, {"time": 1030, "text": "What do you think is the motivation there?"}, {"time": 1039, "text": "What do you think is the thing?"}, {"time": 1039, "text": "Well, you probably have to ask him, but there, and he is notoriously flamboyant, impulsive to the, as we have just seen, to the detriment of his own goals of the health of the company."}, {"time": 1051, "text": "So I don't know what's going on in his mind."}, {"time": 1057, "text": "You probably have to ask him, but I don't think the, and I don't think the distinction between special purpose AI and so called general AI is relevant that in the same way that special purpose AI is not going to do anything conceivable in order to attain a goal."}, {"time": 1070, "text": "All engineering systems are designed to trade off across multiple goals."}, {"time": 1077, "text": "When we build cars in the first place, we didn't forget to install brakes because the goal of a car is to go fast."}, {"time": 1082, "text": "It occurred to people, yes, you want it to go fast, but not always."}, {"time": 1088, "text": "So you would build in brakes too."}, {"time": 1088, "text": "Likewise, if a car is going to be autonomous and program it to take the shortest route to the airport, it's not going to take the diagonal and mow down people and trees and fences because that's the shortest route."}, {"time": 1104, "text": "That's not what we mean by the shortest route when we program it."}, {"time": 1104, "text": "And that's just what an intelligence system is by definition."}, {"time": 1109, "text": "It takes into account multiple constraints."}, {"time": 1116, "text": "The same is true, in fact, even more true of so called general intelligence."}, {"time": 1116, "text": "That is, if it's genuinely intelligent, it's not going to pursue some goal singlemindedly, omitting every other consideration and collateral effect."}, {"time": 1128, "text": "That's not artificial and general intelligence."}, {"time": 1128, "text": "That's artificial stupidity."}, {"time": 1134, "text": "I agree with you, by the way, on the promise of autonomous vehicles for improving human welfare."}, {"time": 1141, "text": "I think it's spectacular."}, {"time": 1141, "text": "And I'm surprised at how little press coverage notes that in the United States alone, something like 40,000 people die every year on the highways, vastly more than are killed by terrorists."}, {"time": 1151, "text": "And we spent a trillion dollars on a war to combat deaths by terrorism, about half a dozen a year."}, {"time": 1158, "text": "Whereas year in, year out, 40,000 people are massacred on the highways, which could be brought down to very close to zero."}, {"time": 1164, "text": "So I'm with you on the humanitarian benefit."}, {"time": 1169, "text": "Let me just mention that as a person who's building these cars, it is a little bit offensive to me to say that engineers would be clueless enough not to engineer safety into systems."}, {"time": 1179, "text": "I often stay up at night thinking about those 40,000 people that are dying."}, {"time": 1185, "text": "And everything I tried to engineer is to save those people's lives."}, {"time": 1185, "text": "So every new invention that I'm super excited about, in all the deep learning literature and CVPR conferences and NIPS, everything I'm super excited about is all grounded in making it safe and help people."}, {"time": 1199, "text": "So I just don't see how that trajectory can all of a sudden slip into a situation where intelligence will be highly negative."}, {"time": 1213, "text": "You and I certainly agree on that."}, {"time": 1213, "text": "And I think that's only the beginning of the potential humanitarian benefits of artificial intelligence."}, {"time": 1217, "text": "There's been enormous attention to what are we going to do with the people whose jobs are made obsolete by artificial intelligence, but very little attention given to the fact that the jobs that are going to be made obsolete are horrible jobs."}, {"time": 1232, "text": "The fact that people aren't going to be picking crops and making beds and driving trucks and mining coal, these are soul deadening jobs."}, {"time": 1238, "text": "And we have a whole literature sympathizing with the people stuck in these menial, mind deadening, dangerous jobs."}, {"time": 1245, "text": "If we can eliminate them, this is a fantastic boon to humanity."}, {"time": 1253, "text": "Now granted, you solve one problem and there's another one, namely, how do we get these people a decent income?"}, {"time": 1258, "text": "But if we're smart enough to invent machines that can make beds and put away dishes and handle hospital patients, I think we're smart enough to figure out how to redistribute income to apportion some of the vast economic savings to the human beings who will no longer be needed to make beds."}, {"time": 1279, "text": "Sam Harris says that it's obvious that eventually AI will be an existential risk."}, {"time": 1286, "text": "He's one of the people who says it's obvious."}, {"time": 1291, "text": "We don't know when the claim goes, but eventually it's obvious."}, {"time": 1291, "text": "And because we don't know when, we should worry about it now."}, {"time": 1298, "text": "This is a very interesting argument in my eyes."}, {"time": 1298, "text": "So how do we think about timescale?"}, {"time": 1305, "text": "How do we think about existential threats when we don't really, we know so little about the threat, unlike nuclear weapons perhaps, about this particular threat, that it could happen tomorrow, right?"}, {"time": 1318, "text": "So, but very likely it won't."}, {"time": 1318, "text": "Very likely it'd be a hundred years away."}, {"time": 1324, "text": "So how do we ignore it?"}, {"time": 1324, "text": "How do we talk about it?"}, {"time": 1324, "text": "Do we worry about it?"}, {"time": 1324, "text": "How do we think about those?"}, {"time": 1332, "text": "What is it?"}, {"time": 1333, "text": "A threat that we can imagine."}, {"time": 1333, "text": "It's within the limits of our imagination, but not within our limits of understanding to accurately predict it."}, {"time": 1344, "text": "But what is the it that we're afraid of?"}, {"time": 1346, "text": "AI being the existential threat."}, {"time": 1350, "text": "Like enslaving us or turning us into paperclips?"}, {"time": 1355, "text": "I think the most compelling from the Sam Harris perspective would be the paperclip situation."}, {"time": 1359, "text": "I mean, I just think it's totally fanciful."}, {"time": 1359, "text": "I mean, that is don't build a system."}, {"time": 1363, "text": "Don't give a, don't, first of all, the code of engineering is you don't implement a system with massive control before testing it."}, {"time": 1370, "text": "Now, perhaps the culture of engineering will radically change."}, {"time": 1375, "text": "Then I would worry, but I don't see any signs that engineers will suddenly do idiotic things, like put a electric power plant in control of a system that they haven't tested first."}, {"time": 1387, "text": "Or all of these scenarios, not only imagine almost a magically powered intelligence, including things like cure cancer, which is probably an incoherent goal because there's so many different kinds of cancer or bring about world peace."}, {"time": 1400, "text": "I mean, how do you even specify that as a goal?"}, {"time": 1405, "text": "But the scenarios also imagine some degree of control of every molecule in the universe, which not only is itself unlikely, but we would not start to connect these systems to infrastructure without testing as we would any kind of engineering system."}, {"time": 1425, "text": "Now, maybe some engineers will be irresponsible and we need legal and regulatory and legal responsibility implemented so that engineers don't do things that are stupid by their own standards."}, {"time": 1440, "text": "But the, I've never seen enough of a plausible scenario of existential threat to devote large amounts of brain power to, to forestall it."}, {"time": 1448, "text": "So you believe in the sort of the power on mass of the engineering of reason, as you argue in your latest book of Reason and Science, to sort of be the very thing that guides the development of new technology so it's safe and also keeps us safe."}, {"time": 1468, "text": "You know, granted the same culture of safety that currently is part of the engineering mindset for airplanes, for example."}, {"time": 1474, "text": "So yeah, I don't think that that should be thrown out the window and that untested all powerful systems should be suddenly implemented, but there's no reason to think they are."}, {"time": 1485, "text": "And in fact, if you look at the progress of artificial intelligence, it's been, you know, it's been impressive, especially in the last 10 years or so, but the idea that suddenly there'll be a step function that all of a sudden before we know it, it will be all powerful, that there'll be some kind of recursive self improvement, some kind of fume is also fanciful."}, {"time": 1506, "text": "We, certainly by the technology that we, that we're now impresses us, such as deep learning, where you train something on hundreds of thousands or millions of examples, they're not hundreds of thousands of problems of which curing cancer is a typical example."}, {"time": 1526, "text": "And so the kind of techniques that have allowed AI to increase in the last five years are not the kind that are going to lead to this fantasy of exponential sudden self improvement."}, {"time": 1531, "text": "I think it's kind of a magical thinking."}, {"time": 1540, "text": "It's not based on our understanding of how AI actually works."}, {"time": 1545, "text": "Now give me a chance here."}, {"time": 1545, "text": "So you said fanciful, magical thinking."}, {"time": 1545, "text": "In his TED talk, Sam Harris says that thinking about AI killing all human civilization is somehow fun, intellectually."}, {"time": 1555, "text": "Now I have to say as a scientist engineer, I don't find it fun, but when I'm having beer with my non AI friends, there is indeed something fun and appealing about it."}, {"time": 1568, "text": "Like talking about an episode of Black Mirror, considering if a large meteor is headed towards Earth, we were just told a large meteor is headed towards Earth, something like this."}, {"time": 1574, "text": "And can you relate to this sense of fun?"}, {"time": 1580, "text": "And do you understand the psychology of it?"}, {"time": 1584, "text": "I personally don't find it fun."}, {"time": 1584, "text": "I find it kind of actually a waste of time because there are genuine threats that we ought to be thinking about like pandemics, like cyber security vulnerabilities, like the possibility of nuclear war and certainly climate change."}, {"time": 1606, "text": "You know, this is enough to fill many conversations."}, {"time": 1606, "text": "And I think Sam did put his finger on something, namely that there is a community, sometimes called the rationality community, that delights in using its brainpower to come up with scenarios that would not occur to mere mortals, to less cerebral people."}, {"time": 1627, "text": "So there is a kind of intellectual thrill in finding new things to worry about that no one has worried about yet."}, {"time": 1634, "text": "I actually think, though, that it's not only is it a kind of fun that doesn't give me particular pleasure, but I think there can be a pernicious side to it, namely that you overcome people with such dread, such fatalism, that there are so many ways to die, to annihilate our civilization, that we may as well enjoy life while we can."}, {"time": 1659, "text": "There's nothing we can do about it."}, {"time": 1659, "text": "If climate change doesn't do us in, then runaway robots will."}, {"time": 1662, "text": "So let's enjoy ourselves now."}, {"time": 1662, "text": "We've got to prioritize."}, {"time": 1662, "text": "We have to look at threats that are close to certainty, such as climate change, and distinguish those from ones that are merely imaginable but with infinitesimal probabilities."}, {"time": 1678, "text": "And we have to take into account people's worry budget."}, {"time": 1685, "text": "You can't worry about everything."}, {"time": 1685, "text": "And if you sow dread and fear and terror and fatalism, it can lead to a kind of numbness."}, {"time": 1692, "text": "Well, these problems are overwhelming, and the engineers are just going to kill us all."}, {"time": 1697, "text": "So let's either destroy the entire infrastructure of science, technology, or let's just enjoy life while we can."}, {"time": 1706, "text": "So there's a certain line of worry, which I'm worried about a lot of things in engineering."}, {"time": 1712, "text": "There's a certain line of worry when you cross, you're allowed to cross, that it becomes paralyzing fear as opposed to productive fear."}, {"time": 1716, "text": "And that's kind of what you're highlighting."}, {"time": 1724, "text": "And we've seen some, we know that human effort is not well calibrated against risk in that because a basic tenet of cognitive psychology is that perception of risk and hence perception of fear is driven by imaginability, not by data."}, {"time": 1738, "text": "And so we misallocate vast amounts of resources to avoiding terrorism, which kills on average about six Americans a year with one exception of 9 11."}, {"time": 1751, "text": "We invade countries, we invent entire new departments of government with massive, massive expenditure of resources and lives to defend ourselves against a trivial risk."}, {"time": 1765, "text": "Whereas guaranteed risks, one of them you mentioned traffic fatalities and even risks that are not here, but are plausible enough to worry about like pandemics, like nuclear war, receive far too little attention."}, {"time": 1785, "text": "In presidential debates, there's no discussion of how to minimize the risk of nuclear war."}, {"time": 1791, "text": "Lots of discussion of terrorism, for example."}, {"time": 1791, "text": "And so I think it's essential to calibrate our budget of fear, worry, concern, planning to the actual probability of harm."}, {"time": 1808, "text": "So let me ask this question."}, {"time": 1808, "text": "So speaking of imaginability, you said it's important to think about reason and one of my favorite people who likes to dip into the outskirts of reason through fascinating exploration of his imagination is Joe Rogan."}, {"time": 1823, "text": "So who has through reason used to believe a lot of conspiracies and through reason has stripped away a lot of his beliefs in that way."}, {"time": 1837, "text": "So it's fascinating actually to watch him through rationality kind of throw away the ideas of Bigfoot and 9 11."}, {"time": 1843, "text": "I'm not sure exactly."}, {"time": 1843, "text": "Kim Trails."}, {"time": 1843, "text": "I don't know what he believes in."}, {"time": 1850, "text": "But he no longer believed in."}, {"time": 1850, "text": "No, that's right."}, {"time": 1850, "text": "No, he's become a real force for good."}, {"time": 1855, "text": "So you were on the Joe Rogan podcast in February and had a fascinating conversation, but as far as I remember, didn't talk much about artificial intelligence."}, {"time": 1860, "text": "I will be on his podcast in a couple of weeks."}, {"time": 1865, "text": "Joe is very much concerned about existential threat of AI."}, {"time": 1865, "text": "I'm not sure if you're, this is why I was hoping that you would get into that topic."}, {"time": 1871, "text": "And in this way, he represents quite a lot of people who look at the topic of AI from 10,000 foot level."}, {"time": 1882, "text": "So as an exercise of communication, you said it's important to be rational and reason about these things."}, {"time": 1889, "text": "Let me ask, if you were to coach me as an AI researcher about how to speak to Joe and the general public about AI, what would you advise?"}, {"time": 1924, "text": "And they all plummet because the culture of engineering is how do you squeeze out the lethal risks, death by fire, death by drowning, death by asphyxiation, all of them drastically declined because of advances in engineering that I got to say, I did not appreciate until I saw those graphs."}]}, {"title": "Jeff Atwood: Stack Overflow and Coding Horror | Lex Fridman Podcast #7", "id": "KZkYSSE8HHI", "quotes": [{"time": 286, "text": "There's a lot of examples of leaders that really mess this up, like they make decisions that are like, wow, it's a bad example for other people."}, {"time": 294, "text": "So I think leading by example is one."}, {"time": 297, "text": "The other one I believe is working really hard."}, {"time": 299, "text": "And I don't mean working exhaustively, but showing a real passion for the problem, not necessarily your solution to the problem, but the problem itself is just one that you really believe in."}, {"time": 311, "text": "Like with discourse, for example, the problem that we're looking at, which is my current project, is how do you get people in groups to communicate in a way that doesn't break down into the howling of wolves?"}, {"time": 321, "text": "How do you deal with trolling?"}, {"time": 323, "text": "Not like technical problems."}, {"time": 324, "text": "How do I get people to post paragraphs?"}, {"time": 326, "text": "How do I get people to use bold?"}, {"time": 327, "text": "How do I get people to use complete sentences, although those are problems as well?"}, {"time": 330, "text": "But how do I get people to get along with each other and then solve whatever problem it is they set out to solve, or reach some consensus on discussion, or just not hurt each other even?"}, {"time": 339, "text": "Maybe it's a discussion that doesn't really matter, but are people yelling at each other?"}, {"time": 344, "text": "Like that's not the purpose of this kind of communication."}, {"time": 346, "text": "So I would say leadership is about setting an example, doing the things that represent what you want to be, and making sure that you're actually doing those things."}, {"time": 356, "text": "And there's a trick to that too, because the things you don't do also say a lot about what you are."}, {"time": 362, "text": "Yeah, so let's pause on that one."}, {"time": 363, "text": "So those two things are fascinating."}, {"time": 365, "text": "So how do you have as a leader that self awareness?"}, {"time": 368, "text": "So you just said it's really hard to be self aware."}, {"time": 370, "text": "So for you personally, or maybe for other leaders you've seen or look up to, how do you know both that the things you're doing are the wrong things to be doing, the way you speak to others, the way you behave, and the things you're not doing?"}, {"time": 383, "text": "How do you get that signal?"}, {"time": 384, "text": "I think there's two aspects to that."}, {"time": 386, "text": "One is like processing feedback that you're getting, so."}, {"time": 389, "text": "How do you get feedback?"}, {"time": 390, "text": "Well, right, so are you getting feedback, right?"}, {"time": 392, "text": "So one way we do it, for example, with discourse, we have three cofounders, and we periodically talk about decisions before we make them."}, {"time": 398, "text": "So it's not like one person can make a mistake, or like, wow, there can be misunderstandings, things like that."}, {"time": 403, "text": "So it's part of like group consensus of leadership is like it's good to have, I think systems where there's one leader, and that leader has the rule of absolute law are just really dangerous in my experience."}, {"time": 413, "text": "For communities, for example, like if you have a community that's run by one person, that one person makes all the decisions, that person's gonna have a bad day."}, {"time": 419, "text": "Something could happen to that person, something, there's a lot of variables."}, {"time": 423, "text": "So like first, when you think about leadership, have multiple people doing leadership and have them talk amongst each other."}, {"time": 428, "text": "So giving each other feedback about the decisions that they're making."}, {"time": 432, "text": "And then when you do get feedback, I think there's that little voice in your head, right?"}, {"time": 436, "text": "Or your gut or wherever you wanna put it in your body."}, {"time": 439, "text": "I think that voice is really important."}, {"time": 442, "text": "Like I think most people who have any kind of moral compass or like want to do, most people want to do the right thing."}, {"time": 447, "text": "I do believe that."}, {"time": 448, "text": "I mean, there might be a handful of sociopaths out there that don't, but most people, they want other people to think of them as a good person."}, {"time": 454, "text": "And why wouldn't you, right?"}, {"time": 455, "text": "Like, do you want people to despise you?"}, {"time": 456, "text": "I mean, that's just weird, right?"}, {"time": 458, "text": "So you have that little voice that sort of the angel and devil on your shoulder sort of talking to you about like what you're doing, how you're doing, how does it make you feel to make these decisions, right?"}, {"time": 466, "text": "And I think having some attunement to that voice is important."}, {"time": 470, "text": "But you said that voice also for, I think this is a programmer situation too, where sometimes the devil on the shoulder is a little too loud."}, {"time": 479, "text": "So you're a little too self critical for a lot of developers, and especially when you have introverted personality."}, {"time": 485, "text": "How do you struggle with a self criticism or the criticism of others?"}, {"time": 489, "text": "So one of the things of leadership is to do something that's potentially unpopular or where people doubt you and you still go through with the decision."}, {"time": 498, "text": "So what's that balance like?"}, {"time": 501, "text": "I think you have to walk people through your decision making, right?"}, {"time": 503, "text": "Like you have to, this is where blogging is really important and communication is so important."}, {"time": 506, "text": "Again, code language is just another kind of code."}, {"time": 507, "text": "It's like, here is the program by which I arrived at the conclusion that I'm gonna reach, right?"}, {"time": 513, "text": "It's one thing to say like, this is a decision, it's final, deal with it, right?"}, {"time": 516, "text": "That's not usually satisfying to people."}, {"time": 518, "text": "But if you say, look, we've been thinking about this problem for a while."}, {"time": 521, "text": "Here's some stuff that's happened."}, {"time": 522, "text": "Here's what we think is right."}, {"time": 523, "text": "Here's our goals."}, {"time": 524, "text": "Here's what we wanna achieve."}, {"time": 525, "text": "And we've looked at these options and we think this available options is the best option."}, {"time": 530, "text": "People will be like, oh, okay, right?"}, {"time": 532, "text": "Maybe I don't totally agree with you, but I can kind of see where you're coming from and I see it's not just arbitrary decision delivered from a cloud of flames in the sky, right?"}, {"time": 540, "text": "It's like a human trying to reach some kind of consensus about goals."}, {"time": 544, "text": "And their goals might be different than yours."}, {"time": 545, "text": "That's completely legit, right?"}, {"time": 546, "text": "But if you're making that clear, it's like, oh, well, the reason we don't agree is because we have totally different goals, right?"}, {"time": 551, "text": "Like, how could we agree?"}, {"time": 552, "text": "It's not that you're a bad person."}, {"time": 554, "text": "It's that we have radically different goals in mind when we started looking at this problem."}, {"time": 558, "text": "And the other one you said is passion."}, {"time": 559, "text": "So, or hard work, sorry."}, {"time": 562, "text": "Well, those are tied together in my mind."}, {"time": 564, "text": "Let's say hard work and passion."}, {"time": 564, "text": "Like for me, like I just really love the problem discourse is setting out to solve because in a way it's like, there's a vision of the world where it all devolves into Facebook basically owning everything and every aspect of human communication, right?"}, {"time": 577, "text": "And this has always been kind of a scary world for me."}, {"time": 579, "text": "First, cause I don't, I think Facebook is really good at execution."}, {"time": 582, "text": "I got to compliment them."}, {"time": 583, "text": "They're very competent in terms of what they're doing, but Facebook has not much of a moral compass in terms of Facebook cares about Facebook, really."}, {"time": 590, "text": "They don't really care about you and your problems."}, {"time": 593, "text": "What they care about is how big they can make Facebook, right?"}, {"time": 596, "text": "Is that you talking about the company or just the mechanism of how Facebook works?"}, {"time": 599, "text": "Kind of both really, right?"}, {"time": 601, "text": "Like, and the idea with discourse, the reason I'm so passionate about it is cause I believe every community should have the right to own themselves, right?"}, {"time": 607, "text": "Like they should have their own software that they can run that belongs to them."}, {"time": 610, "text": "That's their space where they can set the rules."}, {"time": 612, "text": "And if they don't like it, they can move to different hosting or, you know, whatever they need to happen can happen."}, {"time": 618, "text": "But like this idea of a company town where all human communication is implicitly owned by WhatsApp, Instagram, and Facebook."}, {"time": 625, "text": "And it's really disturbing too, cause Facebook is really smart."}, {"time": 627, "text": "Like I said, they're great at execution."}, {"time": 628, "text": "Buying in WhatsApp and buying Instagram were incredibly smart decisions."}, {"time": 633, "text": "And they also do this thing, I don't know if you know, but they have this VPN software that they give away for free on smartphones and it indirectly feeds all the data about the traffic back to Facebook."}, {"time": 642, "text": "So they can see what's actually getting popular through the VPNs, right?"}, {"time": 645, "text": "They have low level access to the network data because users have let them have that."}, {"time": 651, "text": "So let's take a small pause here."}, {"time": 654, "text": "First of all, discourse."}, {"time": 655, "text": "Can you talk about, can you lay out the land of all the different ways you can have communities?"}, {"time": 661, "text": "So there's Stack Overflow that you've built."}, {"time": 663, "text": "There's discourse."}, {"time": 665, "text": "So Stack Overflow is kind of like a Wiki, Wikipedia you talk about."}, {"time": 669, "text": "And it's a very specific scalpel, very focused."}, {"time": 671, "text": "So what is the purpose of discourse and maybe contrast that with Facebook?"}, {"time": 676, "text": "First of all, say, what is discourse?"}, {"time": 678, "text": "Start from the beginning."}, {"time": 679, "text": "Well, let me start from the very beginning."}, {"time": 680, "text": "So Stack Overflow is a very structured Wiki style Q and A for programmers, right?"}, {"time": 684, "text": "And that was the problem we first worked on."}, {"time": 686, "text": "And when we started, we thought it was discussions because we looked at like programming forums and other things, but we quickly realized we were doing Q and A, which is a very narrow subset of human communication, right?"}, {"time": 696, "text": "Sorry, so when you started Stack Overflow, you thought you didn't even know the Q and A."}, {"time": 702, "text": "You didn't know it would be Q and A."}, {"time": 703, "text": "Well, we didn't know."}, {"time": 704, "text": "We had an idea of like, okay, these are things that we see working online."}, {"time": 706, "text": "We had a goal, right?"}, {"time": 707, "text": "Our goal was there was this site, Experts Exchange, with a very unfortunate name."}, {"time": 712, "text": "Thank you for killing that site."}, {"time": 713, "text": "Yeah, I know, right?"}, {"time": 714, "text": "Like a lot of people don't remember it anymore, which is great."}, {"time": 717, "text": "Like that's the measure of success when people don't remember the thing that you were trying to replace, then you've totally won."}, {"time": 722, "text": "So it was a place to get answers to programming questions, but it wasn't clear if it was like focused Q and A, if it was a discussion."}, {"time": 728, "text": "There were plenty of programming forums."}, {"time": 730, "text": "So we weren't really sure."}, {"time": 731, "text": "We were like, okay, we'll take aspects of dig and Reddit, like voting were very important."}, {"time": 735, "text": "Reordering answers based on votes."}, {"time": 737, "text": "Wiki style stuff of like being able to edit posts, not just your posts, but other people's posts to make them better and keep them more up to date."}, {"time": 743, "text": "Ownership of blogging of like, okay, this is me."}, {"time": 746, "text": "I'm saying this in my voice, this is the stuff that I know."}, {"time": 749, "text": "And your reputation accrues to you and it's peer recognition."}, {"time": 754, "text": "So you asked earlier, like what motivates programmers?"}, {"time": 757, "text": "I think peer recognition motivates them a lot."}, {"time": 760, "text": "That was one of the key insights of Stack Overflow was like recognition from your peers is why things get done."}, {"time": 764, "text": "Not necessarily money, not necessarily your boss, but like your peers saying, wow, this person really knows their stuff, has a lot of value."}, {"time": 770, "text": "So the reputation system came from that."}, {"time": 773, "text": "So we were sort of Frankensteining a bunch of stuff together in Stack Overflow, like stuff we had seen working and we knew worked and that became Stack Overflow."}, {"time": 784, "text": "Over time, we realized it wasn't really discussion."}, {"time": 786, "text": "It was very focused questions and answers."}, {"time": 788, "text": "There wasn't a lot of room on the page for let me talk about this tangential thing."}, {"time": 792, "text": "It was more like, okay, is it answering the question?"}, {"time": 794, "text": "Is it clarifying the question?"}, {"time": 796, "text": "Or could it be an alternative answer to the same question?"}, {"time": 798, "text": "Because there's usually more than one way to do it in programming, there's like say five to 10 ways."}, {"time": 802, "text": "And one of the patterns we got into early on with Stack Overflow was there were questions where there would be like hundreds of answers."}, {"time": 808, "text": "And we're like, wow, how can there be a programming question with 500, 200, 500 answers?"}, {"time": 814, "text": "And we looked at those and we realized those were not really questions in the traditional sense."}, {"time": 818, "text": "They were discussions."}, {"time": 819, "text": "It was stuff that we allowed early on that we eventually decided wasn't allowed such as what's your favorite programming food?"}, {"time": 826, "text": "What's the funniest programming cartoon you've seen?"}, {"time": 829, "text": "And we had to sort of backfill a bunch of rules about like, why isn't this allowed?"}, {"time": 833, "text": "Such as, is this a real problem you're facing?"}, {"time": 835, "text": "Like nobody goes to work and says, wow, I can't work cause I don't know what the funniest programming cartoon is."}, {"time": 839, "text": "So sorry, can't compile this code now, right?"}, {"time": 842, "text": "It's not a real problem you're facing in your job."}, {"time": 844, "text": "So that was run rule."}, {"time": 845, "text": "And the second, like, what can you really learn from that?"}, {"time": 847, "text": "It's like what I call accidental learning or Reddit style learning."}, {"time": 850, "text": "Where you're just like, oh, I'll just browse some things and oh, wow, you know, did you know tree frogs only live three years?"}, {"time": 854, "text": "I mean, I just made that up."}, {"time": 856, "text": "I don't know if that's true."}, {"time": 856, "text": "But I didn't really set out to learn that."}, {"time": 858, "text": "I don't need to know that, right?"}, {"time": 860, "text": "It's accidental learning."}, {"time": 861, "text": "It was more intentional learning where you're like, okay, I have a problem."}, {"time": 864, "text": "And I want to learn about stuff around this problem having, right?"}, {"time": 867, "text": "And it could be theory, it could be compiler theory, it could be other stuff, but I'm having a compiler problem."}, {"time": 871, "text": "Hence, I need to know the compiler theory, that aspect of it that gets me to my answer, right?"}, {"time": 878, "text": "So kind of a directed learning."}, {"time": 879, "text": "So we had to backfill all these rules as we sort of figured out what the heck it was we were doing."}, {"time": 883, "text": "And the system came very strict over time."}, {"time": 885, "text": "And a lot of people still complain about that."}, {"time": 886, "text": "And I wrote my latest blog entry, what does Stack Overflow want to be when it grows up?"}, {"time": 892, "text": "Celebrating the 10 year anniversary, yeah."}, {"time": 894, "text": "Yeah, so 10 years."}, {"time": 895, "text": "And the system has trended towards strictness."}, {"time": 897, "text": "There's a variety of reasons for this."}, {"time": 898, "text": "One is people don't like to see other people get reputation for stuff as they view as frivolous, which I can actually understand."}, {"time": 905, "text": "Because if you saw a programmer got like 500 upvotes for funniest programming cartoon or funniest comment they had seen in code, it's like, well, why do they have that reputation?"}, {"time": 913, "text": "Is it because they wrote the joke?"}, {"time": 915, "text": "I mean, if they did, maybe, or the cartoon, right?"}, {"time": 918, "text": "They're getting a bunch of reputation based on someone else's work that's not even programming."}, {"time": 922, "text": "It's just a joke, right?"}, {"time": 923, "text": "It's related to programming."}, {"time": 924, "text": "So you begin to resent that."}, {"time": 926, "text": "You're like, well, that's not fair."}, {"time": 927, "text": "And it isn't."}, {"time": 928, "text": "At some level, they're correct."}, {"time": 929, "text": "I mean, I empathize."}, {"time": 930, "text": "Because it's not correct to get reputation for that."}, {"time": 932, "text": "Versus here's a really gnarly regular expression problem."}, {"time": 936, "text": "And here's a really clever, insightful, detailed answer laying out, oh, here's why you're seeing the behavior that you're seeing."}, {"time": 942, "text": "Here, let me teach you some things about how to avoid that in the future."}, {"time": 945, "text": "That's gold, right?"}, {"time": 946, "text": "You want people to get reputation for that, not so much for, wow, look at this funny thing I saw, right?"}, {"time": 951, "text": "So there's this very specific Q&A format."}, {"time": 954, "text": "And then take me through the journey towards discourse and Facebook and Twitter."}, {"time": 958, "text": "So you started at the beginning that Stack Overflow evolved to have a purpose."}, {"time": 962, "text": "So what is discourse, this passion you have for creating community for discussion?"}, {"time": 970, "text": "When was that born and how?"}, {"time": 972, "text": "Well, part of it is based on the realization that Stack Overflow is only good for very specific subjects where it's based on data, facts, and science, where answers can be kind of verified to be true."}, {"time": 982, "text": "Another form of that is there's the book of knowledge, like the tome of knowledge that defines whatever it is."}, {"time": 988, "text": "You can refer to that book and it'll give you the answer."}, {"time": 990, "text": "There has to be, it only works on subjects where there's like semi clear answers to things that can be verified in some form."}, {"time": 997, "text": "Now again, there's always more than one way to do it."}, {"time": 999, "text": "There's complete flexibility and system around that."}, {"time": 1001, "text": "But where it falls down is stuff like poker and LEGO."}, {"time": 1005, "text": "Like we had, if you go to stackexchange.com, we have an engine that tries to launch different Q&A topics, right?"}, {"time": 1012, "text": "And people can propose Q&A topics, sample questions, and if it gets enough support within the network, we launched that Q&A site."}, {"time": 1020, "text": "So some of the ones we launched were poker and LEGO and they did horribly, right?"}, {"time": 1023, "text": "Because I mean, they might still be there lingering on in some form, but it was an experiment."}, {"time": 1027, "text": "This is like a test, right?"}, {"time": 1029, "text": "And some subjects work super well on the stack engine and some don't."}, {"time": 1032, "text": "But the reason LEGO and poker don't work is because they're so social, really."}, {"time": 1036, "text": "It's not about what's the rule here in poker."}, {"time": 1039, "text": "It's like, well, what kind of cigars do we like to smoke while playing poker?"}, {"time": 1043, "text": "Or what's a cool set of cards to use when I'm playing poker?"}, {"time": 1046, "text": "Or what's some strategies?"}, {"time": 1048, "text": "Say I have this hand come up with some strategies I could use."}, {"time": 1051, "text": "It's more of a discussion around what's happening with LEGO."}, {"time": 1054, "text": "Same thing, here's this cool LEGO set I found."}, {"time": 1056, "text": "Look how awesome this is."}, {"time": 1056, "text": "And I'm like, yeah, that's freaking awesome, right?"}, {"time": 1058, "text": "It's not a question, right?"}, {"time": 1059, "text": "There's all these social components and discussions that don't fit at all."}, {"time": 1063, "text": "We literally have to disallow those in Stack Overflow because it's not about being social."}, {"time": 1066, "text": "It's about problems that you're facing in your work that you need concrete answers for."}, {"time": 1071, "text": "You have a real demonstrated problem that's blocking you in something."}, {"time": 1074, "text": "Nobody's blocked by, what should I do when I have a straight flush?"}, {"time": 1078, "text": "It's not a blocking problem in the world."}, {"time": 1080, "text": "It's just an opportunity to hang out and discuss."}, {"time": 1082, "text": "So discourse was a way to address that and say, look, discussion forum software was very, very bad."}, {"time": 1090, "text": "And when I came out of Stack Overflow in early 2012, it was still very, very bad."}, {"time": 1099, "text": "I expected it improved in the four years since I last looked, but it had not improved at all."}, {"time": 1104, "text": "And I was like, well, that's kind of terrible because I love these communities of people talking about things that they love."}, {"time": 1111, "text": "They're just communities of interest, right?"}, {"time": 1112, "text": "And there's no good software for them."}, {"time": 1115, "text": "Startups would come to me and say, hey, Jeff, I want to have this startup."}, {"time": 1119, "text": "Here's my idea."}, {"time": 1120, "text": "And the first thing I would say to them is, well, first, why are you asking me?"}, {"time": 1124, "text": "I don't really know your field necessarily."}, {"time": 1127, "text": "Why aren't you asking the community, the people that are interested in this problem, the people that are using your product, why aren't you talking to them?"}, {"time": 1133, "text": "And then they'd say, oh, great idea."}, {"time": 1135, "text": "How do I do that?"}, {"time": 1136, "text": "And then that's when I started playing sad trombone because I realized all the software involving talking to your users, customers, audience, patrons, whatever it is, it was all really bad."}, {"time": 1144, "text": "It was stuff that I would be embarrassed to recommend to other people."}, {"time": 1148, "text": "And yet, that's where I felt they could get the biggest and strongest, most effective input for what they should be doing with their product, right?"}, {"time": 1155, "text": "It's from their users, from their community, right?"}, {"time": 1157, "text": "That's what we did on Stack Overflow."}, {"time": 1158, "text": "So what we're talking about with forums, the, what is it, the dark matter of the internet, it's still, I don't know if it's still, but for the longest time, it has some of the most passionate and fascinating discussions."}, {"time": 1172, "text": "And what's the usual structure?"}, {"time": 1174, "text": "There's usually, it's linear, so it's sequential."}, {"time": 1178, "text": "So you're posting one after the other and there's pagination, so it's every, there's 10 posts and then you go to the next page."}, {"time": 1185, "text": "And that format still is used by, like I'm, we're doing a lot of research with Tesla vehicles and there's a Tesla Motors Club forum, which is extremely."}, {"time": 1194, "text": "We really wanted to run that actually."}, {"time": 1196, "text": "They pinged us about it, I don't think we got it, but I really would have liked to gotten that one."}, {"time": 1199, "text": "But they've started before even 2012, I believe."}, {"time": 1202, "text": "I mean, they've been running for a long time."}, {"time": 1204, "text": "It's still an extremely rich source of information."}, {"time": 1206, "text": "So what's broken about that system and how are you trying to fix it?"}, {"time": 1212, "text": "I think there's a lot of power in connecting people that love the same stuff around that specific topic."}, {"time": 1219, "text": "Meaning Facebook's idea of connection is just any human that's related to another human, right?"}, {"time": 1224, "text": "Like through friendship or any other reason."}, {"time": 1227, "text": "Facebook's idea of the world is sort of the status update, right?"}, {"time": 1230, "text": "Like a friend of yours did something, ate at a restaurant, right?"}, {"time": 1234, "text": "Whereas discussion forums were traditionally around the interest graph."}, {"time": 1238, "text": "Like I love electric cars, specifically I love Tesla, right?"}, {"time": 1241, "text": "Like I love the way they approach the problem."}, {"time": 1244, "text": "I love the style of the founder."}, {"time": 1245, "text": "I just love the design ethic."}, {"time": 1248, "text": "And there's a lot to like about Tesla."}, {"time": 1249, "text": "I don't know if you saw the oatmeal, he did a whole love comic to Tesla."}, {"time": 1253, "text": "And it was actually kind of cool because I learned some stuff."}, {"time": 1254, "text": "He was talking about how great Tesla cars were specifically, like how they were built differently."}, {"time": 1258, "text": "And he went into a lot of great detail that was really interesting."}, {"time": 1260, "text": "And to me, that oatmeal post, if you read it, is the genesis of pretty much all interest communities."}, {"time": 1265, "text": "I just really love this stuff."}, {"time": 1266, "text": "So like for me, for example, there's yo yos, right?"}, {"time": 1268, "text": "Like I'm into the yo yo communities."}, {"time": 1269, "text": "And these interest communities are just really fascinating to me."}, {"time": 1272, "text": "And I feel more connected to the yo yo communities than I do to friends that I don't see that often, right?"}, {"time": 1278, "text": "Like to me, the powerful thing is the interest graph."}, {"time": 1281, "text": "And Facebook kind of dabbles in the interest graph."}, {"time": 1285, "text": "I mean, they have groups, you can sign up for groups and stuff, but it's really about the relationship graph."}, {"time": 1289, "text": "Like this is my coworker, this is my relative, this is my friend, but not so much about the interest."}, {"time": 1295, "text": "So I think that's the linchpin of which forums and communities are built on that I personally love."}, {"time": 1300, "text": "Like I said, leadership is about passion, right?"}, {"time": 1304, "text": "And being passionate about stuff is a really valid way to look at the world."}, {"time": 1307, "text": "And I think it's a way a lot of stuff in the world gets done."}, {"time": 1311, "text": "Like I once had someone describe me as, he's like, Jeff, you're a guy who, you just get super passionate about a few things at a time, and you just go super deep in those things."}, {"time": 1319, "text": "And I was like, oh, that's kind of right."}, {"time": 1320, "text": "That's kind of what I do."}, {"time": 1321, "text": "I get into something and just be super into that for a couple of years or whatever, and just learn all I can about it, and go super deep in it."}, {"time": 1327, "text": "And that's how I enjoy experiencing the world, right?"}, {"time": 1331, "text": "Like not being shallow on a bunch of things, but being really deep on a few things that I'm interested in."}, {"time": 1335, "text": "So forums kind of unlock that, right?"}, {"time": 1337, "text": "And you don't want a world where everything belongs to Facebook, at least I don't."}, {"time": 1340, "text": "I want a world where communities can kind of own themselves, set their own norms, set their own rules, control the experience."}, {"time": 1346, "text": "Because community is also about ownership, right?"}, {"time": 1348, "text": "Like if you're meeting at the Barnes and Noble every Thursday and Barnes and Noble says, get out of here, you guys don't buy enough books."}, {"time": 1354, "text": "Well, you know, you're kind of hosed, right?"}, {"time": 1356, "text": "Barnes and Noble owns you, right?"}, {"time": 1357, "text": "Like you can't."}, {"time": 1358, "text": "But if you have your own meeting space, you know, your own clubhouse, you can set your own rules, decide what you want to talk about there, and just really generate a lot better information than you could like hanging out at Barnes and Noble every Thursday at 3 p.m., right?"}, {"time": 1371, "text": "So that's kind of the vision of Discourse, is a place where it's fully open source."}, {"time": 1377, "text": "You can take the software, you can install it anywhere, and, you know, you and a group of people can go deep on whatever it is that you're into."}, {"time": 1382, "text": "And this works for startups, right?"}, {"time": 1384, "text": "Startups are a group of people who go super deep on a specific problem, right?"}, {"time": 1388, "text": "And they want to talk to the community."}, {"time": 1389, "text": "It's like, well, install Discourse, right?"}, {"time": 1391, "text": "That's what we do at Discourse."}, {"time": 1392, "text": "That's what I did at Stack Overflow."}, {"time": 1393, "text": "I spent a lot of time on Meta Stack Overflow, which is our internal, well, public community feedback site, and just experiencing what the users were experiencing, right, because they're the ones doing all the work in the system."}, {"time": 1406, "text": "And they had a lot of interesting feedback."}, {"time": 1407, "text": "And there's that 90, 10 rule of, like, 90% of the feedback you get is not really actionable for a variety of reasons."}, {"time": 1412, "text": "It might be bad feedback, it might be crazy feedback, it might be feedback you just can't act on right now."}, {"time": 1416, "text": "But there's 10% of it that's like gold."}, {"time": 1418, "text": "It's like literally gold and diamonds, where it's like feedback of really good improvements to your core product that are not super hard to get to and actually make a lot of sense."}, {"time": 1425, "text": "And my favorite is about 5% of those stuff I didn't even see coming."}, {"time": 1428, "text": "It's like, oh my God, I never even thought of that."}, {"time": 1430, "text": "But that's a brilliant idea, right?"}, {"time": 1432, "text": "And I can point to so many features of Stack Overflow that we derive from Meta Stack Overflow feedback and Meta discourse, right?"}, {"time": 1438, "text": "Same exact principle of discourse, you know?"}, {"time": 1441, "text": "We're getting ideas from the community."}, {"time": 1442, "text": "I was like, oh my God, I never thought of that, but that's fantastic, right?"}, {"time": 1444, "text": "Like, I love that relationship with the community."}, {"time": 1446, "text": "From having built these communities, what have you learned about?"}, {"time": 1451, "text": "What's the process of getting a critical mass of members in a community?"}, {"time": 1454, "text": "Is it luck, skill, timing, persistence?"}, {"time": 1457, "text": "What is, is it the tools, like discourse, that empower that community?"}, {"time": 1461, "text": "What's the key aspect of starting for one guy or gal and then building it to two and then 10 and a hundred and a thousand and so on?"}, {"time": 1469, "text": "I think when you're starting with an N of one, I mean, I think it's persistence and also you have to be interesting."}, {"time": 1477, "text": "Like somebody I really admire once said something that I always liked about blogging."}, {"time": 1480, "text": "He's like, here's how you blog."}, {"time": 1481, "text": "You have to have something interesting to say and have an interesting way of saying it, right?"}, {"time": 1486, "text": "And then do that for like 10 years."}, {"time": 1489, "text": "So that's the genesis, is like you have to have sort of something interesting to say that's not exactly what everybody else is saying and an interesting way of saying it, which is another way of saying, kind of entertaining way of saying it."}, {"time": 1499, "text": "And then as far as growing it, it's like ritual."}, {"time": 1501, "text": "You know, like you have to, like say you're starting a blog, you have to say, look, I'm gonna blog every week, three times a week, and you have to stick to that schedule, right?"}, {"time": 1509, "text": "Because until you do that for like several years, you're never gonna get anywhere."}, {"time": 1514, "text": "Like it just takes years to get to where you need to get to."}, {"time": 1516, "text": "And part of that is having the discipline to stick with the schedule."}, {"time": 1519, "text": "And it helps, again, if it's something you're passionate about, this won't feel like work."}, {"time": 1522, "text": "You're like, I love this."}, {"time": 1523, "text": "I could talk about this all day, every day, right?"}, {"time": 1526, "text": "You just have to do it in a way that's interesting to other people."}, {"time": 1528, "text": "And then as you're growing the community, that pattern of participation within the community of like generating these artifacts and inviting other people to help you like collaborate on these artifacts, like even in the case of blogging, like I felt in the early days of my blog, which I started in 2004, which is really the genesis of Stack Overflow."}, {"time": 1543, "text": "If you look at all my blog, it leads up to Stack Overflow, which was, I have all this energy in my blog, but I don't, like 40,000 people were subscribing to me."}, {"time": 1551, "text": "And I was like, I wanna do something."}, {"time": 1552, "text": "And then I met Joel and said, hey, Joel, I wanna do something, take this ball of energy from my blog and do something."}, {"time": 1557, "text": "And all the people reading my blog saw that."}, {"time": 1558, "text": "It's like, oh, cool."}, {"time": 1559, "text": "You're involving us."}, {"time": 1560, "text": "You're saying, look, you're part of this community."}, {"time": 1563, "text": "Let's build this thing together."}, {"time": 1564, "text": "Like they pick the name."}, {"time": 1565, "text": "Like we voted on the name for Stack Overflow on my blog."}, {"time": 1568, "text": "Like we came up, and naming is super hard."}, {"time": 1569, "text": "First of all, the hardest problem in computer science is coming up with a good name for stuff, right?"}, {"time": 1574, "text": "But you can go back to my blog."}, {"time": 1575, "text": "There's the poll where we voted and Stack Overflow became the name of the site."}, {"time": 1579, "text": "And all the early beta users of Stack Overflow were audience of my blog plus Joel's blog, right?"}, {"time": 1584, "text": "So we started from, like, if you look at the genesis, okay, I was just a programmer who said, hey, I love programming, but I have no outlet to talk about it."}, {"time": 1591, "text": "So I'm just gonna blog about it, because I don't have enough people to work to talk to about it."}, {"time": 1594, "text": "Because at the time I worked a place where, you know, programming wasn't the core output of the company, it was a pharmaceutical company."}, {"time": 1600, "text": "And I just love this stuff, you know, to an absurd degree."}, {"time": 1603, "text": "So I was like, I'll just blog about it."}, {"time": 1604, "text": "And then I'll find an audience and eventually found an audience, eventually found Joel, and eventually built Stack Overflow from that one core of activity, right?"}, {"time": 1612, "text": "But it was that repetition of feeding back in feedback from my blog comments, feedback from Joel, feedback from the early Stack Overflow community."}, {"time": 1621, "text": "When people see that you're doing that, they will follow along with you, right?"}, {"time": 1624, "text": "They'll say, cool, you're here in good faith."}, {"time": 1625, "text": "You're actually, you know, not listening to everything because that's impossible, that's impossible."}, {"time": 1629, "text": "But you're actually, you know, waiting our feedback and what you're doing."}, {"time": 1634, "text": "And why wouldn't I?"}, {"time": 1634, "text": "Because who does all the work on Stack Overflow?"}, {"time": 1636, "text": "Me, Joel?"}, {"time": 1637, "text": "No, it's the other programmers that are doing all the work."}, {"time": 1640, "text": "So you gotta have some respect for that."}, {"time": 1642, "text": "And then, you know, discipline around, look, you know, we're trying to do a very specific thing here on Stack Overflow."}, {"time": 1647, "text": "We're not trying to solve all the world's problems."}, {"time": 1649, "text": "We're trying to solve this very specific Q and A problem in a very specific way."}, {"time": 1652, "text": "Not cause we're jerks about it, but because these strict set of rules help us get really good results, right?"}, {"time": 1659, "text": "And programmers, that's an easy sell for the most part because programmers are used to dealing with ridiculous systems of rules like constantly."}, {"time": 1665, "text": "That's basically their job."}, {"time": 1666, "text": "So they're very, oh yeah, super strict system of rules that lets me get what I want."}, {"time": 1670, "text": "That's programming, right?"}, {"time": 1671, "text": "That's what Stack Overflow is, so."}, {"time": 1673, "text": "So you're making it sound easy, but in 2004, let's go back there."}, {"time": 1678, "text": "In 2004, you started the blog, Coding Horror."}, {"time": 1681, "text": "Was it called that at the very beginning?"}, {"time": 1684, "text": "One of the smart things I did, it's from a book by Steve McConnell, Code Complete, which is one of my favorite programming books, still probably my number one programming book for anyone to read."}, {"time": 1690, "text": "So one of the smart things I did back then, I don't always do smart things when I start stuff."}, {"time": 1696, "text": "I contacted Steve and said, hey, I really like this."}, {"time": 1698, "text": "It was a sidebar illustration indicating danger in code, right?"}, {"time": 1701, "text": "Coding Horror was like, watch out."}, {"time": 1705, "text": "And I love that illustration because it spoke to me."}, {"time": 1707, "text": "Because I saw that illustration go, oh my God, that's me."}, {"time": 1709, "text": "Like I'm always my own worst enemy."}, {"time": 1711, "text": "Like that's the key insight in programming is every time you write something, think how am I gonna screw myself?"}, {"time": 1716, "text": "Because you will, constantly, right?"}, {"time": 1719, "text": "So that icon was like, oh yeah, I need to constantly hold that mirror up and look, and say, look, you're very fallible."}, {"time": 1725, "text": "You're gonna screw this up."}, {"time": 1726, "text": "Like how can you build this in such a way that you're not gonna screw it up later?"}, {"time": 1730, "text": "Like how can you get that discipline around making sure at every step I'm thinking through all the things that I could do wrong or that other people could do wrong?"}, {"time": 1737, "text": "Because that is actually how you get to be a better programmer a lot of times, right?"}, {"time": 1740, "text": "So that sidebar illustration, I loved it so much."}, {"time": 1743, "text": "And I wrote Steve before I started my blog and said, hey, can I have permission to use this because I just really like this illustration?"}, {"time": 1748, "text": "And Steve was kind enough to give me permission to do that and just continues to give me permission, so yeah."}, {"time": 1753, "text": "Really, that's awesome."}, {"time": 1755, "text": "But in 2004, you started this blog."}, {"time": 1758, "text": "You know, you look at Stephen King, his book on writing, or Stephen Pressfield, War of Art book."}, {"time": 1766, "text": "I mean, it seems like writers suffer."}, {"time": 1770, "text": "I mean, it's a hard process of writing, right?"}, {"time": 1772, "text": "There's gonna be suffering."}, {"time": 1774, "text": "I mean, I won't kid you."}, {"time": 1775, "text": "Well, the work is suffering, right?"}, {"time": 1776, "text": "Like doing the work, like even when you're every week, you're like, okay, that blog post wasn't very good or people didn't like it or people said disparaging things about it."}, {"time": 1784, "text": "You have to like have the attitude like, you know, no matter what happens, I wanna do this for me, right?"}, {"time": 1789, "text": "It's not about you, it's about me."}, {"time": 1791, "text": "I mean, in the end, it is about everyone because this is how good work gets out into the world."}, {"time": 1795, "text": "But you have to be pretty strict about saying like, you know, I'm selfish in the sense that I have to do this for me."}, {"time": 1803, "text": "You know, you mentioned Stephen King, like his book on writing."}, {"time": 1805, "text": "But like one of the things I do, for example, when writing is like, I read it out loud."}, {"time": 1808, "text": "One of the best pieces of advice for writing anything is read it out loud, like multiple times and make it sound like you're talking because that is the goal of good writing."}, {"time": 1817, "text": "It should sound like you said it with slightly better phrasing because you have more time to think about what you're saying but like, it should sound natural when you say it."}, {"time": 1824, "text": "And I think that's probably the single best writing advice I can give anyone."}, {"time": 1827, "text": "Just read it over and over out loud, make sure it sounds like something you would normally say and it sounds good."}, {"time": 1833, "text": "And what's your process of writing?"}, {"time": 1835, "text": "See, there's usually a pretty good idea behind the blog post."}, {"time": 1839, "text": "So ideas, right."}, {"time": 1840, "text": "So I think you gotta have the concept that there's so many interesting things in the world."}, {"time": 1846, "text": "Like, I mean, my God, the world is amazing, right?"}, {"time": 1848, "text": "Like you can never write about everything that's going on because it's so incredible."}, {"time": 1852, "text": "But if you can't come up with like, let's say one interesting thing per day to talk about, then you're not trying hard enough because the world is full of just super interesting stuff."}, {"time": 1860, "text": "And one great way to like mine stuff is go back to old books cause they bring up old stuff that's still super relevant."}, {"time": 1867, "text": "And I did that a lot cause I was like reading classic programming books and a lot of the early blog posts were like, oh, I was reading this programming book and they brought this really cool concept and I wanna talk about it some more."}, {"time": 1875, "text": "And you get the, I mean, you're not claiming credit for the idea but it gives you something interesting to talk about that's kind of evergreen, right?"}, {"time": 1879, "text": "Like you don't have to go, what should I talk about?"}, {"time": 1881, "text": "So we'll just go dig up some old classic programming books and find something that, oh, wow, that's interesting."}, {"time": 1886, "text": "Or how does that apply today?"}, {"time": 1888, "text": "Or what about X and Y or compare these two concepts."}, {"time": 1890, "text": "So pull a couple of sentences from that book and then sort of play off of it, almost agree or disagree."}, {"time": 1896, "text": "So in 2007, you wrote that you were offered a significant amount of money to sell the blog."}, {"time": 1904, "text": "You chose not to."}, {"time": 1905, "text": "What were all the elements you were thinking about?"}, {"time": 1908, "text": "Cause I'd like to take you back."}, {"time": 1910, "text": "It seems like there's a lot of nonlinear decisions you made through life."}, {"time": 1914, "text": "So what was that decision like?"}, {"time": 1916, "text": "Right, so one of the things I love is the Choose Your Own Adventure books, which I loved as a kid and I feel like they're early programmer books cause they're all about if then statements, right?"}, {"time": 1924, "text": "If this, then this."}, {"time": 1925, "text": "And they're also very, very unforgiving."}, {"time": 1927, "text": "Like there's all these sites that map the classic Choose Your Own Adventure books and how many outcomes are bad, a lot of bad outcomes."}, {"time": 1933, "text": "So part of the game is like, oh, I got a bad outcome."}, {"time": 1936, "text": "Go back one step, go back one further step."}, {"time": 1937, "text": "It's like, how did I get here, right?"}, {"time": 1939, "text": "Like it's a sequence of decisions."}, {"time": 1941, "text": "And this is true of life, right?"}, {"time": 1943, "text": "Like every decision is a sequence, right?"}, {"time": 1944, "text": "Individually, any individual decision is not necessarily right or wrong, but they lead you down a path, right?"}, {"time": 1951, "text": "So I do think there's some truth to that."}, {"time": 1952, "text": "So this particular decision, the blog had gotten fairly popular."}, {"time": 1956, "text": "There's a lot of RSS readers that I had discovered."}, {"time": 1959, "text": "And this guy contacted me out of the blue from this like bug tracking company."}, {"time": 1962, "text": "He's like, oh, I really wanna buy your blog for like, I think it was around, it was $100,000, it might have been like 80,000, but it was a lot, right?"}, {"time": 1969, "text": "Like, and that's, you know, at the time, like I would have a year's worth of salary all at once."}, {"time": 1974, "text": "So I didn't really think about like, well, you know, and I remember talking to people at the time, I was like, wow, that's a lot of money."}, {"time": 1979, "text": "But then I'm like, I really like my blog, right?"}, {"time": 1982, "text": "Like, do I wanna sell my blog?"}, {"time": 1983, "text": "Cause it wouldn't really belong to me anymore at that point."}, {"time": 2007, "text": "Cause if you pick the safe choice, it's usually, you're not really pushing."}, {"time": 2010, "text": "You're not pushing yourself."}, {"time": 2011, "text": "You're not choosing the thing that's gonna help you grow."}, {"time": 2013, "text": "So for me, the scarier choice was to say no."}, {"time": 2016, "text": "I was like, well, no, let's just see where this is going."}, {"time": 2018, "text": "Because then I own it."}, {"time": 2019, "text": "I mean, it belongs to me."}, {"time": 2020, "text": "It's my thing."}, {"time": 2022, "text": "And I can just take it and tell some other logical conclusion, right?"}, {"time": 2025, "text": "Because imagine how different the world would have been had I said yes and sold the blog."}, {"time": 2029, "text": "It's like, there probably wouldn't be Stack Overflow."}, {"time": 2031, "text": "You know, a lot of other stuff would have changed."}, {"time": 2033, "text": "So for that particular decision, I think it was that same rule."}, {"time": 2036, "text": "Like what scares me a little bit more."}, {"time": 2037, "text": "Do the thing that scares you."}, {"time": 2040, "text": "So speaking of which, startups."}, {"time": 2041, "text": "I think there's a specific, some more general questions that a lot of people would be interested in."}, {"time": 2047, "text": "You've started Stack Overflow."}, {"time": 2050, "text": "You started this course."}, {"time": 2052, "text": "So what's the, it was one, two, three guys, whatever it is in the beginning."}, {"time": 2057, "text": "What was that process like?"}, {"time": 2059, "text": "Do you start talking about it?"}, {"time": 2060, "text": "Do you start programming?"}, {"time": 2061, "text": "Do you start, like, where's the birth and the catalyst that actually."}, {"time": 2065, "text": "Well, I can talk about it in the context of both Stack Overflow and Discourse."}, {"time": 2068, "text": "So I think the key thing initially is there is a problem."}, {"time": 2071, "text": "Something, there's some state of the world that's unsatisfactory to the point that, like, you're upset about it, right?"}, {"time": 2075, "text": "Like, in that case, it was experts exchange."}, {"time": 2077, "text": "I mean, Joel's original idea, because I approached Joel as like, look, Joel, I have all this energy behind my blog."}, {"time": 2081, "text": "I want to do something."}, {"time": 2082, "text": "I want to build something."}, {"time": 2083, "text": "But I don't know what it is, because I'm honestly not a good idea person."}, {"time": 2085, "text": "I'm really not."}, {"time": 2086, "text": "I'm like the execution guy."}, {"time": 2087, "text": "I'm really good at execution, but I'm not good at, like, blue skying ideas."}, {"time": 2091, "text": "Not my forte."}, {"time": 2092, "text": "Which is another reason why I like the community feedback, because they blue sky all day long for you, right?"}, {"time": 2096, "text": "So when I can just go in and cherry pick a blue sky idea from community, even if I have to spend three hours reading to get one good idea, it's worth it, man."}, {"time": 2102, "text": "But anyway, so the idea from Joel was, hey, experts exchange, it's got great data, but the experience is hideous, right?"}, {"time": 2109, "text": "It's trying to trick you."}, {"time": 2109, "text": "It feels like used car salesman."}, {"time": 2111, "text": "It's just bad."}, {"time": 2112, "text": "So I was like, oh, that's awesome."}, {"time": 2113, "text": "It feeds into community."}, {"time": 2114, "text": "It feeds into, like, you know, we can make creative comments."}, {"time": 2116, "text": "So I think the core is to have a really good idea that you feel very strongly about in the beginning, that, like, there's a wrong in the world, an injustice that we will write through the process of building this thing."}, {"time": 2126, "text": "For Discourse, it was like, look, there's no good software for communities to just hang out and, like, do stuff, right?"}, {"time": 2132, "text": "Like, whether it's problem solving, startup, whatever."}, {"time": 2135, "text": "Forums are such a great building block of online community, and they're hideous."}, {"time": 2138, "text": "They were so bad, right?"}, {"time": 2139, "text": "It was embarrassing."}, {"time": 2140, "text": "Like, I literally was embarrassed to be associated with this software, right?"}, {"time": 2143, "text": "I was like, we have to have software that you can be proud of."}, {"time": 2145, "text": "It's like, this is competitive with Reddit."}, {"time": 2147, "text": "This is competitive with Twitter."}, {"time": 2148, "text": "This is competitive with Facebook, right?"}, {"time": 2150, "text": "I would be proud to have the software on my site."}, {"time": 2153, "text": "So that was the genesis of Discourse, was feeling very strongly about there needs to be a good solution for communities."}, {"time": 2161, "text": "So that's step one."}, {"time": 2162, "text": "Genesis of an idea you feel super strongly about, right?"}, {"time": 2164, "text": "And then people galvanize around the idea."}, {"time": 2166, "text": "Like, Joel was already super excited about the idea."}, {"time": 2168, "text": "I was excited about the idea."}, {"time": 2169, "text": "So with the forum software, I was posting on Twitter."}, {"time": 2173, "text": "I had researched, as part of my research, I start researching the problem, right?"}, {"time": 2176, "text": "And I found a game called Forum Wars, which was a parody of forum."}, {"time": 2181, "text": "It's still very, very funny, of forum behavior, circa, I would say, 2003."}, {"time": 2186, "text": "It's aged some, right?"}, {"time": 2187, "text": "Like, the behavior's a little different in there of Twitter."}, {"time": 2189, "text": "But it was awesome."}, {"time": 2190, "text": "It was very funny."}, {"time": 2191, "text": "And it was like a game."}, {"time": 2192, "text": "It was like an RPG."}, {"time": 2193, "text": "And it had a forum attached to it."}, {"time": 2194, "text": "So it was like a game about forums with a forum attached."}, {"time": 2197, "text": "I was like, this is awesome, right?"}, {"time": 2198, "text": "This is so cool."}, {"time": 2199, "text": "And the founder of that company, or that project, it wasn't really a company, contacted me, this guy Robin Ward from Toronto."}, {"time": 2205, "text": "He said, hey, I saw you've been talking about forums."}, {"time": 2207, "text": "And I really love that problem space."}, {"time": 2209, "text": "He was like, I'd still love to build really good forum software, because I don't think anything out there's any good."}, {"time": 2213, "text": "And I was like, awesome."}, {"time": 2214, "text": "At that point, I was like, we're starting a company."}, {"time": 2215, "text": "Because I couldn't have whooshed for a better person to walk through the door and say, I'm excited about this, too."}, {"time": 2221, "text": "Same thing with Joel, right?"}, {"time": 2222, "text": "I mean, Joel is a legend in the industry, right?"}, {"time": 2224, "text": "So when he walked through and said, I'm excited about this problem, I was like, me too, man."}, {"time": 2226, "text": "We can do this, right?"}, {"time": 2228, "text": "So that, to me, is the most important step."}, {"time": 2230, "text": "It's like, having an idea you're super excited about, and another person, a cofounder, right?"}, {"time": 2234, "text": "Because again, you get that dual leadership, right?"}, {"time": 2236, "text": "Am I making a bad decision?"}, {"time": 2239, "text": "Sometimes it's nice to have checks of like, is this a good idea?"}, {"time": 2242, "text": "I don't know, right?"}, {"time": 2243, "text": "So those are the crucial seeds."}, {"time": 2245, "text": "But then starting to build stuff, whether it's you programming or somebody else's."}, {"time": 2248, "text": "There is prototyping."}, {"time": 2249, "text": "So there's tons of research."}, {"time": 2250, "text": "There's tons of research, like, what's out there that failed?"}, {"time": 2252, "text": "Because a lot of people look at the successes."}, {"time": 2254, "text": "Oh, look at how successful X is."}, {"time": 2256, "text": "Everybody looks at the successes."}, {"time": 2257, "text": "Those are boring."}, {"time": 2258, "text": "Show me the failures, because that is what's interesting."}, {"time": 2260, "text": "That's where people were experimenting."}, {"time": 2262, "text": "That's where people were pushing."}, {"time": 2263, "text": "And they failed, but they probably failed for reasons that weren't directly about the quality of their idea, right?"}, {"time": 2270, "text": "So look at all the failures."}, {"time": 2271, "text": "Don't just look what everybody looks at, which is like, oh, gosh, look at all these successful people."}, {"time": 2274, "text": "Look at the failures."}, {"time": 2275, "text": "Look at the things that didn't work."}, {"time": 2277, "text": "Research the entire field."}, {"time": 2279, "text": "And so that's the research that I was doing that led me to Robin, right?"}, {"time": 2282, "text": "Was that."}, {"time": 2283, "text": "And then when we, for example, when we did Stack Overflow, we're like, okay, well, I really like elements of voting and dig and read it."}, {"time": 2290, "text": "I like the Wikipedia, everything's up to date."}, {"time": 2292, "text": "Nothing is like an old tombstone that has horrible out of date information."}, {"time": 2296, "text": "We know that works."}, {"time": 2297, "text": "Wikipedia is an amazing resource."}, {"time": 2299, "text": "Blogging, the idea of ownership is so powerful, right?"}, {"time": 2302, "text": "Like, oh, I, Joe wrote this, and look how good Joe's answer is, right?"}, {"time": 2306, "text": "All these concepts were rolling together."}, {"time": 2307, "text": "Researching all the things that were out there that were working and why they were working and trying to fold them into, again, that Frankenstein's monster of what Stack Overflow is."}, {"time": 2315, "text": "And by the way, that wasn't a free decision because there's still a ton of tension in the Stack Overflow system."}, {"time": 2320, "text": "There's reasons people complain about Stack Overflow because it's so strict, right?"}, {"time": 2323, "text": "Why is it so strict?"}, {"time": 2324, "text": "Why are you guys always closing my questions?"}, {"time": 2326, "text": "It's because there's so much tension that we built into the system around trying to get good, good results out of the system."}, {"time": 2331, "text": "And it's not a free."}, {"time": 2336, "text": "That stuff doesn't come for free, right?"}, {"time": 2337, "text": "It's not like we, we all have perfect answers and nobody will have to get their feelings heard or nobody will have to get downvoted."}, {"time": 2344, "text": "It doesn't work that way, right?"}, {"time": 2346, "text": "So this is an interesting point and a small tangent."}, {"time": 2349, "text": "You write about anxiety."}, {"time": 2352, "text": "So I've posted a lot of questions and written answers on Stack Overflow."}, {"time": 2356, "text": "On the question side, you usually go to something very specific to something I'm working on."}, {"time": 2361, "text": "And this is something you talk about that really the goal of Stack Overflow isn't about, is to write a question that's not about you, it's about the question that will help the community in the future."}, {"time": 2375, "text": "Right, but that's a tough sell, right?"}, {"time": 2377, "text": "Because people are like, well, I don't really care about the community."}, {"time": 2380, "text": "What I care about is my problem."}, {"time": 2381, "text": "And that's fair, right?"}, {"time": 2383, "text": "It's sort of that, again, that tension, that balancing act of we wanna help you, but we also wanna help everybody that comes behind you."}, {"time": 2388, "text": "The long line of people are gonna come up and say, oh, I kinda have that problem too, right?"}, {"time": 2392, "text": "And if nobody's ever gonna come up and say, I have this problem too, then that question shouldn't exist on Stack Overflow because the question is too specific."}, {"time": 2398, "text": "And even that's tension, right?"}, {"time": 2400, "text": "How do you judge that?"}, {"time": 2400, "text": "How do you know that nobody's ever gonna have this particular question again?"}, {"time": 2404, "text": "So there's a lot of tension in the system."}, {"time": 2406, "text": "Do you think that anxiety of asking the question, the anxiety of answering, that tension is inherent to programmers, is inherent to this kind of process?"}, {"time": 2416, "text": "Or can it be improved?"}, {"time": 2420, "text": "Can it be happy land where that tension is not quite so harsh?"}, {"time": 2426, "text": "I don't think Stack Overflow can totally change the way it works."}, {"time": 2430, "text": "One thing they are working on finally is the ask page had not changed since 2011."}, {"time": 2435, "text": "I'm still kind of bitter about this because I feel like you have a Q&A system and what are the core pages in a Q&A system?"}, {"time": 2441, "text": "Well, first of all, the question, all the answers and also the ask page, particularly when you're a new user or someone trying to ask a question, that's the point at which you need the most help."}, {"time": 2448, "text": "And we just didn't adapt with the times."}, {"time": 2450, "text": "But the good news is they're working on this, from what I understand, and it's gonna be a more wizard based format."}, {"time": 2455, "text": "And you could envision a world where as part of this wizard based program, when you're asking questions, okay, come up with a good title, what are good words to put in the title?"}, {"time": 2462, "text": "One word that's not good to put in the title is problem, for example."}, {"time": 2465, "text": "I have a problem."}, {"time": 2466, "text": "Oh, you have a problem."}, {"time": 2467, "text": "Okay, a problem, that's great."}, {"time": 2470, "text": "You need specifics."}, {"time": 2471, "text": "So it's trying to help you make a good question title, for example, that step will be broken out, all that stuff."}, {"time": 2477, "text": "But one of those steps in that wizard of asking could say, hey, I'm a little nervous."}, {"time": 2481, "text": "I've never done this before."}, {"time": 2482, "text": "Can you put me in a queue for special mentoring?"}, {"time": 2486, "text": "You could opt in to a special mentor."}, {"time": 2487, "text": "I think that would be fantastic."}, {"time": 2488, "text": "I don't have any objection to that at all in terms of being an opt in system."}, {"time": 2492, "text": "Because there are people that are like, I just wanna help them."}, {"time": 2495, "text": "I wanna help a person no matter what."}, {"time": 2496, "text": "I wanna go above and beyond."}, {"time": 2497, "text": "I wanna spend hours with this person."}, {"time": 2501, "text": "It depends what their goals are."}, {"time": 2502, "text": "It's a great idea."}, {"time": 2503, "text": "Who am I to judge?"}, {"time": 2504, "text": "So that's fine."}, {"time": 2505, "text": "It's not precluded from happening."}, {"time": 2507, "text": "But there's a certain big city ethos that we started with."}, {"time": 2509, "text": "Like, look, we're in New York City."}, {"time": 2511, "text": "You don't come to New York City and expect them to be, oh, welcome to the city, Joe."}, {"time": 2514, "text": "How's it going?"}, {"time": 2515, "text": "Come on in."}, {"time": 2516, "text": "Let me show you around."}, {"time": 2517, "text": "That's not how New York City works."}, {"time": 2521, "text": "Again, New York City has a reputation for being rude, which I actually don't think it is, having been there fairly recently."}, {"time": 2525, "text": "It's not rude."}, {"time": 2526, "text": "It's just like going about their business."}, {"time": 2527, "text": "Like, look, I have things to do."}, {"time": 2528, "text": "I'm busy."}, {"time": 2529, "text": "I'm a busy professional, as are you."}, {"time": 2531, "text": "And since you're a busy professional, certainly when you ask a question, you're gonna ask the best possible question."}, {"time": 2536, "text": "Because you're a busy professional and you would not accept anything less than a very well written question with a lot of detail about why you're doing it, what you're doing, what you researched, what you found, because you're a professional like me."}, {"time": 2548, "text": "And this rubs people sometimes the wrong way."}, {"time": 2551, "text": "And I don't think it's wrong to say, look, I don't want that experience."}, {"time": 2553, "text": "I want just a more chill place for beginners."}, {"time": 2557, "text": "And I still think Stack Overflow is not, was never designed for beginners, right?"}, {"time": 2561, "text": "There's this misconception that, even Joel says sometimes, oh yeah, Stack Overflow for beginners."}, {"time": 2566, "text": "And I think if you're a prodigy, it can be."}, {"time": 2569, "text": "But for the most part, not."}, {"time": 2570, "text": "But that's not really representative, right?"}, {"time": 2571, "text": "Like, I think as a beginner, you want a totally different set of tools."}, {"time": 2575, "text": "You want like live screen sharing, live chat."}, {"time": 2578, "text": "You want access to resources."}, {"time": 2579, "text": "You want a playground, like a playground you can experiment in and like test and all this stuff that we just don't give people because that was never really the audience that we were designing Stack Overflow for."}, {"time": 2589, "text": "That doesn't mean it's wrong."}, {"time": 2590, "text": "And I think it would be awesome if there was a site like that on the internet, or if Stack Overflow said, hey, you know, we're gonna start doing this."}, {"time": 2595, "text": "That's fine too."}, {"time": 2596, "text": "You know, I'm not there."}, {"time": 2597, "text": "I'm not making those decisions."}, {"time": 2598, "text": "But I do think the pressure, the tension that you described is there for people to be, look, I'm a little nervous because I know I gotta do my best work, right?"}, {"time": 2606, "text": "The other one is something you talk about, which is also really interesting to me, is duplicate questions or it's a really difficult problem that you highlight."}, {"time": 2618, "text": "It's super hard."}, {"time": 2619, "text": "Like you could take one little topic and you could probably write 10, 20, 30 ways of asking about that topic and there will be all different."}, {"time": 2628, "text": "I don't know if there should be one page that answers all of it."}, {"time": 2631, "text": "Is there a way that Stack Overflow can help disambiguate, like separate these duplicate questions or connect them together?"}, {"time": 2642, "text": "Or is it a totally hopeless, difficult, impossible task?"}, {"time": 2646, "text": "I think it's a very, very hard computer science problem."}, {"time": 2648, "text": "And partly because people are very good at using completely different words."}, {"time": 2651, "text": "It always amazed me on Stack Overflow."}, {"time": 2653, "text": "You'd have two questions that were functionally identical and one question had like zero words in common with the other question."}, {"time": 2658, "text": "Like, oh my God, from a computer science perspective, how do you even begin to solve that?"}, {"time": 2662, "text": "And it happens all the time."}, {"time": 2664, "text": "People are super good at this, right?"}, {"time": 2666, "text": "Accidentally at asking the same thing in like 10, 20 different ways."}, {"time": 2671, "text": "And the other complexity is we want some of those duplicates to exist because if there's five versions with different words, have those five versions point to the one centralized answer, right?"}, {"time": 2679, "text": "It's like, okay, this is a duplicate, no worries."}, {"time": 2681, "text": "Here's the answer that you wanted over here on the prime example that we want to have, rather than having 10 copies of the question and the answer."}, {"time": 2690, "text": "Because if you have 10 copies of the question and answer, this also devalues the reputation system, which programmers hate, as I previously mentioned."}, {"time": 2696, "text": "You're getting reputation for an answer that somebody else already gave."}, {"time": 2699, "text": "It's like, well, it's an answer, but somebody else already gave that answer."}, {"time": 2702, "text": "So why are you getting reputation for the same answer as the other guy who gave it four years ago?"}, {"time": 2706, "text": "People get offended by that, right?"}, {"time": 2707, "text": "So the reputation system itself adds tension to the system in that the people who have a lot of reputation become very incentivized to enforce the reputation system."}, {"time": 2717, "text": "And for the most part, that's good."}, {"time": 2718, "text": "I know it sounds weird, but for most parts, like look, strict systems, I think to use Stack Overflow, you have to have the idea that, OK, strict systems ultimately work better."}, {"time": 2726, "text": "And I do think in programming, you're familiar with loose typing versus strict typing, right?"}, {"time": 2731, "text": "The idea that you can declare a variable, not declare a variable, rather, just start using a variable."}, {"time": 2734, "text": "And OK, I see it's implicitly an integer."}, {"time": 2736, "text": "Bam, awesome."}, {"time": 2737, "text": "Duck equals 5."}, {"time": 2738, "text": "Well, duck is now an integer of 5, right?"}, {"time": 2740, "text": "And you're like, cool, awesome, simpler, right?"}, {"time": 2742, "text": "Why would I want to worry about typing?"}, {"time": 2743, "text": "And for a long time, in the Ruby community, they're like, yeah, this is awesome."}, {"time": 2746, "text": "You just do a bunch of unit testing, which is testing your program's validity after the fact to catch any bugs that strict typing of variables would have caught."}, {"time": 2755, "text": "And now you have this thing called TypeScript for Microsoft from the guy who built C Sharp Anders, who's one of the greatest minds in software development, right, like in terms of language design."}, {"time": 2764, "text": "And says, no, no, no, we want to bolt on a strict type system to JavaScript because it makes things better."}, {"time": 2768, "text": "And now everybody's like, oh my god, we deployed TypeScript and found 50 latent bugs that we didn't know about, right?"}, {"time": 2774, "text": "Like, this is super common."}, {"time": 2775, "text": "So I think there is a truth in programming that strictness, it's not the goal."}, {"time": 2782, "text": "We're not saying be super strict because strictness is correct."}, {"time": 2785, "text": "No, it's no, no."}, {"time": 2786, "text": "Strictness produces better results."}, {"time": 2788, "text": "That's what I'm saying, right?"}, {"time": 2789, "text": "So strict typing of variables, I would say you almost universally have consensus now is basically correct."}, {"time": 2795, "text": "Should be that way in every language, right?"}, {"time": 2797, "text": "Duck equals five should generate an error because no, you didn't declare."}, {"time": 2800, "text": "You didn't tell me that duck was an integer, right?"}, {"time": 2802, "text": "That's a bug, right?"}, {"time": 2803, "text": "Or maybe you mistyped."}, {"time": 2804, "text": "You typed deck instead of duck, right?"}, {"time": 2806, "text": "You never know."}, {"time": 2807, "text": "This happens all the time, right?"}, {"time": 2808, "text": "So with that in mind, I will say that the strictness of the system is correct."}, {"time": 2812, "text": "Now, that doesn't mean cruel."}, {"time": 2813, "text": "That doesn't mean mean."}, {"time": 2815, "text": "That doesn't mean angry."}, {"time": 2816, "text": "It just means strict, OK?"}, {"time": 2817, "text": "So I think where there's misunderstanding is people get cranky, right?"}, {"time": 2820, "text": "Like, another question you asked is like, why are programmers kind of mean sometimes?"}, {"time": 2825, "text": "Well, who do programmers work with all day long?"}, {"time": 2827, "text": "So I have a theory that if you're at a job and you work with assholes all day long, what do you eventually become?"}, {"time": 2835, "text": "And what is the computer except the world's biggest asshole?"}, {"time": 2839, "text": "Because the computer has no time for your bullshit."}, {"time": 2841, "text": "The computer, the minute you make a mistake, everything is crashing down, right?"}, {"time": 2845, "text": "One semicolon has crashed space missions, right?"}, {"time": 2848, "text": "So that's normal."}, {"time": 2849, "text": "So you begin to internalize that."}, {"time": 2850, "text": "You begin to think, oh, my coworker, the computer, is super strict and kind of a jerk about everything."}, {"time": 2857, "text": "So that's kind of how I'm going to be."}, {"time": 2860, "text": "Because I work with this computer, and I have to exceed to its terms on everything."}, {"time": 2864, "text": "So therefore, you start to absorb that."}, {"time": 2866, "text": "You start to think, oh, well, being really strict arbitrarily is really good."}, {"time": 2870, "text": "An error of error code 56249 is a completely good error message because that's what the computer gave me, right?"}, {"time": 2876, "text": "So you kind of forget to be a person at some level."}, {"time": 2879, "text": "And you know how they say great detectives internalize criminals and kind of are criminals themselves, like this trope of the master detective is good because he can think like the criminal."}, {"time": 2888, "text": "Well, I do think that's true of programmers."}, {"time": 2890, "text": "Really good programmers think like the computer because that's their job."}, {"time": 2894, "text": "But if you internalize it too much, you become the computer."}, {"time": 2897, "text": "You kind of become a jerk to everybody because that's what you've internalized."}, {"time": 2901, "text": "You're almost not a jerk, but you have no patience for a lack of strictness, as you said."}, {"time": 2906, "text": "It's not out of a sense of meanness."}, {"time": 2907, "text": "It's accidental."}, {"time": 2908, "text": "But I do believe it's an occupational hazard of being a programmer is you start to behave like the computer."}, {"time": 2913, "text": "You're very unforgiving."}, {"time": 2914, "text": "You're very terse."}, {"time": 2915, "text": "You're very, oh, wrong, incorrect, move on."}, {"time": 2918, "text": "It's like, well, can you help me?"}, {"time": 2920, "text": "What could I do to fix?"}, {"time": 2921, "text": "No, wrong, next question."}, {"time": 2924, "text": "Like, that's normal for the computer."}, {"time": 2926, "text": "Just fail, next."}, {"time": 2929, "text": "I don't know if you remember in Saturday Night Live, in the 90s, they had this character who was an IT guy."}, {"time": 2934, "text": "The move guy."}, {"time": 2936, "text": "Was that Jimmy Fallon?"}, {"time": 2939, "text": "Who played him?"}, {"time": 2941, "text": "OK, yeah, I remember."}, {"time": 2943, "text": "He had no patience for it."}, {"time": 2944, "text": "Might have been Mad TV, actually."}, {"time": 2945, "text": "Wasn't it Mad TV?"}, {"time": 2946, "text": "Might have been."}, {"time": 2947, "text": "But anyway, that's always been the perception."}, {"time": 2950, "text": "You start to behave like the computer."}, {"time": 2952, "text": "It's like, oh, you're wrong, out of the way, you know?"}, {"time": 2954, "text": "You've written so many blog posts about programming, about programs, programming, programmers."}, {"time": 2962, "text": "What do you think makes a good, let's start with, what makes a good solo programmer?"}, {"time": 2969, "text": "Well, I don't think you should be a solo programmer."}, {"time": 2971, "text": "I think to be a good solo programmer, it's kind of like what I talked about, well, not on Mike, but one of the things John Carmack, one of the best points he makes in the book Masters of Doom, which is a fantastic book, and anybody listening to this who hasn't read it, please read it."}, {"time": 2984, "text": "It's such a great book, is that at the time, they were working on stuff like Wolfenstein and Doom."}, {"time": 2990, "text": "They didn't have the resources that we have today."}, {"time": 2992, "text": "They didn't have Stack Overflow."}, {"time": 2993, "text": "They didn't have Wikipedia."}, {"time": 2994, "text": "They didn't have discourse forums."}, {"time": 2996, "text": "They didn't have places to go to get people to help them."}, {"time": 3000, "text": "They had to work on their own."}, {"time": 3001, "text": "And that's why it took a genius like Carmack to do this stuff, because you had to be a genius to invent from first principles."}, {"time": 3007, "text": "A lot of the stuff he was like, the hacks he was coming up with were genius, genius level stuff."}, {"time": 3011, "text": "But you don't need to be a genius anymore, and that means not working by yourself."}, {"time": 3015, "text": "You have to be good at researching stuff online."}, {"time": 3017, "text": "You have to be good at asking questions, really good questions that are really well researched, which implies, oh, I went out and researched for three hours before I wrote these questions."}, {"time": 3024, "text": "That's what you should be doing, because that's what's going to make you good."}, {"time": 3028, "text": "To me, this is the big difference between programming in the 80s versus programming today, is you kind of had to be by yourself back then."}, {"time": 3035, "text": "Where would you go for answers?"}, {"time": 3036, "text": "I remember in the early days when I was learning Visual Basic for Windows, I would call the Microsoft Helpline on the phone when I had programming."}, {"time": 3045, "text": "Because I was like, I don't know what to do."}, {"time": 3047, "text": "So I would go and call, and they had these huge phone banks."}, {"time": 3049, "text": "And I'm like, can you imagine how alien that is now?"}, {"time": 3051, "text": "Who would do that?"}, {"time": 3053, "text": "So there was just nowhere else to go when you got stuck."}, {"time": 3057, "text": "I had the books that came with it."}, {"time": 3059, "text": "I read those, studied those religiously."}, {"time": 3061, "text": "I just saw a post from Steve Sanofsky that said the C++ version 7 came with 10,000 pages of written material."}, {"time": 3070, "text": "Because where else were you going to figure that stuff out?"}, {"time": 3073, "text": "Go to the library?"}, {"time": 3074, "text": "I mean, you didn't have Wikipedia."}, {"time": 3076, "text": "You didn't have Reddit."}, {"time": 3077, "text": "You didn't have anywhere to go to answer these questions."}, {"time": 3080, "text": "So you've talked about, through the years, basically not having an ego and not thinking that you're the best programmer in the world."}, {"time": 3089, "text": "So always kind of just looking to improve, to become a better programmer than you were yesterday."}, {"time": 3096, "text": "So how have you changed as a programmer and as a thinker, designer around programming over the past, what is it, 15 years, really, of being a public figure?"}, {"time": 3108, "text": "I would say the big insight that I had is, eventually, as a programmer, you have to stop writing code to be effective, which is kind of disturbing."}, {"time": 3116, "text": "Because you really love it."}, {"time": 3118, "text": "But you realize being effective at programming, at programming in the general sense, doesn't mean writing code."}, {"time": 3125, "text": "And a lot of times, you can be much more successful by not writing code and writing code in terms of just solving the problems you have, essentially hiring people that are really good and setting them free and giving them basic direction on strategy and stuff."}, {"time": 3138, "text": "Because a lot of the problems you encounter aren't necessarily solved through really gnarly code."}, {"time": 3142, "text": "They're solved by conceptual solutions, which can then be turned into code."}, {"time": 3146, "text": "But are you even solving the right problem?"}, {"time": 3149, "text": "So I would say, for me, the main insight I have is, to succeed as a programmer, you eventually kind of stop writing code."}, {"time": 3157, "text": "That's going to sound discouraging, probably, to people hearing."}, {"time": 3159, "text": "But I don't mean it that way."}, {"time": 3160, "text": "What I mean is that you're coding at a higher level language."}, {"time": 3163, "text": "Eventually, like, OK, so we're coding in assembly language."}, {"time": 3165, "text": "That's the beginning, right?"}, {"time": 3166, "text": "You're hardcoded to the architecture."}, {"time": 3168, "text": "Then you have stuff like C, where it's like, wow, we can abstract across the architecture."}, {"time": 3172, "text": "We can write code."}, {"time": 3172, "text": "I can then compile that code for ARM or whatever x86 or whatever else is out there."}, {"time": 3178, "text": "And then even higher level than that, you're looking at Python, Ruby, interpreted languages."}, {"time": 3183, "text": "And then, to me, as a programmer, I'm like, OK, I want to go even higher."}, {"time": 3186, "text": "I want to go higher than that."}, {"time": 3187, "text": "How do I abstract higher than the language?"}, {"time": 3188, "text": "It's like, well, you abstract in spoken language and written language, right?"}, {"time": 3192, "text": "You're sort of inspiring people to get things done, giving them guidance, like, what if we did this?"}, {"time": 3196, "text": "What if we did this?"}, {"time": 3197, "text": "You're writing in the highest level language that there is, which is, for me, English, whatever your spoken language is."}, {"time": 3203, "text": "So it's all about being effective, right?"}, {"time": 3205, "text": "And I think Patrick McKenzie, patio11 on Hacker News and works at Stripe, has a great post about this, of how calling yourself a programmer is a career limiting move at some level once you get far enough from your career."}, {"time": 3219, "text": "And I really believe that."}, {"time": 3220, "text": "And again, I apologize."}, {"time": 3221, "text": "This is sound discouraging."}, {"time": 3223, "text": "I don't mean it to be, but he's so right."}, {"time": 3225, "text": "Because all the stuff that goes on around the code, like the people, that's another thing, if you look at my early blog entries, is about, wow, programming is about people more than it's about code, which doesn't really make sense."}, {"time": 3236, "text": "But it's about, can these people even get along together?"}, {"time": 3239, "text": "Can they understand each other?"}, {"time": 3240, "text": "Can you even explain to me what it is you're working on?"}, {"time": 3243, "text": "Are you solving the right problem?"}, {"time": 3244, "text": "PeopleWare, another classic programming book, which, again, up there with Code Complete, please read PeopleWare."}, {"time": 3249, "text": "It's that software is people."}, {"time": 3251, "text": "People are the software, first and foremost."}, {"time": 3253, "text": "So a lot of the skills that I was working on early in the blog were about figuring out the people parts of programming, which were the harder parts."}, {"time": 3260, "text": "The hard part of programming, once you get a certain skill level in programming, you can pretty much solve any reasonable problem that's put in front of you."}, {"time": 3266, "text": "You're not writing algorithms from scratch."}, {"time": 3268, "text": "That just doesn't happen."}, {"time": 3269, "text": "So any sort of reasonable problem put in front of you, you're going to be able to solve."}, {"time": 3272, "text": "But what you can't solve is, our manager is a total jerk."}, {"time": 3276, "text": "You cannot solve that with code."}, {"time": 3278, "text": "That is not a code solvable problem."}, {"time": 3280, "text": "And yet, that will cripple you way more than, oh, we had to use this stupid framework I don't like, or Sam keeps writing bad code that I hate, or Dave is off there in the wilderness writing God knows what."}, {"time": 3293, "text": "These are not your problems."}, {"time": 3294, "text": "Your problem is your manager or a co worker is so toxic to everybody else in your team that nobody can get anything done, because everybody's so stressed out and freaked out."}, {"time": 3302, "text": "These are the problems that you have to attack."}, {"time": 3305, "text": "And so as you go to these higher level abstractions, as you've developed as a programmer to higher and higher level abstractions and go into natural language, you're also the guy who preached building it, diving in and doing it, and learn by doing."}, {"time": 3322, "text": "Do you worry that as you get to higher and higher level abstractions, you lose track of the lower level of just building?"}, {"time": 3335, "text": "Do you worry about that, even not maybe now, but 10 years from now, 20 years from now?"}, {"time": 3342, "text": "I mean, there is always that paranoia around, oh, gosh, I don't feel it's valuable since I'm not writing code."}, {"time": 3346, "text": "But for me, when we started the discourse project, it was Ruby, which I didn't really know Ruby."}, {"time": 3350, "text": "I mean, as you pointed out, and this is another valuable observation in Stack Overflow, you can be super proficient in, for example, C Sharp, which I was working in."}, {"time": 3356, "text": "That's what we built Stack Overflow in and still is written in."}, {"time": 3359, "text": "And then switch to Ruby, and you're a newbie again."}, {"time": 3361, "text": "But you have the framework."}, {"time": 3363, "text": "I know what a for loop is."}, {"time": 3364, "text": "I know what recursion is."}, {"time": 3365, "text": "I know what a stack trace is."}, {"time": 3370, "text": "I have all the fundamental concepts to be a programmer."}, {"time": 3372, "text": "I just don't know Ruby."}, {"time": 3373, "text": "So I'm still on a higher level."}, {"time": 3374, "text": "I'm not like a beginner beginner, like you're saying."}, {"time": 3376, "text": "I'm just like, I need to apply my programming concepts I already know to Ruby."}, {"time": 3380, "text": "Well, so there's a question that's really interesting."}, {"time": 3383, "text": "So looking at Ruby, how do you go about learning enough that your intuition can be applied, carried over?"}, {"time": 3389, "text": "That's what I was trying to get to."}, {"time": 3390, "text": "It's like what I realized, particularly when I started with just me and Robin, I realized if I bother Robin, I am now costing us productivity."}, {"time": 3397, "text": "Every time I go to Robin, rather than building our first alpha version of discourse, he's now answering my stupid questions about Ruby."}, {"time": 3406, "text": "Is that a good use of his time?"}, {"time": 3407, "text": "Is that a good use of my time?"}, {"time": 3409, "text": "And the answer to both of those was resoundingly no."}, {"time": 3413, "text": "We were getting to an alpha, and it was pretty much just, OK, we'll hire more programmers."}, {"time": 3416, "text": "We eventually hired Neil, and then eventually Sam, who came in as a cofounder."}, {"time": 3422, "text": "Actually, it was Sam first, then Neil later."}, {"time": 3425, "text": "But the answer to the problem is just hire other competent programmers."}, {"time": 3428, "text": "Now I shall pull myself up by my bootstraps and learn Ruby."}, {"time": 3432, "text": "But at some point, writing code becomes a liability to you in terms of getting things done."}, {"time": 3437, "text": "There's so many other things that go on in the project, like building the prototype."}, {"time": 3440, "text": "You mentioned, well, how do you, if you're not writing code, how does everybody keep focus on what are we building?"}, {"time": 3445, "text": "Well, first, basic mockups and research."}, {"time": 3448, "text": "What do we even want to build?"}, {"time": 3450, "text": "There's a little bit of that that goes on."}, {"time": 3451, "text": "But then very quickly, you get to the prototype stage."}, {"time": 3452, "text": "Like, build a prototype."}, {"time": 3453, "text": "Let's iterate on the prototype really, really rapidly."}, {"time": 3455, "text": "And that's what we do with discourse."}, {"time": 3456, "text": "And that's what we demoed to get our seed funding for discourse was the alpha version of discourse that we had running and ready to go."}, {"time": 3463, "text": "And it was very, it was bad."}, {"time": 3465, "text": "I mean, it was, I'll just tell you it was bad."}, {"time": 3467, "text": "We have screenshots of it."}, {"time": 3468, "text": "I'm just embarrassed to look at it now."}, {"time": 3470, "text": "But it was the prototype."}, {"time": 3471, "text": "We were figuring out what's working, what's not working."}, {"time": 3473, "text": "Because there's such a broad gap between the way you think things will work in your mind or even on paper and the way they work once you sit and live in the software, like actually spend time living and breathing in software, so different."}, {"time": 3486, "text": "So my philosophy is get to a prototype."}, {"time": 3490, "text": "And then what you're really optimizing for is speed of iteration, like how you can turn the crank."}, {"time": 3494, "text": "How quickly can we iterate?"}, {"time": 3496, "text": "That's the absolutely critical metric of any software project."}, {"time": 3499, "text": "And I had a tweet recently that people liked."}, {"time": 3500, "text": "And I totally, this is so fundamental to what I do, is like if you want to measure the core competency of any software tech company, it's the speed at which somebody can say, hey, we really need this word in the product."}, {"time": 3511, "text": "Change this word, right?"}, {"time": 3512, "text": "Because it will be more clear to the user."}, {"time": 3514, "text": "Like, instead of respond, it's reply or something."}, {"time": 3516, "text": "But there's some, from the conception of that idea to how quickly that single word can be changed in your software and rolled out to users, that is your life cycle."}, {"time": 3524, "text": "That's your health, your heartbeat."}, {"time": 3527, "text": "If your heartbeat is like super slow, you're basically dead."}, {"time": 3531, "text": "No, seriously."}, {"time": 3532, "text": "Like, if it takes two weeks or even a month to get that single word changed, everybody's like, oh my god, this is a great idea."}, {"time": 3537, "text": "That word is so much clearer."}, {"time": 3539, "text": "I'm talking about like a super, like everybody's on board for this change."}, {"time": 3541, "text": "It's not like, let's just change a word because we're bored."}, {"time": 3543, "text": "It's like, this is an awesome change."}, {"time": 3545, "text": "And then it takes months to roll out."}, {"time": 3547, "text": "It's like, well, you're dead."}, {"time": 3548, "text": "You can't iterate."}, {"time": 3549, "text": "You can't, how are you going to do anything, right?"}, {"time": 3552, "text": "So anyway, about the heartbeat, it's like, get the prototype and then iterate on it."}, {"time": 3555, "text": "That's what I view as the central tenet of modern software development."}, {"time": 3560, "text": "That's fascinating that you put it that way."}, {"time": 3562, "text": "So I work and I build autonomous vehicles."}, {"time": 3564, "text": "And when you look at what, maybe compare Tesla to most other automakers, the heart beat for Tesla is literally days now in terms of they can over the air deploy software updates to all their vehicles, which is markedly different than every other automaker, which takes years to update a piece of software."}, {"time": 3589, "text": "And that's reflected in everything that's the final product."}, {"time": 3594, "text": "That's reflected in really how slowly they adapt to the times."}, {"time": 3598, "text": "And to be clear, I'm not saying being a hummingbird is the goal either."}, {"time": 3600, "text": "It's like, you don't want a heartbeat that's like so fast."}, {"time": 3602, "text": "It's like you're just freaking out."}, {"time": 3604, "text": "But it is a measure of health."}, {"time": 3605, "text": "You should have a healthy heartbeat."}, {"time": 3607, "text": "It's up to people listening to decide what that means."}, {"time": 3609, "text": "But it has to be healthy."}, {"time": 3610, "text": "It has to be reasonable."}, {"time": 3611, "text": "Because otherwise, you're just going to be frustrated because that's how you build software."}, {"time": 3615, "text": "You make mistakes."}, {"time": 3615, "text": "You roll it out."}, {"time": 3616, "text": "You live with it."}, {"time": 3617, "text": "You see what it feels like and say, oh, God, that was a terrible idea."}, {"time": 3620, "text": "Oh, my gosh, this could be even better if we did Y, right?"}, {"time": 3622, "text": "You turn the crank."}, {"time": 3623, "text": "And then the more you do that, the faster you get ahead of your competitors ultimately."}, {"time": 3628, "text": "It's rate of change, right?"}, {"time": 3629, "text": "Delta V, right?"}, {"time": 3630, "text": "How fast are you moving?"}, {"time": 3632, "text": "Well, within a year, you're going to be miles away by the time they catch up with you, right?"}, {"time": 3636, "text": "That's the way it works."}, {"time": 3637, "text": "And plus, as a software developer and user, I love software that's constantly changing."}, {"time": 3642, "text": "Because I don't understand people who get super pissed off when like, oh, they changed the software on me."}, {"time": 3647, "text": "How dare they?"}, {"time": 3647, "text": "I'm like, yes, change the software."}, {"time": 3649, "text": "Change it all the time, man."}, {"time": 3651, "text": "That's what makes this stuff great is that it can be changed so rapidly and become something that is greater than it is now."}, {"time": 3658, "text": "Now, granted, there are some changes that suck."}, {"time": 3660, "text": "I admit."}, {"time": 3661, "text": "I've seen it many times."}, {"time": 3662, "text": "But in general, that's what makes software cool, right?"}, {"time": 3665, "text": "It's that it is so malleable."}, {"time": 3666, "text": "Fighting that is weird to me."}, {"time": 3668, "text": "Because it's like, well, you're fighting the essence of the thing that you're building."}, {"time": 3672, "text": "That doesn't make sense."}, {"time": 3673, "text": "You want to really embrace that."}, {"time": 3674, "text": "Not to be a hummingbird, but embrace it to a healthy cycle of your heartbeat, right?"}, {"time": 3678, "text": "So you talk about that people really don't change."}, {"time": 3682, "text": "That's why probably a lot of the stuff you write about in your blog probably will remain true."}, {"time": 3687, "text": "Well, there's a flip side of the coin."}, {"time": 3688, "text": "People don't change."}, {"time": 3689, "text": "Like, investing and understanding people is like learning Unix in 1970."}, {"time": 3694, "text": "Because nothing has changed, right?"}, {"time": 3696, "text": "All those things you've learned about people will still be valid 34 years from now."}, {"time": 3700, "text": "Whereas if you learn the latest JavaScript framework, that's going to be good for like two years, right?"}, {"time": 3706, "text": "But if you look at the future of programming, so there's a people component, but there's also the technology itself."}, {"time": 3715, "text": "What do you see as the future of programming?"}, {"time": 3717, "text": "Will it change significantly, or as far as you can tell, people are ultimately programming, and so it's not something that you foresee changing in any fundamental way?"}, {"time": 3730, "text": "Well, you've got to go look back on sort of the basics of programming."}, {"time": 3734, "text": "And one of things that always shocked me is like source control."}, {"time": 3736, "text": "Like, I didn't learn anything about source control."}, {"time": 3738, "text": "Granted, I graduated from college in 1992."}, {"time": 3742, "text": "But I remember hearing from people as late as like 1998, 1999, like even maybe today, they're not learning source control."}, {"time": 3748, "text": "And to me, it's like, well, how can you not learn source control?"}, {"time": 3751, "text": "That is so fundamental to working with other programmers, working in a way that you don't lose your work."}, {"time": 3756, "text": "Just basic software, the literal bedrock of software development is source control."}, {"time": 3761, "text": "Now, you compare it today, like GitHub, right?"}, {"time": 3762, "text": "Like Microsoft bought GitHub, which I think was an incredibly smart acquisition move on their part."}, {"time": 3767, "text": "Now they have anybody who wants reasonable source control to go sign up on GitHub."}, {"time": 3770, "text": "It's all set up for you, right?"}, {"time": 3772, "text": "There's tons of walkthroughs, tons of tutorials."}, {"time": 3775, "text": "So from the concept of like, has programming advanced from, say, 1999, it's like, well, hell, we have GitHub."}, {"time": 3780, "text": "I mean, my god, yes, right?"}, {"time": 3781, "text": "Like, it's massively advanced over what it was."}, {"time": 3784, "text": "Now, as to whether programming is significantly different, I'm going to say no."}, {"time": 3789, "text": "But I think the baseline of what we view as fundamentals will continue to go up and actually get better, like source control."}, {"time": 3797, "text": "That's one of the fundamentals that has gotten hundreds of orders of magnitude better than it was 10, 20 years ago."}, {"time": 3803, "text": "So those are the fundamentals."}, {"time": 3805, "text": "Let me introduce two things that maybe you can comment on."}, {"time": 3808, "text": "So one is mobile phones."}, {"time": 3811, "text": "So that could fundamentally transform what programming is, or maybe not."}, {"time": 3818, "text": "Maybe you can comment on that."}, {"time": 3819, "text": "And the other one is artificial intelligence, which promises to, in some ways, to do some of the programming for you is one way to think about it."}, {"time": 3829, "text": "So it's really what a programmer is, is using the intelligence that's inside your skull to do something useful."}, {"time": 3837, "text": "The hope with artificial intelligence is that it does some of the useful parts for you where you don't have to think about it."}, {"time": 3843, "text": "So do you see smartphones, the fact that everybody has one, and they're getting more and more powerful as potentially changing programming?"}, {"time": 3851, "text": "And do you see AI as potentially changing programming?"}, {"time": 3854, "text": "OK, so that's good."}, {"time": 3855, "text": "So smartphones have definitely changed."}, {"time": 3857, "text": "I mean, since, I guess, 2010 is when they really started getting super popular."}, {"time": 3861, "text": "I mean, in the last eight years, the world has literally changed, right?"}, {"time": 3865, "text": "Everybody carries a computer around, and that's normal."}, {"time": 3868, "text": "I mean, that is such a huge change in society."}, {"time": 3870, "text": "I think we're still dealing with a lot of the positive and negative ramifications of that, right?"}, {"time": 3875, "text": "Everybody's connected all the time."}, {"time": 3876, "text": "Everybody's on the computer all the time."}, {"time": 3877, "text": "That was my dream world as a geek, right?"}, {"time": 3880, "text": "But it's like, be careful what you ask for, right?"}, {"time": 3882, "text": "Like, wow, now everybody has a computer."}, {"time": 3884, "text": "It's not quite the utopia that we thought it would be, right?"}, {"time": 3887, "text": "Computers can be used for a lot of stuff that's not necessarily great."}, {"time": 3891, "text": "So to me, that's the central focus of the smartphone, is just that it puts a computer in front of everyone."}, {"time": 3895, "text": "Granted, a small, touch screen, smallish, touch screen computer."}, {"time": 3899, "text": "But as for programming, I don't know."}, {"time": 3900, "text": "I don't think that I've kind of, over time, come to subscribe to the Unix view of the world when it comes to programming."}, {"time": 3906, "text": "You want to teach these basic command line things, and that is just what programming is going to be for, I think, a long, long time."}, {"time": 3914, "text": "I don't think there's any magical visual programming that's going to happen."}, {"time": 3920, "text": "I've, over time, have become a believer in that Unix philosophy of just, you know, they kind of had to write with Unix."}, {"time": 3926, "text": "That's going to be the way it is for a long, long time."}, {"time": 3928, "text": "And we'll continue to, like I said, raise the baseline."}, {"time": 3931, "text": "The tools will get better."}, {"time": 3932, "text": "It'll get simpler."}, {"time": 3933, "text": "But it's still fundamentally going to be command line tools, fancy IDEs."}, {"time": 3937, "text": "That's kind of it for the foreseeable future."}, {"time": 3939, "text": "I'm not seeing any visual programming stuff on the horizon."}, {"time": 3942, "text": "Because you kind of think, like, what do you do on a smartphone that will be directly analogous to programming?"}, {"time": 3946, "text": "Like, I'm trying to think, right?"}, {"time": 3948, "text": "And there's really not much."}, {"time": 3952, "text": "So not necessarily analogous to programming, but the kind of things that, the kind of programs you would need to write might need to be very different."}, {"time": 3968, "text": "And the kind of languages."}, {"time": 3969, "text": "I mean, but I probably also subscribe to the same, just because everything in this world might be written in JavaScript."}, {"time": 3976, "text": "That's already happening."}, {"time": 3977, "text": "I mean, discourse is a bet."}, {"time": 3978, "text": "Discourse itself, JavaScript, is another bet on that side of the table."}, {"time": 3981, "text": "And I still try and believe in that."}, {"time": 3983, "text": "So I would say smartphones have mostly a cultural shift more than a programming shift."}, {"time": 3987, "text": "Now, your other question was about artificial intelligence and sort of devices predicting what you're going to do."}, {"time": 3992, "text": "And I do think there's some strength to that."}, {"time": 3994, "text": "I think artificial intelligence is kind of overselling it in terms of what it's doing."}, {"time": 3997, "text": "It's more like, people are predictable, right?"}, {"time": 3999, "text": "People do the same things."}, {"time": 4001, "text": "Let me give you an example."}, {"time": 4003, "text": "One check we put in a discourse that's been a lot of big commercial websites is, say you log in from New York City now."}, {"time": 4011, "text": "And then an hour later, you log in from San Francisco."}, {"time": 4014, "text": "It's like, well, hmm, that's interesting."}, {"time": 4016, "text": "How did you get from New York to San Francisco in one hour?"}, {"time": 4019, "text": "So at that point, you're like, OK, this is a suspicious login at that point."}, {"time": 4022, "text": "So we would alert you."}, {"time": 4023, "text": "It's like, OK."}, {"time": 4024, "text": "But that's not AI, right?"}, {"time": 4025, "text": "That's just a heuristic of like, how did you, in one hour, get 2,000 miles, right?"}, {"time": 4030, "text": "That doesn't."}, {"time": 4031, "text": "I mean, you're grand."}, {"time": 4032, "text": "Maybe you're on a VPN."}, {"time": 4032, "text": "There's other ways to happen."}, {"time": 4034, "text": "That's just a basic prediction based on the idea that people pretty much don't move around that much."}, {"time": 4039, "text": "They may travel occasionally."}, {"time": 4040, "text": "But nobody, unless you're a traveling salesman that's literally traveling the world every day, there's so much repetition and predictability in terms of things you're going to do."}, {"time": 4049, "text": "And I think good software anticipates your needs."}, {"time": 4052, "text": "For example, Google, I think it's called Google Now or whatever that Google thing is that predicts your commute and predicts, based on your phone location, where are you every day?"}, {"time": 4059, "text": "Well, that's probably where you work, that kind of stuff."}, {"time": 4061, "text": "I do think computers can get a lot better at that."}, {"time": 4063, "text": "I hesitate to call it full blown AI."}, {"time": 4066, "text": "It's just computers getting better at like, first of all, they have a ton of data because everybody has a smartphone."}, {"time": 4070, "text": "Now, all of a sudden, we have all this data that we didn't have before about location, about communication, and feeding that into some basic heuristics and maybe some fancy algorithms that turn it into predictions of anticipating your needs, like a friend would, right?"}, {"time": 4084, "text": "Like, oh, hey, I see your home."}, {"time": 4086, "text": "Would you like some dinner, right?"}, {"time": 4087, "text": "Like, let's go get some food, because that's usually what we do at this time of day, right?"}, {"time": 4090, "text": "In the context of actually the act of programming, do you see IDEs improving and making the life of programming as better?"}, {"time": 4097, "text": "I do think that is possible, because there's a lot of repetition in programming, right?"}, {"time": 4100, "text": "Oh, you know, Clippy would be the bad example of, oh, I see."}, {"time": 4103, "text": "It looks like you're writing a for loop."}, {"time": 4105, "text": "But there are patterns in code, right?"}, {"time": 4108, "text": "And actually, libraries are kind of like that, right?"}, {"time": 4110, "text": "Rather than go code up your own HTTP request library, it's like, well, you'd use one of the existing ones that we have."}, {"time": 4118, "text": "That's already a troubleshot, right?"}, {"time": 4119, "text": "It's not AI, per se."}, {"time": 4121, "text": "It's just building better LEGO bricks, bigger LEGO bricks, that have more functionality in them, so people don't have to worry about the low level stuff as much anymore."}, {"time": 4130, "text": "Like, WordPress, for example, to me, is like a tool for somebody who isn't a programmer to do something."}, {"time": 4135, "text": "I mean, you can turn WordPress into anything."}, {"time": 4137, "text": "It's kind of crazy, actually, through plugins, right?"}, {"time": 4139, "text": "And that's not programming, per se."}, {"time": 4141, "text": "It's just LEGO bricks stacking WordPress elements, right?"}, {"time": 4144, "text": "And a little bit of configuration glue."}, {"time": 4146, "text": "So I would say, maybe in a broader sense, what I'm seeing, like, there'll be more gluing and less actual programming."}, {"time": 4154, "text": "And that's a good thing, right?"}, {"time": 4155, "text": "Because most of the stuff you need is kind of out there already."}, {"time": 4157, "text": "You said 1970s, Unix."}, {"time": 4160, "text": "Do you see PHP and these kind of old remnants of the early birth of programming remaining with us for a long time?"}, {"time": 4173, "text": "Like you said, Unix in itself."}, {"time": 4175, "text": "Do you see, ultimately, this stuff just being there out of momentum?"}, {"time": 4182, "text": "I kind of do."}, {"time": 4184, "text": "I mean, I was a big believer in Windows early on."}, {"time": 4186, "text": "And I was a big, you know, I was like, Unix, what a waste of time."}, {"time": 4188, "text": "But over time, I've completely flipped on that, where I was like, okay, the Unix guys were right."}, {"time": 4191, "text": "And pretty much Microsoft and Windows were kind of wrong, at least on the server side."}, {"time": 4195, "text": "Now, on the desktop, right, you need a GUI, you need all that stuff."}, {"time": 4198, "text": "And you have the two philosophies, like Apple built on Unix, effectively, Darwin."}, {"time": 4202, "text": "And on the desktop, it's a slightly different story."}, {"time": 4204, "text": "But on the server side, where you're gonna be programming."}, {"time": 4207, "text": "Now, it's a question of where the programming's gonna be."}, {"time": 4208, "text": "There's gonna be a lot more like client side programming, because technically, discourse is client side programming."}, {"time": 4213, "text": "The way you get discourse, we deliver a big ball of JavaScript, which is then executed locally."}, {"time": 4218, "text": "So we're really using a lot more local computing power."}, {"time": 4220, "text": "We'll still retrieve the data, obviously, we have to display the posts on the screen and so forth."}, {"time": 4224, "text": "But in terms of like sorting and a lot of the basic stuff, we're using the host processor."}, {"time": 4229, "text": "But to the extent that a lot of programming is still gonna be server side, I would say, yeah, the Unix philosophy definitely won."}, {"time": 4235, "text": "And there'll be different veneers over Unix, but it's still, if you peel away one or two layers, it's gonna be Unixy for a long, I think Unix won."}, {"time": 4244, "text": "I mean, so definitively."}, {"time": 4245, "text": "It's interesting to hear you say that, because you've done so much excellent work on the Microsoft side in terms of backend development."}, {"time": 4253, "text": "So what's the future hold for Jeff Atwood?"}, {"time": 4256, "text": "I mean, the discourse, continuing the discourse in trying to improve conversation on the web?"}, {"time": 4263, "text": "Well, discourse is what I've viewed as a, and originally I called it a five year project, then really quickly revised that to a 10 year project."}, {"time": 4268, "text": "So we started in early 2013, that's when we launched the first version."}, {"time": 4273, "text": "So we're still five years in."}, {"time": 4276, "text": "This is the part where it starts getting good."}, {"time": 4277, "text": "Like we have a good product now."}, {"time": 4278, "text": "Discourse, there's any project you build in software, it takes three years to build what you want it to build anyway."}, {"time": 4284, "text": "Like V1 is gonna be terrible, which it was."}, {"time": 4286, "text": "But you ship it anyway, because that's how you get better at stuff."}, {"time": 4289, "text": "It's about turning the crank."}, {"time": 4289, "text": "It's not about V1 being perfect, because that's ridiculous."}, {"time": 4292, "text": "It's about V1, then let's get really good at V1.1, 1.2, 1.3, like how fast can we iterate?"}, {"time": 4298, "text": "And I think we're iterating like crazy on discourse, to the point that like, it's a really good product now."}, {"time": 4301, "text": "We have serious momentum."}, {"time": 4304, "text": "And my original vision was, I wanna be the WordPress of discussion."}, {"time": 4308, "text": "Meaning someone came to you and said, I wanna start a blog."}, {"time": 4310, "text": "Although the very question is kind of archaic now."}, {"time": 4313, "text": "It's like, who actually blogs anymore?"}, {"time": 4315, "text": "But I wanted the answer to that to be, it would be WordPress normally, because that's the obvious choice for blogging most of the time."}, {"time": 4324, "text": "But if someone said, hey, I need a group of people to get together and do something, the answer should be discourse, right?"}, {"time": 4330, "text": "That should be the default answer for people."}, {"time": 4331, "text": "Because it's open source, it's free, doesn't cost you anything."}, {"time": 4334, "text": "You control it, you can run it."}, {"time": 4335, "text": "Your minimum server cost for discourse is five bucks a month at this point."}, {"time": 4339, "text": "They actually got the VPS prices down."}, {"time": 4341, "text": "It used to be $10 a month for one gigabyte of RAM, which we have a kind of heavy stack."}, {"time": 4348, "text": "Like there's a lot of stuff in discourse."}, {"time": 4350, "text": "You need Postgres, you need Redis, you need Ruby, and Rails, you need a sidekick for scheduling."}, {"time": 4355, "text": "It's not a trivial amount of stuff because we were architected for like, look, we're building for the next 10 years."}, {"time": 4359, "text": "I don't care about shared PHP hosting."}, {"time": 4361, "text": "That's not my model."}, {"time": 4364, "text": "My idea is like, hey, eventually, this is gonna be very cheap for everybody and I wanna build it right."}, {"time": 4369, "text": "Using again, higher, bigger building block levels, right?"}, {"time": 4373, "text": "That have more requirements."}, {"time": 4374, "text": "And there's a WordPress model of WordPress.org, WordPress.com."}, {"time": 4377, "text": "Is there a central hosting for discourse or no?"}, {"time": 4381, "text": "We're not strictly segmenting into the open source versus the commercial side."}, {"time": 4385, "text": "We have a hosting business."}, {"time": 4386, "text": "That's how discourse makes money is we host discourse instances and we have really close relationship with our customers of the symbiosis of them giving us feedback on the product."}, {"time": 4394, "text": "We definitely wait feedback from customers a lot heavier than feedback from somebody who just wanders by and gives feedback."}, {"time": 4400, "text": "But that's where we make all our money."}, {"time": 4402, "text": "But we don't have a strict division."}, {"time": 4404, "text": "We encourage people to use discourse."}, {"time": 4406, "text": "Like the whole point is that it's free, right?"}, {"time": 4409, "text": "Anybody can set it up."}, {"time": 4409, "text": "I don't wanna be the only person that hosts discourse."}, {"time": 4412, "text": "That's absolutely not the goal."}, {"time": 4414, "text": "But it is a primary way for us to build a business and it's actually kind of a great business."}, {"time": 4417, "text": "I mean, the business is going really, really well in terms of hosting."}, {"time": 4421, "text": "So I used to work at Google Research."}, {"time": 4424, "text": "It's a company that's basically funded on advertisements."}, {"time": 4427, "text": "So it's Facebook."}, {"time": 4428, "text": "Let me ask if you can comment on it."}, {"time": 4430, "text": "I think advertisement is best."}, {"time": 4433, "text": "So you'd be extremely critical on what ads are but at its best, it's actually serving you."}, {"time": 4439, "text": "In a sense, it's giving you, it's connecting you to what you would want to explore."}, {"time": 4445, "text": "So it's like related posts or related content."}, {"time": 4448, "text": "It's the same, that's the best of advertisement."}, {"time": 4450, "text": "So discourse is connecting people based on their interests."}, {"time": 4456, "text": "It seems like a place where advertisement at its best could actually serve the users."}, {"time": 4461, "text": "Is that something that you're considering thinking about as a way to bring, to financially support the platform?"}, {"time": 4469, "text": "That's interesting because I actually have a contrarian view of advertising, which I kind of agree with you."}, {"time": 4473, "text": "I recently installed AdBlocker reluctantly because I don't like to do that."}, {"time": 4478, "text": "But the performance of the ads, man, they're so heavy now and it's just crazy."}, {"time": 4483, "text": "So it's almost like a performance argument more than like, I actually am pro ads and I have a contrarian viewpoint."}, {"time": 4489, "text": "I agree with you."}, {"time": 4490, "text": "If you do ads right, it's serving you stuff you would be interested in anyway."}, {"time": 4493, "text": "I don't mind that, that actually is kind of a good thing."}, {"time": 4496, "text": "So plus I think it's rational to wanna support the people that are doing this work through seeing their ads."}, {"time": 4502, "text": "But that said, I run AdBlock now, which I didn't wanna do, but I was convinced by all these articles, like 30, 40 megabytes of stuff just to serve you ads."}, {"time": 4512, "text": "Yeah, it feels like ads now are like the experts exchange of whenever you start a stock overflow."}, {"time": 4518, "text": "It's a little bit, it's overwhelming."}, {"time": 4519, "text": "Oh, there's so many companies in ad tech that it's embarrassing."}, {"time": 4521, "text": "Like you can do that, have you seen those logo charts of like just the whole page?"}, {"time": 4524, "text": "It's like you can't even see them, they're so small."}, {"time": 4526, "text": "There's so many companies in the space."}, {"time": 4527, "text": "But since you brought it up, I do wanna point out that very, very few discourse sites actually run using an ad supported model."}, {"time": 4533, "text": "It's not effective."}, {"time": 4534, "text": "Like it's too diluted, it's too weird, it doesn't pay well, and like users hate it."}, {"time": 4540, "text": "So it's a combination of like users hate it, it doesn't actually work that well in practice."}, {"time": 4544, "text": "Like in theory, yes, I agree with you."}, {"time": 4545, "text": "If you had clean, fast ads that were exactly the stuff you would be interested in, awesome."}, {"time": 4550, "text": "We're so far from that though, right?"}, {"time": 4552, "text": "Like, and Google does an okay job."}, {"time": 4553, "text": "They do retargeting and stuff like that, but in the real world, discourse sites rarely can make ads work."}, {"time": 4561, "text": "It just doesn't work for so many reasons."}, {"time": 4563, "text": "But you know what does work is subscriptions, Patreon, affiliate codes for like Amazon, of like just, oh, here's a cool yo yo, click, and then you click and go to Amazon, they get a small percentage of that, which is fair, I think."}, {"time": 4577, "text": "I mean, because you saw the yo yo on that site and you clicked through and you bought it, right?"}, {"time": 4581, "text": "That's fair for them to get 5% of that or 2% of that, whatever it is."}, {"time": 4584, "text": "Those things definitely work."}, {"time": 4585, "text": "In fact, a site that I used to participate on a lot, I helped the owner."}, {"time": 4589, "text": "One of the things, I got them to switch to discourse."}, {"time": 4592, "text": "I basically paid them to switch to discourse because I was like, look, you guys got to switch."}, {"time": 4595, "text": "I can't come here anymore on this terrible software."}, {"time": 4598, "text": "But I was like, look, and on top of that, like you're serving people ads that they hate."}, {"time": 4602, "text": "Like you should just go full on Patreon because he had a little bit of Patreon."}, {"time": 4605, "text": "Go full on Patreon, do the Amazon affiliates thing for any Amazon links that get posted and just do that and just triple down on that stuff."}, {"time": 4613, "text": "And that's worked really well for them and this creator in particular."}, {"time": 4616, "text": "So that stuff works, but traditional ads, I mean, definitely not working, at least on discourse."}, {"time": 4621, "text": "So last question."}, {"time": 4623, "text": "You've created the code keyboard."}, {"time": 4625, "text": "I've programmed most of my adult life on a Kinesis keyboard."}, {"time": 4629, "text": "I have one upstairs now."}, {"time": 4632, "text": "Can you describe what a mechanical keyboard is and why is it something that makes you happy?"}, {"time": 4636, "text": "Well, you know, this is another fetish item, really."}, {"time": 4638, "text": "Like, it's not required."}, {"time": 4640, "text": "You can do programming on any kind of keyboard, even like an onscreen keyboard."}, {"time": 4643, "text": "Oh, god, that's terrifying."}, {"time": 4645, "text": "But you could."}, {"time": 4647, "text": "I mean, if you look back at the early days of computing, there were chiclet keyboards, which are awful."}, {"time": 4651, "text": "But what's a chiclet keyboard?"}, {"time": 4652, "text": "Oh, god."}, {"time": 4653, "text": "OK, well, it's just like thin rubber membranes."}, {"time": 4656, "text": "Oh, the rubber ones, oh, no."}, {"time": 4657, "text": "Super bad, right?"}, {"time": 4658, "text": "So it's a fetish item."}, {"time": 4660, "text": "All that really says is, look, I care really about keyboards because the keyboard is the primary method of communication with the computer."}, {"time": 4666, "text": "So it's just like having a nice mic for this podcast."}, {"time": 4669, "text": "You want a nice keyboard, right?"}, {"time": 4670, "text": "Because it has a very tactile feel."}]}, {"title": "Oriol Vinyals: DeepMind AlphaStar, StarCraft, and Language | Lex Fridman Podcast #20", "id": "Kedt2or9xlo", "quotes": [{"time": 318, "text": "And people that train for this really play this game at an amazing skill level."}, {"time": 323, "text": "I've seen many times these and if you can witness this life, it's really, really impressive."}, {"time": 329, "text": "So in a way, it's kind of a chess where you don't see the other side of the board, you're building your own pieces and you also need to gather resources to basically get some money to build other buildings, pieces, technology and so on."}, {"time": 342, "text": "From the perspective of a human player, the difference between that and chess or maybe that and a game like turn based strategy like Heroes of Might and Magic is that there's an anxiety because you have to make these decisions really quickly."}, {"time": 358, "text": "And if you are not actually aware of what decisions work, it's a very stressful balance."}, {"time": 366, "text": "Everything you describe is actually quite stressful, difficult to balance for an amateur human player."}, {"time": 371, "text": "I don't know if it gets easier at the professional level, like if they're fully aware of what they have to do, but at the amateur level, there's this anxiety."}, {"time": 379, "text": "Oh crap, I'm being attacked."}, {"time": 380, "text": "Oh crap, I have to build up resource."}, {"time": 382, "text": "Oh, I have to probably expand."}, {"time": 384, "text": "And all these, the time, the real time strategy aspect is really stressful and computationally I'm sure difficult."}, {"time": 391, "text": "We'll get into it."}, {"time": 392, "text": "But for me, Battle.net, so StarCraft was released in 98, 20 years ago, which is hard to believe."}, {"time": 404, "text": "And Blizzard Battle.net with Diablo in 96 came out."}, {"time": 410, "text": "And to me, it might be a narrow perspective, but it changed online gaming and perhaps society forever."}, {"time": 417, "text": "But I may have made way too narrow viewpoint, but from your perspective, can you talk about the history of gaming over the past 20 years?"}, {"time": 426, "text": "Is this, how transformational, how important is this line of games?"}, {"time": 432, "text": "Right, so I think I kind of was an active gamer whilst this was developing, the internet, online gaming."}, {"time": 440, "text": "So for me, the way it came was I played other games, strategy related, I played a bit of Common and Conquer, and then I played Warcraft II, which is from Blizzard."}, {"time": 451, "text": "But at the time, I didn't know, I didn't understand about what Blizzard was or anything."}, {"time": 455, "text": "Warcraft II was just a game, which was actually very similar to StarCraft in many ways."}, {"time": 459, "text": "It's also real time strategy game where there's orcs and humans, so there's only two races."}, {"time": 464, "text": "But it was offline."}, {"time": 466, "text": "And it was offline, right?"}, {"time": 467, "text": "So I remember a friend of mine came to school, say, oh, there's this new cool game called StarCraft."}, {"time": 473, "text": "And I just said, oh, this sounds like just a copy of Warcraft II, until I kind of installed it."}, {"time": 479, "text": "And at the time, I am from Spain, so we didn't have very good internet, right?"}, {"time": 484, "text": "So there was, for us, StarCraft became first kind of an offline experience where you kind of start to play these missions, right?"}, {"time": 492, "text": "You play against some sort of scripted things to develop the story of the characters in the game."}, {"time": 498, "text": "And then later on, I start playing against the built in AI, and I thought it was impossible to defeat it."}, {"time": 505, "text": "Then eventually you defeat one and you can actually play against seven built in AIs at the same time, which also felt impossible."}, {"time": 512, "text": "But actually, it's not that hard to beat seven built in AIs at once."}, {"time": 516, "text": "So once we achieved that, also we discovered that we could play, as I said, internet wasn't that great, but we could play with the LAN, right?"}, {"time": 525, "text": "Like basically against each other if we were in the same place because you could just connect machines with like cables, right?"}, {"time": 533, "text": "So we started playing in LAN mode and as a group of friends, and it was really, really like much more entertaining than playing against AIs."}, {"time": 542, "text": "And later on, as internet was starting to develop and being a bit faster and more reliable, then it's when I started experiencing Battle.net, which is this amazing universe, not only because of the fact that you can play the game against anyone in the world, but you can also get to know more people."}, {"time": 560, "text": "You just get exposed to now like this vast variety of, it's kind of a bit when the chats came about, right?"}, {"time": 565, "text": "There was a chat system."}, {"time": 567, "text": "You could play against people, but you could also chat with people, not only about Stalker, but about anything."}, {"time": 572, "text": "And that became a way of life for kind of two years."}, {"time": 576, "text": "And obviously then it became like kind of, it exploded in me in that I started to play more seriously, going to tournaments and so on and so forth."}, {"time": 584, "text": "Do you have a sense on a societal, sociological level, what's this whole part of society that many of us are not aware of and it's a huge part of society, which is gamers."}, {"time": 596, "text": "I mean, every time I come across that in YouTube or streaming sites, I mean, this is the huge number of people play games religiously."}, {"time": 607, "text": "Do you have a sense of those folks, especially now that you've returned to that realm a little bit on the AI side?"}, {"time": 612, "text": "Yeah, so in fact, even after Stalker, I actually played World of Warcraft, which is maybe the main sort of online worlds or in presence that you get to interact with lots of people."}, {"time": 624, "text": "So I played that for a little bit."}, {"time": 626, "text": "It was to me, it was a bit less stressful than StarCraft because winning was kind of a given."}, {"time": 630, "text": "You just put in this world and you can always complete missions."}, {"time": 634, "text": "But I think it was actually the social aspect of especially StarCraft first and then games like World of Warcraft really shaped me in a very interesting ways because what you get to experience is just people you wouldn't usually interact with, right?"}, {"time": 651, "text": "So even nowadays, I still have many Facebook friends from the area where I played online and their ways of thinking is even political."}, {"time": 660, "text": "They just, we don't live in, like we don't interact in the real world, but we were connected by basically fiber."}, {"time": 666, "text": "And that way I actually get to understand a bit better that we live in a diverse world."}, {"time": 672, "text": "And these were just connections that were made by, because, you know, I happened to go in a city in a virtual city as a priest and I met this warrior and we became friends and then we start like playing together, right?"}, {"time": 685, "text": "So I think it's transformative and more and more and more people are more aware of it."}, {"time": 691, "text": "I mean, it's becoming quite mainstream, but back in the day, as you were saying in 2000, 2005, even it was very, still very strange thing to do, especially in Europe."}, {"time": 704, "text": "I think there were exceptions like Korea, for instance, it was amazing that everything happened so early in terms of cybercafes, like if you go to Seoul, it's a city that back in the day, StarCraft was kind of, you could be a celebrity by playing StarCraft, but this was like 99, 2000, right?"}, {"time": 723, "text": "It's not like recently."}, {"time": 724, "text": "So yeah, it's quite interesting to look back and yeah, I think it's changing society."}, {"time": 730, "text": "The same way, of course, like technology and social networks and so on are also transforming things."}, {"time": 736, "text": "And a quick tangent, let me ask, you're also one of the most productive people in your particular chosen passion and path in life."}, {"time": 746, "text": "And yet you're also appreciate and enjoy video games."}, {"time": 749, "text": "Do you think it's possible to do, to enjoy video games in moderation?"}, {"time": 755, "text": "Someone told me that you could choose two out of three."}, {"time": 759, "text": "When I was playing video games, you could choose having a girlfriend, playing video games or studying."}, {"time": 766, "text": "And I think for the most part, it was relatively true."}, {"time": 770, "text": "These things do take time."}, {"time": 772, "text": "Games like StarCraft, if you take the game pretty seriously and you wanna study it, then you obviously will dedicate more time to it."}, {"time": 779, "text": "And I definitely took gaming and obviously studying very seriously."}, {"time": 783, "text": "I love learning science and et cetera."}, {"time": 788, "text": "So to me, especially when I started university undergrad, I kind of step off StarCraft."}, {"time": 794, "text": "I actually fully stopped playing."}, {"time": 796, "text": "And then World of Warcraft was a bit more casual."}, {"time": 799, "text": "You could just connect online."}, {"time": 800, "text": "And I mean, it was fun."}, {"time": 802, "text": "But as I said, that was not as much time investment as it was for me in StarCraft."}, {"time": 809, "text": "Okay, so let's get into AlphaStar."}, {"time": 811, "text": "What are the, you're behind the team."}, {"time": 815, "text": "So DeepMind has been working on StarCraft and released a bunch of cool open source agents and so on the past few years."}, {"time": 821, "text": "But AlphaStar really is the moment where the first time you beat a world class player."}, {"time": 829, "text": "So what are the parameters of the challenge in the way that AlphaStar took it on and how did you and David and the rest of the DeepMind team get into it?"}, {"time": 838, "text": "Consider that you can even beat the best in the world or top players."}, {"time": 842, "text": "I think it all started back in 2015."}, {"time": 848, "text": "Actually, I'm lying."}, {"time": 848, "text": "I think it was 2014 when DeepMind was acquired by Google."}, {"time": 854, "text": "And I at the time was at Google Brain, which was in California, is still in California."}, {"time": 858, "text": "We had this summit where we got together, the two groups."}, {"time": 861, "text": "So Google Brain and Google DeepMind got together and we gave a series of talks."}, {"time": 866, "text": "And given that they were doing deep reinforcement learning for games, I decided to bring up part of my past, which I had developed at Berkeley, like this thing which we call Berkeley OverMind, which is really just a StarCraft one bot, right?"}, {"time": 880, "text": "So I talked about that."}, {"time": 882, "text": "And I remember Demis just came to me and said, well, maybe not now, it's perhaps a bit too early, but you should just come to DeepMind and do this again with deep reinforcement learning, right?"}, {"time": 893, "text": "And at the time it sounded very science fiction for several reasons."}, {"time": 898, "text": "But then in 2016, when I actually moved to London and joined DeepMind transferring from Brain, it became apparent that because of the AlphaGo moment and kind of Blizzard reaching out to us to say, wait, like, do you want the next challenge?"}, {"time": 913, "text": "And also me being full time at DeepMind, so sort of kind of all these came together."}, {"time": 917, "text": "And then I went to Irvine in California, to the Blizzard headquarters to just chat with them and try to explain how would it all work before you do anything."}, {"time": 927, "text": "And the approach has always been about the learning perspective, right?"}, {"time": 933, "text": "So in Berkeley, we did a lot of rule based conditioning and if you have more than three units, then go attack."}, {"time": 942, "text": "And if the other has more units than me, I retreat and so on and so forth."}, {"time": 946, "text": "And of course, the point of deep reinforcement learning, deep learning, machine learning in general is that all these should be learned behavior."}, {"time": 953, "text": "So that kind of was the DNA of the project since its inception in 2016, where we just didn't even have an environment to work with."}, {"time": 962, "text": "And so that's how it all started really."}, {"time": 965, "text": "So if you go back to that conversation with Demis or even in your own head, how far away did you, because we're talking about Atari games, we're talking about Go, which is kind of, if you're honest about it, really far away from StarCraft."}, {"time": 980, "text": "In, well, now that you've beaten it, maybe you could say it's close, but it's much, it seems like StarCraft is way harder than Go philosophically and mathematically speaking."}, {"time": 990, "text": "So how far away did you think you were?"}, {"time": 994, "text": "Do you think it's 2019 and 18 you could be doing as well as you have?"}, {"time": 997, "text": "Yeah, when I kind of thought about, okay, I'm gonna dedicate a lot of my time and focus on this."}, {"time": 1004, "text": "And obviously I do a lot of different research in deep learning."}, {"time": 1008, "text": "So spending time on it, I mean, I really had to kind of think there's gonna be something good happening out of this."}, {"time": 1015, "text": "So really I thought, well, this sounds impossible."}, {"time": 1018, "text": "And it probably is impossible to do the full thing, like the full game where you play one versus one and it's only a neural network playing and so on."}, {"time": 1029, "text": "So it really felt like, I just didn't even think it was possible."}, {"time": 1033, "text": "But on the other hand, I could see some stepping stones towards that goal."}, {"time": 1038, "text": "Clearly you could define sub problems in StarCraft and sort of dissect it a bit and say, okay, here is a part of the game, here's another part."}, {"time": 1046, "text": "And also obviously the fact, so this was really also critical to me, the fact that we could access human replays, right?"}, {"time": 1054, "text": "So Blizzard was very kind."}, {"time": 1055, "text": "And in fact, they open source these for the whole community where you can just go and it's not every single StarCraft game ever played, but it's a lot of them you can just go and download."}, {"time": 1065, "text": "And every day they will, you can just query a data set and say, well, give me all the games that were played today."}, {"time": 1071, "text": "And given my kind of experience with language and sequences and supervised learning, I thought, well, that's definitely gonna be very helpful and something quite unique now, because ever before we had such a large data set of replays, of people playing the game at this scale of such a complex video game, right?"}, {"time": 1092, "text": "So that to me was a precious resource."}, {"time": 1095, "text": "And as soon as I knew that Blizzard was able to kind of give this to the community, I started to feel positive about something non trivial happening."}, {"time": 1104, "text": "But I also thought the full thing, like really no rules, no single line of code that tries to say, well, I mean, if you see this unit, build a detector, all these, not having any of these specializations seemed really, really, really difficult to me."}, {"time": 1118, "text": "Intuitively."}, {"time": 1119, "text": "I do also like that Blizzard was teasing or even trolling you, sort of almost, yeah, pulling you in into this really difficult challenge."}, {"time": 1130, "text": "Do they have any awareness?"}, {"time": 1131, "text": "What's the interest from the perspective of Blizzard, except just curiosity?"}, {"time": 1137, "text": "Yeah, I think Blizzard has really understood and really bring forward this competitiveness of esports in games."}, {"time": 1144, "text": "The StarCraft really kind of sparked a lot of, like something that almost was never seen, especially as I was saying, back in Korea."}, {"time": 1153, "text": "So they just probably thought, well, this is such a pure one versus one setup that it would be great to see if something that can play Atari or Go and then later on chess could even tackle these kind of complex real time strategy game, right?"}, {"time": 1170, "text": "So for them, they wanted to see first, obviously whether it was possible, if the game they created was in a way solvable to some extent."}, {"time": 1180, "text": "And I think on the other hand, they also are a pretty modern company that innovates a lot."}, {"time": 1185, "text": "So just starting to understand AI for them to how to bring AI into games is not AI for games, but games for AI, right?"}, {"time": 1194, "text": "I mean, both ways I think can work."}, {"time": 1196, "text": "And we obviously at DeepMind use games for AI, right?"}, {"time": 1200, "text": "To drive AI progress, but Blizzard might actually be able to do and many other companies to start to understand and do the opposite."}, {"time": 1206, "text": "So I think that is also something they can get out of these."}, {"time": 1209, "text": "And they definitely, we have brainstormed a lot about these, right?"}, {"time": 1213, "text": "But one of the interesting things to me about StarCraft and Diablo and these games that Blizzard has created is the task of balancing classes, for example."}, {"time": 1223, "text": "Sort of making the game fair from the starting point and then let skill determine the outcome."}, {"time": 1230, "text": "Is there, I mean, can you first comment, there's three races, Zerg, Protoss and Terran."}, {"time": 1236, "text": "I don't know if I've ever said that out loud."}, {"time": 1238, "text": "Is that how you pronounce it?"}, {"time": 1240, "text": "Terran?"}, {"time": 1240, "text": "Yeah, Terran."}, {"time": 1244, "text": "Yeah, I don't think I've ever in person interacted with anybody about StarCraft, that's funny."}, {"time": 1249, "text": "So they seem to be pretty balanced."}, {"time": 1251, "text": "I wonder if the AI, the work that you're doing with AlphaStar would help balance them even further."}, {"time": 1259, "text": "Is that something you think about?"}, {"time": 1260, "text": "Is that something that Blizzard is thinking about?"}, {"time": 1263, "text": "Right, so balancing when you add a new unit or a new spell type is obviously possible given that you can always train or pre train at scale some agent that might start using that in unintended ways."}, {"time": 1276, "text": "But I think actually, if you understand how StarCraft has kind of co evolved with players, in a way, I think it's actually very cool the ways that many of the things and strategies that people came up with, right?"}, {"time": 1288, "text": "So I think we've seen it over and over in StarCraft that Blizzard comes up with maybe a new unit and then some players get creative and do something kind of unintentional or something that Blizzard designers that just simply didn't test or think about."}, {"time": 1303, "text": "And then after that becomes kind of mainstream in the community, Blizzard patches the game and then they kind of maybe weaken that strategy or make it actually more interesting but a bit more balanced."}, {"time": 1315, "text": "So these kind of continual talk between players and Blizzard is kind of what has defined them actually in actually most games in StarCraft but also in World of Warcraft, they would do that."}, {"time": 1326, "text": "There are several classes and it would be not good that everyone plays absolutely the same race and so on, right?"}, {"time": 1333, "text": "So I think they do care about balancing of course and they do a fair amount of testing but it's also beautiful to also see how players get creative anyways."}, {"time": 1344, "text": "And I mean, whether AI can be more creative at this point, I don't think so, right?"}, {"time": 1348, "text": "I mean, it's just sometimes something so amazing happens."}, {"time": 1351, "text": "Like I remember back in the days, like you have these drop ships that could drop the rivers and that was actually not thought about that you could drop this unit that has this what's called splash damage that would basically eliminate all the enemies workers at once."}, {"time": 1367, "text": "No one thought that you could actually put them in really early game, do that kind of damage and then things change in the game."}, {"time": 1375, "text": "But I don't know, I think it's quite an amazing exploration process from both sides, players and Blizzard alike."}, {"time": 1381, "text": "Well, it's almost like a reinforcement learning exploration but the scale of humans that play Blizzard games is almost on the scale of a large scale deep mind RL experiment."}, {"time": 1395, "text": "I mean, if you look at the numbers, I mean, you're talking about, I don't know how many games but hundreds of thousands of games probably a month."}, {"time": 1402, "text": "I mean, so it's almost the same as running RL agents."}, {"time": 1408, "text": "What aspect of the problem of Starcraft do you think is the hardest?"}, {"time": 1412, "text": "Is it the, like you said, the imperfect information?"}, {"time": 1415, "text": "Is it the fact they have to do longterm planning?"}, {"time": 1418, "text": "Is it the real time aspects?"}, {"time": 1420, "text": "We have to do stuff really quickly."}, {"time": 1422, "text": "Is it the fact that a large action space so you can do so many possible things?"}, {"time": 1427, "text": "Or is it, you know, in the game theoretic sense there is no Nash equilibrium or at least you don't know what the optimal strategy is because there's way too many options."}, {"time": 1437, "text": "Is there something that stands out as just like the hardest the most annoying thing?"}, {"time": 1441, "text": "So when we sort of looked at the problem and start to define like the parameters of it, right?"}, {"time": 1447, "text": "What are the observations?"}, {"time": 1448, "text": "What are the actions?"}, {"time": 1450, "text": "It became very apparent that, you know, the very first barrier that one would hit in Starcraft would be because of the action space being so large and as not being able to search like you could in chess or go even though the search space is vast."}, {"time": 1468, "text": "The main problem that we identified was that of exploration, right?"}, {"time": 1472, "text": "So without any sort of human knowledge or human prior, if you think about Starcraft and you know how deep reinforcement learnings algorithm work which is essentially by issuing random actions and hoping that they will get some wins sometimes so they could learn."}, {"time": 1489, "text": "So if you think of the action space in Starcraft almost anything you can do in the early game is bad because any action involves taking workers which are mining minerals for free."}, {"time": 1501, "text": "That's something that the game does automatically sends them to mine."}, {"time": 1504, "text": "And you would immediately just take them out of mining and send them around."}, {"time": 1509, "text": "So just thinking how is it gonna be possible to get to understand these concepts but even more like expanding, right?"}, {"time": 1519, "text": "There's these buildings you can place in other locations in the map to gather more resources but the location of the building is important and you have to select a worker, send it walking to that location, build the building, wait for the building to be built and then put extra workers there so they start mining."}, {"time": 1537, "text": "That feels like impossible if you just randomly click to produce that state, desirable state that then you could hope to learn from because eventually that may yield to an extra win, right?"}, {"time": 1549, "text": "So for me, the exploration problem and due to the action space and the fact that there's not really turns, there's so many turns because the game essentially takes that 22 times per second."}, {"time": 1562, "text": "I mean, that's how they could discretize sort of time."}, {"time": 1565, "text": "Obviously you always have to discretize time but there's no such thing as real time but it's really a lot of time steps of things that could go wrong."}, {"time": 1574, "text": "And that definitely felt a priori like the hardest."}, {"time": 1577, "text": "You mentioned many good ones."}, {"time": 1579, "text": "I think partial observability and the fact that there is no perfect strategy because of the partial observability."}, {"time": 1585, "text": "Those are very interesting problems."}, {"time": 1586, "text": "We start seeing more and more now in terms of as we solve the previous ones but the core problem to me was exploration and solving it has been basically kind of the focus and how we saw the first breakthroughs."}, {"time": 1599, "text": "So exploration in a multi hierarchical way."}, {"time": 1603, "text": "So like 22 times a second exploration has a very different meaning than it does in terms of should I gather resources early or should I wait or so on."}, {"time": 1613, "text": "So how do you solve the longterm?"}, {"time": 1616, "text": "Let's talk about the internals of AlphaStar."}, {"time": 1618, "text": "So first of all, how do you represent the state of the game as an input?"}, {"time": 1625, "text": "How do you then do the longterm sequence modeling?"}, {"time": 1628, "text": "How do you build a policy?"}, {"time": 1630, "text": "What's the architecture like?"}, {"time": 1632, "text": "So AlphaStar has obviously several components but everything passes through what we call the policy which is a neural network."}, {"time": 1642, "text": "And that's kind of the beauty of it."}, {"time": 1644, "text": "There is, I could just now give you a neural network and some weights."}, {"time": 1648, "text": "And if you fed the right observations and you understood the actions the same way we do you would have basically the agent playing the game."}, {"time": 1655, "text": "There's absolutely nothing else needed other than those weights that were trained."}, {"time": 1660, "text": "Now, the first step is observing the game and we've experimented with a few alternatives."}, {"time": 1666, "text": "The one that we currently use mixes both spatial sort of images that you would process from the game that is the zoomed out version of the map and also a zoomed in version of the camera or the screen as we call it."}, {"time": 1680, "text": "But also we give to the agent the list of units that it sees more of as a set of objects that it can operate on."}, {"time": 1691, "text": "That is not necessarily required to use it."}, {"time": 1694, "text": "And we have versions of the game that play well without this set vision that is a bit not like how humans perceive the game."}, {"time": 1701, "text": "But it certainly helps a lot because it's a very natural way to encode the game is by just looking at all the units that there are."}, {"time": 1709, "text": "They have properties like health, position, type of unit whether it's my unit or the enemies."}, {"time": 1716, "text": "And that sort of is kind of the summary of the state of the game, that list of units or set of units that you see all the time."}, {"time": 1727, "text": "But that's pretty close to the way humans see the game."}, {"time": 1729, "text": "Why do you say it's not, isn't that, you're saying the exactness of it is not similar to humans?"}, {"time": 1735, "text": "The exactness of it is perhaps not the problem."}, {"time": 1737, "text": "I guess maybe the problem if you look at it from how actually humans play the game is that they play with a mouse and a keyboard and a screen and they don't see sort of a structured object with all the units."}, {"time": 1749, "text": "What they see is what they see on the screen, right?"}, {"time": 1753, "text": "Remember that there's a, sorry to interrupt, there's a plot that you showed with camera base where you do exactly that, right?"}, {"time": 1758, "text": "You move around and that seems to converge to similar performance."}, {"time": 1762, "text": "Yeah, I think that's what I, we're kind of experimenting with what's necessary or not, but using the set."}, {"time": 1768, "text": "So, actually, if you look at research in computer vision, where it makes a lot of sense to treat images as two dimensional arrays, there's actually a very nice paper from Facebook."}, {"time": 1780, "text": "I think, I forgot who the authors are, but I think it's part of Caming's group."}, {"time": 1786, "text": "And what they do is they take an image, which is this two dimensional signal, and they actually take pixel by pixel and scramble the image as if it was just a list of pixels."}, {"time": 1799, "text": "Crucially, they encode the position of the pixels with the X, Y coordinates."}, {"time": 1803, "text": "And this is just kind of a new architecture, which we incidentally also use in StarCraft called the Transformer, which is a very popular paper from last year, which yielded very nice result in machine translation."}, {"time": 1815, "text": "And if you actually believe in this kind of, oh, it's actually a set of pixels, as long as you encode X, Y, it's okay, then you could argue that the list of units that we see is precisely that, because we have each unit as a kind of pixel, if you will, and then their X, Y coordinates."}, {"time": 1833, "text": "So in that perspective, we, without knowing it, we use the same architecture that was shown to work very well on Pascal and ImageNet and so on."}, {"time": 1841, "text": "So the interesting thing here is putting it in that way it starts to move it towards the way you usually work with language."}, {"time": 1849, "text": "So what, and especially with your expertise and work in language, it seems like there's echoes of a lot of the way you would work with natural language in the way you've approached AlphaStar."}, {"time": 1863, "text": "What's, does that help with the longterm sequence modeling there somehow?"}, {"time": 1868, "text": "Exactly, so now that we understand what an observation for a given time step is, we need to move on to say, well, there's going to be a sequence of such observations and an agent will need to, given all that it's seen, not only the current time step, but all that it's seen, why?"}, {"time": 1884, "text": "Because there is partial observability."}, {"time": 1885, "text": "We must remember whether we saw a worker going somewhere, for instance, right?"}, {"time": 1890, "text": "Because then there might be an expansion on the top right of the map."}, {"time": 1893, "text": "So given that, what you must then think about is there is the problem of given all the observations, you have to predict the next action."}, {"time": 1902, "text": "And not only given all the observations, but given all the observations and given all the actions you've taken, predict the next action."}, {"time": 1909, "text": "And that sounds exactly like machine translation where, and that's exactly how kind of I saw the problem, especially when you are given supervised data or replays from humans, because the problem is exactly the same."}, {"time": 1923, "text": "You're translating essentially a prefix of observations and actions onto what's going to happen next, which is exactly how you would train a model to translate or to generate language as well, right?"}, {"time": 1934, "text": "Do you have a certain prefix?"}, {"time": 1936, "text": "You must remember everything that comes in the past because otherwise you might start having noncoherent text."}, {"time": 1942, "text": "And the same architectures we're using LSTMs and transformers to operate on across time to kind of integrate all that's happened in the past."}, {"time": 1953, "text": "Those architectures that work so well in translation or language modeling are exactly the same than what the agent is using to issue actions in the game."}, {"time": 1962, "text": "And the way we train it, moreover, for imitation, which is step one of AlphaStar is, take all the human experience and try to imitate it, much like you try to imitate translators that translated many pairs of sentences from French to English say, that sort of principle applies exactly the same."}, {"time": 1980, "text": "It's almost the same code, except that instead of words, you have a slightly more complicated objects, which are the observations and the actions are also a bit more complicated than a word."}, {"time": 1991, "text": "Is there a self play component then too?"}, {"time": 1993, "text": "So once you run out of imitation?"}, {"time": 1996, "text": "Right, so indeed you can bootstrap from human replays, but then the agents you get are actually not as good as the humans you imitated, right?"}, {"time": 2008, "text": "So how do we imitate?"}, {"time": 2010, "text": "Well, we take humans from 3000 MMR and higher."}, {"time": 2014, "text": "3000 MMR is just a metric of human skill and 3000 MMR might be like 50% percentile, right?"}, {"time": 2021, "text": "So it's just average human."}, {"time": 2024, "text": "So maybe quick pause, MMR is a ranking scale, the matchmaking rating for players."}, {"time": 2030, "text": "So it's 3000, I remember there's like a master and a grand master, what's 3000?"}, {"time": 2034, "text": "So 3000 is pretty bad."}, {"time": 2036, "text": "I think it's kind of goals level."}, {"time": 2038, "text": "It just sounds really good relative to chess, I think."}, {"time": 2040, "text": "Oh yeah, yeah, no, the ratings, the best in the world are at 7,000 MMR."}, {"time": 2045, "text": "So 3000, it's a bit like Elo indeed, right?"}, {"time": 2047, "text": "So 3,500 just allows us to not filter a lot of the data."}, {"time": 2053, "text": "So we like to have a lot of data in deep learning as you probably know."}, {"time": 2057, "text": "So we take these kind of 3,500 and above, but then we do a very interesting trick, which is we tell the neural network what level they are imitating."}, {"time": 2067, "text": "So we say, this replay you're gonna try to imitate to predict the next action for all the actions that you're gonna see is a 4,000 MMR replay."}, {"time": 2076, "text": "This one is a 6,000 MMR replay."}, {"time": 2078, "text": "And what's cool about this is then we take this policy that is being trained from human, and then we can ask it to play like a 3000 MMR player by setting a beat saying, well, okay, play like a 3000 MMR player or play like a 6,000 MMR player."}, {"time": 2093, "text": "And you actually see how the policy behaves differently."}, {"time": 2097, "text": "It gets worse economy if you play like a goal level player, it does less actions per minute, which is the number of clicks or number of actions that you will issue in a whole minute."}, {"time": 2107, "text": "And it's very interesting to see that it kind of imitates the skill level quite well."}, {"time": 2112, "text": "But if we ask it to play like a 6,000 MMR player, we tested, of course, these policies to see how well they do."}, {"time": 2118, "text": "They actually beat all the built in AIs that Blizzard put in the game, but they're nowhere near 6,000 MMR players, right?"}, {"time": 2125, "text": "They might be maybe around goal level, platinum, perhaps."}, {"time": 2129, "text": "So there's still a lot of work to be done for the policy to truly understand what it means to win."}, {"time": 2135, "text": "So far, we only asked them, okay, here is the screen."}, {"time": 2138, "text": "And that's what's happened on the game until this point."}, {"time": 2141, "text": "What would the next action be if we ask a pro to now say, oh, you're gonna click here or here or there."}, {"time": 2149, "text": "And the point is experiencing wins and losses is very important to then start to refine."}, {"time": 2156, "text": "Otherwise the policy can get loose, can just go off policy as we call it."}, {"time": 2160, "text": "That's so interesting that you can at least hope eventually to be able to control a policy approximately to be at some MMR level."}, {"time": 2170, "text": "That's so interesting, especially given that you have ground truth for a lot of these cases."}, {"time": 2175, "text": "Can I ask you a personal question?"}, {"time": 2177, "text": "What's your MMR?"}, {"time": 2179, "text": "Well, I haven't played StarCraft II, so I am unranked, which is the kind of lowest league."}, {"time": 2186, "text": "So I used to play StarCraft, the first one."}, {"time": 2189, "text": "But you haven't seriously played StarCraft II."}, {"time": 2192, "text": "So the best player we have at DeepMind is about 5,000 MMR, which is high masters."}, {"time": 2199, "text": "It's not at grand master level."}, {"time": 2202, "text": "Grand master level will be the top 200 players in a certain region like Europe or America or Asia."}, {"time": 2209, "text": "But for me, it would be hard to say."}, {"time": 2211, "text": "I am very bad at the game."}, {"time": 2213, "text": "I actually played AlphaStar a bit too late and it beat me."}, {"time": 2216, "text": "I remember the whole team was, oh, Oreo, you should play."}, {"time": 2219, "text": "And I was, oh, it looks like it's not so good yet."}, {"time": 2222, "text": "And then I remember I kind of got busy and waited an extra week and I played and it really beat me very badly."}, {"time": 2229, "text": "Was that, I mean, how did that feel?"}, {"time": 2231, "text": "Isn't that an amazing feeling?"}, {"time": 2232, "text": "That's amazing, yeah."}, {"time": 2233, "text": "I mean, obviously I tried my best and I tried to also impress my, because I actually played the first game."}, {"time": 2239, "text": "So I'm still pretty good at micromanagement."}, {"time": 2243, "text": "The problem is I just don't understand StarCraft II."}, {"time": 2245, "text": "I understand StarCraft."}, {"time": 2247, "text": "And when I played StarCraft, I probably was consistently like for a couple of years, top 32 in Europe."}, {"time": 2254, "text": "So I was decent, but at the time we didn't have this kind of MMR system as well established."}, {"time": 2260, "text": "So it would be hard to know what it was back then."}, {"time": 2263, "text": "So what's the difference in interface between AlphaStar and StarCraft and a human player in StarCraft?"}, {"time": 2269, "text": "Is there any significant differences between the way they both see the game?"}, {"time": 2274, "text": "I would say the way they see the game, there's a few things that are just very hard to simulate."}, {"time": 2281, "text": "The main one perhaps, which is obvious in hindsight is what's called cloaked units, which are invisible units."}, {"time": 2290, "text": "So in StarCraft, you can make some units that you need to have a particular kind of unit to detect it."}, {"time": 2298, "text": "So these units are invisible."}, {"time": 2300, "text": "If you cannot detect them, you cannot target them."}, {"time": 2302, "text": "So they would just destroy your buildings or kill your workers."}, {"time": 2307, "text": "But despite the fact you cannot target the unit, there's a shimmer that as a human you observe."}, {"time": 2314, "text": "I mean, you need to train a little bit, you need to pay attention, but you would see this kind of space time distortion and you would know, okay, there are, yeah."}, {"time": 2324, "text": "Yeah, there's like a wave thing."}, {"time": 2326, "text": "Yeah, it's called shimmer."}, {"time": 2327, "text": "Space time distortion, I like it."}, {"time": 2329, "text": "That's really like, the Blizzard term is shimmer."}, {"time": 2331, "text": "Shimmer, okay."}, {"time": 2332, "text": "And so these shimmer professional players actually can see it immediately."}, {"time": 2337, "text": "They understand it very well, but it's still something that requires certain amount of attention and it's kind of a bit annoying to deal with."}, {"time": 2345, "text": "Whereas for AlphaStar, in terms of vision, it's very hard for us to simulate sort of, oh, are you looking at this pixel in the screen and so on?"}, {"time": 2354, "text": "So the only thing we can do is, there is a unit that's invisible over there."}, {"time": 2359, "text": "So AlphaStar would know that immediately."}, {"time": 2362, "text": "Obviously still obeys the rules."}, {"time": 2364, "text": "You cannot attack the unit."}, {"time": 2365, "text": "You must have a detector and so on, but it's kind of one of the main things that it just doesn't feel there's a very proper way."}, {"time": 2372, "text": "I mean, you could imagine, oh, you don't have hypers."}, {"time": 2375, "text": "Maybe you don't know exactly where it is, or sometimes you see it, sometimes you don't, but it's just really, really complicated to get it so that everyone would agree, oh, that's the best way to simulate this, right?"}, {"time": 2387, "text": "It seems like a perception problem."}, {"time": 2389, "text": "It is a perception problem."}, {"time": 2390, "text": "So the only problem is people, you ask, oh, what's the difference between how humans perceive the game?"}, {"time": 2396, "text": "I would say they wouldn't be able to tell a shimmer immediately as it appears on the screen, whereas AlphaStar in principle sees it very sharply, right?"}, {"time": 2405, "text": "It sees that the bit turned from zero to one, meaning there's now a unit there, although you don't know the unit, or you know that you cannot attack it and so on."}, {"time": 2415, "text": "So that from a vision standpoint, that probably is the one that is kind of the most obvious one."}, {"time": 2422, "text": "Then there are things humans cannot do perfectly, even professionals, which is they might miss a detail, or they might have not seen a unit."}, {"time": 2430, "text": "And obviously as a computer, if there's a corner of the screen that turns green because a unit enters the field of view, that can go into the memory of the agent, the LSTM, and persist there for a while, and for however long is relevant, right?"}, {"time": 2445, "text": "And in terms of action, it seems like the rate of action from AlphaStar is comparative, if not slower than professional players, but it's more precise is what I read."}, {"time": 2457, "text": "So that's really probably the one that is causing us more issues for a couple of reasons, right?"}, {"time": 2465, "text": "The first one is StarCraft has been an AI environment for quite a few years."}, {"time": 2469, "text": "In fact, I mean, I was participating in the very first competition back in 2010."}, {"time": 2475, "text": "And there's really not been a kind of a very clear set of rules how the actions per minute, the rate of actions that you can issue is."}, {"time": 2484, "text": "And as a result, these agents or bots that people build in a kind of almost very cool way, they do like 20,000, 40,000 actions per minute."}, {"time": 2495, "text": "Now, to put this in perspective, a very good professional human might do 300 to 800 actions per minute."}, {"time": 2504, "text": "They might not be as precise."}, {"time": 2505, "text": "That's why the range is a bit tricky to identify exactly."}, {"time": 2509, "text": "I mean, 300 actions per minute precisely is probably realistic."}, {"time": 2513, "text": "800 is probably not, but you see humans doing a lot of actions because they warm up and they kind of select things and spam and so on just so that when they need, they have the accuracy."}, {"time": 2524, "text": "So we came into this by not having kind of a standard way to say, well, how do we measure whether an agent is at human level or not?"}, {"time": 2535, "text": "On the other hand, we had a huge advantage, which is because we do imitation learning, agents turned out to act like humans in terms of rate of actions, even precisions and imprecisions of actions in the supervised policy."}, {"time": 2550, "text": "You could see all these."}, {"time": 2551, "text": "You could see how agents like to spam click, to move here."}, {"time": 2554, "text": "If you played especially Diablo, you wouldn't know what I mean."}, {"time": 2557, "text": "I mean, you just like spam, oh, move here, move here, move here."}, {"time": 2560, "text": "You're doing literally like maybe five actions in two seconds, but these actions are not very meaningful."}, {"time": 2566, "text": "One would have sufficed."}, {"time": 2568, "text": "So on the one hand, we start from this imitation policy that is at the ballpark of the actions per minutes of humans because it's actually statistically trying to imitate humans."}, {"time": 2578, "text": "So we see these very nicely in the curves that we showed in the blog post."}, {"time": 2582, "text": "There's these actions per minute, and the distribution looks very human like."}, {"time": 2587, "text": "But then, of course, as self play kicks in, and that's the part we haven't talked too much yet, but of course, the agent must play against itself to improve, then there's almost no guarantees that these actions will not become more precise or even the rate of actions is going to increase over time."}, {"time": 2606, "text": "So what we did, and this is probably the first attempt that we thought was reasonable, is we looked at the distribution of actions for humans for certain windows of time."}, {"time": 2616, "text": "And just to give a perspective, because I guess I mentioned that some of these agents that are programmatic, let's call them."}, {"time": 2622, "text": "They do 40,000 actions per minute."}, {"time": 2624, "text": "Professionals, as I said, do 300 to 800."}, {"time": 2627, "text": "So what we looked is we look at the distribution over professional gamers, and we took reasonably high actions per minute, but we kind of identify certain cutoffs after which, even if the agent wanted to act, these actions would be dropped."}, {"time": 2642, "text": "But the problem is this cutoff is probably set a bit too high."}, {"time": 2647, "text": "And what ends up happening, even though the games, and when we ask the professionals and the gamers, by and large, they feel like it's playing humanlike, there are some agents that developed maybe slightly too high APMs, which is actions per minute, combined with the precision, which made people start discussing a very interesting issue, which is, should we have limited these?"}, {"time": 2672, "text": "Should we just let it lose and see what cool things it can come up with?"}, {"time": 2678, "text": "So this is in itself an extremely interesting question, but the same way that modeling the shimmer would be so difficult, modeling absolutely all the details about muscles and precision and tiredness of humans would be quite difficult."}, {"time": 2692, "text": "So we're really here kind of innovating in this sense of, OK, what could be maybe the next iteration of putting more rules that makes the agents more humanlike in terms of restrictions?"}, {"time": 2706, "text": "Yeah, putting constraints that."}, {"time": 2708, "text": "More constraints, yeah."}, {"time": 2710, "text": "That's really innovative."}, {"time": 2711, "text": "So one of the constraints you put on yourself, or at least focused in, is on the Protoss race, as far as I understand."}, {"time": 2719, "text": "Can you tell me about the different races and how they, so Protoss, Terran, and Zerg, how do they compare?"}, {"time": 2727, "text": "How do they interact?"}, {"time": 2728, "text": "Why did you choose Protoss?"}, {"time": 2730, "text": "Yeah, in the dynamics of the game seen from a strategic perspective."}, {"time": 2735, "text": "So Protoss, so in StarCraft there are three races."}, {"time": 2739, "text": "Indeed, in the demonstration, we saw only the Protoss race."}, {"time": 2743, "text": "So maybe let's start with that one."}, {"time": 2745, "text": "Protoss is kind of the most technologically advanced race."}, {"time": 2749, "text": "It has units that are expensive but powerful."}, {"time": 2753, "text": "So in general, you want to kind of conserve your units as you go attack."}, {"time": 2759, "text": "And then you want to utilize these tactical advantages of very fancy spells and so on and so forth."}, {"time": 2767, "text": "And at the same time, they're kind of, people say they're a bit easier to play perhaps."}, {"time": 2775, "text": "But that I actually didn't know."}, {"time": 2777, "text": "I mean, I just talked now a lot to the players that we work with, TLO and Mana, and they said, oh yeah, Protoss is actually, people think, is actually one of the easiest races."}, {"time": 2786, "text": "So perhaps the easier, that doesn't mean that it's obviously professional players excel at the three races."}, {"time": 2794, "text": "And there's never a race that dominates for a very long time anyway."}, {"time": 2798, "text": "So if you look at the top, I don't know, 100 in the world, is there one race that dominates that list?"}, {"time": 2804, "text": "It would be hard to know because it depends on the regions."}, {"time": 2806, "text": "I think it's pretty equal in terms of distribution."}, {"time": 2810, "text": "And Blizzard wants it to be equal."}, {"time": 2813, "text": "They wouldn't want one race like Protoss to not be representative in the top place."}, {"time": 2819, "text": "So definitely, they tried it to be balanced."}, {"time": 2823, "text": "So then maybe the opposite race of Protoss is Zerg."}, {"time": 2827, "text": "Zerg is a race where you just kind of expand and take over as many resources as you can, and they have a very high capacity to regenerate their units."}, {"time": 2837, "text": "So if you have an army, it's not that valuable in terms of losing the whole army is not a big deal as Zerg because you can then rebuild it."}, {"time": 2845, "text": "And given that you generally accumulate a huge bank of resources, Zergs typically play by applying a lot of pressure, maybe losing their whole army, but then rebuilding it quickly."}, {"time": 2857, "text": "So although, of course, every race, I mean, there's never, I mean, they're pretty diverse."}, {"time": 2863, "text": "I mean, there are some units in Zerg that are technologically advanced, and they do some very interesting spells."}, {"time": 2868, "text": "And there's some units in Protoss that are less valuable, and you could lose a lot of them and rebuild them, and it wouldn't be a big deal."}, {"time": 2875, "text": "All right, so maybe I'm missing out."}, {"time": 2877, "text": "Maybe I'm going to say some dumb stuff, but summary of strategy."}, {"time": 2882, "text": "So first, there's collection of a lot of resources."}, {"time": 2885, "text": "That's one option."}, {"time": 2886, "text": "The other one is expanding, so building other bases."}, {"time": 2891, "text": "Then the other is obviously building units and attacking with those units."}, {"time": 2897, "text": "And then I don't know what else there is."}, {"time": 2900, "text": "Maybe there's the different timing of attacks, like do I attack early, attack late?"}, {"time": 2906, "text": "What are the different strategies that emerged that you've learned about?"}, {"time": 2909, "text": "I've read that a bunch of people are super happy that you guys have apparently, that Alpha Star apparently has discovered that it's really good to, what is it, saturate?"}, {"time": 2918, "text": "Oh yeah, the mineral line."}, {"time": 2919, "text": "Yeah, the mineral line."}, {"time": 2922, "text": "And that's for greedy amateur players like myself."}, {"time": 2925, "text": "That's always been a good strategy."}, {"time": 2927, "text": "You just build up a lot of money, and it just feels good to just accumulate and accumulate."}, {"time": 2933, "text": "So thank you for discovering that and validating all of us."}, {"time": 2936, "text": "But is there other strategies that you discovered that are interesting, unique to this game?"}, {"time": 2941, "text": "Yeah, so if you look at the kind of, not being a StarCraft II player, but of course StarCraft and StarCraft II and real time strategy games in general are very similar."}, {"time": 2952, "text": "I would classify perhaps the openings of the game."}, {"time": 2957, "text": "They're very important."}, {"time": 2958, "text": "And generally I would say there's two kinds of openings."}, {"time": 2961, "text": "One that's a standard opening."}, {"time": 2963, "text": "That's generally how players find sort of a balance between risk and economy and building some units early on so that they could defend, but they're not too exposed basically, but also expanding quite quickly."}, {"time": 2978, "text": "So this would be kind of a standard opening."}, {"time": 2981, "text": "And within a standard opening, then what you do choose generally is what technology are you aiming towards?"}, {"time": 2987, "text": "So there's a bit of rock, paper, scissors of you could go for spaceships or you could go for invisible units or you could go for, I don't know, like massive units that attack against certain kinds of units, but they're weak against others."}, {"time": 3001, "text": "So standard openings themselves have some choices like rock, paper, scissors style."}, {"time": 3006, "text": "Of course, if you scout and you're good at guessing what the opponent is doing, then you can play as an advantage because if you know you're gonna play rock, I mean, I'm gonna play paper obviously."}, {"time": 3015, "text": "So you can imagine that normal standard games in StarCraft looks like a continuous rock, paper, scissors game where you guess what the distribution of rock, paper, and scissors is from the enemy and reacting accordingly to try to beat it or put the paper out before he kind of changes his mind from rock to scissors, and then you would be in a weak position."}, {"time": 3039, "text": "So, sorry to pause on that."}, {"time": 3041, "text": "I didn't realize this element because I know it's true with poker."}, {"time": 3044, "text": "I know I looked at Labratus."}, {"time": 3048, "text": "So you're also estimating trying to guess the distribution, trying to better and better estimate the distribution of what the opponent is likely to be doing."}, {"time": 3055, "text": "Yeah, I mean, as a player, you definitely wanna have a belief state over what's up on the other side of the map."}, {"time": 3062, "text": "And when your belief state becomes inaccurate, when you start having that serious doubts, whether he's gonna play something that you must know, that's when you scout."}, {"time": 3071, "text": "You wanna then gather information, right?"}, {"time": 3074, "text": "Is improving the accuracy of the belief or improving the belief state part of the loss that you're trying to optimize?"}, {"time": 3080, "text": "Or is it just a side effect?"}, {"time": 3082, "text": "It's implicit, but you could explicitly model it, and it would be quite good at probably predicting what's on the other side of the map."}, {"time": 3090, "text": "But so far, it's all implicit."}, {"time": 3092, "text": "There's no additional reward for predicting the enemy."}, {"time": 3096, "text": "So there's these standard openings, and then there's what people call cheese, which is very interesting."}, {"time": 3102, "text": "And AlphaStar sometimes really likes this kind of cheese."}, {"time": 3106, "text": "These cheeses, what they are is kind of an all in strategy."}, {"time": 3110, "text": "You're gonna do something sneaky."}, {"time": 3113, "text": "You're gonna hide your own buildings close to the enemy base, or you're gonna go for hiding your technological buildings so that you do invisible units and the enemy just cannot react to detect it and thus lose the game."}, {"time": 3127, "text": "And there's quite a few of these cheeses and variants of them."}, {"time": 3131, "text": "And there it's where actually the belief state becomes even more important."}, {"time": 3136, "text": "Because if I scout your base and I see no buildings at all, any human player knows something's up."}, {"time": 3142, "text": "They might know, well, you're hiding something close to my base."}, {"time": 3145, "text": "Should I build suddenly a lot of units to defend?"}, {"time": 3148, "text": "Should I actually block my ramp with workers so that you cannot come and destroy my base?"}, {"time": 3153, "text": "So there's all this is happening and defending against cheeses is extremely important."}, {"time": 3159, "text": "And in the AlphaStar League, many agents actually develop some cheesy strategies."}, {"time": 3165, "text": "And in the games we saw against TLO and Mana, two out of the 10 agents were actually doing these kind of strategies which are cheesy strategies."}, {"time": 3173, "text": "And then there's a variant of cheesy strategy which is called all in."}, {"time": 3177, "text": "So an all in strategy is not perhaps as drastic as, oh, I'm gonna build cannons on your base and then bring all my workers and try to just disrupt your base and game over, or GG as we say in StarCraft."}, {"time": 3189, "text": "There's these kind of very cool things that you can align precisely at a certain time mark."}, {"time": 3194, "text": "So for instance, you can generate exactly 10 unit composition that is perfect, like five of this type, five of this other type, and align the upgrade so that at four minutes and a half, let's say, you have these 10 units and the upgrade just finished."}, {"time": 3210, "text": "And at that point, that army is really scary."}, {"time": 3213, "text": "And unless the enemy really knows what's going on, if you push, you might then have an advantage because maybe the enemy is doing something more standard, it expanded too much, it developed too much economy, and it trade off badly against having defenses, and the enemy will lose."}, {"time": 3231, "text": "But it's called all in because if you don't win, then you're gonna lose."}, {"time": 3235, "text": "So you see players that do these kinds of strategies, if they don't succeed, game is not over."}, {"time": 3240, "text": "I mean, they still have a base and they still gathering minerals, but they will just GG out of the game because they know, well, game is over."}, {"time": 3246, "text": "I gambled and I failed."}, {"time": 3248, "text": "So if we start entering the game theoretic aspects of the game, it's really rich and it's really, that's why it also makes it quite entertaining to watch."}, {"time": 3257, "text": "Even if I don't play, I still enjoy watching the game."}, {"time": 3261, "text": "But the agents are trying to do this mostly implicitly."}, {"time": 3266, "text": "But one element that we improved in self play is creating the Alpha Star League."}, {"time": 3271, "text": "And the Alpha Star League is not pure self play."}, {"time": 3274, "text": "It's trying to create a different personalities of agents so that some of them will become cheesy agents."}, {"time": 3281, "text": "Some of them might become very economical, very greedy, like getting all the resources, but then being maybe early on, they're gonna be weak, but later on, they're gonna be very strong."}, {"time": 3291, "text": "And by creating this personality of agents, which sometimes it just happens naturally that you can see kind of an evolution of agents that given the previous generation, they train against all of them and then they generate kind of the perfect counter to that distribution."}, {"time": 3305, "text": "But these agents, you must have them in the populations because if you don't have them, you're not covered against these things."}, {"time": 3313, "text": "You wanna create all sorts of the opponents that you will find in the wild."}, {"time": 3318, "text": "So you can be exposed to these cheeses, early aggression, later aggression, more expansions, dropping units in your base from the side, all these things."}, {"time": 3329, "text": "And pure self play is getting a bit stuck at finding some subset of these, but not all of these."}, {"time": 3336, "text": "So the Alpha Star League is a way to kind of do an ensemble of agents that they're all playing in a league, much like people play on Battle.net, right?"}, {"time": 3345, "text": "They play, you play against someone who does a new cool strategy and you immediately, oh my God, I wanna try it, I wanna play again."}, {"time": 3353, "text": "And this to me was another critical part of the problem, which was, can we create a Battle.net for agents?"}, {"time": 3361, "text": "And that's kind of what the Alpha Star League really is."}, {"time": 3364, "text": "And where they stick to their different strategies."}, {"time": 3366, "text": "Yeah, wow, that's really, really interesting."}, {"time": 3369, "text": "But that said, you were fortunate enough or just skilled enough to win five, zero."}, {"time": 3377, "text": "And so how hard is it to win?"}, {"time": 3379, "text": "I mean, that's not the goal."}, {"time": 3380, "text": "I guess, I don't know what the goal is."}, {"time": 3381, "text": "The goal should be to win majority, not five, zero, but how hard is it in general to win all matchups on a one V one?"}, {"time": 3391, "text": "So that's a very interesting question because once you see Alpha Star and superficially you think, well, okay, it won."}, {"time": 3400, "text": "Let's, if you sum all the games like 10 to one, right?"}, {"time": 3402, "text": "It lost the game that it played with the camera interface."}, {"time": 3406, "text": "You might think, well, that's done, right?"}, {"time": 3408, "text": "It's superhuman at the game."}, {"time": 3410, "text": "And that's not really the claim we really can make actually."}, {"time": 3415, "text": "The claim is we beat a professional gamer for the first time."}, {"time": 3420, "text": "StarCraft has really been a thing that has been going on for a few years, but a moment like this had not occurred before yet."}, {"time": 3429, "text": "But are these agents impossible to beat?"}, {"time": 3432, "text": "Absolutely not, right?"}, {"time": 3433, "text": "So that's a bit what's kind of the difference is the agents play at grandmaster level."}, {"time": 3439, "text": "They definitely understand the game enough to play extremely well, but are they unbeatable?"}, {"time": 3444, "text": "Do they play perfect?"}, {"time": 3446, "text": "No, and actually in StarCraft, because of these sneaky strategies, it's always possible that you might take a huge risk sometimes, but you might get wins, right?"}, {"time": 3456, "text": "Out of this."}, {"time": 3458, "text": "So I think that as a domain, it still has a lot of opportunities, not only because of course we wanna learn with less experience, we would like to, I mean, if I learned to play Protoss, I can play Terran and learn it much quicker than Alpha Star can, right?"}, {"time": 3473, "text": "So there are obvious interesting research challenges as well, but even as the raw performance goes, really the claim here can be we are at pro level or at high grandmaster level, but obviously the players also did not know what to expect, right?"}, {"time": 3494, "text": "Their prior distribution was a bit off because they played this kind of new like alien brain as they like to say it, right?"}, {"time": 3501, "text": "And that's what makes it exciting for them."}, {"time": 3504, "text": "But also I think if you look at the games closely, you see there were weaknesses in some points, maybe Alpha Star did not scout, or if it had invisible units going against at certain points, it wouldn't have known and it would have been bad."}, {"time": 3518, "text": "So there's still quite a lot of work to do, but it's really a very exciting moment for us to be seeing, wow, a single neural net on a GPU is actually playing against these guys who are amazing."}, {"time": 3531, "text": "I mean, you have to see them play in life."}, {"time": 3532, "text": "They're really, really amazing players."}, {"time": 3535, "text": "Yeah, I'm sure there must be a guy in Poland somewhere right now training his butt off to make sure that this never happens again with Alpha Star."}, {"time": 3545, "text": "So that's really exciting in terms of Alpha Star having some holes to exploit, which is great."}, {"time": 3551, "text": "And then we build on top of each other and it feels like StarCraft on let go, even if you win, it's still not, there's so many different dimensions in which you can explore."}, {"time": 3564, "text": "So that's really, really interesting."}, {"time": 3565, "text": "Do you think there's a ceiling to Alpha Star?"}, {"time": 3568, "text": "You've said that it hasn't reached, you know, this is a big, wait, let me actually just pause for a second."}, {"time": 3575, "text": "How did it feel to come here to this point, to beat a top professional player?"}, {"time": 3582, "text": "Like that night, I mean, you know, Olympic athletes have their gold medal, right?"}, {"time": 3587, "text": "This is your gold medal in a sense."}, {"time": 3588, "text": "Sure, you're cited a lot, you've published a lot of prestigious papers, whatever, but this is like a win."}, {"time": 3595, "text": "How did it feel?"}, {"time": 3596, "text": "I mean, it was, for me, it was unbelievable because first the win itself, I mean, it was so exciting."}, {"time": 3605, "text": "I mean, so looking back to those last days of 2018 really, that's when the games were played."}, {"time": 3613, "text": "I'm sure I look back at that moment, I'll say, oh my God, I want to be in a project like that."}, {"time": 3618, "text": "It's like, I already feel the nostalgia of like, yeah, that was huge in terms of the energy and the team effort that went into it."}, {"time": 3626, "text": "And so in that sense, as soon as it happened, I already knew it was kind of, I was losing it a little bit."}, {"time": 3633, "text": "So it is almost like sad that it happened and oh my God, but on the other hand, it also verifies the approach."}, {"time": 3641, "text": "But to me also, there's so many challenges and interesting aspects of intelligence that even though we can train a neural network to play at the level of the best humans, there's still so many challenges."}, {"time": 3654, "text": "So for me, it's also like, well, this is really an amazing achievement, but I already was also thinking about next steps."}, {"time": 3659, "text": "I mean, as I said, these Asians play Protoss versus Protoss, but they should be able to play a different race much quicker, right?"}, {"time": 3668, "text": "So that would be an amazing achievement."}, {"time": 3670, "text": "Some people call this meta reinforcement learning, meta learning and so on, right?"}, {"time": 3675, "text": "So there's so many possibilities after that moment, but the moment itself, it really felt great."}, {"time": 3683, "text": "We had this bet, so I'm kind of a pessimist in general."}, {"time": 3687, "text": "So I kind of send an email to the team."}, {"time": 3689, "text": "I said, okay, let's against TLO first, right?"}, {"time": 3693, "text": "Like what's gonna be the result?"}, {"time": 3695, "text": "And I really thought we would lose like five zero, right?"}, {"time": 3698, "text": "We had some calibration made against the 5,000 MMR player."}, {"time": 3704, "text": "TLO was much stronger than that player, even if he played Protoss, which is his off race."}, {"time": 3711, "text": "But yeah, I was not imagining we would win."}, {"time": 3713, "text": "So for me, that was just kind of a test run or something."}, {"time": 3715, "text": "And then it really kind of, he was really surprised."}, {"time": 3719, "text": "And unbelievably, we went to this bar to celebrate and Dave tells me, well, why don't we invite someone who is a thousand MMR stronger in Protoss, like actual Protoss player, like that it turned up being Mana, right?"}, {"time": 3736, "text": "And we had some drinks and I said, sure, why not?"}, {"time": 3739, "text": "But then I thought, well, that's really gonna be impossible to beat."}, {"time": 3742, "text": "I mean, even because it's so much ahead, a thousand MMR is really like 99% probability that Mana would beat TLO as Protoss versus Protoss, right?"}, {"time": 3753, "text": "So we did that."}, {"time": 3754, "text": "And to me, the second game was much more important, even though a lot of uncertainty kind of disappeared after we kind of beat TLO."}, {"time": 3763, "text": "I mean, he is a professional player."}, {"time": 3765, "text": "So that was kind of, oh, but that's really a very nice achievement."}, {"time": 3769, "text": "But Mana really was at the top and you could see he played much better, but our agents got much better too."}, {"time": 3775, "text": "So it's like, ah, and then after the first game, I said, if we take a single game, at least we can say we beat a game."}, {"time": 3782, "text": "I mean, even if we don't beat the series, for me, that was a huge relief."}, {"time": 3786, "text": "And I mean, I remember the hugging demis."}, {"time": 3789, "text": "And I mean, it was really like, this moment for me will resonate forever as a researcher."}, {"time": 3794, "text": "And I mean, as a person, and yeah, it's a really like great accomplishment."}, {"time": 3798, "text": "And it was great also to be there with the team in the room."}, {"time": 3801, "text": "I don't know if you saw like this."}, {"time": 3803, "text": "So it was really like."}, {"time": 3804, "text": "I mean, from my perspective, the other interesting thing is just like watching Kasparov, watching Mana was also interesting because he didn't, he has kind of a loss of words."}, {"time": 3816, "text": "I mean, whenever you lose, I've done a lot of sports."}, {"time": 3818, "text": "You sometimes say excuses, you look for reasons."}, {"time": 3823, "text": "And he couldn't really come up with reasons."}, {"time": 3826, "text": "I mean, so with the off race for Protoss, you could say, well, it felt awkward, it wasn't, but here it was just beaten."}, {"time": 3835, "text": "And it was beautiful to look at a human being being superseded by an AI system."}, {"time": 3840, "text": "I mean, it's a beautiful moment for researchers, so."}, {"time": 3844, "text": "Yeah, for sure it was."}, {"time": 3845, "text": "I mean, probably the highlight of my career so far because of its uniqueness and coolness."}, {"time": 3851, "text": "And I don't know, I mean, it's obviously, as you said, you can look at papers, citations and so on, but these really is like a testament of the whole machine learning approach and using games to advance technology."}, {"time": 3864, "text": "I mean, it really was, everything came together at that moment."}, {"time": 3868, "text": "That's really the summary."}, {"time": 3869, "text": "Also on the other side, it's a popularization of AI too, because it's just like traveling to the moon and so on."}, {"time": 3878, "text": "I mean, this is where a very large community of people that don't really know AI, they get to really interact with it."}, {"time": 3885, "text": "Which is very important."}, {"time": 3886, "text": "I mean, we must, you know, writing papers helps our peers, researchers, to understand what we're doing."}, {"time": 3892, "text": "But I think AI is becoming mature enough that we must sort of try to explain what it is."}, {"time": 3899, "text": "And perhaps through games is an obvious way because these games always had built in AI."}, {"time": 3903, "text": "So it may be everyone experience an AI playing a video game, even if they don't know, because there's always some scripted element and some people might even call that AI already, right?"}, {"time": 3913, "text": "So what are other applications of the approaches underlying AlphaStar that you see happening?"}, {"time": 3920, "text": "There's a lot of echoes of, you said, transformer of language modeling and so on."}, {"time": 3925, "text": "Have you already started thinking where the breakthroughs in AlphaStar get expanded to other applications?"}, {"time": 3932, "text": "Right, so I thought about a few things for like kind of next month, next years."}, {"time": 3938, "text": "The main thing I'm thinking about actually is what's next as a kind of a grand challenge."}, {"time": 3943, "text": "Because for me, like we've seen Atari and then there's like the sort of three dimensional walls that we've seen also like pretty good performance from these capture the flag agents that also some people at DeepMind and elsewhere are working on."}, {"time": 3957, "text": "We've also seen some amazing results on like, for instance, Dota 2, which is also a very complicated game."}, {"time": 3963, "text": "So for me, like the main thing I'm thinking about is what's next in terms of challenge."}, {"time": 3967, "text": "So as a researcher, I see sort of two tensions between research and then applications or areas or domains where you apply them."}, {"time": 3978, "text": "So on the one hand, we've done, thanks to the application of StarCraft is very hard."}, {"time": 3983, "text": "We developed some techniques, some new research that now we could look at elsewhere."}, {"time": 3987, "text": "Like are there other applications where we can apply these?"}, {"time": 3990, "text": "And the obvious ones, absolutely."}, {"time": 3992, "text": "You can think of feeding back to sort of the community we took from, which was mostly sequence modeling or natural language processing."}, {"time": 4001, "text": "So we've developed and extended things from the transformer and we use pointer networks."}, {"time": 4008, "text": "We combine LSTM and transformers in interesting ways."}, {"time": 4011, "text": "So that's perhaps the kind of lowest hanging fruit of feeding back to now a different field of machine learning that's not playing video games."}, {"time": 4020, "text": "Let me go old school and jump to Mr. Alan Turing."}, {"time": 4025, "text": "So the Turing test is a natural language test, a conversational test."}, {"time": 4031, "text": "What's your thought of it as a test for intelligence?"}, {"time": 4035, "text": "Do you think it is a grand challenge that's worthy of undertaking?"}, {"time": 4038, "text": "Maybe if it is, would you reformulate it or phrase it somehow differently?"}, {"time": 4043, "text": "Right, so I really love the Turing test because I also like sequences and language understanding."}, {"time": 4049, "text": "And in fact, some of the early work we did in machine translation, we tried to apply to kind of a neural chatbot, which obviously would never pass the Turing test because it was very limited."}, {"time": 4062, "text": "But it is a very fascinating idea that you could really have an AI that would be indistinguishable from humans in terms of asking or conversing with it."}, {"time": 4076, "text": "So I think the test itself seems very nice."}, {"time": 4080, "text": "And it's kind of well defined, actually, like the passing it or not."}, {"time": 4084, "text": "I think there's quite a few rules that feel pretty simple."}, {"time": 4089, "text": "And I think they have these competitions every year."}, {"time": 4094, "text": "Yes, there's the Lebner Prize."}, {"time": 4095, "text": "But I don't know if you've seen the kind of bots that emerge from that competition."}, {"time": 4104, "text": "They're not quite as what you would."}, {"time": 4107, "text": "So it feels like that there's weaknesses with the way Turing formulated it."}, {"time": 4111, "text": "It needs to be that the definition of a genuine, rich, fulfilling human conversation, it needs to be something else."}, {"time": 4121, "text": "Like the Alexa Prize, which I'm not as well familiar with, has tried to define that more, I think, by saying you have to continue keeping a conversation for 30 minutes, something like that."}, {"time": 4132, "text": "So basically forcing the agent not to just fool, but to have an engaging conversation kind of thing."}, {"time": 4142, "text": "Have you thought about this problem richly?"}, {"time": 4146, "text": "And if you have in general, how far away are we from?"}, {"time": 4150, "text": "You worked a lot on language understanding, language generation, but the full dialogue, the conversation, just sitting at the bar having a couple of beers for an hour, that kind of conversation."}, {"time": 4162, "text": "Have you thought about it?"}, {"time": 4163, "text": "Yeah, so I think you touched here on the critical point, which is feasibility."}, {"time": 4168, "text": "So there's a great essay by Hamming, which describes sort of grand challenges of physics."}, {"time": 4177, "text": "And he argues that, well, OK, for instance, teleportation or time travel are great grand challenges of physics, but there's no attacks."}, {"time": 4186, "text": "We really don't know or cannot kind of make any progress."}, {"time": 4190, "text": "So that's why most physicists and so on, they don't work on these in their PhDs and as part of their careers."}, {"time": 4197, "text": "So I see the Turing test, in the full Turing test, as a bit still too early."}, {"time": 4202, "text": "Like I think we're, especially with the current trend of deep learning language models, we've seen some amazing examples."}, {"time": 4211, "text": "I think GPT2 being the most recent one, which is very impressive."}, {"time": 4215, "text": "But to understand to fully solve passing or fooling a human to think that there's a human on the other side, I think we're quite far."}, {"time": 4224, "text": "So as a result, I don't see myself and I probably would not recommend people doing a PhD on solving the Turing test because it just feels it's kind of too early or too hard of a problem."}, {"time": 4235, "text": "Yeah, but that said, you said the exact same thing about StarCraft about a few years ago."}, {"time": 4241, "text": "To Demis."}, {"time": 4241, "text": "So you'll probably also be the person who passes the Turing test in three years."}, {"time": 4248, "text": "I mean, I think that, yeah."}, {"time": 4250, "text": "So we have this on record."}, {"time": 4252, "text": "This is nice."}, {"time": 4253, "text": "I mean, it's true that progress sometimes is a bit unpredictable."}, {"time": 4257, "text": "I really wouldn't have not."}, {"time": 4259, "text": "Even six months ago, I would not have predicted the level that we see that these agents can deliver at grandmaster level."}, {"time": 4267, "text": "But I have worked on language enough."}, {"time": 4270, "text": "And basically, my concern is not that something could happen, a breakthrough could happen that would bring us to solving or passing the Turing test, is that I just think the statistical approach to it is not going to cut it."}, {"time": 4284, "text": "So we need a breakthrough, which is great for the community."}, {"time": 4288, "text": "But given that, I think there's quite more uncertainty."}, {"time": 4291, "text": "Whereas for StarCraft, I knew what the steps would be to get us there."}, {"time": 4298, "text": "I think it was clear that using the imitation learning part and then using this battle net for agents were going to be key."}, {"time": 4305, "text": "And it turned out that this was the case."}, {"time": 4308, "text": "And a little more was needed, but not much more."}, {"time": 4311, "text": "For Turing test, I just don't know what the plan or execution plan would look like."}, {"time": 4316, "text": "So that's why I myself working on it as a grand challenge is hard."}, {"time": 4321, "text": "But there are quite a few sub challenges that are related that you could say, well, I mean, what if you create a great assistant like Google already has, like the Google Assistant."}, {"time": 4331, "text": "So can we make it better?"}, {"time": 4333, "text": "And can we make it fully neural and so on?"}, {"time": 4335, "text": "That I start to believe maybe we're reaching a point where we should attempt these challenges."}, {"time": 4340, "text": "I like this conversation so much because it echoes very much the StarCraft conversation."}, {"time": 4344, "text": "It's exactly how you approach StarCraft."}, {"time": 4346, "text": "Let's break it down into small pieces and solve those."}, {"time": 4349, "text": "And you end up solving the whole game."}, {"time": 4351, "text": "But that said, you're behind some of the biggest pieces of work in deep learning in the last several years."}, {"time": 4360, "text": "So you mentioned some limits."}, {"time": 4362, "text": "What do you think of the current limits of deep learning?"}, {"time": 4364, "text": "And how do we overcome those limits?"}, {"time": 4367, "text": "So if I had to actually use a single word to define the main challenge in deep learning, it's a challenge that probably has been the challenge for many years."}, {"time": 4376, "text": "And it's that of generalization."}, {"time": 4379, "text": "So what that means is that all that we're doing is fitting functions to data."}, {"time": 4386, "text": "And when the data we see is not from the same distribution, or even if there are some times that it is very close to distribution, but because of the way we train it with limited samples, we then get to this stage where we just don't see generalization as much as we can generalize."}, {"time": 4407, "text": "And I think adversarial examples are a clear example of this."}, {"time": 4411, "text": "But if you study machine learning and literature, and the reason why SVMs came very popular were because they were dealing and they had some guarantees about generalization, which is unseen data or out of distribution, or even within distribution where you take an image adding a bit of noise, these models fail."}, {"time": 4431, "text": "So I think, really, I don't see a lot of progress on generalization in the strong generalization sense of the word."}, {"time": 4441, "text": "I think our neural networks, you can always find design examples that will make their outputs arbitrary, which is not good because we humans would never be fooled by these kind of images or manipulation of the image."}, {"time": 4459, "text": "And if you look at the mathematics, you kind of understand this is a bunch of matrices multiplied together."}, {"time": 4466, "text": "There's probably numerics and instability that you can just find corner cases."}, {"time": 4470, "text": "So I think that's really the underlying topic many times we see when even at the grand stage of Turing test generalization, if you start passing the Turing test, should it be in English or should it be in any language?"}, {"time": 4488, "text": "As a human, if you ask something in a different language, you actually will go and do some research and try to translate it and so on."}, {"time": 4497, "text": "Should the Turing test include that?"}, {"time": 4501, "text": "And it's really a difficult problem and very fascinating and very mysterious, actually."}, {"time": 4506, "text": "But do you think if you were to try to solve it, can you not grow the size of data intelligently in such a way that the distribution of your training set does include the entirety of the testing set?"}, {"time": 4520, "text": "Is that one path?"}, {"time": 4521, "text": "The other path is totally a new methodology."}, {"time": 4523, "text": "It's not statistical."}, {"time": 4524, "text": "So a path that has worked well, and it worked well in StarCraft and in machine translation and in languages, scaling up the data and the model."}, {"time": 4532, "text": "And that's kind of been maybe the only single formula that still delivers today in deep learning, right?"}, {"time": 4540, "text": "It's that data scale and model scale really do more and more of the things that we thought, oh, there's no way it can generalize to these, or there's no way it can generalize to that."}, {"time": 4551, "text": "But I don't think fundamentally it will be solved with this."}, {"time": 4554, "text": "And for instance, I'm really liking some style or approach that would not only have neural networks, but it would have programs or some discrete decision making, because there is where I feel there's a bit more."}, {"time": 4570, "text": "I mean, the best example, I think, for understanding this is I also worked a bit on, oh, we can learn an algorithm with a neural network, right?"}, {"time": 4578, "text": "So you give it many examples, and it's going to sort the input numbers or something like that."}, {"time": 4584, "text": "But really strong generalization is you give me some numbers or you ask me to create an algorithm that sorts numbers."}, {"time": 4592, "text": "And instead of creating a neural net, which will be fragile because it's going to go out of range at some point, you're going to give it numbers that are too large, too small, and whatnot, if you just create a piece of code that sorts the numbers, then you can prove that that will generalize to absolutely all the possible input you could give."}, {"time": 4611, "text": "So I think the problem comes with some exciting prospects."}, {"time": 4615, "text": "I mean, scale is a bit more boring, but it really works."}, {"time": 4619, "text": "And then maybe programs and discrete abstractions are a bit less developed."}, {"time": 4624, "text": "But clearly, I think they're quite exciting in terms of future for the field."}, {"time": 4629, "text": "Do you draw any insight wisdom from the 80s and expert systems and symbolic systems, symbolic computing?"}, {"time": 4636, "text": "Do you ever go back to those reasoning, that kind of logic?"}, {"time": 4640, "text": "Do you think that might make a comeback?"}, {"time": 4643, "text": "You'll have to dust off those books?"}, {"time": 4644, "text": "Yeah, I actually love actually adding more inductive biases."}, {"time": 4651, "text": "To me, the problem really is, what are you trying to solve?"}, {"time": 4654, "text": "If what you're trying to solve is so important that try to solve it no matter what, then absolutely use rules, use domain knowledge, and then use a bit of the magic of machine learning to empower to make the system as the best system that will detect cancer or detect weather patterns, right?"}, {"time": 4676, "text": "Or in terms of StarCraft, it also was a very big challenge."}, {"time": 4679, "text": "So I was definitely happy that if we had to cut a corner here and there, it could have been interesting to do."}, {"time": 4687, "text": "And in fact, in StarCraft, we start thinking about expert systems because it's a very, you know, you can define."}, {"time": 4692, "text": "I mean, people actually build StarCraft bots by thinking about those principles, like state machines and rule based."}, {"time": 4700, "text": "And then you could think of combining a bit of a rule based system, but that has also neural networks incorporated to make it generalize a bit better."}, {"time": 4709, "text": "So absolutely, I mean, we should definitely go back to those ideas."}, {"time": 4712, "text": "And anything that makes the problem simpler, as long as your problem is important, that's OK. And that's research driving a very important problem."}, {"time": 4721, "text": "And on the other hand, if you want to really focus on the limits of reinforcement learning, then of course, you must try not to look at imitation data or to look for some rules of the domain that would help a lot or even feature engineering, right?"}, {"time": 4736, "text": "So this is a tension that depending on what you do, I think both ways are definitely fine."}, {"time": 4743, "text": "And I would never not do one or the other as long as what you're doing is important and needs to be solved, right?"}, {"time": 4750, "text": "Right, so there's a bunch of different ideas that you developed that I really enjoy."}, {"time": 4756, "text": "But one is translating from image captioning, translating from image to text, just another beautiful idea, I think, that resonates throughout your work, actually."}, {"time": 4773, "text": "So the underlying nature of reality being language always, somehow."}, {"time": 4778, "text": "So what's the connection between images and text, or rather the visual world and the world of language in your view?"}, {"time": 4786, "text": "Right, so I think a piece of research that's been central to, I would say, even extending into StarGraph is this idea of sequence to sequence learning, which what we really meant by that is that you can now really input anything to a neural network as the input x."}, {"time": 4806, "text": "And then the neural network will learn a function f that will take x as an input and produce any output y."}, {"time": 4812, "text": "And these x and y's don't need to be static or features, like fixed vectors or anything like that."}, {"time": 4822, "text": "It could be really sequences and now beyond data structures."}, {"time": 4826, "text": "So that paradigm was tested in a very interesting way when we moved from translating French to English to translating an image to its caption."}, {"time": 4837, "text": "But the beauty of it is that, really, and that's actually how it happened."}, {"time": 4843, "text": "I changed a line of code in this thing that was doing machine translation."}, {"time": 4847, "text": "And I came the next day, and I saw how it was producing captions that seemed like, oh my god, this is really, really working."}, {"time": 4855, "text": "And the principle is the same."}, {"time": 4857, "text": "So I think I don't see text, vision, speech, waveforms as something different as long as you basically learn a function that will vectorize these into."}, {"time": 4874, "text": "And then after we vectorize it, we can then use transformers, LSTMs, whatever the flavor of the month of the model is."}, {"time": 4882, "text": "And then as long as we have enough supervised data, really, this formula will work and will keep working, I believe, to some extent."}, {"time": 4891, "text": "Modulo these generalization issues that I mentioned before."}, {"time": 4895, "text": "But the task there is to vectorize, so to form a representation that's meaningful."}, {"time": 4899, "text": "And your intuition now, having worked with all this media, is that once you are able to form that representation, you could basically take any things, any sequence."}, {"time": 4911, "text": "Going back to StarCraft, is there limits on the length so that we didn't really touch on the long term aspect?"}, {"time": 4919, "text": "How did you overcome the whole really long term aspect of things here?"}, {"time": 4923, "text": "Is there some tricks?"}, {"time": 4925, "text": "So the main trick, so StarCraft, if you look at absolutely every frame, you might think it's quite a long game."}, {"time": 4932, "text": "So we would have to multiply 22 times 60 seconds per minute times maybe at least 10 minutes per game on average."}, {"time": 4941, "text": "So there are quite a few frames."}, {"time": 4945, "text": "But the trick really was to only observe, in fact, which might be seen as a limitation, but it is also a computational advantage."}, {"time": 4955, "text": "Only observe when you act."}, {"time": 4957, "text": "And then what the neural network decides is what is the gap going to be until the next action."}, {"time": 4964, "text": "And if you look at most StarCraft games that we have in the data set that Blizzard provided, it turns out that most games are actually only, I mean, it is still a long sequence, but it's maybe like 1,000 to 1,500 actions, which if you start looking at LSTMs, large LSTMs, transformers, it's not that difficult, especially if you have supervised learning."}, {"time": 4994, "text": "If you had to do it with reinforcement learning, the credit assignment problem, what is it in this game that made you win?"}, {"time": 4999, "text": "That would be really difficult."}, {"time": 5001, "text": "But thankfully, because of imitation learning, we didn't have to deal with these directly."}, {"time": 5007, "text": "Although if we had to, we tried it."}, {"time": 5009, "text": "And what happened is you just take all your workers and attack with them."}, {"time": 5013, "text": "And that is kind of obvious in retrospect because you start trying random actions."}, {"time": 5018, "text": "One of the actions will be a worker that goes to the enemy base."}, {"time": 5021, "text": "And because it's self play, it's not going to know how to defend because it basically doesn't know almost anything."}, {"time": 5027, "text": "And eventually, what you develop is this take all workers and attack because the credit assignment issue in a rally is really, really hard."}, {"time": 5035, "text": "I do believe we could do better."}, {"time": 5037, "text": "And that's maybe a research challenge for the future."}, {"time": 5041, "text": "But yeah, even in StarCraft, the sequences are maybe 1,000, which I believe is within the realm of what transformers can do."}, {"time": 5050, "text": "Yeah, I guess the difference between StarCraft and Go is in Go and Chess, stuff starts happening right away."}, {"time": 5058, "text": "So there's not, yeah, it's pretty easy to self play."}, {"time": 5062, "text": "Not easy, but to self play, it's possible to develop reasonable strategies quickly as opposed to StarCraft."}, {"time": 5067, "text": "I mean, in Go, there's only 400 actions."}, {"time": 5070, "text": "But one action is what people would call the God action."}, {"time": 5074, "text": "That would be if you had expanded the whole search tree, that's the best action if you did minimax or whatever algorithm you would do if you had the computational capacity."}, {"time": 5084, "text": "But in StarCraft, 400 is minuscule."}, {"time": 5088, "text": "Like in 400, you couldn't even click on the pixels around a unit."}, {"time": 5093, "text": "So I think the problem there is in terms of action space size is way harder."}, {"time": 5101, "text": "And that search is impossible."}, {"time": 5103, "text": "So there's quite a few challenges indeed that make this kind of a step up in terms of machine learning."}, {"time": 5110, "text": "For humans, maybe playing StarCraft seems more intuitive because it looks real."}, {"time": 5116, "text": "I mean, the graphics and everything moves smoothly, whereas I don't know how to."}, {"time": 5120, "text": "I mean, Go is a game that I would really need to study."}, {"time": 5122, "text": "It feels quite complicated."}, {"time": 5123, "text": "But for machines, kind of maybe it's the reverse, yes."}, {"time": 5127, "text": "Which shows you the gap actually between deep learning and however the heck our brains work."}, {"time": 5134, "text": "So you developed a lot of really interesting ideas."}, {"time": 5136, "text": "It's interesting to just ask, what's your process of developing new ideas?"}, {"time": 5141, "text": "Do you like brainstorming with others?"}, {"time": 5142, "text": "Do you like thinking alone?"}, {"time": 5144, "text": "Do you like, what was it, Ian Goodfellow said he came up with GANs after a few beers."}, {"time": 5152, "text": "He thinks beers are essential for coming up with new ideas."}, {"time": 5155, "text": "We had beers to decide to play another game of StarCraft after a week."}, {"time": 5159, "text": "So it's really similar to that story."}, {"time": 5162, "text": "Actually, I explained this in a DeepMind retreat."}, {"time": 5165, "text": "And I said, this is the same as the GAN story."}, {"time": 5168, "text": "I mean, we were in a bar."}, {"time": 5169, "text": "And we decided, let's play a GAN next week."}, {"time": 5170, "text": "And that's what happened."}, {"time": 5171, "text": "I feel like we're giving the wrong message to young undergrads."}, {"time": 5175, "text": "Yeah, I know."}, {"time": 5175, "text": "But in general, do you like brainstorming?"}, {"time": 5178, "text": "Do you like thinking alone, working stuff out?"}, {"time": 5180, "text": "So I think throughout the years, also, things changed."}, {"time": 5183, "text": "So initially, I was very fortunate to be with great minds like Jeff Hinton, Jeff Dean, Ilya Sutskever."}, {"time": 5194, "text": "I was really fortunate to join Brain at a very good time."}, {"time": 5197, "text": "So at that point, ideas, I was just brainstorming with my colleagues and learned a lot."}, {"time": 5204, "text": "And keep learning is actually something you should never stop doing."}, {"time": 5208, "text": "So learning implies reading papers and also discussing ideas with others."}, {"time": 5213, "text": "It's very hard at some point to not communicate that being reading a paper from someone or actually discussing."}, {"time": 5220, "text": "So definitely, that communication aspect needs to be there, whether it's written or oral."}, {"time": 5228, "text": "Nowadays, I'm also trying to be a bit more strategic about what research to do."}, {"time": 5235, "text": "So I was describing a little bit this tension between research for the sake of research, and then you have, on the other hand, applications that can drive the research."}, {"time": 5245, "text": "And honestly, the formula that has worked best for me is just find a hard problem and then try to see how research fits into it, how it doesn't fit into it, and then you must innovate."}, {"time": 5257, "text": "So I think machine translation drove sequence to sequence."}, {"time": 5263, "text": "Then maybe learning algorithms that had to, combinatorial algorithms led to pointer networks."}, {"time": 5270, "text": "StarCraft led to really scaling up imitation learning and the AlphaStarLeague."}, {"time": 5275, "text": "So that's been a formula that I personally like."}, {"time": 5278, "text": "But the other one is also valid."}, {"time": 5280, "text": "And I've seen it succeed a lot of the times where you just want to investigate model based RL as a research topic."}, {"time": 5288, "text": "And then you must then start to think, well, how are the tests?"}, {"time": 5292, "text": "How are you going to test these ideas?"}, {"time": 5294, "text": "You need a minimal environment to try things."}, {"time": 5297, "text": "You need to read a lot of papers and so on."}, {"time": 5299, "text": "And that's also very fun to do and something I've also done quite a few times, both at Brain, at DeepMind, and obviously as a PhD."}, {"time": 5308, "text": "So I think besides the ideas and discussions, I think it's important also because you start sort of guiding not only your own goals, but other people's goals to the next breakthrough."}, {"time": 5324, "text": "So you must really kind of understand this feasibility also, as we were discussing before, whether this domain is ready to be tackled or not."}, {"time": 5333, "text": "And you don't want to be too early."}, {"time": 5335, "text": "You obviously don't want to be too late."}, {"time": 5337, "text": "So it's really interesting, this strategic component of research, which I think as a grad student, I just had no idea."}, {"time": 5345, "text": "I just read papers and discussed ideas."}, {"time": 5347, "text": "And I think this has been maybe the major change."}, {"time": 5349, "text": "And I recommend people kind of feed forward to success how it looks like and try to backtrack, other than just kind of looking, oh, this looks cool."}, {"time": 5358, "text": "This looks cool."}, {"time": 5359, "text": "And then you do a bit of random work, which sometimes you stumble upon some interesting things."}, {"time": 5363, "text": "But in general, it's also good to plan a bit."}, {"time": 5367, "text": "Yeah, I like it."}, {"time": 5368, "text": "Especially like your approach of taking a really hard problem, stepping right in, and then being super skeptical about being able to solve the problem."}, {"time": 5377, "text": "I mean, there's a balance of both, right?"}, {"time": 5380, "text": "There's a silly optimism and a critical sort of skepticism that's good to balance, which is why it's good to have a team of people that balance that."}, {"time": 5392, "text": "You don't do that on your own."}, {"time": 5393, "text": "You have both mentors that have seen, or you obviously want to chat and discuss whether it's the right time."}, {"time": 5400, "text": "I mean, Demis came in 2014."}, {"time": 5403, "text": "And he said, maybe in a bit we'll do StarCraft."}, {"time": 5406, "text": "And maybe he knew."}, {"time": 5408, "text": "And I'm just following his lead, which is great, because he's brilliant, right?"}, {"time": 5412, "text": "So these things are obviously quite important, that you want to be surrounded by people who are diverse."}, {"time": 5422, "text": "They have their knowledge."}, {"time": 5423, "text": "There's also important to, I mean, I've learned a lot from people who actually have an idea that I might not think it's good."}, {"time": 5432, "text": "But if I give them the space to try it, I've been proven wrong many, many times as well."}, {"time": 5437, "text": "So that's great."}, {"time": 5438, "text": "I think your colleagues are more important than yourself, I think."}, {"time": 5444, "text": "Now let's real quick talk about another impossible problem, AGI."}, {"time": 5450, "text": "What do you think it takes to build a system that's human level intelligence?"}, {"time": 5454, "text": "We talked a little bit about the Turing test, StarCraft."}, {"time": 5456, "text": "All of these have echoes of general intelligence."}, {"time": 5458, "text": "But if you think about just something that you would sit back and say, wow, this is really something that resembles human level intelligence."}, {"time": 5467, "text": "What do you think it takes to build that?"}, {"time": 5469, "text": "So I find that AGI oftentimes is maybe not very well defined."}, {"time": 5477, "text": "So what I'm trying to then come up with for myself is what would be a result look like that you would start to believe that you would have agents or neural nets that no longer overfeed to a single task, but actually learn the skill of learning, so to speak."}, {"time": 5497, "text": "And that actually is a field that I am fascinated by, which is the learning to learn, or meta learning, which is about no longer learning about a single domain."}, {"time": 5508, "text": "So you can think about the learning algorithm itself is general."}, {"time": 5512, "text": "So the same formula we applied for AlphaStar or StarCraft, we can now apply to almost any video game, or you could apply to many other problems and domains."}, {"time": 5523, "text": "But the algorithm is what's generalizing."}, {"time": 5527, "text": "But the neural network, those weights are useless even to play another race."}, {"time": 5532, "text": "I train a network to play very well at Protos versus Protos."}, {"time": 5535, "text": "I need to throw away those weights."}, {"time": 5537, "text": "If I want to play now Terran versus Terran, I would need to retrain a network from scratch with the same algorithm."}, {"time": 5546, "text": "But the network itself will not be useful."}, {"time": 5548, "text": "So I think if I see an approach that can absorb or start solving new problems without the need to kind of restart the process, I think that, to me, would be a nice way to define some form of AGI."}, {"time": 5565, "text": "Again, I don't know the grandiose like age."}, {"time": 5568, "text": "I mean, should Turing tests be solved before AGI?"}, {"time": 5570, "text": "I mean, I don't know."}, {"time": 5571, "text": "I think concretely, I would like to see clearly that meta learning happen, meaning that there is an architecture or a network that as it sees new problem or new data, it solves it."}, {"time": 5584, "text": "And to make it kind of a benchmark, it should solve it at the same speed that we do solve new problems."}, {"time": 5591, "text": "When I define you a new object and you have to recognize it, when you start playing a new game, you played all the Atari games."}, {"time": 5597, "text": "But now you play a new Atari game."}, {"time": 5599, "text": "Well, you're going to be pretty quickly pretty good at the game."}, {"time": 5602, "text": "So that's perhaps what's the domain and what's the exact benchmark is a bit difficult."}, {"time": 5608, "text": "I think as a community, we might need to do some work to define it."}, {"time": 5612, "text": "But I think this first step, I could see it happen relatively soon."}, {"time": 5616, "text": "But then the whole what AGI means and so on, I am a bit more confused about what I think people mean different things."}, {"time": 5624, "text": "There's an emotional, psychological level that like even the Turing test, passing the Turing test is something that we just pass judgment on as human beings what it means to be as a dog in AGI system."}, {"time": 5644, "text": "What level, what does it mean, what does it mean?"}, {"time": 5647, "text": "But I like the generalization."}, {"time": 5648, "text": "And maybe as a community, we converge towards a group of domains that are sufficiently far away."}, {"time": 5654, "text": "That would be really damn impressive if it was able to generalize."}, {"time": 5658, "text": "So perhaps not as close as Protoss and Zerg, but like Wikipedia."}, {"time": 5662, "text": "That would be a step."}, {"time": 5663, "text": "Yeah, that would be a good step and then a really good step."}, {"time": 5666, "text": "But then like from StarCraft to Wikipedia and back."}, {"time": 5670, "text": "Yeah, that kind of thing."}, {"time": 5671, "text": "And that feels also quite hard and far."}, {"time": 5674, "text": "But I think as long as you put the benchmark out, as we discovered, for instance, with ImageNet, then tremendous progress can be had."}, {"time": 5683, "text": "So I think maybe there's a lack of benchmark, but I'm sure we'll find one and the community will then work towards that."}, {"time": 5692, "text": "And then beyond what AGI might mean or would imply, I really am hopeful to see basically machine learning or AI just scaling up and helping people that might not have the resources to hire an assistant or that they might not even know what the weather is like."}, {"time": 5713, "text": "So I think in terms of the positive impact of AI, I think that's maybe what we should also not lose focus."}, {"time": 5722, "text": "The research community building AGI, I mean, that's a real nice goal."}, {"time": 5725, "text": "But I think the way that DeepMind puts it is, and then use it to solve everything else."}, {"time": 5730, "text": "So I think we should paralyze."}, {"time": 5733, "text": "Yeah, we shouldn't forget about all the positive things that are actually coming out of AI already and are going to be coming out."}, {"time": 5741, "text": "But on that note, let me ask relative to popular perception, do you have any worry about the existential threat of artificial intelligence in the near or far future that some people have?"}, {"time": 5755, "text": "I think in the near future, I'm skeptical."}, {"time": 5758, "text": "So I hope I'm not wrong."}, {"time": 5759, "text": "But I'm not concerned, but I appreciate efforts, ongoing efforts, and even like whole research field on AI safety emerging and in conferences and so on."}, {"time": 5770, "text": "I think that's great."}, {"time": 5772, "text": "In the long term, I really hope we just can simply have the benefits outweigh the potential dangers."}, {"time": 5780, "text": "I am hopeful for that."}, {"time": 5783, "text": "But also, we must remain vigilant to monitor and assess whether the tradeoffs are there and we have enough also lead time to prevent or to redirect our efforts if need be."}, {"time": 5797, "text": "But I'm quite optimistic about the technology and definitely more fearful of other threats in terms of planetary level at this point."}, {"time": 5808, "text": "But obviously, that's the one I have more power on."}, {"time": 5812, "text": "So clearly, I do start thinking more and more about this."}, {"time": 5816, "text": "And it's grown in me actually to start reading more about AI safety, which is a field that so far I have not really contributed to."}, {"time": 5825, "text": "But maybe there's something to be done there as well."}, {"time": 5827, "text": "I think it's really important."}, {"time": 5829, "text": "I talk about this with a few folks."}, {"time": 5831, "text": "But it's important to ask you and shove it in your head because you're at the leading edge of actually what people are excited about in AI."}, {"time": 5839, "text": "The work with AlphaStar, it's arguably at the very cutting edge of the kind of thing that people are afraid of."}, {"time": 5847, "text": "And so you speaking to that fact and that we're actually quite far away to the kind of thing that people might be afraid of."}, {"time": 5855, "text": "But it's still worthwhile to think about."}, {"time": 5858, "text": "And it's also good that you're not as worried and you're also open to thinking about it."}, {"time": 5865, "text": "There's two aspects."}, {"time": 5866, "text": "I mean, me not being worried."}, {"time": 5867, "text": "But obviously, we should prepare for things that could go wrong, misuse of the technologies as with any technologies."}, {"time": 5878, "text": "So I think there's always trade offs."}, {"time": 5882, "text": "And as a society, we've kind of solved this to some extent in the past."}, {"time": 5887, "text": "So I'm hoping that by having the researchers and the whole community brainstorm and come up with interesting solutions to the new things that will happen in the future, that we can still also push the research to the avenue that I think is kind of the greatest avenue, which is to understand intelligence."}, {"time": 5907, "text": "How are we doing what we're doing?"}, {"time": 5909, "text": "And obviously, from a scientific standpoint, that is kind of my personal drive of all the time that I spend doing what I'm doing, really."}, {"time": 5920, "text": "Where do you see the deep learning as a field heading?"}, {"time": 5922, "text": "Where do you think the next big breakthrough might be?"}, {"time": 5926, "text": "So I think deep learning, I discussed a little of this before."}, {"time": 5930, "text": "Deep learning has to be combined with some form of discretization, program synthesis."}, {"time": 5936, "text": "I think that's kind of as a research in itself is an interesting topic to expand and start doing more research."}, {"time": 5944, "text": "And then as kind of what will deep learning enable to do in the future?"}, {"time": 5948, "text": "I don't think that's going to be what's going to happen this year."}, {"time": 5951, "text": "But also this idea of starting not to throw away all the weights, that this idea of learning to learn and really having these agents not having to restart their weights."}, {"time": 5964, "text": "And you can have an agent that is kind of solving or classifying images on ImageNet, but also generating speech if you ask it to generate some speech."}, {"time": 5974, "text": "And it should really be kind of almost the same network, but it might not be a neural network."}, {"time": 5981, "text": "It might be a neural network with an optimization algorithm attached to it."}, {"time": 5985, "text": "But I think this idea of generalization to new task is something that we first must define good benchmarks."}, {"time": 5992, "text": "But then I think that's going to be exciting."}, {"time": 5994, "text": "And I'm not sure how close we are."}, {"time": 5996, "text": "But I think if you have a very limited domain, I think we can start doing some progress."}, {"time": 6002, "text": "And much like how we did a lot of programs in computer vision, we should start thinking."}, {"time": 6009, "text": "I really like a talk that Leon Buto gave at ICML a few years ago, which is this train test paradigm should be broken."}, {"time": 6017, "text": "We should stop thinking about a training set and a test set."}, {"time": 6023, "text": "And these are closed things that are untouchable."}, {"time": 6026, "text": "I think we should go beyond these."}, {"time": 6028, "text": "And in meta learning, we call these the meta training set and the meta test set, which is really thinking about, if I know about ImageNet, why would that network not work on MNIST, which is a much simpler problem?"}, {"time": 6041, "text": "But right now, it really doesn't."}, {"time": 6044, "text": "But it just feels wrong."}]}, {"title": "Michael Stevens: Vsauce | Lex Fridman Podcast #58", "id": "3qMemn__kK8", "quotes": [{"time": 355, "text": "When you say those states, the ones that contain memories of its past or ones that contain memories of its past and have degrees of consciousness."}, {"time": 365, "text": "Just the first part, because I think the consciousness then emerges from the fact that a state of the universe that contains fragments or memories of other states is one where you're going to feel like there's time."}, {"time": 382, "text": "You're going to feel like, yeah, things happened in the past."}, {"time": 386, "text": "And I don't know what'll happen in the future because these states don't contain information about the future."}, {"time": 390, "text": "For some reason, those kinds of states are either more common, more plentiful, or you could use the anthropic principle and just say, well, they're extremely rare, but until you are in one, or if you are in one, then you can ask questions, like you're asking me on this podcast."}, {"time": 409, "text": "Why questions?"}, {"time": 410, "text": "Yeah, it's like, why are we conscious?"}, {"time": 412, "text": "Well, because if we weren't, we wouldn't be asking why we were."}, {"time": 416, "text": "You've kind of implied that you have a sense, again, hypothesis, theorizing that the universe is deterministic."}, {"time": 425, "text": "What's your thoughts about free will?"}, {"time": 428, "text": "Do you think of the universe as deterministic in a sense that it's unrolling a particular, like there's a, it's operating under a specific set of physical laws."}, {"time": 437, "text": "And when you have to set the initial conditions, it will unroll in the exact same way in our particular line of the universe every time."}, {"time": 448, "text": "That is a very useful way to think about the universe."}, {"time": 451, "text": "It's done us well."}, {"time": 452, "text": "It's brought us to the moon."}, {"time": 453, "text": "It's brought us to where we are today, right?"}, {"time": 455, "text": "I would not say that I believe in determinism in that kind of an absolute form, or actually I just don't care."}, {"time": 465, "text": "Maybe it's true, but I'm not gonna live my life like it is."}, {"time": 469, "text": "What in your sense, cause you've studied kind of how we humans think of the world."}, {"time": 475, "text": "What's in your view is the difference between our perception, like how we think the world is and reality."}, {"time": 482, "text": "Do you think there's a huge gap there?"}, {"time": 484, "text": "Like we delude ourselves that the whole thing is an illusion."}, {"time": 487, "text": "Just everything about human psychology, the way we see things and how things actually are."}, {"time": 492, "text": "All the things you've studied, what's your sense?"}, {"time": 494, "text": "How big is the gap between reality and perception?"}, {"time": 496, "text": "Well, again, purely speculative."}, {"time": 498, "text": "I think that we will never know the answer."}, {"time": 500, "text": "We cannot know the answer."}, {"time": 502, "text": "There is no experiment to find an answer to that question."}, {"time": 506, "text": "Everything we experience is an event in our brain."}, {"time": 510, "text": "When I look at a cat, I'm not even, I can't prove that there's a cat there."}, {"time": 516, "text": "All I am experiencing is the perception of a cat inside my own brain."}, {"time": 523, "text": "I am only a witness to the events of my mind."}, {"time": 526, "text": "I think it is very useful to infer that if I witness the event of cat in my head, it's because I'm looking at a cat that is literally there and it has its own feelings and motivations and should be pet and given food and water and love."}, {"time": 543, "text": "I think that's the way you should live your life."}, {"time": 545, "text": "But whether or not we live in a simulation, I'm a brain in a vat, I don't know."}, {"time": 553, "text": "Do you care?"}, {"time": 554, "text": "I don't really."}, {"time": 556, "text": "Well, I care because it's a fascinating question."}, {"time": 559, "text": "And it's a fantastic way to get people excited about all kinds of topics, physics, psychology, consciousness, philosophy."}, {"time": 568, "text": "But at the end of the day, what would the difference be?"}, {"time": 571, "text": "If you..."}, {"time": 571, "text": "The cat needs to be fed at the end of the day, otherwise it'll be a dead cat."}, {"time": 575, "text": "Right, but if it's not even a real cat, then it's just like a video game cat."}, {"time": 580, "text": "And right, so what's the difference between killing a digital cat in a video game because of neglect versus a real cat?"}, {"time": 588, "text": "It seems very different to us psychologically."}, {"time": 590, "text": "Like I don't really feel bad about, oh my gosh, I forgot to feed my Tamagotchi, right?"}, {"time": 594, "text": "But I would feel terrible if I forgot to feed my actual cats."}, {"time": 598, "text": "So can you just touch on the topic of simulation?"}, {"time": 603, "text": "Do you find this thought experiment that we're living in a simulation useful, inspiring or constructive in any kind of way?"}, {"time": 611, "text": "Do you think it's ridiculous?"}, {"time": 612, "text": "Do you think it could be true?"}, {"time": 614, "text": "Or is it just a useful thought experiment?"}, {"time": 617, "text": "I think it is extremely useful as a thought experiment because it makes sense to everyone, especially as we see virtual reality and computer games getting more and more complex."}, {"time": 630, "text": "You're not talking to an audience in like Newton's time where you're like, imagine a clock that it has mechanics in it that are so complex that it can create love."}, {"time": 640, "text": "And everyone's like, no."}, {"time": 642, "text": "But today you really start to feel, man, at what point is this little robot friend of mine gonna be like someone I don't want to cancel plans with?"}, {"time": 653, "text": "And so it's a great, the thought experiment of do we live in a simulation?"}, {"time": 660, "text": "Am I a brain in a vat that is just being given electrical impulses from some nefarious other beings so that I believe that I live on earth and that I have a body and all of this?"}, {"time": 673, "text": "And the fact that you can't prove it either way is a fantastic way to introduce people to some of the deepest questions."}, {"time": 680, "text": "So you mentioned a little buddy that you would want to cancel an appointment with."}, {"time": 685, "text": "So that's a lot of our conversations."}, {"time": 687, "text": "That's what my research is, is artificial intelligence."}, {"time": 692, "text": "And I apologize, but you're such a fun person to ask these big questions with."}, {"time": 696, "text": "Well, I hope I can give some answers that are interesting."}, {"time": 700, "text": "Well, because of you've sharpened your brain's ability to explore some of the most, some of the questions that many scientists are actually afraid of even touching, which is fascinating."}, {"time": 712, "text": "I think you're in that sense ultimately a great scientist through this process of sharpening your brain."}, {"time": 718, "text": "Well, I don't know if I am a scientist."}, {"time": 721, "text": "I think science is a way of knowing and there are a lot of questions I investigate that are not scientific questions."}, {"time": 731, "text": "On like mind field, we have definitely done scientific experiments and studies that had hypotheses and all of that, but not to be too like precious about what does the word science mean?"}, {"time": 744, "text": "But I think I would just describe myself as curious and I hope that that curiosity is contagious."}, {"time": 749, "text": "So to you, the scientific method is deeply connected to science because your curiosity took you to asking questions."}, {"time": 758, "text": "To me, asking a good question, even if you feel, society feels that it's not a question within the reach of science currently."}, {"time": 767, "text": "To me, asking the question is the biggest step of the scientific process."}, {"time": 773, "text": "The scientific method is the second part and that may be what traditionally is called science, but to me, asking the questions, being brave enough to ask the questions, being curious and not constrained by what you're supposed to think is just true, what it means to be a scientist to me."}, {"time": 791, "text": "It's certainly a huge part of what it means to be a human."}, {"time": 796, "text": "If I were to say, you know what?"}, {"time": 797, "text": "I don't believe in forces."}, {"time": 799, "text": "I think that when I push on a massive object, a ghost leaves my body and enters the object I'm pushing and these ghosts happen to just get really lazy when they're around massive things and that's why F equals MA."}, {"time": 812, "text": "Oh, and by the way, the laziness of the ghost is in proportion to the mass of the object."}, {"time": 816, "text": "So boom, prove me wrong."}, {"time": 817, "text": "Every experiment, well, you can never find the ghost."}, {"time": 821, "text": "And so none of that theory is scientific, but once I start saying, can I see the ghost?"}, {"time": 829, "text": "Why should there be a ghost?"}, {"time": 830, "text": "And if there aren't ghosts, what might I expect?"}, {"time": 833, "text": "And I start to do different tests to see, is this falsifiable?"}, {"time": 839, "text": "Are there things that should happen if there are ghosts or are there things that shouldn't happen?"}, {"time": 842, "text": "And do they, you know, what do I observe?"}, {"time": 845, "text": "Now I'm thinking scientifically."}, {"time": 846, "text": "I don't think of science as, wow, a picture of a black hole."}, {"time": 850, "text": "That's just a photograph."}, {"time": 852, "text": "That's an image."}, {"time": 853, "text": "That's data."}, {"time": 853, "text": "That's a sensory and perception experience."}, {"time": 856, "text": "Science is how we got that and how we understand it and how we believe in it and how we reduce our uncertainty around what it means."}, {"time": 864, "text": "But I would say I'm deeply within the scientific community and I'm sometimes disheartened by the elitism of the thinking, sort of not allowing yourself to think outside the box."}, {"time": 876, "text": "So allowing the possibility of going against the conventions of science, I think is a beautiful part of some of the greatest scientists in history."}, {"time": 886, "text": "I don't know, I'm impressed by scientists every day and revolutions in our knowledge of the world occur only under very special circumstances."}, {"time": 900, "text": "It is very scary to challenge conventional thinking and risky because let's go back to elitism and ego, right?"}, {"time": 910, "text": "If you just say, you know what?"}, {"time": 911, "text": "I believe in the spirits of my body and all forces are actually created by invisible creatures that transfer themselves between objects."}, {"time": 922, "text": "If you ridicule every other theory and say that you're correct, then ego gets involved and you just don't go anywhere."}, {"time": 931, "text": "But fundamentally the question of well, what is a force is incredibly important."}, {"time": 938, "text": "We need to have that conversation, but it needs to be done in this very political way of like, let's be respectful of everyone and let's realize that we're all learning together and not shutting out other people."}, {"time": 949, "text": "And so when you look at a lot of revolutionary ideas, they were not accepted right away."}, {"time": 957, "text": "And, you know, Galileo had a couple of problems with the authorities and later thinkers, Descartes, was like, all right, look, I kind of agree with Galileo, but I'm gonna have to not say that."}, {"time": 971, "text": "I'll have to create and invent and write different things that keep me from being in trouble, but we still slowly made progress."}, {"time": 977, "text": "Revolutions are difficult in all forms and certainly in science."}, {"time": 980, "text": "Before we get to AI, on topic of revolutionary ideas, let me ask on a Reddit AMA, you said that is the earth flat is one of the favorite questions you've ever answered, speaking of revolutionary ideas."}, {"time": 993, "text": "So your video on that, people should definitely watch, is really fascinating."}, {"time": 999, "text": "Can you elaborate why you enjoyed answering this question so much?"}, {"time": 1003, "text": "Yeah, well, it's a long story."}, {"time": 1005, "text": "I remember a long time ago, I was living in New York at the time, so it had to have been like 2009 or something."}, {"time": 1014, "text": "I visited the Flat Earth forums and this was before the Flat Earth theories became as sort of mainstream as they are."}, {"time": 1023, "text": "Sorry to ask the dumb question, forums, online forums."}, {"time": 1026, "text": "Yeah, the Flat Earth Society, I don't know if it's.com or.org, but I went there and I was reading their ideas and how they responded to typical criticisms of, well, the earth isn't flat because what about this?"}, {"time": 1040, "text": "And I could not tell, and I mentioned this in my video, I couldn't tell how many of these community members actually believe the earth was flat or we're just trolling."}, {"time": 1052, "text": "And I realized that the fascinating thing is, how do we know anything?"}, {"time": 1058, "text": "And what makes for a good belief versus a maybe not so tenable or good belief?"}, {"time": 1065, "text": "And so that's really what my video about earth being flat is about."}, {"time": 1069, "text": "It's about, look, there are a lot of reasons that the earth is probably not flat, but a Flat Earth believer can respond to every single one of them, but it's all in an ad hoc way."}, {"time": 1084, "text": "And all of these, all of their rebuttals aren't necessarily gonna form a cohesive noncontradictory whole."}, {"time": 1090, "text": "And I believe that's the episode where I talk about Occam's razor and Newton's flaming laser sword."}, {"time": 1097, "text": "And then I say, well, you know what, wait a second."}, {"time": 1099, "text": "We know that space contracts as you move."}, {"time": 1105, "text": "And so to a particle moving near the speed of light towards earth, earth would be flattened in the direction of that particles travel."}, {"time": 1112, "text": "So to them, earth is flat."}, {"time": 1115, "text": "Like we need to be really generous to even wild ideas because they're all thinking, they're all the communication of ideas."}, {"time": 1125, "text": "And what else can it mean to be a human?"}, {"time": 1128, "text": "Yeah, and I think I'm a huge fan of the Flat Earth theory, quote unquote, in the sense that to me it feels harmless to explore some of the questions of what it means to believe something, what it means to explore the edge of science and so on."}, {"time": 1145, "text": "Cause it's a harm, it's a, to me, nobody gets hurt whether the earth is flat or round, not literally, but I mean intellectually when we're just having a conversation."}, {"time": 1153, "text": "That said, again, to elitism, I find that scientists roll their eyes way too fast on the Flat Earth."}, {"time": 1161, "text": "The kind of dismissal that I see to this even notion, they haven't like sat down and say, what are the arguments that are being proposed?"}, {"time": 1170, "text": "And this is why these arguments are incorrect."}, {"time": 1172, "text": "So that should be something that scientists should always do, even to the most sort of ideas that seem ridiculous."}, {"time": 1182, "text": "So I like this as almost, it's almost my test when I ask people what they think about Flat Earth theory, to see how quickly they roll their eyes."}, {"time": 1191, "text": "Well, yeah, I mean, let me go on record and say that the earth is not flat."}, {"time": 1198, "text": "It is a three dimensional spheroid."}, {"time": 1202, "text": "However, I don't know that and it has not been proven."}, {"time": 1207, "text": "Science doesn't prove anything."}, {"time": 1208, "text": "It just reduces uncertainty."}, {"time": 1210, "text": "Could the earth actually be flat?"}, {"time": 1213, "text": "Extremely unlikely, extremely unlikely."}, {"time": 1219, "text": "And so it is a ridiculous notion if we care about how probable and certain our ideas might be."}, {"time": 1226, "text": "But I think it's incredibly important to talk about science in that way and to not resort to, well, it's true."}, {"time": 1235, "text": "It's true in the same way that a mathematical theorem is true."}, {"time": 1241, "text": "And I think we're kind of like being pretty pedantic about defining this stuff."}, {"time": 1248, "text": "But like, sure, I could take a rocket ship out and I could orbit earth and look at it and it would look like a ball, right?"}, {"time": 1256, "text": "But I still can't prove that I'm not living in a simulation, that I'm not a brain in a vat, that this isn't all an elaborate ruse created by some technologically advanced extraterrestrial civilization."}, {"time": 1266, "text": "So there's always some doubt and that's fine."}, {"time": 1272, "text": "And I think that kind of doubt, practically speaking, is useful when you start talking about quantum mechanics or string theory, sort of, it helps."}, {"time": 1280, "text": "To me, that kind of adds a little spice into the thinking process of scientists."}, {"time": 1286, "text": "So, I mean, just as a thought experiment, your video kind of, okay, say the earth is flat."}, {"time": 1293, "text": "What would the forces when you walk about this flat earth feel like to the human?"}, {"time": 1298, "text": "That's a really nice thought experiment to think about."}, {"time": 1300, "text": "Right, because what's really nice about it is that it's a funny thought experiment, but you actually wind up accidentally learning a whole lot about gravity and about relativity and geometry."}, {"time": 1313, "text": "And I think that's really the goal of what I'm doing."}, {"time": 1316, "text": "I'm not trying to like convince people that the earth is round."}, {"time": 1318, "text": "I feel like you either believe that it is or you don't and like, that's, you know, how can I change that?"}, {"time": 1324, "text": "What I can do is change how you think and how you are introduced to important concepts."}, {"time": 1330, "text": "Like, well, how does gravity operate?"}, {"time": 1333, "text": "Oh, it's all about the center of mass of an object."}, {"time": 1336, "text": "So right, on a sphere, we're all pulled towards the middle, essentially the centroid geometrically, but on a disc, ooh, you're gonna be pulled at a weird angle if you're out near the edge."}, {"time": 1345, "text": "And that stuff's fascinating."}, {"time": 1348, "text": "Yeah, and to me, that was, that particular video opened my eyes even more to what gravity is."}, {"time": 1357, "text": "It's just a really nice visualization tool of, because you always imagine gravity with spheres, with masses that are spheres."}, {"time": 1365, "text": "And imagining gravity on masses that are not spherical, some other shape, but in here, a plate, a flat object, is really interesting."}, {"time": 1374, "text": "It makes you really kind of visualize in a three dimensional way the force of gravity."}, {"time": 1377, "text": "Yeah, even if a disc the size of Earth would be impossible, I think anything larger than like the moon basically needs to be a sphere because gravity will round it out."}, {"time": 1395, "text": "So you can't have a teacup the size of Jupiter, right?"}, {"time": 1398, "text": "There's a great book about the teacup in the universe that I highly recommend."}, {"time": 1402, "text": "I don't remember the author."}, {"time": 1404, "text": "I forget her name, but it's a wonderful book."}, {"time": 1406, "text": "So look it up."}, {"time": 1408, "text": "I think it's called Teacup in the Universe."}, {"time": 1410, "text": "Just to link on this point briefly, your videos are generally super, people love them, right?"}, {"time": 1417, "text": "If you look at the sort of number of likes versus dislikes is this measure of YouTube, right, is incredible."}, {"time": 1423, "text": "And as do I."}, {"time": 1425, "text": "But this particular flat Earth video has more dislikes than usual."}, {"time": 1431, "text": "What do you, on that topic in general, what's your sense, how big is the community, not just who believes in flat Earth, but sort of the anti scientific community that naturally distrust scientists in a way that's not an open minded way, like really just distrust scientists like they're bought by some kind of mechanism of some kind of bigger system that's trying to manipulate human beings."}, {"time": 1461, "text": "What's your sense of the size of that community?"}, {"time": 1464, "text": "You're one of the sort of great educators in the world that educates people on the exciting power of science."}, {"time": 1474, "text": "So you're kind of up against this community."}, {"time": 1478, "text": "What's your sense of it?"}, {"time": 1479, "text": "I really have no idea."}, {"time": 1481, "text": "I haven't looked at the likes and dislikes on the flat Earth video."}, {"time": 1485, "text": "And so I would wonder if it has a greater percentage of dislikes than usual, is that because of people disliking it because they think that it's a video about Earth being flat and they find that ridiculous and they dislike it without even really watching much?"}, {"time": 1504, "text": "Do they wish that I was more like dismissive of flat Earth theories?"}, {"time": 1509, "text": "That's possible too."}, {"time": 1510, "text": "I know there are a lot of response videos that kind of go through the episode and are pro flat Earth, but I don't know if there's a larger community of unorthodox thinkers today than there have been in the past."}, {"time": 1527, "text": "And I just wanna not lose them."}, {"time": 1529, "text": "I want them to keep listening and thinking and by calling them all idiots or something, that does no good because how idiotic are they really?"}, {"time": 1541, "text": "I mean, the Earth isn't a sphere at all."}, {"time": 1545, "text": "We know that it's an oblate spheroid and that in and of itself is really interesting."}, {"time": 1550, "text": "And I investigated that in which way is down where I'm like, really down does not point towards the center of the Earth."}, {"time": 1556, "text": "It points in different direction, depending on what's underneath you and what's above you and what's around you."}, {"time": 1562, "text": "The whole universe is tugging on me."}, {"time": 1566, "text": "And then you also show that gravity is non uniform across the globe."}, {"time": 1571, "text": "Like if you, there's this I guess thought experiment if you build a bridge all the way across the Earth and then just knock out its pillars, what would happen?"}, {"time": 1583, "text": "And you describe how it would be like a very chaotic, unstable thing that's happening because gravity is non uniform throughout the Earth."}, {"time": 1591, "text": "Yeah, in small spaces, like the ones we work in, we can essentially assume that gravity is uniform, but it's not."}, {"time": 1600, "text": "It is weaker the further you are from the Earth."}, {"time": 1603, "text": "And it also is going to be, it's radially pointed towards the middle of the Earth."}, {"time": 1610, "text": "So a really large object will feel tidal forces because of that non uniformness."}, {"time": 1615, "text": "And we can take advantage of that with satellites, right?"}, {"time": 1618, "text": "Gravitational induced torque."}, {"time": 1620, "text": "It's a great way to align your satellite without having to use fuel or any kind of engine."}, {"time": 1625, "text": "So let's jump back to it, artificial intelligence."}, {"time": 1628, "text": "What's your thought of the state of where we are at currently with artificial intelligence and what do you think it takes to build human level or superhuman level intelligence?"}, {"time": 1637, "text": "I don't know what intelligence means."}, {"time": 1640, "text": "That's my biggest question at the moment."}, {"time": 1642, "text": "And I think it's because my instinct is always to go, well, what are the foundations here of our discussion?"}, {"time": 1648, "text": "What does it mean to be intelligent?"}, {"time": 1651, "text": "How do we measure the intelligence of an artificial machine or a program or something?"}, {"time": 1657, "text": "Can we say that humans are intelligent?"}, {"time": 1659, "text": "Because there's also a fascinating field of how do you measure human intelligence."}, {"time": 1665, "text": "But if we just take that for granted, saying that whatever this fuzzy intelligence thing we're talking about, humans kind of have it."}, {"time": 1673, "text": "What would be a good test for you?"}, {"time": 1676, "text": "So during develop a test that's natural language conversation, would that impress you?"}, {"time": 1681, "text": "A chat bot that you'd want to hang out and have a beer with for a bunch of hours or have dinner plans with."}, {"time": 1688, "text": "Is that a good test, natural language conversation?"}, {"time": 1690, "text": "Is there something else that would impress you?"}, {"time": 1692, "text": "Or is that also too difficult to think about?"}, {"time": 1693, "text": "Oh yeah, I'm pretty much impressed by everything."}, {"time": 1696, "text": "I think that if there was a chat bot that was like incredibly, I don't know, really had a personality."}, {"time": 1704, "text": "And if I didn't be the Turing test, right?"}, {"time": 1707, "text": "Like if I'm unable to tell that it's not another person but then I was shown a bunch of wires and mechanical components."}, {"time": 1719, "text": "And it was like, that's actually what you're talking to."}, {"time": 1722, "text": "I don't know if I would feel that guilty destroying it."}, {"time": 1726, "text": "I would feel guilty because clearly it's well made and it's a really cool thing."}, {"time": 1731, "text": "It's like destroying a really cool car or something but I would not feel like I was a murderer."}, {"time": 1736, "text": "So yeah, at what point would I start to feel that way?"}, {"time": 1738, "text": "And this is such a subjective psychological question."}, {"time": 1742, "text": "If you give it movement or if you have it act as though or perhaps really feel pain as I destroy it and scream and resist, then I'd feel bad."}, {"time": 1755, "text": "Yeah, it's beautifully put."}, {"time": 1756, "text": "And let's just say act like it's a pain."}, {"time": 1760, "text": "So if you just have a robot that not screams, just like moans in pain if you kick it, that immediately just puts it in a class that we humans, it becomes, we anthropomorphize it."}, {"time": 1775, "text": "It almost immediately becomes human."}, {"time": 1777, "text": "So that's a psychology question as opposed to sort of a physics question."}, {"time": 1780, "text": "Right, I think that's a really good instinct to have."}, {"time": 1783, "text": "If the robot."}, {"time": 1785, "text": "Screams."}, {"time": 1786, "text": "Screams and moans, even if you don't believe that it has the mental experience, the qualia of pain and suffering, I think it's still a good instinct to say, you know what, I'd rather not hurt it."}, {"time": 1799, "text": "The problem is that instinct can get us in trouble because then robots can manipulate that."}, {"time": 1805, "text": "And there's different kinds of robots."}, {"time": 1808, "text": "There's robots like the Facebook and the YouTube algorithm that recommends the video, and they can manipulate in the same kind of way."}, {"time": 1814, "text": "Well, let me ask you just to stick on artificial intelligence for a second."}, {"time": 1817, "text": "Do you have worries about existential threats from AI or existential threats from other technologies like nuclear weapons that could potentially destroy life on earth or damage it to a very significant degree?"}, {"time": 1831, "text": "Yeah, of course I do."}, {"time": 1832, "text": "Especially the weapons that we create."}, {"time": 1835, "text": "There's all kinds of famous ways to think about this."}, {"time": 1838, "text": "And one is that, wow, what if we don't see advanced alien civilizations because of the danger of technology?"}, {"time": 1850, "text": "What if we reach a point, and I think there's a channel, Thoughty2, geez, I wish I remembered the name of the channel, but he delves into this kind of limit of maybe once you discover radioactivity and its power, you've reached this important hurdle."}, {"time": 1867, "text": "And the reason that the skies are so empty is that no one's ever managed to survive as a civilization once they have that destructive power."}, {"time": 1876, "text": "And when it comes to AI, I'm not really very worried because I think that there are plenty of other people that are already worried enough."}, {"time": 1886, "text": "And oftentimes these worries are just, they just get in the way of progress."}, {"time": 1892, "text": "And they're questions that we should address later."}, {"time": 1897, "text": "And I think I talk about this in my interview with the self driving autonomous vehicle guy, as I think it was a bonus scene from the trolley problem episode."}, {"time": 1912, "text": "And I'm like, wow, what should a car do if this really weird contrived scenario happens where it has to swerve and save the driver, but kill a kid?"}, {"time": 1920, "text": "And he's like, well, what would a human do?"}, {"time": 1923, "text": "And if we resist technological progress because we're worried about all of these little issues, then it gets in the way."}, {"time": 1931, "text": "And we shouldn't avoid those problems, but we shouldn't allow them to be stumbling blocks to advancement."}, {"time": 1938, "text": "So the folks like Sam Harris or Elon Musk are saying that we're not worried enough."}, {"time": 1944, "text": "So the worry should not paralyze technological progress, but we're sort of marching, technology is marching forward without the key scientists, the developing of technology, worrying about the overnight having some effects that would be very detrimental to society."}, {"time": 1965, "text": "So to push back on your thought of the idea that there's enough people worrying about it, Elon Musk says, there's not enough people worrying about it."}, {"time": 1974, "text": "That's the kind of balance is, it's like folks who are really focused on nuclear deterrence are saying there's not enough people worried about nuclear deterrence, right?"}, {"time": 1986, "text": "So it's an interesting question of what is a good threshold of people to worry about these?"}, {"time": 1992, "text": "And if it's too many people that are worried, you're right."}, {"time": 1995, "text": "It'll be like the press would over report on it and there'll be technological, halt technological progress."}, {"time": 2001, "text": "If not enough, then we can march straight ahead into that abyss that human beings might be destined for with the progress of technology."}, {"time": 2011, "text": "Yeah, I don't know what the right balance is of how many people should be worried and how worried should they be, but we're always worried about new technology."}, {"time": 2020, "text": "We know that Plato was worried about the written word."}, {"time": 2022, "text": "He was like, we shouldn't teach people to write because then they won't use their minds to remember things."}, {"time": 2028, "text": "There have been concerns over technology and its advancement since the beginning of recorded history."}, {"time": 2035, "text": "And so, I think, however, these conversations are really important to have because again, we learn a lot about ourselves."}, {"time": 2043, "text": "If we're really scared of some kind of AI like coming into being that is conscious or whatever and can self replicate, we already do that every day."}, {"time": 2053, "text": "It's called humans being born."}, {"time": 2054, "text": "They're not artificial, they're humans, but they're intelligent and I don't wanna live in a world where we're worried about babies being born because what if they become evil?"}, {"time": 2065, "text": "What if they become mean people?"}, {"time": 2065, "text": "What if they're thieves?"}, {"time": 2067, "text": "Maybe we should just like, what, not have babies born?"}, {"time": 2071, "text": "Like maybe we shouldn't create AI."}, {"time": 2073, "text": "It's like, we will want to have safeguards in place in the same way that we know, look, a kid could be born that becomes some kind of evil person, but we have laws, right?"}, {"time": 2087, "text": "And it's possible that with advanced genetics in general, be able to, it's a scary thought to say that, this, my child, if born would have an 83% chance of being a psychopath, right?"}, {"time": 2108, "text": "Like being able to, if it's something genetic, if there's some sort of, and what to use that information, what to do with that information is a difficult ethical thought."}, {"time": 2120, "text": "Yeah, and I'd like to find an answer that isn't, well, let's not have them live."}, {"time": 2124, "text": "You know, I'd like to find an answer that is, well, all human life is worthy."}, {"time": 2130, "text": "And if you have an 83% chance of becoming a psychopath, well, you still deserve dignity."}, {"time": 2138, "text": "And you still deserve to be treated well."}, {"time": 2142, "text": "You still have rights."}, {"time": 2143, "text": "At least at this part of the world, at least in America, there's a respect for individual life in that way."}, {"time": 2149, "text": "That's, well, to me, but again, I'm in this bubble, is a beautiful thing."}, {"time": 2155, "text": "But there's other cultures where individual human life is not that important, where a society, so I was born in the Soviet Union, where the strength of nation and society together is more important than any one particular individual."}, {"time": 2170, "text": "So it's an interesting also notion, the stories we tell ourselves."}, {"time": 2173, "text": "I like the one where individuals matter, but it's unclear that that was what the future holds."}, {"time": 2179, "text": "Well, yeah, and I mean, let me even throw this out."}, {"time": 2181, "text": "Like, what is artificial intelligence?"}, {"time": 2183, "text": "How can it be artificial?"}, {"time": 2185, "text": "I really think that we get pretty obsessed and stuck on the idea that there is some thing that is a wild human, a pure human organism without technology."}, {"time": 2195, "text": "But I don't think that's a real thing."}, {"time": 2197, "text": "I think that humans and human technology are one organism."}, {"time": 2202, "text": "Look at my glasses, okay?"}, {"time": 2204, "text": "If an alien came down and saw me, would they necessarily know that this is an invention, that I don't grow these organically from my body?"}, {"time": 2213, "text": "They wouldn't know that right away."}, {"time": 2215, "text": "And the written word, and spoons, and cups, these are all pieces of technology."}, {"time": 2222, "text": "We are not alone as an organism."}, {"time": 2226, "text": "And so the technology we create, whether it be video games or artificial intelligence that can self replicate and hate us, it's actually all the same organism."}, {"time": 2236, "text": "When you're in a car, where do you end in the car begin?"}, {"time": 2239, "text": "It seems like a really easy question to answer, but the more you think about it, the more you realize, wow, we are in this symbiotic relationship with our inventions."}, {"time": 2247, "text": "And there are plenty of people who are worried about it."}, {"time": 2250, "text": "And there should be, but it's inevitable."}, {"time": 2252, "text": "And I think that even just us think of ourselves as individual intelligences may be silly notion because it's much better to think of the entirety of human civilization."}, {"time": 2266, "text": "All living organisms on earth is a single living organism."}, {"time": 2270, "text": "As a single intelligent creature, because you're right, everything's intertwined."}, {"time": 2274, "text": "Everything is deeply connected."}, {"time": 2277, "text": "So we mentioned, you know, Musk, so you're a curious lover of science."}, {"time": 2283, "text": "What do you think of the efforts that Elon Musk is doing with space exploration, with electric vehicles, with autopilot, sort of getting into the space of autonomous vehicles, with boring under LA and a Neuralink trying to communicate brain machine interfaces, communicate between machines and human brains?"}, {"time": 2308, "text": "Well, it's really inspiring."}, {"time": 2310, "text": "I mean, look at the fandom that he's amassed."}, {"time": 2314, "text": "It's not common for someone like that to have such a following."}, {"time": 2320, "text": "And so it's... Engineering nerd."}, {"time": 2322, "text": "Yeah, so it's really exciting."}, {"time": 2324, "text": "But I also think that a lot of responsibility comes with that kind of power."}, {"time": 2327, "text": "So like if I met him, I would love to hear how he feels about the responsibility he has."}, {"time": 2333, "text": "When there are people who are such a fan of your ideas and your dreams and share them so closely with you, you have a lot of power."}, {"time": 2346, "text": "And he didn't always have that, you know?"}, {"time": 2349, "text": "He wasn't born as Elon Musk."}, {"time": 2351, "text": "Well, he was, but well, he was named that later."}, {"time": 2353, "text": "But the point is that I wanna know the psychology of becoming a figure like him."}, {"time": 2363, "text": "Well, I don't even know how to phrase the question right, but it's a question about what do you do when you're following, your fans become so large that it's almost bigger than you."}, {"time": 2377, "text": "And how do you responsibly manage that?"}, {"time": 2381, "text": "And maybe it doesn't worry him at all."}, {"time": 2382, "text": "And that's fine too."}, {"time": 2383, "text": "But I'd be really curious."}, {"time": 2385, "text": "And I think there are a lot of people that go through this when they realize, whoa, there are a lot of eyes on me."}, {"time": 2390, "text": "There are a lot of people who really take what I say very earnestly and take it to heart and will defend me."}, {"time": 2397, "text": "And whew, that's, that's, that can be dangerous."}, {"time": 2404, "text": "And you have to be responsible with it."}, {"time": 2407, "text": "Both in terms of impact on society and psychologically for the individual, just the burden psychologically on Elon?"}, {"time": 2415, "text": "Yeah, yeah, how does he think about that?"}, {"time": 2418, "text": "Part of his persona."}, {"time": 2421, "text": "Well, let me throw that right back at you because in some ways you're just a funny guy that gotten a humongous following, a funny guy with a curiosity."}, {"time": 2434, "text": "You've got a huge following."}, {"time": 2436, "text": "How do you psychologically deal with the responsibility?"}, {"time": 2440, "text": "In many ways you have a reach in many ways bigger than Elon Musk."}, {"time": 2444, "text": "What is your, what is the burden that you feel in educating being one of the biggest educators in the world where everybody's listening to you and actually everybody, like most of the world that's uses YouTube for educational material, trust you as a source of good, strong scientific thinking."}, {"time": 2467, "text": "It's a burden and I try to approach it with a lot of humility and sharing."}, {"time": 2476, "text": "Like I'm not out there doing a lot of scientific experiments."}, {"time": 2480, "text": "I am sharing the work of real scientists and I'm celebrating their work and the way that they think and the power of curiosity."}, {"time": 2489, "text": "But I wanna make it clear at all times that like, look, we don't know all the answers and I don't think we're ever going to reach a point where we're like, wow, and there you go."}, {"time": 2499, "text": "That's the universe."}, {"time": 2500, "text": "It's this equation, you plug in some conditions or whatever and you do the math and you know what's gonna happen tomorrow."}, {"time": 2506, "text": "I don't think we're ever gonna reach that point, but I think that there is a tendency to sometimes believe in science and become elitist and become, I don't know, hard when in reality it should humble you and make you feel smaller."}, {"time": 2521, "text": "I think there's something very beautiful about feeling very, very small and very weak and to feel that you need other people."}, {"time": 2530, "text": "So I try to keep that in mind and say, look, thanks for watching."}, {"time": 2534, "text": "Vsauce is not, I'm not Vsauce, you are."}, {"time": 2536, "text": "When I start the episodes, I say, hey, Vsauce, Michael here."}, {"time": 2540, "text": "Vsauce and Michael are actually a different thing in my mind."}, {"time": 2543, "text": "I don't know if that's always clear, but yeah, I have to approach it that way because it's not about me."}, {"time": 2550, "text": "Yeah, so it's not even, you're not feeling the responsibility."}, {"time": 2553, "text": "You're just sort of plugging into this big thing that is scientific exploration of our reality and you're a voice that represents a bunch, but you're just plugging into this big Vsauce ball that others, millions of others are plugged into."}, {"time": 2569, "text": "Yeah, and I'm just hoping to encourage curiosity and responsible thinking and an embracement of doubt and being okay with that."}, {"time": 2585, "text": "So I'm next week talking to Christos Gudrow."}, {"time": 2588, "text": "I'm not sure if you're familiar who he is, but he's the VP of engineering, head of the quote unquote YouTube algorithm or the search and discovery."}, {"time": 2596, "text": "So let me ask, first high level, do you have a question for him that if you can get an honest answer that you would ask, but more generally, how do you think about the YouTube algorithm that drives some of the motivation behind, no, some of the design decisions you make as you ask and answer some of the questions you do, how would you improve this algorithm in your mind in general?"}, {"time": 2625, "text": "So just what would you ask him?"}, {"time": 2627, "text": "And outside of that, how would you like to see the algorithm improve?"}, {"time": 2632, "text": "Well, I think of the algorithm as a mirror."}, {"time": 2636, "text": "It reflects what people put in and we don't always like what we see in that mirror."}, {"time": 2641, "text": "From the individual mirror to the individual mirror to the society."}, {"time": 2645, "text": "Both, in the aggregate, it's reflecting back what people on average want to watch."}, {"time": 2651, "text": "And when you see things being recommended to you, it's reflecting back what it thinks you want to see."}, {"time": 2659, "text": "And specifically, I would guess that it's not just what you want to see, but what you will click on and what you will watch some of and stay on YouTube because of."}, {"time": 2672, "text": "I don't think that, this is all me guessing, but I don't think that YouTube cares if you only watch like a second of a video, as long as the next thing you do is open another video."}, {"time": 2685, "text": "If you close the app or close the site, that's a problem for them because they're not a subscription platform."}, {"time": 2692, "text": "They're not like, look, you're giving us 20 bucks a month no matter what, so who cares?"}, {"time": 2697, "text": "They need you to watch and spend time there and see ads."}, {"time": 2702, "text": "So one of the things I'm curious about whether they do consider longer term sort of develop, your longer term development as a human being, which I think ultimately will make you feel better about using YouTube in the longterm and allowing you to stick with it for longer."}, {"time": 2719, "text": "Because even if you feed the dopamine rush in the short term and you keep clicking on cat videos, eventually you sort of wake up like from a drug and say, I need to quit this."}, {"time": 2730, "text": "So I wonder how much you're trying to optimize for the longterm because when I look at the, your videos aren't exactly sort of, no offense, but they're not the most clickable."}, {"time": 2741, "text": "They're both the most clickable and I feel I watched the entire thing and I feel a better human after I watched it, right?"}, {"time": 2749, "text": "So like they're not just optimizing for the clickability because I hope, so my thought is how do you think of it?"}, {"time": 2759, "text": "And does it affect your own content?"}, {"time": 2762, "text": "Like how deep you go, how profound you explore the directions and so on."}, {"time": 2767, "text": "I've been really lucky in that I don't worry too much about the algorithm."}, {"time": 2772, "text": "I mean, look at my thumbnails."}, {"time": 2773, "text": "I don't really go too wild with them."}, {"time": 2777, "text": "And with minefield where I'm in partnership with YouTube on the thumbnails, I'm often like, let's pull this back."}, {"time": 2782, "text": "Let's be mysterious."}, {"time": 2783, "text": "But usually I'm just trying to do what everyone else is not doing."}, {"time": 2787, "text": "So if everyone's doing crazy Photoshop kind of thumbnails, I'm like, what if the thumbnails just a line?"}, {"time": 2794, "text": "And what if the title is just a word?"}, {"time": 2797, "text": "And I kind of feel like all of the Vsauce channels have cultivated an audience that expects that."}, {"time": 2803, "text": "And so they would rather Jake make a video that's just called stains than one called, I explored stains, shocking."}, {"time": 2810, "text": "But there are other audiences out there that want that."}, {"time": 2813, "text": "And I think most people kind of want what you see the algorithm favoring, which is mainstream traditional celebrity and news kind of information."}, {"time": 2823, "text": "I mean, that's what makes YouTube really different than other streaming platforms."}, {"time": 2826, "text": "No one's like, what's going on in the world?"}, {"time": 2828, "text": "I'll open up Netflix to find out."}, {"time": 2830, "text": "But you do open up Twitter to find that out."}, {"time": 2832, "text": "You open up Facebook and you can open up YouTube because you'll see that the trending videos are like what happened amongst the traditional mainstream people in different industries."}, {"time": 2842, "text": "And that's what's being shown."}, {"time": 2844, "text": "And it's not necessarily YouTube saying, we want that to be what you see."}, {"time": 2849, "text": "It's that that's what people click on."}, {"time": 2851, "text": "When they see Ariana Grande, you know, reads a love letter from like her high school sweetheart, they're like, I wanna see that."}, {"time": 2858, "text": "And when they see a video from me that's got some lines in math and it's called law and causes they're like, well, I mean, I'm just on the bus."}, {"time": 2865, "text": "Like I don't have time to dive into a whole lesson."}, {"time": 2868, "text": "So, you know, before you get super mad at YouTube, you should say, really, they're just reflecting back human behavior."}, {"time": 2875, "text": "Is there something you would improve about the algorithm knowing of course, that as far as we're concerned, it's a black box, so we don't know how it works."}, {"time": 2884, "text": "Right, and I don't think that even anyone at YouTube really knows what it's doing."}, {"time": 2887, "text": "They know what they've tweaked, but then it learns."}, {"time": 2889, "text": "I think that it learns and it decides how to behave."}, {"time": 2893, "text": "And sometimes the YouTube employees are left going, I don't know."}, {"time": 2897, "text": "Maybe we should like change the value of how much it, you know, worries about watch time."}, {"time": 2902, "text": "And maybe it should worry more about something else."}, {"time": 2905, "text": "But I mean, I would like to see, I don't know what they're doing and not doing."}, {"time": 2910, "text": "Well, is there a conversation that you think they should be having just internally, whether they're having it or not?"}, {"time": 2917, "text": "Is there something, should they be thinking about the longterm future?"}, {"time": 2921, "text": "Should they be thinking about educational content and whether that's educating about what just happened in the world today, news or educational content, like what you're providing, which is asking big sort of timeless questions about how the way the world works."}, {"time": 2938, "text": "What should they think about?"}, {"time": 2939, "text": "Because it's called YouTube, not our tube."}, {"time": 2942, "text": "And that's why I think they have so many phenomenal educational creators."}, {"time": 2948, "text": "You don't have shows like Three Blue One Brown or Physics Girl or Looking Glass Universe or Up and Atom or Brain Scoop or, I mean, I could go on and on."}, {"time": 2958, "text": "They aren't on Amazon Prime and Netflix and they don't have commissioned shows from those platforms."}, {"time": 2964, "text": "It's all organically happening because there are people out there that want to share their passion for learning, that wanna share their curiosity."}, {"time": 2972, "text": "And YouTube could promote those kinds of shows more, but first of all, they probably wouldn't get as many clicks and YouTube needs to make sure that the average user is always clicking and staying on the site."}, {"time": 2987, "text": "They could still promote it more for the good of society, but then we're making some really weird claims about what's good for society because I think that cat videos are also an incredibly important part of what it means to be a human."}, {"time": 3000, "text": "I mentioned this quote before from Unumuno about, look, I've seen a cat like estimate distances and calculate a jump more often than I've seen a cat cry."}, {"time": 3009, "text": "And so things that play with our emotions and make us feel things can be cheesy and can feel cheap, but like, man, that's very human."}, {"time": 3018, "text": "And so even the dumbest vlog is still so important that I don't think I have a better claim to take its spot than it has to have that spot."}, {"time": 3029, "text": "It puts a mirror to us, the beautiful parts, the ugly parts, the shallow parts, the deep parts."}, {"time": 3036, "text": "What I would like to see is, I miss the days when engaging with content on YouTube helped push it into my subscribers timelines."}, {"time": 3047, "text": "It used to be that when I liked a video, say from Veritasium, it would show up in the feed on the front page of the app or the website of my subscribers."}, {"time": 3058, "text": "And I knew that if I liked a video, I could send it 100,000 views or more."}, {"time": 3063, "text": "That no longer is true, but I think that was a good user experience."}, {"time": 3067, "text": "When I subscribe to someone, when I'm following them, I want to see more of what they like."}, {"time": 3073, "text": "I want them to also curate the feed for me."}, {"time": 3075, "text": "And I think that Twitter and Facebook are doing that in also some ways that are kind of annoying, but I would like that to happen more."}, {"time": 3082, "text": "And I think we would see communities being stronger on YouTube if it was that way instead of YouTube going, well, technically Michael liked this Veritasium video, but people are way more likely to click on Carpool Karaoke."}, {"time": 3093, "text": "So I don't even care who they are, just give them that."}, {"time": 3096, "text": "Not saying anything against Carpool Karaoke, that is a extremely important part of our society, what it means to be a human on earth, you know, but."}, {"time": 3106, "text": "I'll say it sucks, but."}, {"time": 3108, "text": "Yeah, but a lot of people would disagree with you and they should be able to see as much of that as they want."}, {"time": 3113, "text": "And I think even people who don't think they like it should still be really aware of it because it's such an important thing."}, {"time": 3119, "text": "It's such an influential thing."}, {"time": 3120, "text": "But yeah, I just wish that like new channels I discover and that I subscribe to, I wish that my subscribers found out about that because especially in the education community, a rising tide floats all boats."}, {"time": 3131, "text": "If you watch a video from Numberphile, you're just more likely to want to watch an episode from me, whether it be on Vsauce1 or Ding."}, {"time": 3138, "text": "It's not competitive in the way that traditional TV was where it's like, well, if you tune into that show, it means you're not watching mine because they both air at the same time."}, {"time": 3146, "text": "So helping each other out through collaborations takes a lot of work, but just through engaging, commenting on their videos, liking their videos, subscribing to them, whatever, that I would love to see become easier and more powerful."}, {"time": 3161, "text": "So a quick and impossibly deep question, last question about mortality."}, {"time": 3168, "text": "You've spoken about death as an interesting topic."}, {"time": 3172, "text": "Do you think about your own mortality?"}, {"time": 3175, "text": "Yeah, every day, it's really scary."}, {"time": 3179, "text": "So what do you think is the meaning of life that mortality makes very explicit?"}, {"time": 3187, "text": "So why are you here on earth, Michael?"}, {"time": 3192, "text": "What's the point of this whole thing?"}, {"time": 3198, "text": "What does mortality in the context of the whole universe make you realize about yourself?"}]}, {"title": "Joscha Bach: Artificial Consciousness and the Nature of Reality | Lex Fridman Podcast #101", "id": "P-2P3MSZrBM", "quotes": [{"time": 314, "text": "And he was unable to."}, {"time": 314, "text": "He's unable to do things if he's not intrinsically motivated."}, {"time": 321, "text": "So in some sense, my grandmother broke her son."}, {"time": 321, "text": "And her son responded when he became an architect to become an artist."}, {"time": 327, "text": "So he built 100 Wasser architecture."}, {"time": 327, "text": "He built houses without right angles."}, {"time": 333, "text": "He built lots of things that didn't work in the more brutalist traditions of eastern Germany."}, {"time": 338, "text": "And so he bought an old watermill, moved out to the countryside, and did only what he wanted to do, which was art."}, {"time": 344, "text": "Eastern Germany was perfect for Boheme, because you had complete material safety."}, {"time": 350, "text": "Food was heavily subsidized, healthcare was free."}, {"time": 350, "text": "You didn't have to worry about rent or pensions or anything."}, {"time": 355, "text": "So it's a socialized communist side."}, {"time": 355, "text": "And the other thing is, it was almost impossible not to be in political disagreement with your government, which is very productive for artists."}, {"time": 364, "text": "So everything that you do is intrinsically meaningful, because it will always touch on the deeper currents of society of culture and be in conflict with it and tension with it."}, {"time": 374, "text": "And you will always have to define yourself with respect to this."}, {"time": 374, "text": "So what impacted your father, this outside of the box thinker against the government, against the world artists?"}, {"time": 386, "text": "He was actually not a thinker."}, {"time": 386, "text": "He was somebody who only got self aware to the degree that he needed to make himself functional."}, {"time": 391, "text": "So in some sense, he was also in the late 1960s."}, {"time": 391, "text": "And he was in some sense a hippie."}, {"time": 399, "text": "So he became a one person cult."}, {"time": 399, "text": "He lived out there in his kingdom."}, {"time": 399, "text": "He built big sculpture gardens and started many avenues of art and so on and convinced a woman to live with him."}, {"time": 413, "text": "She was also an architect and she adored him and decided to share her life with him."}, {"time": 418, "text": "And I basically grew up in a big cave full of books."}, {"time": 418, "text": "I'm almost feral."}, {"time": 418, "text": "And I was bored out there."}, {"time": 425, "text": "It was very, very beautiful, very quiet, and quite lonely."}, {"time": 425, "text": "So I started to read."}, {"time": 425, "text": "And by the time I came to school, I've read everything until fourth grade and then some."}, {"time": 431, "text": "And there was not a real way for me to relate to the outside world."}, {"time": 436, "text": "And I couldn't quite put my finger on why."}, {"time": 441, "text": "And today I know it was because I was a nerd, obviously, and it was the only nerd around."}, {"time": 441, "text": "So there was no other kids like me."}, {"time": 446, "text": "And there was nobody interested in physics or computing or mathematics and so on."}, {"time": 452, "text": "And this village school that I went to was basically a nice school."}, {"time": 458, "text": "Kids were nice to me."}, {"time": 458, "text": "I was not beaten up, but I also didn't make many friends or build deep relationships."}, {"time": 462, "text": "They only happened in starting from ninth grade when I went into a school for mathematics and physics."}, {"time": 467, "text": "Do you remember any key books from this moment?"}, {"time": 471, "text": "I basically read everything."}, {"time": 471, "text": "So I went to the library and I worked my way through the children's and young adult sections."}, {"time": 476, "text": "And then I read a lot of science fiction, for instance, Stanislav Lem, basically the great author of Cybernetics, has influenced me."}, {"time": 481, "text": "Back then, I didn't see him as a big influence because everything that he wrote seemed to be so natural to me."}, {"time": 490, "text": "And it's only later that I contrasted it with what other people wrote."}, {"time": 490, "text": "Another thing that was very influential on me were the classical philosophers and also the literature of romanticism."}, {"time": 502, "text": "So German poetry and art, Troste Hilshoff and Heine and up to Hesse and so on."}, {"time": 509, "text": "Hesse."}, {"time": 509, "text": "I love Hesse."}, {"time": 509, "text": "So at which point do the classical philosophers end?"}, {"time": 509, "text": "At this point, we're in the 21st century."}, {"time": 515, "text": "What's the latest classical philosopher?"}, {"time": 515, "text": "Does this stretch through even as far as Nietzsche or is this, are we talking about Plato and Aristotle?"}, {"time": 525, "text": "I think that Nietzsche is the classical equivalent of a shit poster."}, {"time": 532, "text": "He's very smart and easy to read, but he's not so much trolling others."}, {"time": 532, "text": "He's trolling himself because he was at odds with the world."}, {"time": 537, "text": "Largely his romantic relationships didn't work out."}, {"time": 542, "text": "He got angry and he basically became a nihilist."}, {"time": 546, "text": "Isn't that a beautiful way to be as an intellectual is to constantly be trolling yourself, to be in that conflict, in that tension?"}, {"time": 554, "text": "I think it's a lack of self awareness."}, {"time": 554, "text": "At some point, you have to understand the comedy of your own situation."}, {"time": 558, "text": "If you take yourself seriously and you are not functional, it ends in tragedy as it did for Nietzsche."}, {"time": 565, "text": "I think you think he took himself too seriously in that tension."}, {"time": 593, "text": "So it's very, very understandable and have great sympathies for this to the degree that I can have sympathy for my own intellectual history."}, {"time": 602, "text": "But you have to grow out of it."}, {"time": 604, "text": "So as an intellectual, a life well lived, a journey well traveled is one where you don't take yourself seriously from that perspective?"}, {"time": 611, "text": "No, I think that you are neither serious or not serious yourself because you need to become unimportant as a subject."}, {"time": 617, "text": "That is, if you are a philosopher, belief is not a verb."}, {"time": 624, "text": "You don't do this for the audience and you don't do it for yourself."}, {"time": 627, "text": "You have to submit to the things that are possibly true and you have to follow wherever your inquiry leads."}, {"time": 632, "text": "But it's not about you."}, {"time": 632, "text": "It has nothing to do with you."}, {"time": 636, "text": "So do you think then people like Ayn Rand believed sort of an idea of there's objective truth."}, {"time": 642, "text": "So what's your sense in the philosophical, if you remove yourself as objective from the picture, you think it's possible to actually discover ideas that are true or are we just in a mesh of relative concepts that are either true nor false?"}, {"time": 652, "text": "It's just a giant mess."}, {"time": 657, "text": "You cannot define objective truth without understanding the nature of truth in the first place."}, {"time": 662, "text": "So what does the brain mean by saying that discover something as truth?"}, {"time": 662, "text": "So for instance, a model can be predictive or not predictive."}, {"time": 668, "text": "Then there can be a sense in which a mathematical statement can be true because it's defined as true under certain conditions."}, {"time": 674, "text": "So it's basically a particular state that a variable can have in a simple game."}, {"time": 679, "text": "And then you can have a correspondence between systems and talk about truth, which is again, a type of model correspondence."}, {"time": 691, "text": "And there also seems to be a particular kind of ground truth."}, {"time": 691, "text": "So for instance, you're confronted with the enormity of something existing at all."}, {"time": 694, "text": "It's stunning when you realize something exists rather than nothing."}, {"time": 701, "text": "And this seems to be true."}, {"time": 701, "text": "There's an absolute truth in the fact that something seems to be happening."}, {"time": 707, "text": "Yeah, that to me is a showstopper."}, {"time": 707, "text": "I could just think about that idea and be amazed by that idea for the rest of my life and not going any farther because I don't even know the answer to that."}, {"time": 717, "text": "Why does anything exist at all?"}, {"time": 721, "text": "Well, the easiest answer is existence is the default, right?"}, {"time": 721, "text": "So this is the lowest number of bits that you would need to encode this."}, {"time": 724, "text": "Whose answer?"}, {"time": 727, "text": "The simplest answer to this is that existence is the default."}, {"time": 731, "text": "What about nonexistence?"}, {"time": 731, "text": "I mean, that seems... Nonexistence might not be a meaningful notion in this sense."}, {"time": 734, "text": "So in some sense, if everything that can exist exists, for something to exist, it probably needs to be implementable."}, {"time": 743, "text": "The only thing that can be implemented is finite automata."}, {"time": 743, "text": "So maybe the whole of existence is the superposition of all finite automata and we are in some region of the fractal that has the properties that it can contain us."}, {"time": 753, "text": "What does it mean to be a superposition of finite automata?"}, {"time": 760, "text": "Superposition of all possible rules?"}, {"time": 760, "text": "Imagine that every automaton is basically an operator that acts on some substrate and as a result, you get emergent patterns."}, {"time": 770, "text": "What's the substrate?"}, {"time": 772, "text": "I have no idea to know."}, {"time": 772, "text": "But some substrate."}, {"time": 775, "text": "It's something that can store information."}, {"time": 778, "text": "Something that can store information, there's a automaton."}, {"time": 780, "text": "Something that can hold state."}, {"time": 781, "text": "Still, it doesn't make sense to me the why that exists at all."}, {"time": 781, "text": "I could just sit there with a beer or a vodka and just enjoy the fact, pondering the why."}, {"time": 791, "text": "It may not have a why."}, {"time": 791, "text": "This might be the wrong direction to ask into this."}, {"time": 791, "text": "So there could be no relation in the why direction without asking for a purpose or for a cause."}, {"time": 796, "text": "It doesn't mean that everything has to have a purpose or cause."}, {"time": 802, "text": "So we mentioned some philosophers in that early, just taking a brief step back into that."}, {"time": 808, "text": "So we asked ourselves when did classical philosophy end?"}, {"time": 814, "text": "I think for Germany, it largely ended with the first revolution."}, {"time": 818, "text": "That's basically when we entered the monarchy and started a democracy."}, {"time": 818, "text": "And at this point, we basically came up with a new form of government that didn't have a good sense of this new organism that society wanted to be."}, {"time": 830, "text": "And in a way, it decapitated the universities."}, {"time": 836, "text": "So the universities went on through modernism like a headless chicken."}, {"time": 839, "text": "At the same time, democracy failed in Germany and we got fascism as a result."}, {"time": 844, "text": "And it burned down things in a similar way as Stalinism burned down intellectual traditions in Russia."}, {"time": 848, "text": "And Germany, both Germanys have not recovered from this."}, {"time": 848, "text": "Eastern Germany had this vulgar dialectic materialism and Western Germany didn't get much more edgy than Habermas."}, {"time": 854, "text": "So in some sense, both countries lost their intellectual traditions and killing off and driving out the Jews didn't help."}, {"time": 864, "text": "So that was the end of really rigorous what you would say is classical philosophy."}, {"time": 873, "text": "There's also this thing that in some sense, the low hanging foods in philosophy were mostly wrapped."}, {"time": 879, "text": "And the last big things that we discovered was the constructivist turn in mathematics."}, {"time": 886, "text": "So to understand that the parts of mathematics that work are computation, there was a very significant discovery in the first half of the 20th century."}, {"time": 891, "text": "And it hasn't fully permeated philosophy and even physics yet."}, {"time": 897, "text": "Physicists checked out the code libraries for mathematics before constructivism became universal."}, {"time": 902, "text": "What's constructivism?"}, {"time": 913, "text": "Hilbert could get it."}, {"time": 913, "text": "Hilbert saw that, for instance, countries set theoretic experiments and mathematics led into contradictions."}, {"time": 918, "text": "And he noticed that with the current semantics, we cannot build a computer in mathematics that runs mathematics without crashing."}, {"time": 940, "text": "It basically shook his world to the core because in some sense, he felt that the world has to be implemented in classical mathematics."}, {"time": 950, "text": "And for Turing, it wasn't quite so bad."}, {"time": 950, "text": "I think that Turing could see that the solution is to understand that mathematics was computation all along, which means you, for instance, pi in classical mathematics is a value."}, {"time": 961, "text": "It's also a function, but it's the same thing."}, {"time": 961, "text": "And in computation, a function is only a value when you can compute it."}, {"time": 968, "text": "And if you cannot compute the last digit of pi, you only have a function."}, {"time": 973, "text": "You can plug this function into your local sun, let it run until the sun burns out."}, {"time": 978, "text": "This is the last digit of pi you will know."}, {"time": 978, "text": "But it also means there can be no process in the physical universe or in any physically realized computer that depends on having known the last digit of pi."}, {"time": 988, "text": "Which means there are parts of physics that are defined in such a way that cannot strictly be true, because assuming that this could be true leads into contradictions."}, {"time": 998, "text": "So I think putting computation at the center of the world view is actually the right way to think about it."}, {"time": 1004, "text": "And Wittgenstein could see it."}, {"time": 1004, "text": "And Wittgenstein basically preempted the logitist program of AI that Minsky started later, like 30 years later."}, {"time": 1009, "text": "Turing was actually a pupil of Wittgenstein."}, {"time": 1015, "text": "I didn't know there's any connection between Turing and Wittgenstein."}, {"time": 1020, "text": "Wittgenstein even cancelled some classes when Turing was not present because he thought it was not worth spending the time with the others."}, {"time": 1023, "text": "If you read the Tractatus, it's a very beautiful book, like basically one thought on 75 pages."}, {"time": 1029, "text": "It's very non typical for philosophy because it doesn't have arguments in it and it doesn't have references in it."}, {"time": 1035, "text": "It's just one thought that is not intending to convince anybody."}, {"time": 1041, "text": "He says, it's mostly for people that had the same insight as me, just spell it out."}, {"time": 1046, "text": "And this insight is there is a way in which mathematics and philosophy ought to meet."}, {"time": 1052, "text": "Mathematics tries to understand the domain of all languages by starting with those that are so formalizable that you can prove all the properties of the statements that you make."}, {"time": 1062, "text": "But the price that you pay is that your language is very, very simple."}, {"time": 1062, "text": "So it's very hard to say something meaningful in mathematics."}, {"time": 1066, "text": "And it looks complicated to people, but it's far less complicated than what our brain is casually doing all the time when it makes sense of reality."}, {"time": 1072, "text": "And philosophy is coming from the top."}, {"time": 1078, "text": "So it's mostly starting from natural languages with vaguely defined concepts."}, {"time": 1083, "text": "And the hope is that mathematics and philosophy can meet at some point."}, {"time": 1083, "text": "And Wittgenstein was trying to make them meet."}, {"time": 1088, "text": "And he already understood that, for instance, you could express everything with the NAND calculus, that you could reduce the entire logic to NAND gates as we do in our modern computers."}, {"time": 1097, "text": "So in some sense, he already understood Turing universality before Turing spelled it out."}, {"time": 1102, "text": "I think when he wrote the Tractatus, he didn't understand yet that the idea was so important and significant."}, {"time": 1106, "text": "And I suspect then when Turing wrote it out, nobody cared that much."}, {"time": 1106, "text": "Turing was not that famous when he lived."}, {"time": 1112, "text": "It was mostly his work in decrypting the German codes that made him famous or gave him some notoriety."}, {"time": 1119, "text": "But this saint status that he has to computer science right now and the AI is something that I think he could acquire later."}, {"time": 1124, "text": "That's kind of interesting."}, {"time": 1124, "text": "Do you think of computation and computer science?"}, {"time": 1128, "text": "And you kind of represent that to me is maybe that's the modern day."}, {"time": 1133, "text": "You in a sense are the new philosopher by sort of the computer scientist who dares to ask the bigger questions that philosophy originally started is the new philosopher."}, {"time": 1146, "text": "Certainly not me."}, {"time": 1146, "text": "I think I'm mostly still this child that grows up in a very beautiful valley and looks at the world from the outside and tries to understand what's going on."}, {"time": 1156, "text": "And my teachers tell me things and they largely don't make sense."}, {"time": 1156, "text": "So I have to make my own models."}, {"time": 1160, "text": "I have to discover the foundations of what the others are saying."}, {"time": 1160, "text": "I have to try to fix them to be charitable."}, {"time": 1165, "text": "I try to understand what they must have thought originally or what their teachers or their teacher's teachers must have thought until everything got lost in translation and how to make sense of the reality that we are in."}, {"time": 1174, "text": "And whenever I have an original idea, I'm usually late to the party by say 400 years."}, {"time": 1178, "text": "And the only thing that's good is that the parties get smaller and smaller the older I get and the more I explore it."}, {"time": 1183, "text": "The parties get smaller and more exclusive and more exclusive."}, {"time": 1189, "text": "So it seems like one of the key qualities of your upbringing was that you were not tethered, whether it's because of your parents or in general, maybe something within your mind, some genetic material, you were not tethered to the ideas of the general populace, which is actually a unique property."}, {"time": 1207, "text": "We're kind of the education system and whatever, not education system, just existing in this world forces certain sets of ideas onto you."}, {"time": 1220, "text": "Can you disentangle that?"}, {"time": 1220, "text": "Why are you not so tethered?"}, {"time": 1220, "text": "Even in your work today, you seem to not care about perhaps a best paper in Europe, right?"}, {"time": 1228, "text": "Being tethered to particular things that current today in this year, people seem to value as a thing you put on your CV and resume."}, {"time": 1244, "text": "You're a little bit more outside of that world, outside of the world of ideas that people are especially focused in the benchmarks of today, the things."}, {"time": 1256, "text": "Because I think that's inspiring."}, {"time": 1256, "text": "And if there were more people like that, we might be able to solve some of the bigger problems that AI dreams to solve."}, {"time": 1265, "text": "And there's a big danger in this because in a way you are expected to marry into an intellectual tradition and visit this tradition into a particular school."}, {"time": 1270, "text": "If everybody comes up with their own paradigms, the whole thing is not cumulative as an enterprise."}, {"time": 1276, "text": "So in some sense, you need a healthy balance."}, {"time": 1282, "text": "You need paradigmatic thinkers and you need people that work within given paradigms."}, {"time": 1286, "text": "Basically, scientists today define themselves largely by methods."}, {"time": 1286, "text": "And it's almost a disease that we think as a scientist, as somebody who was convinced by their guidance counselor, that they should join a particular discipline and then they find a good mentor to learn the right methods."}, {"time": 1302, "text": "And then they are lucky enough and privileged enough to join the right team."}, {"time": 1302, "text": "And then their name will show up on influential papers."}, {"time": 1307, "text": "But we also see that there are diminishing returns with this approach."}, {"time": 1312, "text": "And when our field, computer science and AI started, most of the people that joined this field had interesting opinions."}, {"time": 1319, "text": "And today's thinkers in AI either don't have interesting opinions at all, or these opinions are inconsequential for what they're actually doing."}, {"time": 1328, "text": "Because what they're doing is they apply the state of the art methods with a small epsilon."}, {"time": 1333, "text": "And this is often a good idea if you think that this is the best way to make progress."}, {"time": 1333, "text": "And for me, it's first of all, very boring."}, {"time": 1341, "text": "If somebody else can do it, why should I do it?"}, {"time": 1341, "text": "If the current methods of machine learning lead to strong AI, why should I be doing it?"}, {"time": 1347, "text": "I will just wait until they're done and wait until they do this on the beach or read interesting books or write some and have fun."}, {"time": 1358, "text": "But if you don't think that we are currently doing the right thing, if we are missing some perspectives, then it's required to think outside of the box."}, {"time": 1365, "text": "It's also required to understand the boxes."}, {"time": 1371, "text": "But it's necessary to understand what worked and what didn't work and for what reasons."}, {"time": 1379, "text": "So you have to be willing to ask new questions and design new methods whenever you want to answer them."}, {"time": 1383, "text": "And you have to be willing to dismiss the existing methods if you think that they're not going to yield the right answers."}, {"time": 1389, "text": "It's very bad career advice to do that."}, {"time": 1389, "text": "So maybe to briefly stay for one more time in the early days, when would you say for you was the dream before we dive into the discussions that we just almost started, when was the dream to understand or maybe to create human level intelligence born for you?"}, {"time": 1415, "text": "I think that you can see AI largely today as advanced information processing."}, {"time": 1415, "text": "If you would change the acronym of AI into that, most people in the field would be happy."}, {"time": 1424, "text": "It would not change anything what they're doing."}, {"time": 1428, "text": "We're automating statistics and many of the statistical models are more advanced than what statisticians had in the past."}, {"time": 1434, "text": "And it's pretty good work."}, {"time": 1434, "text": "It's very productive."}, {"time": 1439, "text": "And the other aspect of AI is philosophical project."}, {"time": 1439, "text": "And this philosophical project is very risky and very few people work on it and it's not clear if it succeeds."}, {"time": 1450, "text": "So first of all, you keep throwing sort of a lot of really interesting ideas and I have to pick which ones we go with."}, {"time": 1456, "text": "But first of all, you use the term information processing, just information processing as if it's the mere, it's the muck of existence as if it's the epitome of existence, that the entirety of the universe might be information processing, that consciousness and intelligence might be information processing."}, {"time": 1476, "text": "So that maybe you can comment on if the advanced information processing is a limiting kind of a round of ideas."}, {"time": 1482, "text": "And then the other one is, what do you mean by the philosophical project?"}, {"time": 1488, "text": "So I suspect that general intelligence is the result of trying to solve general problems."}, {"time": 1494, "text": "So intelligence, I think, is the ability to model."}, {"time": 1500, "text": "It's not necessarily goal directed rationality or something."}, {"time": 1500, "text": "Many intelligent people are bad at this, but it's the ability to be presented with a number of patterns and see a structure in those patterns and be able to predict the next set of patterns, to make sense of things."}, {"time": 1512, "text": "And some problems are very general."}, {"time": 1517, "text": "Usually intelligence serves control, so you make these models for a particular purpose of interacting as an agent with the world and getting certain results."}, {"time": 1526, "text": "But the intelligence itself is in the sense instrumental to something, but by itself it's just the ability to make models."}, {"time": 1531, "text": "And some of the problems are so general that the system that makes them needs to understand what itself is and how it relates to the environment."}, {"time": 1536, "text": "So as a child, for instance, you notice you do certain things despite you perceiving yourself as wanting different things."}, {"time": 1547, "text": "So you become aware of your own psychology."}, {"time": 1547, "text": "You become aware of the fact that you have complex structure in yourself and you need to model yourself, to reverse engineer yourself, to be able to predict how you will react to certain situations and how you deal with yourself in relationship to your environment."}, {"time": 1562, "text": "And this process, this project, if you reverse engineer yourself and your relationship to reality and the nature of a universe that can continue, if you go all the way, this is basically the project of AI, or you could say the project of AI is a very important component in it."}, {"time": 1577, "text": "The Turing test, in a way, is you ask a system, what is intelligence?"}, {"time": 1584, "text": "If that system is able to explain what it is, how it works, then you should assign it the property of being intelligent in this general sense."}, {"time": 1592, "text": "So the test that Turing was administering in a way, I don't think that he couldn't see it, but he didn't express it yet in the original 1950 paper, is that he was trying to find out whether he was generally intelligent."}, {"time": 1601, "text": "Because in order to take this test, the rub is, of course, you need to be able to understand what that system is saying."}, {"time": 1611, "text": "And we don't yet know if we can build an AI."}, {"time": 1611, "text": "We don't yet know if we are generally intelligent."}, {"time": 1616, "text": "Basically, you win the Turing test by building an AI."}, {"time": 1616, "text": "So in a sense, hidden within the Turing test is a kind of recursive test."}, {"time": 1623, "text": "Yes, it's a test on us."}, {"time": 1623, "text": "The Turing test is basically a test of the conjecture, whether people are intelligent enough to understand themselves."}, {"time": 1634, "text": "But you also mentioned a little bit of a self awareness and then the project of AI."}, {"time": 1638, "text": "Do you think this kind of emergent self awareness is one of the fundamental aspects of intelligence?"}, {"time": 1645, "text": "So as opposed to goal oriented, as you said, kind of puzzle solving, is coming to grips with the idea that you're an agent in the world."}, {"time": 1657, "text": "I find that many highly intelligent people are not very self aware, right?"}, {"time": 1657, "text": "So self awareness and intelligence are not the same thing."}, {"time": 1662, "text": "And you can also be self aware if you have good priors, especially, without being especially intelligent."}, {"time": 1667, "text": "So you don't need to be very good at solving puzzles if the system that you are already implements the solution."}, {"time": 1676, "text": "But I do find intelligence, you kind of mentioned children, right?"}, {"time": 1676, "text": "Is that the fundamental project of AI is to create the learning system that's able to exist in the world."}, {"time": 1683, "text": "So you kind of drew a difference between self awareness and intelligence."}, {"time": 1691, "text": "And yet you said that the self awareness seems to be important for children."}, {"time": 1698, "text": "So I call this ability to make sense of the world and your own place in it."}, {"time": 1703, "text": "So to make you able to understand what you're doing in this world, sentience."}, {"time": 1708, "text": "And I would distinguish sentience from intelligence because sentience is possessing certain classes of models."}, {"time": 1714, "text": "And intelligence is a way to get to these models if you don't already have them."}, {"time": 1719, "text": "So can you maybe pause a bit and try to answer the question that we just said we may not be able to answer?"}, {"time": 1727, "text": "And it might be a recursive meta question of what is intelligence?"}, {"time": 1733, "text": "I think that intelligence is the ability to make models."}, {"time": 1739, "text": "So models."}, {"time": 1739, "text": "I think it's useful as examples."}, {"time": 1739, "text": "Very popular now."}, {"time": 1739, "text": "Neural networks form representations of a large scale data set."}, {"time": 1748, "text": "They form models of those data sets."}, {"time": 1748, "text": "When you say models and look at today's neural networks, what are the difference of how you're thinking about what is intelligent in saying that intelligence is the process of making models?"}, {"time": 1762, "text": "Two aspects to this question."}, {"time": 1762, "text": "One is the representation."}, {"time": 1769, "text": "Is the representation adequate for the domain that we're talking about?"}, {"time": 1773, "text": "Is the representation adequate for the domain that we want to represent?"}, {"time": 1779, "text": "The other one is the type of the model that you arrive at adequate."}, {"time": 1779, "text": "So basically, are you modeling the correct domain?"}, {"time": 1785, "text": "I think in both of these cases, modern AI is lacking still."}, {"time": 1785, "text": "I think that I'm not saying anything new here."}, {"time": 1793, "text": "I'm not criticizing the field."}, {"time": 1793, "text": "Most of the people that design our paradigms are aware of that."}, {"time": 1798, "text": "One aspect that we're missing is unified learning."}, {"time": 1805, "text": "When we learn, we at some point discover that everything that we sense is part of the same object, which means we learn it all into one model and we call this model the universe."}, {"time": 1814, "text": "So the experience of the world that we are embedded on is not a secret direct via to physical reality."}, {"time": 1819, "text": "Physical reality is a weird quantum graph that we can never experience or get access to."}, {"time": 1824, "text": "But it has these properties that it can create certain patterns that are systemic interface to the world."}, {"time": 1829, "text": "And we make sense of these patterns and the relationship between the patterns that we discover is what we call the physical universe."}, {"time": 1833, "text": "So at some point in our development as a nervous system, we discover that everything that we relate to in the world can be mapped to a region in the same three dimensional space, by and large."}, {"time": 1847, "text": "We now know in physics that this is not quite true."}, {"time": 1852, "text": "The world is not actually three dimensional, but the world that we are entangled with at the level which we are entangled with is largely a flat three dimensional space."}, {"time": 1856, "text": "And so this is the model that our brain is intuitively making."}, {"time": 1862, "text": "And this is, I think, what gave rise to this intuition of res extensa of this material world, this material domain."}, {"time": 1867, "text": "It's one of the mental domains, but it's just the class of all models that relate to this environment, this three dimensional physics engine in which we are embedded."}, {"time": 1877, "text": "Physics engine which we're embedded."}, {"time": 1877, "text": "Just slowly pause."}, {"time": 1882, "text": "So the quantum graph, I think you called it, which is the real world, which you can never get access to, there's a bunch of questions I want to sort of disentangle that."}, {"time": 1897, "text": "But maybe one useful one, one of your recent talks I looked at, can you just describe the basics?"}, {"time": 1903, "text": "Can you talk about what is dualism?"}, {"time": 1903, "text": "What is idealism?"}, {"time": 1903, "text": "What is materialism?"}, {"time": 1903, "text": "What is functionalism?"}, {"time": 1909, "text": "And what connects with you most in terms of, because you just mentioned there's a reality we don't have access to."}, {"time": 1913, "text": "What does that even mean?"}, {"time": 1913, "text": "And why don't we get access to it?"}, {"time": 1920, "text": "Aren't we part of that reality?"}, {"time": 1920, "text": "Why can't we access it?"}, {"time": 1920, "text": "So the particular trajectory that mostly exists in the West is the result of our indoctrination by a cult for 2000 years."}, {"time": 1931, "text": "A cult?"}, {"time": 1931, "text": "Oh, 2000 years."}, {"time": 1931, "text": "The Catholic cult mostly."}, {"time": 1931, "text": "And for better or worse, it has created or defined many of the modes of interaction that we have that has created the society."}, {"time": 1940, "text": "But it has also in some sense scarred our rationality."}, {"time": 1940, "text": "And the intuition that exists, if you would translate the mythology of the Catholic church into the modern world is that the world in which you and me interact is something like a multiplayer role playing adventure."}, {"time": 1955, "text": "And the money and the objects that we have in this world, this is all not real."}, {"time": 1961, "text": "Or as Eastern philosophers would say, it's Maya."}, {"time": 1968, "text": "It's just stuff that appears to be meaningful."}, {"time": 1968, "text": "And this embedding in this meaning, if you believe in it, is samsara."}, {"time": 1974, "text": "It's basically the identification with the needs of the mundane, secular, everyday existence."}, {"time": 1980, "text": "And the Catholics also introduced the notion of higher meaning, the sacred."}, {"time": 1986, "text": "And this existed before, but eventually the natural shape of God is the Platonic form of the civilization that you're part of."}, {"time": 1992, "text": "It's basically the superorganism that is formed by the individuals as an intentional agent."}, {"time": 1997, "text": "And basically, the Catholics used a relatively crude mythology to implement software on the minds of people and get the software synchronized to make them walk on lockstep, to basically get this God online and to make it efficient and effective."}, {"time": 2014, "text": "And I think God technically is just a self that spends multiple brains as opposed to your and my self, which mostly exists just on one brain."}, {"time": 2025, "text": "And so in some sense, you can construct a self functionally as a function is implemented by brains that exists across brains."}, {"time": 2030, "text": "And this is a God with a small g. That's one of the, if you, Yuval Harari kind of talking about, this is one of the nice features of our brains."}, {"time": 2039, "text": "It seems to that we can all download the same piece of software like God in this case and kind of share it."}, {"time": 2047, "text": "So basically you give everybody a spec and the mathematical constraints that are intrinsic to information processing, make sure that given the same spec, you come up with a compatible structure."}, {"time": 2060, "text": "So that's, there's the space of ideas that we all share."}, {"time": 2060, "text": "And we think that's kind of the mind, but that's separate from the idea is from Christianity for, from religion is that there's a separate thing between the mind."}, {"time": 2075, "text": "There is a real world."}, {"time": 2075, "text": "And this real world is the world in which God exists."}, {"time": 2079, "text": "God is the coder of the multiplayer adventure, so to speak."}, {"time": 2079, "text": "And we are all players in this game."}, {"time": 2085, "text": "And that's dualism."}, {"time": 2087, "text": "But the aspect is because the mental realm exists in a different implementation than the physical realm."}, {"time": 2093, "text": "And the mental realm is real."}, {"time": 2093, "text": "And a lot of people have this intuition that there is this real room in which you and me talk and speak right now, then comes a layer of physics and abstract rules and so on."}, {"time": 2104, "text": "And then comes another real room where our souls are and our true form isn't a thing that gives us phenomenal experience."}, {"time": 2110, "text": "And this is, of course, a very confused notion that you would get."}, {"time": 2114, "text": "And it's basically, it's the result of connecting materialism and idealism in the wrong way."}, {"time": 2124, "text": "I apologize, but I think it's really helpful if we just try to define, try to define terms."}, {"time": 2130, "text": "Like what is dualism?"}, {"time": 2130, "text": "For people that don't know."}, {"time": 2134, "text": "So the idea of dualism in our cultural tradition is that there are two substances, a mental substance and a physical substance."}, {"time": 2140, "text": "And they interact by different rules."}, {"time": 2140, "text": "And the physical world is basically causally closed and is built on a low level causal structure."}, {"time": 2146, "text": "So they're basically a bottom level that is causally closed."}, {"time": 2151, "text": "That's entirely mechanical and mechanical in the widest sense."}, {"time": 2156, "text": "So it's computational."}, {"time": 2156, "text": "There's basically a physical world in which information flows around and physics describes the laws of how information flows around in this world."}, {"time": 2166, "text": "Would you compare it to like a computer where you have hardware and software?"}, {"time": 2170, "text": "The computer is a generalization of information flowing around."}, {"time": 2170, "text": "Basically, but if you want to discover that there is a universal principle, you can define this universal machine that is able to perform all the computations."}, {"time": 2177, "text": "So all these machines have the same power."}, {"time": 2183, "text": "This means that you can always define a translation between them, as long as they have unlimited memory to be able to perform each other's computations."}, {"time": 2193, "text": "So would you then say that materialism is this whole world is just the hardware and idealism is this whole world is just the software?"}, {"time": 2200, "text": "I think that most idealists don't have a notion of software yet because software also comes down to information processing."}, {"time": 2206, "text": "So what you notice is the only thing that is real to you and me is this experiential world in which things matter, in which things have taste, in which things have color, phenomenal content, and so on."}, {"time": 2220, "text": "You are bringing up consciousness."}, {"time": 2222, "text": "This is distinct from the physical world in which things have values only in an abstract sense."}, {"time": 2227, "text": "And you only look at cold patterns moving around."}, {"time": 2227, "text": "So how does anything feel like something?"}, {"time": 2235, "text": "And this connection between the two things is very puzzling to a lot of people, of course, too many philosophers."}, {"time": 2239, "text": "So idealism starts out with the notion that mind is primary, materialism, things that matter is primary."}, {"time": 2243, "text": "And so for the idealist, the material patterns that we see playing out are part of the dream that the mind is dreaming."}, {"time": 2250, "text": "And we exist in a mind on a higher plane of existence, if you want."}, {"time": 2257, "text": "And for the materialist, there is only this material thing, and that generates some models, and we are the result of these models."}, {"time": 2263, "text": "And in some sense, I don't think that we should understand, if we understand it properly, materialism and idealism as a dichotomy, but as two different aspects of the same thing."}, {"time": 2279, "text": "So the weird thing is we don't exist in the physical world."}, {"time": 2279, "text": "We do exist inside of a story that the brain tells itself."}, {"time": 2284, "text": "Let my information processing take that in."}, {"time": 2295, "text": "We don't exist in the physical world."}, {"time": 2295, "text": "We exist in the narrative."}, {"time": 2298, "text": "Basically, a brain cannot feel anything."}, {"time": 2298, "text": "A neuron cannot feel anything."}, {"time": 2298, "text": "They're physical things."}, {"time": 2302, "text": "Physical systems are unable to experience anything."}, {"time": 2302, "text": "But it would be very useful for the brain or for the organism to know what it would be like to be a person and to feel something."}, {"time": 2310, "text": "So the brain creates a simulacrum of such a person that it uses to model the interactions of the person."}, {"time": 2316, "text": "It's the best model of what that brain, this organism thinks it is in relationship to its environment."}, {"time": 2321, "text": "So it creates that model."}, {"time": 2321, "text": "It's a story, a multimedia novel that the brain is continuously writing and updating."}, {"time": 2326, "text": "But you also kind of said that you said that we kind of exist in that story."}, {"time": 2333, "text": "In that story."}, {"time": 2333, "text": "What is real in any of this?"}, {"time": 2333, "text": "So again, these terms are... You kind of said there's a quantum graph."}, {"time": 2344, "text": "I mean, what is this whole thing running on then?"}, {"time": 2344, "text": "Is the story... And is it completely fundamentally impossible to get access to it?"}, {"time": 2351, "text": "Because isn't the story supposed to..."}, {"time": 2356, "text": "Isn't the brain in something existing in some kind of context?"}, {"time": 2364, "text": "So what we can identify as computer scientists, we can engineer systems and test our theories this way that might have the necessary insufficient properties to produce the phenomena that we are observing, which is the self in a virtual world that is generated in somebody's neocortex that is contained in the skull of this primate here."}, {"time": 2384, "text": "And when I point at this, this indexicality is of course wrong."}, {"time": 2388, "text": "But I do create something that is likely to give rise to patterns on your retina that allow you to interpret what I'm saying."}, {"time": 2395, "text": "But we both know that the world that you and me are seeing is not the real physical world."}, {"time": 2400, "text": "What we are seeing is a virtual reality generated in your brain to explain the patterns on your retina."}, {"time": 2405, "text": "How close is it to the real world?"}, {"time": 2405, "text": "That's kind of the question."}, {"time": 2410, "text": "Is it when you have people like Donald Hoffman that say that you're really far away."}, {"time": 2418, "text": "The thing we're seeing, you and I now, that interface we have is very far away from anything."}, {"time": 2424, "text": "We don't even have anything close to the sense of what the real world is."}, {"time": 2424, "text": "Or is it a very surface piece of architecture?"}, {"time": 2429, "text": "I imagine you look at the Mandelbrot fractal, this famous thing that Bernard Mandelbrot discovered."}, {"time": 2435, "text": "You see an overall shape in there."}, {"time": 2435, "text": "But if you truly understand it, you know it's two lines of code."}, {"time": 2443, "text": "It's basically in a series that is being tested for complex numbers in the complex number plane for every point."}, {"time": 2450, "text": "And for those where the series is diverging, you paint this black."}, {"time": 2456, "text": "And where it's converging, you don't."}, {"time": 2456, "text": "And you get the intermediate colors by taking how far it diverges."}, {"time": 2464, "text": "This gives you this shape of this fractal."}, {"time": 2464, "text": "But imagine you live inside of this fractal and you don't have access to where you are in the fractal."}, {"time": 2473, "text": "Or you have not discovered the generator function even."}, {"time": 2478, "text": "So what you see is, all I can see right now is a spiral."}, {"time": 2483, "text": "And this spiral moves a little bit to the right."}, {"time": 2483, "text": "Is this an accurate model of reality?"}, {"time": 2488, "text": "It is an adequate description."}, {"time": 2488, "text": "You know that there is actually no spiral in the Mandelbrot fractal."}, {"time": 2493, "text": "It only appears like this to an observer that is interpreting things as a two dimensional space and then defines certain regularities in there at a certain scale that it currently observes."}, {"time": 2499, "text": "Because if you zoom in, the spiral might disappear and turn out to be something different at a different resolution."}, {"time": 2507, "text": "So at this level, you have the spiral."}, {"time": 2507, "text": "And then you discover the spiral moves to the right and at some point it disappears."}, {"time": 2512, "text": "So you have a singularity."}, {"time": 2512, "text": "At this point, your model is no longer valid."}, {"time": 2516, "text": "You cannot predict what happens beyond the singularity."}, {"time": 2516, "text": "But you can observe again and you will see it hit another spiral and at this point it disappeared."}, {"time": 2521, "text": "So we now have a second order law."}, {"time": 2526, "text": "And if you make 30 layers of these laws, then you have a description of the world that is similar to the one that we come up with when we describe the reality around us."}, {"time": 2534, "text": "It's reasonably predictive."}, {"time": 2534, "text": "It does not cut to the core of it."}, {"time": 2534, "text": "It does not explain how it's being generated, how it actually works."}, {"time": 2539, "text": "But it's relatively good to explain the universe that we are entangled with."}, {"time": 2544, "text": "But you don't think the tools of computer science, the tools of physics could get, could step outside, see the whole drawing and get at the basic mechanism of how the pattern, the spirals are generated."}, {"time": 2555, "text": "Imagine you would find yourself embedded into a motherboard fractal and you try to figure out what works and you somehow have a Turing machine with enough memory to think."}, {"time": 2566, "text": "And as a result, you come to this idea, it must be some kind of automaton."}, {"time": 2566, "text": "And maybe you just enumerate all the possible automata until you get to the one that produces your reality."}, {"time": 2576, "text": "So you can identify necessary and sufficient condition."}, {"time": 2576, "text": "For instance, we discover that mathematics itself is the domain of all languages."}, {"time": 2579, "text": "And then we see that most of the domains of mathematics that we have discovered are in some sense describing the same fractals."}, {"time": 2590, "text": "This is what category theory is obsessed about, that you can map these different domains to each other."}, {"time": 2594, "text": "So they're not that many fractals."}, {"time": 2594, "text": "And some of these have interesting structure and symmetry breaks."}, {"time": 2599, "text": "And so you can discover what region of this global fractal you might be embedded in from first principles."}, {"time": 2606, "text": "But the only way you can get there is from first principles."}, {"time": 2606, "text": "So basically your understanding of the universe has to start with automata and then number theory and then spaces and so on."}, {"time": 2615, "text": "I think like Stephen Wolfram still dreams that he'll be able to arrive at the fundamental rules of the cellular automata or the generalization of which is behind our universe."}, {"time": 2626, "text": "You've said on this topic, you said in a recent conversation that quote, some people think that a simulation can't be conscious and only a physical system can, but they got it completely backward."}, {"time": 2640, "text": "A physical system cannot be conscious."}, {"time": 2640, "text": "Only a simulation can be conscious."}, {"time": 2645, "text": "Consciousness is a simulated property that simulates itself."}, {"time": 2645, "text": "Just like you said, the mind is kind of the, we'll call it story narrative."}, {"time": 2651, "text": "There's a simulation."}, {"time": 2651, "text": "So our mind is essentially a simulation."}, {"time": 2657, "text": "Usually I try to use the terminology so that the mind is basically a principles that produce the simulation."}, {"time": 2664, "text": "It's the software that is implemented by your brain."}, {"time": 2669, "text": "And the mind is creating both the universe that we are in and the self, the idea of a person that is on the other side of attention and is embedded in this world."}, {"time": 2676, "text": "Why is that important that idea of a self, why is that an important feature in the simulation?"}, {"time": 2681, "text": "It's basically a result of the purpose that the mind has."}, {"time": 2688, "text": "It's a tool for modeling, right?"}, {"time": 2688, "text": "We are not actually monkeys."}, {"time": 2688, "text": "We are side effects of the regulation needs of monkeys."}, {"time": 2693, "text": "And what the monkey has to regulate is the relationship of an organism to an outside world that is in large part also consisting of other organisms."}, {"time": 2706, "text": "And as a result, it basically has regulation targets that it tries to get to."}, {"time": 2712, "text": "These regulation targets start with priors."}, {"time": 2712, "text": "They're basically like unconditional reflexes that we are more or less born with."}, {"time": 2716, "text": "And then we can reverse engineer them to make them more consistent."}, {"time": 2720, "text": "And then we get more detailed models about how the world works and how to interact with it."}, {"time": 2724, "text": "And so these priors that you commit to are largely target values that our needs should approach set points."}, {"time": 2731, "text": "And this deviation to the set point creates some urge, some tension."}, {"time": 2731, "text": "And we find ourselves living inside of feedback loops, right?"}, {"time": 2738, "text": "Consciousness emerges over dimensions of disagreements with the universe, things that you care, things are not the way they should be, but you need to regulate."}, {"time": 2748, "text": "And so in some sense, the sense self is the result of all the identifications that you're having."}, {"time": 2752, "text": "And that identification is a regulation target that you're committing to."}, {"time": 2756, "text": "It's a dimension that you care about, you think is important."}, {"time": 2756, "text": "And this is also what locks you in."}, {"time": 2761, "text": "If you let go of these commitments, of these identifications, you get free."}, {"time": 2767, "text": "There's nothing that you have to do anymore."}, {"time": 2767, "text": "And if you let go of all of them, you're completely free and you can enter nirvana because you're done."}, {"time": 2777, "text": "I wanted to give him a shout out."}, {"time": 2783, "text": "He's a brilliant guy."}, {"time": 2783, "text": "And I think the AI community is actually quite amazing."}, {"time": 2783, "text": "And Gustav is a good representative of that."}, {"time": 2789, "text": "You are as well."}, {"time": 2789, "text": "So I'm glad, first of all, I'm glad the internet exists, YouTube exists, where I can watch your talks and then get to your book and study your writing and think about, you know, that's amazing."}, {"time": 2800, "text": "But you've kind of described sort of this emergent phenomenon of consciousness from the simulation."}, {"time": 2806, "text": "So what about the hard problem of consciousness?"}, {"time": 2812, "text": "Can you just linger on it?"}, {"time": 2812, "text": "Why does it still feel like, I understand you're kind of, the self is an important part of the simulation, but why does the simulation feel like something?"}, {"time": 2828, "text": "So if you look at a book by, say, George R. R. Martin, where the characters have plausible psychology and they stand on a hill because they want to conquer the city below the hill and they're done in it."}, {"time": 2839, "text": "And they look at the color of the sky and they are apprehensive and feel empowered and all these things."}, {"time": 2844, "text": "Why do they have these emotions?"}, {"time": 2844, "text": "It's because it's written into the story, right?"}, {"time": 2847, "text": "And it's written to the story because there's an adequate model of the person that predicts what they're going to do next."}, {"time": 2852, "text": "And the same thing is true for us."}, {"time": 2852, "text": "So it's basically a story that our brain is writing."}, {"time": 2857, "text": "It's not written in words."}, {"time": 2857, "text": "It's written in perceptual content, basically multimedia content."}, {"time": 2863, "text": "And it's a model of what the person would feel if it existed."}, {"time": 2870, "text": "So it's a virtual person."}, {"time": 2870, "text": "And you and me happen to be this virtual person."}, {"time": 2870, "text": "So this virtual person gets access to the language center and talks about the sky being blue."}, {"time": 2876, "text": "And this is us."}, {"time": 2881, "text": "But hold on a second."}, {"time": 2881, "text": "Do I exist in your simulation?"}, {"time": 2885, "text": "You do exist in an almost similar way as me."}, {"time": 2885, "text": "So there are internal states that are less accessible for me that you have and so on."}, {"time": 2893, "text": "And my model might not be completely adequate."}, {"time": 2900, "text": "There are also things that I might perceive about you that you don't perceive."}, {"time": 2900, "text": "But in some sense, both you and me are some puppets, two puppets that enact a play in my mind."}, {"time": 2905, "text": "And I identify with one of them because I can control one of the puppets directly."}, {"time": 2911, "text": "And with the other one, I can create things in between."}, {"time": 2916, "text": "So for instance, we can go on an interaction that even leads to a coupling to a feedback loop."}, {"time": 2921, "text": "So we can think things together in a certain way or feel things together."}, {"time": 2926, "text": "But this coupling is itself not a physical phenomenon."}, {"time": 2926, "text": "It's entirely a software phenomenon."}, {"time": 2930, "text": "It's the result of two different implementations interacting with each other."}, {"time": 2934, "text": "So are you suggesting, like the way you think about it, is the entirety of existence a simulation and where kind of each mind is a little subsimulation, that like, why don't you, why doesn't your mind have access to my mind's full state?"}, {"time": 2958, "text": "Like, for the same reason that my mind doesn't have access to its own full state."}, {"time": 2962, "text": "So what, I mean, There is no trick involved."}, {"time": 2965, "text": "So basically, when I know something about myself, it's because I made a model."}, {"time": 2969, "text": "So one part of your brain is tasked with modeling what other parts of your brain are doing."}, {"time": 2975, "text": "But there seems to be an incredible consistency about this world in the physical sense that there's repeatable experiments and so on."}, {"time": 2980, "text": "How does that fit into our silly, the center of apes simulation of the world?"}, {"time": 2986, "text": "So why is it so repeatable?"}, {"time": 2986, "text": "Why is everything so repeatable?"}, {"time": 2990, "text": "And not everything."}, {"time": 2990, "text": "There's a lot of fundamental physics experiments that are repeatable for a long time, all over the place and so on."}, {"time": 2999, "text": "Laws of physics."}, {"time": 2999, "text": "How does that fit in?"}, {"time": 3005, "text": "It seems that the parts of the world that are not deterministic are not long lived."}, {"time": 3010, "text": "So if you build a system, any kind of automaton, so if you build simulations of something, you'll notice that the phenomena that endure are those that give rise to stable dynamics."}, {"time": 3023, "text": "So basically, if you see anything that is complex in the world, it's the result of usually of some control of some feedback that keeps it stable around certain attractors."}, {"time": 3028, "text": "And the things that are not stable that don't give rise to certain harmonic patterns and so on, they tend to get weeded out over time."}, {"time": 3037, "text": "So if we are in a region of the universe that sustains complexity, which is required to implement minds like ours, this is going to be a region of the universe that is very tightly controlled and controllable."}, {"time": 3050, "text": "So it's going to have lots of interesting symmetries and also symmetry breaks that allow the creation of structure."}, {"time": 3055, "text": "But they exist where?"}, {"time": 3055, "text": "So there's such an interesting idea that our mind is simulation that's constructing the narrative."}, {"time": 3066, "text": "But my question is, just to try to understand how that fits with this, with the entirety of the universe, you're saying that there's a region of this universe that allows enough complexity to create creatures like us."}, {"time": 3079, "text": "But what's the connection between the brain, the mind, and the broader universe?"}, {"time": 3087, "text": "Which comes first?"}, {"time": 3087, "text": "Which is more fundamental?"}, {"time": 3087, "text": "Is the mind the starting point, the universe is emergent?"}, {"time": 3092, "text": "Is the universe the starting point, the minds are emergent?"}, {"time": 3097, "text": "I think quite clearly the latter."}, {"time": 3097, "text": "That's at least a much easier explanation because it allows us to make causal models."}, {"time": 3102, "text": "And I don't see any way to construct an inverse causality."}, {"time": 3107, "text": "So what happens when you die to your mind simulation?"}, {"time": 3111, "text": "My implementation ceases."}, {"time": 3111, "text": "So basically the thing that implements myself will no longer be present, which means if I am not implemented on the minds of other people, the thing that I identify with, the weird thing is I don't actually have an identity beyond the identity that I construct."}, {"time": 3127, "text": "If I was the Dalai Lama, he identifies as a form of government."}, {"time": 3127, "text": "So basically the Dalai Lama gets reborn, not because he's confused, but because he is not identifying as a human being."}, {"time": 3134, "text": "He runs on a human being."}, {"time": 3141, "text": "He's basically a governmental software that is instantiated in every new generation and you."}, {"time": 3147, "text": "So his advice is to pick someone who does this in the next generation."}, {"time": 3151, "text": "So if you identify with this, you are no longer a human and you don't die in the sense that what dies is only the body of the human that you run on."}, {"time": 3157, "text": "To kill the Dalai Lama, you would have to kill his tradition."}, {"time": 3162, "text": "And if we look at ourselves, we realize that we are to a small part like this, most of us."}, {"time": 3168, "text": "So for instance, if you have children, you realize something lives on in them."}, {"time": 3168, "text": "Or if you spark an idea in the world, something lives on, or if you identify with the society around you, because you are in part that you're not just this human being."}, {"time": 3181, "text": "So in a sense, you are kind of like a Dalai Lama in the sense that you, Joshua Bach, is just a collection of ideas."}, {"time": 3187, "text": "So like you have this operating system on which a bunch of ideas live and interact."}, {"time": 3192, "text": "And then once you die, they kind of part, some of them jump off the ship."}, {"time": 3198, "text": "You put it put it the other way."}, {"time": 3198, "text": "Identity is a software state."}, {"time": 3198, "text": "It's a construction."}, {"time": 3203, "text": "It's not physically real."}, {"time": 3203, "text": "Identity is not a physical concept."}, {"time": 3207, "text": "It's basically a representation of different objects on the same world line."}, {"time": 3212, "text": "But identity lives and dies."}, {"time": 3212, "text": "Are you attached?"}, {"time": 3212, "text": "What's the fundamental thing?"}, {"time": 3212, "text": "Is it the ideas that come together to form identity?"}, {"time": 3221, "text": "Or is each individual identity actually a fundamental thing?"}, {"time": 3226, "text": "It's a representation that you can get agency over if you care."}, {"time": 3226, "text": "So basically, you can choose what you identify with if you want to."}, {"time": 3233, "text": "No, but it just seems if the mind is not real, that the birth and death is not a crucial part of it."}, {"time": 3244, "text": "Well, maybe I'm silly."}, {"time": 3244, "text": "Maybe I'm attached to this whole biological organism."}, {"time": 3244, "text": "But it seems that being a physical object in this world is an important aspect of birth and death."}, {"time": 3263, "text": "Like it feels like it has to be physical to die."}, {"time": 3263, "text": "It feels like simulations don't have to die."}, {"time": 3270, "text": "The physics that we experience is not the real physics."}, {"time": 3270, "text": "There is no color and sound in the real world."}, {"time": 3274, "text": "Color and sound are types of representations that you get if you want to model reality with oscillators."}, {"time": 3280, "text": "So colors and sound in some sense have octaves, and it's because they are represented probably with oscillators."}, {"time": 3285, "text": "So that's why colors form a circle of use."}, {"time": 3285, "text": "And colors have harmonics, sounds have harmonics as a result of synchronizing oscillators in the brain."}, {"time": 3292, "text": "So the world that we subjectively interact with is fundamentally the result of the representation mechanisms in our brain."}, {"time": 3303, "text": "They are mathematically to some degree universal."}, {"time": 3303, "text": "There are certain regularities that you can discover in the patterns and not others."}, {"time": 3308, "text": "But the patterns that we get, this is not the real world."}, {"time": 3312, "text": "The world that we interact with is always made of too many parts to count."}, {"time": 3312, "text": "So when you look at this table and so on, it's consisting of so many molecules and atoms that you cannot count them."}, {"time": 3323, "text": "So you only look at the aggregate dynamics, at limit dynamics."}, {"time": 3323, "text": "If you had almost infinitely many particles, what would be the dynamics of the table?"}, {"time": 3329, "text": "And this is roughly what you get."}, {"time": 3329, "text": "So geometry that we are interacting with is the result of discovering those operators that work in the limit that you get by building an infinite series that converges."}, {"time": 3339, "text": "For those parts where it converges, it's geometry."}, {"time": 3344, "text": "For those parts where it doesn't converge, it's chaos."}, {"time": 3348, "text": "And then so all of that is filtered through the consciousness that's emergent in our narrative."}, {"time": 3355, "text": "The consciousness gives it color, gives it feeling, gives it flavor."}, {"time": 3360, "text": "So I think the feeling, flavor and so on is given by the relationship that a feature has to all the other features."}, {"time": 3366, "text": "It's basically a giant relational graph that is our subjective universe."}, {"time": 3366, "text": "The color is given by those aspects of the representation or this experiential color where you care about, where you have identifications, where something means something, where you are the inside of a feedback loop."}, {"time": 3382, "text": "And the dimensions of caring are basically dimensions of this motivational system that we emerge over."}, {"time": 3388, "text": "The meaning of the relations, the graph."}, {"time": 3388, "text": "Can you elaborate on that a little bit?"}, {"time": 3394, "text": "Like where does the, maybe we can even step back and ask the question of what is consciousness to be sort of more systematic."}, {"time": 3401, "text": "Like what do you, how do you think about consciousness?"}, {"time": 3407, "text": "I think that consciousness is largely a model of the contents of your attention."}, {"time": 3407, "text": "It's a mechanism that has evolved for a certain type of learning."}, {"time": 3412, "text": "At the moment, our machine learning systems largely work by building chains of weighted sums of real numbers with some nonlinearity."}, {"time": 3425, "text": "And you learn by piping an error signal through these different chained layers and adjusting the weights in these weighted sums."}, {"time": 3433, "text": "And you can approximate most polynomials with this if you have enough training data."}, {"time": 3439, "text": "But the price is you need to change a lot of these weights."}, {"time": 3444, "text": "Basically, the error is piped backwards into the system until it accumulates at certain junctures in the network."}, {"time": 3450, "text": "And everything else evens out statistically."}, {"time": 3450, "text": "And only at these junctures, this is where you had the actual error in the network, you make the change there."}, {"time": 3454, "text": "This is a very slow process."}, {"time": 3458, "text": "And our brains don't have enough time for that because we don't get old enough to play Go the way that our machines learn to play Go."}, {"time": 3462, "text": "So instead, what we do is an attention based learning."}, {"time": 3467, "text": "We pinpoint the probable region in the network where we can make an improvement."}, {"time": 3472, "text": "And then we store this binding state together with the expected outcome in a protocol."}, {"time": 3478, "text": "And this ability to make index memories for the purpose of learning to revisit these commitments later, this requires a memory of the contents of our attention."}, {"time": 3490, "text": "Another aspect is when I construct my reality, I make mistakes."}, {"time": 3490, "text": "So I see things that turn out to be reflections or shadows and so on, which means I have to be able to point out which features of my perception gave rise to a present construction of reality."}, {"time": 3500, "text": "So the system needs to pay attention to the features that are currently in its focus."}, {"time": 3508, "text": "And it also needs to pay attention to whether it pays attention itself, in part because the attentional system gets trained with the same mechanism, so it's reflexive, but also in part because your attention lapses if you don't pay attention to the attention itself."}, {"time": 3521, "text": "So it's the thing that I'm currently seeing, just a dream that my brain has spun off into some kind of daydream, or am I still paying attention to my percept?"}, {"time": 3532, "text": "So you have to periodically go back and see whether you're still paying attention."}, {"time": 3532, "text": "And if you have this loop and you make it tight enough between the system becoming aware of the contents of its attention and the fact that it's paying attention itself and makes attention the object of its attention, I think this is the loop over which we wake up."}, {"time": 3545, "text": "So there's this attentional mechanism that's somehow self referential that's fundamental to what consciousness is."}, {"time": 3552, "text": "So just ask you a question, I don't know how much you're familiar with the recent breakthroughs in natural language processing, they use attentional mechanism, they use something called transformers to learn patterns and sentences by allowing the network to focus its attention to particular parts of the sentence and each individual."}, {"time": 3577, "text": "So like parameterize and make it learnable the dynamics of a sentence by having like a little window into the sentence."}, {"time": 3582, "text": "Do you think that's like a little step towards that eventually will take us to the attentional mechanisms from which consciousness can emerge?"}, {"time": 3598, "text": "I think it models only one aspect of attention."}, {"time": 3603, "text": "In the early days of automated language translation, there was an example that I found particularly funny where somebody tried to translate a text from English into German and it was a bat broke the window."}, {"time": 3613, "text": "And the translation in German was to translate back into English a bat, this flying mammal broke the window with a baseball bat."}, {"time": 3631, "text": "And it seemed to be the most similar to this program because it somehow maximized the possibility of translating the concept bat into German in the same sentence."}, {"time": 3639, "text": "And this is a mistake that the transformer model is not doing because it's tracking identity."}, {"time": 3645, "text": "And the attentional mechanism in the transformer model is basically putting its finger on individual concepts and make sure that these concepts pop up later in the text and tracks basically the individuals through the text."}, {"time": 3656, "text": "And it's why the system can learn things that other systems couldn't before it, which makes it, for instance, possible to write a text where it talks about the scientist, then the scientist has a name and has a pronoun and it gets a consistent story about that thing."}, {"time": 3670, "text": "What it does not do, it doesn't fully integrate this."}, {"time": 3676, "text": "So this meaning falls apart at some point, it loses track of this context."}, {"time": 3680, "text": "It does not yet understand that everything that it says has to refer to the same universe."}, {"time": 3685, "text": "And this is where this thing falls apart."}, {"time": 3685, "text": "But the attention in the transformer model does not go beyond tracking identity."}, {"time": 3691, "text": "And tracking identity is an important part of attention, but it's a different, very specific attentional mechanism."}, {"time": 3696, "text": "And it's not the one that gives rise to the type of consciousness that we have."}, {"time": 3701, "text": "Just to linger on, what do you mean by identity in the context of language?"}, {"time": 3704, "text": "So when you talk about language, you have different words that can refer to the same concept."}, {"time": 3712, "text": "And in the sense that..."}, {"time": 3713, "text": "The space of concepts."}, {"time": 3713, "text": "And it can also be in a nominal sense or in an inexical sense that you say this word does not only refer to this class of objects, but it refers to a definite object, to some kind of agent that waves their way through the story."}, {"time": 3731, "text": "And it's only referred by different ways in the language."}, {"time": 3731, "text": "So the language is basically a projection from a conceptual representation from a scene that is evolving into a discrete string of symbols."}, {"time": 3743, "text": "And what the transformer is able to do, it learns aspects of this projection mechanism that other models couldn't learn."}, {"time": 3749, "text": "So have you ever seen an artificial intelligence or any kind of construction idea that allows for, unlike neural networks or perhaps within neural networks, that's able to form something where the space of concepts continues to be integrated?"}, {"time": 3767, "text": "So what you're describing, building a knowledge base, building this consistent, larger and larger sets of ideas that would then allow for deeper understanding."}, {"time": 3779, "text": "Wittgenstein thought that we can build everything from language, from basically a logical grammatical construct."}, {"time": 3782, "text": "And I think to some degree, this was also what Minsky believed."}, {"time": 3787, "text": "So that's why he focused so much on common sense reasoning and so on."}, {"time": 3792, "text": "And a project that was inspired by him was Psych."}, {"time": 3792, "text": "That was basically going on."}, {"time": 3799, "text": "Of course, ideas don't die."}, {"time": 3799, "text": "Only people die."}, {"time": 3807, "text": "And Alt Psych is a productive project."}, {"time": 3807, "text": "It's just probably not one that is going to converge to general intelligence."}, {"time": 3811, "text": "The thing that Wittgenstein couldn't solve, and he looked at this in his book at the end of his life, Philosophical Investigations, was the notion of images."}, {"time": 3820, "text": "So images play an important role in Tractatus."}, {"time": 3820, "text": "The Tractatus is an attempt to basically turn philosophy into logical probing language, to design a logical language in which you can do actual philosophy that's rich enough for doing this."}, {"time": 3829, "text": "And the difficulty was to deal with perceptual content."}, {"time": 3834, "text": "And eventually, I think he decided that he was not able to solve it."}, {"time": 3840, "text": "And I think this preempted the failure of the logitist program in AI."}, {"time": 3846, "text": "And the solution, as we see it today, is we need more general function approximation."}, {"time": 3846, "text": "There are geometric functions that we learn to approximate that cannot be efficiently expressed and computed in a grammatical language."}, {"time": 3856, "text": "We can, of course, build automata that go via number theory and so on to learn in algebra and then compute an approximation of this geometry."}, {"time": 3866, "text": "But to equate language and geometry is not an efficient way to think about it."}, {"time": 3872, "text": "So function, well, you kind of just said that neural networks are sort of, the approach that neural networks takes is actually more general than what can be expressed through language."}, {"time": 3884, "text": "So what can be efficiently expressed through language at the data rates at which we process grammatical language?"}, {"time": 3891, "text": "So you don't think languages, so you disagree with Wittgenstein, that language is not fundamental to..."}, {"time": 3898, "text": "I agree with Wittgenstein."}, {"time": 3898, "text": "I just agree with the late Wittgenstein."}, {"time": 3903, "text": "And I also agree with the beauty of the early Wittgenstein."}, {"time": 3903, "text": "I think that the Tractatus itself is probably the most beautiful philosophical text that was written in the 20th century."}, {"time": 3913, "text": "But language is not fundamental to cognition and intelligence and consciousness."}, {"time": 3918, "text": "So I think that language is a particular way or the natural language that we're using is a particular level of abstraction that we use to communicate with each other."}, {"time": 3923, "text": "But the languages in which we express geometry are not grammatical languages in the same sense."}, {"time": 3928, "text": "So they work slightly differently, more general expressions of functions."}, {"time": 3935, "text": "And I think the general nature of a model is you have a bunch of parameters."}, {"time": 3941, "text": "These have a range, these are the variances of the world, and you have relationships between them, which are constraints, which say if certain parameters have these values, then other parameters have to have the following values."}, {"time": 3952, "text": "And this is a very early insight in computer science."}, {"time": 3958, "text": "And I think some of the earliest formulations is the Boltzmann machine."}, {"time": 3963, "text": "And the problem with the Boltzmann machine is that it has a measure of whether it's good."}, {"time": 3963, "text": "This is basically the energy on the system, the amount of tension that you have left in the constraints where the constraints don't quite match."}, {"time": 3971, "text": "It's very difficult to, despite having this global measure, to train it."}, {"time": 3976, "text": "Because as soon as you add more than trivially few elements, parameters into the system, it's very difficult to get it settled in the right architecture."}, {"time": 3987, "text": "And so the solution that Hinton and Zanofsky found was to use a restricted Boltzmann machine, which uses the hidden links, the internal links in the Boltzmann machine and only has basically input and output layer."}, {"time": 3999, "text": "But this limits the expressivity of the Boltzmann machine."}, {"time": 3999, "text": "So now he builds a network of these primitive Boltzmann machines."}, {"time": 4004, "text": "And in some sense, you can see almost continuous development from this to the deep learning models that we're using today, even though we don't use Boltzmann machines at this point."}, {"time": 4014, "text": "But the idea of the Boltzmann machine is you take this model, you clamp some of the values to perception, and this forces the entire machine to go into a state that is compatible with the states that you currently perceive."}, {"time": 4026, "text": "And this state is your model of the world."}, {"time": 4026, "text": "I think it's a very general way of thinking about models, but we have to use a different approach to make it work."}, {"time": 4032, "text": "We have to find different networks that train the Boltzmann machine."}, {"time": 4039, "text": "So the mechanism that trains the Boltzmann machine and the mechanism that makes the Boltzmann machine settle into its state are distinct from the constrained architecture of the Boltzmann machine itself."}, {"time": 4053, "text": "The kind of mechanisms that we want to develop, you're saying?"}, {"time": 4056, "text": "So the direction in which I think our research is going to go is going to, for instance, what you notice in perception is our perceptual models of the world are not probabilistic, but possibilistic, which means you should be able to perceive things that are improbable, but possible."}, {"time": 4070, "text": "A perceptual state is valid, not if it's probable, but if it's possible, if it's coherent."}, {"time": 4077, "text": "So if you see a tiger coming after you, you should be able to see this even if it's unlikely."}, {"time": 4082, "text": "And the probability is necessary for convergence of the model."}, {"time": 4082, "text": "So given the state of possibilities that is very, very large and a set of perceptual features, how should you change the states of the model to get it to converge with your perception?"}, {"time": 4101, "text": "But the space of ideas that are coherent with the context that you're sensing is perhaps not as large."}, {"time": 4109, "text": "I mean, that's perhaps pretty small."}, {"time": 4114, "text": "The degree of coherence that you need to achieve depends, of course, how deep your models go."}, {"time": 4119, "text": "That is, for instance, politics is very simple when you know very little about game theory and human nature."}, {"time": 4124, "text": "So the younger you are, the more obvious it is how politics would work, right?"}, {"time": 4129, "text": "And because you get a coherent aesthetics from relatively few inputs."}, {"time": 4129, "text": "And the more layers you model, the more layers you model reality, the harder it gets to satisfy all the constraints."}, {"time": 4140, "text": "So, you know, the current neural networks are fundamentally supervised learning system with a feed forward neural network is back propagation to learn."}, {"time": 4147, "text": "What's your intuition about what kind of mechanisms might we move towards to improve the learning procedure?"}, {"time": 4158, "text": "I think one big aspect is going to be meta learning and architecture search starts in this direction."}, {"time": 4162, "text": "In some sense, the first wave of classical AI work by identifying a problem and a possible solution and implementing the solution, right?"}, {"time": 4168, "text": "A program that plays chess."}, {"time": 4172, "text": "And right now we are in the second wave of AI."}, {"time": 4172, "text": "So instead of writing the algorithm that implements the solution, we write an algorithm that automatically searches for an algorithm that implements the solution."}, {"time": 4181, "text": "So the learning system in some sense is an algorithm that itself discovers the algorithm that solves the problem, like Go."}, {"time": 4186, "text": "Go is too hard to implement the solution by hand, but we can implement an algorithm that finds the solution."}, {"time": 4196, "text": "So now let's move to the third stage, right?"}, {"time": 4196, "text": "The third stage would be meta learning."}, {"time": 4200, "text": "Find an algorithm that discovers a learning algorithm for the given domain."}, {"time": 4205, "text": "Our brain is probably not a learning system, but a meta learning system."}, {"time": 4208, "text": "This is one way of looking at what we are doing."}, {"time": 4208, "text": "There is another way."}, {"time": 4208, "text": "If you look at the way our brain is, for instance, implemented, there is no central control that tells all the neurons how to wire up."}, {"time": 4218, "text": "Instead, every neuron is an individual reinforcement learning agent."}, {"time": 4218, "text": "Every neuron is a single celled organism that is quite complicated and in some sense quite motivated to get fed."}, {"time": 4228, "text": "And it gets fed if it fires on average at the right time."}, {"time": 4228, "text": "And the right time depends on the context that the neuron exists in, which is the electrical and chemical environment that it has."}, {"time": 4242, "text": "So it basically has to learn a function over its environment that tells us when to fire to get fed."}, {"time": 4248, "text": "Or if you see it as a reinforcement learning agent, every neuron is in some sense making a hypothesis when it sends a signal and tries to pipe a signal through the universe and tries to get positive feedback for it."}, {"time": 4257, "text": "And the entire thing is set up in such a way that it's robustly self organizing into a brain, which means you start out with different neuron types that have different priors on which hypothesis to test and how to get its reward."}, {"time": 4272, "text": "And you put them into different concentrations in a certain spatial alignment, and then you entrain it in a particular order."}, {"time": 4276, "text": "And as a result, you get a well organized brain."}, {"time": 4282, "text": "Yeah, so okay, so the brain is a meta learning system with a bunch of reinforcement learning agents."}, {"time": 4289, "text": "And what I think you said, but just to clarify, there's no centralized government that tells you, here's a loss function, here's a loss function, here's a loss function."}, {"time": 4300, "text": "Who says what's the objective?"}, {"time": 4308, "text": "There are also governments which impose loss functions on different parts of the brain."}, {"time": 4312, "text": "So we have differential attention."}, {"time": 4312, "text": "Some areas in your brain get specially rewarded when you look at faces."}, {"time": 4316, "text": "If you don't have that, you will get prosopagnosia, which basically the inability to tell people apart by their faces."}, {"time": 4321, "text": "And the reason that happens is because it had an evolutionary advantage."}, {"time": 4327, "text": "So like evolution comes into play here."}, {"time": 4327, "text": "But it's basically an extraordinary attention that we have for faces."}, {"time": 4332, "text": "I don't think that people with prosopagnosia have a perceived defective brain, the brain just has an average attention for faces."}, {"time": 4337, "text": "So people with prosopagnosia don't look at faces more than they look at cups."}, {"time": 4342, "text": "So the level at which they resolve the geometry of faces is not higher than for cups."}, {"time": 4347, "text": "And people that don't have prosopagnosia look obsessively at faces, right?"}, {"time": 4354, "text": "For you and me, it's impossible to move through a crowd without scanning the faces."}, {"time": 4358, "text": "And as a result, we make insanely detailed models of faces that allow us to discern mental states of people."}, {"time": 4363, "text": "So obviously, we don't know 99% of the details of this meta learning system."}, {"time": 4369, "text": "That's our mind."}, {"time": 4369, "text": "But still, we took a leap from something much dumber to that from through the evolutionary process."}, {"time": 4375, "text": "Can you first of all, maybe say how hard the, how big of a leap is that from our brain, from our ancestors to multi cell organisms?"}, {"time": 4384, "text": "And is there something we can think about?"}, {"time": 4394, "text": "As we start to think about how to engineer intelligence, is there something we can learn from evolution?"}, {"time": 4401, "text": "In some sense, life exists because of the market opportunity of controlled chemical reactions."}, {"time": 4408, "text": "We compete with dump chemical reactions and we win in some areas against this dump combustion because we can harness those entropy gradients where you need to add a little bit of energy in a specific way to harvest more energy."}, {"time": 4420, "text": "So we out competed combustion."}, {"time": 4424, "text": "Yes, in many regions we do and we try very hard because when we are in direct competition, we lose, right?"}, {"time": 4429, "text": "So because the combustion is going to close the entropy gradients much faster than we can run."}, {"time": 4435, "text": "So basically we do this because every cell has a Turing machine built into it."}, {"time": 4442, "text": "It's like literally a read write head on the tape."}, {"time": 4449, "text": "So everything that's more complicated than a molecule that just is a vortex around attractors that needs a Turing machine for its regulation."}, {"time": 4456, "text": "And then you bind cells together and you get next level organizational organism where the cells together implement some kind of software."}, {"time": 4468, "text": "For me, a very interesting discovery in the last year was the word spirit because I realized that what spirit actually means is an operating system for an autonomous robot."}, {"time": 4473, "text": "And when the word was invented, people needed this word."}, {"time": 4478, "text": "But they didn't have robots that they built themselves yet."}, {"time": 4478, "text": "The only autonomous robots that were known were people, animals, plants, ecosystems, cities, and so on."}, {"time": 4488, "text": "And they all had spirits."}, {"time": 4488, "text": "And it makes sense to say that the plant has an operating system, right?"}, {"time": 4493, "text": "If you pinch the plant in one area, then it's going to have repercussions throughout the plant."}, {"time": 4497, "text": "Everything in the plant is in some sense connected into some global aesthetics like in other organisms."}, {"time": 4502, "text": "An organism is not a collection of cells, it's a function that tells cells how to behave."}, {"time": 4507, "text": "And this function is not implemented as some kind of supernatural thing, like some morphogenetic field."}, {"time": 4513, "text": "It is an emergent result of the interactions of each cell with each other cell."}, {"time": 4519, "text": "So what you're saying is the organism is a function that tells what to do and the function emerges from the interaction of the cells."}, {"time": 4531, "text": "So it's basically a description of what the plant is doing in terms of microstates."}, {"time": 4539, "text": "And the microstates, the physical implementation are too many of them to describe them."}, {"time": 4546, "text": "So the software that we use to describe what the plant is doing, the spirit of the plant is the software, the operating system of the plant, right?"}, {"time": 4551, "text": "This is a way in which we, the observers, make sense of the plant."}, {"time": 4557, "text": "And the same is true for people."}, {"time": 4557, "text": "So people have spirits, which is their operating system in a way, right?"}, {"time": 4563, "text": "And there's aspects of that operating system that relate to how your body functions and others, how you socially interact, how you interact with yourself and so on."}, {"time": 4572, "text": "And we make models of that spirit."}, {"time": 4572, "text": "And we think it's a loaded term because it's from a pre scientific age."}, {"time": 4578, "text": "But it took the scientific age a long time to rediscover a term that is pretty much the same thing."}, {"time": 4584, "text": "And I suspect that the differences that we still see between the old word and the new word are translation errors that have happened over the centuries."}, {"time": 4593, "text": "Can you actually linger on that?"}, {"time": 4593, "text": "Why do you say that spirit, just to clarify, because I'm a little bit confused."}, {"time": 4599, "text": "So the word spirit is a powerful thing."}, {"time": 4599, "text": "But why did you say in the last year or so that you discovered this?"}, {"time": 4605, "text": "Do you mean the same old traditional idea of a spirit?"}, {"time": 4610, "text": "I try to find out what people mean by spirit."}, {"time": 4610, "text": "When people say spirituality in the US, it usually refers to the phantom limb that they develop in the absence of culture."}, {"time": 4620, "text": "And a culture is in some sense, you could say the spirit of a society that is long game."}, {"time": 4620, "text": "This thing that is become self aware at a level above the individuals where you say, if you don't do the following things, then the grand, grand, grand grandchildren of our children will have nothing to eat."}, {"time": 4636, "text": "So if you take this long scope, where you try to maximize the length of the game that you are playing as a species, you realize that you're part of a larger thing that you cannot fully control."}, {"time": 4647, "text": "You probably need to submit to the ecosphere instead of trying to completely control it."}, {"time": 4652, "text": "There needs to be a certain level at which we can exist as a species if you want to endure."}, {"time": 4659, "text": "And our culture is not sustaining this anymore."}, {"time": 4659, "text": "We basically made this bet with the industrial revolution that we can control everything."}, {"time": 4664, "text": "And the modernist societies with basically unfettered growth led to a situation in which we depend on the ability to control the entire planet."}, {"time": 4674, "text": "And since we are not able to do that, as it seems, this culture will die."}, {"time": 4674, "text": "And we realize that it doesn't have a future, right?"}, {"time": 4680, "text": "We called our children generation Z."}, {"time": 4680, "text": "That's a very optimistic thing to do."}, {"time": 4686, "text": "So you can have this kind of intuition that our civilization, you said culture, but you really mean the spirit of the civilization, the entirety of the civilization may not exist for long."}, {"time": 4702, "text": "Can you untangle that?"}, {"time": 4702, "text": "What's your intuition behind that?"}, {"time": 4702, "text": "So you kind of offline mentioned to me that the industrial revolution was kind of the moment we agreed to accept the offer sign on the paper on the dotted line with the industrial revolution, we doomed ourselves."}, {"time": 4722, "text": "This is a suspicion."}, {"time": 4722, "text": "I, of course, don't know how it plays out."}, {"time": 4722, "text": "But it seems to me that in a society in which you leverage yourself very far over an entropic abyss without land on the other side, it's relatively clear that your cantilever is at some point going to break down into this entropic abyss."}, {"time": 4740, "text": "And you have to pay the bill."}, {"time": 4740, "text": "Russia is my first language."}, {"time": 4746, "text": "And I'm also an idiot."}, {"time": 4746, "text": "This is just two apes."}, {"time": 4753, "text": "Instead of playing with a banana, trying to have fun by talking."}, {"time": 4753, "text": "Anthropic what?"}, {"time": 4753, "text": "And what's entropic?"}, {"time": 4761, "text": "Entropic."}, {"time": 4761, "text": "So entropic in the sense of entropy."}, {"time": 4761, "text": "Oh, entropic."}, {"time": 4761, "text": "And entropic, what was the other word you used?"}, {"time": 4769, "text": "Abyss."}, {"time": 4769, "text": "It's a big gorge."}, {"time": 4769, "text": "Oh, abyss."}, {"time": 4769, "text": "Abyss, yes."}, {"time": 4775, "text": "Entropic abyss."}, {"time": 4775, "text": "So many of the things you say are poetic."}, {"time": 4775, "text": "It's hurting my ears."}, {"time": 4775, "text": "And this one is amazing, right?"}, {"time": 4779, "text": "It's mispronounced, which makes you more poetic."}, {"time": 4779, "text": "Wittgenstein would be proud."}, {"time": 4779, "text": "So entropic abyss."}, {"time": 4790, "text": "Let's rewind then."}, {"time": 4790, "text": "The industrial revolution."}, {"time": 4790, "text": "So how does that get us into the entropic abyss?"}, {"time": 4798, "text": "So in some sense, we burned a hundred million years worth of trees to get everybody plumbing."}, {"time": 4804, "text": "And the society that we had before that had a very limited number of people."}, {"time": 4810, "text": "So basically since zero BC, we hovered between 300 and 400 million people."}, {"time": 4810, "text": "And this only changed with the enlightenment and the subsequent industrial revolution."}, {"time": 4818, "text": "And in some sense, the enlightenment freed our rationality and also freed our norms from the preexisting order gradually."}, {"time": 4830, "text": "It was a process that basically happened in feedback loops."}, {"time": 4830, "text": "So it was not that just one caused the other."}, {"time": 4835, "text": "It was a dynamic that started."}, {"time": 4835, "text": "And the dynamic worked by basically increasing productivity to such a degree that we could feed all our children."}, {"time": 4841, "text": "And I think the definition of poverty is that you have as many children as you can feed before they die, which is in some sense, the state that all animals on earth are in."}, {"time": 4855, "text": "The definition of poverty is having enough."}, {"time": 4861, "text": "So you can have only so many children as you can feed and if you have more, they die."}, {"time": 4866, "text": "And in our societies, you can basically have as many children as you want, they don't die."}, {"time": 4872, "text": "So the reason why we don't have as many children as we want is because we also have to pay a price in terms of we have to insert ourselves in a lower social stratum if we have too many children."}, {"time": 4882, "text": "So basically everybody in the under middle and lower upper class has only a limited number of children because having more of them would mean a big economic hit to the individual families."}, {"time": 4893, "text": "Because children, especially in the US, super expensive to have."}, {"time": 4893, "text": "And you only are taken out of this if you are basically super rich or if you are super poor."}, {"time": 4899, "text": "If you're super poor, it doesn't matter how many kids you have because your status is not going to change."}, {"time": 4903, "text": "And these children allow you not going to die of hunger."}, {"time": 4908, "text": "So how does this lead to self destruction?"}, {"time": 4908, "text": "So there's a lot of unpleasant properties about this process."}, {"time": 4914, "text": "So basically what we try to do is we try to let our children survive, even if they have diseases."}, {"time": 4918, "text": "Like I would have died before my mid twenties without modern medicine."}, {"time": 4926, "text": "And most of my friends would have as well."}, {"time": 4926, "text": "And so many of us wouldn't live without the advantages of modern medicine and modern industrialized society."}, {"time": 4932, "text": "We get our protein largely by subduing the entirety of nature."}, {"time": 4938, "text": "Imagine there would be some very clever microbe that would live in our organisms and would completely harvest them and change them into a thing that is necessary to sustain itself."}, {"time": 4952, "text": "And it would discover that for instance, brain cells are kind of edible, but they're not quite nice."}, {"time": 4958, "text": "So you need to have more fat in them and you turn them into more fat cells."}, {"time": 4963, "text": "And basically this big organism would become a vegetable that is barely alive and it's going to be very brittle and not resilient when the environment changes."}, {"time": 4972, "text": "Yeah, but some part of that organism, the one that's actually doing all the using of the, there'll still be somebody thriving."}, {"time": 4977, "text": "So it relates back to this original question I suspect that we are not the smartest thing on this planet."}, {"time": 4984, "text": "I suspect that basically every complex system has to have some complex regulation if it depends on feedback loops."}, {"time": 4990, "text": "And so for instance, it's likely that we should describe a certain degree of intelligence to plants."}, {"time": 4997, "text": "The problem is that plants don't have a nervous system."}, {"time": 5004, "text": "So they don't have a way to telegraph messages over large distances almost instantly in the plant."}, {"time": 5008, "text": "And instead, they will rely on chemicals between adjacent cells, which means the signal processing speed depends on the signal processing with a rate of a few millimeters per second."}, {"time": 5020, "text": "And as a result, if the plant is intelligent, it's not going to be intelligent at similar timescales as this."}, {"time": 5029, "text": "Yeah, the time scale is different."}, {"time": 5029, "text": "So you suspect we might not be the most intelligent but we're the most intelligent in this spatial scale in our timescale."}, {"time": 5040, "text": "So basically, if you would zoom out very far, we might discover that there have been intelligent ecosystems on the planet that existed for thousands of years in an almost undisturbed state."}, {"time": 5045, "text": "And it could be that these ecosystems actively related their environment."}, {"time": 5052, "text": "So basically change the course of the evolution vision, this ecosystem to make it more efficient in the future."}, {"time": 5060, "text": "So it's possible something like plants is actually a set of living organisms, an ecosystem of living organisms that are just operating a different timescale and are far superior in intelligence than human beings."}, {"time": 5070, "text": "And then human beings will die out and plants will still be there and they'll be there."}, {"time": 5076, "text": "Yeah, there's an evolutionary adaptation playing a role at all of these levels."}, {"time": 5076, "text": "For instance, if mice don't get enough food and get stressed, the next step is to get more sparse and more scrawny."}, {"time": 5085, "text": "And the reason for this is because they in a natural environment, the mice have probably hidden a drought or something else."}, {"time": 5091, "text": "And if they're overgrazed, then all the things that sustain them might go extinct."}, {"time": 5096, "text": "And there will be no mice a few generations from now."}, {"time": 5101, "text": "So to make sure that there will be mice in five generations from now, basically the mice scale back."}, {"time": 5105, "text": "And a similar thing happens with the predators of mice."}, {"time": 5110, "text": "They should make sure that the mice don't completely go extinct."}, {"time": 5110, "text": "So in some sense, if the predators are smart enough, they will be tasked with shepherding their food supply."}, {"time": 5115, "text": "Maybe the reason why lions have much larger brains than antelopes is not so much because it's so hard to catch an antelope as opposed to run away from the lion."}, {"time": 5127, "text": "But the lions need to make complex models of their environment, more complex than the antelopes."}, {"time": 5135, "text": "So first of all, just describing that there's a bunch of complex systems and human beings may not even be the most special or intelligent of those complex systems, even on Earth, makes me feel a little better about the extinction of human species that we're talking about."}, {"time": 5148, "text": "Yes, maybe you're just Guy Astploit to put the carbon back into the atmosphere."}, {"time": 5152, "text": "Yeah, this is just a nice, we tried it out."}, {"time": 5154, "text": "The big stain on evolution is not us, it was trees."}, {"time": 5154, "text": "Earth evolved trees before there could be digested again."}, {"time": 5160, "text": "There were no insects that could break all of them apart."}, {"time": 5160, "text": "Cellulose is so robust that you cannot get all of it with microorganisms."}, {"time": 5165, "text": "So many of these trees fell into swamps and all this carbon became inert and could no longer be recycled into organisms."}, {"time": 5171, "text": "And we are the species that is destined to take care of that."}, {"time": 5177, "text": "So this is kind of... To get out of the ground, put it back into the atmosphere and the Earth is already greening."}, {"time": 5184, "text": "So we have to be careful about that."}, {"time": 5186, "text": "To get out of the ground, put it back into the atmosphere and the Earth is already greening."}, {"time": 5190, "text": "So within a million years or so when the ecosystems have recovered from the rapid changes, that they're not compatible with right now, the Earth is going to be awesome again."}, {"time": 5199, "text": "And there won't be even a memory of us, of us little apes."}, {"time": 5202, "text": "I think there will be memories of us."}, {"time": 5202, "text": "I suspect we are the first generally intelligent species in the sense."}, {"time": 5206, "text": "We are the first species within industrial society because we will leave more phones than bones in the stratosphere."}, {"time": 5213, "text": "Phones than bones."}, {"time": 5213, "text": "But then let me push back."}, {"time": 5213, "text": "You've kind of suggested that we have a very narrow definition of..."}, {"time": 5221, "text": "I mean, why aren't trees a higher level of general intelligence?"}, {"time": 5229, "text": "If trees were intelligent, then they would be at different timescales, which means within a hundred years, the tree is probably not going to make models that are as complex as the ones that we make in 10 years."}, {"time": 5238, "text": "But maybe the trees are the ones that made the phones, right?"}, {"time": 5245, "text": "You could say the entirety of life did it."}, {"time": 5245, "text": "The first cell never died."}, {"time": 5245, "text": "The first cell only split, right?"}, {"time": 5251, "text": "And every cell in our body is still an instance of the first cell that split off from that very first cell."}, {"time": 5256, "text": "There was only one cell on this planet as far as we know."}, {"time": 5260, "text": "And so the cell is not just a building block of life."}, {"time": 5260, "text": "It's a hyperorganism."}, {"time": 5260, "text": "And we are part of this hyperorganism."}, {"time": 5269, "text": "So nevertheless, this hyperorganism, no, this little particular branch of it, which is us humans, because of the industrial revolution and maybe the exponential growth of technology might somehow destroy ourselves."}, {"time": 5282, "text": "So what do you think is the most likely way we might destroy ourselves?"}, {"time": 5287, "text": "So some people worry about genetic manipulation."}, {"time": 5287, "text": "Some people, as we've talked about, worry about either dumb artificial intelligence or super intelligent artificial intelligence destroying us."}, {"time": 5298, "text": "Some people worry about nuclear weapons and weapons of war in general."}, {"time": 5305, "text": "If you were a betting man, what would you bet on in terms of self destruction?"}, {"time": 5309, "text": "And then would it be higher than 50%?"}, {"time": 5314, "text": "So it's very likely that nothing that we bet on matters after we win our bets."}, {"time": 5314, "text": "So I don't think that bets are literally the right way to go about this."}, {"time": 5324, "text": "I mean, once you're dead, you won't be there to collect the wings."}, {"time": 5327, "text": "So it's also not clear if we as a species go extinct."}, {"time": 5327, "text": "But I think that our present civilization is not sustainable."}, {"time": 5333, "text": "So the thing that will change is there will be probably fewer people on the planet than there are today."}, {"time": 5337, "text": "And even if not, then still most of people that are alive today will not have offspring in 100 years from now because of the geographic changes and so on and the changes in the food supply."}, {"time": 5345, "text": "It's quite likely that many areas of the planet will only be livable with a close cooling chain in 100 years from now."}, {"time": 5355, "text": "So many of the areas around the equator and in subtropical climates that are now quite pleasant to live in, will stop to be inhabitable without air conditioning."}, {"time": 5367, "text": "So you honestly, wow, cooling chain, close knit cooling chain communities."}, {"time": 5367, "text": "So you think you have a strong worry about the effects of global warming?"}, {"time": 5378, "text": "By itself, it's not a big issue."}, {"time": 5378, "text": "If you live in Arizona right now, you have basically three months in the summer in which you cannot be outside."}, {"time": 5382, "text": "And so you have a close cooling chain."}, {"time": 5387, "text": "You have air conditioning in your car and in your home and you're fine."}, {"time": 5387, "text": "And if the air conditioning would stop for a few days, then in many areas you would not be able to survive."}, {"time": 5396, "text": "Can we just pause for a second?"}, {"time": 5396, "text": "You say so many brilliant, poetic things."}, {"time": 5396, "text": "Do people use that term closed cooling chain?"}, {"time": 5403, "text": "I imagine that people use it when they describe how they get meat into a supermarket, right?"}, {"time": 5408, "text": "If you break the cooling chain and this thing starts to thaw, you're in trouble and you have to throw it away."}, {"time": 5413, "text": "That's such a beautiful way to put it."}, {"time": 5413, "text": "It's like calling a city a closed social chain or something like that."}, {"time": 5419, "text": "I mean, that's right."}, {"time": 5419, "text": "I mean, the locality of it is really important."}, {"time": 5425, "text": "It basically means you wake up in a climatized room, you go to work in a climatized car, you work in a climatized office, you shop in a climatized supermarket and in between you have very short distance in which you run from your car to the supermarket, but you have to make sure that your temperature does not approach the temperature of the environment."}, {"time": 5442, "text": "The crucial thing is the wet barb temperature."}, {"time": 5442, "text": "The wet barb temperature."}, {"time": 5442, "text": "It's what you get when you take a wet cloth and you put it around your thermometer and then you move it very quickly through the air so you get the evaporation heat."}, {"time": 5454, "text": "And as soon as you can no longer cool your body temperature via evaporation to a temperature below something like I think 35 degrees, you die."}, {"time": 5468, "text": "Which means if the outside world is dry, you can still cool yourself down by sweating."}, {"time": 5475, "text": "But if it has a certain degree of humidity or if it goes over a certain temperature, then sweating will not save you."}, {"time": 5480, "text": "And this means even if you're a healthy, fit individual within a few hours, even if you try to be in the shade and so on, you'll die unless you have some climatizing equipment."}, {"time": 5491, "text": "And this itself, as long as you maintain civilization and you have energy supply and you have foot trucks coming to your home that are climatized, everything is fine."}, {"time": 5501, "text": "But what if you lose large scale open agriculture at the same time?"}, {"time": 5501, "text": "So basically you run into foot insecurity because climate becomes very irregular or weather becomes very irregular and you have a lot of extreme weather events."}, {"time": 5512, "text": "So you need to roll most of your foot maybe indoor or you need to import your foot from certain regions."}, {"time": 5519, "text": "And maybe you're not able to maintain the civilization throughout the planet to get the infrastructure to get the foot to your home."}, {"time": 5529, "text": "But there could be significant impacts in the sense that people begin to suffer."}, {"time": 5533, "text": "There could be wars over resources and so on."}, {"time": 5533, "text": "But ultimately, do you not have a, not a faith, but what do you make of the capacity of technological innovation to help us prevent some of the worst damages that this condition can create?"}, {"time": 5550, "text": "So as an example, as an almost out there example, is the work that SpaceX and Elon Musk is doing of trying to also consider our propagation throughout the universe in deep space to colonize other planets."}, {"time": 5565, "text": "That's one technological step."}, {"time": 5571, "text": "But of course, what Elon Musk is trying on Mars is not to save us from global warming, because Mars looks much worse than Earth will look like after the worst outcomes of global warming imaginable, right?"}, {"time": 5581, "text": "Mars is essentially not habitable."}, {"time": 5586, "text": "It's exceptionally harsh environment, yes."}, {"time": 5586, "text": "But what he is doing, what a lot of people throughout history since the Industrial Revolution are doing, are just doing a lot of different technological innovation with some kind of target."}, {"time": 5595, "text": "And when it ends up happening, it's totally unexpected new things come up."}, {"time": 5600, "text": "So trying to terraform or trying to colonize Mars, extremely harsh environment, might give us totally new ideas of how to expand or increase the power of this closed cooling circuit that empowers the community."}, {"time": 5616, "text": "So it seems like there's a little bit of a race between our open ended technological innovation of this communal operating system that we have and our general tendency to want to overuse resources and thereby destroy ourselves."}, {"time": 5635, "text": "You don't think technology can win that race?"}, {"time": 5642, "text": "I think the probability is relatively low, given that our technology is, for instance, the US is stagnating since the 1970s roughly, in terms of technology."}, {"time": 5655, "text": "Most of the things that we do are the result of incremental processes."}, {"time": 5655, "text": "What about Intel?"}, {"time": 5659, "text": "What about Moore's Law?"}, {"time": 5659, "text": "It's basically, it's very incremental."}, {"time": 5659, "text": "The things that we're doing is, so the invention of the microprocessor was a major thing, right?"}, {"time": 5664, "text": "The miniaturization of transistors was really major."}, {"time": 5671, "text": "But the things that we did afterwards largely were not that innovative."}, {"time": 5678, "text": "We had gradual changes of scaling things from CPUs into GPUs and things like that."}, {"time": 5688, "text": "But I don't think that there are, basically there are not many things."}, {"time": 5688, "text": "If you take a person that died in the 70s and was at the top of their game, they would not need to read that many books to be current again."}, {"time": 5699, "text": "But it's all about books."}, {"time": 5699, "text": "Who cares about books?"}, {"time": 5699, "text": "There might be things that are beyond books."}, {"time": 5705, "text": "Or say papers."}, {"time": 5705, "text": "No, papers."}, {"time": 5705, "text": "Forget papers."}, {"time": 5705, "text": "There might be things that are, so papers and books and knowledge, that's a concept of a time when you were sitting there by candlelight and individual consumers of knowledge."}, {"time": 5716, "text": "What about the impact that we're not in the middle of, might not be understanding of Twitter, of YouTube?"}, {"time": 5721, "text": "The reason you and I are sitting here today is because of Twitter and YouTube."}, {"time": 5727, "text": "So the ripple effect, and there's two minds, sort of two dumb apes coming up with a new, perhaps a new clean insights, and there's 200 other apes listening right now, 200,000 other apes listening right now."}, {"time": 5742, "text": "And that effect, it's very difficult to understand what that effect will have."}, {"time": 5748, "text": "That might be bigger than any of the advancements of the microprocessor or any of the industrial revolution, the ability of spread knowledge."}, {"time": 5753, "text": "And that knowledge, like it allows good ideas to reach millions much faster."}, {"time": 5762, "text": "And the effect of that, that might be the new, that might be the 21st century, is the multiplying of ideas, of good ideas."}, {"time": 5769, "text": "Because if you say one good thing today, that will multiply across huge amounts of people, and then they will say something, and then they will have another podcast, and they'll say something, and then they'll write a paper."}, {"time": 5787, "text": "That could be a huge, you don't think that?"}, {"time": 5787, "text": "Yeah, we should have billions for Neumann's right now in two rings, and we don't for some reason."}, {"time": 5793, "text": "I suspect the reason is that we destroy our attention span."}, {"time": 5798, "text": "Also the incentives, of course, different."}, {"time": 5798, "text": "Yeah, we have extreme Kardashians, yeah."}, {"time": 5803, "text": "So the reason why we're sitting here and doing this as a YouTube video is because you and me don't have the attention span to write a book together right now."}, {"time": 5808, "text": "And you guys probably don't have the attention span to read it."}, {"time": 5812, "text": "So let me tell you, it's very short."}, {"time": 5812, "text": "But we're an hour and 40 minutes in, and I guarantee you that 80% of the people are still listening."}, {"time": 5821, "text": "So there is an attention span."}, {"time": 5826, "text": "It's just the form."}, {"time": 5826, "text": "Who said that the book is the optimal way to transfer information?"}, {"time": 5833, "text": "This is still an open question."}, {"time": 5833, "text": "That's what we're..."}, {"time": 5833, "text": "It's something that social media could be doing that other forms could not be doing."}, {"time": 5837, "text": "I think the end game of social media is a global brain."}, {"time": 5842, "text": "And Twitter is in some sense a global brain that is completely hooked on dopamine, doesn't have any kind of inhibition, and as a result is caught in a permanent seizure."}, {"time": 5846, "text": "It's also in some sense a multiplayer role playing game."}, {"time": 5852, "text": "And people use it to play an avatar that is not like them, as they were in this sane world, and they look through the world through the lens of their phones and think it's the real world."}, {"time": 5861, "text": "But it's the Twitter world that is distorted by the popularity incentives of Twitter."}, {"time": 5865, "text": "Yeah, the incentives and just our natural biological, the dopamine rush of a like, no matter how..."}, {"time": 5872, "text": "I try to be very kind of Zen like and minimalist and not be influenced by likes and so on, but it's probably very difficult to avoid that to some degree."}, {"time": 5887, "text": "Speaking at a small tangent of Twitter, how can Twitter be done better?"}, {"time": 5895, "text": "I think it's an incredible mechanism that has a huge impact on society by doing exactly what you're doing."}, {"time": 5899, "text": "Sorry, doing exactly what you described, which is having this... We're like, is this some kind of game, and we're kind of our individual RL agents in this game, and it's uncontrollable because there's not really a centralized control."}, {"time": 5913, "text": "Neither Jack Dorsey nor the engineers at Twitter seem to be able to control this game."}, {"time": 5917, "text": "Or can they?"}, {"time": 5917, "text": "That's sort of a question."}, {"time": 5924, "text": "Is there any advice you would give on how to control this game?"}, {"time": 5929, "text": "I wouldn't give advice because I am certainly not an expert, but I can give my thoughts on this."}, {"time": 5933, "text": "And our brain has solved this problem to some degree."}, {"time": 5933, "text": "Our brain has lots of individual agents that manage to play together in a way."}, {"time": 5941, "text": "And we have also many contexts in which other organisms have found ways to solve the problems of cooperation that we don't solve on Twitter."}, {"time": 5952, "text": "And maybe the solution is to go for an evolutionary approach."}, {"time": 5952, "text": "So imagine that you have something like Reddit or something like Facebook and something like Twitter, and you think about what they have in common."}, {"time": 5963, "text": "What they have in common, they are companies that in some sense own a protocol."}, {"time": 5967, "text": "And this protocol is imposed on a community, and the protocol has different components for monetization, for user management, for user display, for rating, for anonymity, for import of other content, and so on."}, {"time": 5979, "text": "And now imagine that you take these components of the protocol apart, and you do it in some sense like communities within this social network."}, {"time": 5990, "text": "And these communities are allowed to mix and match their protocols and design new ones."}, {"time": 5995, "text": "So for instance, the UI and the UX can be defined by the community."}, {"time": 5995, "text": "The rules for sharing content across communities can be defined."}, {"time": 6002, "text": "The monetization can be redefined."}, {"time": 6002, "text": "The way you reward individual users for what can be redefined."}, {"time": 6007, "text": "The way users can represent themselves and to each other can redefined."}, {"time": 6013, "text": "Who could be the redefiner?"}, {"time": 6013, "text": "So can individual human beings build enough intuition to redefine those things?"}, {"time": 6018, "text": "This itself can become part of the protocol."}, {"time": 6018, "text": "So for instance, it could be in some communities, it will be a single person that comes up with these things."}, {"time": 6027, "text": "And others, it's a group of friends."}, {"time": 6027, "text": "Some might implement a voting scheme that has some interesting weighted voting."}, {"time": 6032, "text": "Who knows what will be the best self organizing principle for this."}, {"time": 6036, "text": "But the process can't be automated."}, {"time": 6036, "text": "I mean, it seems like the brain."}, {"time": 6039, "text": "It can be automated so people can write software for this."}, {"time": 6039, "text": "And eventually the idea is, let's not make an assumption about this thing if you don't know what the right solution is."}, {"time": 6045, "text": "In those areas that we have no idea whether the right solution will be people designing this ad hoc, or machines doing this."}, {"time": 6055, "text": "Whether you want to enforce compliance by social norms like Wikipedia, or with software solutions, or with AI that goes through the posts of people, or with a legal principle, and so on."}, {"time": 6066, "text": "This is something maybe you need to find out."}, {"time": 6066, "text": "And so the idea would be if you let the communities evolve, and you just control it in such a way that you are incentivizing the most sentient communities."}, {"time": 6077, "text": "The ones that produce the most interesting behaviors that allow you to interact in the most helpful ways to the individuals."}, {"time": 6089, "text": "You have a network that gives you information that is relevant to you."}, {"time": 6092, "text": "It helps you to maintain relationships to others in healthy ways."}, {"time": 6092, "text": "It allows you to build teams."}, {"time": 6092, "text": "It allows you to basically bring the best of you into this thing and goes into a coupling into a relationship with others in which you produce things that you would be unable to produce alone."}, {"time": 6107, "text": "Yes, beautifully put."}, {"time": 6107, "text": "But the key process of that with incentives and evolution is things that don't adopt themselves to effectively get the incentives have to die."}, {"time": 6122, "text": "And the thing about social media is communities that are unhealthy or whatever you wanted that defines the incentives really don't like dying."}, {"time": 6127, "text": "One of the things that people really get aggressive, protest aggressively is when they're censored."}, {"time": 6133, "text": "Especially in America."}, {"time": 6133, "text": "I don't know much about the rest of the world, but the idea of freedom of speech, the idea of censorship is really painful in America."}, {"time": 6144, "text": "And so what do you think about that?"}, {"time": 6144, "text": "Having grown up in East Germany, do you think censorship is an important tool in our brain and the intelligence and in social networks?"}, {"time": 6165, "text": "So basically, if you're not a good member of the entirety of the system, they should be blocked away."}, {"time": 6173, "text": "Well, locked away, blocked."}, {"time": 6173, "text": "An important thing is who decides that you are a good member."}, {"time": 6179, "text": "Is it distributed?"}, {"time": 6179, "text": "And what is the outcome of the process that decides it, both for the individual and for society at large."}, {"time": 6184, "text": "For instance, if you have a high trust society, you don't need a lot of surveillance."}, {"time": 6189, "text": "And the surveillance is even in some sense undermining trust."}, {"time": 6194, "text": "Because it's basically punishing people that look suspicious when surveyed, but do the right thing anyway."}, {"time": 6201, "text": "And the opposite, if you have a low trust society, then surveillance can be a better trade off."}, {"time": 6206, "text": "And the US is currently making a transition from a relatively high trust or mixed trust society to a low trust society."}, {"time": 6210, "text": "So surveillance will increase."}, {"time": 6216, "text": "Another thing is that beliefs are not just inert representations."}, {"time": 6216, "text": "There are implementations that run code on your brain and change your reality and change the way you interact with each other at some level."}, {"time": 6225, "text": "And some of the beliefs are just public opinions that we use to display our alignment."}, {"time": 6232, "text": "So for instance, people might say, all cultures are the same and equally good, but still they prefer to live in some cultures over others, very, very strongly so."}, {"time": 6238, "text": "And it turns out that the cultures are defined by certain rules of interaction."}, {"time": 6243, "text": "And these rules of interaction lead to different results when you implement them."}, {"time": 6248, "text": "So if you adhere to certain rules, you get different outcomes in different societies."}, {"time": 6252, "text": "And this all leads to very tricky situations when people do not have a commitment to a shared purpose."}, {"time": 6262, "text": "And our societies probably need to rediscover what it means to have a shared purpose and how to make this compatible with a non totalitarian view."}, {"time": 6267, "text": "So in some sense, the US is caught in a conundrum between totalitarianism and diversity, and doesn't need to know how to resolve this."}, {"time": 6282, "text": "And the solutions that the US has found so far are very crude because it's a very young society that is also under a lot of tension."}, {"time": 6287, "text": "It seems to me that the US will have to reinvent itself."}, {"time": 6292, "text": "What do you think, just philosophizing, what kind of mechanisms of government do you think we as a species should be involved with, US or broadly?"}, {"time": 6301, "text": "What do you think will work well as a system?"}, {"time": 6307, "text": "Of course, we don't know."}, {"time": 6307, "text": "It all seems to work pretty crappily, some things worse than others."}, {"time": 6311, "text": "Some people argue that communism is the best."}, {"time": 6311, "text": "Others say, yeah, look at the Soviet Union."}, {"time": 6316, "text": "Some people argue that anarchy is the best and then completely discarding the positive effects of government."}, {"time": 6322, "text": "There's a lot of arguments."}, {"time": 6322, "text": "US seems to be doing pretty damn well in the span of history."}, {"time": 6329, "text": "There's a respect for human rights, which seems to be a nice feature, not a bug."}, {"time": 6336, "text": "And economically, a lot of growth, a lot of technological development."}, {"time": 6342, "text": "People seem to be relatively kind on the grand scheme of things."}, {"time": 6347, "text": "What lessons do you draw from that?"}, {"time": 6347, "text": "What kind of government system do you think is good?"}, {"time": 6352, "text": "Ideally, a government should not be perceivable."}, {"time": 6352, "text": "It should be frictionless."}, {"time": 6352, "text": "The more you notice the influence of the government, the more friction you experience, the less effective and efficient the government probably is."}, {"time": 6364, "text": "A government, game theoretically, is an agent that imposes an offset on your payout metrics to make your Nash equilibrium compatible with the common good."}, {"time": 6377, "text": "You have these situations where people act on local incentives and these local incentives, everybody does the thing that's locally the best for them, but the global outcome is not good."}, {"time": 6387, "text": "And this is even the case when people care about the global outcome, because a regulation mechanism exists that creates a causal relationship between what I want to have for the global good and what I do."}, {"time": 6396, "text": "For instance, if I think that we should fly less and I stay at home, there's not a single plane that is going to not start because of me, right?"}, {"time": 6401, "text": "It's not going to have an influence, but I don't get from A to B."}, {"time": 6409, "text": "So the way to implement this would be to have a government that is sharing this idea that we should fly less and is then imposing a regulation that, for instance, makes flying more expensive and gives incentives for inventing other forms of transportation that are less putting that strain on the environment, for instance."}, {"time": 6426, "text": "So there's so much optimism and so many things you describe, and yet there's the pessimism of you think our civilization is going to come to an end."}, {"time": 6438, "text": "So that's not a hundred percent probability."}, {"time": 6438, "text": "Nothing in this world is."}, {"time": 6443, "text": "So what's the trajectory out of self destruction, do you think?"}, {"time": 6443, "text": "I suspect that in some sense, we are both too smart and not smart enough, which means we are very good at solving near term problems."}, {"time": 6455, "text": "And at the same time, we are unwilling to submit to the imperatives that we would have to follow in if you want to stick around."}, {"time": 6463, "text": "So that makes it difficult."}, {"time": 6463, "text": "If you were unable to solve everything technologically, you can probably understand how high the child mortality needs to be to absorb the mutation rate and how high the mutation rate needs to be to adapt to a slowly changing ecosystemic environment."}, {"time": 6479, "text": "So you could in principle compute all these things game theoretically and adapt to it."}, {"time": 6484, "text": "But if you cannot do this, because you are like me and you have children, you don't want them to die, you will use any kind of medical information to keep mortality low."}, {"time": 6496, "text": "Even if it means that within a few generations, we have enormous genetic drift, and most of us have allergies as a result of not being adapted to the changes that we made to our food supply."}, {"time": 6506, "text": "That's for now, I say technologically speaking, we're just very young, 300 years industrial revolution, we're very new to this idea."}, {"time": 6511, "text": "So you're attached to your kids being alive and not being murdered for the good of society."}, {"time": 6516, "text": "But that might be a very temporary moment of time that we might evolve in our thinking."}, {"time": 6521, "text": "So like you said, we're both smart and not smart enough."}, {"time": 6528, "text": "We are probably not the first human civilization that has discovered technology that allows us to efficiently overgraze our resources."}, {"time": 6534, "text": "And this overgrazing, this thing, at some point, we think we can compensate this because if we have eaten all the grass, we will find a way to grow mushrooms."}, {"time": 6544, "text": "But it could also be that the ecosystems tip."}, {"time": 6550, "text": "And so what really concerns me is not so much the end of the civilization, because we will invent a new one."}, {"time": 6554, "text": "But what concerns me is the fact that, for instance, the oceans might tip."}, {"time": 6561, "text": "So for instance, maybe the plankton dies because of ocean acidification and cyanobacteria take over, and as a result, we can no longer breathe the atmosphere."}, {"time": 6567, "text": "This would be really concerning."}, {"time": 6572, "text": "So basically a major reboot of most complex organisms on Earth."}, {"time": 6572, "text": "And I think this is a possibility."}, {"time": 6577, "text": "I don't know what the percentage for this possibility is, but it doesn't seem to be outlandish to me if you look at the scale of the changes that we've already triggered on this planet."}, {"time": 6586, "text": "And so Danny Hiller suggests that, for instance, we may be able to put chalk into the stratosphere to limit solar radiation."}, {"time": 6591, "text": "Maybe it works."}, {"time": 6591, "text": "Maybe this is sufficient to counter the effects of what we've done."}, {"time": 6597, "text": "Maybe it won't be."}, {"time": 6597, "text": "Maybe we won't be able to implement it by the time it's prevalent."}, {"time": 6601, "text": "I have no idea how the future is going to play out in this regard."}, {"time": 6601, "text": "It's just, I think it's quite likely that we cannot continue like this."}, {"time": 6607, "text": "All our cousin species, the other hominids are gone."}, {"time": 6612, "text": "So the right step would be to what?"}, {"time": 6612, "text": "To rewind and to rewind towards the industrial revolution and slow the, so try to contain the technological process that leads to the overconsumption of resources?"}, {"time": 6628, "text": "Imagine you get to choose, you have one lifetime."}, {"time": 6633, "text": "You get born into a sustainable agricultural civilization, 300, maybe 400 million people on the planet tops."}, {"time": 6638, "text": "Or before this, some kind of nomadic species was like a million or 2 million."}, {"time": 6645, "text": "And so you don't meet new people unless you give birth to them."}, {"time": 6651, "text": "You cannot travel to other places in the world."}, {"time": 6651, "text": "There is no internet."}, {"time": 6651, "text": "There is no interesting intellectual tradition that reaches considerably deep."}, {"time": 6655, "text": "So you would not discover human completeness probably and so on."}, {"time": 6660, "text": "We wouldn't exist."}, {"time": 6660, "text": "And the alternative is you get born into an insane world."}, {"time": 6666, "text": "One that is doomed to die because it has just burned a hundred million years worth of trees in a single century."}, {"time": 6671, "text": "Which one do you like?"}, {"time": 6671, "text": "I think I like this one."}, {"time": 6671, "text": "It's a very weird thing that when you find yourself on a Titanic and you see this iceberg and it looks like we are not going to miss it."}, {"time": 6681, "text": "And a lot of people are in denial."}, {"time": 6681, "text": "And most of the counter arguments sound like denial to me."}, {"time": 6685, "text": "They don't seem to be rational arguments."}, {"time": 6685, "text": "And the other thing is we are born on this Titanic."}, {"time": 6690, "text": "Without this Titanic, we wouldn't have been born."}, {"time": 6690, "text": "We wouldn't be here."}, {"time": 6690, "text": "We wouldn't be talking."}, {"time": 6694, "text": "We wouldn't be on the internet."}, {"time": 6694, "text": "We wouldn't do all the things that we enjoy."}, {"time": 6698, "text": "And we are not responsible for this happening."}, {"time": 6698, "text": "If we had the choice, we would probably try to prevent it."}, {"time": 6705, "text": "But when we were born, we were never asked when we want to be born, in which society we want to be born, what incentive structures we want to be exposed to."}, {"time": 6711, "text": "We have relatively little agency in the entire thing."}, {"time": 6715, "text": "Humanity has relatively little agency in the whole thing."}, {"time": 6715, "text": "It's basically a giant machine that's tumbling down a hill and everybody is frantically trying to push some buttons."}, {"time": 6724, "text": "Nobody knows what these buttons are meaning, what they connect to."}, {"time": 6724, "text": "And most of them are not stopping this tumbling down the hill."}, {"time": 6729, "text": "Is it possible that artificial intelligence will give us an escape latch somehow?"}, {"time": 6735, "text": "So there's a lot of worry about existential threats of artificial intelligence."}, {"time": 6745, "text": "But what AI also allows, in general forms of automation, allows the potential of extreme productivity growth that will also perhaps in a positive way transform society, that may allow us to inadvertently to return to the more, to the same kind of ideals of closer to nature that's represented in hunter gatherer societies."}, {"time": 6772, "text": "That's not destroying the planet, that's not doing overconsumption and so on."}, {"time": 6779, "text": "I mean, generally speaking, do you have hope that AI can help somehow?"}, {"time": 6783, "text": "I think it's not fun to be very close to nature until you completely subdue nature."}, {"time": 6789, "text": "So our idea of being close to nature means being close to agriculture, basically forests that don't have anything in them that eats us."}, {"time": 6801, "text": "TITO See, I mean, I want to disagree with that."}, {"time": 6801, "text": "I think the niceness of being close to nature is to being fully present and in like, when survival becomes your primary, not just your goal, but your whole existence."}, {"time": 6817, "text": "I'm not just romanticizing, I can just speak for myself."}, {"time": 6827, "text": "I am self aware enough that that is a fulfilling existence."}, {"time": 6834, "text": "I personally prefer to be in nature and not fight for my survival."}, {"time": 6834, "text": "I think fighting for your survival while being in the cold and in the rain and being hunted by animals and having open wounds is very unpleasant."}, {"time": 6847, "text": "There's a contradiction in there."}, {"time": 6847, "text": "Yes, I and you, just as you said, would not choose it."}, {"time": 6854, "text": "But if I was forced into it, it would be a fulfilling existence."}, {"time": 6857, "text": "Yes, if you are adapted to it, basically, if your brain is wired up in such a way that you get rewards optimally in such an environment."}, {"time": 6863, "text": "And there's some evidence for this that for a certain degree of complexity, basically, people are more happy in such an environment because it's what you largely have evolved for."}, {"time": 6873, "text": "In between, we had a few thousand years in which I think we have evolved for a slightly more comfortable environment."}, {"time": 6878, "text": "So there is probably something like an intermediate stage in which people would be more happy than they would be if they would have to fend for themselves in small groups in the forest and often die."}, {"time": 6891, "text": "Versus something like this, where we now have basically a big machine, a big Mordor in which we run through concrete boxes and press buttons and machines, and largely don't feel well cared for as the monkeys that we are."}, {"time": 6905, "text": "So returning briefly to, not briefly, but returning to AI, what, let me ask a romanticized question, what is the most beautiful to you, silly ape, the most beautiful or surprising idea in the development of artificial intelligence, whether in your own life or in the history of artificial intelligence that you've come across?"}, {"time": 6930, "text": "If you built an AI, it probably can make models at an arbitrary degree of detail, right, of the world."}, {"time": 6937, "text": "And then it would try to understand its own nature."}, {"time": 6937, "text": "It's tempting to think that at some point when we have general intelligence, we have competitions where we will let the AIs wake up in different kinds of physical universes, and we measure how many movements of the Rubik's cube it takes until it's figured out what's going on in its universe and what it is in its own nature and its own physics and so on, right?"}, {"time": 6955, "text": "So what if we exist in the memory of an AI that is trying to understand its own nature and remembers its own genesis and remembers Lex and Joscha sitting in a hotel room, sparking some of the ideas off that led to the development of general intelligence."}, {"time": 6971, "text": "So we're a kind of simulation that's running in an AI system that's trying to understand itself."}, {"time": 6975, "text": "It's not that I believe that, but I think it's a beautiful idea."}, {"time": 6981, "text": "I mean, you kind of returned to this idea with the Turing test of intelligence being the process of asking and answering what is intelligence."}, {"time": 6991, "text": "I mean, do you think there is an answer?"}, {"time": 7007, "text": "Why is there such a search for an answer?"}, {"time": 7007, "text": "So does there have to be like an answer?"}, {"time": 7007, "text": "You just said an AI system that's trying to understand the why of what, you know, understand itself."}, {"time": 7024, "text": "Is that a fundamental process of greater and greater complexity, greater and greater intelligence is the continuous trying of understanding itself?"}, {"time": 7033, "text": "No, I think you will find that most people don't care about that because they're well adjusted enough to not care."}, {"time": 7038, "text": "And the reason why people like you and me care about it probably has to do with the need to understand ourselves."}, {"time": 7043, "text": "It's because we are in fundamental disagreement with the universe that we wake up in."}, {"time": 7048, "text": "They look down on me and they see, oh my God, I'm caught in a monkey."}, {"time": 7052, "text": "Some people are unhappy with the government and I'm unhappy with the entire universe that I find myself in."}, {"time": 7058, "text": "Oh, so you don't think that's a fundamental aspect of human nature that some people are just suppressing?"}, {"time": 7065, "text": "That they wake up shocked they're in the body of a monkey?"}, {"time": 7071, "text": "No, there is a clear adaptive value to not be confused by that and by... Well, no, that's not what I asked."}, {"time": 7076, "text": "So you have this clear adaptive value, then there's clear there's clear adaptive value to while fundamentally your brain is confused by that, by creating an illusion, another layer of the narrative that says, you know, that tries to suppress that and instead say that, you know, what's going on with the government right now is the most important thing."}, {"time": 7101, "text": "What's going on with my football team is the most important thing."}, {"time": 7105, "text": "But it seems to me, like for me, it was a really interesting moment reading Ernest Becker's Denial of Death."}, {"time": 7112, "text": "That, you know, this kind of idea that we're all, you know, the fundamental thing from which most of our human mind springs is this fear of mortality and being cognizant of your mortality and the fear of that mortality."}, {"time": 7129, "text": "And then you construct illusions on top of that."}, {"time": 7134, "text": "I guess you being just a push on it, you really don't think it's possible that this worry of the big existential questions is actually fundamental as the existentialist thought to our existence."}, {"time": 7151, "text": "I think that the fear of death only plays a role as long as you don't see the big picture."}, {"time": 7157, "text": "The thing is that minds are software states, right?"}, {"time": 7157, "text": "Software doesn't have identity."}, {"time": 7162, "text": "Software in some sense is a physical law."}, {"time": 7162, "text": "But it feels like there's an identity."}, {"time": 7162, "text": "I thought that was the for this particular piece of software and the narrative it tells, that's a fundamental property of it."}, {"time": 7175, "text": "The maintenance of the identity is not terminal."}, {"time": 7175, "text": "It's instrumental to something else."}, {"time": 7181, "text": "You maintain your identity so you can serve your meaning."}, {"time": 7181, "text": "So you can do the things that you're supposed to do before you die."}, {"time": 7186, "text": "And I suspect that for most people the fear of death is the fear of dying before they are done with the things that they feel they have to do, even though they cannot quite put their finger on it, what that is."}, {"time": 7199, "text": "But in the software world, to return to the question, then what happens after we die?"}, {"time": 7210, "text": "Why would you care?"}, {"time": 7210, "text": "You will not be longer there."}, {"time": 7210, "text": "The point of dying is that you are gone."}, {"time": 7214, "text": "Well, maybe I'm not."}, {"time": 7214, "text": "This is what, you know, it seems like there's so much, in the idea that this is just, the mind is just a simulation that's constructing a narrative around some particular aspects of the quantum mechanical wave function world that we can't quite get direct access to."}, {"time": 7237, "text": "Then like the idea of mortality seems to be a little fuzzy as well."}, {"time": 7237, "text": "It doesn't, maybe there's not a clear answer."}, {"time": 7244, "text": "The fuzzy idea is the one of continuous existence."}, {"time": 7244, "text": "We don't have continuous existence."}, {"time": 7249, "text": "How do you know that?"}, {"time": 7249, "text": "Because it's not computable."}, {"time": 7249, "text": "Because you're saying it's going to be directly infinite."}, {"time": 7255, "text": "There is no continuous process."}, {"time": 7255, "text": "The only thing that binds you together with the Lex Friedman from yesterday is the illusion that you have memories about him."}, {"time": 7262, "text": "So if you want to upload, it's very easy."}, {"time": 7262, "text": "You make a machine that thinks it's you."}, {"time": 7267, "text": "Because this is the same thing that you are."}, {"time": 7267, "text": "You are a machine that thinks it's you."}, {"time": 7270, "text": "But that's immortality."}, {"time": 7270, "text": "Yeah, but it's just a belief."}, {"time": 7270, "text": "You can create this belief very easily once you realize that the question whether you are immortal or not depends entirely on your beliefs and your own continuity."}, {"time": 7281, "text": "But then you can be immortal by the continuity of the belief."}, {"time": 7288, "text": "You cannot be immortal, but you can stop being afraid of your mortality because you realize you were never continuously existing in the first place."}, {"time": 7293, "text": "Well, I don't know if I'd be more terrified or less terrified by that."}, {"time": 7299, "text": "It seems like the fact that I existed."}, {"time": 7304, "text": "You don't know this state in which you don't have a self."}, {"time": 7304, "text": "You can't turn off yourself."}, {"time": 7309, "text": "I can't turn off myself."}, {"time": 7310, "text": "You can't turn it off."}, {"time": 7312, "text": "I can."}, {"time": 7312, "text": "And you can basically meditate yourself in a state where you are still conscious, where still things are happening, where you know everything that you knew before, but you're no longer identified with changing anything."}, {"time": 7323, "text": "And this means that yourself, in a way, dissolves."}, {"time": 7323, "text": "There is no longer this person."}, {"time": 7323, "text": "You know that this person construct exists in other states and it runs on this brain of Lex Friedman, but it's not a real thing."}, {"time": 7335, "text": "It's a construct."}, {"time": 7335, "text": "It's an idea."}, {"time": 7335, "text": "And you can change that idea."}, {"time": 7335, "text": "And if you let go of this idea, if you don't think that you are special, you realize it's just one of many people and it's not your favorite person even."}, {"time": 7346, "text": "It's just one of many."}, {"time": 7346, "text": "And it's the one that you are doomed to control for the most part."}, {"time": 7351, "text": "And that is basically informing the actions of this organism as a control model."}, {"time": 7357, "text": "And this is all there is."}, {"time": 7357, "text": "And you are somehow afraid that this control model gets interrupted or loses the identity of continuity."}, {"time": 7367, "text": "So I'm attached."}, {"time": 7367, "text": "I mean, yeah, it's a very popular, it's a somehow compelling notion that being attached, like there's no need to be attached to this idea of an identity."}, {"time": 7378, "text": "But that in itself could be an illusion that you construct."}, {"time": 7378, "text": "So the process of meditation, while popular, is thought of as getting under the concept of identity."}, {"time": 7383, "text": "It could be just putting a cloak over it, just telling it to be quiet for the moment."}, {"time": 7388, "text": "I think that meditation is eventually just a bunch of techniques that let you control attention."}, {"time": 7398, "text": "And when you can control attention, you can get access to your own source code, hopefully not before you understand what you're doing."}, {"time": 7411, "text": "And then you can change the way it works temporarily or permanently."}, {"time": 7416, "text": "So yeah, meditation is to get a glimpse at the source code, get under, so basically control or turn off the attention."}, {"time": 7422, "text": "The entire thing is that you learn to control attention."}, {"time": 7422, "text": "So everything else is downstream from controlling attention."}, {"time": 7427, "text": "And control the attention that's looking at the attention."}, {"time": 7430, "text": "Normally we only get attention in the parts of our mind that create heat, where you have a mismatch between model and the results that are happening."}, {"time": 7434, "text": "And so most people are not self aware because their control is too good."}, {"time": 7440, "text": "If everything works out roughly the way you want, and the only things that don't work out is whether your football team wins, then you will mostly have models about these domains."}, {"time": 7449, "text": "And it's only when, for instance, your fundamental relationships to the world around you don't work, because the ideology of your country is insane, and you don't understand why it's insane, and the other kids are not nerds, and don't understand why you understand physics, and you don't, why you want to understand physics, and you don't understand why somebody would not want to understand physics."}, {"time": 7472, "text": "So we kind of brought up neurons in the brain as reinforcement learning agents."}, {"time": 7480, "text": "And there's been some successes as you brought up with Go, with AlphaGo, AlphaZero, with ideas which I think are incredibly interesting ideas of systems playing each other in an automated way to improve by playing other systems in a particular construct of a game that are a little bit better than itself, and then thereby improving continuously."}, {"time": 7500, "text": "All the competitors in the game are improving gradually."}, {"time": 7505, "text": "So being just challenging enough and from learning from the process of the competition."}, {"time": 7511, "text": "Do you have hope for that reinforcement learning process to achieve greater and greater level of intelligence?"}, {"time": 7516, "text": "So we talked about different ideas in AI that need to be solved."}, {"time": 7521, "text": "Is RL a part of that process of trying to create an AGI system?"}, {"time": 7528, "text": "Definitely forms of unsupervised learning, but there are many algorithms that can achieve that."}, {"time": 7532, "text": "And I suspect that ultimately the algorithms that work, there will be a class of them or many of them."}, {"time": 7538, "text": "And they might have small differences of like a magnitude and efficiency, but eventually what matters is the type of model that you form and the types of models that we form right now are not sparse enough."}, {"time": 7549, "text": "What does it mean to be sparse?"}, {"time": 7549, "text": "It means that ideally every potential model state should correspond to a potential world state."}, {"time": 7559, "text": "So basically if you vary states in your model, you always end up with valid world states and our mind is not quite there."}, {"time": 7570, "text": "So an indication is basically what we see in dreams."}, {"time": 7570, "text": "The older we get, the more boring our dreams become because we incorporate more and more constraints that we learned about how the world works."}, {"time": 7579, "text": "So many of the things that we imagine to be possible as children turn out to be constrained by physical and social dynamics."}, {"time": 7585, "text": "And as a result, fewer and fewer things remain possible."}, {"time": 7591, "text": "It's not because our imagination scales back, but the constraints under which it operates become tighter and tighter."}, {"time": 7596, "text": "And so the constraints under which our neural networks operate are almost limitless, which means it's very difficult to get a neural network to imagine things that look real."}, {"time": 7607, "text": "So I suspect part of what we need to do is we probably need to build dreaming systems."}, {"time": 7615, "text": "I suspect that part of the purpose of dreams is similar to a generative adversarial network, we learn certain constraints and then it produces alternative perspectives on the same set of constraints."}, {"time": 7627, "text": "So you can recognize it under different circumstances."}, {"time": 7627, "text": "Maybe we have flying dreams as children because we recreate the objects that we know and the maps that we know from different perspectives, which also means from a bird's eye perspective."}, {"time": 7636, "text": "So I mean, aren't we doing that anyway?"}, {"time": 7641, "text": "I mean, not with our eyes closed and when we're sleeping, aren't we just constantly running dreams and simulations in our mind as we try to interpret the environment?"}, {"time": 7652, "text": "I mean, sort of considering all the different possibilities, the way we interact with the environment seems like, essentially, like you said, sort of creating a bunch of simulations that are consistent with our expectations, with our previous experiences, with the things we just saw recently."}, {"time": 7672, "text": "And through that hallucination process, we are able to then somehow stitch together what actually we see in the world with the simulations that match it well and thereby interpret it."}, {"time": 7687, "text": "I suspect that you and my brain are slightly unusual in this regard, which is probably what got you into MIT."}, {"time": 7693, "text": "So this obsession of constantly pondering possibilities and solutions to problems."}, {"time": 7699, "text": "Oh, stop it."}, {"time": 7699, "text": "I think I'm not talking about intellectual stuff."}, {"time": 7699, "text": "I'm talking about just doing the kind of stuff it takes to walk and not fall."}, {"time": 7707, "text": "Yes, this is largely automatic."}, {"time": 7715, "text": "Yes, but the process is, I mean..."}, {"time": 7715, "text": "It's not complicated."}, {"time": 7715, "text": "It's relatively easy to build a neural network that, in some sense, learns the dynamics."}, {"time": 7723, "text": "The fact that we haven't done it right so far doesn't mean it's hard, because you can see that a biological organism does it with relatively few neurons."}, {"time": 7732, "text": "So basically, you build a bunch of neural oscillators that entrain themselves with the dynamics of your body in such a way that the regulator becomes isomorphic in its model to the dynamics that it regulates, and then it's automatic."}, {"time": 7746, "text": "And it's only interesting in the sense that it captures attention when the system is off."}, {"time": 7752, "text": "See, but thinking of the kind of mechanism that's required to do walking as a controller, as a neural network, I think it's a compelling notion, but it discards quietly, or at least makes implicit, the fact that you need to have something like common sense reasoning to walk."}, {"time": 7773, "text": "It's an open question whether you do or not."}, {"time": 7773, "text": "But my intuition is to act in this world, there's a huge knowledge base that's underlying it somehow."}, {"time": 7780, "text": "There's so much information of the kind we have never been able to construct in neural networks in an artificial intelligence systems period, which is like, it's humbling, at least in my imagination, the amount of information required to act in this world humbles me."}, {"time": 7800, "text": "And I think saying that neural networks can accomplish it is missing the fact that we don't have yet a mechanism for constructing something like common sense reasoning."}, {"time": 7816, "text": "I mean, what's your sense about to linger on the idea of what kind of mechanism would be effective at walking?"}, {"time": 7828, "text": "You said just a neural network, not maybe the kind we have, but something a little bit better, would be able to walk easily."}, {"time": 7833, "text": "Don't you think it also needs to know like a huge amount of knowledge that's represented under the flag of common sense reasoning?"}, {"time": 7847, "text": "How much common sense knowledge do we actually have?"}, {"time": 7847, "text": "Imagine that you are really hardworking for all your life and you form two new concepts every half hour or so."}, {"time": 7851, "text": "You end up with something like a million concepts because you don't get that old."}, {"time": 7856, "text": "So a million concepts, that's not a lot."}, {"time": 7862, "text": "So it's not just a million concepts."}, {"time": 7862, "text": "I think it would be a lot."}, {"time": 7862, "text": "I personally think it might be much more than a million."}, {"time": 7866, "text": "But if you think just about the numbers, you don't live that long."}, {"time": 7872, "text": "If you think about how many cycles do your neurons have in your life, it's quite limited."}, {"time": 7876, "text": "You don't get that old."}, {"time": 7876, "text": "Yeah, but the powerful thing is the number of concepts, and they're probably deeply hierarchical in nature."}, {"time": 7883, "text": "The relations, as you described between them, is the key thing."}, {"time": 7889, "text": "So it's like, even if it's a million concepts, the graph of relations that's formed and some kind of, perhaps, some kind of probabilistic relationships, that's what's common sense reasoning is the relationship between things."}, {"time": 7902, "text": "Yeah, so in some sense, I think of the concepts as the address space for our behavior programs."}, {"time": 7908, "text": "And the behavior programs allow us to recognize objects and interact with them, also mental objects."}, {"time": 7913, "text": "And a large part of that is the physical world that we interact with, which is this RAS extender thing, which is basically navigation of information in space."}, {"time": 7924, "text": "And basically, it's similar to a game engine."}, {"time": 7924, "text": "It's a physics engine that you can use to describe and predict how things that look in a particular way, that feel when you touch them in a particular way, that love proprioception, that love auditory, for example."}, {"time": 7938, "text": "So it's a lot of auditory perception and so on, how they work out."}, {"time": 7942, "text": "So basically, the geometry of all these things."}, {"time": 7947, "text": "And this is probably 80% of what our brain is doing is dealing with that, with this real time simulation."}, {"time": 7953, "text": "And by itself, a game engine is fascinating, but it's not that hard to understand what it's doing."}, {"time": 7959, "text": "And our game engines are already, in some sense, approximating the fidelity of what we can perceive."}, {"time": 7967, "text": "So if we put on an Oculus Quest, we get something that is still relatively crude with respect to what we can perceive, but it's also in the same ballpark already."}, {"time": 7974, "text": "It's just a couple order of magnitudes away from saturating our perception in terms of the complexity that it can produce."}, {"time": 7984, "text": "So in some sense, it's reasonable to say that the computer that you can buy and put into your home is able to give a perceptual reality that has a detail that is already in the same ballpark as what your brain can process."}, {"time": 7995, "text": "And everything else are ideas about the world."}, {"time": 8002, "text": "And I suspect that they are relatively sparse and also the intuitive models that we form about social interaction."}, {"time": 8007, "text": "Social interaction is not so hard."}, {"time": 8007, "text": "It's just hard for us nerds because we all have our wires crossed, so we need to deduce them."}, {"time": 8012, "text": "But the pyres are present in most social animals."}, {"time": 8017, "text": "So it's interesting thing to notice that many domestic social animals, like cats and dogs, have better social cognition than children."}, {"time": 8024, "text": "I hope it's not that many concepts fundamentally to do to exist in this world."}, {"time": 8031, "text": "For me, it's more like I'm afraid so because this thing that we only appear to be so complex to each other because we are so stupid is a little bit depressing."}, {"time": 8042, "text": "Yeah, to me that's inspiring if we're indeed as stupid as it seems."}, {"time": 8042, "text": "The things our brains don't scale and the information processing that we build tend to scale very well."}, {"time": 8056, "text": "Yeah, but I mean, one of the things that worries me is that the fact that the brain doesn't scale means that that's actually a fundamental feature of the brain."}, {"time": 8095, "text": "It could also be that our brains are so small, not just because they take up so much glucose in our body, like 20% of the glucose, so they don't arbitrarily scale."}, {"time": 8107, "text": "There's some animals like elephants which have larger brains than us and they don't seem to be smarter."}, {"time": 8111, "text": "Elephants seem to be autistic."}, {"time": 8111, "text": "They have very, very good motor control and they're really good with details, but they really struggle to see the big picture."}, {"time": 8116, "text": "So you can make them recreate drawings stroke by stroke, they can do that, but they cannot reproduce a still life."}, {"time": 8121, "text": "So they cannot make a drawing of a scene that they see."}, {"time": 8127, "text": "They will always be only able to reproduce the line drawing, at least as far from what I could see in the experiments."}, {"time": 8131, "text": "So why is that?"}, {"time": 8137, "text": "Maybe smarter elephants would meditate themselves out of existence because their brains are too large."}, {"time": 8141, "text": "So basically the elephants that were not autistic, they didn't reproduce."}, {"time": 8146, "text": "So we have to remember that the brain is fundamentally interlinked with the body in our human and biological system."}, {"time": 8150, "text": "Do you think that AGI systems that we try to create or greater intelligent systems would need to have a body?"}, {"time": 8155, "text": "I think they should be able to make use of a body if you give it to them."}, {"time": 8160, "text": "But I don't think that they fundamentally need a body."}, {"time": 8160, "text": "So I suspect if you can interact with the world by moving your eyes and your head, you can make controlled experiments."}, {"time": 8171, "text": "And this allows you to have many magnitudes, fewer observations in order to reduce the uncertainty in your models."}, {"time": 8179, "text": "So you can pinpoint the areas in your models where you're not quite sure and you just move your head and see what's going on over there and you get additional information."}, {"time": 8188, "text": "If you just have to use YouTube as an input and you cannot do anything beyond this, you probably need just much more data."}, {"time": 8193, "text": "But we have much more data."}, {"time": 8193, "text": "So if you can build a system that has enough time and attention to browse all of YouTube and extract all the information that there is to be found, I don't think there's an obvious limit to what it can do."}, {"time": 8204, "text": "Yeah, but it seems that the interactivity is a fundamental thing that the physical body allows you to do."}, {"time": 8210, "text": "But let me ask on that topic sort of that that's what a body is, is allowing the brain to like touch things and move things and interact with the whether the physical world exists or not, whatever, but interact with some interface to the physical world."}, {"time": 8226, "text": "What about a virtual world?"}, {"time": 8226, "text": "Do you think we can do the same kind of reasoning, consciousness, intelligence if we put on a VR headset and move over to that world?"}, {"time": 8243, "text": "Do you think there's any fundamental difference between the interface to the physical world that it's here in this hotel and if we were sitting in the same hotel in a virtual world?"}, {"time": 8248, "text": "The question is, does this nonphysical world or this other environment entice you to solve problems that require general intelligence?"}, {"time": 8259, "text": "If it doesn't, then you probably will not develop general intelligence and arguably most people are not generally intelligent because they don't have to solve problems that make them generally intelligent."}, {"time": 8268, "text": "And even for us, it's not yet clear if we are smart enough to build AI and understand our own nature to this degree."}, {"time": 8272, "text": "So it could be a matter of capacity and for most people, it's in the first place a matter of interest."}, {"time": 8278, "text": "They don't see the point because the benefit of attempting this project are marginal because you're probably not going to succeed in it and the cost of trying to do it requires complete dedication of your entire life."}, {"time": 8291, "text": "But it seems like the possibilities of what you can do in the virtual world, so imagine that is much greater than you can in the real world."}, {"time": 8295, "text": "So imagine a situation, maybe interesting option for me."}, {"time": 8301, "text": "If somebody came to me and offered what I'll do is, so from now on, you can only exist in the virtual world."}, {"time": 8307, "text": "And so you put on this headset and when you eat, we'll make sure to connect your body up in a way that when you eat in the virtual world, your body will be nourished in the same way in the virtual world."}, {"time": 8321, "text": "So the aligning incentives between our common sort of real world and the virtual world, but then the possibilities become much bigger."}, {"time": 8330, "text": "Like I could be other kinds of creatures."}, {"time": 8330, "text": "I could do, I can break the laws of physics as we know them."}, {"time": 8337, "text": "I could do a lot."}, {"time": 8337, "text": "I mean, the possibilities are endless, right?"}, {"time": 8337, "text": "As far as we think it's an interesting thought, whether like what existence would be like, what kind of intelligence would emerge there?"}, {"time": 8348, "text": "What kind of consciousness?"}, {"time": 8348, "text": "What kind of maybe greater intelligence, even in me, Lex, even at this stage in my life, if I spend the next 20 years in that world to see how that intelligence emerges."}, {"time": 8359, "text": "And if that happened at the very beginning, before I was even cognizant of my existence in this physical world, it's interesting to think how that child would develop."}, {"time": 8371, "text": "And the way virtual reality and digitization of everything is moving, it's not completely out of the realm of possibility that we're all, that some part of our lives will, if not entirety of it, will live in a virtual world to a greater degree than we currently have living on Twitter and social media and so on."}, {"time": 8391, "text": "Do you have, I mean, does something draw you intellectually or naturally in terms of thinking about AI to this virtual world where more possibilities are?"}, {"time": 8403, "text": "I think that currently it's a waste of time to deal with the physical world before we have mechanisms that can automatically learn how to deal with it."}, {"time": 8413, "text": "The body gives you second order agency, but what constitutes the body is the things that you can indirectly control."}, {"time": 8418, "text": "The third order are tools, and the second order is the things that are basically always present, but you operate on them with first order things, which are mental operators."}, {"time": 8429, "text": "And the zero order is in some sense, the direct sense of what you're deciding."}, {"time": 8436, "text": "So you observe yourself initiating an action, there are features that you interpret as the initiation of an action."}, {"time": 8442, "text": "Then you perform the operations that you perform to make that happen."}, {"time": 8447, "text": "And then you see the movement of your limbs and you learn to associate those and thereby model your own agency over this feedback, right?"}, {"time": 8452, "text": "But the first feedback that you get is from this first order thing already."}, {"time": 8456, "text": "Basically, you decide to think a thought and the thought is being thought."}, {"time": 8461, "text": "You decide to change the thought and you observe how the thought is being changed."}, {"time": 8465, "text": "And in some sense, this is, you could say, an embodiment already, right?"}, {"time": 8465, "text": "And I suspect it's sufficient as an embodiment for intelligence."}, {"time": 8470, "text": "And so it's not that important at least at this time to consider variations in the second order."}, {"time": 8474, "text": "But the thing that you also put mentioned just now is physics that you could change in any way you want."}, {"time": 8484, "text": "So you need an environment that puts up resistance against you."}, {"time": 8484, "text": "If there's nothing to control, you cannot make models, right?"}, {"time": 8489, "text": "There needs to be a particular way that resists you."}, {"time": 8494, "text": "And by the way, your motivation is usually outside of your mind."}, {"time": 8494, "text": "It resists you."}, {"time": 8494, "text": "Motivation is what gets you up in the morning even though it would be much less work to stay in bed."}, {"time": 8503, "text": "So it's basically forcing you to resist the environment and it forces your mind to serve it, to serve this resistance to the environment."}, {"time": 8511, "text": "So in some sense, it is also putting up resistance against the natural tendency of the mind to not do anything."}, {"time": 8516, "text": "So some of that resistance, just like you described with motivation is like in the first order, it's in the mind."}, {"time": 8525, "text": "Some resistance is in the second order, like actual physical objects pushing against you and so on."}, {"time": 8531, "text": "It seems that the second order stuff in virtual reality could be recreated."}, {"time": 8534, "text": "But it might be sufficient that you just do mathematics and mathematics is already putting up enough resistance against you."}, {"time": 8539, "text": "So basically just with an aesthetic motive, this could maybe sufficient to form a type of intelligence."}, {"time": 8544, "text": "It would probably not be a very human intelligence, but it might be one that is already general."}, {"time": 8549, "text": "So to mess with this zero order, maybe first order, what do you think about ideas of brain computer interfaces?"}, {"time": 8557, "text": "So again, returning to our friend Elon Musk and Neuralink, a company that's trying to, of course, there's a lot of a trying to cure diseases and so on with a near term, but the longterm vision is to add an extra layer to basically expand the capacity of the brain connected to the computational world."}, {"time": 8583, "text": "Do you think one that's possible too, how does that change the fundamentals of the zeroth order in the first order?"}, {"time": 8587, "text": "It's technically possible, but I don't see that the FDA would ever allow me to drill holes in my skull to interface my neocortex the way Elon Musk envisions."}, {"time": 8591, "text": "So at the moment, I can do horrible things to mice, but I'm not able to do useful things to people, except maybe at some point down the line in medical applications."}, {"time": 8601, "text": "So this thing that we are envisioning, which means recreational and creational brain computer interfaces are probably not going to happen in the present legal system."}, {"time": 8616, "text": "I love it how I'm asking you out there philosophical and sort of engineering questions."}, {"time": 8623, "text": "And for the first time ever, you jumped to the legal FDA."}, {"time": 8628, "text": "There would be enough people that would be crazy enough to have holes drilled in their skull to try a new type of brain computer interface."}, {"time": 8631, "text": "But also, if it works, FDA will approve it."}, {"time": 8637, "text": "I mean, yes, it's like, you know, I work a lot with autonomous vehicles."}, {"time": 8637, "text": "Yes, you can say that it's going to be a very difficult regulatory process of approving autonomous, but it doesn't mean autonomous vehicles are never going to happen."}, {"time": 8648, "text": "No, they will totally happen as soon as we create jobs for at least two lawyers and one regulator per car."}, {"time": 8657, "text": "Yes, lawyers, that's actually like lawyers is the fundamental substrate of reality."}, {"time": 8664, "text": "In the US, it's a very weird system."}, {"time": 8664, "text": "It's not universal in the world."}, {"time": 8664, "text": "The law is a very interesting software once you realize it, right?"}, {"time": 8670, "text": "These circuits are in some sense streams of software and this is largely works by exception handling."}, {"time": 8674, "text": "So you make decisions on the ground and they get synchronized with the next level structure as soon as an exception is being thrown."}, {"time": 8683, "text": "So it escalates the exception handling."}, {"time": 8683, "text": "The process is very expensive, especially since it incentivizes the lawyers for producing work for lawyers."}, {"time": 8694, "text": "Yes, so the exceptions are actually incentivized for firing often."}, {"time": 8694, "text": "But to return, outside of lawyers, is there anything interesting, insightful about the possibility of this extra layer of intelligence added to the brain?"}, {"time": 8715, "text": "I do think so, but I don't think that you need technically invasive procedures to do so."}, {"time": 8720, "text": "We can already interface with other people by observing them very, very closely and getting in some kind of empathetic resonance."}, {"time": 8725, "text": "And I'm not very good at this, but I noticed that people are able to do this to some degree."}, {"time": 8731, "text": "And it basically means that we model an interface layer of the other person in real time."}, {"time": 8737, "text": "And it works despite our neurons being slow because most of the things that we do are built on periodic processes."}, {"time": 8742, "text": "So you just need to entrain yourself with the oscillation that happens."}, {"time": 8746, "text": "And if the oscillation itself changes slowly enough, you can basically follow along."}, {"time": 8754, "text": "But the bandwidth of the interaction, it seems like you can do a lot more computation when there's... Of course."}, {"time": 8764, "text": "But the other thing is that the bandwidth that our brain, our own mind is running on is actually quite slow."}, {"time": 8768, "text": "So the number of thoughts that I can productively think in any given day is quite limited."}, {"time": 8772, "text": "If they had the discipline to write it down and the speed to write it down, maybe it would be a book every day or so."}, {"time": 8778, "text": "But if you think about the computers that we can build, the magnitudes at which they operate, this would be nothing."}, {"time": 8788, "text": "It's something that it can put out in a second."}, {"time": 8790, "text": "So it's possible the number of thoughts you have in your brain is..."}, {"time": 8790, "text": "It could be several orders of magnitude higher than what you're possibly able to express through your fingers or through your voice."}, {"time": 8805, "text": "Most of them are going to be repetitive because they... How do you know that?"}, {"time": 8808, "text": "If they have to control the same problems every day."}, {"time": 8808, "text": "When I walk, there are going to be processes in my brain that model my walking pattern and regulate them and so on."}, {"time": 8813, "text": "But it's going to be pretty much the same every day."}, {"time": 8819, "text": "But that could be... Every step."}, {"time": 8821, "text": "But I'm talking about intellectual reasoning, thinking."}, {"time": 8821, "text": "So the question, what is the best system of government?"}, {"time": 8824, "text": "So you sit down and start thinking about that."}, {"time": 8824, "text": "One of the constraints is that you don't have access to a lot of facts, a lot of studies."}, {"time": 8829, "text": "You always have to interface with something else to learn more, to aid in your reasoning process."}, {"time": 8836, "text": "If you can directly access all of Wikipedia in trying to understand what is the best form of government, then every thought won't be stuck in a loop."}, {"time": 8848, "text": "Every thought that requires some extra piece of information will be able to grab it really quickly."}, {"time": 8853, "text": "That's the possibility of if the bottleneck is literally the information that..."}, {"time": 8858, "text": "The bottleneck of breakthrough ideas is just being able to quickly access huge amounts of information, then the possibility of connecting your brain to the computer could lead to totally new breakthroughs."}, {"time": 8871, "text": "You can think of mathematicians being able to just up the orders of magnitude of power in their reasoning about mathematical proofs."}, {"time": 8888, "text": "What if humanity has already discovered the optimal form of government through an evolutionary process?"}, {"time": 8892, "text": "There is an evolution going on."}, {"time": 8892, "text": "So what we discover is that maybe the problem of government doesn't have stable solutions for us as a species, because we are not designed in such a way that we can make everybody conform to them."}, {"time": 8908, "text": "But there could be solutions that work under given circumstances or that are the best for certain environment and depends on, for instance, the primary forms of ownership and the means of production."}, {"time": 8918, "text": "So if the main means of production is land, then the forms of government will be regulated by the landowners and you get a monarchy."}, {"time": 8925, "text": "If you also want to have a form of government in which you depend on some form of slavery, for instance, where the peasants have to work very long hours for very little gain, so very few people can have plumbing, then maybe you need to promise them to get paid in the afterlife, the overtime."}, {"time": 8941, "text": "So you need a theocracy."}, {"time": 8948, "text": "And so for much of human history in the West, we had a combination of monarchy and theocracy that was our form of governance."}, {"time": 8954, "text": "At the same time, the Catholic Church implemented game theoretic principles."}, {"time": 8961, "text": "I recently reread Thomas Aquinas."}, {"time": 8961, "text": "It's very interesting to see this because he was not dualist."}, {"time": 8967, "text": "He was translating Aristotle in a particular way for designing an operating system for the Catholic society."}, {"time": 8972, "text": "And he says that basically people are animals in very much the same way as Aristotle envisions, which is basically organisms with cybernetic control."}, {"time": 8979, "text": "And then he says that there are additional rational principles that humans can discover and everybody can discover them so they are universal."}, {"time": 8988, "text": "If you are sane, you should understand, you should submit to them because you can rationally deduce them."}, {"time": 8993, "text": "And these principles are roughly you should be willing to self regulate correctly."}, {"time": 9000, "text": "You should be willing to do correct social regulation."}, {"time": 9000, "text": "It's intraorganismic."}, {"time": 9006, "text": "You should be willing to act on your models so you have skin in the game."}, {"time": 9017, "text": "And you should have goal rationality."}, {"time": 9017, "text": "You should be choosing the right goals to work on."}, {"time": 9020, "text": "So basically these three rational principles, goal rationality he calls prudence or wisdom, social regulation is justice, the correct social one, and the internal regulation is temperance."}, {"time": 9033, "text": "And this willingness to act on your models is courage."}, {"time": 9033, "text": "And then he says that there are additionally to these four cardinal virtues, three divine virtues."}, {"time": 9040, "text": "And these three divine virtues cannot be rationally deduced, but they reveal themselves by the harmony, which means if you assume them and you extrapolate what's going to happen, you will see that they make sense."}, {"time": 9055, "text": "And it's often been misunderstood as God has to tell you that these are the things."}, {"time": 9055, "text": "So basically there's something nefarious going on."}, {"time": 9060, "text": "The Christian conspiracy forces you to believe some guy with a long beard that they discovered this."}, {"time": 9065, "text": "So these principles are relatively simple."}, {"time": 9071, "text": "Again, it's for high level organization for the resulting civilization that you form."}, {"time": 9076, "text": "A commitment to unity."}, {"time": 9076, "text": "So basically you serve this higher, larger thing, this structural principle on the next level."}, {"time": 9081, "text": "And he calls that faith."}, {"time": 9081, "text": "Then there needs to be a commitment to shared purpose."}, {"time": 9088, "text": "This is basically this global reward that you try to figure out what that should be and how you can facilitate this."}, {"time": 9092, "text": "And this is love."}, {"time": 9092, "text": "The commitment to shared purpose is the core of love, right?"}, {"time": 9096, "text": "You see the sacred thing that is more important than your own organismic interests in the other, and you serve this together."}, {"time": 9100, "text": "And this is how you see the sacred in the other."}, {"time": 9105, "text": "And the last one is hope, which means you need to be willing to act on that principle without getting rewards in the here and now because it doesn't exist yet."}, {"time": 9115, "text": "Then you start out building the civilization, right?"}, {"time": 9115, "text": "So you need to be able to do this in the absence of its actual existence yet."}, {"time": 9119, "text": "So it can come into being."}, {"time": 9119, "text": "So the way it comes into being is by you accepting those notions and then you see these three divine concepts and you see them realized."}, {"time": 9132, "text": "Divine is a loaded concept in our world because we are outside of this cult and we are still scarred from breaking free of it."}, {"time": 9138, "text": "But the idea is basically we need to have a civilization that acts as an intentional agent, like an insect state."}, {"time": 9143, "text": "And we are not actually a tribal species, we are a state building species."}, {"time": 9148, "text": "And what enables state building is basically the formation of religious states and other forms of rule based administration in which the individual doesn't matter as much as the rule or the higher goal."}, {"time": 9160, "text": "We got there by the question, what's the optimal form of governance?"}, {"time": 9165, "text": "So I don't think that Catholicism is the optimal form of governance because it's obviously on the way out, right?"}, {"time": 9170, "text": "So it is for the present type of society that we are in."}, {"time": 9174, "text": "Religious institutions don't seem to be optimal to organize that."}, {"time": 9174, "text": "So what we discovered right now that we live in in the West is democracy."}, {"time": 9181, "text": "And democracy is the rule of oligarchs that are the people that currently own the means of production that is administered not by the oligarchs themselves because there's too much disruption."}, {"time": 9191, "text": "We have so much innovation that we have in every generation new means of production that we invent."}, {"time": 9197, "text": "And corporations die usually after 30 years or so and something other takes a leading role in our societies."}, {"time": 9203, "text": "So it's administered by institutions and these institutions themselves are not elected but they provide continuity and they are led by electable politicians."}, {"time": 9215, "text": "And this makes it possible that you can adapt to change without having to kill people, right?"}, {"time": 9220, "text": "So you can, for instance, have a change in governments if people think that the current government is too corrupt or is not up to date, you can just elect new people."}, {"time": 9224, "text": "Or if a journalist finds out something inconvenient about the institution and the institution has no plan B like in Russia, the journalist has to die."}, {"time": 9235, "text": "This is when you run society by the deep state."}, {"time": 9235, "text": "So ideally you have an administration layer that you can change if something bad happens, right?"}, {"time": 9242, "text": "So you will have a continuity in the whole thing."}, {"time": 9249, "text": "And this is the system that we came up in the West."}, {"time": 9253, "text": "And the way it's set up in the US is largely a result of low level models."}, {"time": 9253, "text": "So it's mostly just second, third order consequences that people are modeling in the design of these institutions."}, {"time": 9257, "text": "So it's a relatively young society that doesn't really take care of the downstream effects of many of the decisions that are being made."}, {"time": 9267, "text": "And I suspect that AI can help us this in a way if you can fix the incentives."}, {"time": 9273, "text": "The society of the US is a society of cheaters."}, {"time": 9273, "text": "It's basically cheating is so indistinguishable from innovation and we want to encourage innovation."}, {"time": 9279, "text": "Can you elaborate on what you mean by cheating?"}, {"time": 9284, "text": "It's basically people do things that they know are wrong."}, {"time": 9284, "text": "It's acceptable to do things that you know are wrong in this society to a certain degree."}, {"time": 9288, "text": "You can, for instance, suggest some non sustainable business models and implement them."}, {"time": 9292, "text": "But you're always pushing the boundaries."}, {"time": 9297, "text": "I mean, yes, this is seen as a good thing largely."}, {"time": 9297, "text": "And this is different from other societies."}, {"time": 9305, "text": "So for instance, social mobility is an aspect of this."}, {"time": 9305, "text": "Social mobility is the result of individual innovation that would not be sustainable at scale for everybody else."}, {"time": 9314, "text": "Normally you should not go up, you should go deep, right?"}, {"time": 9314, "text": "We need bakers and if we are very very good bakers, but in a society that innovates, maybe you can replace all the bakers with a really good machine."}, {"time": 9323, "text": "And that's not a bad thing."}, {"time": 9323, "text": "And it's a thing that made the US so successful, right?"}, {"time": 9329, "text": "But it also means that the US is not optimizing for sustainability, but for innovation."}, {"time": 9334, "text": "And so it's not obvious as the evolutionary process is unrolling, it's not obvious that that long term would be better."}, {"time": 9339, "text": "It has side effects."}, {"time": 9339, "text": "So you basically, if you cheat, you will have a certain layer of toxic sludge that covers everything that is a result of cheating."}, {"time": 9350, "text": "And we have to unroll this evolutionary process to figure out if these side effects are so damaging that the system is horrible, or if the benefits actually outweigh the negative effects."}, {"time": 9363, "text": "How do we get to which system of government is best?"}, {"time": 9363, "text": "That was from, I'm trying to trace back the last like five minutes."}, {"time": 9370, "text": "I suspect that we can find a way back to AI by thinking about the way in which our brain has to organize itself."}, {"time": 9376, "text": "In some sense, our brain is a society of neurons."}, {"time": 9376, "text": "And our mind is a society of behaviors."}, {"time": 9384, "text": "And they need to be organizing themselves into a structure that implements regulation and government is social regulation."}, {"time": 9390, "text": "We often see government as the manifestation of power or local interests, but it's actually a platform for negotiating the conditions of human survival."}, {"time": 9400, "text": "And this platform emerges over the current needs and possibilities and the trajectory that we have."}, {"time": 9406, "text": "So given the present state, there are only so many options on how we can move into the next state without completely disrupting everything."}, {"time": 9412, "text": "And we mostly agree that it's a bad idea to disrupt everything because it will endanger our food supply for a while and the entire infrastructure and fabric of society."}, {"time": 9421, "text": "So we do try to find natural transitions, and there are not that many natural transitions available at any given point."}, {"time": 9430, "text": "What do you mean by natural transitions?"}, {"time": 9432, "text": "So we try not to have revolutions if we can have it."}, {"time": 9434, "text": "So speaking of revolutions and the connection between government systems and the mind, you've also said that in some sense, becoming an adult means you take charge of your emotions."}, {"time": 9449, "text": "Maybe you never said that."}, {"time": 9449, "text": "Maybe I just made that up."}, {"time": 9449, "text": "But in the context of the mind, what's the role of emotion?"}, {"time": 9455, "text": "And what is it?"}, {"time": 9455, "text": "First of all, what is emotion?"}, {"time": 9455, "text": "What's its role?"}, {"time": 9462, "text": "It's several things."}, {"time": 9462, "text": "So psychologists often distinguish between emotion and feeling, and in common day parlance, we don't."}, {"time": 9466, "text": "I think that emotion is a configuration of the cognitive system."}, {"time": 9472, "text": "And that's especially true for the lowest level for the affective state."}, {"time": 9472, "text": "So when you have an affect, it's the configuration of certain modulation parameters like arousal, valence, your attentional focus, whether it's wide or narrow, inter reception or extra reception, and so on."}, {"time": 9488, "text": "And all these parameters together put you in a certain way."}, {"time": 9488, "text": "You relate to the environment and to yourself, and this is in some sense an emotional configuration."}, {"time": 9497, "text": "In the more narrow sense, an emotion is an affective state."}, {"time": 9497, "text": "It has an object, and the relevance of that object is given by motivation."}, {"time": 9502, "text": "And motivation is a bunch of needs that are associated with rewards, things that give you pleasure and pain."}, {"time": 9506, "text": "And you don't actually act on your needs, you act on models of your needs."}, {"time": 9511, "text": "Because when the pleasure and pain manifest, it's too late, you've done everything."}, {"time": 9515, "text": "So you act on expectations that will give you pleasure and pain."}, {"time": 9520, "text": "And these are your purposes."}, {"time": 9520, "text": "The needs don't form a hierarchy, they just coexist and compete."}, {"time": 9525, "text": "And your brain has to find a dynamic homeostasis between them."}, {"time": 9525, "text": "But the purposes need to be consistent."}, {"time": 9531, "text": "So you basically can create a story for your life and make plans."}, {"time": 9531, "text": "And so we organize them all into hierarchies."}, {"time": 9537, "text": "And there is not a unique solution for this."}, {"time": 9537, "text": "Some people eat to make art and other people make art to eat."}, {"time": 9542, "text": "They might end up doing the same things, but they cooperate in very different ways."}, {"time": 9547, "text": "Because their ultimate goals are different."}, {"time": 9547, "text": "And we cooperate based on shared purpose."}, {"time": 9552, "text": "Everything else that is not cooperation on shared purpose is transactional."}, {"time": 9556, "text": "I don't think I understood that last piece of achieving the homeostasis."}, {"time": 9566, "text": "Are you distinguishing between the experience of emotion and the expression of emotion?"}, {"time": 9570, "text": "So the experience of emotion is a feeling."}, {"time": 9570, "text": "And in this sense, what you feel is an appraisal that your perceptual system has made of the situation at hand."}, {"time": 9577, "text": "And it makes this based on your motivation and on your estimates, not your but of the subconscious geometric parts of your mind that assess the situation in the world with something like a neural network."}, {"time": 9590, "text": "And this neural network is making itself known to the symbolic parts of your mind, to your conscious attention by mapping them as features into a space."}, {"time": 9602, "text": "So what you will feel about your emotion is a projection usually into your body map."}, {"time": 9608, "text": "So you might feel anxiety in your solar plexus, and you might feel it as a contraction, which is all geometry."}, {"time": 9612, "text": "Your body map is the space that is always instantiated and always available."}, {"time": 9618, "text": "So it's a very obvious cheat if your non symbolic parts of your brain try to talk to your symbolic parts of your brain to map the feelings into the body map."}, {"time": 9631, "text": "And then you perceive them as pleasant and unpleasant, depending on whether the appraisal has a negative or positive valence."}, {"time": 9635, "text": "And then you have different features of them that give you more knowledge about the nature of what you're feeling."}, {"time": 9640, "text": "So for instance, when you feel connected to other people, you typically feel this in your chest region around the heart."}, {"time": 9648, "text": "And you feel this is an expansive feeling in which you're reaching out, right?"}, {"time": 9648, "text": "And it's very intuitive to encode it like this."}, {"time": 9653, "text": "That's why it's encoded like this."}, {"time": 9653, "text": "It's a code in which the non symbolic parts of your mind talk to the symbolic ones."}, {"time": 9659, "text": "And then the expression of emotion is then the final step that could be sort of gestural or visual and so on."}, {"time": 9664, "text": "That's part of the communication."}, {"time": 9669, "text": "This probably evolved as part of an adversarial communication."}, {"time": 9669, "text": "So as soon as you started to observe the facial expression and posture of others to understand what emotional state they're in, others started to use this as signaling and also to subvert your model of their emotional state."}, {"time": 9683, "text": "So we now look at the inflections, at the difference between the standard face that they're going to make in this situation."}, {"time": 9689, "text": "When you are at a funeral, everybody expects you to make a solemn face, but the solemn face doesn't express whether you're sad or not."}, {"time": 9693, "text": "It just expresses that you understand what face you have to make at a funeral."}, {"time": 9698, "text": "Nobody should know that you are triumphant."}, {"time": 9704, "text": "So when you try to read the emotion of another person, you try to look at the delta between a truly sad expression and the things that are animating this face behind the curtain."}, {"time": 9716, "text": "So the interesting thing is, so having done this podcast and the video component, one of the things I've learned is that now I'm Russian and I just don't know how to express emotion on my face."}, {"time": 9730, "text": "One, I see that as weakness, but whatever."}, {"time": 9730, "text": "The people look to me after you say something, they look to my face to help them see how they should feel about what you said, which is fascinating because then they'll often comment on why did you look bored or why did you particularly enjoy that part or why did you whatever."}, {"time": 9748, "text": "It's a kind of interesting, it makes me cognizant of I'm part, like you're basically saying a bunch of brilliant things, but I'm part of the play that you're the key actor in by making my facial expressions and then therefore telling the narrative of what the big, like the big point is, which is fascinating."}, {"time": 9771, "text": "Makes me cognizant that I'm supposed to be making facial expressions."}, {"time": 9771, "text": "Even this conversation is hard because my preference would be to wear a mask with sunglasses to where I could just listen."}, {"time": 9781, "text": "Yes, I understand this because it's intrusive to interact with others this way."}, {"time": 9781, "text": "And basically Eastern European society have a taboo against that and especially Russia, the further you go to the East and in the US it's the opposite."}, {"time": 9791, "text": "You're expected to be hyperanimated in your face and you're also expected to show positive affect."}, {"time": 9802, "text": "And if you show positive affect without a good reason in Russia, people will think you are a stupid, unsophisticated person."}, {"time": 9813, "text": "And here positive affect without reason goes either appreciated or goes unnoticed."}, {"time": 9820, "text": "No, it's the default."}, {"time": 9820, "text": "It's being expected."}, {"time": 9820, "text": "Everything is amazing."}, {"time": 9820, "text": "Have you seen these?"}, {"time": 9825, "text": "Lego movie?"}, {"time": 9827, "text": "No, there was a diagram where somebody gave the appraisals that exist in the US and Russia, so you have your bell curve."}, {"time": 9832, "text": "And the lower 10% in the US, it's a good start."}, {"time": 9832, "text": "Everything above the lowest 10%, it's amazing."}, {"time": 9846, "text": "And for Russians, everything below the top 10%, it's terrible."}, {"time": 9846, "text": "And then everything except the top percent is, I don't like it."}, {"time": 9854, "text": "And the top percent is even so."}, {"time": 9863, "text": "It's funny, but it's kind of true."}, {"time": 9867, "text": "There's a deeper aspect to this."}, {"time": 9867, "text": "It's also how we construct meaning in the US."}, {"time": 9867, "text": "Usually you focus on the positive aspects and you just suppress the negative aspects."}, {"time": 9873, "text": "And in our Eastern European traditions, we emphasize the fact that if you hold something above the waterline, you also need to put something below the waterline because existence by itself is as best neutral."}, {"time": 9891, "text": "That's the basic intuition, at best neutral."}, {"time": 9891, "text": "Or it could be just suffering, the default is suffering."}, {"time": 9896, "text": "There are moments of beauty, but these moments of beauty are inextricably linked to the reality of suffering."}, {"time": 9902, "text": "And to not acknowledge the reality of suffering means that you are really stupid and unaware of the fact that basically every conscious being spends most of the time suffering."}, {"time": 9912, "text": "You just summarized the ethos of the Eastern Europe."}, {"time": 9912, "text": "Most of life is suffering with an occasional moments of beauty."}, {"time": 9919, "text": "And if your facial expressions don't acknowledge the abundance of suffering in the world and in existence itself, then you must be an idiot."}, {"time": 9930, "text": "It's an interesting thing when you raise children in the US and you, in some sense, preserve the identity of the intellectual and cultural traditions that are embedded in your own families."}, {"time": 9940, "text": "And your daughter asks you about Ariel the mermaid and asks you, why is Ariel not allowed to play with the humans?"}, {"time": 9946, "text": "And you tell her the truth."}, {"time": 9946, "text": "She's a siren."}, {"time": 9946, "text": "Sirens eat people."}, {"time": 9953, "text": "You don't play with your food."}, {"time": 9953, "text": "It does not end well."}, {"time": 9953, "text": "And then you tell her the original story, which is not the one by Anderson, which is the romantic one."}, {"time": 9958, "text": "And there's a much darker one, which is Undine's story."}, {"time": 9962, "text": "So Undine is a mermaid or a water woman."}, {"time": 9962, "text": "She lives on the ground of a river and she meets this prince and they fall in love."}, {"time": 9971, "text": "And the prince really, really wants to be with her."}, {"time": 9975, "text": "And she says, okay, but the deal is you cannot have any other woman."}, {"time": 9980, "text": "If you marry somebody else, even though you cannot be with me, because obviously you cannot breathe underwater and have other things to do than managing your kingdom as you have here, you will die."}, {"time": 9989, "text": "And eventually after a few years, he falls in love with some princess and marries her."}, {"time": 9989, "text": "And she shows up and quietly goes into his chamber and nobody is able to stop her or willing to do so because she is fierce."}, {"time": 10001, "text": "And she comes quietly and sad out of his chamber."}, {"time": 10001, "text": "And they ask her, what has happened?"}, {"time": 10007, "text": "And she said, I kissed him to death."}, {"time": 10012, "text": "All done."}, {"time": 10013, "text": "And you know the Anderson story, right?"}, {"time": 10013, "text": "In the Anderson story, the mermaid is playing with this prince that she saves and she falls in love with him and she cannot live out there."}, {"time": 10019, "text": "So she is giving up her voice and her tale for a human like appearance so she can walk among the humans."}, {"time": 10024, "text": "But this guy does not recognize that she is the one that you would marry."}, {"time": 10031, "text": "Instead, he marries somebody who has a kingdom and economical and political relationships to his own kingdom and so on, as he should."}, {"time": 10042, "text": "And she dies."}, {"time": 10045, "text": "Instead, Disney, the Little Mermaid story has a little bit of a happy ending."}, {"time": 10045, "text": "That's the Western, that's the American way."}, {"time": 10057, "text": "My own problem is this, of course, that I read Oscar Wilde before I read the other things."}, {"time": 10057, "text": "So I'm indoctrinated, inoculated with this romanticism."}, {"time": 10061, "text": "And I think that the mermaid is right."}, {"time": 10061, "text": "You sacrifice your life for romantic love."}, {"time": 10066, "text": "That's what you do."}, {"time": 10066, "text": "Because if you are confronted with either serving the machine and doing the obviously right thing under the economic and social and other human incentives, that's wrong."}, {"time": 10077, "text": "You should follow your heart."}, {"time": 10084, "text": "So do you think suffering is fundamental to happiness along these lines?"}, {"time": 10089, "text": "Suffering is the result of caring about things that you cannot change."}, {"time": 10089, "text": "And if you are able to change what you care about to those things that you can change, you will not suffer."}, {"time": 10097, "text": "But would you then be able to experience happiness?"}, {"time": 10102, "text": "But happiness itself is not important."}, {"time": 10102, "text": "Happiness is like a cookie."}, {"time": 10102, "text": "When you are a child, you think cookies are very important and you want to have all the cookies in the world, you look forward to being an adult because then you have as many cookies as you want."}, {"time": 10115, "text": "But as an adult, you realize a cookie is a tool."}, {"time": 10115, "text": "It's a tool to make you eat vegetables."}, {"time": 10120, "text": "And once you eat your vegetables anyway, you stop eating cookies for the most part, because otherwise you will get diabetes and will not be around for your kids."}, {"time": 10126, "text": "Yes, but then the cookie, the scarcity of a cookie, if scarcity is enforced, nevertheless, so like the pleasure comes from the scarcity."}, {"time": 10134, "text": "But the happiness is a cookie that your brain bakes for itself."}, {"time": 10134, "text": "It's not made by the environment."}, {"time": 10139, "text": "The environment cannot make you happy."}, {"time": 10139, "text": "It's your appraisal of the environment that makes you happy."}, {"time": 10143, "text": "And if you can change the appraisal of the environment, which you can learn to, then you can create arbitrary states of happiness."}, {"time": 10147, "text": "And some meditators fall into this trap."}, {"time": 10151, "text": "So they discover the womb, this basement womb in their brain where the cookies are made, and they indulge and stuff themselves."}, {"time": 10156, "text": "And after a few months, it gets really old and the big crisis of meaning comes."}, {"time": 10160, "text": "Because they thought before that their unhappiness was the result of not being happy enough."}, {"time": 10165, "text": "So they fixed this, right?"}, {"time": 10165, "text": "They can release the newer transmitters at will if they train."}, {"time": 10169, "text": "And then the crisis of meaning pops up in a deeper layer."}, {"time": 10176, "text": "And the question is, why do I live?"}, {"time": 10176, "text": "How can I make a sustainable civilization that is meaningful to me?"}, {"time": 10180, "text": "How can I insert myself into this?"}, {"time": 10180, "text": "And this was the problem that you couldn't solve in the first place."}, {"time": 10184, "text": "But at the end of all this, let me then ask that same question."}, {"time": 10184, "text": "What is the answer to that?"}, {"time": 10193, "text": "What could the possible answer be of the meaning of life?"}, {"time": 10193, "text": "What could an answer be?"}, {"time": 10193, "text": "What is it to you?"}, {"time": 10199, "text": "I think that if you look at the meaning of life, you look at what the cell is."}, {"time": 10199, "text": "Life is the cell."}, {"time": 10206, "text": "Or this principle, the cell."}, {"time": 10206, "text": "It's this self organizing thing that can participate in evolution."}, {"time": 10214, "text": "In order to make it work, it's a molecular machine."}, {"time": 10214, "text": "It needs a self replicator and an entropy extractor and a Turing machine."}, {"time": 10218, "text": "If any of these parts is missing, you don't have a cell and it is not living."}, {"time": 10222, "text": "And life is basically the emergent complexity over that principle."}, {"time": 10227, "text": "Once you have this intelligent super molecule, the cell, there is very little that you cannot make it do."}, {"time": 10232, "text": "It's probably the optimal computronium and especially in terms of resilience."}, {"time": 10232, "text": "It's very hard to sterilize the planet once it's infected with life."}, {"time": 10237, "text": "So it's active function of these three components or the supercell cell is present in the cell, it's present in us, and it's just... We are just an expression of the cell."}, {"time": 10251, "text": "It's a certain layer of complexity in the organization of cells."}, {"time": 10255, "text": "So in a way, it's tempting to think of the cell as a von Neumann probe."}, {"time": 10255, "text": "If you want to build intelligence on other planets, the best way to do this is to infect them with cells and wait for long enough and there's a reasonable chance the stuff is going to evolve into an information processing principle that is general enough to become sentient."}, {"time": 10276, "text": "That idea is very akin to the same dream and beautiful ideas that are expressed to cellular automata in their most simple mathematical form."}, {"time": 10281, "text": "If you just inject the system with some basic mechanisms of replication and so on, basic rules, amazing things would emerge."}, {"time": 10292, "text": "The cell is able to do something that James Trardy calls existential design."}, {"time": 10292, "text": "He points out that in technical design, we go from the outside in."}, {"time": 10298, "text": "We work in a highly controlled environment in which everything is deterministic, like our computers, our labs, or our engineering workshops."}, {"time": 10308, "text": "And then we use this determinism to implement a particular kind of function that we dream up and that seamlessly interfaces with all the other deterministic functions that we already have in our world."}, {"time": 10317, "text": "So it's basically from the outside in."}, {"time": 10317, "text": "Biological systems designed from the inside out as seed will become a seedling by taking some of the relatively unorganized matter around it and turning it into its own structure and thereby subdue the environment."}, {"time": 10331, "text": "Cells can cooperate if they can rely on other cells having a similar organization that is already compatible."}, {"time": 10336, "text": "But unless that's there, the cell needs to divide to create that structure by itself."}, {"time": 10341, "text": "So it's a self organizing principle that works on a somewhat chaotic environment."}, {"time": 10347, "text": "And the purpose of life in this sense is to produce complexity."}, {"time": 10352, "text": "And the complexity allows you to harvest entropy gradients that you couldn't harvest without the complexity."}, {"time": 10358, "text": "And in this sense, intelligence and life are very strongly connected because the purpose of intelligence is to allow control under conditions and the conditions of complexity."}, {"time": 10368, "text": "So basically, you shift the boundary between the ordered systems into the realm of chaos."}, {"time": 10373, "text": "You build bridge heads into chaos with complexity."}, {"time": 10373, "text": "And this is what we are doing."}, {"time": 10380, "text": "This is not necessarily a deeper meaning."}, {"time": 10380, "text": "I think the meaning that we have priors for that we are all for outside of the priors, there is no meaning."}, {"time": 10385, "text": "Meaning only exists if the mind projects it."}, {"time": 10389, "text": "That is probably civilization."}, {"time": 10389, "text": "I think that what feels most meaningful to me is to try to build and maintain a sustainable civilization."}, {"time": 10396, "text": "And taking a slight step outside of that, we talked about a man with a beard and God, but something, some mechanism, perhaps must have planted the seed, the initial seed of the cell."}, {"time": 10414, "text": "Do you think there is a God?"}, {"time": 10414, "text": "What is a God?"}, {"time": 10422, "text": "And what would that look like?"}, {"time": 10422, "text": "If there was no spontaneous biogenesis, in the sense that the first cell formed by some happy random accidents where the molecules just happened to be in the right constellation to each other."}, {"time": 10434, "text": "But there could also be the mechanism that allows for the random."}, {"time": 10439, "text": "I mean, there's like turtles all the way down."}, {"time": 10439, "text": "There seems to be, there has to be a head turtle at the bottom."}, {"time": 10444, "text": "Let's consider something really wild."}, {"time": 10444, "text": "Imagine, is it possible that a gas giant could become intelligent?"}, {"time": 10450, "text": "What would that involve?"}, {"time": 10450, "text": "So imagine you have vortices that spontaneously emerge on the gas giants, like big storm systems that endure for thousands of years."}, {"time": 10461, "text": "And some of these storm systems produce electromagnetic fields because some of the clouds are ferromagnetic or something."}, {"time": 10464, "text": "And as a result, they can change how certain clouds react rather than other clouds and thereby produce some self stabilizing patterns that eventually lead to regulation feedback loops, nested feedback loops and control."}, {"time": 10474, "text": "So imagine you have such this thing that basically has emergent self sustaining, self organizing complexity."}, {"time": 10480, "text": "And at some point, this breaks up and realizes and basically lam solaris, I am a thinking planet, but I will not replicate because I can recreate the conditions of my own existence somewhere else."}, {"time": 10490, "text": "I'm just basically an intelligence that has spontaneously formed because it could."}, {"time": 10495, "text": "And now it builds a von Neumann probe and the best von Neumann probe for such a thing might be the cell."}, {"time": 10505, "text": "So maybe it, because it's very, very clever and very enduring, creates cells and sends them out."}, {"time": 10510, "text": "And one of them has infected our planet."}, {"time": 10510, "text": "And I'm not suggesting that this is the case, but it would be compatible with the Prince Birmingham hypothesis."}, {"time": 10514, "text": "And it was my intuition that our biogenesis is very unlikely."}, {"time": 10519, "text": "It's possible, but you probably need to roll the cosmic dice very often, maybe more often than there are planetary surfaces."}, {"time": 10528, "text": "So God is just a large enough, a system that's large enough that allows randomness."}, {"time": 10537, "text": "No, I don't think that God has anything to do with creation."}, {"time": 10537, "text": "I think it's a mistranslation of the Talmud into the Catholic mythology."}, {"time": 10541, "text": "I think that Genesis is actually the childhood memories of a God."}, {"time": 10546, "text": "So the, when."}, {"time": 10546, "text": "Sorry, Genesis is the."}, {"time": 10551, "text": "The childhood memories of a God."}, {"time": 10551, "text": "It's basically a mind that is remembering how it came into being."}, {"time": 10557, "text": "And we typically interpret Genesis as the creation of a physical universe by a supernatural being."}]}, {"title": "Russ Tedrake: Underactuated Robotics, Control, Dynamics and Touch | Lex Fridman Podcast #114", "id": "A22Ej6kb2wo", "quotes": [{"time": 283, "text": "The ones in particular that Steve Collins built with Andy Ruina at Cornell, a 3D walking machine."}, {"time": 290, "text": "So it was not confined to a boom or a plane that you put it on top of a small ramp, give it a little push, it's powered only by gravity."}, {"time": 300, "text": "No controllers, no batteries whatsoever."}, {"time": 304, "text": "It just falls down the ramp."}, {"time": 306, "text": "And at the time it looked more natural, more graceful, more human like than any robot we'd seen to date powered only by gravity."}, {"time": 315, "text": "How does it work?"}, {"time": 317, "text": "Well, okay, the simplest model, it's kind of like a slinky."}, {"time": 319, "text": "It's like an elaborate slinky."}, {"time": 321, "text": "One of the simplest models we used to think about it is actually a rimless wheel."}, {"time": 325, "text": "So imagine taking a bicycle wheel, but take the rim off."}, {"time": 330, "text": "So it's now just got a bunch of spokes."}, {"time": 332, "text": "If you give that a push, it still wants to roll down the ramp, but every time its foot, its spoke comes around and hits the ground, it loses a little energy."}, {"time": 341, "text": "Every time it takes a step forward, it gains a little energy."}, {"time": 345, "text": "Those things can come into perfect balance."}, {"time": 348, "text": "And actually they want to, it's a stable phenomenon."}, {"time": 351, "text": "If it's going too slow, it'll speed up."}, {"time": 353, "text": "If it's going too fast, it'll slow down and it comes into a stable periodic motion."}, {"time": 359, "text": "Now you can take that rimless wheel, which doesn't look very much like a human walking, take all the extra spokes away, put a hinge in the middle."}, {"time": 368, "text": "Now it's two legs."}, {"time": 369, "text": "That's called our compass gait walker."}, {"time": 371, "text": "That can still, you give it a little push, it starts falling down a ramp."}, {"time": 375, "text": "It looks a little bit more like walking."}, {"time": 377, "text": "At least it's a biped."}, {"time": 379, "text": "But what Steve and Andy, and Tad McGeer started the whole exercise, but what Steve and Andy did was they took it to this beautiful conclusion where they built something that had knees, arms, a torso."}, {"time": 392, "text": "The arms swung naturally, give it a little push."}, {"time": 396, "text": "And that looked like a stroll through the park."}, {"time": 398, "text": "How do you design something like that?"}, {"time": 400, "text": "I mean, is that art or science?"}, {"time": 402, "text": "It's on the boundary."}, {"time": 403, "text": "I think there's a science to getting close to the solution."}, {"time": 407, "text": "I think there's certainly art in the way that they made a beautiful robot."}, {"time": 412, "text": "But then the finesse, because they were working with a system that wasn't perfectly modeled, wasn't perfectly controlled, there's all these little tricks that you have to tune the suction cups at the knees, for instance, so that they stick, but then they release at just the right time."}, {"time": 429, "text": "Or there's all these little tricks of the trade, which really are art, but it was a point."}, {"time": 434, "text": "I mean, it made the point."}, {"time": 436, "text": "We were, at that time, the walking robot, the best walking robot in the world was Honda's Asmo."}, {"time": 441, "text": "Absolutely marvel of modern engineering."}, {"time": 444, "text": "Is this 90s?"}, {"time": 445, "text": "This was in 97 when they first released."}, {"time": 447, "text": "It sort of announced P2, and then it went through."}, {"time": 449, "text": "It was Asmo by then in 2004."}, {"time": 452, "text": "And it looks like this very cautious walking, like you're walking on hot coals or something like that."}, {"time": 461, "text": "I think it gets a bad rap."}, {"time": 463, "text": "Asmo is a beautiful machine."}, {"time": 465, "text": "It does walk with its knees bent."}, {"time": 467, "text": "Our Atlas walking had its knees bent."}, {"time": 469, "text": "But actually, Asmo was pretty fantastic."}, {"time": 472, "text": "But it wasn't energy efficient."}, {"time": 474, "text": "Neither was Atlas when we worked on Atlas."}, {"time": 478, "text": "None of our robots that have been that complicated have been very energy efficient."}, {"time": 484, "text": "But there's a thing that happens when you do control, when you try to control a system of that complexity."}, {"time": 492, "text": "You try to use your motors to basically counteract gravity."}, {"time": 497, "text": "Take whatever the world's doing to you and push back, erase the dynamics of the world, and impose the dynamics you want because you can make them simple and analyzable, mathematically simple."}, {"time": 510, "text": "And this was a very sort of beautiful example that you don't have to do that."}, {"time": 516, "text": "You can just let go."}, {"time": 517, "text": "Let physics do most of the work, right?"}, {"time": 520, "text": "And you just have to give it a little bit of energy."}, {"time": 522, "text": "This one only walked down a ramp."}, {"time": 523, "text": "It would never walk on the flat."}, {"time": 525, "text": "To walk on the flat, you have to give a little energy at some point."}, {"time": 528, "text": "But maybe instead of trying to take the forces imparted to you by the world and replacing them, what we should be doing is letting the world push us around and we go with the flow."}, {"time": 539, "text": "Very zen, very zen robot."}, {"time": 541, "text": "Yeah, but okay, so that sounds very zen, but I can also imagine how many like failed versions they had to go through."}, {"time": 551, "text": "Like how many, like, I would say it's probably, would you say it's in the thousands that they've had to have the system fall down before they figured out how to get it?"}, {"time": 559, "text": "I don't know if it's thousands, but it's a lot."}, {"time": 562, "text": "It takes some patience."}, {"time": 565, "text": "So in that sense, control might help a little bit."}, {"time": 568, "text": "Oh, I think everybody, even at the time, said that the answer is to do with that with control."}, {"time": 575, "text": "But it was just pointing out that maybe the way we're doing control right now isn't the way we should."}, {"time": 581, "text": "So what about on the animal side, the ones that figured out how to move efficiently?"}, {"time": 586, "text": "Is there anything you find inspiring or beautiful in the movement of any particular animal?"}, {"time": 591, "text": "I do have a favorite example."}, {"time": 592, "text": "So it sort of goes with the passive walking idea."}, {"time": 597, "text": "So is there, you know, how energy efficient are animals?"}, {"time": 601, "text": "Okay, there's a great series of experiments by George Lauder at Harvard and Mike Tranofilo at MIT."}, {"time": 607, "text": "They were studying fish swimming in a water tunnel."}, {"time": 611, "text": "And one of these, the type of fish they were studying were these rainbow trout, because there was a phenomenon well understood that rainbow trout, when they're swimming upstream in mating season, they kind of hang out behind the rocks."}, {"time": 625, "text": "And it looks like, I mean, that's tiring work swimming upstream."}, {"time": 628, "text": "They're hanging out behind the rocks."}, {"time": 629, "text": "Maybe there's something energetically interesting there."}, {"time": 631, "text": "So they tried to recreate that."}, {"time": 633, "text": "They put in this water tunnel, a rock basically, a cylinder that had the same sort of vortex street, the eddies coming off the back of the rock that you would see in a stream."}, {"time": 644, "text": "And they put a real fish behind this and watched how it swims."}, {"time": 648, "text": "And the amazing thing is that if you watch from above what the fish swims when it's not behind a rock, it has a particular gate."}, {"time": 656, "text": "You can identify the fish the same way you look at a human walking down the street."}, {"time": 659, "text": "You sort of have a sense of how a human walks."}, {"time": 662, "text": "The fish has a characteristic gate."}, {"time": 665, "text": "You put that fish behind the rock, its gate changes."}, {"time": 669, "text": "And what they saw was that it was actually resonating and kind of surfing between the vortices."}, {"time": 676, "text": "Now, here was the experiment that really was the clincher."}, {"time": 680, "text": "Because there was still, it wasn't clear how much of that was mechanics of the fish, how much of that is control, the brain."}, {"time": 686, "text": "So the clincher experiment, and maybe one of my favorites to date, although there are many good experiments."}, {"time": 693, "text": "They took, this was now a dead fish."}, {"time": 698, "text": "They took a dead fish."}, {"time": 700, "text": "They put a string that went, that tied the mouth of the fish to the rock so it couldn't go back and get caught in the grates."}, {"time": 707, "text": "And then they asked what would that dead fish do when it was hanging out behind the rock?"}, {"time": 711, "text": "And so what you'd expect, it sort of flopped around like a dead fish in the vortex wake until something sort of amazing happens."}, {"time": 717, "text": "And this video is worth putting in, right?"}, {"time": 724, "text": "The dead fish basically starts swimming upstream, right?"}, {"time": 727, "text": "It's completely dead, no brain, no motors, no control."}, {"time": 732, "text": "But it's somehow the mechanics of the fish resonate with the vortex street and it starts swimming upstream."}, {"time": 738, "text": "It's one of the best examples ever."}, {"time": 740, "text": "Who do you give credit for that to?"}, {"time": 743, "text": "Is that just evolution constantly just figuring out by killing a lot of generations of animals, like the most efficient motion?"}, {"time": 753, "text": "Is that, or maybe the physics of our world completely like, is like if evolution applied not only to animals, but just the entirety of it somehow drives to efficiency, like nature likes efficiency?"}, {"time": 767, "text": "I don't know if that question even makes any sense."}, {"time": 769, "text": "I understand the question."}, {"time": 771, "text": "That's reasonable."}, {"time": 771, "text": "I mean, do they co evolve?"}, {"time": 774, "text": "Yeah, somehow co, yeah."}, {"time": 775, "text": "Like I don't know if an environment can evolve, but."}, {"time": 780, "text": "I mean, there are experiments that people do, careful experiments that show that animals can adapt to unusual situations and recover efficiency."}, {"time": 788, "text": "So there seems like at least in one direction, I think there is reason to believe that the animal's motor system and probably its mechanics adapt in order to be more efficient."}, {"time": 800, "text": "But efficiency isn't the only goal, of course."}, {"time": 803, "text": "Sometimes it's too easy to think about only efficiency, but we have to do a lot of other things first, not get eaten."}, {"time": 810, "text": "And then all other things being equal, try to save energy."}, {"time": 814, "text": "By the way, let's draw a distinction between control and mechanics."}, {"time": 818, "text": "Like how would you define each?"}, {"time": 821, "text": "I mean, I think part of the point is that we shouldn't draw a line as clearly as we tend to."}, {"time": 827, "text": "But on a robot, we have motors and we have the links of the robot, let's say."}, {"time": 834, "text": "If the motors are turned off, the robot has some passive dynamics, okay?"}, {"time": 839, "text": "Gravity does the work."}, {"time": 841, "text": "You can put springs, I would call that mechanics, right?"}, {"time": 843, "text": "If we have springs and dampers, which our muscles are springs and dampers and tendons."}, {"time": 848, "text": "But then you have something that's doing active work, putting energy in, which are your motors on the robot."}, {"time": 853, "text": "The controller's job is to send commands to the motor that add new energy into the system, right?"}, {"time": 859, "text": "So the mechanics and control interplay somewhere, the divide is around, you know, did you decide to send some commands to your motor or did you just leave the motors off, let them do their work?"}, {"time": 870, "text": "Would you say is most of nature on the dynamic side or the control side?"}, {"time": 879, "text": "So like, if you look at biological systems, we're living in a pandemic now, like, do you think a virus is a, do you think it's a dynamic system or is there a lot of control, intelligence?"}, {"time": 894, "text": "I think it's both, but I think we maybe have underestimated how important the dynamics are, right?"}, {"time": 902, "text": "I mean, even our bodies, the mechanics of our bodies, certainly with exercise, they evolve."}, {"time": 906, "text": "But so I actually, I lost a finger in early 2000s and it's my fifth metacarpal."}, {"time": 914, "text": "And it turns out you use that a lot in ways you don't expect when you're opening jars, even when I'm just walking around, if I bump it on something, there's a bone there that was used to taking contact."}, {"time": 926, "text": "My fourth metacarpal wasn't used to taking contact, it used to hurt, it still does a little bit."}, {"time": 931, "text": "But actually my bone has remodeled, right?"}, {"time": 934, "text": "Over a couple of years, the geometry, the mechanics of that bone changed to address the new circumstances."}, {"time": 944, "text": "So the idea that somehow it's only our brain that's adapting or evolving is not right."}, {"time": 950, "text": "Maybe sticking on evolution for a bit, because it's tended to create some interesting things."}, {"time": 956, "text": "Bipedal walking, why the heck did evolution give us, I think we're, are we the only mammals that walk on two feet?"}, {"time": 965, "text": "No, I mean, there's a bunch of animals that do it a bit."}, {"time": 969, "text": "I think we are the most successful bipeds."}, {"time": 972, "text": "I think I read somewhere that the reason the evolution made us walk on two feet is because there's an advantage to being able to carry food back to the tribe or something like that."}, {"time": 988, "text": "So like you can carry, it's kind of this communal, cooperative thing, so like to carry stuff back to a place of shelter and so on to share with others."}, {"time": 1000, "text": "Do you understand at all the value of walking on two feet from both a robotics and a human perspective?"}, {"time": 1008, "text": "Yeah, there are some great books written about evolution of, walking evolution of the human body."}, {"time": 1014, "text": "I think it's easy though to make bad evolutionary arguments."}, {"time": 1020, "text": "Sure, most of them are probably bad, but what else can we do?"}, {"time": 1026, "text": "I mean, I think a lot of what dominated our evolution probably was not the things that worked well sort of in the steady state, you know, when things are good, but for instance, people talk about what we should eat now because our ancestors were meat eaters or whatever."}, {"time": 1048, "text": "Oh yeah, I love that, yeah."}, {"time": 1050, "text": "But probably, you know, the reason that one pre Homo sapiens species versus another survived was not because of whether they ate well when there was lots of food."}, {"time": 1065, "text": "But when the ice age came, you know, probably one of them happened to be in the wrong place."}, {"time": 1070, "text": "One of them happened to forage a food that was okay even when the glaciers came or something like that, I mean."}, {"time": 1078, "text": "There's a million variables that contributed and we can't, and our, actually the amount of information we're working with and telling these stories, these evolutionary stories is very little."}, {"time": 1090, "text": "So yeah, just like you said, it seems like, if you study history, it seems like history turns on like these little events that otherwise would seem meaningless, but in a grant, like when you, in retrospect, were turning points."}, {"time": 1142, "text": "There's probably an even larger community of people, including my mom, who says it's deeply unhealthy, it's wrong, but I just feel good doing it."}, {"time": 1150, "text": "But you're right, these evolutionary arguments can be flawed, but is there anything interesting to pull out for?"}, {"time": 1157, "text": "There's a great book, by the way, well, a series of books by Nicholas Taleb about Fooled by Randomness and Black Swan."}, {"time": 1164, "text": "Highly recommend them, but yeah, they make the point nicely that probably it was a few random events that, yes, maybe it was someone getting hit by a rock, as you say."}, {"time": 1179, "text": "That said, do you think, I don't know how to ask this question or how to talk about this, but there's something elegant and beautiful about moving on two feet, obviously biased because I'm human, but from a robotics perspective, too, you work with robots on two feet, is it all useful to build robots that are on two feet as opposed to four?"}, {"time": 1201, "text": "Is there something useful about it?"}, {"time": 1202, "text": "I think the most, I mean, the reason I spent a long time working on bipedal walking was because it was hard and it challenged control theory in ways that I thought were important."}, {"time": 1213, "text": "I wouldn't have ever tried to convince you that you should start a company around bipeds or something like this."}, {"time": 1224, "text": "There are people that make pretty compelling arguments."}, {"time": 1226, "text": "I think the most compelling one is that the world is built for the human form, and if you want a robot to work in the world we have today, then having a human form is a pretty good way to go."}, {"time": 1239, "text": "There are places that a biped can go that would be hard for other form factors to go, even natural places, but at some point in the long run, we'll be building our environments for our robots, probably, and so maybe that argument falls aside."}, {"time": 1256, "text": "So you famously run barefoot."}, {"time": 1260, "text": "Do you still run barefoot?"}, {"time": 1262, "text": "I still run barefoot."}, {"time": 1263, "text": "That's so awesome."}, {"time": 1264, "text": "Much to my wife's chagrin."}, {"time": 1267, "text": "Do you want to make an evolutionary argument for why running barefoot is advantageous?"}, {"time": 1272, "text": "What have you learned about human and robot movement in general from running barefoot?"}, {"time": 1281, "text": "Human or robot and or?"}, {"time": 1283, "text": "Well, you know, it happened the other way, right?"}, {"time": 1285, "text": "So I was studying walking robots, and there's a great conference called the Dynamic Walking Conference where it brings together both the biomechanics community and the walking robots community."}, {"time": 1299, "text": "And so I had been going to this for years and hearing talks by people who study barefoot running and other, the mechanics of running."}, {"time": 1308, "text": "So I did eventually read Born to Run."}, {"time": 1310, "text": "Most people read Born to Run in the first, right?"}, {"time": 1314, "text": "The other thing I had going for me is actually that I wasn't a runner before, and I learned to run after I had learned about barefoot running, or I mean, started running longer distances."}, {"time": 1325, "text": "So I didn't have to unlearn."}, {"time": 1327, "text": "And I'm definitely, I'm a big fan of it for me, but I'm not going to, I tend to not try to convince other people."}, {"time": 1334, "text": "There's people who run beautifully with shoes on, and that's good."}, {"time": 1340, "text": "But here's why it makes sense for me."}, {"time": 1344, "text": "It's all about the longterm game, right?"}, {"time": 1346, "text": "So I think it's just too easy to run 10 miles, feel pretty good, and then you get home at night and you realize my knees hurt."}, {"time": 1353, "text": "I did something wrong, right?"}, {"time": 1357, "text": "If you take your shoes off, then if you hit hard with your foot at all, then it hurts."}, {"time": 1365, "text": "You don't like run 10 miles and then realize you've done some damage."}, {"time": 1370, "text": "You have immediate feedback telling you that you've done something that's maybe suboptimal, and you change your gait."}, {"time": 1376, "text": "I mean, it's even subconscious."}, {"time": 1377, "text": "If I, right now, having run many miles barefoot, if I put a shoe on, my gait changes in a way that I think is not as good."}, {"time": 1385, "text": "So it makes me land softer."}, {"time": 1389, "text": "And I think my goals for running are to do it for as long as I can into old age, not to win any races."}, {"time": 1399, "text": "And so for me, this is a way to protect myself."}, {"time": 1403, "text": "Yeah, I think, first of all, I've tried running barefoot many years ago, probably the other way, just reading Born to Run."}, {"time": 1413, "text": "But just to understand, because I felt like I couldn't put in the miles that I wanted to."}, {"time": 1420, "text": "And it feels like running for me, and I think for a lot of people, was one of those activities that we do often and we never really try to learn to do correctly."}, {"time": 1433, "text": "Like, it's funny, there's so many activities we do every day, like brushing our teeth, right?"}, {"time": 1440, "text": "I think a lot of us, at least me, probably have never deeply studied how to properly brush my teeth, right?"}, {"time": 1447, "text": "Or wash, as now with the pandemic, or how to properly wash our hands."}, {"time": 1450, "text": "We do it every day, but we haven't really studied, like, am I doing this correctly?"}, {"time": 1455, "text": "But running felt like one of those things, it was absurd not to study how to do correctly, because it's the source of so much pain and suffering."}, {"time": 1463, "text": "Like, I hate running, but I do it."}, {"time": 1465, "text": "I do it because I hate it, but I feel good afterwards."}, {"time": 1468, "text": "But I think it feels like you need to learn how to do it properly."}, {"time": 1471, "text": "So that's where barefoot running came in, and then I quickly realized that my gait was completely wrong."}, {"time": 1478, "text": "I was taking huge steps, and landing hard on the heel, all those elements."}, {"time": 1485, "text": "And so, yeah, from that I actually learned to take really small steps, look."}, {"time": 1490, "text": "I already forgot the number, but I feel like it was 180 a minute or something like that."}, {"time": 1495, "text": "And I remember I actually just took songs that are 180 beats per minute, and then like tried to run at that beat, and just to teach myself."}, {"time": 1507, "text": "It took a long time, and I feel like after a while, you learn to run, you adjust properly, without going all the way to barefoot."}, {"time": 1515, "text": "But I feel like barefoot is the legit way to do it."}, {"time": 1519, "text": "I mean, I think a lot of people would be really curious about it."}, {"time": 1523, "text": "Can you, if they're interested in trying, what would you, how would you recommend they start, or try, or explore?"}, {"time": 1531, "text": "That's the biggest thing people do, is they are excellent runners, and they're used to running long distances, or running fast, and they take their shoes off, and they hurt themselves instantly trying to do something that they were used to doing."}, {"time": 1544, "text": "I think I lucked out in the sense that I couldn't run very far when I first started trying."}, {"time": 1550, "text": "And I run with minimal shoes too."}, {"time": 1551, "text": "I mean, I will bring along a pair of, actually, like aqua socks or something like this, I can just slip on, or running sandals, I've tried all of them."}, {"time": 1560, "text": "What's the difference between a minimal shoe and nothing at all?"}, {"time": 1563, "text": "What's, like, feeling wise, what does it feel like?"}, {"time": 1567, "text": "There is a, I mean, I notice my gait changing, right?"}, {"time": 1570, "text": "So, I mean, your foot has as many muscles and sensors as your hand does, right?"}, {"time": 1577, "text": "Sensors, ooh, okay."}, {"time": 1579, "text": "And we do amazing things with our hands."}, {"time": 1583, "text": "And we stick our foot in a big, solid shoe, right?"}, {"time": 1586, "text": "So there's, I think, you know, when you're barefoot, you're just giving yourself more proprioception."}, {"time": 1593, "text": "And that's why you're more aware of some of the gait flaws and stuff like this."}, {"time": 1597, "text": "Now, you have less protection too, so."}, {"time": 1600, "text": "Rocks and stuff."}, {"time": 1602, "text": "I mean, yeah, so I think people who are afraid of barefoot running are worried about getting cuts or stepping on rocks."}, {"time": 1609, "text": "First of all, even if that was a concern, I think those are all, like, very short term."}, {"time": 1614, "text": "You know, if I get a scratch or something, it'll heal in a week."}, {"time": 1616, "text": "If I blow out my knees, I'm done running forever."}, {"time": 1618, "text": "So I will trade the short term for the long term anytime."}, {"time": 1621, "text": "But even then, you know, and this, again, to my wife's chagrin, your feet get tough, right?"}, {"time": 1627, "text": "And, yeah, I can run over almost anything now."}, {"time": 1633, "text": "I mean, what, can you talk about, is there, like, is there tips or tricks that you have, suggestions about, like, if I wanted to try it?"}, {"time": 1646, "text": "You know, there is a good book, actually."}, {"time": 1649, "text": "There's probably more good books since I read them."}, {"time": 1652, "text": "But Ken Bob, Barefoot Ken Bob Saxton."}, {"time": 1657, "text": "He's an interesting guy."}, {"time": 1658, "text": "But I think his book captures the right way to describe running, barefoot running, to somebody better than any other I've seen."}, {"time": 1668, "text": "So you run pretty good distances, and you bike, and is there, you know, if we talk about bucket list items, is there something crazy on your bucket list, athletically, that you hope to do one day?"}, {"time": 1684, "text": "I mean, my commute is already a little crazy."}, {"time": 1687, "text": "What are we talking about here?"}, {"time": 1689, "text": "What distance are we talking about?"}, {"time": 1691, "text": "Well, I live about 12 miles from MIT, but you can find lots of different ways to get there."}, {"time": 1696, "text": "So, I mean, I've run there for many years, I've biked there."}, {"time": 1700, "text": "Old ways?"}, {"time": 1701, "text": "Yeah, but normally I would try to run in and then bike home, bike in, run home."}, {"time": 1705, "text": "But you have run there and back before?"}, {"time": 1708, "text": "Barefoot?"}, {"time": 1709, "text": "Yeah, or with minimal shoes or whatever that."}, {"time": 1712, "text": "12, 12 times two?"}, {"time": 1716, "text": "It became kind of a game of how can I get to work?"}, {"time": 1718, "text": "I've rollerbladed, I've done all kinds of weird stuff, but my favorite one these days, I've been taking the Charles River to work."}, {"time": 1725, "text": "So, I can put in the rowboat not so far from my house, but the Charles River takes a long way to get to MIT, so I can spend a long time getting there."}, {"time": 1736, "text": "And it's not about, I don't know, it's just about, I've had people ask me, how can you justify taking that time?"}, {"time": 1745, "text": "But for me, it's just a magical time to think, to compress, decompress."}, {"time": 1753, "text": "Especially, I'll wake up, do a lot of work in the morning, and then I kind of have to just let that settle before I'm ready for all my meetings."}, {"time": 1760, "text": "And then on the way home, it's a great time to sort of let that settle."}, {"time": 1764, "text": "You lead a large group of people."}, {"time": 1771, "text": "Is there days where you're like, oh shit, I gotta get to work in an hour?"}, {"time": 1776, "text": "Like, I mean, is there a tension there?"}, {"time": 1785, "text": "And like, if we look at the grand scheme of things, just like you said, long term, that meeting probably doesn't matter."}, {"time": 1791, "text": "Like, you can always say, I'll just, I'll run and let the meeting happen, how it happens."}, {"time": 1797, "text": "Like, what, how do you, that zen, how do you, what do you do with that tension between the real world saying urgently, you need to be there, this is important, everything is melting down, how are we gonna fix this robot?"}, {"time": 1811, "text": "There's this critical meeting, and then there's this, the zen beauty of just running, the simplicity of it, you along with nature."}, {"time": 1821, "text": "What do you do with that?"}, {"time": 1822, "text": "I would say I'm not a fast runner, particularly."}, {"time": 1825, "text": "Probably my fastest splits ever was when I had to get to daycare on time because they were gonna charge me, you know, some dollar per minute that I was late."}, {"time": 1833, "text": "I've run some fast splits to daycare."}, {"time": 1836, "text": "But those times are past now."}, {"time": 1841, "text": "I think work, you can find a work life balance in that way."}, {"time": 1844, "text": "I think you just have to."}, {"time": 1847, "text": "I think I am better at work because I take time to think on the way in."}, {"time": 1852, "text": "So I plan my day around it, and I rarely feel that those are really at odds."}, {"time": 1860, "text": "So what, the bucket list item."}, {"time": 1863, "text": "If we're talking 12 times two, or approaching a marathon, what, have you run an ultra marathon before?"}, {"time": 1875, "text": "Do you do races?"}, {"time": 1876, "text": "Is there, what's a... Not to win."}, {"time": 1881, "text": "I'm not gonna like take a dinghy across the Atlantic or something if that's what you want."}, {"time": 1884, "text": "But if someone does and wants to write a book, I would totally read it because I'm a sucker for that kind of thing."}, {"time": 1891, "text": "No, I do have some fun things that I will try."}, {"time": 1893, "text": "You know, I like to, when I travel, I almost always bike to Logan Airport and fold up a little folding bike and then take it with me and bike to wherever I'm going."}, {"time": 1901, "text": "And it's taken me, or I'll take a stand up paddle board these days on the airplane, and then I'll try to paddle around where I'm going or whatever."}, {"time": 1907, "text": "And I've done some crazy things, but..."}, {"time": 1910, "text": "But not for the, you know, I now talk, I don't know if you know who David Goggins is by any chance."}, {"time": 1917, "text": "Not well, but yeah."}, {"time": 1918, "text": "But I talk to him now every day."}, {"time": 1920, "text": "So he's the person who made me do this stupid challenge."}, {"time": 1925, "text": "So he's insane and he does things for the purpose in the best kind of way."}, {"time": 1931, "text": "He does things like for the explicit purpose of suffering."}, {"time": 1936, "text": "Like he picks the thing that, like whatever he thinks he can do, he does more."}, {"time": 1942, "text": "So is that, do you have that thing in you or are you..."}, {"time": 1947, "text": "I think it's become the opposite."}, {"time": 1950, "text": "So you're like that dynamical system that the walker, the efficient... Yeah, it's leave no pain, right?"}, {"time": 1958, "text": "You should end feeling better than you started."}, {"time": 1961, "text": "But it's mostly, I think, and COVID has tested this because I've lost my commute."}, {"time": 1967, "text": "I think I'm perfectly happy walking around town with my wife and kids if they could get them to go."}, {"time": 1975, "text": "And it's more about just getting outside and getting away from the keyboard for some time just to let things compress."}, {"time": 1982, "text": "Let's go into robotics a little bit."}, {"time": 1984, "text": "What to use the most beautiful idea in robotics?"}, {"time": 1987, "text": "Whether we're talking about control or whether we're talking about optimization and the math side of things or the engineering side of things or the philosophical side of things."}, {"time": 2000, "text": "I think I've been lucky to experience something that not so many roboticists have experienced, which is to hang out with some really amazing control theorists."}, {"time": 2014, "text": "And the clarity of thought that some of the more mathematical control theory can bring to even very complex, messy looking problems is really, it really had a big impact on me and I had a day even just a couple of weeks ago where I had spent the day on a Zoom robotics conference having great conversations with lots of people."}, {"time": 2044, "text": "Felt really good about the ideas that were flowing and the like."}, {"time": 2049, "text": "And then I had a late afternoon meeting with one of my favorite control theorists and we went from these abstract discussions about maybes and what ifs and what a great idea to these super precise statements about systems that aren't that much more simple or abstract than the ones I care about deeply."}, {"time": 2078, "text": "And the contrast of that is, I don't know, it really gets me."}, {"time": 2083, "text": "I think people underestimate maybe the power of clear thinking."}, {"time": 2091, "text": "And so for instance, deep learning is amazing."}, {"time": 2098, "text": "I use it heavily in our work."}, {"time": 2100, "text": "I think it's changed the world, unquestionable."}, {"time": 2104, "text": "It makes it easy to get things to work without thinking as critically about it."}, {"time": 2108, "text": "So I think one of the challenges as an educator is to think about how do we make sure people get a taste of the more rigorous thinking that I think goes along with some different approaches."}, {"time": 2122, "text": "Yeah, so that's really interesting."}, {"time": 2124, "text": "So understanding like the fundamentals, the first principles of the problem, where in this case it's mechanics, like how a thing moves, how a thing behaves, like all the forces involved, like really getting a deep understanding of that."}, {"time": 2142, "text": "I mean, from physics, the first principle thing come from physics, and here it's literally physics."}, {"time": 2150, "text": "Yeah, and this applies, in deep learning, this applies to not just, I mean, it applies so cleanly in robotics, but it also applies to just in any data set."}, {"time": 2161, "text": "I find this true, I mean, driving as well."}, {"time": 2165, "text": "There's a lot of folks in that work on autonomous vehicles that work on autonomous vehicles that don't study driving, like deeply."}, {"time": 2180, "text": "I might be coming a little bit from the psychology side, but I remember I spent a ridiculous number of hours at lunch, at this like lawn chair, and I would sit somewhere in MIT's campus, there's a few interesting intersections, and we'd just watch people cross."}, {"time": 2199, "text": "So we were studying pedestrian behavior, and I felt like, as we record a lot of video, to try, and then there's the computer vision extracts their movement, how they move their head, and so on, but like every time, I felt like I didn't understand enough."}, {"time": 2215, "text": "I just, I felt like I wasn't understanding what, how are people signaling to each other, what are they thinking, how cognizant are they of their fear of death?"}, {"time": 2227, "text": "Like, what's the underlying game theory here?"}, {"time": 2231, "text": "What are the incentives?"}, {"time": 2234, "text": "And then I finally found a live stream of an intersection that's like high def that I just, I would watch so I wouldn't have to sit out there."}, {"time": 2241, "text": "But it's interesting, so like, I feel."}, {"time": 2243, "text": "But that's tough, that's a tough example, because I mean, the learning."}, {"time": 2247, "text": "Humans are involved."}, {"time": 2248, "text": "Not just because human, but I think the learning mantra is that basically the statistics of the data will tell me things I need to know, right?"}, {"time": 2257, "text": "And, you know, for the example you gave of all the nuances of, you know, eye contact, or hand gestures, or whatever that are happening for these subtle interactions between pedestrians and traffic, right?"}, {"time": 2271, "text": "Maybe the data will tell that story."}, {"time": 2274, "text": "I maybe even, one level more meta than what you're saying."}, {"time": 2281, "text": "For a particular problem, I think it might be the case that data should tell us the story."}, {"time": 2287, "text": "But I think there's a rigorous thinking that is just an essential skill for a mathematician or an engineer that I just don't wanna lose it."}, {"time": 2298, "text": "There are certainly super rigorous control, or sorry, machine learning people."}, {"time": 2304, "text": "I just think deep learning makes it so easy to do some things that our next generation, are not immediately rewarded for going through some of the more rigorous approaches."}, {"time": 2318, "text": "And then I wonder where that takes us."}, {"time": 2320, "text": "Well, I'm actually optimistic about it."}, {"time": 2322, "text": "I just want to do my part to try to steer that rigorous thinking."}, {"time": 2328, "text": "So there's like two questions I wanna ask."}, {"time": 2330, "text": "Do you have sort of a good example of rigorous thinking where it's easy to get lazy and not do the rigorous thinking?"}, {"time": 2340, "text": "And the other question I have is like, do you have advice of how to practice rigorous thinking in all the computer science disciplines that we've mentioned?"}, {"time": 2356, "text": "Yeah, I mean, there are times where problems that can be solved with well known mature methods could also be solved with a deep learning approach."}, {"time": 2370, "text": "And there's an argument that you must use learning even for the parts we already think we know, because if the human has touched it, then you've biased the system and you've suddenly put a bottleneck in there that is your own mental model."}, {"time": 2386, "text": "But something like converting a matrix, I think we know how to do that pretty well, even if it's a pretty big matrix, and we understand that pretty well."}, {"time": 2393, "text": "And you could train a deep network to do it, but you shouldn't probably."}, {"time": 2397, "text": "So in that sense, rigorous thinking is understanding the scope and the limitations of the methods that we have, like how to use the tools of mathematics properly."}, {"time": 2410, "text": "Yeah, I think taking a class on analysis is all I'm sort of arguing is to take a chance to stop and force yourself to think rigorously about even the rational numbers or something."}, {"time": 2425, "text": "It doesn't have to be the end all problem."}, {"time": 2427, "text": "But that exercise of clear thinking, I think goes a long way, and I just wanna make sure we keep preaching it."}, {"time": 2435, "text": "We don't lose it."}, {"time": 2436, "text": "But do you think when you're doing rigorous thinking or maybe trying to write down equations or sort of explicitly formally describe a system, do you think we naturally simplify things too much?"}, {"time": 2451, "text": "Is that a danger you run into?"}, {"time": 2453, "text": "Like in order to be able to understand something about the system mathematically, we make it too much of a toy example."}, {"time": 2461, "text": "But I think that's the good stuff, right?"}, {"time": 2464, "text": "That's how you understand the fundamentals?"}, {"time": 2467, "text": "I think maybe even that's a key to intelligence or something, but I mean, okay, what if Newton and Galileo had deep learning?"}, {"time": 2475, "text": "And they had done a bunch of experiments and they told the world, here's your weights of your neural network."}, {"time": 2482, "text": "We've solved the problem."}, {"time": 2484, "text": "Where would we be today?"}, {"time": 2485, "text": "I don't think we'd be as far as we are."}, {"time": 2488, "text": "There's something to be said about having the simplest explanation for a phenomenon."}, {"time": 2492, "text": "So I don't doubt that we can train neural networks to predict even physical F equals MA type equations."}, {"time": 2506, "text": "But I maybe, I want another Newton to come along because I think there's more to do in terms of coming up with the simple models for more complicated tasks."}, {"time": 2519, "text": "Yeah, let's not offend AI systems from 50 years from now that are listening to this that are probably better at, might be better coming up with F equals MA equations themselves."}, {"time": 2533, "text": "So sorry, I actually think learning is probably a route to achieving this, but the representation matters, right?"}, {"time": 2541, "text": "And I think having a function that takes my inputs to outputs that is arbitrarily complex may not be the end goal."}, {"time": 2550, "text": "I think there's still the most simple or parsimonious explanation for the data."}, {"time": 2557, "text": "Simple doesn't mean low dimensional."}, {"time": 2559, "text": "That's one thing I think that we've, a lesson that we've learned."}, {"time": 2561, "text": "So a standard way to do model reduction or system identification and controls is the typical formulation is that you try to find the minimal state dimension realization of a system that hits some error bounds or something like that."}, {"time": 2577, "text": "And that's maybe not, I think we're learning that state dimension is not the right metric."}, {"time": 2587, "text": "But for me, I think a lot about contact, the mechanics of contact, if a robot hand is picking up an object or something."}, {"time": 2594, "text": "And when I write down the equations of motion for that, they look incredibly complex, not because, actually not so much because of the dynamics of the hand when it's moving, but it's just the interactions and when they turn on and off, right?"}, {"time": 2610, "text": "So having a high dimensional, but simple description of what's happening out here is fine."}, {"time": 2616, "text": "But if when I actually start touching, if I write down a different dynamical system for every polygon on my robot hand and every polygon on the object, whether it's in contact or not, with all the combinatorics that explodes there, then that's too complex."}, {"time": 2634, "text": "So I need to somehow summarize that with a more intuitive physics way of thinking."}, {"time": 2641, "text": "And yeah, I'm very optimistic that machine learning will get us there."}, {"time": 2645, "text": "First of all, I mean, I'll probably do it in the introduction, but you're one of the great robotics people at MIT."}, {"time": 2652, "text": "You're a professor at MIT."}, {"time": 2654, "text": "You've teach him a lot of amazing courses."}, {"time": 2656, "text": "You run a large group and you have a important history for MIT, I think, as being a part of the DARPA Robotics Challenge."}, {"time": 2666, "text": "Can you maybe first say, what is the DARPA Robotics Challenge and then tell your story around it, your journey with it?"}, {"time": 2679, "text": "So the DARPA Robotics Challenge, it came on the tails of the DARPA Grand Challenge and DARPA Urban Challenge, which were the challenges that brought us, put a spotlight on self driving cars."}, {"time": 2695, "text": "Gil Pratt was at DARPA and pitched a new challenge that involved disaster response."}, {"time": 2704, "text": "It didn't explicitly require humanoids, although humanoids came into the picture."}, {"time": 2710, "text": "This happened shortly after the Fukushima disaster in Japan and our challenge was motivated roughly by that because that was a case where if we had had robots that were ready to be sent in, there's a chance that we could have averted disaster."}, {"time": 2726, "text": "And certainly after the, in the disaster response, there were times we would have loved to have sent robots in."}, {"time": 2734, "text": "So in practice, what we ended up with was a grand challenge, a DARPA Robotics Challenge, where Boston Dynamics was to make humanoid robots."}, {"time": 2748, "text": "People like me and the amazing team at MIT were competing first in a simulation challenge to try to be one of the ones that wins the right to work on one of the Boston Dynamics humanoids in order to compete in the final challenge, which was a physical challenge."}, {"time": 2768, "text": "And at that point, it was already, so it was decided as humanoid robots early on."}, {"time": 2773, "text": "There were two tracks."}, {"time": 2775, "text": "You could enter as a hardware team where you brought your own robot, or you could enter through the virtual robotics challenge as a software team that would try to win the right to use one of the Boston Dynamics robots."}, {"time": 2785, "text": "Sure, called Atlas."}, {"time": 2787, "text": "Atlas."}, {"time": 2788, "text": "Humanoid robots."}, {"time": 2789, "text": "Yeah, it was a 400 pound Marvel, but a pretty big, scary looking robot."}, {"time": 2795, "text": "Expensive too."}, {"time": 2796, "text": "Expensive, yeah."}, {"time": 2798, "text": "Okay, so I mean, how did you feel at the prospect of this kind of challenge?"}, {"time": 2804, "text": "I mean, it seems autonomous vehicles, yeah, I guess that sounds hard, but not really from a robotics perspective."}, {"time": 2813, "text": "It's like, didn't they do it in the 80s is the kind of feeling I would have, like when you first look at the problem, it's on wheels, but like humanoid robots, that sounds really hard."}, {"time": 2827, "text": "So what are your, psychologically speaking, what were you feeling, excited, scared?"}, {"time": 2835, "text": "Why the heck did you get yourself involved in this kind of messy challenge?"}, {"time": 2868, "text": "The challenge could have really highlighted perception and autonomous planning, or it ended up that locomoting over complex terrain played a pretty big role in the competition."}, {"time": 2883, "text": "So... And the degree of autonomy wasn't clear."}, {"time": 2888, "text": "The degree of autonomy was always a central part of the discussion."}, {"time": 2891, "text": "So what wasn't clear was how we would be able, how far we'd be able to get with it."}, {"time": 2897, "text": "So the idea was always that you want semi autonomy, that you want the robot to have enough compute that you can have a degraded network link to a human."}, {"time": 2907, "text": "And so the same way we had degraded networks at many natural disasters, you'd send your robot in, you'd be able to get a few bits back and forth, but you don't get to have enough potentially to fully operate the robot in every joint of the robot."}, {"time": 2924, "text": "So, and then the question was, and the gamesmanship of the organizers was to figure out what we're capable of, push us as far as we could, so that it would differentiate the teams that put more autonomy on the robot and had a few clicks and just said, go there, do this, go there, do this, versus someone who's picking every footstep or something like that."}, {"time": 2945, "text": "So what were some memories, painful, triumphant from the experience?"}, {"time": 2953, "text": "Like what was that journey?"}, {"time": 2955, "text": "Maybe if you can dig in a little deeper, maybe even on the technical side, on the team side, that whole process of, from the early idea stages to actually competing."}, {"time": 2968, "text": "I mean, this was a defining experience for me."}, {"time": 2971, "text": "It came at the right time for me in my career."}, {"time": 2973, "text": "I had gotten tenure before I was due a sabbatical, and most people do something relaxing and restorative for a sabbatical."}, {"time": 2981, "text": "So you got tenure before this?"}, {"time": 2986, "text": "It was a good time for me."}, {"time": 2988, "text": "We had a bunch of algorithms that we were very happy with."}, {"time": 2990, "text": "We wanted to see how far we could push them, and this was a chance to really test our mettle to do more proper software engineering."}, {"time": 2996, "text": "So the team, we all just worked our butts off."}, {"time": 3001, "text": "We were in that lab almost all the time."}, {"time": 3007, "text": "Okay, so there were some, of course, high highs and low lows throughout that."}, {"time": 3012, "text": "Anytime you're not sleeping and devoting your life to a 400 pound humanoid."}, {"time": 3018, "text": "I remember actually one funny moment where we're all super tired, and so Atlas had to walk across cinder blocks."}, {"time": 3024, "text": "That was one of the obstacles."}, {"time": 3026, "text": "And I remember Atlas was powered down and hanging limp on its harness, and the humans were there picking up and laying the brick down so that the robot could walk over it."}, {"time": 3036, "text": "And I thought, what is wrong with this?"}, {"time": 3038, "text": "We've got a robot just watching us do all the manual labor so that it can take its little stroll across the train."}, {"time": 3047, "text": "But I mean, even the virtual robotics challenge was super nerve wracking and dramatic."}, {"time": 3054, "text": "I remember, so we were using Gazebo as a simulator on the cloud, and there was all these interesting challenges."}, {"time": 3063, "text": "I think the investment that OSR FC, whatever they were called at that time, Brian Gerkey's team at Open Source Robotics, they were pushing on the capabilities of Gazebo in order to scale it to the complexity of these challenges."}, {"time": 3080, "text": "So, you know, up to the virtual competition."}, {"time": 3083, "text": "So the virtual competition was, you will sign on at a certain time and we'll have a network connection to another machine on the cloud that is running the simulator of your robot."}, {"time": 3094, "text": "And your controller will run on this computer and the physics will run on the other and you have to connect."}, {"time": 3103, "text": "Now, the physics, they wanted it to run at real time rates because there was an element of human interaction."}, {"time": 3110, "text": "And humans, if you do want to teleop, it works way better if it's at frame rate."}, {"time": 3117, "text": "But it was very hard to simulate these complex scenes at real time rate."}, {"time": 3123, "text": "So right up to like days before the competition, the simulator wasn't quite at real time rate."}, {"time": 3131, "text": "And that was great for me because my controller was solving a pretty big optimization problem and it wasn't quite at real time rate."}, {"time": 3137, "text": "So I was fine."}, {"time": 3138, "text": "I was keeping up with the simulator."}, {"time": 3140, "text": "We were both running at about 0.7."}, {"time": 3142, "text": "And I remember getting this email."}, {"time": 3144, "text": "And by the way, the perception folks on our team hated that they knew that if my controller was too slow, the robot was gonna fall down."}, {"time": 3152, "text": "And no matter how good their perception system was, if I can't make my controller fast."}, {"time": 3156, "text": "Anyways, we get this email like three days before the virtual competition."}, {"time": 3160, "text": "It's for all the marbles."}, {"time": 3161, "text": "We're gonna either get a humanoid robot or we're not."}, {"time": 3164, "text": "And we get an email saying, good news, we made the robot, the simulator faster."}, {"time": 3168, "text": "It's now at one point."}, {"time": 3170, "text": "And I was just like, oh man, what are we gonna do here?"}, {"time": 3174, "text": "So that came in late at night for me."}, {"time": 3179, "text": "A few days ahead."}, {"time": 3181, "text": "I went over, it happened at Frank Permenter, who's a very, very sharp."}, {"time": 3186, "text": "He was a student at the time working on optimization."}, {"time": 3191, "text": "He was still in lab."}, {"time": 3193, "text": "Frank, we need to make the quadratic programming solver faster, not like a little faster."}, {"time": 3198, "text": "It's actually, you know, and we wrote a new solver for that QP together that night."}, {"time": 3208, "text": "It was terrifying."}, {"time": 3209, "text": "So there's a really hard optimization problem that you're constantly solving."}, {"time": 3214, "text": "You didn't make the optimization problem simpler?"}, {"time": 3216, "text": "You wrote a new solver?"}, {"time": 3218, "text": "So, I mean, your observation is almost spot on."}, {"time": 3222, "text": "What we did was what everybody, I mean, people know how to do this, but we had not yet done this idea of warm starting."}, {"time": 3229, "text": "So we are solving a big optimization problem at every time step."}, {"time": 3232, "text": "But if you're running fast enough, the optimization problem you're solving on the last time step is pretty similar to the optimization you're gonna solve with the next."}, {"time": 3240, "text": "We had course had told our commercial solver to use warm starting, but even the interface to that commercial solver was causing us these delays."}, {"time": 3249, "text": "So what we did was we basically wrote, we called it fast QP at the time."}, {"time": 3255, "text": "We wrote a very lightweight, very fast layer, which would basically check if nearby solutions to the quadratic program were, which were very easily checked, could stabilize the robot."}, {"time": 3268, "text": "And if they couldn't, we would fall back to the solver."}, {"time": 3270, "text": "You couldn't really test this well, right?"}, {"time": 3273, "text": "I mean, so we always knew that if we fell back to, if we, it got to the point where if for some reason things slowed down and we fell back to the original solver, the robot would actually literally fall down."}, {"time": 3286, "text": "So it was a harrowing sort of edge we were, ledge we were sort of on."}, {"time": 3291, "text": "But I mean, it actually, like the 400 pound human could come crashing to the ground if your solver's not fast enough."}, {"time": 3298, "text": "But you know, we had lots of good experiences."}, {"time": 3301, "text": "So can I ask you a weird question I get about idea of hard work?"}, {"time": 3309, "text": "So actually people, like students of yours that I've interacted with and just, and robotics people in general, but they have moments, at moments have worked harder than most people I know in terms of, if you look at different disciplines of how hard people work."}, {"time": 3332, "text": "But they're also like the happiest."}, {"time": 3334, "text": "Like, just like, I don't know."}, {"time": 3337, "text": "It's the same thing with like running."}, {"time": 3339, "text": "People that push themselves to like the limit, they also seem to be like the most like full of life somehow."}, {"time": 3346, "text": "And I get often criticized like, you're not getting enough sleep."}, {"time": 3350, "text": "What are you doing to your body?"}, {"time": 3352, "text": "Blah, blah, blah, like this kind of stuff."}, {"time": 3354, "text": "And I usually just kind of respond like, I'm doing what I love."}, {"time": 3359, "text": "I'm passionate about it."}, {"time": 3361, "text": "I feel like it's, it's invigorating."}, {"time": 3364, "text": "I actually think, I don't think the lack of sleep is what hurts you."}, {"time": 3368, "text": "I think what hurts you is stress and lack of doing things that you're passionate about."}, {"time": 3373, "text": "But in this world, yeah, I mean, can you comment about why the heck robotics people are willing to push themselves to that degree?"}, {"time": 3386, "text": "Is there value in that?"}, {"time": 3387, "text": "And why are they so happy?"}, {"time": 3390, "text": "I think, I think you got it right."}, {"time": 3391, "text": "I mean, I think the causality is not that we work hard."}, {"time": 3396, "text": "And I think other disciplines work very hard too, but it's, I don't think it's that we work hard and therefore we are happy."}, {"time": 3403, "text": "I think we found something that we're truly passionate about."}, {"time": 3408, "text": "It makes us very happy."}, {"time": 3409, "text": "And then we get a little involved with it and spend a lot of time on it."}, {"time": 3414, "text": "What a luxury to have something that you wanna spend all your time on, right?"}, {"time": 3419, "text": "We could talk about this for many hours, but maybe if we could pick, is there something on the technical side on the approach that you took that's interesting that turned out to be a terrible failure or a success that you carry into your work today about all the different ideas that were involved in making, whether in the simulation or in the real world, making this semi autonomous system work?"}, {"time": 3445, "text": "I mean, it really did teach me something fundamental about what it's gonna take to get robustness out of a system of this complexity."}, {"time": 3455, "text": "I would say the DARPA challenge really was foundational in my thinking."}, {"time": 3461, "text": "I think the autonomous driving community thinks about this."}, {"time": 3463, "text": "I think lots of people thinking about safety critical systems that might have machine learning in the loop are thinking about these questions."}, {"time": 3470, "text": "For me, the DARPA challenge was the moment where I realized we've spent every waking minute running this robot."}, {"time": 3478, "text": "And again, for the physical competition, days before the competition, we saw the robot fall down in a way it had never fallen down before."}, {"time": 3485, "text": "I thought, how could we have found that?"}, {"time": 3490, "text": "We only have one robot, it's running almost all the time."}, {"time": 3493, "text": "We just didn't have enough hours in the day to test that robot."}, {"time": 3497, "text": "Something has to change, right?"}, {"time": 3499, "text": "And then I think that, I mean, I would say that the team that won was, from KAIST, was the team that had two robots and was able to do not only incredible engineering, just absolutely top rate engineering, but also they were able to test at a rate and discipline that we didn't keep up with."}, {"time": 3519, "text": "What does testing look like?"}, {"time": 3522, "text": "Like, what's a loop of tests?"}, {"time": 3525, "text": "Like from start to finish, what is a loop of testing?"}, {"time": 3528, "text": "Yeah, I mean, I think there's a whole philosophy to testing."}, {"time": 3531, "text": "There's the unit tests, and you can do that on a hardware, you can do that in a small piece of code."}, {"time": 3536, "text": "You write one function, you should write a test that checks that function's input and outputs."}, {"time": 3540, "text": "You should also write an integration test at the other extreme of running the whole system together, where they try to turn on all of the different functions that you think are correct."}, {"time": 3551, "text": "It's much harder to write the specifications for a system level test, especially if that system is as complicated as a humanoid robot."}, {"time": 3558, "text": "But the philosophy is sort of the same."}, {"time": 3561, "text": "On the real robot, it's no different, but on a real robot, it's impossible to run the same experiment twice."}, {"time": 3568, "text": "So if you see a failure, you hope you caught something in the logs that tell you what happened, but you'd probably never be able to run exactly that experiment again."}, {"time": 3579, "text": "And right now, I think our philosophy is just, basically Monte Carlo estimation, is just run as many experiments as we can, maybe try to set up the environment to make the things we are worried about happen as often as possible."}, {"time": 3599, "text": "But really we're relying on somewhat random search in order to test."}, {"time": 3604, "text": "Maybe that's all we'll ever be able to, but I think, you know, cause there's an argument that the things that'll get you are the things that are really nuanced in the world."}, {"time": 3614, "text": "And there'd be very hard to, for instance, put back in a simulation."}, {"time": 3616, "text": "Yeah, I guess the edge cases."}, {"time": 3619, "text": "What was the hardest thing?"}, {"time": 3621, "text": "Like, so you said walking over rough terrain, like just taking footsteps."}, {"time": 3627, "text": "I mean, people, it's so dramatic and painful in a certain kind of way to watch these videos from the DRC of robots falling."}, {"time": 3638, "text": "It's just so heartbreaking."}, {"time": 3640, "text": "Maybe it's because for me at least, we anthropomorphize the robot."}, {"time": 3645, "text": "Of course, it's also funny for some reason, like humans falling is funny for, I don't, it's some dark reason."}, {"time": 3653, "text": "I'm not sure why it is so, but it's also like tragic and painful."}, {"time": 3657, "text": "And so speaking of which, I mean, what made the robots fall and fail in your view?"}, {"time": 3665, "text": "So I can tell you exactly what happened on our, we, I contributed one of those."}, {"time": 3668, "text": "Our team contributed one of those spectacular falls."}, {"time": 3670, "text": "Every one of those falls has a complicated story."}, {"time": 3675, "text": "I mean, at one time, the power effectively went out on the robot because it had been sitting at the door waiting for a green light to be able to proceed and its batteries, you know, and therefore it just fell backwards and smashed its head against the ground."}, {"time": 3689, "text": "And it was hilarious, but it wasn't because of bad software, right?"}, {"time": 3694, "text": "But for ours, so the hardest part of the challenge, the hardest task in my view was getting out of the Polaris."}, {"time": 3700, "text": "It was actually relatively easy to drive the Polaris."}, {"time": 3703, "text": "Can you tell the story?"}, {"time": 3705, "text": "The story of the car."}, {"time": 3710, "text": "People should watch this video."}, {"time": 3711, "text": "I mean, the thing you've come up with is just brilliant, but anyway, sorry, what's... Yeah, we kind of joke."}, {"time": 3716, "text": "We call it the big robot, little car problem because somehow the race organizers decided to give us a 400 pound humanoid."}, {"time": 3725, "text": "And then they also provided the vehicle, which was a little Polaris."}, {"time": 3728, "text": "And the robot didn't really fit in the car."}, {"time": 3731, "text": "So you couldn't drive the car with your feet under the steering column."}, {"time": 3735, "text": "We actually had to straddle the main column of the, and have basically one foot in the passenger seat, one foot in the driver's seat, and then drive with our left hand."}, {"time": 3748, "text": "But the hard part was we had to then park the car, get out of the car."}, {"time": 3753, "text": "It didn't have a door, that was okay."}, {"time": 3754, "text": "But it's just getting up from crouched, from sitting, when you're in this very constrained environment."}, {"time": 3761, "text": "First of all, I remember after watching those videos, I was much more cognizant of how hard it is for me to get in and out of the car, and out of the car, especially."}, {"time": 3771, "text": "It's actually a really difficult control problem."}, {"time": 3775, "text": "I'm very cognizant of it when I'm like injured for whatever reason."}, {"time": 3779, "text": "Oh, that's really hard."}, {"time": 3781, "text": "So how did you approach this problem?"}, {"time": 3783, "text": "So we had, you think of NASA's operations, and they have these checklists, prelaunched checklists and the like."}, {"time": 3791, "text": "We weren't far off from that."}, {"time": 3792, "text": "We had this big checklist."}, {"time": 3793, "text": "And on the first day of the competition, we were running down our checklist."}, {"time": 3797, "text": "And one of the things we had to do, we had to turn off the controller, the piece of software that was running that would drive the left foot of the robot in order to accelerate on the gas."}, {"time": 3808, "text": "And then we turned on our balancing controller."}, {"time": 3810, "text": "And the nerves, jitters of the first day of the competition, someone forgot to check that box and turn that controller off."}, {"time": 3817, "text": "So we used a lot of motion planning to figure out a sort of configuration of the robot that we could get up and over."}, {"time": 3827, "text": "We relied heavily on our balancing controller."}, {"time": 3830, "text": "And basically, when the robot was in one of its most precarious sort of configurations, trying to sneak its big leg out of the side, the other controller that thought it was still driving told its left foot to go like this."}, {"time": 3846, "text": "And that wasn't good."}, {"time": 3851, "text": "But it turned disastrous for us because what happened was a little bit of push here."}, {"time": 3856, "text": "Actually, we have videos of us running into the robot with a 10 foot pole and it kind of will recover."}, {"time": 3864, "text": "But this is a case where there's no space to recover."}, {"time": 3867, "text": "So a lot of our secondary balancing mechanisms about like take a step to recover, they were all disabled because we were in the car and there was no place to step."}, {"time": 3875, "text": "So we were relying on our just lowest level reflexes."}, {"time": 3878, "text": "And even then, I think just hitting the foot on the seat, on the floor, we probably could have recovered from it."}, {"time": 3884, "text": "But the thing that was bad that happened is when we did that and we jostled a little bit, the tailbone of our robot was only a little off the seat, it hit the seat."}, {"time": 3895, "text": "And the other foot came off the ground just a little bit."}, {"time": 3898, "text": "And nothing in our plans had ever told us what to do if your butt's on the seat and your feet are in the air."}, {"time": 3905, "text": "Feet in the air."}, {"time": 3906, "text": "And then the thing is once you get off the script, things can go very wrong because even our state estimation, our system that was trying to collect all the data from the sensors and understand what's happening with the robot, it didn't know about this situation."}, {"time": 3920, "text": "So it was predicting things that were just wrong."}, {"time": 3922, "text": "And then we did a violent shake and fell off in our face first out of the robot."}, {"time": 3929, "text": "But like into the destination."}, {"time": 3932, "text": "That's true, we fell in, we got our point for egress."}, {"time": 3936, "text": "But so is there any hope for, that's interesting, is there any hope for Atlas to be able to do something when it's just on its butt and feet in the air?"}, {"time": 3947, "text": "So you can, what do you?"}, {"time": 3948, "text": "No, so that is one of the big challenges."}, {"time": 3950, "text": "And I think it's still true, you know, Boston Dynamics and Antimal and there's this incredible work on legged robots happening around the world."}, {"time": 3964, "text": "Most of them still are very good at the case where you're making contact with the world at your feet."}, {"time": 3970, "text": "And they have typically point feet relatively, they have balls on their feet, for instance."}, {"time": 3974, "text": "If those robots get in a situation where the elbow hits the wall or something like this, that's a pretty different situation."}, {"time": 3981, "text": "Now they have layers of mechanisms that will make, I think the more mature solutions have ways in which the controller won't do stupid things."}, {"time": 3991, "text": "But a human, for instance, is able to leverage incidental contact in order to accomplish a goal."}, {"time": 3996, "text": "In fact, I might, if you push me, I might actually put my hand out and make a new brand new contact."}, {"time": 4002, "text": "The feet of the robot are doing this on quadrupeds, but we mostly in robotics are afraid of contact on the rest of our body, which is crazy."}, {"time": 4013, "text": "There's this whole field of motion planning, collision free motion planning."}, {"time": 4018, "text": "And we write very complex algorithms so that the robot can dance around and make sure it doesn't touch the world."}, {"time": 4025, "text": "So people are just afraid of contact because contact the scene is a difficult."}, {"time": 4029, "text": "It's still a difficult control problem and sensing problem."}, {"time": 4033, "text": "Now you're a serious person, I'm a little bit of an idiot and I'm going to ask you some dumb questions."}, {"time": 4044, "text": "So I do martial arts."}, {"time": 4047, "text": "So like jiu jitsu, I wrestled my whole life."}, {"time": 4050, "text": "So let me ask the question, like whenever people learn that I do any kind of AI or like I mentioned robots and things like that, they say, when are we going to have robots that can win in a wrestling match or in a fight against a human?"}, {"time": 4069, "text": "So we just mentioned sitting on your butt, if you're in the air, that's a common position."}, {"time": 4073, "text": "Jiu jitsu, when you're on the ground, you're a down opponent."}, {"time": 4079, "text": "Like how difficult do you think is the problem?"}, {"time": 4083, "text": "And when will we have a robot that can defeat a human in a wrestling match?"}, {"time": 4088, "text": "And we're talking about a lot, like, I don't know if you're familiar with wrestling, but essentially."}, {"time": 4095, "text": "Not very."}, {"time": 4096, "text": "It's basically the art of contact."}, {"time": 4099, "text": "It's like, it's because you're picking contact points and then using like leverage like to off balance to trick people, like you make them feel like you're doing one thing and then they change their balance and then you switch what you're doing and then results in a throw or whatever."}, {"time": 4124, "text": "So like, it's basically the art of multiple contacts."}, {"time": 4129, "text": "Awesome, that's a nice description of it."}, {"time": 4130, "text": "So there's also an opponent in there, right?"}, {"time": 4133, "text": "So if."}, {"time": 4134, "text": "Very dynamic."}, {"time": 4135, "text": "Right, if you are wrestling a human and are in a game theoretic situation with a human, that's still hard, but just to speak to the, you know, quickly reasoning about contact part of it, for instance."}, {"time": 4151, "text": "Yeah, maybe even throwing the game theory out of it, almost like, yeah, almost like a non dynamic opponent."}, {"time": 4157, "text": "Right, there's reasons to be optimistic, but I think our best understanding of those problems are still pretty hard."}, {"time": 4164, "text": "I have been increasingly focused on manipulation, partly where that's a case where the contact has to be much more rich."}, {"time": 4175, "text": "And there are some really impressive examples of deep learning policies, controllers that can appear to do good things through contact."}, {"time": 4187, "text": "We've even got new examples of, you know, deep learning models of predicting what's gonna happen to objects as they go through contact."}, {"time": 4196, "text": "But I think the challenge you just offered there still eludes us, right?"}, {"time": 4201, "text": "The ability to make a decision based on those models quickly."}, {"time": 4207, "text": "You know, I have to think though, it's hard for humans too, when you get that complicated."}, {"time": 4211, "text": "I think probably you had maybe a slow motion version of where you learned the basic skills and you've probably gotten better at it and there's much more subtle to you."}, {"time": 4224, "text": "But it might still be hard to actually, you know, really on the fly take a, you know, model of your humanoid and figure out how to plan the optimal sequence."}, {"time": 4235, "text": "That might be a problem we never solve."}, {"time": 4236, "text": "Well, the, I mean, one of the most amazing things to me about the, we can talk about martial arts."}, {"time": 4243, "text": "We could also talk about dancing."}, {"time": 4245, "text": "Doesn't really matter."}, {"time": 4246, "text": "Too human, I think it's the most interesting study of contact."}, {"time": 4251, "text": "It's not even the dynamic element of it."}, {"time": 4253, "text": "It's the, like when you get good at it, it's so effortless."}, {"time": 4258, "text": "Like I can just, I'm very cognizant of the entirety of the learning process being essentially like learning how to move my body in a way that I could throw very large weights around effortlessly, like, and I can feel the learning."}, {"time": 4278, "text": "Like I'm a huge believer in drilling of techniques and you can just like feel your, I don't, you're not feeling, you're feeling, sorry, you're learning it intellectually a little bit, but a lot of it is the body learning it somehow, like instinctually and whatever that learning is, that's really, I'm not even sure if that's equivalent to like a deep learning, learning a controller."}, {"time": 4304, "text": "I think it's something more, it feels like there's a lot of distributed learning going on."}, {"time": 4310, "text": "Yeah, I think there's hierarchy and composition probably in the systems that we don't capture very well yet."}, {"time": 4320, "text": "You have layers of control systems."}, {"time": 4322, "text": "You have reflexes at the bottom layer and you have a system that's capable of planning a vacation to some distant country, which is probably, you probably don't have a controller, a policy for every possible destination you'll ever pick."}, {"time": 4340, "text": "But there's something magical in the in between and how do you go from these low level feedback loops to something that feels like a pretty complex set of outcomes."}, {"time": 4352, "text": "You know, my guess is, I think there's evidence that you can plan at some of these levels, right?"}, {"time": 4357, "text": "So Josh Tenenbaum just showed it in his talk the other day."}, {"time": 4361, "text": "He's got a game he likes to talk about."}, {"time": 4363, "text": "I think he calls it the pick three game or something, where he puts a bunch of clutter down in front of a person and he says, okay, pick three objects."}, {"time": 4372, "text": "And it might be a telephone or a shoe or a Kleenex box or whatever."}, {"time": 4379, "text": "And apparently you pick three items and then you pick, he says, okay, pick the first one up with your right hand, the second one up with your left hand."}, {"time": 4386, "text": "Now using those objects, now as tools, pick up the third object."}, {"time": 4391, "text": "Right, so that's down at the level of physics and mechanics and contact mechanics that I think we do learning or we do have policies for, we do control for, almost feedback, but somehow we're able to still, I mean, I've never picked up a telephone with a shoe and a water bottle before."}, {"time": 4410, "text": "And somehow, and it takes me a little longer to do that the first time, but most of the time we can sort of figure that out."}, {"time": 4417, "text": "So yeah, I think the amazing thing is this ability to be flexible with our models, plan when we need to use our well oiled controllers when we don't, when we're in familiar territory."}, {"time": 4433, "text": "Having models, I think the other thing you just said was something about, I think your awareness of what's happening is even changing as you improve your expertise, right?"}, {"time": 4442, "text": "So maybe you have a very approximate model of the mechanics to begin with."}, {"time": 4446, "text": "And as you gain expertise, you get a more refined version of that model."}, {"time": 4451, "text": "You're aware of muscles or balance components that you just weren't even aware of before."}, {"time": 4459, "text": "So how do you scaffold that?"}, {"time": 4461, "text": "Yeah, plus the fear of injury, the ambition of goals, of excelling, and fear of mortality."}, {"time": 4472, "text": "Let's see, what else is in there?"}, {"time": 4473, "text": "As the motivations, overinflated ego in the beginning, and then a crash of confidence in the middle."}, {"time": 4482, "text": "All of those seem to be essential for the learning process."}, {"time": 4486, "text": "And if all that's good, then you're probably optimizing energy efficiency."}, {"time": 4490, "text": "Yeah, right, so we have to get that right."}, {"time": 4493, "text": "So there was this idea that you would have robots play soccer better than human players by 2050."}, {"time": 4503, "text": "That was the goal."}, {"time": 4505, "text": "Basically, it was the goal to beat world champion team, to become a world cup, beat like a world cup level team."}, {"time": 4513, "text": "So are we gonna see that first?"}, {"time": 4515, "text": "Or a robot, if you're familiar, there's an organization called UFC for mixed martial arts."}, {"time": 4523, "text": "Are we gonna see a world cup championship soccer team that have robots, or a UFC champion mixed martial artist as a robot?"}, {"time": 4533, "text": "I mean, it's very hard to say one thing is harder, some problem is harder than the other."}, {"time": 4538, "text": "What probably matters is who started the organization that, I mean, I think RoboCup has a pretty serious following, and there is a history now of people playing that game, learning about that game, building robots to play that game, building increasingly more human robots."}, {"time": 4555, "text": "It's got momentum."}, {"time": 4557, "text": "So if you want to have mixed martial arts compete, you better start your organization now, right?"}, {"time": 4565, "text": "I think almost independent of which problem is technically harder, because they're both hard and they're both different."}, {"time": 4572, "text": "I mean, those videos are just hilarious, like especially the humanoid robots trying to play soccer."}, {"time": 4581, "text": "I mean, they're kind of terrible right now."}, {"time": 4583, "text": "I mean, I guess there is robo sumo wrestling."}, {"time": 4586, "text": "There's like the robo one competitions, where they do have these robots that go on the table and basically fight."}, {"time": 4592, "text": "So maybe I'm wrong, maybe."}, {"time": 4593, "text": "First of all, do you have a year in mind for RoboCup, just from a robotics perspective?"}, {"time": 4599, "text": "Seems like a super exciting possibility that like in the physical space, this is what's interesting."}, {"time": 4607, "text": "I think the world is captivated."}, {"time": 4610, "text": "I think it's really exciting."}, {"time": 4612, "text": "It inspires just a huge number of people when a machine beats a human at a game that humans are really damn good at."}, {"time": 4623, "text": "So you're talking about chess and go, but that's in the world of digital."}, {"time": 4629, "text": "I don't think machines have beat humans at a game in the physical space yet, but that would be just."}, {"time": 4637, "text": "You have to make the rules very carefully, right?"}, {"time": 4640, "text": "I mean, if Atlas kicked me in the shins, I'm down and game over."}, {"time": 4645, "text": "So it's very subtle on what's fair."}, {"time": 4651, "text": "I think the fighting one is a weird one."}, {"time": 4653, "text": "Yeah, because you're talking about a machine that's much stronger than you."}, {"time": 4656, "text": "But yeah, in terms of soccer, basketball, all those kinds."}, {"time": 4659, "text": "Even soccer, right?"}, {"time": 4660, "text": "I mean, as soon as there's contact or whatever, and there are some things that the robot will do better."}, {"time": 4666, "text": "I think if you really set yourself up to try to see could robots win the game of soccer as the rules were written, the right thing for the robot to do is to play very differently than a human would play."}, {"time": 4679, "text": "You're not gonna get the perfect soccer player robot."}, {"time": 4684, "text": "You're gonna get something that exploits the rules, exploits its super actuators, its super low bandwidth feedback loops or whatever, and it's gonna play the game differently than you want it to play."}, {"time": 4697, "text": "And I bet there's ways, I bet there's loopholes, right?"}, {"time": 4701, "text": "We saw that in the DARPA challenge that it's very hard to write a set of rules that someone can't find a way to exploit."}, {"time": 4712, "text": "Let me ask another ridiculous question."}, {"time": 4715, "text": "I think this might be the last ridiculous question, but I doubt it."}, {"time": 4719, "text": "I aspire to ask as many ridiculous questions of a brilliant MIT professor."}, {"time": 4728, "text": "Okay, I don't know if you've seen the black mirror."}, {"time": 4733, "text": "It's funny, I never watched the episode."}, {"time": 4736, "text": "I know when it happened though, because I gave a talk to some MIT faculty one day on a unassuming Monday or whatever I was telling him about the state of robotics."}, {"time": 4748, "text": "And I showed some video from Boston Dynamics of the quadruped spot at the time."}, {"time": 4753, "text": "It was the early version of spot."}, {"time": 4755, "text": "And there was a look of horror that went across the room."}, {"time": 4759, "text": "And I said, I've shown videos like this a lot of times, what happened?"}, {"time": 4764, "text": "And it turns out that this video had gone, this black mirror episode had changed the way people watched the videos I was putting out."}, {"time": 4773, "text": "The way they see these kinds of robots."}, {"time": 4774, "text": "So I talked to so many people who are just terrified because of that episode probably of these kinds of robots."}, {"time": 4781, "text": "I almost wanna say that they almost enjoy being terrified."}, {"time": 4784, "text": "I don't even know what it is about human psychology that kind of imagine doomsday, the destruction of the universe or our society and kind of like enjoy being afraid."}, {"time": 4797, "text": "I don't wanna simplify it, but it feels like they talk about it so often."}, {"time": 4801, "text": "It almost, there does seem to be an addictive quality to it."}, {"time": 4806, "text": "I talked to a guy, a guy named Joe Rogan, who's kind of the flag bearer for being terrified at these robots."}, {"time": 4814, "text": "Do you have two questions?"}, {"time": 4817, "text": "One, do you have an understanding of why people are afraid of robots?"}, {"time": 4821, "text": "And the second question is in black mirror, just to tell you the episode, I don't even remember it that much anymore, but these robots, I think they can shoot like a pellet or something."}, {"time": 4832, "text": "They basically have, it's basically a spot with a gun."}, {"time": 4836, "text": "And how far are we away from having robots that go rogue like that?"}, {"time": 4844, "text": "Basically spot that goes rogue for some reason and somehow finds a gun."}, {"time": 4851, "text": "Right, so, I mean, I'm not a psychologist."}, {"time": 4856, "text": "I think, I don't know exactly why people react the way they do."}, {"time": 4861, "text": "I think we have to be careful about the way robots influence our society and the like."}, {"time": 4867, "text": "I think that's something, that's a responsibility that roboticists need to embrace."}, {"time": 4873, "text": "I don't think robots are gonna come after me with a kitchen knife or a pellet gun right away."}, {"time": 4878, "text": "And I mean, if they were programmed in such a way, but I used to joke with Atlas that all I had to do was run for five minutes and its battery would run out."}, {"time": 4888, "text": "But actually they've got to be careful and actually they've got a very big battery in there by the end."}, {"time": 4893, "text": "So it was over an hour."}, {"time": 4897, "text": "I think the fear is a bit cultural though."}, {"time": 4899, "text": "Cause I mean, you notice that, like, I think in my age, in the US, we grew up watching Terminator, right?"}, {"time": 4908, "text": "If I had grown up at the same time in Japan, I probably would have been watching Astro Boy."}, {"time": 4912, "text": "And there's a very different reaction to robots in different countries, right?"}, {"time": 4917, "text": "So I don't know if it's a human innate fear of metal marvels or if it's something that we've done to ourselves with our sci fi."}, {"time": 4929, "text": "Yeah, the stories we tell ourselves through movies, through just through popular media."}, {"time": 4936, "text": "But if I were to tell, you know, if you were my therapist and I said, I'm really terrified that we're going to have these robots very soon that will hurt us."}, {"time": 4950, "text": "Like, how do you approach making me feel better?"}, {"time": 4956, "text": "Like, why shouldn't people be afraid?"}, {"time": 4959, "text": "There's a, I think there's a video that went viral recently."}, {"time": 4964, "text": "Everything, everything was spot in Boston, which goes viral in general."}, {"time": 4968, "text": "But usually it's like really cool stuff."}, {"time": 4970, "text": "Like they're doing flips and stuff or like sad stuff, the Atlas being hit with a broomstick or something like that."}, {"time": 4977, "text": "But there's a video where I think one of the new productions bought robots, which are awesome."}, {"time": 4984, "text": "It was like patrolling somewhere in like in some country."}, {"time": 4988, "text": "And like people immediately were like saying like, this is like the dystopian future, like the surveillance state."}, {"time": 4996, "text": "For some reason, like you can just have a camera, like something about spot being able to walk on four feet with like really terrified people."}, {"time": 5005, "text": "So like, what do you say to those people?"}, {"time": 5011, "text": "I think there is a legitimate fear there because so much of our future is uncertain."}, {"time": 5017, "text": "But at the same time, technically speaking, it seems like we're not there yet."}, {"time": 5021, "text": "So what do you say?"}, {"time": 5022, "text": "I mean, I think technology is complicated."}, {"time": 5028, "text": "It can be used in many ways."}, {"time": 5029, "text": "I think there are purely software attacks that somebody could use to do great damage."}, {"time": 5039, "text": "Maybe they have already, you know, I think wheeled robots could be used in bad ways too."}, {"time": 5048, "text": "Drones."}, {"time": 5049, "text": "Drones, right, I don't think that, let's see."}, {"time": 5056, "text": "I don't want to be building technology just because I'm compelled to build technology and I don't think about it."}, {"time": 5063, "text": "But I would consider myself a technological optimist, I guess, in the sense that I think we should continue to create and evolve and our world will change."}, {"time": 5077, "text": "And if we will introduce new challenges, we'll screw something up maybe, but I think also we'll invent ourselves out of those challenges and life will go on."}, {"time": 5089, "text": "So it's interesting because you didn't mention like this is technically too hard."}, {"time": 5094, "text": "I don't think robots are, I think people attribute a robot that looks like an animal as maybe having a level of self awareness or consciousness or something that they don't have yet."}, {"time": 5105, "text": "Right, so it's not, I think our ability to anthropomorphize those robots is probably, we're assuming that they have a level of intelligence that they don't yet have."}, {"time": 5117, "text": "And that might be part of the fear."}, {"time": 5120, "text": "So in that sense, it's too hard."}, {"time": 5122, "text": "But, you know, there are many scary things in the world."}, {"time": 5125, "text": "Right, so I think we're right to ask those questions."}, {"time": 5129, "text": "We're right to think about the implications of our work."}, {"time": 5133, "text": "Right, in the short term as we're working on it for sure, is there something long term that scares you about our future with AI and robots?"}, {"time": 5147, "text": "A lot of folks from Elon Musk to Sam Harris to a lot of folks talk about the existential threats about artificial intelligence."}, {"time": 5158, "text": "Oftentimes, robots kind of inspire that the most because of the anthropomorphism."}, {"time": 5165, "text": "Do you have any fears?"}, {"time": 5167, "text": "It's an important question."}, {"time": 5172, "text": "I actually, I think I like Rod Brooks answer maybe the best on this, I think."}, {"time": 5177, "text": "And it's not the only answer he's given over the years, but maybe one of my favorites is he says, it's not gonna be, he's got a book, Flesh and Machines, I believe, it's not gonna be the robots versus the people, we're all gonna be robot people."}, {"time": 5194, "text": "Because, you know, we already have smartphones, some of us have serious technology implanted in our bodies already, whether we have a hearing aid or a pacemaker or anything like this, people with amputations might have prosthetics."}, {"time": 5210, "text": "And that's a trend I think that is likely to continue."}, {"time": 5217, "text": "I mean, this is now wild speculation."}, {"time": 5221, "text": "But I mean, when do we get to cognitive implants and the like, and."}, {"time": 5226, "text": "Yeah, with neural link, brain computer interfaces, that's interesting."}, {"time": 5230, "text": "So there's a dance between humans and robots that's going to be, it's going to be impossible to be scared of the other out there, the robot, because the robot will be part of us, essentially."}, {"time": 5246, "text": "It'd be so intricately sort of part of our society that."}, {"time": 5250, "text": "Yeah, and it might not even be implanted part of us, but just, it's so much a part of our, yeah, our society."}, {"time": 5257, "text": "So in that sense, the smartphone is already the robot we should be afraid of, yeah."}, {"time": 5261, "text": "I mean, yeah, and all the usual fears arise of the misinformation, the manipulation, all those kinds of things that, the problems are all the same."}, {"time": 5277, "text": "They're human problems, essentially, it feels like."}, {"time": 5280, "text": "Yeah, I mean, I think the way we interact with each other online is changing the value we put on, you know, personal interaction."}, {"time": 5288, "text": "And that's a crazy big change that's going to happen and rip through our, has already been ripping through our society, right?"}, {"time": 5294, "text": "And that has implications that are massive."}, {"time": 5298, "text": "I don't know if they should be scared of it or go with the flow, but I don't see, you know, some battle lines between humans and robots being the first thing to worry about."}, {"time": 5309, "text": "I mean, I do want to just, as a kind of comment, maybe you can comment about your just feelings about Boston Dynamics in general, but you know, I love science, I love engineering, I think there's so many beautiful ideas in it."}, {"time": 5322, "text": "And when I look at Boston Dynamics or legged robots in general, I think they inspire people, curiosity and feelings in general, excitement about engineering more than almost anything else in popular culture."}, {"time": 5340, "text": "And I think that's such an exciting, like responsibility and possibility for robotics."}, {"time": 5346, "text": "And Boston Dynamics is riding that wave pretty damn well."}, {"time": 5350, "text": "Like they found it, they've discovered that hunger and curiosity in the people and they're doing magic with it."}, {"time": 5357, "text": "I don't care if the, I mean, I guess is that their company, they have to make money, right?"}, {"time": 5361, "text": "But they're already doing incredible work and inspiring the world about technology."}, {"time": 5366, "text": "I mean, do you have thoughts about Boston Dynamics and maybe others, your own work in robotics and inspiring the world in that way?"}, {"time": 5376, "text": "I completely agree, I think Boston Dynamics is absolutely awesome."}, {"time": 5382, "text": "I think I show my kids those videos, you know, and the best thing that happens is sometimes they've already seen them, you know, right?"}, {"time": 5390, "text": "I think, I just think it's a pinnacle of success in robotics that is just one of the best things that's happened, absolutely completely agree."}, {"time": 5401, "text": "One of the heartbreaking things to me is how many robotics companies fail, how hard it is to make money with a robotics company."}, {"time": 5413, "text": "Like iRobot like went through hell just to arrive at a Roomba to figure out one product."}, {"time": 5419, "text": "And then there's so many home robotics companies like Jibo and Anki, Anki, the cutest toy that's a great robot I thought went down, I'm forgetting a bunch of them, but a bunch of robotics companies fail, Rod's company, Rethink Robotics."}, {"time": 5442, "text": "Like, do you have anything hopeful to say about the possibility of making money with robots?"}, {"time": 5450, "text": "Oh, I think you can't just look at the failures."}, {"time": 5454, "text": "I mean, Boston Dynamics is a success."}, {"time": 5455, "text": "There's lots of companies that are still doing amazingly good work in robotics."}, {"time": 5461, "text": "I mean, this is the capitalist ecology or something, right?"}, {"time": 5465, "text": "I think you have many companies, you have many startups and they push each other forward and many of them fail and some of them get through and that's sort of the natural way of those things."}, {"time": 5477, "text": "I don't know that is robotics really that much worse."}, {"time": 5480, "text": "I feel the pain that you feel too."}, {"time": 5482, "text": "Every time I read one of these, sometimes it's friends and I definitely wish it went better or went differently."}, {"time": 5493, "text": "But I think it's healthy and good to have bursts of ideas, bursts of activities, ideas, if they are really aggressive, they should fail sometimes."}, {"time": 5505, "text": "Certainly that's the research mantra, right?"}, {"time": 5506, "text": "If you're succeeding at every problem you attempt, then you're not choosing aggressively enough."}, {"time": 5513, "text": "Is it exciting to you, the new spot?"}, {"time": 5515, "text": "Oh, it's so good."}, {"time": 5517, "text": "When are you getting them as a pet or it?"}, {"time": 5520, "text": "Yeah, I mean, I have to dig up 75K right now."}, {"time": 5523, "text": "I mean, it's so cool that there's a price tag, you can go and then actually buy it."}, {"time": 5528, "text": "I have a Skydio R1, love it."}, {"time": 5531, "text": "So no, I would absolutely be a customer."}, {"time": 5538, "text": "I wonder what your kids would think about it."}, {"time": 5540, "text": "I actually, Zach from Boston Dynamics would let my kid drive in one of their demos one time."}, {"time": 5547, "text": "And that was just so good, so good."}, {"time": 5551, "text": "And again, I'll forever be grateful for that."}, {"time": 5554, "text": "And there's something magical about the anthropomorphization of that arm, it adds another level of human connection."}, {"time": 5562, "text": "I'm not sure we understand from a control aspect, the value of anthropomorphization."}, {"time": 5571, "text": "I think that's an understudied and under understood engineering problem."}, {"time": 5577, "text": "There's been a, like psychologists have been studying it."}, {"time": 5580, "text": "I think it's part like manipulating our mind to believe things is a valuable engineering."}, {"time": 5586, "text": "Like this is another degree of freedom that can be controlled."}, {"time": 5589, "text": "I like that, yeah, I think that's right."}, {"time": 5591, "text": "I think there's something that humans seem to do or maybe my dangerous introspection is, I think we are able to make very simple models that assume a lot about the world very quickly."}, {"time": 5607, "text": "And then it takes us a lot more time, like you're wrestling."}, {"time": 5611, "text": "You probably thought you knew what you were doing with wrestling and you were fairly functional as a complete wrestler."}, {"time": 5616, "text": "And then you slowly got more expertise."}, {"time": 5619, "text": "So maybe it's natural that our first level of defense against seeing a new robot is to think of it in our existing models of how humans and animals behave."}, {"time": 5632, "text": "And it's just, as you spend more time with it, then you'll develop more sophisticated models that will appreciate the differences."}, {"time": 5641, "text": "Can you say what does it take to control a robot?"}, {"time": 5645, "text": "Like what is the control problem of a robot?"}, {"time": 5648, "text": "And in general, what is a robot in your view?"}, {"time": 5650, "text": "Like how do you think of this system?"}, {"time": 5655, "text": "What is a robot?"}, {"time": 5657, "text": "I think robotics."}, {"time": 5658, "text": "I told you ridiculous questions."}, {"time": 5660, "text": "No, no, it's good."}, {"time": 5661, "text": "I mean, there's standard definitions of combining computation with some ability to do mechanical work."}, {"time": 5669, "text": "I think that gets us pretty close."}, {"time": 5670, "text": "But I think robotics has this problem that once things really work, we don't call them robots anymore."}, {"time": 5678, "text": "Like my dishwasher at home is pretty sophisticated, beautiful mechanisms."}, {"time": 5685, "text": "There's actually a pretty good computer, probably a couple of chips in there doing amazing things."}, {"time": 5689, "text": "We don't think of that as a robot anymore, which isn't fair."}, {"time": 5692, "text": "Because then what roughly it means that robotics always has to solve the next problem and doesn't get to celebrate its past successes."}, {"time": 5700, "text": "I mean, even factory room floor robots are super successful."}, {"time": 5708, "text": "But that's not the ones, I mean, people think of them as robots, but they don't, if you ask what are the successes of robotics, somehow it doesn't come to your mind immediately."}, {"time": 5717, "text": "So the definition of robot is a system with some level of automation that fails frequently."}, {"time": 5723, "text": "Something like, it's the computation plus mechanical work and an unsolved problem."}, {"time": 5730, "text": "It's an unsolved problem, yeah."}, {"time": 5732, "text": "So from a perspective of control and mechanics, dynamics, what is a robot?"}, {"time": 5740, "text": "So there are many different types of robots."}, {"time": 5742, "text": "The control that you need for a Jibo robot, you know, some robot that's sitting on your countertop and interacting with you, but not touching you, for instance, is very different than what you need for an autonomous car or an autonomous drone."}, {"time": 5759, "text": "It's very different than what you need for a robot that's gonna walk or pick things up with its hands, right?"}, {"time": 5764, "text": "My passion has always been for the places where you're interacting more, you're doing more dynamic interactions with the world."}, {"time": 5773, "text": "So walking, now manipulation."}, {"time": 5778, "text": "And the control problems there are beautiful."}, {"time": 5781, "text": "I think contact is one thing that differentiates them from many of the control problems we've solved classically, right, like modern control grew up stabilizing fighter jets that were passively unstable, and there's like amazing success stories from control all over the place."}, {"time": 5799, "text": "Power grid, I mean, there's all kinds of, it's everywhere that we don't even realize, just like AI is now."}, {"time": 5807, "text": "So you mentioned contact, like what's contact?"}, {"time": 5811, "text": "So an airplane is an extremely complex system or a spacecraft landing or whatever, but at least it has the luxury of things change relatively continuously."}, {"time": 5823, "text": "That's an oversimplification."}, {"time": 5824, "text": "But if I make a small change in the command I send to my actuator, then the path that the robot will take tends to change only by a small amount."}, {"time": 5836, "text": "And there's a feedback mechanism here."}, {"time": 5838, "text": "That's what we're talking about."}, {"time": 5839, "text": "And there's a feedback mechanism."}, {"time": 5840, "text": "And thinking about this as locally, like a linear system, for instance, I can use more linear algebra tools to study systems like that, generalizations of linear algebra to these smooth systems."}, {"time": 5856, "text": "What is contact?"}, {"time": 5857, "text": "The robot has something very discontinuous that happens when it makes or breaks, when it starts touching the world."}, {"time": 5865, "text": "And even the way it touches or the order of contacts can change the outcome in potentially unpredictable ways."}, {"time": 5873, "text": "Not unpredictable, but complex ways."}, {"time": 5876, "text": "I do think there's a little bit of, a lot of people will say that contact is hard in robotics, even to simulate."}, {"time": 5886, "text": "And I think there's a little bit of a, there's truth to that, but maybe a misunderstanding around that."}, {"time": 5893, "text": "So what is limiting is that when we think about our robots and we write our simulators, we often make an assumption that objects are rigid."}, {"time": 5906, "text": "And when it comes down, that their mass moves all, stays in a constant position relative to each other itself."}, {"time": 5917, "text": "And that leads to some paradoxes when you go to try to talk about rigid body mechanics and contact."}, {"time": 5923, "text": "And so for instance, if I have a three legged stool with just imagine it comes to a point at the leg."}, {"time": 5931, "text": "So it's only touching the world at a point."}, {"time": 5934, "text": "If I draw my physics, my high school physics diagram of the system, then there's a couple of things that I'm given by elementary physics."}, {"time": 5943, "text": "I know if the system, if the table is at rest, if it's not moving, zero velocities, that means that the normal force, all the forces are in balance."}, {"time": 5953, "text": "So the force of gravity is being countered by the forces that the ground is pushing on my table legs."}, {"time": 5961, "text": "I also know since it's not rotating that the moments have to balance."}, {"time": 5965, "text": "And since it's a three dimensional table, it could fall in any direction."}, {"time": 5971, "text": "It actually tells me uniquely what those three normal forces have to be."}, {"time": 5977, "text": "If I have four legs on my table, four legged table and they were perfectly machined to be exactly the right same height and they're set down and the table's not moving, then the basic conservation laws don't tell me, there are many solutions for the forces that the ground could be putting on my legs that would still result in the table not moving."}, {"time": 6000, "text": "Now, the reason that seems fine, I could just pick one."}, {"time": 6003, "text": "But it gets funny now because if you think about friction, what we think about with friction is our standard model says the amount of force that the table will push back if I were to now try to push my table sideways, I guess I have a table here, is proportional to the normal force."}, {"time": 6024, "text": "So if I'm barely touching and I push, I'll slide, but if I'm pushing more and I push, I'll slide less."}, {"time": 6030, "text": "It's called coulomb friction is our standard model."}, {"time": 6033, "text": "Now, if you don't know what the normal force is on the four legs and you push the table, then you don't know what the friction forces are gonna be."}, {"time": 6043, "text": "And so you can't actually tell, the laws just aren't explicit yet about which way the table's gonna go."}, {"time": 6049, "text": "It could veer off to the left, it could veer off to the right, it could go straight."}, {"time": 6054, "text": "So the rigid body assumption of contact leaves us with some paradoxes, which are annoying for writing simulators and for writing controllers."}, {"time": 6064, "text": "We still do that sometimes because soft contact is potentially harder numerically or whatever, and the best simulators do both or do some combination of the two."}, {"time": 6075, "text": "But anyways, because of these kinds of paradoxes, there's all kinds of paradoxes in contact, mostly due to these rigid body assumptions."}, {"time": 6083, "text": "It becomes very hard to write the same kind of control laws that we've been able to be successful with for fighter jets."}, {"time": 6092, "text": "Like fighter jets, we haven't been as successful writing those controllers for manipulation."}, {"time": 6097, "text": "And so you don't know what's going to happen at the point of contact, at the moment of contact."}, {"time": 6101, "text": "There are situations absolutely where our laws don't tell us."}, {"time": 6105, "text": "So the standard approach, that's okay."}, {"time": 6107, "text": "I mean, instead of having a differential equation, you end up with a differential inclusion, it's called."}, {"time": 6113, "text": "It's a set valued equation."}, {"time": 6116, "text": "It says that I'm in this configuration, I have these forces applied on me."}, {"time": 6120, "text": "And there's a set of things that could happen, right?"}, {"time": 6123, "text": "And you can... And those aren't continuous, I mean, what..."}, {"time": 6127, "text": "So when you're saying like non smooth, they're not only not smooth, but this is discontinuous?"}, {"time": 6134, "text": "The non smooth comes in when I make or break a new contact first, or when I transition from stick to slip."}, {"time": 6141, "text": "So you typically have static friction, and then you'll start sliding, and that'll be a discontinuous change in philosophy."}, {"time": 6148, "text": "In philosophy, for instance, especially if you come to rest or... That's so fascinating."}, {"time": 6154, "text": "Okay, so what do you do?"}, {"time": 6157, "text": "Sorry, I interrupted you."}, {"time": 6161, "text": "What's the hope under so much uncertainty about what's going to happen?"}, {"time": 6166, "text": "I mean, control has an answer for this."}, {"time": 6168, "text": "Robust control is one approach, but roughly you can write controllers which try to still perform the right task despite all the things that could possibly happen."}, {"time": 6178, "text": "The world might want the table to go this way and this way, but if I write a controller that pushes a little bit more and pushes a little bit, I can certainly make the table go in the direction I want."}, {"time": 6188, "text": "It just puts a little bit more of a burden on the control system, right?"}, {"time": 6192, "text": "And this discontinuities do change the control system because the way we write it down right now, every different control configuration, including sticking or sliding or parts of my body that are in contact or not, looks like a different system."}, {"time": 6210, "text": "And I think of them, I reason about them separately or differently and the combinatorics of that blow up, right?"}, {"time": 6218, "text": "So I just don't have enough time to compute all the possible contact configurations of my humanoid."}, {"time": 6225, "text": "Interestingly, I mean, I'm a humanoid."}, {"time": 6229, "text": "I have lots of degrees of freedom, lots of joints."}, {"time": 6232, "text": "I've only been around for a handful of years."}, {"time": 6234, "text": "It's getting up there, but I haven't had time in my life to visit all of the states in my system, certainly all the contact configurations."}, {"time": 6245, "text": "So if step one is to consider every possible contact configuration that I'll ever be in, that's probably not a problem I need to solve, right?"}, {"time": 6257, "text": "Just as a small tangent, what's a contact configuration?"}, {"time": 6260, "text": "What like, just so we can enumerate what are we talking about?"}, {"time": 6266, "text": "How many are there?"}, {"time": 6267, "text": "The simplest example maybe would be, imagine a robot with a flat foot."}, {"time": 6272, "text": "And we think about the phases of gait where the heel strikes and then the front toe strikes, and then you can heel up, toe off."}, {"time": 6283, "text": "Those are each different contact configurations."}, {"time": 6286, "text": "I only had two different contacts, but I ended up with four different contact configurations."}, {"time": 6291, "text": "Now, of course, my robot might actually have bumps on it or other things, so it could be much more subtle than that, right?"}, {"time": 6300, "text": "But it's just even with one sort of box interacting with the ground already in the plane has that many, right?"}, {"time": 6307, "text": "And if I was just even a 3D foot, then it probably my left toe might touch just before my right toe and things get subtle."}, {"time": 6314, "text": "Now, if I'm a dexterous hand and I go to talk about just grabbing a water bottle, if I have to enumerate every possible order that my hand came into contact with the bottle, then I'm dead in the water."}, {"time": 6332, "text": "Any approach that we were able to get away with that in walking because we mostly touched the ground within a small number of points, for instance, and we haven't been able to get dexterous hands that way."}, {"time": 6343, "text": "So you've mentioned that people think that contact is really hard and that that's the reason that robotic manipulation is problem is really hard."}, {"time": 6360, "text": "Is there any flaws in that thinking?"}, {"time": 6366, "text": "So I think simulating contact is one aspect."}, {"time": 6370, "text": "I know people often say that we don't, that one of the reasons that we have a limit in robotics is because we do not simulate contact accurately in our simulators."}, {"time": 6380, "text": "And I think that is the extent to which that's true is partly because our simulators, we haven't got mature enough simulators."}, {"time": 6391, "text": "There are some things that are still hard, difficult, that we should change, but we actually, we know what the governing equations are."}, {"time": 6401, "text": "They have some foibles like this indeterminacy, but we should be able to simulate them accurately."}, {"time": 6408, "text": "We have incredible open source community in robotics, but it actually just takes a professional engineering team a lot of work to write a very good simulator like that."}, {"time": 6419, "text": "Now, where does, I believe you've written, Drake."}, {"time": 6423, "text": "There's a team of people."}, {"time": 6424, "text": "I certainly spent a lot of hours on it myself."}, {"time": 6427, "text": "But what is Drake and what does it take to create a simulation environment for the kind of difficult control problems we're talking about?"}, {"time": 6440, "text": "Right, so Drake is the simulator that I've been working on."}, {"time": 6444, "text": "There are other good simulators out there."}, {"time": 6446, "text": "I don't like to think of Drake as just a simulator because we write our controllers in Drake, we write our perception systems a little bit in Drake, but we write all of our low level control and even planning and optimization."}, {"time": 6460, "text": "So it has optimization capabilities as well?"}, {"time": 6463, "text": "I mean, Drake is three things roughly."}, {"time": 6466, "text": "It's an optimization library, which is sits on, it provides a layer of abstraction in C++ and Python for commercial solvers."}, {"time": 6475, "text": "You can write linear programs, quadratic programs, semi definite programs, sums of squares programs, the ones we've used, mixed integer programs, and it will do the work to curate those and send them to whatever the right solver is for instance, and it provides a level of abstraction."}, {"time": 6523, "text": "If you have any state, for instance, in the system, any variables that are gonna persist, you have to declare them."}, {"time": 6529, "text": "Parameters can be declared and the like, but the advantage of doing that is that you can, if you like, run things all on one process, but you can also do control design against it."}, {"time": 6540, "text": "You can do, I mean, simple things like rewinding and playing back your simulations, for instance, these things, you get some rewards for spending a little bit more upfront cost in describing each system."}, {"time": 6553, "text": "And I was inspired to do that because I think the complexity of Atlas, for instance, is just so great."}, {"time": 6562, "text": "And I think, although, I mean, ROS has been an incredible, absolutely huge fan of what it's done for the robotics community, but the ability to rapidly put different pieces together and have a functioning thing is very good."}, {"time": 6578, "text": "But I do think that it's hard to think clearly about a bag of disparate parts, Mr."}, {"time": 6585, "text": "Potato Head kind of software stack."}, {"time": 6588, "text": "And if you can ask a little bit more out of each of those parts, then you can understand the way they work better."}, {"time": 6596, "text": "You can try to verify them and the like, or you can do learning against them."}, {"time": 6602, "text": "And then one of those systems, the last thing, I said the first two things that Drake is, but the last thing is that there is a set of multi body equations, rigid body equations, that is trying to provide a system that simulates physics."}, {"time": 6616, "text": "And we also have renderers and other things, but I think the physics component of Drake is special in the sense that we have done excessive amount of engineering to make sure that we've written the equations correctly."}, {"time": 6631, "text": "Every possible tumbling satellite or spinning top or anything that we could possibly write as a test is tested."}, {"time": 6638, "text": "We are making some, I think, fundamental improvements on the way you simulate contact."}, {"time": 6644, "text": "Just what does it take to simulate contact?"}, {"time": 6647, "text": "I mean, it just seems, I mean, there's something just beautiful to the way you were like explaining contact and you were like tapping your fingers on the table while you're doing it, just."}, {"time": 6660, "text": "Easily, right?"}, {"time": 6661, "text": "Easily, just like, just not even like, it was like helping you think, I guess."}, {"time": 6670, "text": "So you have this like awesome demo of loading or unloading a dishwasher, just picking up a plate, or grasping it like for the first time."}, {"time": 6686, "text": "That's just seems like so difficult."}, {"time": 6689, "text": "What, how do you simulate any of that?"}, {"time": 6693, "text": "So it was really interesting that what happened was that we started getting more professional about our software development during the DARPA Robotics Challenge."}, {"time": 6703, "text": "I learned the value of software engineering and how these, how to bridle complexity."}, {"time": 6708, "text": "I guess that's what I want to somehow fight against and bring some of the clear thinking of controls into these complex systems we're building for robots."}, {"time": 6720, "text": "Shortly after the DARPA Robotics Challenge, Toyota opened a research institute, TRI, Toyota Research Institute."}, {"time": 6728, "text": "They put one of their, there's three locations."}, {"time": 6730, "text": "One of them is just down the street from MIT."}, {"time": 6733, "text": "And I helped ramp that up right up as a part of my, the end of my sabbatical, I guess."}, {"time": 6743, "text": "So TRI has given me, the TRI robotics effort has made this investment in simulation in Drake."}, {"time": 6752, "text": "And Michael Sherman leads a team there of just absolutely top notch dynamics experts that are trying to write those simulators that can pick up the dishes."}, {"time": 6761, "text": "And there's also a team working on manipulation there that is taking problems like loading the dishwasher."}, {"time": 6768, "text": "And we're using that to study these really hard corner cases kind of problems in manipulation."}, {"time": 6775, "text": "So for me, this, you know, simulating the dishes, we could actually write a controller."}, {"time": 6781, "text": "If we just cared about picking up dishes in the sink once, we could write a controller without any simulation whatsoever, and we could call it done."}, {"time": 6790, "text": "But we want to understand like, what is the path you take to actually get to a robot that could perform that for any dish in anybody's kitchen with enough confidence that it could be a commercial product, right?"}, {"time": 6806, "text": "And it has deep learning perception in the loop."}, {"time": 6809, "text": "It has complex dynamics in the loop."}, {"time": 6811, "text": "It has controller, it has a planner."}, {"time": 6813, "text": "And how do you take all of that complexity and put it through this engineering discipline and verification and validation process to actually get enough confidence to deploy?"}, {"time": 6826, "text": "I mean, the DARPA challenge made me realize that that's not something you throw over the fence and hope that somebody will harden it for you, that there are really fundamental challenges in closing that last gap."}, {"time": 6839, "text": "They're doing the validation and the testing."}, {"time": 6843, "text": "I think it might even change the way we have to think about the way we write systems."}, {"time": 6849, "text": "What happens if you have the robot running lots of tests and it screws up, it breaks a dish, right?"}, {"time": 6859, "text": "How do you capture that?"}, {"time": 6859, "text": "I said, you can't run the same simulation or the same experiment twice on a real robot."}, {"time": 6867, "text": "Do we have to be able to bring that one off failure back into simulation in order to change our controllers, study it, make sure it won't happen again?"}, {"time": 6877, "text": "Do we, is it enough to just try to add that to our distribution and understand that on average, we're gonna cover that situation again?"}, {"time": 6885, "text": "There's like really subtle questions at the corner cases that I think we don't yet have satisfying answers for."}, {"time": 6893, "text": "Like how do you find the corner cases?"}, {"time": 6895, "text": "That's one kind of, is there, do you think that's possible to create a systematized way of discovering corner cases efficiently?"}, {"time": 6905, "text": "In whatever the problem is?"}, {"time": 6907, "text": "Yes, I mean, I think we have to get better at that."}, {"time": 6910, "text": "I mean, control theory has for decades talked about active experiment design."}, {"time": 6919, "text": "So people call it curiosity these days."}, {"time": 6922, "text": "It's roughly this idea of trying to exploration or exploitation, but in the active experiment design is even, is more specific."}, {"time": 6929, "text": "You could try to understand the uncertainty in your system, design the experiment that will provide the maximum information to reduce that uncertainty."}, {"time": 6940, "text": "If there's a parameter you wanna learn about, what is the optimal trajectory I could execute to learn about that parameter, for instance."}, {"time": 6949, "text": "Scaling that up to something that has a deep network in the loop and a planning in the loop is tough."}, {"time": 6955, "text": "We've done some work on, you know, with Matt Okely and Aman Sinha, we've worked on some falsification algorithms that are trying to do rare event simulation that try to just hammer on your simulator."}, {"time": 6968, "text": "And if your simulator is good enough, you can spend a lot of time, or you can write good algorithms that try to spend most of their time in the corner cases."}, {"time": 6979, "text": "So you basically imagine you're building an autonomous car and you wanna put it in, I don't know, downtown New Delhi all the time, right?"}, {"time": 6989, "text": "And accelerated testing."}, {"time": 6991, "text": "If you can write sampling strategies, which figure out where your controller's performing badly in simulation and start generating lots of examples around that."}, {"time": 7000, "text": "You know, it's just the space of possible places where that can be, where things can go wrong is very big."}, {"time": 7008, "text": "So it's hard to write those algorithms."}, {"time": 7009, "text": "Yeah, rare event simulation is just a really compelling notion, if it's possible."}, {"time": 7015, "text": "We joked and we call it the black swan generator."}, {"time": 7018, "text": "It's a black swan."}, {"time": 7020, "text": "Because you don't just want the rare events, you want the ones that are highly impactful."}, {"time": 7024, "text": "I mean, that's the most, those are the most sort of profound questions we ask of our world."}, {"time": 7030, "text": "Like, what's the worst that can happen?"}, {"time": 7036, "text": "But what we're really asking isn't some kind of like computer science, worst case analysis."}, {"time": 7042, "text": "We're asking like, what are the millions of ways this can go wrong?"}, {"time": 7047, "text": "And that's like our curiosity."}, {"time": 7049, "text": "And we humans, I think are pretty bad at, we just like run into it."}, {"time": 7056, "text": "And I think there's a distributed sense because there's now like 7.5 billion of us."}, {"time": 7061, "text": "And so there's a lot of them."}, {"time": 7062, "text": "And then a lot of them write blog posts about the stupid thing they've done."}, {"time": 7066, "text": "So we learn in a distributed way."}, {"time": 7070, "text": "I think that's gonna be important for robots too."}, {"time": 7073, "text": "I mean, that's another massive theme at Toyota Research for Robotics is this fleet learning concept is the idea that I, as a human, I don't have enough time to visit all of my states, right?"}, {"time": 7087, "text": "There's just a, it's very hard for one robot to experience all the things."}, {"time": 7092, "text": "But that's not actually the problem we have to solve, right?"}, {"time": 7096, "text": "We're gonna have fleets of robots that can have very similar appendages."}, {"time": 7100, "text": "And at some point, maybe collectively, they have enough data that their computational processes should be set up differently than ours, right?"}, {"time": 7111, "text": "It's this vision of just, I mean, all these dishwasher unloading robots."}, {"time": 7118, "text": "I mean, that robot dropping a plate and a human looking at the robot probably pissed off."}, {"time": 7127, "text": "But that's a special moment to record."}, {"time": 7131, "text": "I think one thing in terms of fleet learning, and I've seen that because I've talked to a lot of folks, just like Tesla users or Tesla drivers, they're another company that's using this kind of fleet learning idea."}, {"time": 7145, "text": "One hopeful thing I have about humans is they really enjoy when a system improves, learns."}, {"time": 7153, "text": "So they enjoy fleet learning."}, {"time": 7154, "text": "And the reason it's hopeful for me is they're willing to put up with something that's kind of dumb right now."}, {"time": 7162, "text": "And they're like, if it's improving, they almost like enjoy being part of the, like teaching it."}, {"time": 7169, "text": "Almost like if you have kids, like you're teaching them something, right?"}, {"time": 7173, "text": "I think that's a beautiful thing because that gives me hope that we can put dumb robots out there."}, {"time": 7180, "text": "I mean, the problem on the Tesla side with cars, cars can kill you."}, {"time": 7185, "text": "That makes the problem so much harder."}, {"time": 7187, "text": "Dishwasher unloading is a little safe."}, {"time": 7190, "text": "That's why home robotics is really exciting."}, {"time": 7194, "text": "And just to clarify, I mean, for people who might not know, I mean, TRI, Toyota Research Institute."}, {"time": 7200, "text": "So they're, I mean, they're pretty well known for like autonomous vehicle research, but they're also interested in home robotics."}, {"time": 7210, "text": "Yep, there's a big group working on, multiple groups working on home robotics."}, {"time": 7214, "text": "It's a major part of the portfolio."}, {"time": 7217, "text": "There's also a couple other projects in advanced materials discovery, using AI and machine learning to discover new materials for car batteries and the like, for instance, yeah."}, {"time": 7228, "text": "And that's been actually an incredibly successful team."}, {"time": 7231, "text": "There's new projects starting up too, so."}, {"time": 7233, "text": "Do you see a future of where like robots are in our home and like robots that have like actuators that look like arms in our home or like, you know, more like humanoid type robots?"}, {"time": 7249, "text": "Or is this, are we gonna do the same thing that you just mentioned that, you know, the dishwasher is no longer a robot."}, {"time": 7255, "text": "We're going to just not even see them as robots."}, {"time": 7258, "text": "But I mean, what's your vision of the home of the future 10, 20 years from now, 50 years, if you get crazy?"}, {"time": 7266, "text": "Yeah, I think we already have Roombas cruising around."}, {"time": 7270, "text": "We have, you know, Alexis or Google Homes on our kitchen counter."}, {"time": 7276, "text": "It's only a matter of time until they spring arms and start doing something useful like that."}, {"time": 7281, "text": "So I do think it's coming."}, {"time": 7283, "text": "I think lots of people have lots of motivations for doing it."}, {"time": 7289, "text": "It's been super interesting actually learning about Toyota's vision for it, which is about helping people age in place."}, {"time": 7298, "text": "Cause I think that's not necessarily the first entry, the most lucrative entry point, but it's the problem maybe that we really need to solve no matter what."}, {"time": 7310, "text": "And so I think there's a real opportunity."}, {"time": 7313, "text": "It's a delicate problem."}, {"time": 7315, "text": "How do you work with people, help people, keep them active, engaged, you know, but improve their quality of life and help them age in place, for instance."}, {"time": 7328, "text": "It's interesting because older folks are also, I mean, there's a contrast there because they're not always the folks who are the most comfortable with technology, for example."}, {"time": 7340, "text": "So there's a division that's interesting."}, {"time": 7344, "text": "You can do so much good with a robot for older folks, but there's a gap to fill of understanding."}, {"time": 7356, "text": "I mean, it's actually kind of beautiful."}, {"time": 7359, "text": "Robot is learning about the human and the human is kind of learning about this new robot thing."}, {"time": 7364, "text": "And it's also with, at least with, like when I talked to my parents about robots, there's a little bit of a blank slate there too."}, {"time": 7374, "text": "Like you can, I mean, they don't know anything about robotics, so it's completely like wide open."}, {"time": 7382, "text": "They don't have, they haven't, my parents haven't seen Black Mirror."}, {"time": 7386, "text": "So like they, it's a blank slate."}, {"time": 7389, "text": "Here's a cool thing, like what can it do for me?"}, {"time": 7391, "text": "Yeah, so it's an exciting space."}, {"time": 7394, "text": "I think it's a really important space."}, {"time": 7396, "text": "I do feel like a few years ago, drones were successful enough in academia."}, {"time": 7402, "text": "They kind of broke out and started an industry and autonomous cars have been happening."}, {"time": 7409, "text": "It does feel like manipulation in logistics, of course, first, but in the home shortly after, seems like one of the next big things that's gonna really pop."}, {"time": 7420, "text": "So I don't think we talked about it, but what's soft robotics?"}, {"time": 7424, "text": "So we talked about like rigid bodies."}, {"time": 7429, "text": "Like if we can just linger on this whole touch thing."}, {"time": 7432, "text": "Yeah, so what's soft robotics?"}, {"time": 7434, "text": "So I told you that I really dislike the fact that robots are afraid of touching the world all over their body."}, {"time": 7444, "text": "So there's a couple reasons for that."}, {"time": 7446, "text": "If you look carefully at all the places that robots actually do touch the world, they're almost always soft."}, {"time": 7452, "text": "They have some sort of pad on their fingers or a rubber sole on their foot."}, {"time": 7457, "text": "But if you look up and down the arm, we're just pure aluminum or something."}, {"time": 7465, "text": "So that makes it hard actually."}, {"time": 7466, "text": "In fact, hitting the table with your rigid arm or nearly rigid arm has some of the problems that we talked about in terms of simulation."}, {"time": 7477, "text": "I think it fundamentally changes the mechanics of contact when you're soft, right?"}, {"time": 7481, "text": "You turn point contacts into patch contacts, which can have torsional friction."}, {"time": 7487, "text": "You can have distributed load."}, {"time": 7489, "text": "If I wanna pick up an egg, right?"}, {"time": 7492, "text": "If I pick it up with two points, then in order to put enough force to sustain the weight of the egg, I might have to put a lot of force to break the egg."}, {"time": 7499, "text": "If I envelop it with contact all around, then I can distribute my force across the shell of the egg and have a better chance of not breaking it."}, {"time": 7510, "text": "So soft robotics is for me a lot about changing the mechanics of contact."}, {"time": 7515, "text": "Does it make the problem a lot harder?"}, {"time": 7519, "text": "Quite the opposite."}, {"time": 7524, "text": "It changes the computational problem."}, {"time": 7526, "text": "I think because of the, I think our world and our mathematics has biased us towards rigid."}, {"time": 7535, "text": "But it really should make things better in some ways, right?"}, {"time": 7540, "text": "I think the future is unwritten there."}, {"time": 7544, "text": "But the other thing it can do."}, {"time": 7545, "text": "I think ultimately, sorry to interrupt, but I think ultimately it will make things simpler if we embrace the softness of the world."}, {"time": 7551, "text": "It makes things smoother, right?"}, {"time": 7555, "text": "So the result of small actions is less discontinuous, but it also means potentially less instantaneously bad."}, {"time": 7565, "text": "For instance, I won't necessarily contact something and send it flying off."}, {"time": 7572, "text": "The other aspect of it that just happens to dovetail really well is that soft robotics tends to be a place where we can embed a lot of sensors too."}, {"time": 7579, "text": "So if you change your hardware and make it more soft, then you can potentially have a tactile sensor, which is measuring the deformation."}, {"time": 7587, "text": "So there's a team at TRI that's working on soft hands and you get so much more information."}, {"time": 7595, "text": "You can put a camera behind the skin roughly and get fantastic tactile information, which is, it's super important."}, {"time": 7627, "text": "So in all the part that really matters, all of your off board sensors are occluded."}, {"time": 7633, "text": "And really, if you don't have tactile information, then you're blind in an important way."}, {"time": 7639, "text": "So it happens that soft robotics and tactile sensing tend to go hand in hand."}, {"time": 7645, "text": "I think we've kind of talked about it, but you taught a course on underactuated robotics."}, {"time": 7651, "text": "I believe that was the name of it, actually."}, {"time": 7654, "text": "Can you talk about it in that context?"}, {"time": 7657, "text": "What is underactuated robotics?"}, {"time": 7660, "text": "Right, so underactuated robotics is my graduate course."}, {"time": 7663, "text": "It's online mostly now, in the sense that the lectures."}, {"time": 7667, "text": "Several versions of it, I think."}, {"time": 7669, "text": "Right, the YouTube."}, {"time": 7669, "text": "It's really great, I recommend it highly."}, {"time": 7672, "text": "Look on YouTube for the 2020 versions."}, {"time": 7675, "text": "Until March, and then you have to go back to 2019, thanks to COVID."}, {"time": 7680, "text": "No, I've poured my heart into that class."}, {"time": 7684, "text": "And lecture one is basically explaining what the word underactuated means."}, {"time": 7687, "text": "So people are very kind to show up and then maybe have to learn what the title of the course means over the course of the first lecture."}, {"time": 7695, "text": "That first lecture is really good."}, {"time": 7697, "text": "You should watch it."}, {"time": 7699, "text": "It's a strange name, but I thought it captured the essence of what control was good at doing and what control was bad at doing."}, {"time": 7709, "text": "So what do I mean by underactuated?"}, {"time": 7711, "text": "So a mechanical system has many degrees of freedom, for instance."}, {"time": 7719, "text": "I think of a joint as a degree of freedom."}, {"time": 7721, "text": "And it has some number of actuators, motors."}, {"time": 7726, "text": "So if you have a robot that's bolted to the table that has five degrees of freedom and five motors, then you have a fully actuated robot."}, {"time": 7737, "text": "If you take away one of those motors, then you have an underactuated robot."}, {"time": 7743, "text": "Now, why on earth?"}, {"time": 7744, "text": "I have a good friend who likes to tease me."}, {"time": 7747, "text": "He said, Ross, if you had more research funding, would you work on fully actuated robots?"}, {"time": 7755, "text": "The world gives us underactuated robots, whether we like it or not."}, {"time": 7758, "text": "I'm a human."}, {"time": 7759, "text": "I'm an underactuated robot, even though I have more muscles than my big degrees of freedom, because I have in some places multiple muscles attached to the same joint."}, {"time": 7770, "text": "But still, there's a really important degree of freedom that I have, which is the location of my center of mass in space, for instance."}, {"time": 7779, "text": "All right, I can jump into the air, and there's no motor that connects my center of mass to the ground in that case."}, {"time": 7787, "text": "So I have to think about the implications of not having control over everything."}, {"time": 7792, "text": "The passive dynamic walkers are the extreme view of that, where you've taken away all the motors, and you have to let physics do the work."}, {"time": 7799, "text": "But it shows up in all of the walking robots, where you have to use some of the actuators to push and pull even the degrees of freedom that you don't have an actuator on."}, {"time": 7809, "text": "That's referring to walking if you're falling forward."}, {"time": 7813, "text": "Is there a way to walk that's fully actuated?"}, {"time": 7816, "text": "So it's a subtle point."}, {"time": 7818, "text": "When you're in contact and you have your feet on the ground, there are still limits to what you can do, right?"}, {"time": 7826, "text": "Unless I have suction cups on my feet, I cannot accelerate my center of mass towards the ground faster than gravity, because I can't get a force pushing me down, right?"}, {"time": 7837, "text": "But I can still do most of the things that I want to."}, {"time": 7839, "text": "So you can get away with basically thinking of the system as fully actuated, unless you suddenly needed to accelerate down super fast."}, {"time": 7847, "text": "But as soon as I take a step, I get into the more nuanced territory, and to get to really dynamic robots, or airplanes or other things, I think you have to embrace the underactuated dynamics."}, {"time": 7862, "text": "Manipulation, people think, is manipulation underactuated?"}, {"time": 7866, "text": "Even if my arm is fully actuated, I have a motor, if my goal is to control the position and orientation of this cup, then I don't have an actuator for that directly."}, {"time": 7879, "text": "So I have to use my actuators over here to control this thing."}, {"time": 7883, "text": "Now it gets even worse, like what if I have to button my shirt, okay?"}, {"time": 7889, "text": "What are the degrees of freedom of my shirt, right?"}, {"time": 7891, "text": "I suddenly, that's a hard question to think about."}, {"time": 7894, "text": "It kind of makes me queasy thinking about my state space control ideas."}, {"time": 7900, "text": "But actually those are the problems that make me so excited about manipulation right now, is that it breaks some of the, it breaks a lot of the foundational control stuff that I've been thinking about."}, {"time": 7911, "text": "Is there, what are some interesting insights you could say about trying to solve an underactuated, a control in an underactuated system?"}, {"time": 7922, "text": "So I think the philosophy there is let physics do more of the work."}, {"time": 7928, "text": "The technical approach has been optimization."}, {"time": 7932, "text": "So you typically formulate your decision making for control as an optimization problem."}, {"time": 7937, "text": "And you use the language of optimal control and sometimes often numerical optimal control in order to make those decisions and balance, these complicated equations of, and in order to control, you don't have to use optimal control to do underactuated systems, but that has been the technical approach that has borne the most fruit in our, at least in our line of work."}, {"time": 7960, "text": "And there's some, so in underactuated systems, when you say let physics do some of the work, so there's a kind of feedback loop that observes the state that the physics brought you to."}, {"time": 7974, "text": "So like you've, there's a perception there, there's a feedback somehow."}, {"time": 7980, "text": "Do you ever loop in like complicated perception systems into this whole picture?"}, {"time": 7986, "text": "Right, right around the time of the DARPA challenge, we had a complicated perception system in the DARPA challenge."}, {"time": 7992, "text": "We also started to embrace perception for our flying vehicles at the time."}, {"time": 7997, "text": "We had a really good project on trying to make airplanes fly at high speeds through forests."}, {"time": 8004, "text": "Sirtash Karaman was on that project and we had, it was a really fun team to work on."}, {"time": 8010, "text": "He's carried it farther, much farther forward since then."}, {"time": 8014, "text": "And that's using cameras for perception?"}, {"time": 8015, "text": "So that was using cameras."}, {"time": 8017, "text": "That was, at the time we felt like LIDAR was too heavy and too power heavy to be carried on a light UAV, and we were using cameras."}, {"time": 8029, "text": "And that was a big part of it was just how do you do even stereo matching at a fast enough rate with a small camera, small onboard compute."}, {"time": 8038, "text": "Since then we have now, so the deep learning revolution unquestionably changed what we can do with perception for robotics and control."}, {"time": 8049, "text": "So in manipulation, we can address, we can use perception in I think a much deeper way."}, {"time": 8054, "text": "And we get into not only, I think the first use of it naturally would be to ask your deep learning system to look at the cameras and produce the state, which is like the pose of my thing, for instance."}, {"time": 8068, "text": "But I think we've quickly found out that that's not always the right thing to do."}, {"time": 8075, "text": "Because what's the state of my shirt?"}, {"time": 8078, "text": "Imagine, I've always, Very noisy, you mean, or?"}, {"time": 8081, "text": "It's, if the first step of me trying to button my shirt is estimate the full state of my shirt, including like what's happening in the back here, whatever, whatever."}, {"time": 8091, "text": "That's just not the right specification."}, {"time": 8095, "text": "There are aspects of the state that are very important to the task."}, {"time": 8100, "text": "There are many that are unobservable and not important to the task."}, {"time": 8105, "text": "So you really need, it begs new questions about state representation."}, {"time": 8111, "text": "Another example that we've been playing with in lab has been just the idea of chopping onions, okay?"}, {"time": 8117, "text": "Or carrots, turns out to be better."}, {"time": 8120, "text": "So onions stink up the lab."}, {"time": 8122, "text": "And they're hard to see in a camera."}, {"time": 8126, "text": "But so, Details matter, yeah."}, {"time": 8128, "text": "Details matter, you know?"}, {"time": 8130, "text": "So if I'm moving around a particular object, right?"}, {"time": 8135, "text": "Then I think about, oh, it's got a position or an orientation in space."}, {"time": 8138, "text": "That's the description I want."}, {"time": 8139, "text": "Now, when I'm chopping an onion, okay?"}, {"time": 8142, "text": "Like the first chop comes down."}, {"time": 8144, "text": "I have now a hundred pieces of onion."}, {"time": 8148, "text": "Does my control system really need to understand the position and orientation and even the shape of the hundred pieces of onion in order to make a decision?"}, {"time": 8156, "text": "Probably not, you know?"}, {"time": 8156, "text": "And if I keep going, I'm just getting, more and more is my state space getting bigger as I cut?"}, {"time": 8164, "text": "It's not right."}, {"time": 8166, "text": "So somehow there's a, I think there's a richer idea of state."}, {"time": 8173, "text": "It's not the state that is given to us by Lagrangian mechanics."}, {"time": 8177, "text": "There is a proper Lagrangian state of the system, but the relevant state for this is some latent state is what we call it in machine learning."}, {"time": 8188, "text": "But, you know, there's some different state representation."}, {"time": 8192, "text": "Some compressed representation, some."}, {"time": 8195, "text": "And that's what I worry about saying compressed because it doesn't, I don't mind that it's low dimensional or not, but it has to be something that's easier to think about."}, {"time": 8206, "text": "By us humans."}, {"time": 8208, "text": "Or my algorithms."}, {"time": 8209, "text": "Or the algorithms being like control, optimal."}, {"time": 8213, "text": "So for instance, if the contact mechanics of all of those onion pieces and all the permutations of possible touches between those onion pieces, you know, you can give me a high dimensional state representation, I'm okay if it's linear."}, {"time": 8226, "text": "But if I have to think about all the possible shattering combinatorics of that, then my robot's gonna sit there thinking and the soup's gonna get cold or something."}, {"time": 8237, "text": "So since you taught the course, it kind of entered my mind, the idea of underactuated as really compelling to see the world in this kind of way."}, {"time": 8249, "text": "Do you ever, you know, if we talk about onions or you talk about the world with people in it in general, do you see the world as basically an underactuated system?"}, {"time": 8259, "text": "Do you like often look at the world in this way?"}, {"time": 8262, "text": "Or is this overreach?"}, {"time": 8267, "text": "Underactuated is a way of life, man."}, {"time": 8269, "text": "Exactly, I guess that's what I'm asking."}, {"time": 8273, "text": "I do think it's everywhere."}, {"time": 8274, "text": "I think in some places, we already have natural tools to deal with it."}, {"time": 8281, "text": "You know, it rears its head."}, {"time": 8282, "text": "I mean, in linear systems, it's not a problem."}, {"time": 8284, "text": "We just, like an underactuated linear system is really not sufficiently distinct from a fully actuated linear system."}, {"time": 8290, "text": "It's a subtle point about when that becomes a bottleneck in what we know how to do with control."}, {"time": 8297, "text": "It happens to be a bottleneck, although we've gotten incredibly good solutions now, but for a long time that I felt that that was the key bottleneck in legged robots."}, {"time": 8307, "text": "And roughly now the underactuated course is me trying to tell people everything I can about how to make Atlas do a backflip, right?"}, {"time": 8318, "text": "I have a second course now that I teach in the other semesters, which is on manipulation."}, {"time": 8323, "text": "And that's where we get into now more of the, that's a newer class."}, {"time": 8327, "text": "I'm hoping to put it online this fall completely."}, {"time": 8331, "text": "And that's gonna have much more aspects about these perception problems and the state representation questions, and then how do you do control."}, {"time": 8339, "text": "And the thing that's a little bit sad is that, for me at least, is there's a lot of manipulation tasks that people wanna do and should wanna do."}, {"time": 8349, "text": "They could start a company with it and be very successful that don't actually require you to think that much about underact, or dynamics at all even, but certainly underactuated dynamics."}, {"time": 8360, "text": "Once I have, if I reach out and grab something, if I can sort of assume it's rigidly attached to my hand, then I can do a lot of interesting, meaningful things with it without really ever thinking about the dynamics of that object."}, {"time": 8372, "text": "So we've built systems that kind of reduce the need for that."}, {"time": 8377, "text": "Enveloping grasps and the like."}, {"time": 8380, "text": "But I think the really good problems in manipulation."}, {"time": 8383, "text": "So manipulation, by the way, is more than just pick and place."}, {"time": 8388, "text": "That's like a lot of people think of that, just grasping."}, {"time": 8391, "text": "I don't mean that."}, {"time": 8392, "text": "I mean buttoning my shirt, I mean tying shoelaces."}, {"time": 8396, "text": "How do you program a robot to tie shoelaces?"}, {"time": 8399, "text": "And not just one shoe, but every shoe, right?"}, {"time": 8402, "text": "That's a really good problem."}, {"time": 8405, "text": "It's tempting to write down like the infinite dimensional state of the laces, that's probably not needed to write a good controller."}, {"time": 8415, "text": "I know we could hand design a controller that would do it, but I don't want that."}, {"time": 8419, "text": "I want to understand the principles that would allow me to solve another problem that's kind of like that."}, {"time": 8425, "text": "But I think if we can stay pure in our approach, then the challenge of tying anybody's shoes is a great challenge."}, {"time": 8436, "text": "That's a great challenge."}, {"time": 8437, "text": "I mean, and the soft touch comes into play there."}, {"time": 8443, "text": "Let me ask another ridiculous question on this topic."}, {"time": 8447, "text": "How important is touch?"}, {"time": 8449, "text": "We haven't talked much about humans, but I have this argument with my dad where like I think you can fall in love with a robot based on language alone."}, {"time": 8462, "text": "And he believes that touch is essential."}, {"time": 8466, "text": "Touch and smell, he says."}, {"time": 8467, "text": "But so in terms of robots, connecting with humans, we can go philosophical in terms of like a deep, meaningful connection, like love, but even just like collaborating in an interesting way, how important is touch like from an engineering perspective and a philosophical one?"}, {"time": 8492, "text": "I think it's super important."}, {"time": 8495, "text": "Even just in a practical sense, if we forget about the emotional part of it."}, {"time": 8500, "text": "But for robots to interact safely while they're doing meaningful mechanical work in the close contact with or vicinity of people that need help, I think we have to have them, we have to build them differently."}, {"time": 8517, "text": "They have to be afraid, not afraid of touching the world."}, {"time": 8519, "text": "So I think Baymax is just awesome."}, {"time": 8522, "text": "That's just like the movie of Big Hero 6 and the concept of Baymax, that's just awesome."}, {"time": 8528, "text": "I think we should, and we have some folks at Toyota that are trying to, Toyota Research that are trying to build Baymax roughly."}, {"time": 8536, "text": "And I think it's just a fantastically good project."}, {"time": 8541, "text": "I think it will change the way people physically interact."}, {"time": 8545, "text": "The same way, I mean, you gave a couple examples earlier, but if the robot that was walking around my home looked more like a teddy bear and a little less like the Terminator, that could change completely the way people perceive it and interact with it."}, {"time": 8559, "text": "And maybe they'll even wanna teach it, like you said, right?"}, {"time": 8564, "text": "You could not quite gamify it, but somehow instead of people judging it and looking at it as if it's not doing as well as a human, they're gonna try to help out the cute teddy bear, right?"}, {"time": 8577, "text": "Who knows, but I think we're building robots wrong and being more soft and more contact is important, right?"}, {"time": 8587, "text": "Yeah, I mean, like all the magical moments I can remember with robots, well, first of all, just visiting your lab and seeing Atlas, but also Spotmini, when I first saw Spotmini in person and hung out with him, her, it, I don't have trouble engendering robots."}, {"time": 8608, "text": "I feel the robotics people really say, oh, is it it?"}, {"time": 8611, "text": "I kinda like the idea that it's a her or a him."}, {"time": 8615, "text": "There's a magical moment, but there's no touching."}, {"time": 8618, "text": "I guess the question I have, have you ever been, like, have you had a human robot experience where a robot touched you?"}, {"time": 8629, "text": "And like, it was like, wait, like, was there a moment that you've forgotten that a robot is a robot and like, the anthropomorphization stepped in and for a second you forgot that it's not human?"}, {"time": 8644, "text": "I mean, I think when you're in on the details, then we, of course, anthropomorphized our work with Atlas, but in verbal communication and the like, I think we were pretty aware of it as a machine that needed to be respected."}, {"time": 8661, "text": "And I actually, I worry more about the smaller robots that could still move quickly if programmed wrong and we have to be careful actually about safety and the like right now."}, {"time": 8673, "text": "And that, if we build our robots correctly, I think then those, a lot of those concerns could go away."}, {"time": 8680, "text": "And we're seeing that trend."}, {"time": 8681, "text": "We're seeing the lower cost, lighter weight arms now that could be fundamentally safe."}, {"time": 8686, "text": "I mean, I do think touch is so fundamental."}, {"time": 8689, "text": "Ted Adelson is great."}, {"time": 8691, "text": "He's a perceptual scientist at MIT and he studied vision most of his life."}, {"time": 8698, "text": "And he said, when I had kids, I expected to be fascinated by their perceptual development."}, {"time": 8706, "text": "But what really, what he noticed was, felt more impressive, more dominant was the way that they would touch everything and lick everything."}, {"time": 8713, "text": "And pick things up, stick it on their tongue and whatever."}, {"time": 8716, "text": "And he said, watching his daughter convinced him that actually he needed to study tactile sensing more."}, {"time": 8725, "text": "So there's something very important."}, {"time": 8730, "text": "I think it's a little bit also of the passive versus active part of the world, right?"}, {"time": 8735, "text": "You can passively perceive the world."}, {"time": 8738, "text": "But it's fundamentally different if you can do an experiment and if you can change the world and you can learn a lot more than a passive observer."}, {"time": 8747, "text": "So you can in dialogue, that was your initial example, you could have an active experiment exchange."}, {"time": 8754, "text": "But I think if you're just a camera watching YouTube, I think that's a very different problem than if you're a robot that can apply force."}, {"time": 8763, "text": "And I think that's a very different problem than if you're a robot that can apply force and touch."}, {"time": 8775, "text": "Yeah, I think it's just an exciting area of research."}, {"time": 8778, "text": "I think you're probably right that this hasn't been under researched."}, {"time": 8783, "text": "To me as a person who's captivated by the idea of human robot interaction, it feels like such a rich opportunity to explore touch."}, {"time": 8794, "text": "Not even from a safety perspective, but like you said, the emotional too."}, {"time": 8798, "text": "I mean, safety comes first, but the next step is like a real human connection."}, {"time": 8808, "text": "Even in the industrial setting, it just feels like it's nice for the robot."}, {"time": 8815, "text": "I don't know, you might disagree with this, but because I think it's important to see robots as tools often, but I don't know, I think they're just always going to be more effective once you humanize them."}, {"time": 8831, "text": "Like it's convenient now to think of them as tools because we want to focus on the safety, but I think ultimately to create like a good experience for the worker, for the person, there has to be a human element."}, {"time": 8847, "text": "I don't know, for me, it feels like an industrial robotic arm would be better if it has a human element."}, {"time": 8854, "text": "I think like Rethink Robotics had that idea with the Baxter and having eyes and so on, having, I don't know, I'm a big believer in that."}, {"time": 8865, "text": "It's not my area, but I am also a big believer."}, {"time": 8869, "text": "Do you have an emotional connection to Atlas?"}, {"time": 8871, "text": "Like do you miss him?"}, {"time": 8874, "text": "I mean, yes, I don't know if I more so than if I had a different science project that I'd worked on super hard, right?"}, {"time": 8883, "text": "But yeah, I mean, the robot, we basically had to do heart surgery on the robot in the final competition because we melted the core."}, {"time": 8898, "text": "Yeah, there was something about watching that robot hanging there."}, {"time": 8900, "text": "We know we had to compete with it in an hour and it was getting its guts ripped out."}, {"time": 8905, "text": "Those are all historic moments."}, {"time": 8907, "text": "I think if you look back like a hundred years from now, yeah, I think those are important moments in robotics."}, {"time": 8915, "text": "I mean, these are the early days."}, {"time": 8916, "text": "You look at like the early days of a lot of scientific disciplines."}, {"time": 8919, "text": "They look ridiculous, they're full of failure, but it feels like robotics will be important in the coming a hundred years."}, {"time": 8928, "text": "And these are the early days."}, {"time": 8930, "text": "So I think a lot of people are, look at a brilliant person such as yourself and are curious about the intellectual journey they've took."}, {"time": 8941, "text": "Is there maybe three books, technical, fiction, philosophical that had a big impact on your life that you would recommend perhaps others reading?"}, {"time": 8955, "text": "Yeah, so I actually didn't read that much as a kid, but I read fairly voraciously now."}, {"time": 8961, "text": "There are some recent books that if you're interested in this kind of topic, like AI Superpowers by Kai Fu Lee is just a fantastic read."}, {"time": 8971, "text": "You must read that."}, {"time": 8975, "text": "Yuval Harari is just, I think that can open your mind."}, {"time": 8980, "text": "Sapiens."}, {"time": 8981, "text": "Sapiens is the first one, Homo Deus is the second, yeah."}, {"time": 8986, "text": "We mentioned it in the book, Homo Deus is the second, yeah."}, {"time": 8991, "text": "We mentioned The Black Swan by Taleb."}, {"time": 8993, "text": "I think that's a good sort of mind opener."}, {"time": 8997, "text": "I actually, so there's maybe a more controversial recommendation I could give."}, {"time": 9006, "text": "Great, we love controversy."}, {"time": 9008, "text": "In some sense, it's so classical it might surprise you, but I actually recently read Mortimer Adler's How to Read a Book, not so long, it was a while ago, but some people hate that book."}, {"time": 9023, "text": "I loved it."}, {"time": 9024, "text": "I think we're in this time right now where, boy, we're just inundated with research papers that you could read on archive with limited peer review and just this wealth of information."}, {"time": 9071, "text": "I think that was really, I read it at the right time where I was just feeling just overwhelmed with really low quality stuff, I guess."}, {"time": 9083, "text": "And similarly, I'm just giving more than three now, I'm sorry if I've exceeded my quota."}, {"time": 9091, "text": "But on that topic just real quick is, so basically finding a few companions to keep for the rest of your life in terms of papers and books and so on and those are the ones, like not doing, what is it, FOMO, fear of missing out, constantly trying to update yourself, but really deeply making a life journey of studying a particular paper, essentially, set of papers."}, {"time": 9148, "text": "But Adler says, no, no, a really good book is a dialogue between you and the author and it crosses time and space and I don't know, I think it's a very romantic, there's a bunch of like specific advice, which you can just gloss over, but the romantic view of how to read and really appreciate it is so good."}, {"time": 9172, "text": "And similarly, teaching, yeah, I thought a lot about teaching and so Isaac Asimov, great science fiction writer, has also actually spent a lot of his career writing nonfiction, right?"}, {"time": 9187, "text": "His memoir is fantastic."}, {"time": 9189, "text": "He was passionate about explaining things, right?"}, {"time": 9192, "text": "He wrote all kinds of books on all kinds of topics in science."}, {"time": 9196, "text": "He was known as the great explainer and I do really resonate with his style and just his way of talking about, by communicating and explaining to something is really the way that you learn something."}, {"time": 9212, "text": "I think about problems very differently because of the way I've been given the opportunity to teach them at MIT."}, {"time": 9222, "text": "We have questions asked, the fear of the lecture, the experience of the lecture and the questions I get and the interactions just forces me to be rock solid on these ideas in a way that if I didn't have that, I don't know, I would be in a different intellectual space."}, {"time": 9238, "text": "Also, video, does that scare you that your lectures are online and people like me in sweatpants can sit sipping coffee and watch you give lectures?"}, {"time": 9248, "text": "I think it's great."}, {"time": 9249, "text": "I do think that something's changed right now, which is, right now we're giving lectures over Zoom."}, {"time": 9256, "text": "I mean, giving seminars over Zoom and everything."}, {"time": 9261, "text": "I'm trying to figure out, I think it's a new medium."}, {"time": 9264, "text": "I'm trying to figure out how to exploit it."}, {"time": 9268, "text": "Yeah, I've been quite cynical about human to human connection over that medium, but I think that's because it hasn't been explored fully and teaching is a different thing."}, {"time": 9285, "text": "Every lecture is a, I'm sorry, every seminar even, I think every talk I give is an opportunity to give that differently."}, {"time": 9294, "text": "I can deliver content directly into your browser."}, {"time": 9297, "text": "You have a WebGL engine right there."}, {"time": 9300, "text": "I can throw 3D content into your browser while you're listening to me, right?"}, {"time": 9306, "text": "And I can assume that you have at least a powerful enough laptop or something to watch Zoom while I'm doing that, while I'm giving a lecture."}, {"time": 9315, "text": "That's a new communication tool that I didn't have last year, right?"}, {"time": 9319, "text": "And I think robotics can potentially benefit a lot from teaching that way."}, {"time": 9326, "text": "We'll see, it's gonna be an experiment this fall."}, {"time": 9329, "text": "I'm thinking a lot about it."}, {"time": 9330, "text": "Yeah, and also like the length of lectures or the length of like, there's something, so like I guarantee you, it's like 80% of people who started listening to our conversation are still listening to now, which is crazy to me."}, {"time": 9348, "text": "But so there's a patience and interest in long form content, but at the same time, there's a magic to forcing yourself to condense an idea to as short as possible."}, {"time": 9362, "text": "As short as possible, like clip, it can be a part of a longer thing, but like just like really beautifully condense an idea."}, {"time": 9369, "text": "There's a lot of opportunity there that's easier to do in remote with, I don't know, with editing too."}, {"time": 9379, "text": "Editing is an interesting thing."}, {"time": 9380, "text": "Like what, you know, most professors don't get, when they give a lecture, they don't get to go back and edit out parts, like crisp it up a little bit."}, {"time": 9391, "text": "That's also, it can do magic."}, {"time": 9394, "text": "Like if you remove like five to 10 minutes from an hour lecture, it can actually, it can make something special of a lecture."}, {"time": 9403, "text": "I've seen that in myself and in others too, because I edit other people's lectures to extract clips."}, {"time": 9410, "text": "It's like, there's certain tangents that are like, that lose, they're not interesting."}, {"time": 9414, "text": "They're mumbling, they're just not, they're not clarifying, they're not helpful at all."}, {"time": 9419, "text": "And once you remove them, it's just, I don't know."}, {"time": 9422, "text": "Editing can be magic."}, {"time": 9424, "text": "It takes a lot of time."}, {"time": 9425, "text": "Yeah, it takes, it depends like what is teaching, you have to ask."}, {"time": 9433, "text": "Cause I find the editing process is also beneficial as for teaching, but also for your own learning."}, {"time": 9441, "text": "I don't know if, have you watched yourself?"}, {"time": 9444, "text": "Have you watched those videos?"}, {"time": 9446, "text": "I mean, not all of them."}, {"time": 9447, "text": "It could be painful to see like how to improve."}, {"time": 9453, "text": "So do you find that, I know you segment your podcast."}, {"time": 9457, "text": "Do you think that helps people with the, the attention span aspect of it?"}, {"time": 9462, "text": "Or is it the segment like sections like, yeah, we're talking about this topic, whatever."}, {"time": 9466, "text": "Nope, nope, that just helps me."}, {"time": 9468, "text": "It's actually bad."}, {"time": 9469, "text": "So, and you've been incredible."}, {"time": 9473, "text": "So I'm learning, like I'm afraid of conversation."}, {"time": 9476, "text": "This is even today, I'm terrified of talking to you."}, {"time": 9479, "text": "I mean, it's something I'm trying to remove for myself."}, {"time": 9484, "text": "There's a guy, I mean, I've learned from a lot of people, but really there's been a few people who's been inspirational to me in terms of conversation."}, {"time": 9494, "text": "Whatever people think of him, Joe Rogan has been inspirational to me because comedians have been too."}, {"time": 9500, "text": "Being able to just have fun and enjoy themselves and lose themselves in conversation that requires you to be a great storyteller, to be able to pull a lot of different pieces of information together."}, {"time": 9512, "text": "But mostly just to enjoy yourself in conversations."}, {"time": 9516, "text": "And I'm trying to learn that."}, {"time": 9518, "text": "These notes are, you see me looking down."}, {"time": 9521, "text": "That's like a safety blanket that I'm trying to let go of more and more."}, {"time": 9526, "text": "So that's, people love just regular conversation."}, {"time": 9529, "text": "That's what they, the structure is like, whatever."}, {"time": 9532, "text": "I would say, I would say maybe like 10 to like, so there's a bunch of, you know, there's probably a couple of thousand PhD students listening to this right now, right?"}, {"time": 9546, "text": "And they might know what we're talking about."}, {"time": 9549, "text": "But there is somebody, I guarantee you right now, in Russia, some kid who's just like, who's just smoked some weed, is sitting back and just enjoying the hell out of this conversation."}, {"time": 9562, "text": "Not really understanding."}, {"time": 9563, "text": "He kind of watched some Boston Dynamics videos."}, {"time": 9565, "text": "He's just enjoying it."}, {"time": 9567, "text": "And I salute you, sir."}, {"time": 9569, "text": "No, but just like, there's so much variety of people that just have curiosity about engineering, about sciences, about mathematics."}, {"time": 9577, "text": "And also like, I should, I mean, enjoying it is one thing, but also often notice it inspires people to, there's a lot of people who are like in their undergraduate studies trying to figure out what, trying to figure out what to pursue."}, {"time": 9596, "text": "And these conversations can really spark the direction of their life."}, {"time": 9601, "text": "And in terms of robotics, I hope it does, because I'm excited about the possibilities of what robotics brings."}, {"time": 9607, "text": "On that topic, do you have advice?"}, {"time": 9612, "text": "Like what advice would you give to a young person about life?"}, {"time": 9618, "text": "A young person about life or a young person about life in robotics?"}, {"time": 9623, "text": "It could be in robotics."}, {"time": 9624, "text": "Robotics, it could be in life in general."}, {"time": 9626, "text": "It could be career."}, {"time": 9628, "text": "It could be a relationship advice."}, {"time": 9631, "text": "It could be running advice."}, {"time": 9632, "text": "Just like they're, that's one of the things I see, like we talked to like 20 year olds."}, {"time": 9638, "text": "They're like, how do I do this thing?"}, {"time": 9642, "text": "What do I do?"}, {"time": 9645, "text": "If they come up to you, what would you tell them?"}, {"time": 9648, "text": "I think it's an interesting time to be a kid these days."}, {"time": 9653, "text": "Everything points to this being sort of a winner, take all economy and the like."}, {"time": 9659, "text": "I think the people that will really excel in my opinion are going to be the ones that can think deeply about problems."}, {"time": 9671, "text": "You have to be able to ask questions agilely and use the internet for everything it's good for and stuff like this."}, {"time": 9676, "text": "And I think a lot of people will develop those skills."}, {"time": 9679, "text": "I think the leaders, thought leaders, robotics leaders, whatever, are gonna be the ones that can do more and they can think very deeply and critically."}, {"time": 9692, "text": "And that's a harder thing to learn."}, {"time": 9695, "text": "I think one path to learning that is through mathematics, through engineering."}, {"time": 9701, "text": "I would encourage people to start math early."}, {"time": 9704, "text": "I mean, I didn't really start."}, {"time": 9706, "text": "I mean, I was always in the better math classes that I could take, but I wasn't pursuing super advanced mathematics or anything like that until I got to MIT."}, {"time": 9716, "text": "I think MIT lit me up and really started the life that I'm living now."}, {"time": 9725, "text": "But yeah, I really want kids to dig deep, really understand things, building things too."}, {"time": 9732, "text": "I mean, pull things apart, put them back together."}, {"time": 9735, "text": "Like that's just such a good way to really understand things and expect it to be a long journey, right?"}, {"time": 9743, "text": "It's, you don't have to know everything."}, {"time": 9747, "text": "You're never gonna know everything."}, {"time": 9749, "text": "So think deeply and stick with it."}, {"time": 9752, "text": "Enjoy the ride, but just make sure you're not, yeah, just make sure you're stopping to think about why things work."}, {"time": 9763, "text": "And it's true, it's easy to lose yourself in the distractions of the world."}, {"time": 9771, "text": "We're overwhelmed with content right now, but you have to stop and pick some of it and really understand it."}, {"time": 9778, "text": "Yeah, on the book point, I've read Animal Farm by George Orwell a ridiculous number of times."}, {"time": 9786, "text": "So for me, like that book, I don't know if it's a good book in general, but for me it connects deeply somehow."}, {"time": 9793, "text": "It somehow connects, so I was born in the Soviet Union."}, {"time": 9798, "text": "So it connects to me into the entirety of the history of the Soviet Union and to World War II and to the love and hatred and suffering that went on there and the corrupting nature of power and greed and just somehow I just, that book has taught me more about life than like anything else."}, {"time": 9819, "text": "Even though it's just like a silly childlike book about pigs, I don't know why, it just connects and inspires."}, {"time": 9829, "text": "The same, there's a few technical books too and algorithms that just, yeah, you return to often."}, {"time": 9841, "text": "Yeah, there's, and I've been losing that because of the internet."}, {"time": 9845, "text": "I've been like going on, I've been going on archive and blog posts and GitHub and the new thing and you lose your ability to really master an idea."}]}, {"title": "Max Tegmark: AI and Physics | Lex Fridman Podcast #155", "id": "RL4j4KPwNGM", "quotes": [{"time": 376, "text": "No, we figured out Newton's laws of gravitation and other things and got a really deep fundamental understanding."}, {"time": 386, "text": "And that's what gives us such confidence in rockets."}, {"time": 390, "text": "And my vision is that in the future, all machine learning systems that actually have impact on people's lives will be understood at a really, really deep level."}, {"time": 403, "text": "So we trust them, not because some sales rep told us to, but because they've earned our trust."}, {"time": 410, "text": "And really safety critical things even prove that they will always do what we expect them to do."}, {"time": 415, "text": "That's very much the physics mindset."}, {"time": 417, "text": "So it's interesting, if you look at big breakthroughs that have happened in machine learning this year, from dancing robots, it's pretty fantastic."}, {"time": 428, "text": "Not just because it's cool, but if you just think about not that many years ago, this YouTube video at this DARPA challenge with the MIT robot comes out of the car and face plants."}, {"time": 440, "text": "How far we've come in just a few years."}, {"time": 443, "text": "Similarly, Alpha Fold 2, crushing the protein folding problem."}, {"time": 451, "text": "We can talk more about implications for medical research and stuff."}, {"time": 454, "text": "But hey, that's huge progress."}, {"time": 459, "text": "You can look at the GPT3 that can spout off English text, which sometimes really, really blows you away."}, {"time": 468, "text": "You can look at DeepMind's MuZero, which doesn't just kick our butt in Go and Chess and Shogi, but also in all these Atari games."}, {"time": 479, "text": "And you don't even have to teach it the rules now."}, {"time": 482, "text": "What all of those have in common is, besides being powerful, is we don't fully understand how they work."}, {"time": 490, "text": "And that's fine if it's just some dancing robots."}, {"time": 493, "text": "And the worst thing that can happen is they face plant."}, {"time": 496, "text": "Or if they're playing Go, and the worst thing that can happen is that they make a bad move and lose the game."}, {"time": 502, "text": "It's less fine if that's what's controlling your self driving car or your nuclear power plant."}, {"time": 509, "text": "And we've seen already that even though Hollywood had all these movies where they try to make us worry about the wrong things, like machines turning evil, the actual bad things that have happened with automation have not been machines turning evil."}, {"time": 525, "text": "They've been caused by overtrust in things we didn't understand as well as we thought we did."}, {"time": 531, "text": "Even very simple automated systems like what Boeing put into the 737 MAX killed a lot of people."}, {"time": 540, "text": "Was it that that little simple system was evil?"}, {"time": 543, "text": "But we didn't understand it as well as we should have."}, {"time": 547, "text": "And we trusted without understanding."}, {"time": 551, "text": "That's the overtrust."}, {"time": 552, "text": "We didn't even understand that we didn't understand."}, {"time": 555, "text": "The humility is really at the core of being a scientist."}, {"time": 559, "text": "I think step one, if you want to be a scientist, is don't ever fool yourself into thinking you understand things when you actually don't."}, {"time": 567, "text": "That's probably good advice for humans in general."}, {"time": 569, "text": "I think humility in general can do us good."}, {"time": 571, "text": "But in science, it's so spectacular."}, {"time": 573, "text": "Why did we have the wrong theory of gravity ever from Aristotle onward until Galileo's time?"}, {"time": 580, "text": "Why would we believe something so dumb as that if I throw this water bottle, it's going to go up with constant speed until it realizes that its natural motion is down?"}, {"time": 589, "text": "It changes its mind."}, {"time": 591, "text": "Because people just kind of assumed Aristotle was right."}, {"time": 595, "text": "He's an authority."}, {"time": 596, "text": "We understand that."}, {"time": 597, "text": "Why did we believe things like that the sun is going around the Earth?"}, {"time": 601, "text": "Why did we believe that time flows at the same rate for everyone until Einstein?"}, {"time": 606, "text": "Same exact mistake over and over again."}, {"time": 608, "text": "We just weren't humble enough to acknowledge that we actually didn't know for sure."}, {"time": 613, "text": "We assumed we knew."}, {"time": 615, "text": "So we didn't discover the truth because we assumed there was nothing there to be discovered, right?"}, {"time": 620, "text": "There was something to be discovered about the 737 Max."}, {"time": 624, "text": "And if you had been a bit more suspicious and tested it better, we would have found it."}, {"time": 628, "text": "And it's the same thing with most harm that's been done by automation so far, I would say."}, {"time": 633, "text": "So I don't know if you heard here of a company called Knight Capital?"}, {"time": 638, "text": "That means you didn't invest in them earlier."}, {"time": 642, "text": "They deployed this automated trading system, all nice and shiny."}, {"time": 647, "text": "They didn't understand it as well as they thought."}, {"time": 649, "text": "And it went about losing $10 million per minute for 44 minutes straight until someone presumably was like, oh, no, shut this up."}, {"time": 659, "text": "Was it evil?"}, {"time": 661, "text": "It was, again, misplaced trust, something they didn't fully understand, right?"}, {"time": 665, "text": "And there have been so many, even when people have been killed by robots, which is quite rare still, but in factory accidents, it's in every single case been not malice, just that the robot didn't understand that a human is different from an auto part or whatever."}, {"time": 684, "text": "So this is why I think there's so much opportunity for a physics approach, where you just aim for a higher level of understanding."}, {"time": 693, "text": "And if you look at all these systems that we talked about from reinforcement learning systems and dancing robots to all these neural networks that power GPT3 and go playing software and stuff, they're all basically black boxes, not so different from if you teach a human something, you have no idea how their brain works, right?"}, {"time": 718, "text": "Except the human brain, at least, has been error corrected during many, many centuries of evolution in a way that some of these systems have not, right?"}, {"time": 727, "text": "And my MIT research is entirely focused on demystifying this black box, intelligible intelligence is my slogan."}, {"time": 735, "text": "That's a good line, intelligible intelligence."}, {"time": 738, "text": "Yeah, that we shouldn't settle for something that seems intelligent, but it should be intelligible so that we actually trust it because we understand it, right?"}, {"time": 746, "text": "Like, again, Elon trusts his rockets because he understands Newton's laws and thrust and how everything works."}, {"time": 753, "text": "And can I tell you why I'm optimistic about this?"}, {"time": 757, "text": "I think we've made a bit of a mistake where some people still think that somehow we're never going to understand neural networks."}, {"time": 767, "text": "We're just going to have to learn to live with this."}, {"time": 769, "text": "It's this very powerful black box."}, {"time": 772, "text": "Basically, for those who haven't spent time building their own, it's super simple what happens inside."}, {"time": 779, "text": "You send in a long list of numbers, and then you do a bunch of operations on them, multiply by matrices, et cetera, et cetera, and some other numbers come out that's output of it."}, {"time": 789, "text": "And then there are a bunch of knobs you can tune."}, {"time": 793, "text": "And when you change them, it affects the computation, the input output relation."}, {"time": 798, "text": "And then you just give the computer some definition of good, and it keeps optimizing these knobs until it performs as good as possible."}, {"time": 804, "text": "And often, you go like, wow, that's really good."}, {"time": 807, "text": "This robot can dance, or this machine is beating me at chess now."}, {"time": 811, "text": "And in the end, you have something which, even though you can look inside it, you have very little idea of how it works."}, {"time": 818, "text": "You can print out tables of all the millions of parameters in there."}, {"time": 823, "text": "Is it crystal clear now how it's working?"}, {"time": 826, "text": "Many of my colleagues seem willing to settle for that."}, {"time": 829, "text": "And I'm like, no, that's like the halfway point."}, {"time": 834, "text": "Some have even gone as far as sort of guessing that the mistrutability of this is where some of the power comes from, and some sort of mysticism."}, {"time": 845, "text": "I think that's total nonsense."}, {"time": 846, "text": "I think the real power of neural networks comes not from inscrutability, but from differentiability."}, {"time": 855, "text": "And what I mean by that is simply that the output changes only smoothly if you tweak your knobs."}, {"time": 863, "text": "And then you can use all these powerful methods we have for optimization in science."}, {"time": 868, "text": "We can just tweak them a little bit and see, did that get better or worse?"}, {"time": 871, "text": "That's the fundamental idea of machine learning, that the machine itself can keep optimizing until it gets better."}, {"time": 877, "text": "Suppose you wrote this algorithm instead in Python or some other programming language, and then what the knobs did was they just changed random letters in your code."}, {"time": 889, "text": "Now it would just epically fail."}, {"time": 891, "text": "You change one thing, and instead of saying print, it says, synth, syntax error."}, {"time": 896, "text": "You don't even know, was that for the better or for the worse, right?"}, {"time": 899, "text": "This, to me, is what I believe is the fundamental power of neural networks."}, {"time": 905, "text": "And just to clarify, the changing of the different letters in a program would not be a differentiable process."}, {"time": 910, "text": "It would make it an invalid program, typically."}, {"time": 913, "text": "And then you wouldn't even know if you changed more letters if it would make it work again, right?"}, {"time": 918, "text": "So that's the magic of neural networks, the inscrutability."}, {"time": 923, "text": "The differentiability, that every setting of the parameters is a program, and you can tell is it better or worse, right?"}, {"time": 931, "text": "So you don't like the poetry of the mystery of neural networks as the source of its power?"}, {"time": 935, "text": "I generally like poetry, but."}, {"time": 937, "text": "Not in this case."}, {"time": 939, "text": "It's so misleading."}, {"time": 940, "text": "And above all, it shortchanges us."}, {"time": 942, "text": "It makes us underestimate the good things we can accomplish."}, {"time": 947, "text": "So what we've been doing in my group is basically step one, train the mysterious neural network to do something well."}, {"time": 954, "text": "And then step two, do some additional AI techniques to see if we can now transform this black box into something equally intelligent that you can actually understand."}, {"time": 967, "text": "So for example, I'll give you one example, this AI Feynman project that we just published, right?"}, {"time": 971, "text": "So we took the 100 most famous or complicated equations from one of my favorite physics textbooks, in fact, the one that got me into physics in the first place, the Feynman lectures on physics."}, {"time": 985, "text": "And so you have a formula."}, {"time": 988, "text": "Maybe it has what goes into the formula as six different variables, and then what comes out as one."}, {"time": 995, "text": "So then you can make a giant Excel spreadsheet with seven columns."}, {"time": 999, "text": "You put in just random numbers for the six columns for those six input variables, and then you calculate with a formula the seventh column, the output."}, {"time": 1006, "text": "So maybe it's like the force equals in the last column some function of the other."}, {"time": 1011, "text": "And now the task is, OK, if I don't tell you what the formula was, can you figure that out from looking at my spreadsheet I gave you?"}, {"time": 1020, "text": "This problem is called symbolic regression."}, {"time": 1024, "text": "If I tell you that the formula is what we call a linear formula, so it's just that the output is sum of all the things, input, the times, some constants, that's the famous easy problem we can solve."}, {"time": 1038, "text": "We do it all the time in science and engineering."}, {"time": 1041, "text": "But the general one, if it's more complicated functions with logarithms or cosines or other math, it's a very, very hard one and probably impossible to do fast in general, just because the number of formulas with n symbols just grows exponentially, just like the number of passwords you can make grow dramatically with length."}, {"time": 1063, "text": "But we had this idea that if you first have a neural network that can actually approximate the formula, you just trained it, even if you don't understand how it works, that can be the first step towards actually understanding how it works."}, {"time": 1078, "text": "So that's what we do first."}, {"time": 1080, "text": "And then we study that neural network now and put in all sorts of other data that wasn't in the original training data and use that to discover simplifying properties of the formula."}, {"time": 1091, "text": "And that lets us break it apart, often into many simpler pieces in a kind of divide and conquer approach."}, {"time": 1097, "text": "So we were able to solve all of those 100 formulas, discover them automatically, plus a whole bunch of other ones."}, {"time": 1102, "text": "And it's actually kind of humbling to see that this code, which anyone who wants now is listening to this, can type pip install AI Feynman on the computer and run it."}, {"time": 1114, "text": "It can actually do what Johannes Kepler spent four years doing when he stared at Mars data until he was like, finally, Eureka, this is an ellipse."}, {"time": 1124, "text": "This will do it automatically for you in one hour."}, {"time": 1126, "text": "Or Max Planck, he was looking at how much radiation comes out from different wavelengths from a hot object and discovered the famous blackbody formula."}, {"time": 1137, "text": "This discovers it automatically."}, {"time": 1140, "text": "I'm actually excited about seeing if we can discover not just old formulas again, but new formulas that no one has seen before."}, {"time": 1152, "text": "I do like this process of using kind of a neural network to find some basic insights and then dissecting the neural network to then gain the final."}, {"time": 1161, "text": "So in that way, you've forcing the explainability issue, really trying to analyze the neural network for the things it knows in order to come up with the final beautiful, simple theory underlying the initial system that you were looking at."}, {"time": 1184, "text": "And the reason I'm so optimistic that it can be generalized to so much more is because that's exactly what we do as human scientists."}, {"time": 1193, "text": "Think of Galileo, whom we mentioned, right?"}, {"time": 1195, "text": "I bet when he was a little kid, if his dad threw him an apple, he would catch it."}, {"time": 1201, "text": "Because he had a neural network in his brain that he had trained to predict the parabolic orbit of apples that are thrown under gravity."}, {"time": 1209, "text": "If you throw a tennis ball to a dog, it also has this same ability of deep learning to figure out how the ball is going to move and catch it."}, {"time": 1218, "text": "But Galileo went one step further when he got older."}, {"time": 1221, "text": "He went back and was like, wait a minute."}, {"time": 1226, "text": "I can write down a formula for this."}, {"time": 1227, "text": "Y equals x squared, a parabola."}, {"time": 1231, "text": "And he helped revolutionize physics as we know it, right?"}, {"time": 1236, "text": "So there was a basic neural network in there from childhood that captured the experiences of observing different kinds of trajectories."}, {"time": 1246, "text": "And then he was able to go back in with another extra little neural network and analyze all those experiences and be like, wait a minute."}, {"time": 1254, "text": "There's a deeper rule here."}, {"time": 1256, "text": "He was able to distill out in symbolic form what that complicated black box neural network was doing."}, {"time": 1263, "text": "Not only did the formula he got ultimately become more accurate, and similarly, this is how Newton got Newton's laws, which is why Elon can send rockets to the space station now, right?"}, {"time": 1275, "text": "So it's not only more accurate, but it's also simpler, much simpler."}, {"time": 1280, "text": "And it's so simple that we can actually describe it to our friends and each other, right?"}, {"time": 1286, "text": "We've talked about it just in the context of physics now."}, {"time": 1288, "text": "But hey, isn't this what we're doing when we're talking to each other also?"}, {"time": 1293, "text": "We go around with our neural networks, just like dogs and cats and chipmunks and Blue Jays."}, {"time": 1298, "text": "And we experience things in the world."}, {"time": 1301, "text": "But then we humans do this additional step on top of that, where we then distill out certain high level knowledge that we've extracted from this in a way that we can communicate it to each other in a symbolic form in English in this case, right?"}, {"time": 1316, "text": "So if we can do it and we believe that we are information processing entities, then we should be able to make machine learning that does it also."}, {"time": 1327, "text": "Well, do you think the entire thing could be learning?"}, {"time": 1330, "text": "Because this dissection process, like for AI Feynman, the secondary stage feels like something like reasoning."}, {"time": 1339, "text": "And the initial step feels more like the more basic kind of differentiable learning."}, {"time": 1345, "text": "Do you think the whole thing could be differentiable learning?"}, {"time": 1348, "text": "Do you think the whole thing could be basically neural networks on top of each other?"}, {"time": 1352, "text": "It's like turtles all the way down."}, {"time": 1353, "text": "Could it be neural networks all the way down?"}, {"time": 1355, "text": "I mean, that's a really interesting question."}, {"time": 1357, "text": "We know that in your case, it is neural networks all the way down because that's all you have in your skull is a bunch of neurons doing their thing, right?"}, {"time": 1365, "text": "But if you ask the question more generally, what algorithms are being used in your brain, I think it's super interesting to compare."}, {"time": 1376, "text": "I think we've gone a little bit backwards historically because we humans first discovered good old fashioned AI, the logic based AI that we often call GoFi for good old fashioned AI."}, {"time": 1389, "text": "And then more recently, we did machine learning because it required bigger computers."}, {"time": 1394, "text": "So we had to discover it later."}, {"time": 1395, "text": "So we think of machine learning with neural networks as the modern thing and the logic based AI as the old fashioned thing."}, {"time": 1404, "text": "But if you look at evolution on Earth, it's actually been the other way around."}, {"time": 1409, "text": "I would say that, for example, an eagle has a better vision system than I have using."}, {"time": 1418, "text": "And dogs are just as good at casting tennis balls as I am."}, {"time": 1422, "text": "All this stuff which is done by training in neural network and not interpreting it in words is something so many of our animal friends can do, at least as well as us, right?"}, {"time": 1433, "text": "What is it that we humans can do that the chipmunks and the eagles cannot?"}, {"time": 1438, "text": "It's more to do with this logic based stuff, right, where we can extract out information in symbols, in language, and now even with equations if you're a scientist, right?"}, {"time": 1452, "text": "So basically what happened was first we built these computers that could multiply numbers real fast and manipulate symbols."}, {"time": 1458, "text": "And we felt they were pretty dumb."}, {"time": 1460, "text": "And then we made neural networks that can see as well as a cat can and do a lot of this inscrutable black box neural networks."}, {"time": 1470, "text": "What we humans can do also is put the two together in a useful way."}, {"time": 1474, "text": "Yes, in our own brain."}, {"time": 1477, "text": "So if we ever want to get artificial general intelligence that can do all jobs as well as humans can, right, then that's what's going to be required to be able to combine the neural networks with symbolic, combine the old AI with the new AI in a good way."}, {"time": 1495, "text": "We do it in our brains."}, {"time": 1497, "text": "And there seems to be basically two strategies I see in industry now."}, {"time": 1501, "text": "One scares the heebie jeebies out of me, and the other one I find much more encouraging."}, {"time": 1505, "text": "OK, which one?"}, {"time": 1507, "text": "Can we break them apart?"}, {"time": 1508, "text": "Which of the two?"}, {"time": 1509, "text": "The one that scares the heebie jeebies out of me is this attitude that we're just going to make ever bigger systems that we still don't understand until they can be as smart as humans."}, {"time": 1522, "text": "I think it's just such a reckless thing to do."}, {"time": 1524, "text": "And unfortunately, if we actually succeed as a species to build artificial general intelligence, then we still have no clue how it works."}, {"time": 1531, "text": "I think at least 50% chance we're going to be extinct before too long."}, {"time": 1537, "text": "It's just going to be an utter epic own goal."}, {"time": 1540, "text": "So it's that 44 minute losing money problem or the paper clip problem where we don't understand how it works, and it just in a matter of seconds runs away in some kind of direction that's going to be very problematic."}, {"time": 1554, "text": "Even long before, you have to worry about the machines themselves somehow deciding to do things."}, {"time": 1561, "text": "And to us, we have to worry about people using machines that are short of AGI and power to do bad things."}, {"time": 1569, "text": "I mean, just take a moment."}, {"time": 1573, "text": "And if anyone is not worried particularly about advanced AI, just take 10 seconds and just think about your least favorite leader on the planet right now."}, {"time": 1583, "text": "Don't tell me who it is."}, {"time": 1585, "text": "I want to keep this apolitical."}, {"time": 1586, "text": "But just see the face in front of you, that person, for 10 seconds."}, {"time": 1590, "text": "Now imagine that that person has this incredibly powerful AI under their control and can use it to impose their will on the whole planet."}, {"time": 1604, "text": "So can we break that apart just briefly?"}, {"time": 1609, "text": "For the 50% chance that we'll run to trouble with this approach, do you see the bigger worry in that leader or humans using the system to do damage?"}, {"time": 1620, "text": "Or are you more worried, and I think I'm in this camp, more worried about accidental, unintentional destruction of everything?"}, {"time": 1630, "text": "So humans trying to do good, and in a way where everyone agrees it's kind of good, it's just they're trying to do good without understanding."}, {"time": 1640, "text": "Because I think every evil leader in history thought they're, to some degree, thought they're trying to do good."}, {"time": 1645, "text": "I'm sure Hitler thought he was doing good."}, {"time": 1649, "text": "I've been reading a lot about Stalin."}, {"time": 1651, "text": "I'm sure Stalin is from, he legitimately thought that communism was good for the world, and that he was doing good."}, {"time": 1657, "text": "I think Mao Zedong thought what he was doing with the Great Leap Forward was good too."}, {"time": 1662, "text": "I'm actually concerned about both of those."}, {"time": 1665, "text": "Before, I promised to answer this in detail, but before we do that, let me finish answering the first question."}, {"time": 1671, "text": "Because I told you that there were two different routes we could get to artificial general intelligence, and one scares the hell out of me, which is this one where we build something, we just say bigger neural networks, ever more hardware, and just train the heck out of more data, and poof, now it's very powerful."}, {"time": 1687, "text": "That, I think, is the most unsafe and reckless approach."}, {"time": 1724, "text": "Maybe we can even prove theorems about it, that this car here will never be hacked when it's driving, because here is the proof."}, {"time": 1733, "text": "There is a whole science of this."}, {"time": 1735, "text": "It doesn't work for neural networks that are big black boxes, but it works well and works with certain other kinds of codes, right?"}, {"time": 1742, "text": "That approach, I think, is much more promising."}, {"time": 1745, "text": "That's exactly why I'm working on it, frankly, not just because I think it's cool for science, but because I think the more we understand these systems, the better the chances that we can make them do the things that are good for us that are actually intended, not unintended."}, {"time": 1761, "text": "So you think it's possible to prove things about something as complicated as a neural network?"}, {"time": 1767, "text": "That's the hope?"}, {"time": 1768, "text": "Well, ideally, there's no reason it has to be a neural network in the end either, right?"}, {"time": 1774, "text": "We discovered Newton's laws of gravity with neural network in Newton's head."}, {"time": 1780, "text": "But that's not the way it's programmed into the navigation system of Elon Musk's rocket anymore."}, {"time": 1786, "text": "It's written in C++, or I don't know what language he uses exactly."}, {"time": 1791, "text": "And then there are software tools called symbolic verification."}, {"time": 1794, "text": "DARPA and the US military has done a lot of really great research on this, because they really want to understand that when they build weapon systems, they don't just go fire at random or malfunction, right?"}, {"time": 1807, "text": "And there is even a whole operating system called Cell 3 that's been developed by a DARPA grant, where you can actually mathematically prove that this thing can never be hacked."}, {"time": 1820, "text": "One day, I hope that will be something you can say about the OS that's running on our laptops too."}, {"time": 1825, "text": "As you know, we're not there."}, {"time": 1827, "text": "But I think we should be ambitious, frankly."}, {"time": 1830, "text": "And if we can use machine learning to help do the proofs and so on as well, then it's much easier to verify that a proof is correct than to come up with a proof in the first place."}, {"time": 1842, "text": "That's really the core idea here."}, {"time": 1845, "text": "If someone comes on your podcast and says they proved the Riemann hypothesis or some sensational new theorem, it's much easier for someone else, take some smart grad, math grad students to check, oh, there's an error here on equation five, or this really checks out, than it was to discover the proof."}, {"time": 1867, "text": "Yeah, although some of those proofs are pretty complicated."}, {"time": 1869, "text": "But yes, it's still nevertheless much easier to verify the proof."}, {"time": 1874, "text": "We kind of, even with the security of systems, there's a kind of cynicism that pervades people who think about this, which is like, oh, it's hopeless."}, {"time": 1884, "text": "I mean, in the same sense, exactly like you're saying when you own networks, oh, it's hopeless to understand what's happening."}, {"time": 1890, "text": "With security, people are just like, well, it's always going, there's always going to be attack vectors, like ways to attack the system."}, {"time": 1900, "text": "But you're right, we're just very new with these computational systems."}, {"time": 1904, "text": "We're new with these intelligent systems."}, {"time": 1906, "text": "And it's not out of the realm of possibly, just like people that understand the movement of the stars and the planets and so on."}, {"time": 1914, "text": "It's entirely possible that within, hopefully soon, but it could be within 100 years, we start to have an obvious laws of gravity about intelligence and God forbid about consciousness too."}, {"time": 1929, "text": "That one is..."}, {"time": 1932, "text": "I think, of course, if you're selling computers that get hacked a lot, that's in your interest as a company that people think it's impossible to make it safe, but he's going to get the idea of suing you."}, {"time": 1941, "text": "I want to really inject optimism here."}, {"time": 1944, "text": "It's absolutely possible to do much better than we're doing now."}, {"time": 1950, "text": "And your laptop does so much stuff."}, {"time": 1954, "text": "You don't need the music player to be super safe in your future self driving car, right?"}, {"time": 1962, "text": "If someone hacks it and starts playing music you don't like, the world won't end."}, {"time": 1967, "text": "But what you can do is you can break out and say that your drive computer that controls your safety must be completely physically decoupled entirely from the entertainment system."}, {"time": 1977, "text": "And it must physically be such that it can't take on over the air updates while you're driving."}, {"time": 1983, "text": "And it can have ultimately some operating system on it which is symbolically verified and proven that it's always going to do what it's supposed to do, right?"}, {"time": 1997, "text": "We can basically have, and companies should take that attitude too."}, {"time": 2000, "text": "They should look at everything they do and say what are the few systems in our company that threaten the whole life of the company if they get hacked and have the highest standards for them."}, {"time": 2011, "text": "And then they can save money by going for the el cheapo poorly understood stuff for the rest."}, {"time": 2016, "text": "This is very feasible, I think."}, {"time": 2018, "text": "And coming back to the bigger question that you worried about that there'll be unintentional failures, I think there are two quite separate risks here."}, {"time": 2028, "text": "We talked a lot about one of them which is that the goals are noble of the human."}, {"time": 2032, "text": "The human says, I want this airplane to not crash because this is not Muhammad Atta now flying the airplane, right?"}, {"time": 2040, "text": "And now there's this technical challenge of making sure that the autopilot is actually gonna behave as the pilot wants."}, {"time": 2051, "text": "If you set that aside, there's also the separate question."}, {"time": 2053, "text": "How do you make sure that the goals of the pilot are actually aligned with the goals of the passenger?"}, {"time": 2059, "text": "How do you make sure very much more broadly that if we can all agree as a species that we would like things to kind of go well for humanity as a whole, that the goals are aligned here."}, {"time": 2070, "text": "The alignment problem."}, {"time": 2071, "text": "And yeah, there's been a lot of progress in the sense that there's suddenly huge amounts of research going on on it about it."}, {"time": 2082, "text": "I'm very grateful to Elon Musk for giving us that money five years ago so we could launch the first research program on technical AI safety and alignment."}, {"time": 2089, "text": "There's a lot of stuff happening."}, {"time": 2091, "text": "But I think we need to do more than just make sure little machines do always what their owners do."}, {"time": 2098, "text": "That wouldn't have prevented September 11th if Muhammad Atta said, okay, autopilot, please fly into World Trade Center."}, {"time": 2108, "text": "That even happened in a different situation."}, {"time": 2111, "text": "There was this depressed pilot named Andreas Lubitz, right?"}, {"time": 2115, "text": "Who told his German wings passenger jet to fly into the Alps."}, {"time": 2119, "text": "He just told the computer to change the altitude to a hundred meters or something like that."}, {"time": 2123, "text": "And you know what the computer said?"}, {"time": 2126, "text": "And it had the freaking topographical map of the Alps in there, it had GPS, everything."}, {"time": 2131, "text": "No one had bothered teaching it even the basic kindergarten ethics of like, no, we never want airplanes to fly into mountains under any circumstances."}, {"time": 2141, "text": "And so we have to think beyond just the technical issues and think about how do we align in general incentives on this planet for the greater good?"}, {"time": 2153, "text": "So starting with simple stuff like that, every airplane that has a computer in it should be taught whatever kindergarten ethics that's smart enough to understand."}, {"time": 2162, "text": "Like, no, don't fly into fixed objects if the pilot tells you to do so."}, {"time": 2167, "text": "Then go on autopilot mode."}, {"time": 2170, "text": "Send an email to the cops and land at the latest airport, nearest airport, you know."}, {"time": 2174, "text": "Any car with a forward facing camera should just be programmed by the manufacturer so that it will never accelerate into a human ever."}, {"time": 2184, "text": "That would avoid things like the NIS attack and many horrible terrorist vehicle attacks where they deliberately did that, right?"}, {"time": 2193, "text": "This was not some sort of thing, oh, you know, US and China, different views on, no, there was not a single car manufacturer in the world, right, who wanted the cars to do this."}, {"time": 2204, "text": "They just hadn't thought to do the alignment."}, {"time": 2205, "text": "And if you look at more broadly problems that happen on this planet, the vast majority have to do a poor alignment."}, {"time": 2213, "text": "I mean, think about, let's go back really big because I know you're so good at that."}, {"time": 2219, "text": "Let's go big, yeah."}, {"time": 2219, "text": "Yeah, so long ago in evolution, we had these genes."}, {"time": 2223, "text": "And they wanted to make copies of themselves."}, {"time": 2226, "text": "That's really all they cared about."}, {"time": 2227, "text": "So some genes said, hey, I'm gonna build a brain on this body I'm in so that I can get better at making copies of myself."}, {"time": 2237, "text": "And then they decided for their benefit to get copied more, to align your brain's incentives with their incentives."}, {"time": 2244, "text": "So it didn't want you to starve to death."}, {"time": 2249, "text": "So it gave you an incentive to eat and it wanted you to make copies of the genes."}, {"time": 2255, "text": "So it gave you incentive to fall in love and do all sorts of naughty things to make copies of itself, right?"}, {"time": 2264, "text": "So that was successful value alignment done on the genes."}, {"time": 2267, "text": "They created something more intelligent than themselves, but they made sure to try to align the values."}, {"time": 2272, "text": "But then something went a little bit wrong against the idea of what the genes wanted because a lot of humans discovered, hey, you know, yeah, we really like this business about sex that the genes have made us enjoy, but we don't wanna have babies right now."}, {"time": 2289, "text": "So we're gonna hack the genes and use birth control."}, {"time": 2293, "text": "And I really feel like drinking a Coca Cola right now, but I don't wanna get a potbelly, so I'm gonna drink Diet Coke."}, {"time": 2301, "text": "We have all these things we've figured out because we're smarter than the genes, how we can actually subvert their intentions."}, {"time": 2309, "text": "So it's not surprising that we humans now, when we are in the role of these genes, creating other nonhuman entities with a lot of power, have to face the same exact challenge."}, {"time": 2319, "text": "How do we make other powerful entities have incentives that are aligned with ours?"}, {"time": 2325, "text": "And so they won't hack them."}, {"time": 2327, "text": "Corporations, for example, right?"}, {"time": 2328, "text": "We humans decided to create corporations because it can benefit us greatly."}, {"time": 2333, "text": "Now all of a sudden there's a supermarket."}, {"time": 2335, "text": "I can go buy food there."}, {"time": 2336, "text": "I don't have to hunt."}, {"time": 2337, "text": "Awesome, and then to make sure that this corporation would do things that were good for us and not bad for us, we created institutions to keep them in check."}, {"time": 2348, "text": "Like if the local supermarket sells poisonous food, then the owners of the supermarket have to spend some years reflecting behind bars, right?"}, {"time": 2362, "text": "So we created incentives to align them."}, {"time": 2365, "text": "But of course, just like we were able to see through this thing and you develop birth control, if you're a powerful corporation, you also have an incentive to try to hack the institutions that are supposed to govern you."}, {"time": 2376, "text": "Because you ultimately, as a corporation, have an incentive to maximize your profit."}, {"time": 2380, "text": "Just like you have an incentive to maximize the enjoyment your brain has, not for your genes."}, {"time": 2386, "text": "So if they can figure out a way of bribing regulators, then they're gonna do that."}, {"time": 2392, "text": "In the US, we kind of caught onto that and made laws against corruption and bribery."}, {"time": 2398, "text": "Then in the late 1800s, Teddy Roosevelt realized that, no, we were still being kind of hacked because the Massachusetts Railroad companies had like a bigger budget than the state of Massachusetts and they were doing a lot of very corrupt stuff."}, {"time": 2413, "text": "So he did the whole trust busting thing to try to align these other nonhuman entities, the companies, again, more with the incentives of Americans as a whole."}, {"time": 2423, "text": "It's not surprising, though, that this is a battle you have to keep fighting."}, {"time": 2426, "text": "Now we have even larger companies than we ever had before."}, {"time": 2430, "text": "And of course, they're gonna try to, again, subvert the institutions."}, {"time": 2437, "text": "Not because, I think people make a mistake of getting all too, thinking about things in terms of good and evil."}, {"time": 2446, "text": "Like arguing about whether corporations are good or evil, or whether robots are good or evil."}, {"time": 2453, "text": "A robot isn't good or evil, it's a tool."}, {"time": 2457, "text": "And you can use it for great things like robotic surgery or for bad things."}, {"time": 2461, "text": "And a corporation also is a tool, of course."}, {"time": 2464, "text": "And if you have good incentives to the corporation, it'll do great things, like start a hospital or a grocery store."}, {"time": 2470, "text": "If you have any bad incentives, then it's gonna start maybe marketing addictive drugs to people and you'll have an opioid epidemic, right?"}, {"time": 2478, "text": "It's all about, we should not make the mistake of getting into some sort of fairytale, good, evil thing about corporations or robots."}, {"time": 2487, "text": "We should focus on putting the right incentives in place."}, {"time": 2490, "text": "My optimistic vision is that if we can do that, then we can really get good things."}, {"time": 2495, "text": "We're not doing so great with that right now, either on AI, I think, or on other intelligent nonhuman entities, like big companies, right?"}, {"time": 2503, "text": "We just have a new second generation of AI and a secretary of defense who's gonna start up now in the Biden administration, who was an active member of the board of Raytheon, for example."}, {"time": 2519, "text": "So, I have nothing against Raytheon."}, {"time": 2524, "text": "I'm not a pacifist, but there's an obvious conflict of interest if someone is in the job where they decide who they're gonna contract with."}, {"time": 2534, "text": "And I think somehow we have, maybe we need another Teddy Roosevelt to come along again and say, hey, you know, we want what's good for all Americans, and we need to go do some serious realigning again of the incentives that we're giving to these big companies."}, {"time": 2550, "text": "And then we're gonna be better off."}, {"time": 2553, "text": "It seems that naturally with human beings, just like you beautifully described the history of this whole thing, of it all started with the genes and they're probably pretty upset by all the unintended consequences that happened since."}, {"time": 2565, "text": "But it seems that it kind of works out, like it's in this collective intelligence that emerges at the different levels."}, {"time": 2573, "text": "It seems to find sometimes last minute a way to realign the values or keep the values aligned."}, {"time": 2580, "text": "It's almost, it finds a way, like different leaders, different humans pop up all over the place that reset the system."}, {"time": 2590, "text": "Do you want, I mean, do you have an explanation why that is?"}, {"time": 2595, "text": "Or is that just survivor bias?"}, {"time": 2597, "text": "And also is that different, somehow fundamentally different than with AI systems where you're no longer dealing with something that was a direct, maybe companies are the same, a direct byproduct of the evolutionary process?"}, {"time": 2613, "text": "I think there is one thing which has changed."}, {"time": 2616, "text": "That's why I'm not all optimistic."}, {"time": 2620, "text": "That's why I think there's about a 50% chance if we take the dumb route with artificial intelligence that humanity will be extinct in this century."}, {"time": 2631, "text": "First, just the big picture."}, {"time": 2633, "text": "Yeah, companies need to have the right incentives."}, {"time": 2637, "text": "Even governments, right?"}, {"time": 2639, "text": "We used to have governments, usually there were just some king, who was the king because his dad was the king."}, {"time": 2647, "text": "And then there were some benefits of having this powerful kingdom or empire of any sort because then it could prevent a lot of local squabbles."}, {"time": 2657, "text": "So at least everybody in that region would stop warring against each other."}, {"time": 2660, "text": "And their incentives of different cities in the kingdom became more aligned, right?"}, {"time": 2665, "text": "That was the whole selling point."}, {"time": 2667, "text": "Harare, Noel Harare has a beautiful piece on how empires were collaboration enablers."}, {"time": 2675, "text": "And then we also, Harare says, invented money for that reason so we could have better alignment and we could do trade even with people we didn't know."}, {"time": 2684, "text": "So this sort of stuff has been playing out since time immemorial, right?"}, {"time": 2687, "text": "What's changed is that it happens on ever larger scales, right?"}, {"time": 2692, "text": "The technology keeps getting better because science gets better."}, {"time": 2694, "text": "So now we can communicate over larger distances, transport things fast over larger distances."}, {"time": 2699, "text": "And so the entities get ever bigger, but our planet is not getting bigger anymore."}, {"time": 2705, "text": "So in the past, you could have one experiment that just totally screwed up like Easter Island, where they actually managed to have such poor alignment that when they went extinct, people there, there was no one else to come back and replace them, right?"}, {"time": 2721, "text": "If Elon Musk doesn't get us to Mars and then we go extinct on a global scale, then we're not coming back."}, {"time": 2728, "text": "That's the fundamental difference."}, {"time": 2731, "text": "And that's a mistake we don't make for that reason."}, {"time": 2735, "text": "In the past, of course, history is full of fiascos, right?"}, {"time": 2739, "text": "But it was never the whole planet."}, {"time": 2742, "text": "And then, okay, now there's this nice uninhabited land here."}, {"time": 2745, "text": "Some other people could move in and organize things better."}, {"time": 2749, "text": "This is different."}, {"time": 2750, "text": "The second thing, which is also different is that technology gives us so much more empowerment, right?"}, {"time": 2758, "text": "Both to do good things and also to screw up."}, {"time": 2760, "text": "In the stone age, even if you had someone whose goals were really poorly aligned, like maybe he was really pissed off because his stone age girlfriend dumped him and he just wanted to, if he wanted to kill as many people as he could, how many could he really take out with a rock and a stick before he was overpowered, right?"}, {"time": 2777, "text": "Just handful, right?"}, {"time": 2778, "text": "Now, with today's technology, if we have an accidental nuclear war between Russia and the US, which we almost have about a dozen times, and then we have a nuclear winter, it could take out seven billion people or six billion people, we don't know."}, {"time": 2797, "text": "So the scale of the damage is bigger that we can do."}, {"time": 2800, "text": "And there's obviously no law of physics that says that technology will never get powerful enough that we could wipe out our species entirely."}, {"time": 2811, "text": "That would just be fantasy to think that science is somehow doomed to not get more powerful than that, right?"}, {"time": 2817, "text": "And it's not at all unfeasible in our lifetime that someone could design a designer pandemic which spreads as easily as COVID, but just basically kills everybody."}, {"time": 2826, "text": "We already had smallpox."}, {"time": 2828, "text": "It killed one third of everybody who got it."}, {"time": 2833, "text": "What do you think of the, here's an intuition, maybe it's completely naive and this optimistic intuition I have, which it seems, and maybe it's a biased experience that I have, but it seems like the most brilliant people I've met in my life all are really like fundamentally good human beings."}, {"time": 2853, "text": "And not like naive good, like they really wanna do good for the world in a way that, well, maybe is aligned to my sense of what good means."}, {"time": 2861, "text": "And so I have a sense that the people that will be defining the very cutting edge of technology, there'll be much more of the ones that are doing good versus the ones that are doing evil."}, {"time": 2875, "text": "So the race, I'm optimistic on the, us always like last minute coming up with a solution."}, {"time": 2883, "text": "So if there's an engineered pandemic that has the capability to destroy most of the human civilization, it feels like to me either leading up to that before or as it's going on, there will be, we're able to rally the collective genius of the human species."}, {"time": 2903, "text": "I can tell by your smile that you're at least some percentage doubtful, but could that be a fundamental law of human nature?"}, {"time": 2915, "text": "That evolution only creates, like karma is beneficial, good is beneficial, and therefore we'll be all right."}, {"time": 2924, "text": "I hope you're right."}, {"time": 2926, "text": "I would really love it if you're right, if there's some sort of law of nature that says that we always get lucky in the last second with karma, but I prefer not playing it so close and gambling on that."}, {"time": 2943, "text": "And I think, in fact, I think it can be dangerous to have too strong faith in that because it makes us complacent."}, {"time": 2950, "text": "Like if someone tells you, you never have to worry about your house burning down, then you're not gonna put in a smoke detector because why would you need to?"}, {"time": 2957, "text": "Even if it's sometimes very simple precautions, we don't take them."}, {"time": 2960, "text": "If you're like, oh, the government is gonna take care of everything for us, I can always trust my politicians."}, {"time": 2964, "text": "I can always, we advocate our own responsibility."}, {"time": 2967, "text": "I think it's a healthier attitude to say, yeah, maybe things will work out."}, {"time": 2970, "text": "Maybe I'm actually gonna have to myself step up and take responsibility."}, {"time": 2977, "text": "And the stakes are so huge."}, {"time": 2978, "text": "I mean, if we do this right, we can develop all this ever more powerful technology and cure all diseases and create a future where humanity is healthy and wealthy for not just the next election cycle, but like billions of years throughout our universe."}, {"time": 2992, "text": "That's really worth working hard for and not just sitting and hoping for some sort of fairytale karma."}, {"time": 2999, "text": "Well, I just mean, so you're absolutely right."}, {"time": 3001, "text": "From the perspective of the individual, like for me, the primary thing should be to take responsibility and to build the solutions that your skillset allows."}, {"time": 3011, "text": "Yeah, which is a lot."}, {"time": 3012, "text": "I think we underestimate often very much how much good we can do."}, {"time": 3016, "text": "If you or anyone listening to this is completely confident that our government would do a perfect job on handling any future crisis with engineered pandemics or future AI, I actually reflect a bit on what actually happened in 2020."}, {"time": 3036, "text": "Do you feel that the government by and large around the world has handled this flawlessly?"}, {"time": 3042, "text": "That's a really sad and disappointing reality that hopefully is a wake up call for everybody."}, {"time": 3048, "text": "For the scientists, for the engineers, for the researchers in AI especially, it was disappointing to see how inefficient we were at collecting the right amount of data in a privacy preserving way and spreading that data and utilizing that data to make decisions, all that kind of stuff."}, {"time": 3070, "text": "Yeah, I think when something bad happens to me, I made myself a promise many years ago that I would not be a whiner."}, {"time": 3081, "text": "So when something bad happens to me, of course it's a process of disappointment, but then I try to focus on what did I learn from this that can make me a better person in the future."}, {"time": 3092, "text": "And there's usually something to be learned when I fail."}, {"time": 3095, "text": "And I think we should all ask ourselves, what can we learn from the pandemic about how we can do better in the future?"}, {"time": 3103, "text": "And you mentioned there a really good lesson."}, {"time": 3106, "text": "We were not as resilient as we thought we were and we were not as prepared maybe as we wish we were."}, {"time": 3113, "text": "You can even see very stark contrast around the planet."}, {"time": 3117, "text": "South Korea, they have over 50 million people."}, {"time": 3121, "text": "Do you know how many deaths they have from COVID last time I checked?"}, {"time": 3126, "text": "It's about 500."}, {"time": 3130, "text": "Well, the short answer is that they had prepared."}, {"time": 3136, "text": "They were incredibly quick, incredibly quick to get on it with very rapid testing and contact tracing and so on, which is why they never had more cases than they could contract trace effectively, right?"}, {"time": 3150, "text": "They never even had to have the kind of big lockdowns we had in the West."}, {"time": 3153, "text": "But the deeper answer to, it's not just the Koreans are just somehow better people."}, {"time": 3159, "text": "The reason I think they were better prepared was because they had already had a pretty bad hit from the SARS pandemic, or which never became a pandemic, something like 17 years ago, I think."}, {"time": 3172, "text": "So it was kind of fresh memory that we need to be prepared for pandemics."}, {"time": 3176, "text": "So they were, right?"}, {"time": 3179, "text": "So maybe this is a lesson here for all of us to draw from COVID that rather than just wait for the next pandemic or the next problem with AI getting out of control or anything else, maybe we should just actually set aside a tiny fraction of our GDP to have people very systematically do some horizon scanning and say, okay, what are the things that could go wrong?"}, {"time": 3203, "text": "And let's duke it out and see which are the more likely ones and which are the ones that are actually actionable and then be prepared."}, {"time": 3209, "text": "So one of the observations as one little ant slash human that I am of disappointment is the political division over information that has been observed, that I observed this year, that it seemed the discussion was less about sort of what happened and understanding what happened deeply and more about there's different truths out there."}, {"time": 3244, "text": "And it's like an argument, my truth is better than your truth."}, {"time": 3247, "text": "And it's like red versus blue or different."}, {"time": 3250, "text": "It was like this ridiculous discourse that doesn't seem to get at any kind of notion of the truth."}, {"time": 3256, "text": "It's not like some kind of scientific process."}, {"time": 3259, "text": "Even science got politicized in ways that's very heartbreaking to me."}, {"time": 3264, "text": "You have an exciting project on the AI front of trying to rethink one of the, you mentioned corporations."}, {"time": 3274, "text": "There's one of the other collective intelligence systems that have emerged through all of this is social networks."}, {"time": 3280, "text": "And just the spread, the internet is the spread of information on the internet, our ability to share that information."}, {"time": 3288, "text": "There's all different kinds of news sources and so on."}, {"time": 3290, "text": "And so you said like that's from first principles, let's rethink how we think about the news, how we think about information."}, {"time": 3299, "text": "Can you talk about this amazing effort that you're undertaking?"}, {"time": 3303, "text": "Oh, I'd love to."}, {"time": 3304, "text": "This has been my big COVID project and nights and weekends on ever since the lockdown."}, {"time": 3311, "text": "To segue into this actually, let me come back to what you said earlier that you had this hope that in your experience, people who you felt were very talented were often idealistic and wanted to do good."}, {"time": 3321, "text": "Frankly, I feel the same about all people by and large, there are always exceptions, but I think the vast majority of everybody, regardless of education and whatnot, really are fundamentally good, right?"}, {"time": 3333, "text": "So how can it be that people still do so much nasty stuff?"}, {"time": 3337, "text": "I think it has everything to do with this, with the information that we're given."}, {"time": 3342, "text": "If you go into Sweden 500 years ago and you start telling all the farmers that those Danes in Denmark, they're so terrible people, and we have to invade them because they've done all these terrible things that you can't fact check yourself."}, {"time": 3356, "text": "A lot of people, Swedes did that, right?"}, {"time": 3359, "text": "And we're seeing so much of this today in the world, both geopolitically, where we are told that China is bad and Russia is bad and Venezuela is bad, and people in those countries are often told that we are bad."}, {"time": 3377, "text": "And we also see it at a micro level where people are told that, oh, those who voted for the other party are bad people."}, {"time": 3384, "text": "It's not just an intellectual disagreement, but they're bad people and we're getting ever more divided."}, {"time": 3392, "text": "So how do you reconcile this with this intrinsic goodness in people?"}, {"time": 3399, "text": "I think it's pretty obvious that it has, again, to do with the information that we're fed and given, right?"}, {"time": 3406, "text": "We evolved to live in small groups where you might know 30 people in total, right?"}, {"time": 3412, "text": "So you then had a system that was quite good for assessing who you could trust and who you could not."}, {"time": 3417, "text": "And if someone told you that Joe there is a jerk, but you had interacted with him yourself and seen him in action, and you would quickly realize maybe that that's actually not quite accurate, right?"}, {"time": 3431, "text": "But now that the most people on the planet are people we've never met, it's very important that we have a way of trusting the information we're given."}, {"time": 3439, "text": "And so, okay, so where does the news project come in?"}, {"time": 3443, "text": "Well, throughout history, you can go read Machiavelli, from the 1400s, and you'll see how already then they were busy manipulating people with propaganda and stuff."}, {"time": 3451, "text": "Propaganda is not new at all."}, {"time": 3455, "text": "And the incentives to manipulate people is just not new at all."}, {"time": 3460, "text": "What is it that's new?"}, {"time": 3461, "text": "What's new is machine learning meets propaganda."}, {"time": 3464, "text": "That's what's new."}, {"time": 3465, "text": "That's why this has gotten so much worse."}, {"time": 3467, "text": "Some people like to blame certain individuals, like in my liberal university bubble, many people blame Donald Trump and say it was his fault."}, {"time": 3476, "text": "I see it differently."}, {"time": 3479, "text": "I think Donald Trump just had this extreme skill at playing this game in the machine learning algorithm age."}, {"time": 3487, "text": "A game he couldn't have played 10 years ago."}, {"time": 3489, "text": "So what's changed?"}, {"time": 3490, "text": "What's changed is, well, Facebook and Google and other companies, and I'm not badmouthing them, I have a lot of friends who work for these companies, good people, they deployed machine learning algorithms just to increase their profit a little bit, to just maximize the time people spent watching ads."}, {"time": 3508, "text": "And they had totally underestimated how effective they were gonna be."}, {"time": 3512, "text": "This was, again, the black box, non intelligible intelligence."}, {"time": 3517, "text": "They just noticed, oh, we're getting more ad revenue."}, {"time": 3520, "text": "It took a long time until they even realized why and how and how damaging this was for society."}, {"time": 3525, "text": "Because of course, what the machine learning figured out was that the by far most effective way of gluing you to your little rectangle was to show you things that triggered strong emotions, anger, et cetera, resentment, and if it was true or not, it didn't really matter."}, {"time": 3544, "text": "It was also easier to find stories that weren't true."}, {"time": 3547, "text": "If you weren't limited, that's just the limitation, is to show people."}, {"time": 3550, "text": "That's a very limiting fact."}, {"time": 3552, "text": "And before long, we got these amazing filter bubbles on a scale we had never seen before."}, {"time": 3558, "text": "A couple of days to the fact that also the online news media were so effective that they killed a lot of people that were so effective that they killed a lot of print journalism."}, {"time": 3570, "text": "There's less than half as many journalists now in America, I believe, as there was a generation ago."}, {"time": 3579, "text": "You just couldn't compete with the online advertising."}, {"time": 3582, "text": "So all of a sudden, most people are not getting even reading newspapers."}, {"time": 3588, "text": "They get their news from social media."}, {"time": 3591, "text": "And most people only get news in their little bubble."}, {"time": 3595, "text": "So along comes now some people like Donald Trump, who figured out, among the first successful politicians, to figure out how to really play this new game and become very, very influential."}, {"time": 3605, "text": "But I think Donald Trump was as simple."}, {"time": 3609, "text": "He took advantage of it."}, {"time": 3611, "text": "He didn't create the fundamental conditions were created by machine learning taking over the news media."}, {"time": 3619, "text": "So this is what motivated my little COVID project here."}, {"time": 3622, "text": "So I said before, machine learning and tech in general is not evil, but it's also not good."}, {"time": 3629, "text": "It's just a tool that you can use for good things or bad things."}, {"time": 3632, "text": "And as it happens, machine learning and news was mainly used by the big players, big tech, to manipulate people and to watch as many ads as possible, which had this unintended consequence of really screwing up our democracy and fragmenting it into filter bubbles."}, {"time": 3650, "text": "So I thought, well, machine learning algorithms are basically free."}, {"time": 3654, "text": "They can run on your smartphone for free also if someone gives them away to you, right?"}, {"time": 3657, "text": "There's no reason why they only have to help the big guy to manipulate the little guy."}, {"time": 3662, "text": "They can just as well help the little guy to see through all the manipulation attempts from the big guy."}, {"time": 3668, "text": "So this project is called, you can go to improvethenews.org."}, {"time": 3672, "text": "The first thing we've built is this little news aggregator."}, {"time": 3676, "text": "Looks a bit like Google News, except it has these sliders on it to help you break out of your filter bubble."}, {"time": 3681, "text": "So if you're reading, you can click, click and go to your favorite topic."}, {"time": 3687, "text": "And then if you just slide the left, right slider away all the way over to the left."}, {"time": 3692, "text": "There's two sliders, right?"}, {"time": 3693, "text": "Yeah, there's the one, the most obvious one is the one that has left, right labeled on it."}, {"time": 3698, "text": "You go to the left, you get one set of articles, you go to the right, you see a very different truth appearing."}, {"time": 3704, "text": "Oh, that's literally left and right on the political spectrum."}, {"time": 3707, "text": "On the political spectrum."}, {"time": 3708, "text": "So if you're reading about immigration, for example, it's very, very noticeable."}, {"time": 3715, "text": "And I think step one always, if you wanna not get manipulated is just to be able to recognize the techniques people use."}, {"time": 3722, "text": "So it's very helpful to just see how they spin things on the two sides."}, {"time": 3728, "text": "I think many people are under the misconception that the main problem is fake news."}, {"time": 3734, "text": "I had an amazing team of MIT students where we did an academic project to use machine learning to detect the main kinds of bias over the summer."}, {"time": 3743, "text": "And yes, of course, sometimes there's fake news where someone just claims something that's false, right?"}, {"time": 3750, "text": "Like, oh, Hillary Clinton just got divorced or something."}, {"time": 3752, "text": "But what we see much more of is actually just omissions."}, {"time": 3757, "text": "If you go to, there's some stories which just won't be mentioned by the left or the right, because it doesn't suit their agenda."}, {"time": 3766, "text": "And then they'll mention other ones very, very, very much."}, {"time": 3769, "text": "So for example, we've had a number of stories about the Trump family's financial dealings."}, {"time": 3779, "text": "And then there's been a bunch of stories about the Biden family's, Hunter Biden's financial dealings."}, {"time": 3785, "text": "Surprise, surprise, they don't get equal coverage on the left and the right."}, {"time": 3788, "text": "One side loves to cover the Biden, Hunter Biden's stuff, and one side loves to cover the Trump."}, {"time": 3795, "text": "You can never guess which is which, right?"}, {"time": 3797, "text": "But the great news is if you're a normal American citizen and you dislike corruption in all its forms, then slide, slide, you can just look at both sides and you'll see all those political corruption stories."}, {"time": 3812, "text": "It's really liberating to just take in the both sides, the spin on both sides."}, {"time": 3819, "text": "It somehow unlocks your mind to think on your own, to realize that, I don't know, it's the same thing that was useful, right, in the Soviet Union times for when everybody was much more aware that they're surrounded by propaganda, right?"}, {"time": 3837, "text": "That is so interesting what you're saying, actually."}, {"time": 3840, "text": "So Noam Chomsky, used to be our MIT colleague, once said that propaganda is to democracy what violence is to totalitarianism."}, {"time": 3851, "text": "And what he means by that is if you have a really totalitarian government, you don't need propaganda."}, {"time": 3859, "text": "People will do what you want them to do anyway, but out of fear, right?"}, {"time": 3864, "text": "But otherwise, you need propaganda."}, {"time": 3868, "text": "So I would say actually that the propaganda is much higher quality in democracies, much more believable."}, {"time": 3874, "text": "And it's really, it's really striking."}, {"time": 3876, "text": "When I talk to colleagues, science colleagues like from Russia and China and so on, I notice they are actually much more aware of the propaganda in their own media than many of my American colleagues are about the propaganda in Western media."}, {"time": 3891, "text": "That means the propaganda in the Western media is just better."}, {"time": 3896, "text": "Everything's better in the West, even the propaganda."}, {"time": 3898, "text": "But once you realize that, you realize there's also something very optimistic there that you can do about it, right?"}, {"time": 3910, "text": "Because first of all, omissions, as long as there's no outright censorship, you can just look at both sides and pretty quickly piece together a much more accurate idea of what's actually going on, right?"}, {"time": 3926, "text": "And develop a natural skepticism too."}, {"time": 3928, "text": "Just an analytical scientific mind about the way you're taking the information."}, {"time": 3933, "text": "And I think, I have to say, sometimes I feel that some of us in the academic bubble are too arrogant about this and somehow think, oh, it's just people who aren't as educated as the dots are pulled."}, {"time": 3945, "text": "When we are often just as gullible also, we read only our media and don't see through things."}, {"time": 3952, "text": "Anyone who looks at both sides like this and compares a little will immediately start noticing the shenanigans being pulled."}, {"time": 3958, "text": "And I think what I tried to do with this app is that the big tech has to some extent tried to blame the individual for being manipulated, much like big tobacco tried to blame the individuals entirely for smoking."}, {"time": 3973, "text": "And then later on, our government stepped up and say, actually, you can't just blame little kids for starting to smoke."}, {"time": 3980, "text": "We have to have more responsible advertising and this and that."}, {"time": 3983, "text": "I think it's a bit the same here."}, {"time": 3984, "text": "It's very convenient for a big tech to blame."}, {"time": 3987, "text": "So it's just people who are so dumb and get fooled."}, {"time": 3992, "text": "The blame usually comes in saying, oh, it's just human psychology."}, {"time": 3996, "text": "People just wanna hear what they already believe."}, {"time": 3998, "text": "But professor David Rand at MIT actually partly debunked that with a really nice study showing that people tend to be interested in hearing things that go against what they believe, if it's presented in a respectful way."}, {"time": 4012, "text": "Suppose, for example, that you have a company and you're just about to launch this project and you're convinced it's gonna work."}, {"time": 4020, "text": "And someone says, you know, Lex, I hate to tell you this, but this is gonna fail."}, {"time": 4026, "text": "Would you be like, shut up, I don't wanna hear it."}, {"time": 4028, "text": "La, la, la, la, la, la, la, la, la."}, {"time": 4030, "text": "Would you?"}, {"time": 4031, "text": "You would be interested, right?"}, {"time": 4033, "text": "And also if you're on an airplane, back in the pre COVID times, and the guy next to you is clearly from the opposite side of the political spectrum, but is very respectful and polite to you."}, {"time": 4046, "text": "Wouldn't you be kind of interested to hear a bit about how he or she thinks about things?"}, {"time": 4052, "text": "But it's not so easy to find out respectful disagreement now, because like, for example, if you are a Democrat and you're like, oh, I wanna see something on the other side, so you just go Breitbart.com."}, {"time": 4065, "text": "And then after the first 10 seconds, you feel deeply insulted by something."}, {"time": 4069, "text": "And they, it's not gonna work."}, {"time": 4072, "text": "Or if you take someone who votes Republican and they go to something on the left, then they just get very offended very quickly by them having put a deliberately ugly picture of Donald Trump on the front page or something."}, {"time": 4084, "text": "It doesn't really work."}, {"time": 4085, "text": "So this news aggregator also has this nuance slider, which you can pull to the right and then sort of make it easier to get exposed to actually more sort of academic style or more respectful, portrayals of different views."}, {"time": 4099, "text": "And finally, the one kind of bias I think people are mostly aware of is the left, right, because it's so obvious, because both left and right are very powerful here, right?"}, {"time": 4110, "text": "Both of them have well funded TV stations and newspapers, and it's kind of hard to miss."}, {"time": 4115, "text": "But there's another one, the establishment slider, which is also really fun."}, {"time": 4121, "text": "I love to play with it."}, {"time": 4122, "text": "And that's more about corruption."}, {"time": 4125, "text": "I love that one."}, {"time": 4127, "text": "Because if you have a society where almost all the powerful entities want you to believe a certain thing, that's what you're gonna read in both the big media, mainstream media on the left and on the right, of course."}, {"time": 4144, "text": "And the powerful companies can push back very hard, like tobacco companies push back very hard back in the day when some newspapers started writing articles about tobacco being dangerous, so that it was hard to get a lot of coverage about it initially."}, {"time": 4158, "text": "And also if you look geopolitically, right, of course, in any country, when you read their media, you're mainly gonna be reading a lot of articles about how our country is the good guy and the other countries are the bad guys, right?"}, {"time": 4170, "text": "So if you wanna have a really more nuanced understanding, like the Germans used to be told that the British used to be told that the French were the bad guys and the French used to be told that the British were the bad guys."}, {"time": 4181, "text": "Now they visit each other's countries a lot and have a much more nuanced understanding."}, {"time": 4187, "text": "I don't think there's gonna be any more wars between France and Germany."}, {"time": 4190, "text": "But on the geopolitical scale, it's just as much as ever, you know, big Cold War, now US, China, and so on."}, {"time": 4197, "text": "And if you wanna get a more nuanced understanding of what's happening geopolitically, then it's really fun to look at this establishment slider because it turns out there are tons of little newspapers, both on the left and on the right, who sometimes challenge establishment and say, you know, maybe we shouldn't actually invade Iraq right now."}, {"time": 4217, "text": "Maybe this weapons of mass destruction thing is BS."}, {"time": 4220, "text": "If you look at the journalism research afterwards, you can actually see that quite clearly."}, {"time": 4225, "text": "Both CNN and Fox were very pro."}, {"time": 4229, "text": "Let's get rid of Saddam."}, {"time": 4230, "text": "There are weapons of mass destruction."}, {"time": 4232, "text": "Then there were a lot of smaller newspapers."}, {"time": 4234, "text": "They were like, wait a minute, this evidence seems a bit sketchy and maybe we..."}, {"time": 4240, "text": "But of course they were so hard to find."}, {"time": 4242, "text": "Most people didn't even know they existed, right?"}, {"time": 4244, "text": "Yet it would have been better for American national security if those voices had also come up."}, {"time": 4250, "text": "I think it harmed America's national security actually that we invaded Iraq."}, {"time": 4253, "text": "And arguably there's a lot more interest in that kind of thinking too, from those small sources."}, {"time": 4260, "text": "So like when you say big, it's more about kind of the reach of the broadcast, but it's not big in terms of the interest."}, {"time": 4272, "text": "I think there's a lot of interest in that kind of anti establishment or like skepticism towards, you know, out of the box thinking."}, {"time": 4280, "text": "There's a lot of interest in that kind of thing."}, {"time": 4282, "text": "Do you see this news project or something like it being basically taken over the world as the main way we consume information?"}, {"time": 4292, "text": "Like how do we get there?"}, {"time": 4295, "text": "Like how do we, you know?"}, {"time": 4297, "text": "So, okay, the idea is brilliant."}, {"time": 4299, "text": "It's a, you're calling it your little project in 2020, but how does that become the new way we consume information?"}, {"time": 4308, "text": "I hope, first of all, just to plant a little seed there because normally the big barrier of doing anything in media is you need a ton of money, but this costs no money at all."}, {"time": 4319, "text": "I've just been paying myself."}, {"time": 4320, "text": "You pay a tiny amount of money each month to Amazon to run the thing in their cloud."}, {"time": 4324, "text": "We're not, there never will never be any ads."}, {"time": 4326, "text": "The point is not to make any money off of it."}, {"time": 4329, "text": "And we just train machine learning algorithms to classify the articles and stuff."}, {"time": 4333, "text": "So it just kind of runs by itself."}, {"time": 4334, "text": "So if it actually gets good enough at some point that it starts catching on, it could scale."}, {"time": 4340, "text": "And if other people carbon copy it and make other versions that are better, that's the more the merrier."}, {"time": 4348, "text": "I think there's a real opportunity for machine learning to empower the individual against the powerful players."}, {"time": 4359, "text": "As I said in the beginning here, it's been mostly the other way around so far, that the big players have the AI and then they tell people, this is the truth, this is how it is."}, {"time": 4369, "text": "But it can just as well go the other way around."}, {"time": 4372, "text": "And when the internet was born, actually, a lot of people had this hope that maybe this will be a great thing for democracy, make it easier to find out about things."}, {"time": 4379, "text": "And maybe machine learning and things like this can actually help again."}, {"time": 4383, "text": "And I have to say, I think it's more important than ever now because this is very linked also to the whole future of life as we discussed earlier."}, {"time": 4393, "text": "We're getting this ever more powerful tech."}, {"time": 4397, "text": "Frank, it's pretty clear if you look on the one or two generation, three generation timescale that there are only two ways this can end geopolitically."}, {"time": 4404, "text": "Either it ends great for all humanity or it ends terribly for all of us."}, {"time": 4411, "text": "There's really no in between."}, {"time": 4413, "text": "And we're so stuck in that because technology knows no borders."}, {"time": 4419, "text": "And you can't have people fighting when the weapons just keep getting ever more powerful indefinitely."}, {"time": 4427, "text": "Eventually, the luck runs out."}, {"time": 4430, "text": "And right now we have, I love America, but the fact of the matter is what's good for America is not opposite in the long term to what's good for other countries."}, {"time": 4444, "text": "It would be if this was some sort of zero sum game like it was thousands of years ago when the only way one country could get more resources was to take land from other countries because that was basically the resource."}, {"time": 4457, "text": "Look at the map of Europe."}, {"time": 4458, "text": "Some countries kept getting bigger and smaller, endless wars."}, {"time": 4463, "text": "But then since 1945, there hasn't been any war in Western Europe."}, {"time": 4467, "text": "And they all got way richer because of tech."}, {"time": 4469, "text": "So the optimistic outcome is that the big winner in this century is going to be America and China and Russia and everybody else because technology just makes us all healthier and wealthier."}, {"time": 4481, "text": "And we just find some way of keeping the peace on this planet."}, {"time": 4486, "text": "But I think, unfortunately, there are some pretty powerful forces right now that are pushing in exactly the opposite direction and trying to demonize other countries, which just makes it more likely that this ever more powerful tech we're building is going to be used in disastrous ways."}, {"time": 4502, "text": "Yeah, for aggression versus cooperation, that kind of thing."}, {"time": 4505, "text": "Yeah, even look at just military AI now."}, {"time": 4509, "text": "It was so awesome to see these dancing robots."}, {"time": 4514, "text": "But one of the biggest growth areas in robotics now is, of course, autonomous weapons."}, {"time": 4519, "text": "And 2020 was like the best marketing year ever for autonomous weapons."}, {"time": 4524, "text": "Because in both Libya, it's a civil war, and in Nagorno Karabakh, they made the decisive difference."}, {"time": 4534, "text": "And everybody else is watching this."}, {"time": 4536, "text": "Oh, yeah, we want to build autonomous weapons, too."}, {"time": 4538, "text": "In Libya, you had, on one hand, our ally, the United Arab Emirates that were flying their autonomous weapons that they bought from China, bombing Libyans."}, {"time": 4551, "text": "And on the other side, you had our other ally, Turkey, flying their drones."}, {"time": 4557, "text": "And they had no skin in the game, any of these other countries."}, {"time": 4561, "text": "And of course, it was the Libyans who really got screwed."}, {"time": 4564, "text": "In Nagorno Karabakh, you had actually, again, Turkey is sending drones built by this company that was actually founded by a guy who went to MIT AeroAstro."}, {"time": 4577, "text": "Do you know that?"}, {"time": 4578, "text": "Bacratyar."}, {"time": 4579, "text": "So MIT has a direct responsibility for ultimately this."}, {"time": 4582, "text": "And a lot of civilians were killed there."}, {"time": 4585, "text": "So because it was militarily so effective, now suddenly there's a huge push."}, {"time": 4591, "text": "Oh, yeah, yeah, let's go build ever more autonomy into these weapons, and it's going to be great."}, {"time": 4599, "text": "And I think, actually, people who are obsessed about some sort of future Terminator scenario right now should start focusing on the fact that we have two much more urgent threats happening from machine learning."}, {"time": 4614, "text": "One of them is the whole destruction of democracy that we've talked about now, where our flow of information is being manipulated by machine learning."}, {"time": 4624, "text": "And the other one is that right now, this is the year when the big arms race and out of control arms race in at least Thomas Weapons is going to start, or it's going to stop."}, {"time": 4634, "text": "So you have a sense that there is like 2020 was an instrumental catalyst for the autonomous weapons race."}, {"time": 4644, "text": "Yeah, because it was the first year when they proved decisive in the battlefield."}, {"time": 4648, "text": "And these ones are still not fully autonomous, mostly."}, {"time": 4651, "text": "They're remote controlled, right?"}, {"time": 4652, "text": "But we could very quickly make things about the size and cost of a smartphone, which you just put in the GPS coordinates or the face of the one you want to kill, a skin color or whatever, and it flies away and does it."}, {"time": 4668, "text": "And the real good reason why the US and all the other superpowers should put the kibosh on this is the same reason we decided to put the kibosh on bioweapons."}, {"time": 4681, "text": "So we gave the Future of Life Award that we can talk more about later to Matthew Messelson from Harvard before for convincing Nixon to ban bioweapons."}, {"time": 4690, "text": "And I asked him, how did you do it?"}, {"time": 4693, "text": "And he was like, well, I just said, look, we don't want there to be a $500 weapon of mass destruction that all our enemies can afford, even nonstate actors."}, {"time": 4706, "text": "And Nixon was like, good point."}, {"time": 4712, "text": "It's in America's interest that the powerful weapons are all really expensive, so only we can afford them, or maybe some more stable adversaries, right?"}, {"time": 4721, "text": "Nuclear weapons are like that."}, {"time": 4722, "text": "But bioweapons were not like that."}, {"time": 4724, "text": "That's why we banned them."}, {"time": 4726, "text": "And that's why you never hear about them now."}, {"time": 4728, "text": "That's why we love biology."}, {"time": 4730, "text": "So you have a sense that it's possible for the big power houses in terms of the big nations in the world to agree that autonomous weapons is not a race we want to be on, that it doesn't end well."}, {"time": 4743, "text": "Yeah, because we know it's just going to end in mass proliferation."}, {"time": 4746, "text": "And every terrorist everywhere is going to have these super cheap weapons that they will use against us."}, {"time": 4753, "text": "And our politicians have to constantly worry about being assassinated every time they go outdoors by some anonymous little mini drone."}, {"time": 4761, "text": "And even if the US and China and everyone else could just agree that you can only build these weapons if they cost at least $10 million, that would be a huge win for the superpowers and, frankly, for everybody."}, {"time": 4778, "text": "And people often push back and say, well, it's so hard to prevent cheating."}, {"time": 4783, "text": "But hey, you could say the same about bioweapons."}, {"time": 4785, "text": "Take any of your MIT colleagues in biology."}, {"time": 4789, "text": "Of course, they could build some nasty bioweapon if they really wanted to."}, {"time": 4793, "text": "But first of all, they don't want to because they think it's disgusting because of the stigma."}, {"time": 4797, "text": "And second, even if there's some sort of nutcase and want to, it's very likely that some of their grad students or someone would rat them out because everyone else thinks it's so disgusting."}, {"time": 4808, "text": "And in fact, we now know there was even a fair bit of cheating on the bioweapons ban."}, {"time": 4813, "text": "But no countries used them because it was so stigmatized that it just wasn't worth revealing that they had cheated."}, {"time": 4822, "text": "You talk about drones, but you kind of think that drones is a remote operation."}, {"time": 4828, "text": "Which they are, mostly, still."}, {"time": 4830, "text": "But you're not taking the next intellectual step of where does this go."}, {"time": 4836, "text": "You're kind of saying the problem with drones is that you're removing yourself from direct violence."}, {"time": 4842, "text": "Therefore, you're not able to sort of maintain the common humanity required to make the proper decisions strategically."}, {"time": 4848, "text": "But that's the criticism as opposed to like, if this is automated, and just exactly as you said, if you automate it and there's a race, then the technology's gonna get better and better and better which means getting cheaper and cheaper and cheaper."}, {"time": 4863, "text": "And unlike, perhaps, nuclear weapons which is connected to resources in a way, like it's hard to engineer, yeah."}, {"time": 4873, "text": "It feels like there's too much overlap between the tech industry and autonomous weapons to where you could have smartphone type of cheapness."}, {"time": 4884, "text": "If you look at drones, for $1,000, you can have an incredible system that's able to maintain flight autonomously for you and take pictures and stuff."}, {"time": 4896, "text": "You could see that going into the autonomous weapons space that's, but why is that not thought about or discussed enough in the public, do you think?"}, {"time": 4905, "text": "You see those dancing Boston Dynamics robots and everybody has this kind of, as if this is like a far future."}, {"time": 4915, "text": "They have this fear like, oh, this'll be Terminator in like some, I don't know, unspecified 20, 30, 40 years."}, {"time": 4923, "text": "And they don't think about, well, this is like some much less dramatic version of that is actually happening now."}, {"time": 4931, "text": "It's not gonna be legged, it's not gonna be dancing, but it already has the capability to use artificial intelligence to kill humans."}, {"time": 4940, "text": "Yeah, the Boston Dynamics legged robots, I think the reason we imagine them holding guns is just because you've all seen Arnold Schwarzenegger, right?"}, {"time": 4948, "text": "That's our reference point."}, {"time": 4950, "text": "That's pretty useless."}, {"time": 4952, "text": "That's not gonna be the main military use of them."}, {"time": 4955, "text": "They might be useful in law enforcement in the future and then there's a whole debate about, do you want robots showing up at your house with guns telling you who'll be perfectly obedient to whatever dictator controls them?"}, {"time": 4967, "text": "But let's leave that aside for a moment and look at what's actually relevant now."}, {"time": 4971, "text": "So there's a spectrum of things you can do with AI in the military."}, {"time": 4975, "text": "And again, to put my card on the table, I'm not the pacifist, I think we should have good defense."}, {"time": 4983, "text": "So for example, a predator drone is basically a fancy little remote controlled airplane, right?"}, {"time": 4991, "text": "There's a human piloting it and the decision ultimately about whether to kill somebody with it is made by a human still."}, {"time": 4999, "text": "And this is a line I think we should never cross."}, {"time": 5003, "text": "There's a current DOD policy."}, {"time": 5005, "text": "Again, you have to have a human in the loop."}, {"time": 5007, "text": "I think algorithms should never make life or death decisions, they should be left to humans."}, {"time": 5014, "text": "Now, why might we cross that line?"}, {"time": 5017, "text": "Well, first of all, these are expensive, right?"}, {"time": 5020, "text": "So for example, when Azerbaijan had all these drones and Armenia didn't have any, they start trying to jerry rig little cheap things, fly around."}, {"time": 5031, "text": "But then of course, the Armenians would jam them or the Azeris would jam them."}, {"time": 5035, "text": "And remote control things can be jammed, that makes them inferior."}, {"time": 5040, "text": "Also, there's a bit of a time delay between, if we're piloting something from far away, speed of light, and the human has a reaction time as well, it would be nice to eliminate that jamming possibility in the time that they by having it fully autonomous."}, {"time": 5054, "text": "But now you might be, so then if you do, but now you might be crossing that exact line."}, {"time": 5059, "text": "You might program it to just, oh yeah, the air drone, go hover over this country for a while and whenever you find someone who is a bad guy, kill them."}, {"time": 5070, "text": "Now the machine is making these sort of decisions and some people who defend this still say, well, that's morally fine because we are the good guys and we will tell it the definition of bad guy that we think is moral."}, {"time": 5085, "text": "But now it would be very naive to think that if ISIS buys that same drone, that they're gonna use our definition of bad guy."}, {"time": 5094, "text": "Maybe for them, bad guy is someone wearing a US army uniform or maybe there will be some, weird ethnic group who decides that someone of another ethnic group, they are the bad guys, right?"}, {"time": 5107, "text": "The thing is human soldiers with all our faults, we still have some basic wiring in us."}, {"time": 5114, "text": "Like, no, it's not okay to kill kids and civilians."}, {"time": 5120, "text": "And Thomas Weprin has none of that."}, {"time": 5121, "text": "It's just gonna do whatever is programmed."}, {"time": 5123, "text": "It's like the perfect Adolf Eichmann on steroids."}, {"time": 5127, "text": "Like they told him, Adolf Eichmann, you know, he wanted to do this and this and this to make the Holocaust more efficient."}, {"time": 5133, "text": "And he was like, yeah, and off he went and did it, right?"}, {"time": 5137, "text": "Do we really wanna make machines that are like that, like completely amoral and we'll take the user's definition of who is the bad guy?"}, {"time": 5145, "text": "And do we then wanna make them so cheap that all our adversaries can have them?"}, {"time": 5149, "text": "Like what could possibly go wrong?"}, {"time": 5152, "text": "That's I think the big ordeal of the whole thing."}, {"time": 5156, "text": "I think the big argument for why we wanna, this year really put the kibosh on this."}, {"time": 5163, "text": "And I think you can tell there's a lot of very active debate even going on within the US military and undoubtedly in other militaries around the world also about whether we should have some sort of international agreement to at least require that these weapons have to be above a certain size and cost, you know, so that things just don't totally spiral out of control."}, {"time": 5189, "text": "And finally, just for your question, but is it possible to stop it?"}, {"time": 5193, "text": "Because some people tell me, oh, just give up, you know."}, {"time": 5197, "text": "But again, so Matthew Messelsen again from Harvard, right, who the bioweapons hero, he had exactly this criticism also with bioweapons."}, {"time": 5207, "text": "People were like, how can you check for sure that the Russians aren't cheating?"}, {"time": 5212, "text": "And he told me this, I think really ingenious insight."}, {"time": 5218, "text": "He said, you know, Max, some people think you have to have inspections and things and you have to make sure that you can catch the cheaters with 100% chance."}, {"time": 5228, "text": "You don't need 100%, he said."}, {"time": 5230, "text": "1% is usually enough."}, {"time": 5234, "text": "Because if it's another big state, suppose China and the US have signed the treaty drawing a certain line and saying, yeah, these kind of drones are OK, but these fully autonomous ones are not."}, {"time": 5248, "text": "Now suppose you are China and you have cheated and secretly developed some clandestine little thing or you're thinking about doing it."}, {"time": 5257, "text": "What's your calculation that you do?"}, {"time": 5259, "text": "Well, you're like, OK, what's the probability that we're going to get caught?"}, {"time": 5264, "text": "If the probability is 100%, of course, we're not going to do it."}, {"time": 5269, "text": "But if the probability is 5% that we're going to get caught, then it's going to be like a huge embarrassment for us."}, {"time": 5275, "text": "And we still have our nuclear weapons anyway, so it doesn't really make an enormous difference in terms of deterring the US."}, {"time": 5287, "text": "And that feeds the stigma that you kind of established, like this fabric, this universal stigma over the thing."}, {"time": 5295, "text": "It's very reasonable for them to say, well, we probably get away with it."}, {"time": 5298, "text": "If we don't, then the US will know we cheated, and then they're going to go full tilt with their program and say, look, the Chinese are cheaters, and now we have all these weapons against us, and that's bad."}, {"time": 5307, "text": "So the stigma alone is very, very powerful."}, {"time": 5312, "text": "And again, look what happened with bioweapons."}, {"time": 5314, "text": "It's been 50 years now."}, {"time": 5316, "text": "When was the last time you read about a bioterrorism attack?"}, {"time": 5320, "text": "The only deaths I really know about with bioweapons that have happened when we Americans managed to kill some of our own with anthrax, or the idiot who sent them to Tom Daschle and others in letters, right?"}, {"time": 5330, "text": "And similarly in Sverdlovsk in the Soviet Union, they had some anthrax in some lab there."}, {"time": 5337, "text": "Maybe they were cheating or who knows, and it leaked out and killed a bunch of Russians."}, {"time": 5342, "text": "I'd say that's a pretty good success, right?"}, {"time": 5344, "text": "50 years, just two own goals by the superpowers, and then nothing."}, {"time": 5349, "text": "And that's why whenever I ask anyone what they think about biology, they think it's great."}, {"time": 5355, "text": "They associate it with new cures, new diseases, maybe a good vaccine."}, {"time": 5359, "text": "This is how I want to think about AI in the future."}, {"time": 5362, "text": "And I want others to think about AI too, as a source of all these great solutions to our problems, not as, oh, AI, oh yeah, that's the reason I feel scared going outside these days."}, {"time": 5374, "text": "Yeah, it's kind of brilliant that bioweapons and nuclear weapons, we've figured out, I mean, of course there's still a huge source of danger, but we figured out some way of creating rules and social stigma over these weapons that then creates a stability to our, whatever that game theoretic stability that occurs."}, {"time": 5397, "text": "And we don't have that with AI, and you're kind of screaming from the top of the mountain about this, that we need to find that because it's very possible with the future of life, as you point out, Institute Awards pointed out that with nuclear weapons, we could have destroyed ourselves quite a few times."}, {"time": 5421, "text": "And it's a learning experience that is very costly."}, {"time": 5428, "text": "We gave this Future Life Award, we gave it the first time to this guy, Vasily Arkhipov."}, {"time": 5434, "text": "He was on, most people haven't even heard of him."}, {"time": 5437, "text": "Yeah, can you say who he is?"}, {"time": 5438, "text": "Vasily Arkhipov, he has, in my opinion, made the greatest positive contribution to humanity of any human in modern history."}, {"time": 5450, "text": "And maybe it sounds like hyperbole here, like I'm just over the top, but let me tell you the story and I think maybe you'll agree."}, {"time": 5456, "text": "So during the Cuban Missile Crisis, we Americans first didn't know that the Russians had sent four submarines, but we caught two of them."}, {"time": 5466, "text": "And we didn't know that, so we dropped practice depth charges on the one that he was on, try to force it to the surface."}, {"time": 5475, "text": "But we didn't know that this nuclear submarine actually was a nuclear submarine with a nuclear torpedo."}, {"time": 5480, "text": "We also didn't know that they had authorization to launch it without clearance from Moscow."}, {"time": 5485, "text": "And we also didn't know that they were running out of electricity."}, {"time": 5488, "text": "Their batteries were almost dead."}, {"time": 5489, "text": "They were running out of oxygen."}, {"time": 5491, "text": "Sailors were fainting left and right."}, {"time": 5494, "text": "The temperature was about 110, 120 Fahrenheit on board."}, {"time": 5499, "text": "It was really hellish conditions, really just a kind of doomsday."}, {"time": 5503, "text": "And at that point, these giant explosions start happening from the Americans dropping these."}, {"time": 5508, "text": "The captain thought World War III had begun."}, {"time": 5510, "text": "They decided they were gonna launch the nuclear torpedo."}, {"time": 5513, "text": "And one of them shouted, we're all gonna die, but we're not gonna disgrace our Navy."}, {"time": 5518, "text": "We don't know what would have happened if there had been a giant mushroom cloud all of a sudden against the Americans."}, {"time": 5524, "text": "But since everybody had their hands on the triggers, you don't have to be too creative to think that it could have led to an all out nuclear war, in which case we wouldn't be having this conversation now."}, {"time": 5535, "text": "What actually took place was they needed three people to approve this."}, {"time": 5541, "text": "The captain had said yes."}, {"time": 5542, "text": "There was the Communist Party political officer."}, {"time": 5544, "text": "He also said, yes, let's do it."}, {"time": 5546, "text": "And the third man was this guy, Vasily Arkhipov, who said, no."}, {"time": 5549, "text": "For some reason, he was just more chill than the others and he was the right man at the right time."}, {"time": 5554, "text": "I don't want us as a species rely on the right person being there at the right time, you know."}, {"time": 5560, "text": "We tracked down his family living in relative poverty outside Moscow."}, {"time": 5567, "text": "When he flew his daughter, he had passed away and flew them to London."}, {"time": 5572, "text": "They had never been to the West even."}, {"time": 5574, "text": "It was incredibly moving to get to honor them for this."}, {"time": 5577, "text": "The next year we gave them a medal."}, {"time": 5579, "text": "The next year we gave this Future Life Award to Stanislav Petrov."}, {"time": 5584, "text": "Have you heard of him?"}, {"time": 5585, "text": "So he was in charge of the Soviet early warning station, which was built with Soviet technology and honestly not that reliable."}, {"time": 5594, "text": "It said that there were five US missiles coming in."}, {"time": 5598, "text": "Again, if they had launched at that point, we probably wouldn't be having this conversation."}, {"time": 5603, "text": "He decided based on just mainly gut instinct to just not escalate this."}, {"time": 5612, "text": "And I'm very glad he wasn't replaced by an AI that was just automatically following orders."}, {"time": 5617, "text": "And then we gave the third one to Matthew Messelson."}, {"time": 5619, "text": "Last year, we gave this award to these guys who actually use technology for good, not avoiding something bad, but for something good."}, {"time": 5630, "text": "The guys who eliminated this disease, it was way worse than COVID that had killed half a billion people in its final century."}, {"time": 5638, "text": "Smallpox, right?"}, {"time": 5639, "text": "So you mentioned it earlier."}, {"time": 5641, "text": "COVID on average kills less than 1% of people who get it."}, {"time": 5645, "text": "Smallpox, about 30%."}, {"time": 5677, "text": "And as a result, we haven't had any, we went from 15 million deaths the year I was born in smallpox."}, {"time": 5684, "text": "So what do we have in COVID now?"}, {"time": 5685, "text": "A little bit short of 2 million, right?"}, {"time": 5688, "text": "To zero deaths, of course, this year and forever."}, {"time": 5692, "text": "There have been 200 million people, we estimate, who would have died since then by smallpox had it not been for this."}, {"time": 5698, "text": "So isn't science awesome when you use it for good?"}, {"time": 5702, "text": "The reason we wanna celebrate these sort of people is to remind them of this."}, {"time": 5705, "text": "Science is so awesome when you use it for good."}, {"time": 5710, "text": "And those awards actually, the variety there, it's a very interesting picture."}, {"time": 5714, "text": "So the first two are looking at, it's kind of exciting to think that these average humans in some sense, they're products of billions of other humans that came before them, evolution, and some little, you said gut, but there's something in there that stopped the annihilation of the human race."}, {"time": 5741, "text": "And that's a magical thing, but that's like this deeply human thing."}, {"time": 5745, "text": "And then there's the other aspect where that's also very human, which is to build solution to the existential crises that we're facing, like to build it, to take the responsibility and to come up with different technologies and so on."}, {"time": 5760, "text": "And both of those are deeply human, the gut and the mind, whatever that is that creates."}, {"time": 5767, "text": "The best is when they work together."}, {"time": 5768, "text": "Arkhipov, I wish I could have met him, of course, but he had passed away."}, {"time": 5773, "text": "He was really a fantastic military officer, combining all the best traits that we in America admire in our military."}, {"time": 5781, "text": "Because first of all, he was very loyal, of course."}, {"time": 5783, "text": "He never even told anyone about this during his whole life, even though you think he had some bragging rights, right?"}, {"time": 5788, "text": "But he just was like, this is just business, just doing my job."}, {"time": 5791, "text": "It only came out later after his death."}, {"time": 5794, "text": "And second, the reason he did the right thing was not because he was some sort of liberal or some sort of, not because he was just, oh, peace and love."}, {"time": 5807, "text": "It was partly because he had been the captain on another submarine that had a nuclear reactor meltdown."}, {"time": 5813, "text": "And it was his heroism that helped contain this."}, {"time": 5818, "text": "That's why he died of cancer later also."}, {"time": 5819, "text": "But he had seen many of his crew members die."}, {"time": 5821, "text": "And I think for him, that gave him this gut feeling that if there's a nuclear war between the US and the Soviet Union, the whole world is gonna go through what I saw my dear crew members suffer through."}, {"time": 5833, "text": "It wasn't just an abstract thing for him."}, {"time": 5835, "text": "I think it was real."}, {"time": 5837, "text": "And second though, not just the gut, the mind, right?"}, {"time": 5840, "text": "He was, for some reason, very levelheaded personality and very smart guy, which is exactly what we want our best fighter pilots to be also, right?"}, {"time": 5850, "text": "I never forget Neil Armstrong when he's landing on the moon and almost running out of gas."}, {"time": 5854, "text": "And he doesn't even change when they say 30 seconds, he doesn't even change the tone of voice, just keeps going."}, {"time": 5859, "text": "Arkhipov, I think was just like that."}, {"time": 5861, "text": "So when the explosions start going off and his captain is screaming and we should nuke them and all, he's like, I don't think the Americans are trying to sink us."}, {"time": 5874, "text": "I think they're trying to send us a message."}, {"time": 5878, "text": "That's pretty bad ass."}, {"time": 5880, "text": "Coolness, because he said, if they wanted to sink us, and he said, listen, listen, it's alternating one loud explosion on the left, one on the right, one on the left, one on the right."}, {"time": 5892, "text": "He was the only one who noticed this pattern."}, {"time": 5895, "text": "And he's like, I think this is, I'm trying to send us a signal that they want it to surface and they're not gonna sink us."}, {"time": 5905, "text": "And somehow, this is how he then managed it ultimately with his combination of gut and also just cool analytical thinking, was able to deescalate the whole thing."}, {"time": 5920, "text": "And yeah, so this is some of the best in humanity."}, {"time": 5924, "text": "I guess coming back to what we talked about earlier, it's the combination of the neural network, the instinctive, with, I'm getting teary up here, getting emotional, but he was just, he is one of my superheroes, having both the heart and the mind combined."}, {"time": 5940, "text": "And especially in that time, there's something about the, I mean, this is a very, in America, people are used to this kind of idea of being the individual of like on your own thinking."}, {"time": 5952, "text": "I think under, in the Soviet Union under communism, it's actually much harder to do that."}, {"time": 5957, "text": "Oh yeah, he didn't even, he even got, he didn't get any accolades either when he came back for this, right?"}, {"time": 5964, "text": "They just wanted to hush the whole thing up."}, {"time": 5965, "text": "Yeah, there's echoes of that with Chernobyl, there's all kinds of, that's one, that's a really hopeful thing that amidst big centralized powers, whether it's companies or states, there's still the power of the individual to think on their own, to act."}, {"time": 5983, "text": "But I think we need to think of people like this, not as a panacea we can always count on, but rather as a wake up call."}, {"time": 5995, "text": "So because of them, because of Arkhipov, we are alive to learn from this lesson, to learn from the fact that we shouldn't keep playing Russian roulette and almost have a nuclear war by mistake now and then, because relying on luck is not a good longterm strategy."}, {"time": 6009, "text": "If you keep playing Russian roulette over and over again, the probability of surviving just drops exponentially with time."}, {"time": 6015, "text": "And if you have some probability of having an accidental nuke war every year, the probability of not having one also drops exponentially."}, {"time": 6021, "text": "I think we can do better than that."}, {"time": 6022, "text": "So I think the message is very clear, once in a while shit happens, and there's a lot of very concrete things we can do to reduce the risk of things like that happening in the first place."}, {"time": 6036, "text": "On the AI front, if we just link on that for a second."}, {"time": 6040, "text": "So you're friends with, you often talk with Elon Musk throughout history, you've did a lot of interesting things together."}, {"time": 6048, "text": "He has a set of fears about the future of artificial intelligence, AGI."}, {"time": 6097, "text": "Do you have a sense of where his thinking is on this?"}, {"time": 6100, "text": "From my many conversations with Elon, yeah, I certainly have a model of how he thinks."}, {"time": 6107, "text": "It's actually very much like the way I think also, I'll elaborate on it a bit."}, {"time": 6111, "text": "I just wanna push back on when you said evil people, I don't think it's a very helpful concept."}, {"time": 6118, "text": "Evil people, sometimes people do very, very bad things, but they usually do it because they think it's a good thing because somehow other people had told them that that was a good thing or given them incorrect information or whatever, right?"}, {"time": 6135, "text": "I believe in the fundamental goodness of humanity that if we educate people well and they find out how things really are, people generally wanna do good and be good."}, {"time": 6147, "text": "Hence the value alignment, as opposed to it's about information, about knowledge, and then once we have that, we'll likely be able to do good in the way that's aligned with everybody else who thinks differently."}, {"time": 6162, "text": "Yeah, and it's not just the individual people we have to align."}, {"time": 6164, "text": "So we don't just want people to be educated to know the way things actually are and to treat each other well, but we also need to align other nonhuman entities."}, {"time": 6176, "text": "We talked about corporations, there has to be institutions so that what they do is actually good for the country they're in and we should align, make sure that what countries do is actually good for the species as a whole, et cetera."}, {"time": 6187, "text": "Coming back to Elon, yeah, my understanding of how Elon sees this is really quite similar to my own, which is one of the reasons I like him so much and enjoy talking with him so much."}, {"time": 6199, "text": "I feel he's quite different from most people in that he thinks much more than most people about the really big picture, not just what's gonna happen in the next election cycle, but in millennia, millions and billions of years from now."}, {"time": 6216, "text": "And when you look in this more cosmic perspective, it's so obvious that we are gazing out into this universe that as far as we can tell is mostly dead with life being almost imperceptibly tiny perturbation, and he sees this enormous opportunity for our universe to come alive, first to become an interplanetary species."}, {"time": 6236, "text": "Mars is obviously just first stop on this cosmic journey."}, {"time": 6242, "text": "And precisely because he thinks more long term, it's much more clear to him than to most people that what we do with this Russian roulette thing we keep playing with our nukes is a really poor strategy, really reckless strategy."}, {"time": 6256, "text": "And also that we're just building these ever more powerful AI systems that we don't understand is also just a really reckless strategy."}, {"time": 6263, "text": "I feel Elon is very much a humanist in the sense that he wants an awesome future for humanity."}, {"time": 6270, "text": "He wants it to be us that control the machines rather than the machines that control us."}, {"time": 6279, "text": "And why shouldn't we insist on that?"}, {"time": 6282, "text": "We're building them after all, right?"}, {"time": 6284, "text": "Why should we build things that just make us into some little cog in the machinery that has no further say in the matter, right?"}, {"time": 6290, "text": "That's not my idea of an inspiring future either."}, {"time": 6294, "text": "Yeah, if you think on the cosmic scale in terms of both time and space, so much is put into perspective."}, {"time": 6304, "text": "Whenever I have a bad day, that's what I think about."}, {"time": 6306, "text": "It immediately makes me feel better."}, {"time": 6309, "text": "It makes me sad that for us individual humans, at least for now, the ride ends too quickly."}, {"time": 6316, "text": "That we don't get to experience the cosmic scale."}, {"time": 6320, "text": "Yeah, I mean, I think of our universe sometimes as an organism that has only begun to wake up a tiny bit, just like the very first little glimmers of consciousness you have in the morning when you start coming around."}, {"time": 6332, "text": "Before the coffee."}, {"time": 6333, "text": "Before the coffee, even before you get out of bed, before you even open your eyes."}, {"time": 6337, "text": "You start to wake up a little bit."}, {"time": 6340, "text": "There's something here."}, {"time": 6343, "text": "That's very much how I think of where we are."}, {"time": 6347, "text": "All those galaxies out there, I think they're really beautiful, but why are they beautiful?"}, {"time": 6352, "text": "They're beautiful because conscious entities are actually observing them, experiencing them through our telescopes."}, {"time": 6361, "text": "I define consciousness as subjective experience, whether it be colors or emotions or sounds."}, {"time": 6369, "text": "So beauty is an experience."}, {"time": 6372, "text": "Meaning is an experience."}, {"time": 6373, "text": "Purpose is an experience."}, {"time": 6375, "text": "If there was no conscious experience, observing these galaxies, they wouldn't be beautiful."}, {"time": 6380, "text": "If we do something dumb with advanced AI in the future here and Earth originating, life goes extinct."}, {"time": 6389, "text": "And that was it for this."}, {"time": 6390, "text": "If there is nothing else with telescopes in our universe, then it's kind of game over for beauty and meaning and purpose in our whole universe."}, {"time": 6398, "text": "And I think that would be just such an opportunity lost, frankly."}, {"time": 6401, "text": "And I think when Elon points this out, he gets very unfairly maligned in the media for all the dumb media bias reasons we talked about."}, {"time": 6412, "text": "They want to print precisely the things about Elon out of context that are really click baity."}, {"time": 6418, "text": "He has gotten so much flack for this summoning the demon statement."}, {"time": 6424, "text": "I happen to know exactly the context because I was in the front row when he gave that talk."}, {"time": 6429, "text": "It was at MIT, you'll be pleased to know, it was the AeroAstro anniversary."}, {"time": 6433, "text": "They had Buzz Aldrin there from the moon landing, a whole house, a Kresge auditorium packed with MIT students."}, {"time": 6440, "text": "And he had this amazing Q&A, it might've gone for an hour."}, {"time": 6443, "text": "And they talked about rockets and Mars and everything."}, {"time": 6447, "text": "At the very end, this one student who has actually hit my class asked him, what about AI?"}, {"time": 6453, "text": "Elon makes this one comment and they take this out of context, print it, goes viral."}, {"time": 6459, "text": "What is it like with AI, we're summoning the demons, something like that."}, {"time": 6462, "text": "And try to cast him as some sort of doom and gloom dude."}, {"time": 6467, "text": "You know Elon, he's not the doom and gloom dude."}, {"time": 6471, "text": "He is such a positive visionary."}, {"time": 6474, "text": "And the whole reason he warns about this is because he realizes more than most what the opportunity cost is of screwing up."}, {"time": 6479, "text": "That there is so much awesomeness in the future that we can and our descendants can enjoy if we don't screw up, right?"}, {"time": 6487, "text": "I get so pissed off when people try to cast him as some sort of technophobic Luddite."}, {"time": 6495, "text": "And at this point, it's kind of ludicrous when I hear people say that people who worry about artificial general intelligence are Luddites because of course, if you look more closely, you have some of the most outspoken people making warnings are people like Professor Stuart Russell from Berkeley who's written the bestselling AI textbook, you know."}, {"time": 6518, "text": "So claiming that he's a Luddite who doesn't understand AI is the joke is really on the people who said it."}, {"time": 6526, "text": "But I think more broadly, this message is really not sunk in at all."}, {"time": 6530, "text": "What it is that people worry about, they think that Elon and Stuart Russell and others are worried about the dancing robots picking up an AR 15 and going on a rampage, right?"}, {"time": 6544, "text": "They think they're worried about robots turning evil."}, {"time": 6548, "text": "They're not, I'm not."}, {"time": 6550, "text": "The risk is not malice, it's competence."}, {"time": 6555, "text": "The risk is just that we build some systems that are incredibly competent, which means they're always gonna get their goals accomplished, even if they clash with our goals."}, {"time": 6564, "text": "That's the risk."}, {"time": 6565, "text": "Why did we humans drive the West African black rhino extinct?"}, {"time": 6570, "text": "Is it because we're malicious, evil rhinoceros haters?"}, {"time": 6574, "text": "No, it's just because our goals didn't align with the goals of those rhinos and tough luck for the rhinos, you know."}, {"time": 6582, "text": "So the point is just we don't wanna put ourselves in the position of those rhinos creating something more powerful than us if we haven't first figured out how to align the goals."}, {"time": 6593, "text": "And I am optimistic."}, {"time": 6594, "text": "I think we could do it if we worked really hard on it, because I spent a lot of time around intelligent entities that were more intelligent than me, my mom and my dad."}, {"time": 6605, "text": "And I was little and that was fine because their goals were actually aligned with mine quite well."}, {"time": 6611, "text": "But we've seen today many examples of where the goals of our powerful systems are not so aligned."}, {"time": 6617, "text": "So those click through optimization algorithms that are polarized social media, right?"}, {"time": 6624, "text": "They were actually pretty poorly aligned with what was good for democracy, it turned out."}, {"time": 6628, "text": "And again, almost all problems we've had in the machine learning again came so far, not from malice, but from poor alignment."}, {"time": 6635, "text": "And that's exactly why that's why we should be concerned about it in the future."}, {"time": 6639, "text": "Do you think it's possible that with systems like Neuralink and brain computer interfaces, you know, again, thinking of the cosmic scale, Elon's talked about this, but others have as well throughout history of figuring out how the exact mechanism of how to achieve that kind of alignment."}, {"time": 6660, "text": "So one of them is having a symbiosis with AI, which is like coming up with clever ways where we're like stuck together in this weird relationship, whether it's biological or in some kind of other way."}, {"time": 6674, "text": "Do you think that's a possibility of having that kind of symbiosis?"}, {"time": 6679, "text": "Or do we wanna instead kind of focus on this distinct entities of us humans talking to these intelligible, self doubting AIs, maybe like Stuart Russell thinks about it, like we're self doubting and full of uncertainty and our AI systems are full of uncertainty."}, {"time": 6699, "text": "We communicate back and forth and in that way achieve symbiosis."}, {"time": 6706, "text": "I would say that because we don't know for sure what if any of our, which of any of our ideas will work."}, {"time": 6712, "text": "But we do know that if we don't, I'm pretty convinced that if we don't get any of these things to work and just barge ahead, then our species is, you know, probably gonna go extinct this century."}, {"time": 6723, "text": "I think it's..."}, {"time": 6724, "text": "This century, you think like, you think we're facing this crisis is a 21st century crisis."}, {"time": 6731, "text": "Like this century will be remembered."}, {"time": 6733, "text": "But on a hard drive and a hard drive somewhere or maybe by future generations is like, like there'll be future Future of Life Institute awards for people that have done something about AI."}, {"time": 6750, "text": "It could also end even worse, whether we're not superseded by leaving any AI behind either."}, {"time": 6755, "text": "We just totally wipe out, you know, like on Easter Island."}, {"time": 6758, "text": "Our century is long."}, {"time": 6759, "text": "You know, there are still 79 years left of it, right?"}, {"time": 6764, "text": "Think about how far we've come just in the last 30 years."}, {"time": 6767, "text": "So we can talk more about what might go wrong, but you asked me this really good question about what's the best strategy."}, {"time": 6775, "text": "Is it Neuralink or Russell's approach or whatever?"}, {"time": 6779, "text": "I think, you know, when we did the Manhattan project, we didn't know if any of our four ideas for enriching uranium and getting out the uranium 235 were gonna work."}, {"time": 6792, "text": "But we felt this was really important to get it before Hitler did."}, {"time": 6796, "text": "So, you know what we did?"}, {"time": 6797, "text": "We tried all four of them."}, {"time": 6799, "text": "Here, I think it's analogous where there's the greatest threat that's ever faced our species."}, {"time": 6805, "text": "And of course, US national security by implication."}, {"time": 6809, "text": "We don't know if we don't have any method that's guaranteed to work, but we have a lot of ideas."}, {"time": 6814, "text": "So we should invest pretty heavily in pursuing all of them with an open mind and hope that one of them at least works."}, {"time": 6820, "text": "These are, the good news is the century is long, and it might take decades until we have artificial general intelligence."}, {"time": 6830, "text": "So we have some time hopefully, but it takes a long time to solve these very, very difficult problems."}, {"time": 6837, "text": "It's gonna actually be the, it's the most difficult problem we were ever trying to solve as a species."}, {"time": 6841, "text": "So we have to start now."}, {"time": 6843, "text": "So we don't have, rather than begin thinking about it the night before some people who've had too much Red Bull switch it on."}, {"time": 6849, "text": "And we have to, coming back to your question, we have to pursue all of these different avenues and see."}, {"time": 6854, "text": "If you were my investment advisor and I was trying to invest in the future, how do you think the human species is most likely to destroy itself in the century?"}, {"time": 6869, "text": "Yeah, so if the crises, many of the crises we're facing are really before us within the next hundred years, how do we make explicit, make known the unknowns and solve those problems to avoid the biggest, starting with the biggest existential crisis?"}, {"time": 6891, "text": "So as your investment advisor, how are you planning to make money on us destroying ourselves?"}, {"time": 6896, "text": "I have to ask."}, {"time": 6898, "text": "It might be the Russian origins."}, {"time": 6901, "text": "Somehow it's involved."}, {"time": 6902, "text": "At the micro level of detailed strategies, of course, these are unsolved problems."}, {"time": 6908, "text": "For AI alignment, we can break it into three sub problems that are all unsolved."}, {"time": 6913, "text": "I think you want first to make machines understand our goals, then adopt our goals and then retain our goals."}, {"time": 6923, "text": "So to hit on all three real quickly."}, {"time": 6927, "text": "The problem when Andreas Lubitz told his autopilot to fly into the Alps was that the computer didn't even understand anything about his goals."}, {"time": 6939, "text": "It was too dumb."}, {"time": 6940, "text": "It could have understood actually, but you would have had to put some effort in as a systems designer to don't fly into mountains."}, {"time": 6948, "text": "So that's the first challenge."}, {"time": 6949, "text": "How do you program into computers human values, human goals?"}, {"time": 6956, "text": "We can start rather than saying, oh, it's so hard."}, {"time": 6959, "text": "We should start with the simple stuff, as I said, self driving cars, airplanes, just put in all the goals that we all agree on already, and then have a habit of whenever machines get smarter so they can understand one level higher goals, put them into."}, {"time": 6976, "text": "The second challenge is getting them to adopt the goals."}, {"time": 6980, "text": "It's easy for situations like that where you just program it in, but when you have self learning systems like children, you know, any parent knows that there was a difference between getting our kids to understand what we want them to do and to actually adopt our goals, right?"}, {"time": 6997, "text": "With humans, with children, fortunately, they go through this phase."}, {"time": 7004, "text": "First, they're too dumb to understand what we want our goals are."}, {"time": 7006, "text": "And then they have this period of some years when they're both smart enough to understand them and malleable enough that we have a chance to raise them well."}, {"time": 7015, "text": "And then they become teenagers kind of too late."}, {"time": 7019, "text": "But we have this window with machines, the challenges, the intelligence might grow so fast that that window is pretty short."}, {"time": 7026, "text": "So that's a research problem."}, {"time": 7028, "text": "The third one is how do you make sure they keep the goals if they keep learning more and getting smarter?"}, {"time": 7034, "text": "Many sci fi movies are about how you have something in which initially was aligned, but then things kind of go off keel."}, {"time": 7040, "text": "And, you know, my kids were very, very excited about their Legos when they were little."}, {"time": 7047, "text": "Now they're just gathering dust in the basement."}, {"time": 7049, "text": "If we create machines that are really on board with the goal of taking care of humanity, we don't want them to get as bored with us as my kids got with Legos."}, {"time": 7059, "text": "So this is another research challenge."}, {"time": 7061, "text": "How can you make some sort of recursively self improving system retain certain basic goals?"}, {"time": 7067, "text": "That said, a lot of adult people still play with Legos."}, {"time": 7070, "text": "So maybe we succeeded with the Legos."}, {"time": 7072, "text": "Maybe, I like your optimism."}, {"time": 7075, "text": "But above all."}, {"time": 7076, "text": "So not all AI systems have to maintain the goals, right?"}, {"time": 7079, "text": "Just some fraction."}, {"time": 7080, "text": "Yeah, so there's a lot of talented AI researchers now who have heard of this and want to work on it."}, {"time": 7087, "text": "Not so much funding for it yet."}, {"time": 7090, "text": "Of the billions that go into building AI more powerful, it's only a minuscule fraction so far going into this safety research."}, {"time": 7098, "text": "My attitude is generally we should not try to slow down the technology, but we should greatly accelerate the investment in this sort of safety research."}, {"time": 7105, "text": "And also, this was very embarrassing last year, but the NSF decided to give out six of these big institutes."}, {"time": 7113, "text": "We got one of them for AI and science, you asked me about."}, {"time": 7117, "text": "Another one was supposed to be for AI safety research."}, {"time": 7120, "text": "And they gave it to people studying oceans and climate and stuff."}, {"time": 7126, "text": "So I'm all for studying oceans and climates, but we need to actually have some money that actually goes into AI safety research also and doesn't just get grabbed by whatever."}, {"time": 7136, "text": "That's a fantastic investment."}, {"time": 7137, "text": "And then at the higher level, you asked this question, okay, what can we do?"}, {"time": 7142, "text": "What are the biggest risks?"}, {"time": 7145, "text": "I think we cannot just consider this to be only a technical problem."}, {"time": 7151, "text": "Again, because if you solve only the technical problem, can I play with your robot?"}, {"time": 7155, "text": "If we can get our machines to just blindly obey the orders we give them, so we can always trust that it will do what we want."}, {"time": 7166, "text": "That might be great for the owner of the robot."}, {"time": 7168, "text": "That might not be so great for the rest of humanity if that person is that least favorite world leader or whatever you imagine, right?"}, {"time": 7176, "text": "So we have to also take a look at the, apply alignment, not just to machines, but to all the other powerful structures."}, {"time": 7184, "text": "That's why it's so important to strengthen our democracy again, as I said, to have institutions, make sure that the playing field is not rigged so that corporations are given the right incentives to do the things that both make profit and are good for people, to make sure that countries have incentives to do things that are both good for their people and don't screw up the rest of the world."}, {"time": 7206, "text": "And this is not just something for AI nerds to geek out on."}, {"time": 7210, "text": "This is an interesting challenge for political scientists, economists, and so many other thinkers."}, {"time": 7216, "text": "So one of the magical things that perhaps makes this earth quite unique is that it's home to conscious beings."}, {"time": 7228, "text": "So you mentioned consciousness."}, {"time": 7231, "text": "Perhaps as a small aside, because we didn't really get specific to how we might do the alignment."}, {"time": 7239, "text": "Like you said, is there just a really important research problem, but do you think engineering consciousness into AI systems is a possibility, is something that we might one day do, or is there something fundamental to consciousness that is, is there something about consciousness that is fundamental to humans and humans only?"}, {"time": 7264, "text": "I think both consciousness and intelligence are information processing."}, {"time": 7270, "text": "Certain types of information processing."}, {"time": 7273, "text": "And that fundamentally, it doesn't matter whether the information is processed by carbon atoms in the neurons and brains or by silicon atoms and so on in our technology."}, {"time": 7287, "text": "Some people disagree."}, {"time": 7288, "text": "This is what I think as a physicist."}, {"time": 7292, "text": "That consciousness is the same kind of, you said consciousness is information processing."}, {"time": 7297, "text": "So meaning, I think you had a quote of something like it's information knowing itself, that kind of thing."}, {"time": 7307, "text": "I think consciousness is, yeah, is the way information feels when it's being processed."}, {"time": 7311, "text": "One's being put in complex ways."}, {"time": 7313, "text": "We don't know exactly what those complex ways are."}, {"time": 7316, "text": "It's clear that most of the information processing in our brains does not create an experience."}, {"time": 7321, "text": "We're not even aware of it, right?"}, {"time": 7323, "text": "Like for example, you're not aware of your heartbeat regulation right now, even though it's clearly being done by your body, right?"}, {"time": 7330, "text": "It's just kind of doing its own thing."}, {"time": 7332, "text": "When you go jogging, there's a lot of complicated stuff about how you put your foot down and we know it's hard."}, {"time": 7338, "text": "That's why robots used to fall over so much, but you're mostly unaware about it."}, {"time": 7342, "text": "Your brain, your CEO consciousness module just sends an email, hey, I'm gonna keep jogging along this path."}, {"time": 7349, "text": "The rest is on autopilot, right?"}, {"time": 7351, "text": "So most of it is not conscious, but somehow there is some of the information processing, which is we don't know what exactly."}, {"time": 7361, "text": "I think this is a science problem that I hope one day we'll have some equation for or something so we can be able to build a consciousness detector and say, yeah, here there is some consciousness, here there's not."}, {"time": 7373, "text": "Oh, don't boil that lobster because it's feeling pain or it's okay because it's not feeling pain."}, {"time": 7379, "text": "Right now we treat this as sort of just metaphysics, but it would be very useful in emergency rooms to know if a patient has locked in syndrome and is conscious or if they are actually just out."}, {"time": 7394, "text": "And in the future, if you build a very, very intelligent helper robot to take care of you, I think you'd like to know if you should feel guilty about shutting it down or if it's just like a zombie going through the motions like a fancy tape recorder, right?"}, {"time": 7409, "text": "And once we can make progress on the science of consciousness and figure out what is conscious and what isn't, then assuming we want to create positive experiences and not suffering, we'll probably choose to build some machines that are deliberately unconscious that do incredibly boring, repetitive jobs in an iron mine somewhere or whatever."}, {"time": 7439, "text": "And maybe we'll choose to create helper robots for the elderly that are conscious so that people don't just feel creeped out that the robot is just faking it when it acts like it's sad or happy."}, {"time": 7452, "text": "Like you said, elderly, I think everybody gets pretty deeply lonely in this world."}, {"time": 7456, "text": "And so there's a place I think for everybody to have a connection with conscious beings, whether they're human or otherwise."}, {"time": 7464, "text": "But I know for sure that I would, if I had a robot, if I was gonna develop any kind of personal emotional connection with it, I would be very creeped out if I knew it in an intellectual level that the whole thing was just a fraud."}, {"time": 7476, "text": "Now today you can buy a little talking doll for a kid which will say things and the little child will often think that this is actually conscious and even real secrets to it that then go on the internet and with lots of the creepy repercussions."}, {"time": 7492, "text": "I would not wanna be just hacked and tricked like this."}, {"time": 7498, "text": "If I was gonna be developing real emotional connections with the robot, I would wanna know that this is actually real."}, {"time": 7505, "text": "It's acting conscious, acting happy because it actually feels it."}, {"time": 7509, "text": "And I think this is not sci fi."}, {"time": 7511, "text": "I think it's possible to measure, to come up with tools."}, {"time": 7515, "text": "After we understand the science of consciousness, you're saying we'll be able to come up with tools that can measure consciousness and definitively say like this thing is experiencing the things it says it's experiencing."}, {"time": 7527, "text": "Kind of by definition."}, {"time": 7528, "text": "If it is a physical phenomenon, information processing and we know that some information processing is conscious and some isn't, well, then there is something there to be discovered with the methods of science."}, {"time": 7538, "text": "Giulio Tononi has stuck his neck out the farthest and written down some equations for a theory."}, {"time": 7543, "text": "Maybe that's right, maybe it's wrong."}, {"time": 7545, "text": "We certainly don't know."}, {"time": 7546, "text": "But I applaud that kind of efforts to sort of take this, say this is not just something that philosophers can have beer and muse about, but something we can measure and study."}, {"time": 7558, "text": "And coming, bringing that back to us, I think what we would probably choose to do, as I said, is if we cannot figure this out, choose to make, to be quite mindful about what sort of consciousness, if any, we put in different machines that we have."}, {"time": 7576, "text": "And certainly, we wouldn't wanna make, we should not be making much machines that suffer without us even knowing it, right?"}, {"time": 7583, "text": "And if at any point someone decides to upload themselves like Ray Kurzweil wants to do, I don't know if you've had him on your show."}, {"time": 7591, "text": "We agree, but then COVID happens, so we're waiting it out a little bit."}, {"time": 7594, "text": "Suppose he uploads himself into this robo Ray and it talks like him and acts like him and laughs like him."}, {"time": 7602, "text": "And before he powers off his biological body, he would probably be pretty disturbed if he realized that there's no one home."}, {"time": 7609, "text": "This robot is not having any subjective experience, right?"}, {"time": 7613, "text": "If humanity gets replaced by machine descendants, which do all these cool things and build spaceships and go to intergalactic rock concerts, and it turns out that they are all unconscious, just going through the motions, wouldn't that be like the ultimate zombie apocalypse, right?"}, {"time": 7636, "text": "Just a play for empty benches?"}, {"time": 7638, "text": "Yeah, I have a sense that there's some kind of, once we understand consciousness better, we'll understand that there's some kind of continuum and it would be a greater appreciation."}, {"time": 7648, "text": "And we'll probably understand, just like you said, it'd be unfortunate if it's a trick."}, {"time": 7652, "text": "We'll probably definitely understand that love is indeed a trick that we'll play on each other, that we humans are, we convince ourselves we're conscious, but we're really, us and trees and dolphins are all the same kind of consciousness."}, {"time": 7666, "text": "Can I try to cheer you up a little bit with a philosophical thought here about the love part?"}, {"time": 7670, "text": "Yes, let's do it."}, {"time": 7671, "text": "You know, you might say, okay, yeah, love is just a collaboration enabler."}, {"time": 7678, "text": "And then maybe you can go and get depressed about that."}, {"time": 7681, "text": "But I think that would be the wrong conclusion, actually."}, {"time": 7684, "text": "You know, I know that the only reason I enjoy food is because my genes hacked me and they don't want me to starve to death."}, {"time": 7693, "text": "Not because they care about me consciously enjoying succulent delights of pistachio ice cream, but they just want me to make copies of them."}, {"time": 7703, "text": "The whole thing, so in a sense, the whole enjoyment of food is also a scam like this."}, {"time": 7708, "text": "But does that mean I shouldn't take pleasure in this pistachio ice cream?"}, {"time": 7712, "text": "I love pistachio ice cream."}, {"time": 7714, "text": "And I can tell you, I know this is an experimental fact."}, {"time": 7718, "text": "I enjoy pistachio ice cream every bit as much, even though I scientifically know exactly why, what kind of scam this was."}, {"time": 7726, "text": "Your genes really appreciate that you like the pistachio ice cream."}, {"time": 7730, "text": "Well, but I, my mind appreciates it too, you know?"}, {"time": 7733, "text": "And I have a conscious experience right now."}, {"time": 7735, "text": "Ultimately, all of my brain is also just something the genes built to copy themselves."}, {"time": 7741, "text": "You know, I'm grateful that, yeah, thanks genes for doing this, but you know, now it's my brain that's in charge here and I'm gonna enjoy my conscious experience, thank you very much."}, {"time": 7750, "text": "And not just the pistachio ice cream, but also the love I feel for my amazing wife and all the other delights of being conscious."}, {"time": 7759, "text": "I don't, actually Richard Feynman, I think said this so well."}, {"time": 7765, "text": "He is also the guy, you know, really got me into physics."}, {"time": 7769, "text": "Some art friend said that, oh, science kind of just is the party pooper."}, {"time": 7774, "text": "It's kind of ruins the fun, right?"}, {"time": 7776, "text": "When like you have a beautiful flowers as the artist and then the scientist is gonna deconstruct that into just a blob of quarks and electrons."}, {"time": 7784, "text": "And Feynman pushed back on that in such a beautiful way, which I think also can be used to push back and make you not feel guilty about falling in love."}, {"time": 7793, "text": "So here's what Feynman basically said."}, {"time": 7795, "text": "He said to his friend, you know, yeah, I can also as a scientist see that this is a beautiful flower, thank you very much."}, {"time": 7800, "text": "Maybe I can't draw as good a painting as you because I'm not as talented an artist, but yeah, I can really see the beauty in it."}, {"time": 7806, "text": "And it just, it also looks beautiful to me."}, {"time": 7809, "text": "But in addition to that, Feynman said, as a scientist, I see even more beauty that the artist did not see, right?"}, {"time": 7816, "text": "Suppose this is a flower on a blossoming apple tree."}, {"time": 7821, "text": "You could say this tree has more beauty in it than just the colors and the fragrance."}, {"time": 7826, "text": "This tree is made of air, Feynman wrote."}, {"time": 7829, "text": "This is one of my favorite Feynman quotes ever."}, {"time": 7831, "text": "And it took the carbon out of the air and bound it in using the flaming heat of the sun, you know, to turn the air into a tree."}, {"time": 7838, "text": "And when you burn logs in your fireplace, it's really beautiful to think that this is being reversed."}, {"time": 7845, "text": "Now the tree is going, the wood is going back into air."}, {"time": 7848, "text": "And in this flaming, beautiful dance of the fire that the artist can see is the flaming light of the sun that was bound in to turn the air into tree."}, {"time": 7859, "text": "And then the ashes is the little residue that didn't come from the air that the tree sucked out of the ground, you know."}, {"time": 7864, "text": "Feynman said, these are beautiful things."}, {"time": 7866, "text": "And science just adds, it doesn't subtract."}, {"time": 7870, "text": "And I feel exactly that way about love and about pistachio ice cream also."}, {"time": 7876, "text": "I can understand that there is even more nuance to the whole thing, right?"}, {"time": 7880, "text": "At this very visceral level, you can fall in love just as much as someone who knows nothing about neuroscience."}, {"time": 7887, "text": "But you can also appreciate this even greater beauty in it."}, {"time": 7891, "text": "Just like, isn't it remarkable that it came about from this completely lifeless universe, just a bunch of hot blob of plasma expanding."}, {"time": 7903, "text": "And then over the eons, you know, gradually, first the strong nuclear force decided to combine quarks together into nuclei."}, {"time": 7910, "text": "And then the electric force bound in electrons and made atoms."}, {"time": 7913, "text": "And then they clustered from gravity and you got planets and stars and this and that."}, {"time": 7917, "text": "And then natural selection came along and the genes had their little thing."}, {"time": 7921, "text": "And you started getting what went from seeming like a completely pointless universe that we're just trying to increase entropy and approach heat death into something that looked more goal oriented."}, {"time": 7931, "text": "Isn't that kind of beautiful?"}, {"time": 7933, "text": "And then this goal orientedness through evolution got ever more sophisticated where you got ever more."}, {"time": 7938, "text": "And then you started getting this thing, which is kind of like DeepMind's mu zero and steroids, the ultimate self play is not what DeepMind's AI does against itself to get better at go."}, {"time": 7952, "text": "It's what all these little quark blobs did against each other in the game of survival of the fittest."}, {"time": 7958, "text": "Now, when you had really dumb bacteria living in a simple environment, there wasn't much incentive to get intelligent, but then the life made environment more complex."}, {"time": 7970, "text": "And then there was more incentive to get even smarter."}, {"time": 7973, "text": "And that gave the other organisms more of incentive to also get smarter."}, {"time": 7977, "text": "And then here we are now, just like mu zero learned to become world master at go and chess from playing against itself by just playing against itself."}, {"time": 7988, "text": "All the quirks here on our planet, the electrons have created giraffes and elephants and humans and love."}, {"time": 7997, "text": "I just find that really beautiful."}, {"time": 8000, "text": "And to me, that just adds to the enjoyment of love."}, {"time": 8004, "text": "It doesn't subtract anything."}, {"time": 8005, "text": "Do you feel a little more careful now?"}, {"time": 8007, "text": "I feel way better, that was incredible."}, {"time": 8010, "text": "So this self play of quirks, taking back to the beginning of our conversation a little bit, there's so many exciting possibilities about artificial intelligence understanding the basic laws of physics."}, {"time": 8024, "text": "Do you think AI will help us unlock?"}, {"time": 8027, "text": "There's been quite a bit of excitement throughout the history of physics of coming up with more and more general simple laws that explain the nature of our reality."}, {"time": 8038, "text": "And then the ultimate of that would be a theory of everything that combines everything together."}, {"time": 8043, "text": "Do you think it's possible that one, we humans, but perhaps AI systems will figure out a theory of physics that unifies all the laws of physics?"}, {"time": 8057, "text": "Yeah, I think it's absolutely possible."}, {"time": 8059, "text": "I think it's very clear that we're gonna see a great boost to science."}, {"time": 8064, "text": "We're already seeing a boost actually from machine learning helping science."}, {"time": 8068, "text": "Alpha fold was an example, the decades old protein folding problem."}, {"time": 8074, "text": "So, and gradually, yeah, unless we go extinct by doing something dumb like we discussed, I think it's very likely that our understanding of physics will become so good that our technology will no longer be limited by human intelligence, but instead be limited by the laws of physics."}, {"time": 8098, "text": "So our tech today is limited by what we've been able to invent, right?"}, {"time": 8102, "text": "I think as AI progresses, it'll just be limited by the speed of light and other physical limits, which would mean it's gonna be just dramatically beyond where we are now."}, {"time": 8115, "text": "Do you think it's a fundamentally mathematical pursuit of trying to understand like the laws of our universe from a mathematical perspective?"}, {"time": 8125, "text": "So almost like if it's AI, it's exploring the space of like theorems and those kinds of things, or is there some other more computational ideas, more sort of empirical ideas?"}, {"time": 8141, "text": "They're both, I would say."}, {"time": 8143, "text": "It's really interesting to look out at the landscape of everything we call science today."}, {"time": 8148, "text": "So here you come now with this big new hammer."}, {"time": 8150, "text": "It says machine learning on it and that's, you know, where are there some nails that you can help with here that you can hammer?"}, {"time": 8156, "text": "Ultimately, if machine learning gets the point that it can do everything better than us, it will be able to help across the whole space of science."}, {"time": 8166, "text": "But maybe we can anchor it by starting a little bit right now near term and see how we kind of move forward."}, {"time": 8171, "text": "So like right now, first of all, you have a lot of big data science, right?"}, {"time": 8177, "text": "Where, for example, with telescopes, we are able to collect way more data every hour than a grad student can just pour over like in the old times, right?"}, {"time": 8188, "text": "And machine learning is already being used very effectively, even at MIT, to find planets around other stars, to detect exciting new signatures of new particle physics in the sky, to detect the ripples in the fabric of space time that we call gravitational waves caused by enormous black holes crashing into each other halfway across the observable universe."}, {"time": 8209, "text": "Machine learning is running and ticking right now, doing all these things, and it's really helping all these experimental fields."}, {"time": 8218, "text": "There is a separate front of physics, computational physics, which is getting an enormous boost also."}, {"time": 8225, "text": "So we had to do all our computations by hand, right?"}, {"time": 8229, "text": "People would have these giant books with tables of logarithms, and oh my God, it pains me to even think how long time it would have taken to do simple stuff."}, {"time": 8239, "text": "Then we started to get little calculators and computers that could do some basic math for us."}, {"time": 8246, "text": "Now, what we're starting to see is kind of a shift from GOFI, computational physics, to neural network, computational physics."}, {"time": 8260, "text": "What I mean by that is most computational physics would be done by humans programming in the intelligence of how to do the computation into the computer."}, {"time": 8272, "text": "Just as when Garry Kasparov got his posterior kicked by IBM's Deep Blue in chess, humans had programmed in exactly how to play chess."}, {"time": 8279, "text": "Intelligence came from the humans."}, {"time": 8281, "text": "It wasn't learned, right?"}, {"time": 8283, "text": "Mu zero can be not only Kasparov in chess, but also Stockfish, which is the best sort of GOFI chess program."}, {"time": 8292, "text": "By learning, and we're seeing more of that now, that shift beginning to happen in physics."}, {"time": 8298, "text": "So let me give you an example."}, {"time": 8300, "text": "So lattice QCD is an area of physics whose goal is basically to take the periodic table and just compute the whole thing from first principles."}, {"time": 8311, "text": "This is not the search for theory of everything."}, {"time": 8313, "text": "We already know the theory that's supposed to produce as output the periodic table, which atoms are stable, how heavy they are, all that good stuff, their spectral lines."}, {"time": 8325, "text": "It's a theory, lattice QCD, you can put it on your tshirt."}, {"time": 8330, "text": "Our colleague Frank Wilczek got the Nobel Prize for working on it."}, {"time": 8334, "text": "But the math is just too hard for us to solve."}, {"time": 8336, "text": "We have not been able to start with these equations and solve them to the extent that we can predict, oh yeah."}, {"time": 8341, "text": "And then there is carbon, and this is what the spectrum of the carbon atom looks like."}, {"time": 8347, "text": "But awesome people are building these supercomputer simulations where you just put in these equations and you make a big cubic lattice of space, or actually it's a very small lattice because you're going down to the subatomic scale, and you try to solve it."}, {"time": 8366, "text": "But it's just so computationally expensive that we still haven't been able to calculate things as accurately as we measure them in many cases."}, {"time": 8374, "text": "And now machine learning is really revolutionizing this."}, {"time": 8377, "text": "So my colleague Fiala Shanahan at MIT, for example, she's been using this really cool machine learning technique called normalizing flows, where she's realized she can actually speed up the calculation dramatically by having the AI learn how to do things faster."}, {"time": 8395, "text": "Another area like this where we suck up an enormous amount of supercomputer time to do physics is black hole collisions."}, {"time": 8405, "text": "So now that we've done the sexy stuff of detecting a bunch of this with LIGO and other experiments, we want to be able to know what we're seeing."}, {"time": 8413, "text": "And so it's a very simple conceptual problem."}, {"time": 8416, "text": "It's the two body problem."}, {"time": 8419, "text": "Newton solved it for classical gravity hundreds of years ago, but the two body problem is still not fully solved."}, {"time": 8426, "text": "For black holes."}, {"time": 8426, "text": "Black holes, yes, and Einstein's gravity because they won't just orbit in space, they won't just orbit each other forever anymore, two things, they give off gravitational waves and make sure they crash into each other."}, {"time": 8437, "text": "And the game, what you want to do is you want to figure out, okay, what kind of wave comes out as a function of the masses of the two black holes, as a function of how they're spinning, relative to each other, et cetera."}, {"time": 8450, "text": "And that is so hard."}, {"time": 8452, "text": "It can take months of supercomputer time and massive numbers of cores to do it."}, {"time": 8456, "text": "Now, wouldn't it be great if you can use machine learning to greatly speed that up, right?"}, {"time": 8464, "text": "Now you can use the expensive old GoFi calculation as the truth, and then see if machine learning can figure out a smarter, faster way of getting the right answer."}, {"time": 8476, "text": "Yet another area, like computational physics."}, {"time": 8480, "text": "These are probably the big three that suck up the most computer time."}, {"time": 8484, "text": "Lattice QCD, black hole collisions, and cosmological simulations, where you take not a subatomic thing and try to figure out the mass of the proton, but you take something enormous and try to look at how all the galaxies get formed in there."}, {"time": 8501, "text": "There again, there are a lot of very cool ideas right now about how you can use machine learning to do this sort of stuff better."}, {"time": 8509, "text": "The difference between this and the big data is you kind of make the data yourself, right?"}, {"time": 8514, "text": "So, and then finally, we're looking over the physics landscape and seeing what can we hammer with machine learning, right?"}, {"time": 8522, "text": "So we talked about experimental data, big data, discovering cool stuff that we humans then look more closely at."}, {"time": 8529, "text": "Then we talked about taking the expensive computations we're doing now and figuring out how to do them much faster and better with AI."}, {"time": 8538, "text": "And finally, let's go really theoretical."}, {"time": 8541, "text": "So things like discovering equations, having deep fundamental insights, this is something closest to what I've been doing in my group."}, {"time": 8553, "text": "We talked earlier about the whole AI Feynman project, where if you just have some data, how do you automatically discover equations that seem to describe this well, that you can then go back as a human and then work with and test and explore."}, {"time": 8566, "text": "And you asked a really good question also about if this is sort of a search problem in some sense."}, {"time": 8574, "text": "That's very deep actually what you said, because it is."}, {"time": 8576, "text": "Suppose I ask you to prove some mathematical theorem."}, {"time": 8581, "text": "What is a proof in math?"}, {"time": 8582, "text": "It's just a long string of steps, logical steps that you can write out with symbols."}, {"time": 8587, "text": "And once you find it, it's very easy to write a program to check whether it's a valid proof or not."}, {"time": 8594, "text": "So why is it so hard to prove it?"}, {"time": 8596, "text": "Well, because there are ridiculously many possible candidate proofs you could write down, right?"}, {"time": 8601, "text": "If the proof contains 10,000 symbols, even if there were only 10 options for what each symbol could be, that's 10 to the power of 1,000 possible proofs, which is way more than there are atoms in our universe."}, {"time": 8616, "text": "So you could say it's trivial to prove these things."}, {"time": 8618, "text": "You just write a computer, generate all strings, and then check, is this a valid proof?"}, {"time": 8624, "text": "Is this a valid proof?"}, {"time": 8627, "text": "And then you just keep doing this forever."}, {"time": 8631, "text": "But there are a lot of, but it is fundamentally a search problem."}, {"time": 8635, "text": "You just want to search the space of all those, all strings of symbols to find one that is the proof, right?"}, {"time": 8643, "text": "And there's a whole area of machine learning called search."}, {"time": 8648, "text": "How do you search through some giant space to find the needle in the haystack?"}, {"time": 8652, "text": "And it's easier in cases where there's a clear measure of good, like you're not just right or wrong, but this is better and this is worse, so you can maybe get some hints as to which direction to go in."}, {"time": 8663, "text": "That's why we talked about neural networks work so well."}, {"time": 8668, "text": "I mean, that's such a human thing of that moment of genius of figuring out the intuition of good, essentially."}, {"time": 8677, "text": "I mean, we thought that that was... Or is it?"}, {"time": 8680, "text": "Maybe it's not, right?"}, {"time": 8681, "text": "We thought that about chess, right?"}, {"time": 8682, "text": "That the ability to see like 10, 15, sometimes 20 steps ahead was not a calculation that humans were performing."}, {"time": 8691, "text": "It was some kind of weird intuition about different patterns, about board positions, about the relative positions, somehow stitching stuff together."}, {"time": 8701, "text": "And a lot of it is just like intuition, but then you have like alpha, I guess zero be the first one that did the self play."}, {"time": 8710, "text": "It just came up with this."}, {"time": 8712, "text": "It was able to learn through self play mechanism, this kind of intuition."}, {"time": 8716, "text": "But just like you said, it's so fascinating to think, well, they're in the space of totally new ideas."}, {"time": 8724, "text": "Can that be done in developing theorems?"}, {"time": 8728, "text": "We know it can be done by neural networks because we did it with the neural networks in the craniums of the great mathematicians of humanity."}, {"time": 8736, "text": "And I'm so glad you brought up alpha zero because that's the counter example."}, {"time": 8739, "text": "It turned out we were flattering ourselves when we said intuition is something different."}, {"time": 8745, "text": "Only humans can do it."}, {"time": 8746, "text": "It's not information processing."}, {"time": 8750, "text": "It used to be that way."}, {"time": 8753, "text": "Again, it's really instructive, I think, to compare the chess computer Deep Blue that beat Kasparov with alpha zero that beat Lisa Dahl at Go."}, {"time": 8764, "text": "Because for Deep Blue, there was no intuition."}, {"time": 8768, "text": "There was some, humans had programmed in some intuition."}, {"time": 8772, "text": "After humans had played a lot of games, they told the computer, count the pawn as one point, the bishop is three points, rook is five points, and so on, you add it all up, and then you add some extra points for past pawns and subtract if the opponent has it and blah, blah, blah."}, {"time": 8788, "text": "And then what Deep Blue did was just search."}, {"time": 8792, "text": "Just very brute force and tried many, many moves ahead, all these combinations and a prune tree search."}, {"time": 8797, "text": "And it could think much faster than Kasparov, and it won."}, {"time": 8802, "text": "And that, I think, inflated our egos in a way it shouldn't have, because people started to say, yeah, yeah, it's just brute force search, but it has no intuition."}, {"time": 8812, "text": "Alpha zero really popped our bubble there, because what alpha zero does, yes, it does also do some of that tree search, but it also has this intuition module, which in geek speak is called a value function, where it just looks at the board and comes up with a number for how good is that position."}, {"time": 8834, "text": "The difference was no human told it how good the position is, it just learned it."}, {"time": 8842, "text": "And mu zero is the coolest or scariest of all, depending on your mood, because the same basic AI system will learn what the good board position is, regardless of whether it's chess or Go or Shogi or Pacman or Lady Pacman or Breakout or Space Invaders or any number, a bunch of other games."}, {"time": 8865, "text": "You don't tell it anything, and it gets this intuition after a while for what's good."}, {"time": 8869, "text": "So this is very hopeful for science, I think, because if it can get intuition for what's a good position there, maybe it can also get intuition for what are some good directions to go if you're trying to prove something."}, {"time": 8883, "text": "I often, one of the most fun things in my science career is when I've been able to prove some theorem about something and it's very heavily intuition guided, of course."}, {"time": 8892, "text": "I don't sit and try all random strings."}, {"time": 8894, "text": "I have a hunch that, you know, this reminds me a little bit of about this other proof I've seen for this thing."}, {"time": 8899, "text": "So maybe I first, what if I try this?"}, {"time": 8902, "text": "Nah, that didn't work out."}, {"time": 8904, "text": "But this reminds me actually, the way this failed reminds me of that."}, {"time": 8908, "text": "So combining the intuition with all these brute force capabilities, I think it's gonna be able to help physics too."}, {"time": 8918, "text": "Do you think there'll be a day when an AI system being the primary contributor, let's say 90% plus, wins the Nobel Prize in physics?"}, {"time": 8930, "text": "Obviously they'll give it to the humans because we humans don't like to give prizes to machines."}, {"time": 8934, "text": "It'll give it to the humans behind the system."}, {"time": 8937, "text": "You could argue that AI has already been involved in some Nobel Prizes, probably, maybe something with black holes and stuff like that."}, {"time": 8943, "text": "Yeah, we don't like giving prizes to other life forms."}, {"time": 8947, "text": "If someone wins a horse racing contest, they don't give the prize to the horse either."}, {"time": 8953, "text": "But do you think that we might be able to see something like that in our lifetimes when AI, so like the first system I would say that makes us think about a Nobel Prize seriously is like Alpha Fold is making us think about in medicine, physiology, a Nobel Prize, perhaps discoveries that are direct result of something that's discovered by Alpha Fold."}, {"time": 8976, "text": "Do you think in physics we might be able to see that in our lifetimes?"}, {"time": 8981, "text": "I think what's probably gonna happen is more of a blurring of the distinctions."}, {"time": 8986, "text": "So today if somebody uses a computer to do a computation that gives them the Nobel Prize, nobody's gonna dream of giving the prize to the computer."}, {"time": 8997, "text": "They're gonna be like, that was just a tool."}, {"time": 8999, "text": "I think for these things also, people are just gonna for a long time view the computer as a tool."}, {"time": 9006, "text": "But what's gonna change is the ubiquity of machine learning."}, {"time": 9011, "text": "I think at some point in my lifetime, finding a human physicist who knows nothing about machine learning is gonna be almost as hard as it is today finding a human physicist who doesn't says, oh, I don't know anything about computers or I don't use math."}, {"time": 9030, "text": "That would just be a ridiculous concept."}, {"time": 9034, "text": "You see, but the thing is there is a magic moment though, like with Alpha Zero, when the system surprises us in a way where the best people in the world truly learn something from the system in a way where you feel like it's another entity."}, {"time": 9052, "text": "Like the way people, the way Magnus Carlsen, the way certain people are looking at the work of Alpha Zero, it's like, it truly is no longer a tool in the sense that it doesn't feel like a tool."}, {"time": 9066, "text": "It feels like some other entity."}, {"time": 9068, "text": "So there's a magic difference like where you're like, if an AI system is able to come up with an insight that surprises everybody in some like major way that's a phase shift in our understanding of some particular science or some particular aspect of physics, I feel like that is no longer a tool."}, {"time": 9092, "text": "And then you can start to say that like it perhaps deserves the prize."}, {"time": 9098, "text": "So for sure, the more important and the more fundamental transformation of the 21st century science is exactly what you're saying, which is probably everybody will be doing machine learning."}, {"time": 9110, "text": "It's to some degree."}, {"time": 9111, "text": "Like if you want to be successful at unlocking the mysteries of science, you should be doing machine learning."}, {"time": 9118, "text": "But it's just exciting to think about like, whether there'll be one that comes along that's super surprising and they'll make us question like who the real inventors are in this world."}, {"time": 9131, "text": "Yeah, I think the question of, isn't if it's gonna happen, but when?"}, {"time": 9135, "text": "And, but it's important."}, {"time": 9137, "text": "Honestly, in my mind, the time when that happens is also more or less the same time when we get artificial general intelligence."}, {"time": 9145, "text": "And then we have a lot bigger things to worry about than whether we should get the Nobel prize or not, right?"}, {"time": 9151, "text": "Because when you have machines that can outperform our best scientists at science, they can probably outperform us at a lot of other stuff as well, which can at a minimum make them incredibly powerful agents in the world."}, {"time": 9169, "text": "And I think it's a mistake to think we only have to start worrying about loss of control when machines get to AGI across the board, where they can do everything, all our jobs."}, {"time": 9182, "text": "Long before that, they'll be hugely influential."}, {"time": 9187, "text": "We talked at length about how the hacking of our minds with algorithms trying to get us glued to our screens, right, has already had a big impact on society."}, {"time": 9202, "text": "That was an incredibly dumb algorithm in the grand scheme of things, right?"}, {"time": 9205, "text": "The supervised machine learning, yet that had huge impact."}, {"time": 9209, "text": "So I just don't want us to be lulled into false sense of security and think there won't be any societal impact until things reach human level, because it's happening already."}, {"time": 9218, "text": "And I was just thinking the other week, when I see some scaremonger going, oh, the robots are coming, the implication is always that they're coming to kill us."}, {"time": 9231, "text": "And maybe you should have worried about that if you were in Nagorno Karabakh during the recent war there."}, {"time": 9235, "text": "But more seriously, the robots are coming right now, but they're mainly not coming to kill us."}, {"time": 9243, "text": "They're coming to hack us."}, {"time": 9246, "text": "They're coming to hack our minds, into buying things that maybe we didn't need, to vote for people who may not have our best interest in mind."}, {"time": 9255, "text": "And it's kind of humbling, I think, actually, as a human being to admit that it turns out that our minds are actually much more hackable than we thought."}, {"time": 9264, "text": "And the ultimate insult is that we are actually getting hacked by the machine learning algorithms that are, in some objective sense, much dumber than us, you know?"}, {"time": 9273, "text": "But maybe we shouldn't be so surprised because, you know, how do you feel about cute puppies?"}, {"time": 9280, "text": "Love them."}, {"time": 9281, "text": "So, you know, you would probably argue that in some across the board measure, you're more intelligent than they are, but boy, are cute puppies good at hacking us, right?"}, {"time": 9291, "text": "They move into our house, persuade us to feed them and do all these things."}, {"time": 9294, "text": "And what do they ever do but for us?"}, {"time": 9297, "text": "Other than being cute and making us feel good, right?"}, {"time": 9300, "text": "So if puppies can hack us, maybe we shouldn't be so surprised if pretty dumb machine learning algorithms can hack us too."}, {"time": 9309, "text": "Not to speak of cats, which is another level."}, {"time": 9311, "text": "And I think we should, to counter your previous point about there, let us not think about evil creatures in this world."}, {"time": 9318, "text": "We can all agree that cats are as close to objective evil as we can get."}, {"time": 9322, "text": "But that's just me saying that."}, {"time": 9324, "text": "Okay, so you have."}, {"time": 9325, "text": "Have you seen the cartoon?"}, {"time": 9327, "text": "I think it's maybe the onion with this incredibly cute kitten."}, {"time": 9333, "text": "And it just says, it's underneath something that thinks about murder all day."}, {"time": 9343, "text": "You've mentioned offline that there might be a link between post biological AGI and SETI."}, {"time": 9347, "text": "So last time we talked, you've talked about this intuition that we humans might be quite unique in our galactic neighborhood."}, {"time": 9362, "text": "Perhaps our galaxy, perhaps the entirety of the observable universe who might be the only intelligent civilization here, which is, and you argue pretty well for that thought."}, {"time": 9377, "text": "So I have a few little questions around this."}, {"time": 9381, "text": "One, the scientific question, in which way would you be, if you were wrong in that intuition, in which way do you think you would be surprised?"}, {"time": 9396, "text": "Like why were you wrong?"}, {"time": 9398, "text": "We find out that you ended up being wrong."}, {"time": 9401, "text": "Like in which dimension?"}, {"time": 9403, "text": "So like, is it because we can't see them?"}, {"time": 9408, "text": "Is it because the nature of their intelligence or the nature of their life is totally different than we can possibly imagine?"}, {"time": 9416, "text": "Is it because the, I mean, something about the great filters and surviving them, or maybe because we're being protected from signals, all those explanations for why we haven't heard a big, loud, like red light that says we're here."}, {"time": 9441, "text": "So there are actually two separate things there that I could be wrong about, two separate claims that I made, right?"}, {"time": 9448, "text": "One of them is, I made the claim, I think most civilizations, when you're going from simple bacteria like things to space colonizing civilizations, they spend only a very, very tiny fraction of their life being where we are."}, {"time": 9475, "text": "That I could be wrong about."}, {"time": 9477, "text": "The other one I could be wrong about is the quite different statement that I think that actually I'm guessing that we are the only civilization in our observable universe from which light has reached us so far that's actually gotten far enough to invent telescopes."}, {"time": 9492, "text": "So let's talk about maybe both of them in turn because they really are different."}, {"time": 9495, "text": "The first one, if you look at the N equals one, the data point we have on this planet, right?"}, {"time": 9502, "text": "So we spent four and a half billion years fluxing around on this planet with life, right?"}, {"time": 9508, "text": "We got, and most of it was pretty lame stuff from an intelligence perspective, you know, it was bacteria and then the dinosaurs spent, then the things gradually accelerated, right?"}, {"time": 9521, "text": "Then the dinosaurs spent over a hundred million years stomping around here without even inventing smartphones."}, {"time": 9526, "text": "And then very recently, you know, it's only, we've only spent 400 years going from Newton to us, right?"}, {"time": 9535, "text": "In terms of technology."}, {"time": 9536, "text": "And look what we've done even, you know, when I was a little kid, there was no internet even."}, {"time": 9542, "text": "So it's, I think it's pretty likely for, in this case of this planet, right?"}, {"time": 9548, "text": "That we're either gonna really get our act together and start spreading life into space, the century, and doing all sorts of great things, or we're gonna wipe out."}, {"time": 9558, "text": "It's a little hard."}, {"time": 9560, "text": "If I, I could be wrong in the sense that maybe what happened on this earth is very atypical."}, {"time": 9565, "text": "And for some reason, what's more common on other planets is that they spend an enormously long time futzing around with the ham radio and things, but they just never really take it to the next level for reasons I don't, I haven't understood."}, {"time": 9578, "text": "I'm humble and open to that."}, {"time": 9580, "text": "But I would bet at least 10 to one that our situation is more typical because the whole thing with Moore's law and accelerating technology, it's pretty obvious why it's happening."}, {"time": 9591, "text": "Everything that grows exponentially, we call it an explosion, whether it's a population explosion or a nuclear explosion, it's always caused by the same thing."}, {"time": 9598, "text": "It's that the next step triggers a step after that."}, {"time": 9601, "text": "So I, we, tomorrow's technology, today's technology enables tomorrow's technology and that enables the next level."}, {"time": 9609, "text": "And as I think, because the technology is always better, of course, the steps can come faster and faster."}, {"time": 9617, "text": "On the other question that I might be wrong about, that's the much more controversial one, I think."}, {"time": 9622, "text": "But before we close out on this thing about, if, the first one, if it's true that most civilizations spend only a very short amount of their total time in the stage, say, between inventing telescopes or mastering electricity and leaving there and doing space travel, if that's actually generally true, then that should apply also elsewhere out there."}, {"time": 9649, "text": "So we should be very, very, we should be very, very surprised if we find some random civilization and we happen to catch them exactly in that very, very short stage."}, {"time": 9658, "text": "It's much more likely that we find a planet full of bacteria."}, {"time": 9662, "text": "Or that we find some civilization that's already post biological and has done some really cool galactic construction projects in their galaxy."}, {"time": 9673, "text": "Would we be able to recognize them, do you think?"}, {"time": 9675, "text": "Is it possible that we just can't, I mean, this post biological world, could it be just existing in some other dimension?"}, {"time": 9683, "text": "It could be just all a virtual reality game for them or something, I don't know, that it changes completely where we won't be able to detect."}, {"time": 9692, "text": "We have to be honestly very humble about this."}, {"time": 9695, "text": "I think I said earlier the number one principle of being a scientist is you have to be humble and willing to acknowledge that everything we think, guess might be totally wrong."}, {"time": 9705, "text": "Of course, you could imagine some civilization where they all decide to become Buddhists and very inward looking and just move into their little virtual reality and not disturb the flora and fauna around them and we might not notice them."}, {"time": 9718, "text": "But this is a numbers game, right?"}, {"time": 9719, "text": "If you have millions of civilizations out there or billions of them, all it takes is one with a more ambitious mentality that decides, hey, we are gonna go out and settle a bunch of other solar systems and maybe galaxies."}, {"time": 9737, "text": "And then it doesn't matter if they're a bunch of quiet Buddhists, we're still gonna notice that expansionist one, right?"}, {"time": 9743, "text": "And it seems like quite the stretch to assume that, now we know even in our own galaxy that there are probably a billion or more planets that are pretty Earth like."}, {"time": 9755, "text": "And many of them are formed over a billion years before ours, so had a big head start."}, {"time": 9791, "text": "That seems like a bit of a stretch, frankly."}, {"time": 9793, "text": "And this leads into the second thing you challenged me that I might be wrong about, how rare or common is life, you know?"}, {"time": 9802, "text": "So Francis Drake, when he wrote down the Drake equation, multiplied together a huge number of factors and then we don't know any of them."}, {"time": 9809, "text": "So we know even less about what you get when you multiply together the whole product."}, {"time": 9815, "text": "Since then, a lot of those factors have become much better known."}, {"time": 9818, "text": "One of his big uncertainties was how common is it that a solar system even has a planet?"}, {"time": 9824, "text": "Well, now we know it very common."}, {"time": 9826, "text": "Earth like planets, we know we have better."}, {"time": 9828, "text": "There are a dime a dozen, there are many, many of them, even in our galaxy."}, {"time": 9832, "text": "At the same time, you know, we have thanks to, I'm a big supporter of the SETI project and its cousins and I think we should keep doing this and we've learned a lot."}, {"time": 9842, "text": "We've learned that so far, all we have is still unconvincing hints, nothing more, right?"}, {"time": 9848, "text": "And there are certainly many scenarios where it would be dead obvious."}, {"time": 9853, "text": "If there were a hundred million other human like civilizations in our galaxy, it would not be that hard to notice some of them with today's technology and we haven't, right?"}, {"time": 9863, "text": "So what we can say is, well, okay, we can rule out that there is a human level of civilization on the moon and in fact, the many nearby solar systems where we cannot rule out, of course, that there is something like Earth sitting in a galaxy five billion light years away."}, {"time": 9885, "text": "But we've ruled out a lot and that's already kind of shocking given that there are all these planets there, you know?"}, {"time": 9890, "text": "So like, where are they?"}, {"time": 9891, "text": "Where are they all?"}, {"time": 9892, "text": "That's the classic Fermi paradox."}, {"time": 9894, "text": "And so my argument, which might very well be wrong, it's very simple really, it just goes like this."}, {"time": 9901, "text": "Okay, we have no clue about this."}, {"time": 9905, "text": "It could be the probability of getting life on a random planet, it could be 10 to the minus one a priori or 10 to the minus five, 10, 10 to the minus 20, 10 to the minus 30, 10 to the minus 40."}, {"time": 9917, "text": "Basically every order of magnitude is about equally likely."}, {"time": 9921, "text": "When then do the math and ask the question, how close is our nearest neighbor?"}, {"time": 9927, "text": "It's again, equally likely that it's 10 to the 10 meters away, 10 to 20 meters away, 10 to the 30 meters away."}, {"time": 9933, "text": "We have some nerdy ways of talking about this with Bayesian statistics and a uniform log prior, but that's irrelevant."}, {"time": 9939, "text": "This is the simple basic argument."}, {"time": 9942, "text": "And now comes the data."}, {"time": 9943, "text": "So we can say, okay, there are all these orders of magnitude, 10 to the 26 meters away, there's the edge of our observable universe."}, {"time": 9951, "text": "If it's farther than that, light hasn't even reached us yet."}, {"time": 9954, "text": "If it's less than 10 to the 16 meters away, well, it's within Earth's, it's no farther away than the sun."}, {"time": 9963, "text": "We can definitely rule that out."}, {"time": 9967, "text": "So I think about it like this, a priori before we looked at the telescopes, it could be 10 to the 10 meters, 10 to the 20, 10 to the 30, 10 to the 40, 10 to the 50, 10 to blah, blah, blah."}, {"time": 9976, "text": "Equally likely anywhere here."}, {"time": 9978, "text": "And now we've ruled out like this chunk."}, {"time": 9981, "text": "And here is the edge of our observable universe already."}, {"time": 9987, "text": "So I'm certainly not saying I don't think there's any life elsewhere in space."}, {"time": 9992, "text": "If space is infinite, then you're basically a hundred percent guaranteed that there is, but the probability that there is life, that the nearest neighbor, it happens to be in this little region between where we would have seen it already and where we will never see it."}, {"time": 10008, "text": "There's actually significantly less than one, I think."}, {"time": 10011, "text": "And I think there's a moral lesson from this, which is really important, which is to be good stewards of this planet and this shot we've had."}, {"time": 10021, "text": "It can be very dangerous to say, oh, it's fine if we nuke our planet or ruin the climate or mess it up with unaligned AI, because I know there is this nice Star Trek fleet out there."}, {"time": 10035, "text": "They're gonna swoop in and take over where we failed."}, {"time": 10038, "text": "Just like it wasn't the big deal that the Easter Island losers wiped themselves out."}, {"time": 10043, "text": "That's a dangerous way of lulling yourself into false sense of security."}, {"time": 10047, "text": "If it's actually the case that it might be up to us and only us, the whole future of intelligent life in our observable universe, then I think it really puts a lot of responsibility on our shoulders."}, {"time": 10063, "text": "It's inspiring, it's a little bit terrifying, but it's also inspiring."}, {"time": 10066, "text": "But it's empowering, I think, most of all, because the biggest problem today is, I see this even when I teach, so many people feel that it doesn't matter what they do or we do, we feel disempowered."}, {"time": 10078, "text": "Oh, it makes no difference."}, {"time": 10082, "text": "This is about as far from that as you can come."}, {"time": 10085, "text": "But we realize that what we do on our little spinning ball here in our lifetime could make the difference for the entire future of life in our universe."}, {"time": 10097, "text": "How empowering is that?"}, {"time": 10098, "text": "Yeah, survival of consciousness."}, {"time": 10100, "text": "I mean, a very similar kind of empowering aspect of the Drake equation is, say there is a huge number of intelligent civilizations that spring up everywhere, but because of the Drake equation, which is the lifetime of a civilization, maybe many of them hit a wall."}, {"time": 10119, "text": "And just like you said, it's clear that that, for us, the great filter, the one possible great filter seems to be coming in the next 100 years."}, {"time": 10131, "text": "So it's also empowering to say, okay, well, we have a chance to not, I mean, the way great filters work, they just get most of them."}, {"time": 10142, "text": "Nick Bostrom has articulated this really beautifully too."}, {"time": 10146, "text": "Every time yet another search for life on Mars comes back negative or something, I'm like, yes, yes."}, {"time": 10154, "text": "Our odds for us surviving is the best."}, {"time": 10157, "text": "You already made the argument in broad brush there, right?"}, {"time": 10160, "text": "But just to unpack it, right?"}, {"time": 10162, "text": "The point is we already know there is a crap ton of planets out there that are Earth like, and we also know that most of them do not seem to have anything like our kind of life on them."}, {"time": 10175, "text": "So what went wrong?"}, {"time": 10177, "text": "There's clearly one step along the evolutionary, at least one filter or roadblock in going from no life to spacefaring life."}, {"time": 10185, "text": "And where is it?"}, {"time": 10188, "text": "Is it in front of us or is it behind us, right?"}, {"time": 10191, "text": "If there's no filter behind us, and we keep finding all sorts of little mice on Mars or whatever, right?"}, {"time": 10201, "text": "That's actually very depressing because that makes it much more likely that the filter is in front of us."}, {"time": 10206, "text": "And that what actually is going on is like the ultimate dark joke that whenever a civilization invents sufficiently powerful tech, it's just, you just set your clock."}, {"time": 10217, "text": "And then after a little while it goes poof for one reason or other and wipes itself out."}, {"time": 10221, "text": "Now wouldn't that be like utterly depressing if we're actually doomed?"}, {"time": 10226, "text": "Whereas if it turns out that there is a really, there is a great filter early on that for whatever reason seems to be really hard to get to the stage of sexually reproducing organisms or even the first ribosome or whatever, right?"}, {"time": 10243, "text": "Or maybe you have lots of planets with dinosaurs and cows, but for some reason they tend to get stuck there and never invent smartphones."}, {"time": 10250, "text": "All of those are huge boosts for our own odds because been there done that, you know?"}, {"time": 10258, "text": "It doesn't matter how hard or unlikely it was that we got past that roadblock because we already did."}, {"time": 10265, "text": "And then that makes it likely that the future is in our own hands, we're not doomed."}, {"time": 10271, "text": "So that's why I think the fact that life is rare in the universe, it's not just something that there is some evidence for, but also something we should actually hope for."}, {"time": 10286, "text": "So that's the end, the mortality, the death of human civilization that we've been discussing in life, maybe prospering beyond any kind of great filter."}, {"time": 10296, "text": "Do you think about your own death?"}, {"time": 10299, "text": "Does it make you sad that you may not witness some of the, you know, you lead a research group on working some of the biggest questions in the universe actually, both on the physics and the AI side?"}, {"time": 10313, "text": "Does it make you sad that you may not be able to see some of these exciting things come to fruition that we've been talking about?"}, {"time": 10320, "text": "Of course, of course it sucks, the fact that I'm gonna die."}, {"time": 10324, "text": "I remember once when I was much younger, my dad made this remark that life is fundamentally tragic."}, {"time": 10330, "text": "And I'm like, what are you talking about, daddy?"}, {"time": 10333, "text": "And then many years later, I felt, now I feel I totally understand what he means."}, {"time": 10337, "text": "You know, we grow up, we're little kids and everything is infinite and it's so cool."}, {"time": 10341, "text": "And then suddenly we find out that actually, you know, you got to serve only, this is the, you're gonna get game over at some point."}, {"time": 10350, "text": "So of course it's something that's sad."}, {"time": 10362, "text": "No, not in the sense that I think anything terrible is gonna happen after I die or anything like that."}, {"time": 10368, "text": "No, I think it's really gonna be a game over, but it's more that it makes me very acutely aware of what a wonderful gift this is that I get to be alive right now."}, {"time": 10380, "text": "And is a steady reminder to just live life to the fullest and really enjoy it because it is finite, you know."}, {"time": 10388, "text": "And I think actually, and we know we all get the regular reminders when someone near and dear to us dies that one day it's gonna be our turn."}, {"time": 10399, "text": "It adds this kind of focus."}, {"time": 10401, "text": "I wonder what it would feel like actually to be an immortal being if they might even enjoy some of the wonderful things of life a little bit less just because there isn't that."}, {"time": 10413, "text": "Finiteness?"}, {"time": 10415, "text": "Do you think that could be a feature, not a bug, the fact that we beings are finite?"}, {"time": 10422, "text": "Maybe there's lessons for engineering in artificial intelligence systems as well that are conscious."}, {"time": 10428, "text": "Like do you think it makes, is it possible that the reason the pistachio ice cream is delicious is the fact that you're going to die one day and you will not have all the pistachio ice cream that you could eat because of that fact?"}, {"time": 10446, "text": "Well, let me say two things."}, {"time": 10447, "text": "First of all, it's actually quite profound what you're saying."}, {"time": 10450, "text": "I do think I appreciate the pistachio ice cream a lot more knowing that I will, there's only a finite number of times I get to enjoy that."}, {"time": 10457, "text": "And I can only remember a finite number of times in the past."}, {"time": 10461, "text": "And moreover, my life is not so long that it just starts to feel like things are repeating themselves in general."}, {"time": 10468, "text": "It's so new and fresh."}, {"time": 10470, "text": "I also think though that death is a little bit overrated in the sense that it comes from a sort of outdated view of physics and what life actually is."}, {"time": 10485, "text": "Because if you ask, okay, what is it that's gonna die exactly, what am I really?"}, {"time": 10492, "text": "When I say I feel sad about the idea of myself dying, am I really sad that this skin cell here is gonna die?"}, {"time": 10499, "text": "Of course not, because it's gonna die next week anyway and I'll grow a new one, right?"}, {"time": 10504, "text": "And it's not any of my cells that I'm associating really with who I really am."}, {"time": 10511, "text": "Nor is it any of my atoms or quarks or electrons."}, {"time": 10515, "text": "In fact, basically all of my atoms get replaced on a regular basis, right?"}, {"time": 10520, "text": "So what is it that's really me from a more modern physics perspective?"}, {"time": 10524, "text": "It's the information in processing me."}, {"time": 10528, "text": "That's where my memory, that's my memories, that's my values, my dreams, my passion, my love."}, {"time": 10540, "text": "That's what's really fundamentally me."}, {"time": 10543, "text": "And frankly, not all of that will die when my body dies."}, {"time": 10548, "text": "Like Richard Feynman, for example, his body died of cancer, but many of his ideas that he felt made him very him actually live on."}, {"time": 10561, "text": "This is my own little personal tribute to Richard Feynman."}, {"time": 10564, "text": "I try to keep a little bit of him alive in myself."}, {"time": 10567, "text": "I've even quoted him today, right?"}, {"time": 10569, "text": "Yeah, he almost came alive for a brief moment in this conversation, yeah."}, {"time": 10573, "text": "Yeah, and this honestly gives me some solace."}, {"time": 10577, "text": "When I work as a teacher, I feel, if I can actually share a bit about myself that my students feel worthy enough to copy and adopt as some part of things that they know or they believe or aspire to, now I live on also a little bit in them, right?"}, {"time": 10599, "text": "And so being a teacher is a little bit of what I, that's something also that contributes to making me a little teeny bit less mortal, right?"}, {"time": 10613, "text": "Because I'm not, at least not all gonna die all at once, right?"}, {"time": 10617, "text": "And I find that a beautiful tribute to people we do not respect."}, {"time": 10621, "text": "If we can remember them and carry in us the things that we felt was the most awesome about them, right, then they live on."}, {"time": 10631, "text": "And I'm getting a bit emotional here, but it's a very beautiful idea you bring up there."}, {"time": 10636, "text": "I think we should stop this old fashioned materialism and just equate who we are with our quirks and electrons."}]}, {"title": "Frank Wilczek: Physics of Quarks, Dark Matter, Complexity, Life & Aliens | Lex Fridman Podcast #187", "id": "LDTe8uFqbws", "quotes": [{"time": 792, "text": "It makes you wonder why."}, {"time": 800, "text": "So I come from Russia and the question of Dostoevsky he has said that beauty will save the world."}, {"time": 807, "text": "Maybe as a physicist you can tell me what do you think he meant by that?"}, {"time": 811, "text": "I don't know if it saves the world but it does turn out to be a tremendous source of insight into the world."}, {"time": 817, "text": "When we investigate kind of the most fundamental interactions, things that are hard to access because they occur at very short distances between very special kinds of particles whose properties are only revealed at high energies."}, {"time": 841, "text": "We don't have much to go on from everyday life but so we have when we guess what the, and the experiments are difficult to do so you can't really follow a very wholly empirical procedure to sort of in the Baconian style figure out the laws kind of step by step just by accumulating a lot of data what we actually do is guess."}, {"time": 865, "text": "And the guesses are kind of aesthetic really."}, {"time": 869, "text": "What would be a nice description that's consistent with what we know and then you try it out and see if it works and by gosh it does in many profound cases."}, {"time": 958, "text": "So the rules of development when you have simple rules and they work again and again, you get symmetrical patterns."}, {"time": 967, "text": "That's kind of, in fact it's a recipe also for generating fractals, like the kind of broccoli that has all this internal structure and I wish I had a picture to show but maybe people remember it from the supermarket and you say how did a vegetable get so intelligent to make such a beautiful object with all this fractal structure and the secret is stupidity."}, {"time": 995, "text": "You just do the same thing over and over again and in our brains also, you know, we came out, we start from single cells and they reproduce and each one does basically roughly the same thing."}, {"time": 1071, "text": "But what you're describing, this kind of beauty that we're talking about now is a very small sample in terms of space time in a very big world in a very short, brief moment in this long history."}, {"time": 1088, "text": "In your book, Fundamentals, 10 Keys to Reality, I'd really recommend people read it."}, {"time": 1094, "text": "You say that space and time are pretty big or very big."}, {"time": 1100, "text": "How big are we talking about?"}, {"time": 1101, "text": "Can you tell a brief history of space and time?"}, {"time": 1106, "text": "It's easy to tell a brief history, but the details get very involved, of course, but one thing I'd like to say is that if you take a broad enough view, the history of the universe is simpler than the history of Sweden, say, because your standards are lower."}, {"time": 1125, "text": "But just to make it quantitative, I'll just give a few highlights."}, {"time": 1131, "text": "And it's a little bit easier to talk about time, so let's start with that."}, {"time": 1137, "text": "The Big Bang occurred, we think."}, {"time": 1140, "text": "The universe was much hotter and denser and more uniform about 13.8 billion years ago, and that's what we call the Big Bang."}, {"time": 1150, "text": "And it's been expanding and cooling, the matter in it has been expanding and cooling ever since."}, {"time": 1156, "text": "So in a real sense, the universe is 13.8 billion years old."}, {"time": 1160, "text": "That's a big number, kind of hard to think about."}, {"time": 1164, "text": "A nice way to think about it, though, is to map it onto one year."}, {"time": 1169, "text": "So let's say the universe just linearly mapped the time intervals from 13.8 billion years onto one year."}, {"time": 1177, "text": "So the Big Bang then is on January 1st at 12 a.m. And you wait for quite a long time before the dinosaurs emerge."}, {"time": 1191, "text": "The dinosaurs emerge on Christmas, it turns out."}, {"time": 1195, "text": "And... 12 months, almost 12 months later."}, {"time": 1197, "text": "Getting close to the end, yes."}, {"time": 1199, "text": "Getting close to the end."}, {"time": 1201, "text": "And the extinction event that let the mammals and ultimately humans inherit the Earth from the dinosaurs occurred on December 30th."}, {"time": 1213, "text": "And all of human history is a small part of the last day."}, {"time": 1218, "text": "And so, yes, so we're occupying only, and a human lifetime is a very, very infinitesimal part of this interval of these gigantic cosmic reaches of time."}, {"time": 1235, "text": "And in space, we can tell a very similar story."}, {"time": 1239, "text": "In fact, it's convenient to think that the size of the universe is the distance that light can travel in 13.8 billion years."}, {"time": 1250, "text": "So it's 13.8 billion light years."}, {"time": 1254, "text": "That's how far you can see out."}, {"time": 1256, "text": "That's how far signals can reach us."}, {"time": 1261, "text": "And that is a big distance."}, {"time": 1266, "text": "That is a big distance because compared to that, the Earth is a fraction of a light second."}, {"time": 1278, "text": "So again, it's really, really big."}, {"time": 1281, "text": "And so if we wanna think about the universe as a whole in space and time, we really need a different kind of imagination."}, {"time": 1295, "text": "It's not something you can grasp in terms of psychological time in a useful way."}, {"time": 1304, "text": "You have to think, you have to use exponential notation and abstract concepts to really get any hold on these vast times and spaces."}, {"time": 1316, "text": "On the other hand, let me hasten to add that that doesn't make us small or make the time that we have to us small."}, {"time": 1326, "text": "Because again, looking at those pictures of what our minds are and some of the components of our minds, these beautiful drawings of the cellular patterns inside the brain, you see that there are many, many, many processing units."}, {"time": 1344, "text": "And if you analyze how fast they operate, I tried to estimate how many thoughts a person can have in a lifetime."}, {"time": 1353, "text": "That's kind of a fuzzy question, but I'm very proud that I was able to define it pretty precisely."}, {"time": 1359, "text": "And it turns out we have time for billions of meaningful thoughts in a lifetime."}, {"time": 1366, "text": "So it's a lot."}, {"time": 1368, "text": "We shouldn't think of ourselves as terribly small either in space or in time, because although we're small in those dimensions compared to the universe, we're large compared to meaningful units of processing information and being able to conceptualize and understand things."}, {"time": 1391, "text": "Yeah, but 99% of those thoughts are probably food, sex, or internet related."}, {"time": 1396, "text": "Well, yeah, well, they're not necessarily, that's right."}, {"time": 1400, "text": "Only like point one is Nobel Prize winning ideas."}, {"time": 1404, "text": "That's true, but there's more to life than winning Nobel Prizes."}, {"time": 1407, "text": "How did you do that calculate?"}, {"time": 1409, "text": "Can you maybe break that apart a little bit, just kind of for fun, sort of an intuition of how we calculate the number of thoughts?"}, {"time": 1415, "text": "The number of thoughts, right."}, {"time": 1417, "text": "It's necessarily imprecise because a lot of things are going on in different ways and what is a thought."}, {"time": 1423, "text": "But there are several things that point to more or less the same rate of being able to have meaningful thoughts."}, {"time": 1432, "text": "For instance, the one that I think is maybe the most penetrating is how fast we can process visual images."}, {"time": 1447, "text": "If you've ever watched old movies, you can see that, well, any movie, in fact, a motion picture is really not a motion picture."}, {"time": 1458, "text": "It's a series of snapshots that are playing one after the other and it's because our brains also work that way."}, {"time": 1466, "text": "We take snapshots of the world, integrate over a certain time and then go on to the next one and then by post processing, create the illusion of continuity and flow, we can deal with that."}, {"time": 1478, "text": "And if the flicker rate is too slow, then you start to see that it's a series of snapshots and you can ask, what is the crossover?"}, {"time": 1491, "text": "When does it change from being something that is matched to our processing speed versus too fast?"}, {"time": 1497, "text": "And it turns out about 40 per second."}, {"time": 1500, "text": "And then if you take 40 per second as how well, how fast we can process visual images, you get to several billions of thoughts."}, {"time": 1510, "text": "If you, similarly, if you ask what are some of the fastest things that people can do?"}, {"time": 1516, "text": "Well, they can play video games, they can play the piano very fast if they're skilled at it."}, {"time": 1522, "text": "And again, you get to similar units or how fast can people talk?"}, {"time": 1527, "text": "You get to similar, you know, within a couple of orders of magnitude, you get more or less to the same idea."}, {"time": 1533, "text": "So that's how you can say that there's billions of meaningful, there's room for billions of meaningful thoughts."}, {"time": 1542, "text": "I won't argue for exactly two billion versus 1.8 billion."}, {"time": 1547, "text": "It's not that kind of question, but I think any estimate that's reasonable will come out within, say, 100 billion and 100 million."}, {"time": 1561, "text": "It would be interesting to map out for an individual human being the landscape of thoughts that they've sort of traveled."}, {"time": 1569, "text": "If you think of thoughts as a set of trajectories, what that landscape looks like."}, {"time": 1576, "text": "I mean, I've been recently really thinking about this Richard Dawkins idea of memes and just all this ideas and the evolution of ideas inside of one particular human mind and how they're then changed and evolved by interaction with other human beings."}, {"time": 1598, "text": "So if you think the number is billions, you think there's also social interaction."}, {"time": 1604, "text": "So these aren't like there's interaction in the same way you have interaction with particles."}, {"time": 1610, "text": "There's interaction between human thoughts that perhaps that interaction in itself is fundamental to the process of thinking."}, {"time": 1619, "text": "Like without social interaction, we would be like stuck, like walking in a circle."}, {"time": 1624, "text": "We need the perturbation of other humans to create change and evolution."}, {"time": 1629, "text": "Once you bring in concepts of interactions and correlations and relations, then you have what's called a combinatorial explosion that the number of possibilities expands exponentially technically with the number of things you're considering."}, {"time": 1648, "text": "And it can easily rapidly outstrip these billions of thoughts that we're talking about."}, {"time": 1656, "text": "So we definitely cannot by brute force master complex situations or think of all the possibilities in a complex situations."}, {"time": 1668, "text": "I mean, even something as relatively simple as chess is still something that human beings can't comprehend completely."}, {"time": 1677, "text": "Even the best players lose, still sometimes lose and they consistently lose to computers these days."}, {"time": 1685, "text": "And in computer science, there's a concept of NP complete."}, {"time": 1688, "text": "So large classes of problems when you scale them up beyond a few individuals become intractable."}, {"time": 1696, "text": "And so that in that sense, the world is inexhaustible."}, {"time": 1701, "text": "And that makes it beautiful that we can make any laws that generalize efficiently and well can compress all of that combinatorial complexity just like a simple rule."}, {"time": 1713, "text": "That in itself is beautiful."}, {"time": 1715, "text": "It's a happy situation."}, {"time": 1716, "text": "And I think that we can find general principles of sort of of the operating system that are comprehensible, simple, extremely powerful and let us control things very well and ask profound questions."}, {"time": 1735, "text": "And on the other hand, that the world is going to be inexhaustible."}, {"time": 1739, "text": "That once we start asking about relationships and how they evolve and social interactions and we'll never have a theory of everything in any meaningful sense because that."}, {"time": 1753, "text": "Of everything, everything, truly everything is."}, {"time": 1757, "text": "Can I ask you about the Big Bang?"}, {"time": 1759, "text": "So we talked about the space and time are really big."}, {"time": 1764, "text": "But then, and we humans give a lot of meaning to the word space and time in our like daily lives."}, {"time": 1773, "text": "But then can we talk about this moment of beginning and how we're supposed to think about it?"}, {"time": 1780, "text": "That at the moment of the Big Bang, everything was what, like infinitely small and then it just blew up?"}, {"time": 1788, "text": "We have to be careful here because there's a common misconception that the Big Bang is like the explosion of a bomb in empty space that fills up the surrounding place."}, {"time": 1802, "text": "It is space."}, {"time": 1845, "text": "Like really hot."}, {"time": 1846, "text": "Really, really, really hot."}, {"time": 1849, "text": "We're talking about way, way hotter than the surface of the sun."}, {"time": 1856, "text": "Well, in fact, if you take the equations as they come, the prediction is that the temperature just goes to infinity, but then the equations break down."}, {"time": 1866, "text": "We don't really, there are various, the equations become infinity equals infinity, so they don't feel that it's called a singularity."}, {"time": 1875, "text": "We don't really know."}, {"time": 1876, "text": "This is running the equations backwards, so you can't really get a sensible idea of what happened before the Big Bang."}, {"time": 1883, "text": "So we need different equations to address the very earliest moments."}, {"time": 1891, "text": "But so things were hotter and denser."}, {"time": 1895, "text": "We don't really know why things started out that way."}, {"time": 1900, "text": "We have a lot of evidence that they did start out that way."}, {"time": 1903, "text": "But since most of the, we don't get to visit there and do controlled experiments."}, {"time": 1915, "text": "Most of the record is very, very processed and we have to use very subtle techniques and powerful instruments to get information that has survived."}, {"time": 1931, "text": "Get closer and closer to the Big Bang."}, {"time": 1934, "text": "Get closer and closer to the beginning of things."}, {"time": 1936, "text": "And what's revealed there is that, as I said, there undoubtedly was a period when everything in the universe that we have been able to look at and understand, and that's consistent with everything, is in a condition where it was much, much hotter and much, much denser, but still obeying the laws of physics as we know them today."}, {"time": 1968, "text": "And then you start with that."}, {"time": 1971, "text": "So all the matter is in equilibrium."}, {"time": 1974, "text": "And then with small quantum fluctuations and run it forward, and then it produces, at least in broad strokes, the universe we see around us today."}, {"time": 1986, "text": "Do you think we'll ever be able to, with the tools of physics, with the way science is, with the way the human mind is, we'll ever be able to get to the moment of the Big Bang in our understanding or even the moment before the Big Bang?"}, {"time": 2001, "text": "Can we understand what happened before the Big Bang?"}, {"time": 2004, "text": "I'm optimistic both that we'll be able to measure more, so observe more, and that we'll be able to figure out more."}, {"time": 2016, "text": "So they're very, very tangible prospects for observing the extremely early universe, so even much earlier than we can observe now through looking at gravitational waves."}, {"time": 2032, "text": "Gravitational waves, since they interact so weakly with ordinary matter, sort of send a minimally processed signal from the Big Bang."}, {"time": 2043, "text": "It's a very weak signal because it's traveled a long way and diffused over long spaces, but people are gearing up to try to detect gravitational waves that could have come from the early universe."}, {"time": 2056, "text": "Yeah, LIGO's an incredible engineering project."}, {"time": 2059, "text": "It's the most sensitive, precise devices on Earth."}, {"time": 2064, "text": "The fact that humans can build something like that is truly awe inspiring from an engineering perspective."}, {"time": 2071, "text": "Right, but these gravitational waves from the early universe will probably be of a much longer wavelength than LIGO is capable of sensing, so there's a beautiful project that's contemplated to put lasers in different locations in the solar system."}, {"time": 2094, "text": "We really, really separate it by solar system scale differences, like artificial planets or moons in different places and see the tiny motions of those relative to one another as a signal of radiation from the Big Bang."}, {"time": 2110, "text": "We can also maybe indirectly see the imprint of gravitational waves from the early universe on the photons, the microwave background radiation."}, {"time": 2123, "text": "That is our present way of seeing into the earliest universe, but those photons interact much more strongly with matter."}, {"time": 2131, "text": "They're much more strongly processed, so they don't give us directly such an unprocessed view of the early universe, of the very early universe, but if gravitational waves leave some imprint on that as they move through, we could detect that too, and people are trying, as we speak, working very hard towards that goal."}, {"time": 2156, "text": "It's so exciting to think about a sensor the size of the solar system."}, {"time": 2161, "text": "That would be a fantastic, I mean, that would be a pinnacle artifact of human endeavor to me."}, {"time": 2168, "text": "It would be such an inspiring thing that just we want to know, and we go to these extraordinary lengths of making gigantic things that are also very sophisticated because what you're trying to do, you have to understand how they move."}, {"time": 2184, "text": "You have to understand the properties of light that are being used, the interference between light, and you have to be able to make the light with lasers and understand the quantum theory and get the timing exactly right."}, {"time": 2198, "text": "It's an extraordinary endeavor involving all kinds of knowledge from the very small to the very large, and all in the service of curiosity and built on a grand scale, so."}, {"time": 2212, "text": "Yeah, it would make me proud to be a human if we did that."}, {"time": 2218, "text": "I love that you're inspired both by the power of theory and the power of experiment."}, {"time": 2222, "text": "So both, I think, are exceptionally impressive that the human mind can come up with theories that give us a peek into how the universe works, but also construct tools that are way bigger than the evolutionary origins we came from."}, {"time": 2240, "text": "Right, and by the way, the fact that we can design such things and they work is an extraordinary demonstration that we really do understand a lot."}, {"time": 2250, "text": "And then in some ways."}, {"time": 2253, "text": "And it's our ability to answer questions that also leads us to be able to address more ambitious questions."}, {"time": 2259, "text": "So you mentioned at the Big Bang in the early days, things are pretty homogeneous."}, {"time": 2267, "text": "But here we are, sitting on Earth, two hairless apes, you could say, with microphones."}, {"time": 2277, "text": "In talking about the brief history of things, you said it's much harder to describe Sweden than it is the universe."}, {"time": 2283, "text": "So there's a lot of complexity."}, {"time": 2285, "text": "There was a lot of interesting details here."}, {"time": 2287, "text": "So how does this complexity come to be, do you think?"}, {"time": 2291, "text": "It seems like there's these pockets."}, {"time": 2294, "text": "We don't know how rare of like where hairless apes emerge."}, {"time": 2299, "text": "And then that came from the initial soup that was homogeneous."}, {"time": 2303, "text": "Was that an accident?"}, {"time": 2306, "text": "Well, we understand in broad outlines how it could happen."}, {"time": 2313, "text": "We certainly don't understand why it happened exactly in the way it did."}, {"time": 2320, "text": "Or there are certainly open questions about the origins of life and how inevitable the emergence of intelligence was and how that happened."}, {"time": 2328, "text": "But in the very broadest terms, the universe early on was quite homogeneous, but not completely homogeneous."}, {"time": 2341, "text": "There were part in 10,000 fluctuations in density within this primordial plasma."}, {"time": 2350, "text": "And as time goes on, there's an instability which causes those density contrasts to increase."}, {"time": 2360, "text": "There's a gravitational instability where it's denser, the gravitational attractions are stronger."}, {"time": 2365, "text": "And so that brings in more matter and it gets even denser and so on and so on."}, {"time": 2369, "text": "So there's a natural tendency of matter to clump because of gravitational interactions."}, {"time": 2377, "text": "And then the equation is complicated."}, {"time": 2379, "text": "We have lots of things clumping together."}, {"time": 2383, "text": "Then we know what the laws are, but we have to a certain extent wave our hands about what happens."}, {"time": 2391, "text": "But basic understanding of chemistry says that if things and the physics of radiation tells us that as things start to clump together, they can radiate, give off some energy."}, {"time": 2405, "text": "So they don't just, they slow down."}, {"time": 2407, "text": "As a result, they lose energy."}, {"time": 2409, "text": "They can collaborate together, cool down, form things like stars, form things like planets."}, {"time": 2416, "text": "And so in broad terms, there's no mystery."}, {"time": 2419, "text": "There's, that's what the scenario, that's what the equations tell you should happen."}, {"time": 2425, "text": "But because it's a process involving many, many fundamental individual units, the application of the laws that govern individual units to these things is very delicate, computationally very difficult."}, {"time": 2448, "text": "And more profoundly, the equations have this probability of chaos or sensitivity to initial conditions, which tells you tiny differences in the initial state can lead to enormous differences in the subsequent behavior."}, {"time": 2462, "text": "So physics, fundamental physics at some point says, okay, chemists, biologists, this is your problem."}, {"time": 2471, "text": "And then again, in broad terms, we know how it's conceivable that the humans and things like that, how complex structure can emerge."}, {"time": 2488, "text": "It's a matter of having the right kind of temperature and the right kind of stuff."}, {"time": 2496, "text": "So you need to be able to make chemical bonds that are reasonably stable and be able to make complex structures."}, {"time": 2505, "text": "And we're very fortunate that carbon has this ability to make backbones and elaborate branchings and things."}, {"time": 2514, "text": "So you can get complex things that we call biochemistry."}, {"time": 2517, "text": "And yet the bonds can be broken a little bit with the help of energetic injections from the sun."}, {"time": 2524, "text": "So you have to have both the possibility of changing, but also the useful degree of stability."}, {"time": 2530, "text": "And we know at that very, very broad level, physics can tell you that it's conceivable."}, {"time": 2537, "text": "If you want to know what really happened, what really can happen, then you have to work a bit, go to chemistry."}, {"time": 2547, "text": "If you want to know what actually happened, then you really have to consult the fossil record and biologists."}, {"time": 2553, "text": "And so these ways of addressing the issue are complimentary in a sense."}, {"time": 2563, "text": "They use different kinds of concepts, they use different languages and they address different kinds of questions, but they're not inconsistent, they're just complimentary."}, {"time": 2579, "text": "It's kind of interesting to think about those early fluctuations as our earliest ancestors."}, {"time": 2588, "text": "So it's amazing to think that this is the modern answer to the, or the modern version of what the Hindu philosophers had, that art thou."}, {"time": 2605, "text": "If you ask what, okay, those little quantum fluctuations in the early universe are the seeds out of which complexity, including plausibly humans, really evolve."}, {"time": 2620, "text": "You don't need anything else."}, {"time": 2622, "text": "That brings up the question of asking for a friend here if there's other pockets of complexity, commonly called as alien intelligent civilizations out there."}, {"time": 2639, "text": "Well, we don't know for sure, but I have a strong suspicion that the answer is yes because the one case we do have at hand to study here on Earth, we sort of know what the conditions were that were helpful to life, the right kind of temperature, the right kind of star that keeps, maintains that temperature for a long time, the liquid environment of water."}, {"time": 2668, "text": "And once those conditions emerged on Earth, which was roughly four and a half billion years ago, it wasn't very long before what we call life started to leave relics."}, {"time": 2681, "text": "So we can find forms of life, primitive forms of life that are almost as old as the Earth itself in the sense that once the Earth was turned from a very hot boiling thing and cooled off into a solid mass with water, life emerged very, very quickly."}, {"time": 2703, "text": "So it seems that these general conditions for life are enough to make it happen relatively quickly."}, {"time": 2713, "text": "Now, the other lesson I think that one can draw from this one example, it's dangerous to draw lessons from one example, but that's all we've got, and that the emergence of intelligent life is a different issue altogether."}, {"time": 2735, "text": "That took a long time and seems to have been pretty contingent for a long time."}, {"time": 2747, "text": "Well, for most of the history of life, it was single celled things."}, {"time": 2755, "text": "Even multicellular life only rose about 600 million years ago, so much after."}, {"time": 2761, "text": "And then intelligence is kind of a luxury."}, {"time": 2772, "text": "Many more kinds of creatures have big stomachs than big brains."}, {"time": 2780, "text": "In fact, most have no brains at all in any reasonable sense."}, {"time": 2785, "text": "And the dinosaurs ruled for a long, long time and some of them were pretty smart, but they were at best bird brains because birds came from the dinosaurs."}, {"time": 2797, "text": "And it could have stayed that way."}, {"time": 2801, "text": "And then the emergence of humans was very contingent and kind of a very, very recent development on evolutionary timescales."}, {"time": 2811, "text": "And you can argue about the level of human intelligence, but I think that's what we're talking about."}, {"time": 2818, "text": "It's very impressive and can ask these kinds of questions and discuss them intelligently."}, {"time": 2827, "text": "So I guess my, so this is a long winded answer or justification of my feeling is that the conditions for life in some form are probably satisfied many, many places around the universe and even within our galaxy."}, {"time": 2853, "text": "I'm not so sure about the emergence of intelligent life or the emergence of technological civilizations."}, {"time": 2861, "text": "That seems much more contingent and special."}, {"time": 2867, "text": "And we might, it's conceivable to me that we're the only example in the galaxy."}, {"time": 2874, "text": "Although, yeah, I don't know one way or the other."}, {"time": 2876, "text": "I have different opinions on different days of the week."}, {"time": 2879, "text": "But one of the things that worries me in the spirit of being humble, that our particular kind of intelligence is not very special."}, {"time": 2890, "text": "So there's all kinds of different intelligences."}, {"time": 2893, "text": "And even more broadly, there could be many different kinds of life."}, {"time": 2899, "text": "So the basic definition, and I just had, I think somebody that you know, Sarah Walker, I just had a very long conversation with her about even just the very basic question of trying to define what is life from a physics perspective."}, {"time": 2914, "text": "Even that question within itself, I think one of the most fundamental questions in science and physics and everything is just trying to get a hold, trying to get some universal laws around the ideas of what is life because that kind of unlocks a bunch of things around life, intelligence, consciousness, all those kinds of things."}, {"time": 2933, "text": "I agree with you in a sense, but I think that's a dangerous question because the answer can't be any more precise than the question."}, {"time": 2942, "text": "And the question, what is life, kind of assumes that we have a definition of life and that it's a natural phenomena that can be distinguished."}, {"time": 2954, "text": "But really there are edge cases like viruses and some people would like to say that electrons have consciousness."}, {"time": 2965, "text": "So you can't, if you really have fuzzy concepts, it's very hard to reach precise kinds of scientific answers."}, {"time": 2974, "text": "But I think there's a very fruitful question that's adjacent to it, which has been pursued in different forms for quite a while and is now becoming very sophisticated in reaching in new directions."}, {"time": 2990, "text": "And that is, what are the states of matter that are possible?"}, {"time": 2995, "text": "So in high school or grade school, you learn about solids, liquids and gases, but that really just scratches the surface of different ways that are distinguishable, that matter can form into macroscopically different, meaningful patterns that we call phases."}, {"time": 3017, "text": "And then there are precise definitions of what we mean by phases of matter and that have been worked out fruitful over the decades."}, {"time": 3026, "text": "And we're discovering new states of matter all the time and kind of having to work at what we mean by matter."}, {"time": 3033, "text": "We're discovering the capabilities of matter to organize in interesting ways."}, {"time": 3039, "text": "And some of them, like liquid crystals, are important ingredients of life."}, {"time": 3049, "text": "Our cell membranes are liquid crystals, and that's very important to the way they work."}, {"time": 3055, "text": "Recently, there's been a development in where we're talking about states of matter that are not static, but that have dynamics, that have characteristic patterns, not only in space, but in time."}, {"time": 3071, "text": "These are called time crystals, and that's been a development that's just in the last decade or so."}, {"time": 3077, "text": "It's just really, really flourishing."}, {"time": 3080, "text": "And so is there a state of matter or a group of states of matter that corresponds to life?"}, {"time": 3091, "text": "Maybe, but the answer can't be any more definite than the question."}, {"time": 3095, "text": "I mean, I gotta push back on the, those are just words."}, {"time": 3099, "text": "I mean, I disagree with you."}, {"time": 3101, "text": "The question points to a direction."}, {"time": 3105, "text": "The answer might be able to be more precise than the question, because just as you're saying, there is a, we could be discovering certain characteristics and patterns that are associated with a certain type of matter, macroscopically speaking, and that we can then be able to post facto say, this is, let's assign the word life to this kind of matter."}, {"time": 3134, "text": "I agree with that completely, that's what that's, but that's, so it's not a disagreement."}, {"time": 3139, "text": "It's very frequent in physics that, or in science, that words that are in common use get refined and reprocessed into scientific terms that's happened for things like force and energy."}, {"time": 3155, "text": "And so we, in a way, we find out what the useful definition is, or symmetry, for instance."}, {"time": 3163, "text": "And the common usage may be quite different from the scientific usage, but the scientific usage is special and takes on a life of its own, and we find out what the useful version of it is, the fruitful version of it is."}, {"time": 3182, "text": "So I do think, so in that spirit, I think if we can identify states of matter or linked states of matter that can carry on processes of self reproduction and development and information processing, we might be tempted to classify those things as life."}, {"time": 3214, "text": "Well, can I ask you about the craziest one, which is the one we know maybe least about, which is consciousness."}, {"time": 3222, "text": "Is it possible that there are certain kinds of matter would be able to classify as conscious, meaning like, so there's the panpsychists, right, who are the philosophers who kind of try to imply that all matter has some degree of consciousness, and you can almost construct like a physics of consciousness."}, {"time": 3244, "text": "Do you, again, we're in such early days of this, but nevertheless, it seems useful to talk about it."}, {"time": 3253, "text": "Is there some sense from a physics perspective to make sense of consciousness?"}, {"time": 3258, "text": "Is there some hope?"}, {"time": 3259, "text": "Well, again, consciousness is a very imprecise word and loaded with connotations that I think we should, we don't wanna start a scientific analysis with that, I don't think."}, {"time": 3274, "text": "It's often been important in science to start with simple cases and work up."}, {"time": 3283, "text": "Consciousness, I think what most people think of when you talk about consciousness is, okay, what am I doing in the world?"}, {"time": 3293, "text": "I have a rich inner life and experience, and where is that in the equations?"}, {"time": 3299, "text": "And I think that's a great question, a great, great question, and actually, I think I'm gearing up to spend part of, I mean, to try to address that in coming years."}, {"time": 3310, "text": "One version of asking that question, just as you said now, is what is the simplest formulation of that to study?"}, {"time": 3319, "text": "I think I'm much more comfortable with the idea of studying self awareness as opposed to consciousness, because that sort of gets rid of the mystical aura of the thing."}, {"time": 3330, "text": "And self awareness is in simple, you know, I think contiguous at least with ideas about feedback."}, {"time": 3341, "text": "So if you have a system that looks at its own state and responds to it, that's a kind of self awareness."}, {"time": 3350, "text": "And more sophisticated versions could be like in information processing things, computers that look into their own internal state and do something about it."}, {"time": 3363, "text": "And I think that could also be done in neural nets."}, {"time": 3368, "text": "This is called recurrent neural nets, which are hard to understand and kind of a frontier."}, {"time": 3375, "text": "So I think understanding those and gradually building up a kind of profound ability to conceptualize different levels of self awareness."}, {"time": 3392, "text": "What do you have to not know?"}, {"time": 3393, "text": "And what do you have to know?"}, {"time": 3394, "text": "And when do you know that you don't know it?"}, {"time": 3396, "text": "Or when do you, what do you think you know that you don't really know?"}, {"time": 3399, "text": "And these, I think clarifying those issues, when we clarify those issues and get a rich theory around self awareness, I think that will illuminate the questions about consciousness in a way that, you know, scratching your chin and talking about qualia and blah, blah, blah, blah is never gonna do."}, {"time": 3424, "text": "Well, I also have a different approach to the whole thing."}, {"time": 3426, "text": "So there's, from a robotics perspective, you can engineer things that exhibit qualities of consciousness without understanding how things work."}, {"time": 3439, "text": "And from that perspective, you, it's like a back door, like enter through the psychology door."}, {"time": 3448, "text": "Precisely, I think we're on the same wavelength here."}, {"time": 3452, "text": "I think that, and let me just add one comment, which is I think we should try to understand consciousness as we experience it as, in evolutionary terms, and ask ourselves, why, why does it happen?"}, {"time": 3473, "text": "This thing seems useful."}, {"time": 3477, "text": "I think we've got a conscious eyewatch here."}, {"time": 3482, "text": "Thank you, Siri."}, {"time": 3488, "text": "I'll get back to you later."}, {"time": 3525, "text": "There's, there'll also be an unconscious."}, {"time": 3527, "text": "I think that that is gonna be, turn out to be really essential to doing efficient information processing."}, {"time": 3535, "text": "And that's why it evolved, because it's, it's, it's, it's helpful in, because brains come at a high cost."}, {"time": 3546, "text": "So there has to be, there has to be a good why."}, {"time": 3549, "text": "And there's a reason, yeah."}, {"time": 3550, "text": "They're rare in evolution and big brains are rare in evolution and they, they come at a big cost."}, {"time": 3559, "text": "You mean, if you, you, they, they, they have high metabolic demands."}, {"time": 3567, "text": "They require, you know, very active lifestyle, warm bloodedness and take, take away from the ability to support metabolism of digestion."}, {"time": 3579, "text": "And so, so it's, it's, it comes at a high cost."}, {"time": 3582, "text": "It has to, it has to pay back."}, {"time": 3584, "text": "Yeah, I think it has a lot of value in social interaction."}, {"time": 3587, "text": "So I actually am spending the rest of the day today and with our friends that are, our legged friends in robotic form at Boston Dynamics."}, {"time": 3598, "text": "And I think, so my probably biggest passion is human robot interaction."}, {"time": 3605, "text": "And it seems that consciousness from the perspective of the robot is very useful to improve the human robot interaction experience."}, {"time": 3616, "text": "The first, the display of consciousness, but then to me, there's a gray area between the display of consciousness and consciousness itself."}, {"time": 3623, "text": "If you think of consciousness from an evolutionary perspective, it seems like a useful tool in human communication, so."}, {"time": 3629, "text": "Yes, it's certainly, well, whatever consciousness is will turn out to be."}, {"time": 3635, "text": "I think addressing it through its use and working up from simple cases and also working up from engineering experience in trying to do efficient computation, including efficient management of social interactions is going to really shed light on these questions."}, {"time": 3656, "text": "As I said, in a way that sort of musing abstractly about consciousness never would."}, {"time": 3661, "text": "So as I mentioned, I talked to Sarah Walker and first of all, she says, hi, spoke very highly of you."}, {"time": 3667, "text": "One of her concerns about physics and physicists and humans is that we may not fully understand the system that we're inside of."}, {"time": 3678, "text": "Meaning like, there may be limits to the kind of physics we do in trying to understand the system of which we're part of."}, {"time": 3688, "text": "So like, the observer is also the observed."}, {"time": 3693, "text": "In that sense, it seems like our tools of understanding the world, I mean, this is mostly centered around the questions of what is life, trying to understand the patterns that are characteristic of life and intelligence, all those kinds of things."}, {"time": 3713, "text": "We're not using the right tools because we're in the system."}, {"time": 3717, "text": "Is there something that resonates with you there?"}, {"time": 3721, "text": "Almost like... Well, yes, we have limitations, of course, in the amount of information we can process."}, {"time": 3732, "text": "On the other hand, we can get help from our Silicon friends and we can get help from all kinds of instruments that make up for our perceptual deficits."}, {"time": 3745, "text": "And we can use, at a conceptual level, we can use different kinds of concepts to address different kinds of questions."}, {"time": 3755, "text": "So I'm not sure exactly what problem she's talking about."}, {"time": 3760, "text": "It's a problem akin to an organism living in a 2D plane trying to understand a three dimensional world."}, {"time": 3767, "text": "Well, we can do that."}, {"time": 3768, "text": "I mean, in fact, for practical purposes, most of our experience is two dimensional."}, {"time": 3775, "text": "It's hard to move vertically."}, {"time": 3777, "text": "And yet we've produced conceptually a three dimensional symmetry and in fact, four dimensional space time."}, {"time": 3785, "text": "So by thinking in appropriate ways and using instruments and getting consistent accounts and rich accounts, we find out what concepts are necessary."}, {"time": 3802, "text": "And I don't see any end in sight of the process or any showstoppers because, let me give you an example."}, {"time": 3812, "text": "I mean, for instance, QCD, our theory of the strong interaction, has nice equations, which I helped to discover."}, {"time": 3820, "text": "What's QCD?"}, {"time": 3821, "text": "Quantum chromodynamics."}, {"time": 3822, "text": "So it's our theory of the strong interaction, the interaction that is responsible for nuclear physics."}, {"time": 3831, "text": "So it's the interaction that governs how quarks and gluons interact with each other and make protons and neutrons and all the strong, the related particles and many things in physics."}, {"time": 3845, "text": "It's one of the four basic forces of nature as we presently understand it."}, {"time": 3849, "text": "And so we have beautiful equations, which we can test in very special circumstances using at high energies, at accelerators."}, {"time": 3865, "text": "So we're certain that these equations are correct."}, {"time": 3868, "text": "Prizes are given for it and so on."}, {"time": 3870, "text": "And people try to knock it down and they can't."}, {"time": 3872, "text": "Yeah, but the situations in which we can calculate the consequences of these equations are very limited."}, {"time": 3886, "text": "So for instance, no one has been able to demonstrate that this theory, which is built on quarks and gluons, which no one, which you don't observe, actually produces protons and neutrons and the things you do observe."}, {"time": 3904, "text": "This is called the problem of confinement."}, {"time": 3907, "text": "So no one's been able to prove that analytically in a way that a human can understand."}, {"time": 3913, "text": "On the other hand, we can take these equations to a computer, to gigantic computers and compute."}, {"time": 3920, "text": "And by God, you get the world from it."}, {"time": 3925, "text": "So these equations in a way that we don't understand in terms of human concepts, we can't do the calculations, but our machines can do them."}, {"time": 3939, "text": "So with the help of what I like to call our silicon friends and their descendants in the future, we can understand in a different way that allows us to understand more."}, {"time": 3953, "text": "But I don't think we'll ever, no human is ever going to be able to solve those equations in the same way."}, {"time": 3960, "text": "So, but I think that's, you know, when we find limitations to our natural abilities, we can try to find workarounds."}, {"time": 3972, "text": "And sometimes that's appropriate concepts."}, {"time": 3975, "text": "Sometimes it's appropriate instruments."}, {"time": 3977, "text": "Sometimes it's a combination of the two."}, {"time": 3979, "text": "But I think it's premature to get defeatist about it."}, {"time": 3986, "text": "I don't see any logical contradiction or paradox or limitation that will bring this process to a halt."}, {"time": 3998, "text": "Well, I think the idea is to continue thinking outside the box in different directions, meaning just like how the math allows us to think in multiple dimensions outside of our perception system, sort of thinking, you know, coming up with new tools of mathematics or computation or all those kinds of things to take different perspectives on our universe."}, {"time": 4024, "text": "Well, I'm all for that."}, {"time": 4025, "text": "You know, and I kind of have even elevated into a principle which is of complementarity following Bohr that you need different ways of thinking even about the same things in order to do justice to their reality and answer different kinds of questions about them."}, {"time": 4043, "text": "I mean, we've several times alluded to the fact that human beings are hard to understand and the concepts that you use to understand human beings if you wanna prescribe drugs for them or see what's gonna happen if they move very fast or are exposed to radiation."}, {"time": 4065, "text": "And so that requires one kind of thinking that's very physical based on the fact that the materials that were made out of."}, {"time": 4075, "text": "On the other hand, if you want to understand how a person's going to behave in a different kind of situation, you need entirely different concepts from psychology and there's nothing wrong with that."}, {"time": 4088, "text": "You can have very different ways of addressing the same material that are useful for different purposes, right?"}, {"time": 4094, "text": "Can you describe this idea which is fascinating of complementarity a little bit?"}, {"time": 4098, "text": "Sort of first of all, what state is the principle?"}, {"time": 4106, "text": "And second of all, what are good examples starting from quantum mechanics?"}, {"time": 4110, "text": "You used to mention psychology."}, {"time": 4112, "text": "Let's talk about this more."}, {"time": 4113, "text": "It's like in your new book one of the most fascinating ideas actually."}, {"time": 4118, "text": "I think it's a wonderful, yeah."}, {"time": 4120, "text": "To me it's, well, it's the culminating chapter of the book and I think since the whole book is about the big lessons or big takeaways from profound understanding of the physical world that we've achieved, including that it's mysterious in some ways, this was the final overarching lesson, complementarity."}, {"time": 4146, "text": "Lesson, complementarity and it's a approach."}, {"time": 4156, "text": "So unlike some of these other things which are just facts about the world, like the world is both big and small and different sizes and is big but we're not small, things we talked about earlier and the fact that the universe is comprehensible and how complexity could emerge from simplicity and so those things are in the broad sense facts about the world."}, {"time": 4179, "text": "Complementarity is more an attitude towards the world than encouraged by the facts about the world."}, {"time": 4186, "text": "And it's the concept or the approach or the realization that it can be appropriate and useful and inevitable and unavoidable to use very different descriptions of the same object or the same system or the same situation to answer different kinds of questions that may be very different and even mutually uninterpretable, immutually incomprehensible."}, {"time": 4227, "text": "But both correct somehow."}, {"time": 4228, "text": "But both correct and sources of different kinds of insight which is so weird."}, {"time": 4234, "text": "But it seems to work in so many cases."}, {"time": 4236, "text": "It works in many cases and I think it's a deep fact about the world and how we should approach it."}, {"time": 4244, "text": "It's most rigorous form where it's actually a theorem if quantum mechanics is correct, occurs in quantum mechanics where the primary description of the world is in terms of wave functions."}, {"time": 4263, "text": "But let's not talk about the world."}, {"time": 4264, "text": "Let's just talk about a particle, an electron."}, {"time": 4269, "text": "The primary description of that electron is its wave function."}, {"time": 4274, "text": "And the wave function can be used to predict where it's gonna be."}, {"time": 4281, "text": "If you observe, it'll be in different places with different probabilities or how fast it's moving."}, {"time": 4287, "text": "And it'll also be moving in different ways with different probabilities."}, {"time": 4292, "text": "That's what quantum mechanics says."}, {"time": 4295, "text": "And you can predict either set of probabilities if you know what's gonna happen if I make an observation of the position or the velocity."}, {"time": 4308, "text": "So the wave function gives you ways of doing both of those."}, {"time": 4311, "text": "But to do it, to get those predictions, you have to process the wave function in different ways."}, {"time": 4317, "text": "You process it one way for position and in a different way for momentum."}, {"time": 4321, "text": "And those ways are mathematically incompatible."}, {"time": 4325, "text": "It's like you have a stone and you can sculpt it into a Venus de Milo or you can sculpt it into David, but you can't do both."}, {"time": 4338, "text": "And that's an example of complementarity."}, {"time": 4340, "text": "To answer different kinds of questions, you have to analyze the system in different ways that are mutually incompatible, but both valid to answer different kinds of questions."}, {"time": 4352, "text": "So in that case, it's a theorem, but I think it's a much more widespread phenomena that applies to many cases where we can't prove it as a theorem, but it's a piece of wisdom, if you like, and appears to be a very important insight."}, {"time": 4373, "text": "And if you ignore it, you can get very confused and misguided."}, {"time": 4382, "text": "Do you think this is a useful hack for ideas that we don't fully understand?"}, {"time": 4390, "text": "Or is this somehow a fundamental property of all or many ideas, that you can take multiple perspectives and they're both true?"}, {"time": 4400, "text": "Well, I think it's both."}, {"time": 4404, "text": "So it's both the answer to all questions."}, {"time": 4407, "text": "It's not either or, it's both."}, {"time": 4408, "text": "It's paralyzing to think that we live in a world that's fundamentally surrounded by complementary ideas."}, {"time": 4419, "text": "Because we somehow want to attach ourselves to absolute truths, and absolute truths certainly don't like the idea of complementarity."}, {"time": 4430, "text": "Yes, Einstein was very uncomfortable with complementarity."}, {"time": 4433, "text": "And in a broad sense, the famous Bohr Einstein debates revolved around this question of whether the complementarity that is a foundational feature of quantum mechanics, as we have it, is a permanent feature of the universe and our description of nature."}, {"time": 4459, "text": "And so far, quantum mechanics wins."}, {"time": 4462, "text": "And it's gone from triumph to triumph."}, {"time": 4466, "text": "Whether complementarity is rock bottom, I guess, you can never be sure."}, {"time": 4471, "text": "I mean, but it looks awfully good and it's been very successful."}, {"time": 4475, "text": "And certainly, complementarity has been extremely useful and fruitful in that domain, including some of Einstein's attempts to challenge it with the famous Einstein Podolsky Rosen experiment turned out to be confirmations that have been useful in themselves."}, {"time": 4503, "text": "But so thinking about these things was fruitful, but not in the way that Einstein hoped."}, {"time": 4507, "text": "Yeah, so as I said, in the case of quantum mechanics and this dilemma or dichotomy between processing the wave function in different ways, it's a theorem."}, {"time": 4530, "text": "They're mutually incompatible and the physical correlate of that is the Heisenberg uncertainty principle you can't have position and momentum determined at once."}, {"time": 4541, "text": "But in other cases, like one that I like to think about or like to point out as an example is free will and determinism."}, {"time": 4552, "text": "It's much less of a theorem and more a kind of way of thinking about things that I think is reassuring and avoids a lot of unnecessary quarreling and confusion."}, {"time": 4576, "text": "The quarreling I'm okay with and the confusion I'm okay with, I mean, people debate about difficult ideas, but the question is whether it could be almost a fundamental truth."}, {"time": 4586, "text": "I think it is a fundamental truth."}, {"time": 4588, "text": "That free will is both an illusion and not."}, {"time": 4592, "text": "Yes, I think that's correct."}, {"time": 4595, "text": "There's a reason why people say quantum mechanics is weird and complementarity is a big part of that."}, {"time": 4605, "text": "To say that our actual whole world is weird, the whole hierarchy of the universe is weird in this kind of particular way, and it's quite profound, but it's also humbling because it's like we're never going to be on sturdy ground in the way that humans like to be."}, {"time": 4629, "text": "It's like you have to embrace that this whole thing is like unsteady mess."}, {"time": 4638, "text": "It's one of many lessons in humility that we run into in profound understanding of the world."}, {"time": 4648, "text": "The Copernican revolution was one, that the earth is not the center of the universe."}, {"time": 4655, "text": "Darwinian evolution is another, that humans are not the pinnacle of God's creation and the apparent result of deep understanding of physical reality, that mind emerges from matter and there's no call on special life forces or souls."}, {"time": 4689, "text": "These are all lessons in humility, and I actually find complementarity a liberating concept."}, {"time": 4699, "text": "It's, okay, you know, we... Yeah, it is in a way."}, {"time": 4702, "text": "That is what I remember."}, {"time": 4708, "text": "There's a story about Dr. Johnson, and he's talking with Boswell, and Boswell was, they were discussing a sermon that they'd both heard, and the sort of culmination of the sermon was the speaker saying, I accept the universe."}, {"time": 4725, "text": "And Dr. Johnson said, well, damn well better."}, {"time": 4730, "text": "And there's a certain joy in accepting the universe because it's mind expanding."}, {"time": 4737, "text": "And to me, complementarity also suggests tolerance, suggests opportunities for understanding things in different ways that add to rather than detract from understanding."}, {"time": 4765, "text": "So I think it's an opportunity for mind expansion and demanding that there's only one way to think about things can be very limiting."}, {"time": 4776, "text": "On the free will one, that's a trippy one, though."}, {"time": 4778, "text": "To think like I am the decider of my own actions and at the same time I'm not is tricky to think about, but there does seem to be some kind of profound truth in that."}, {"time": 4793, "text": "I get, well, I think it is tied up."}, {"time": 4796, "text": "It will turn out to be tied up when we understand things better with these issues of self awareness and where we get, what we perceive as making choices, what does that really mean and what's going on under the hood."}, {"time": 4812, "text": "But I'm speculating about a future understanding that's not in place at present."}, {"time": 4817, "text": "Your sense there will always be, like as you dig into the self awareness thing, there'll always be some places where complementarity is gonna show up."}, {"time": 4826, "text": "Oh, definitely, yeah."}, {"time": 4828, "text": "I mean, there will be, how should I say?"}, {"time": 4831, "text": "There'll be kind of a God's eye view which sees everything that's going on in the computer or the brain."}, {"time": 4840, "text": "And then there's the brain's own view or the central processor or whatever it is, what we call the self, the consciousness, that's only aware of a very small part of it."}, {"time": 4853, "text": "And those are very different."}, {"time": 4854, "text": "Those are, so the God's eye view can be deterministic while the self view sees free will."}, {"time": 4867, "text": "I'm pretty sure that's how it's gonna work out actually."}, {"time": 4871, "text": "But as it stands, free will is a concept that we definitely, at least I feel I definitely experience, I can choose to do one thing then another."}, {"time": 4881, "text": "And other people I think are sufficiently similar to me that I trust that they feel the same way."}, {"time": 4890, "text": "And it's an essential concept in psychology and law and so forth."}, {"time": 4895, "text": "But at the same time, I think that mind emerges from matter and that there's an alternative description of matter that's up to subtleties about quantum mechanics, which I don't think are relevant here, really is deterministic."}, {"time": 4916, "text": "Let me ask you about some particles."}, {"time": 4919, "text": "First the absurd question, almost like a question that like Plato would ask."}, {"time": 4924, "text": "What is the smallest thing in the universe?"}, {"time": 4928, "text": "As far as we know, the fundamental particles out of which we build our most successful description of nature are points."}, {"time": 4940, "text": "They don't have any internal structure."}, {"time": 4947, "text": "So that's as small as can be."}, {"time": 4951, "text": "So what does that mean operationally?"}, {"time": 4954, "text": "That means that they obey equations that describe entities that are singular concentrations of energy, momentum, angular momentum, the things that particles have, but localized at individual points."}, {"time": 4973, "text": "Now that mathematical structure is only revealed partially in the world because to process the wave function in a way that accesses information about the precise position of things, you have to apply a lot of energy and that's an idealization and you can apply infinite amount of energy to determine a precise position."}, {"time": 4999, "text": "But at the mathematical level, we build the world out of particles that are points."}, {"time": 5006, "text": "So do they actually exist and what are we talking about?"}, {"time": 5009, "text": "Oh, they exist."}, {"time": 5010, "text": "So let me ask sort of do quarks exist?"}, {"time": 5013, "text": "Yes, do electrons exist?"}, {"time": 5016, "text": "Yes, do photons exist?"}, {"time": 5018, "text": "But what does it mean for them to exist?"}, {"time": 5068, "text": "So in the case of electrons, we can isolate them and study them and individual ones in great detail and we can check that they all actually are identical and that's why chemistry works and yes."}, {"time": 5085, "text": "So in that case, it's very tangible."}, {"time": 5089, "text": "Similarly with photons, you can study them individually, the units of light and nowadays, it's very practical to study individual photons and determine their spin and their other basic properties and check out the equations in great detail."}, {"time": 5111, "text": "For quarks and gluons, which are the other two main ingredients of our model of matter that's so successful, it's a little more complicated because the quarks and gluons that appear in our equations don't appear directly as particles you can isolate and study individually."}, {"time": 5135, "text": "They always occur within what are called bound states or structures like protons."}, {"time": 5143, "text": "A proton, roughly speaking, is composed of three quarks and a lot of gluons but we can detect them in a remarkably direct way actually nowadays, whereas at relatively low energies, the behavior of quarks is complicated."}, {"time": 5160, "text": "At high energies, they can propagate through space relatively freely for a while and we can see their tracks."}, {"time": 5171, "text": "So ultimately, they get recaptured into protons and other mesons and funny things but for a short time, they propagate freely and while that happens, we can take snapshots and see their manifestations."}, {"time": 5189, "text": "Actually, this kind of thing is exactly what I got the Nobel Prize for, predicting that this would work."}, {"time": 5239, "text": "Can we talk about asymptotic freedom, this very idea that you won the Nobel Prize for?"}, {"time": 5245, "text": "So it describes a very weird effect to me, the weird in the following way."}, {"time": 5253, "text": "So the way I think of most forces or interactions, the closer you are, the stronger the effect, the stronger the force, right?"}, {"time": 5266, "text": "With quarks, the close they are, the less so the strong interaction."}, {"time": 5273, "text": "And in fact, they're basically act like free particles when they're very close."}, {"time": 5281, "text": "But this requires a huge amount of energy."}, {"time": 5284, "text": "Like can you describe me why, how does this even work?"}, {"time": 5291, "text": "How weird it is?"}, {"time": 5292, "text": "A proper description must bring in quantum mechanics and relativity and it's, so a proper description and equations, so a proper description really is probably more than we have time for and require quite a bit of patience on your part, but."}, {"time": 5315, "text": "How does relativity come into play?"}, {"time": 5317, "text": "Wait, wait a minute."}, {"time": 5319, "text": "Relativity is important because when we talk about trying to think about short distances, we have to think about very large momenta and very large momenta are connected to very large energy in relativity."}, {"time": 5339, "text": "And so the connection between how things behave at short distances and how things behave at high energy really is connected through relativity in sort of a slightly backhanded way."}, {"time": 5353, "text": "Quantum mechanics indicates that short, to get to analyze short distances, you need to bring in probes that carry a lot of momentum."}, {"time": 5366, "text": "This again is related to uncertainty because it's the fact that you have to bring in a lot of momentum that interferes with the possibility of determining position and momentum at the same time."}, {"time": 5380, "text": "If you want to determine position, you have to use instruments that bring in a lot of momentum."}, {"time": 5385, "text": "And because of that, those same instruments can't also measure momentum because they're disturbing the momentum that, and then the momentum brings in energy and yeah."}, {"time": 5396, "text": "So that there's also the effect that asymptotic freedom comes from the possibility of spontaneously making quarks and gluons for short amounts of time that fluctuate into existence and out of existence."}, {"time": 5416, "text": "And the fact that that can be done with a very little amount of energy and uncertainty and energy translates into uncertainty and time."}, {"time": 5427, "text": "So if you do that for a short time, you can do that."}, {"time": 5431, "text": "Well, it's all comes in a package."}, {"time": 5435, "text": "So I told you it would take a while to really explain, but the results can be understood."}, {"time": 5444, "text": "I mean, we can state the results pretty simply, I think."}, {"time": 5448, "text": "So in everyday life, we do encounter some forces that increase with distance and kind of turn off at short distances."}, {"time": 5459, "text": "That's the way rubber bands work, if you think about it, or if you pull them hard, they resist, but they get flabby if the rubber band is not pulled."}, {"time": 5472, "text": "And so there are, that can happen in the physical world, but what's really difficult is to see how that could be a fundamental force that's consistent with everything else we know."}, {"time": 5484, "text": "And that's what asymptotic freedom is."}, {"time": 5488, "text": "It says that there's a very particular kind of fundamental force that involves special particles called gluons with very special properties that enables that kind of behavior."}, {"time": 5503, "text": "So there were experiment, at the time we did our work, there were experimental indications that quarks and gluons did have this kind of property, but there were no equations that were capable of capturing it."}, {"time": 5519, "text": "And we found the equations and showed how they work and showed how they, that they were basically unique."}, {"time": 5526, "text": "And this led to a complete theory of how the strong interaction works, which is the quantum chromodynamics we mentioned earlier."}, {"time": 5534, "text": "And so that's the phenomenon that quarks and gluons interact very, very weakly when they're close together."}, {"time": 5546, "text": "That's connected through relativity with the fact that they also interact very, very weakly at high energies."}, {"time": 5554, "text": "So if you have, so at high energies, the simplicity of the fundamental interaction gets revealed."}, {"time": 5562, "text": "At the time we did our work, the clues were very subtle, but nowadays at what are now high energy accelerators, it's all obvious."}, {"time": 5571, "text": "So we would have had a much, well, somebody would have had a much easier time 20 years later, looking at the data, you can sort of see the quarks and gluons."}, {"time": 5579, "text": "As I mentioned, they leave these short tracks that would have been much, much easier, but from fundamental, from indirect clues, we were able to piece together enough to make that behavior a prediction rather than a post diction, right?"}, {"time": 5595, "text": "So it becomes obvious at high energies."}, {"time": 5597, "text": "It becomes very obvious."}, {"time": 5599, "text": "When we first did this work, it was frontiers of high energy physics and at big international conferences, there would always be sessions on testing QCD and whether this proposed description of the strong interaction was in fact correct and so forth."}, {"time": 5617, "text": "And it was very exciting."}, {"time": 5619, "text": "But nowadays the same kind of work, but much more precise with calculations to more accuracy and experiments that are much more precise and comparisons that are very precise."}, {"time": 5637, "text": "Now it's called calculating backgrounds because people take this for granted and wanna see deviations from the theory, which would be the new discoveries."}, {"time": 5649, "text": "Yeah, the cutting edge becomes a foundation and the foundation becomes boring."}, {"time": 5655, "text": "Is there some, for basic explanation purposes, is there something to be said about strong interactions in the context of the strong nuclear force for the attraction between protons and neutrons versus the interaction between quarks within protons?"}, {"time": 5675, "text": "Well, quarks and gluons have the same relation basically to nuclear physics as electrons and photons have to atomic and molecular physics."}, {"time": 5689, "text": "So atoms and photons are the dynamic entities that really come into play in chemistry and atomic physics."}, {"time": 5701, "text": "Of course, you have to have the atomic nuclei, but those are small and relatively inert, really the dynamical part."}, {"time": 5709, "text": "And for most purposes of chemistry, you just say that you have this tiny little nucleus, which QCD gives you."}, {"time": 5717, "text": "Don't worry about it."}, {"time": 5717, "text": "It just, it's there."}, {"time": 5719, "text": "The real action is the electrons moving around and exchanging and things like that."}, {"time": 5726, "text": "Okay, but we want it to understand the nucleus too."}, {"time": 5729, "text": "And so atoms are sort of quantum mechanical clouds of electrons held together by electrical forces, which is photons."}, {"time": 5739, "text": "And then this radiation, which is another aspect of photons."}, {"time": 5743, "text": "That's where all the fun happens is the electrons and the photons."}, {"time": 5747, "text": "And the nucleus are kind of the, well, they give the positive charge and most of the mass of matter, but they don't, since they're so heavy, they don't move very much in chemistry."}, {"time": 5763, "text": "And I'm oversimplifying drastically."}, {"time": 5767, "text": "They're not contributing much to the interaction in chemistry."}, {"time": 5772, "text": "For most purposes in chemistry, you can just idealize them as concentrations of positive mass and charge that are, you don't have to look inside, but people are curious what's inside."}, {"time": 5784, "text": "And that was a big thing on the agenda of 20th century physics starting in the 19, well, starting with the 20th century and unfolding throughout of trying to understand what forces held the atomic nucleus together, what it was and so."}, {"time": 5804, "text": "Anyway, the story that emerges from QCD is that very similar to the way that, well, broadly similar to the way that clouds of electrons held together by electrical forces give you atoms and ultimately molecules."}, {"time": 5828, "text": "Protons and neutrons are like atoms made now out of quarks, quark clouds held together by gluons, which are like the photons that give the electric forces, but this is giving a different force, the strong force."}, {"time": 5846, "text": "And the residual forces between protons and neutrons that are leftover from the basic binding are like the residual forces between atoms that give molecules, but in the case of protons and neutrons, it gives you atomic nuclei."}, {"time": 5865, "text": "So again, for definitional purposes, QCD, quantum chromodynamics, is basically the physics of strong interaction."}, {"time": 5874, "text": "Yeah, we understand, we now would understand, I think most physicists would say it's the theory of quarks and gluons and how they interact."}, {"time": 5884, "text": "But it's a very precise, and I think it's fair to say, very beautiful theory based on mathematical symmetry of a high order, and another thing that's beautiful about it is that it's kind of in the same family as electrodynamics."}, {"time": 5906, "text": "The conceptual structure of the equations are very similar."}, {"time": 5911, "text": "They're based on having particles that respond to charge in a very symmetric way."}, {"time": 5917, "text": "In the case of electrodynamics, it's photons that respond to electric charge."}, {"time": 5922, "text": "In the case of quantum chromodynamics, there are three kinds of charge that we call colors, but they're nothing like colors."}, {"time": 5929, "text": "They really are like different kinds of charge."}, {"time": 5931, "text": "But they rhyme with the same kind of, like it's similar kind of dynamics."}, {"time": 5936, "text": "Similar kind of dynamics."}, {"time": 5937, "text": "I'd like to say that QCD is like QED on steroids."}, {"time": 5942, "text": "And instead of one photon, you have eight gluons."}, {"time": 5945, "text": "Instead of one charge, you have three color charges."}, {"time": 5949, "text": "But there's a strong family resemblance between them."}, {"time": 5953, "text": "But the context in which QCD does this thing is it's much higher energies."}, {"time": 5959, "text": "Like that's where it comes to life."}, {"time": 5960, "text": "Well, it's a stronger force, so that to access how it works and kind of pry things apart, you have to inject more energy."}, {"time": 5970, "text": "And so that gives us, in some sense, a hint of how things were in the earlier universe."}, {"time": 5979, "text": "Yeah, well, in that regard, asymptotic freedom is a tremendous blessing because it means things get simpler at high energy."}, {"time": 5988, "text": "The universe was born free."}, {"time": 5990, "text": "Born free."}, {"time": 5990, "text": "That's very good, yes."}, {"time": 5992, "text": "Universe was born."}, {"time": 5993, "text": "So in atomic physics, a similar thing happens in the theory of stars."}, {"time": 5999, "text": "Stars are hot enough that the interactions between electrons and photons, they're liberated."}, {"time": 6007, "text": "They don't form atoms anymore."}, {"time": 6008, "text": "They make a plasma, which in some ways is simpler to understand."}, {"time": 6012, "text": "You don't have complicated chemistry."}, {"time": 6014, "text": "And in the early universe, according to QCD, similarly atomic nuclei dissolved and take the constituent quarks and gluons, which are moving around very fast and interacting in relatively simple ways."}, {"time": 6027, "text": "And so this opened up the early universe to scientific calculation."}, {"time": 6033, "text": "Can I ask you about some other weird particles that make up our universe?"}, {"time": 6037, "text": "What are axions?"}, {"time": 6039, "text": "And what is the strong CP problem?"}, {"time": 6042, "text": "Okay, so let me start with what the strong CP problem is."}, {"time": 6049, "text": "First of all, well, C is charge conjugation, which is the transformation, the notional transformation, if you like, that changes all particles into their antiparticles."}, {"time": 6063, "text": "And the concept of C symmetry, charge conjugation symmetry, is that if you do that, you find the same laws that would work."}, {"time": 6076, "text": "So the laws are symmetric if the behavior that particles exhibit is the same as the behavior you get with all their antiparticles."}, {"time": 6087, "text": "And then P is parity, which is also called spatial inversion."}, {"time": 6095, "text": "It's basically looking at a mirror universe and saying that the laws that are obeyed in a mirror universe, when you look, that the mirror images obey the same laws as the sources of their images."}, {"time": 6110, "text": "There's no way of telling left from right, for instance, that the laws don't distinguish between left and right."}, {"time": 6115, "text": "Now, in the mid 20th century, people discovered that both of those are not quite true."}, {"time": 6125, "text": "Really, the equation that the mirror universe, the universe that you see in a mirror is not gonna obey the same laws as the universe that we actually interpret."}, {"time": 6143, "text": "You would be able to tell if you did the right kind of experiments, which was the mirror and which was the real thing."}, {"time": 6153, "text": "Anyway, that."}, {"time": 6154, "text": "That's the parity and they show that the parity doesn't necessarily hold."}, {"time": 6157, "text": "It doesn't quite hold."}, {"time": 6161, "text": "Examining what the exceptions are turned out to be, to lead to all kinds of insight about the nature of fundamental interactions, especially properties of neutrinos and the weak interaction, it's a long story."}, {"time": 6173, "text": "But it's a very, it's a."}, {"time": 6175, "text": "So you just define the C and the P, the conjugation, the charge conjugation."}, {"time": 6179, "text": "Now that I've done that, I wanna."}, {"time": 6181, "text": "Shove them off."}, {"time": 6184, "text": "Because it's easier to talk about T, which is time reversal symmetry."}, {"time": 6188, "text": "We have very good reasons to think CPT is an accurate symmetry of nature."}, {"time": 6197, "text": "It's on the same level as relativity and quantum mechanics, basically."}, {"time": 6200, "text": "So that better be true."}, {"time": 6203, "text": "Or else we."}, {"time": 6204, "text": "So it's symmetric when you."}, {"time": 6206, "text": "When you do."}, {"time": 6206, "text": "When you do conjugation parity and time."}, {"time": 6208, "text": "And time and space reversal."}, {"time": 6210, "text": "If you do all three, then you get the same physical consequences."}, {"time": 6215, "text": "Now, so, but that means that CP is equivalent to T. But what's observed in the world is that T is not quite an accurate symmetry of nature, either."}, {"time": 6226, "text": "So most phenomena of, at the fundamental level."}, {"time": 6232, "text": "So interactions among elementary particles and the basic gravitational interaction."}, {"time": 6239, "text": "If you ran them backwards in time, you'd get the same laws."}, {"time": 6245, "text": "So if, again, going back."}, {"time": 6248, "text": "This time we don't talk about a mirror, but we talk about a movie."}, {"time": 6253, "text": "If you take a movie and then run it backwards, that's the time reversal."}, {"time": 6261, "text": "It's good to think about a mirror in time."}, {"time": 6263, "text": "Yeah, it's like a mirror in time."}, {"time": 6265, "text": "If you run the movie backwards, it would look very strange if you were looking at complicated objects and a Charlie Chaplin movie or whatever."}, {"time": 6277, "text": "It would look very strange if you ran it backwards in time."}, {"time": 6280, "text": "But at the level of basic interactions, if you were able to look at the atoms and the quarks involved, they would obey the same laws."}, {"time": 6289, "text": "They do a very good approximation, but not exactly."}, {"time": 6293, "text": "So this is not exactly, that means you could tell."}, {"time": 6295, "text": "You could tell, but you'd have to do very, very subtle experiments with at high energy accelerators to take a movie that looked different when you ran it backwards."}, {"time": 6308, "text": "This was a discovery by two great physicists named Jim Cronin and Val Fitch in the mid 1960s."}, {"time": 6320, "text": "Previous to that, over all the centuries of development of physics with all its precise laws, they did seem to have this gratuitous property that they look the same if you run the equations backwards."}, {"time": 6333, "text": "It's kind of an embarrassing property actually because life isn't like that."}, {"time": 6338, "text": "So empirical reality does not have this imagery in any obvious way."}, {"time": 6342, "text": "And yet the laws did."}, {"time": 6344, "text": "It's almost like the laws of physics are missing something fundamental about life if it holds that property, right?"}, {"time": 6351, "text": "Well, that's the embarrassing nature of it."}, {"time": 6354, "text": "Yeah, it's embarrassing."}, {"time": 6391, "text": "And that's still an interesting endeavor."}, {"time": 6395, "text": "And actually it's an exciting frontier of physics now to sort of explore the boundary between when that's true and when it's not true."}, {"time": 6402, "text": "When you get to smaller objects and exceptions like time crystals."}, {"time": 6407, "text": "I definitely have to ask you about time crystals in a second here."}, {"time": 6410, "text": "But so the CP problem and T, so there's all of these."}, {"time": 6415, "text": "We're in danger of infinite regress, but we have to convert soon."}, {"time": 6420, "text": "Can't possibly be turtles all the way down."}, {"time": 6422, "text": "We're gonna get to the bottom turtle."}, {"time": 6423, "text": "So it became, so it got to be a real, I mean, it's a really puzzling thing why the laws should have this very odd property that we don't need."}, {"time": 6436, "text": "And in fact, it's kind of an embarrassment in addressing empirical reality."}, {"time": 6442, "text": "But it seemed to be almost, it seemed to be exactly true for a long time."}, {"time": 6446, "text": "And then almost true."}, {"time": 6449, "text": "And in way, almost true is even, is more disturbing than exactly true because exactly true, it could have been just a fundamental feature of the world."}, {"time": 6459, "text": "And at some level you just have to take it as it is."}, {"time": 6462, "text": "And if it's a beautiful, easily articulatable regularity, you could say that, okay, that's fine as a fundamental law of nature."}, {"time": 6471, "text": "But to say that it's approximately true, but not exactly, that's weird."}, {"time": 6476, "text": "So, and then, so there was great progress in the late part of the 20th century in getting to an understanding of fundamental interactions in general that shed light on this issue."}, {"time": 6494, "text": "It turns out that the basic principles of relativity and quantum mechanics, plus the kind of high degree of symmetry that we found, the so called gauge symmetry that characterizes the fundamental interactions, when you put all that together, it's a very, very constraining framework."}, {"time": 6517, "text": "And it has some indirect consequences because the possible interactions are so constrained."}, {"time": 6525, "text": "And one of the indirect consequences is that the possibilities for violating the symmetry between forwards and backwards in time are very limited."}, {"time": 6537, "text": "They're basically only two."}, {"time": 6541, "text": "And one of them occurs and leads to a very rich theory that explains the Cronin Fish experiment and a lot of things that have been done subsequently has been used to make all kinds of successful predictions."}, {"time": 6553, "text": "So that's turned out to be a very rich interaction."}, {"time": 6559, "text": "It's esoteric and the effects only show up at accelerators and are small and so on, but they might've been very important in the early universe and lead to them be connected to the asymmetry between matter and antimatter in the present universe."}, {"time": 6572, "text": "And so, but that's another digression."}, {"time": 6576, "text": "The point is that that was fine."}, {"time": 6580, "text": "That was a triumph to say that there was one possible kind of interaction that would violate time reversal symmetry."}, {"time": 6587, "text": "And sure enough, there it is."}, {"time": 6589, "text": "But the other kind doesn't occur."}, {"time": 6594, "text": "So we still got a problem."}, {"time": 6595, "text": "Why doesn't it occur?"}, {"time": 6599, "text": "So we're close to really finally understanding this profound gratuitous feature of the world that is almost but not quite symmetric under reversing the direction of time, but not quite there."}, {"time": 6612, "text": "And to understand that last bit is a challenging frontier of physics today."}, {"time": 6622, "text": "And we have a promising proposal for how it works, which is a kind of theory of evolution."}, {"time": 6631, "text": "So there's this possible interaction, which we call a coupling, and there's a numerical quantity that tells us how strong that is."}, {"time": 6641, "text": "And traditionally in physics, we think of these kinds of numerical quantities as constants of nature that you just have to put them in."}, {"time": 6654, "text": "From experiment, they have a certain value and that's it."}, {"time": 6657, "text": "And who am I to question what God doing?"}, {"time": 6661, "text": "They're just constant."}, {"time": 6662, "text": "Well, they seem to be just constants."}, {"time": 6664, "text": "I'm just wondering."}, {"time": 6666, "text": "But in this case, it's been fruitful to think and work out a theory where that strength of interaction is actually not a constant."}, {"time": 6683, "text": "It's a fun, it's a field."}, {"time": 6687, "text": "It's a, fields are the fundamental ingredients of modern physics."}, {"time": 6692, "text": "Like there's an electron field, there's a photon field, which is also called the electromagnetic field."}, {"time": 6697, "text": "And so all of these particles are manifestations of different fields."}, {"time": 6701, "text": "And there could be a field, something that depends on space and time."}, {"time": 6707, "text": "So a dynamical entity instead of just a constant here."}, {"time": 6713, "text": "And if you do things in a nice way, that's very symmetric, very much suggested aesthetically by the theory."}, {"time": 6722, "text": "But the theory we do have, then you find that you get a field which as it evolves from the early universe, settles down to a value that's just right to make the laws very nearly exact, invariant or symmetric with respect to reversal of time."}, {"time": 6753, "text": "It might appear as a constant, but it's actually a field that evolved over time."}, {"time": 6756, "text": "It evolved over time, okay."}, {"time": 6758, "text": "But when you examine this proposal in detail, you find that it hasn't quite settled down to exactly zero."}, {"time": 6767, "text": "There it's still, the field is still moving around a little bit."}, {"time": 6772, "text": "And because the motion is so, the motion is so difficult."}, {"time": 6779, "text": "The material is so rigid."}, {"time": 6780, "text": "And this material, the field that fills all space is so rigid."}, {"time": 6783, "text": "Even small amounts of motion can involve lots of energy."}, {"time": 6788, "text": "And that energy takes the form of particles, fields that are in motion are always associated with particles."}, {"time": 6798, "text": "And those are the axioms."}, {"time": 6800, "text": "And if you calculate how much energy is in these residual oscillations, this axiom gas that fills all the universe, if this fundamental theory is correct, you get just the right amount to make the dark matter that astronomers want."}, {"time": 6819, "text": "And it has just the right properties."}, {"time": 6821, "text": "So I'd love to believe that."}, {"time": 6824, "text": "So that might be a thing that unlocks, might be the key to understanding dark matter."}, {"time": 6830, "text": "Yeah, I'd like to think so."}, {"time": 6831, "text": "And many, many physicists are coming around to this point of view, which I've been a voice in the wilderness."}, {"time": 6838, "text": "I was a voice in the wilderness for a long time, but now it's become very popular, maybe even dominant."}, {"time": 6844, "text": "So almost like, so this axion particle slash field would be the thing that explains dark matter."}, {"time": 6853, "text": "It explains, yeah, would solve this fundamental question of finally, of why the laws are almost, but not quite exactly the same if you run them backwards in time."}, {"time": 6866, "text": "And then seemingly in a totally different conceptual universe, it would also provide, give us an understanding of the dark matter."}, {"time": 6878, "text": "That's not what it was designed for."}, {"time": 6881, "text": "And the theory wasn't proposed with that in mind, but when you work out the equations, that's what you get."}, {"time": 6887, "text": "That's always a good sign."}, {"time": 6891, "text": "I think I vaguely read somewhere that there may be early experimental validation of axion."}, {"time": 6899, "text": "Is that, am I reading the wrong?"}, {"time": 6903, "text": "Well, there've been quite a few false alarms and I think there are some of them still, people desperately wanna find this thing."}, {"time": 6910, "text": "And, but I don't think any of them are convincing at this point, but there are very ambitious experiments and kind of new, you have to design new kinds of antennas that are capable of detecting these predicted particles."}, {"time": 6928, "text": "And it's very difficult."}, {"time": 6929, "text": "They interact very, very weakly."}, {"time": 6931, "text": "If it were easy, it would have been done already."}, {"time": 6933, "text": "But I think there's good hope that we can get down to the required sensitivity and actually test whether these ideas are right in coming years or maybe decades."}, {"time": 6947, "text": "And then understand one of the big mysteries, like literally big in terms of its fraction of the universe is dark matter."}, {"time": 6956, "text": "Let me ask you about, you mentioned a few times, time crystals."}, {"time": 6962, "text": "These things are, it's a very beautiful idea when we start to treat space and time as similar frameworks."}, {"time": 6974, "text": "Physical phenomena."}, {"time": 6975, "text": "Right, that's what motivated it."}, {"time": 6977, "text": "First of all, what are crystals?"}, {"time": 6980, "text": "And what are time crystals?"}, {"time": 6980, "text": "Okay, so crystals are orderly arrangements of atoms in space."}, {"time": 6987, "text": "And many materials, if you cool them down gently, will form crystals."}, {"time": 6998, "text": "And so we say that that's a state of matter that forms spontaneously."}, {"time": 7005, "text": "And an important feature of that state of matter is that the end result, the crystal, has less symmetry than the equations that give rise to the crystal."}, {"time": 7023, "text": "So the equations, the basic equations of physics are the same if you move a little bit."}, {"time": 7032, "text": "So you can move, they're homogeneous, but crystals aren't."}, {"time": 7036, "text": "The atoms are in particular place, so they have less symmetry."}, {"time": 7040, "text": "And time crystals are the same thing in time, basically."}, {"time": 7047, "text": "But of course, so it's not positions of atoms, but it's orderly behavior that certain states of matter will arrange themselves into spontaneously if you treat them gently and let them do what they want to do."}, {"time": 7066, "text": "But repeat in that same way indefinitely."}, {"time": 7070, "text": "That's the crystalline form."}, {"time": 7071, "text": "You can also have time liquids, or you can have all kinds of other states of matter."}, {"time": 7077, "text": "You can also have space time crystals where the pattern only repeats if with each step of time, you also move at a certain direction in space."}, {"time": 7087, "text": "So yeah, basically it's states of matter that displace structure in time spontaneously."}, {"time": 7097, "text": "So here's the difference."}, {"time": 7101, "text": "When it happens in time, it sure looks a lot like it's motion, and if it repeats indefinitely, it sure looks a lot like perpetual motion."}, {"time": 7112, "text": "Like looks like free lunch."}, {"time": 7115, "text": "And I was told that there's no such thing as free lunch."}, {"time": 7119, "text": "Does this violate laws of thermodynamics?"}, {"time": 7122, "text": "No, but it requires a critical examination of the laws of thermodynamics."}, {"time": 7127, "text": "I mean, let me say on background that the laws of thermodynamics are not fundamental laws of physics."}, {"time": 7135, "text": "There are things we prove under certain circumstances emerge from the fundamental laws of physics."}, {"time": 7143, "text": "They're not, we don't posit them separately."}, {"time": 7146, "text": "They're meant to be deduced, and they can be deduced under limited circumstances, but not necessarily universally."}, {"time": 7152, "text": "And we're finding some of the subtleties and sort of accept edge cases where they don't apply in a straightforward way."}, {"time": 7162, "text": "And this is one."}, {"time": 7165, "text": "So time crystals do obey, do have this structure in time, but it's not a free lunch because although in a sense, things are moving, they're already doing what they want to do."}, {"time": 7179, "text": "They're in the, so if you want to extract energy from it, you're gonna be foiled because there's no spare energy there."}, {"time": 7190, "text": "So you can add energy to it and kind of disturb it, but you can't extract energy from this motion because it's gonna, it wants to do, that's the lowest energy configuration that there is, so you can't get further energy out of it."}, {"time": 7206, "text": "So in theory, I guess perpetual motion, you would be able to extract energy from it if such a thing was to be created, you can then milk it for energy."}, {"time": 7217, "text": "Well, what's usually meant in the literature of perpetual motion is a kind of macroscopic motion that you could extract energy from and somehow it would crank back up."}, {"time": 7233, "text": "That's not the case here."}, {"time": 7235, "text": "If you want to extract energy, this motion is not something you can extract energy from."}, {"time": 7242, "text": "If you intervene in the behavior, you can change it, but only by injecting energy, not by taking away energy."}, {"time": 7251, "text": "You mentioned that a theory of everything may be quite difficult to come by."}, {"time": 7256, "text": "A theory of everything broadly defined meaning like truly a theory of everything, but let's look at a more narrow theory of everything, which is the way it's used often in physics is a theory that unifies our current laws of physics, general relativity, quantum field theory."}, {"time": 7279, "text": "Do you have thoughts on this dream of a theory of everything in physics?"}, {"time": 7285, "text": "How close are we?"}, {"time": 7286, "text": "Is there any promising ideas out there in your view?"}, {"time": 7289, "text": "Well, it would be nice to have."}, {"time": 7292, "text": "It would be aesthetically pleasing."}, {"time": 7295, "text": "Will it be useful?"}, {"time": 7296, "text": "No, probably not."}, {"time": 7298, "text": "Well, I shouldn't, it's dangerous to say that, but probably not."}, {"time": 7305, "text": "I think we, certainly not in the foreseeable future."}, {"time": 7312, "text": "Maybe to understand black holes."}, {"time": 7314, "text": "Yeah, but that's, yes, maybe to understand black holes, but that's not useful."}, {"time": 7320, "text": "That's my book."}, {"time": 7357, "text": "They're questions about very, very small black holes when quantum effects come into play so that black holes are, not black holes, they're emitting this discovery of Hawking called Hawking radiation, which for astronomical black holes is a tiny, tiny effect that no one has ever observed, it's a prediction that's never been checked."}, {"time": 7384, "text": "So like supermassive black holes, that doesn't apply?"}, {"time": 7386, "text": "No, no, the predicted rate of radiation from those black holes is so tiny that it's absolutely unobservable and is overwhelmed by all kinds of other effects."}, {"time": 7457, "text": "We don't, but."}, {"time": 7459, "text": "But what about the engineering question?"}, {"time": 7461, "text": "So if we look at space travel, so I think you've spoken with him, Eric Weinstein."}, {"time": 7468, "text": "Really, you know, he says things like we want to get off this planet."}, {"time": 7476, "text": "His intuition is almost motivated for the engineering project of space exploration in order for us to crack this problem of becoming a multi planetary species, we have to solve the physics problem."}, {"time": 7489, "text": "His intuition is like, if we figure out this, what he calls the source code, which is like, like a theory of everything might give us clues on how to start hacking the fabric of reality, like getting shortcuts, right?"}, {"time": 7506, "text": "I can't say that, you know, I can't say that it won't, but I can say that in the 1970s and early 1980s, we achieved huge steps in understanding matter."}, {"time": 7523, "text": "QCD, much better understanding of the weak interaction, much better understanding of quantum mechanics in general."}, {"time": 7532, "text": "And it's had minimal impact on technology."}, {"time": 7536, "text": "On rocket design, on propulsion."}, {"time": 7538, "text": "On rocket design, on anything, any technology whatsoever."}, {"time": 7542, "text": "And now we're talking about much more esoteric things."}, {"time": 7546, "text": "And since I don't know what they are, I can't say for sure that they won't affect technology, but I'm very, very skeptical that they would affect technology."}, {"time": 7557, "text": "Because, you know, to access them, you need very exotic circumstances to make new kinds of particles with high energy."}, {"time": 7564, "text": "You need accelerators that are very expensive and you don't produce many of them, and so forth."}, {"time": 7569, "text": "You know, it's just, it's a pipe dream, I think."}, {"time": 7573, "text": "Yeah, about space exploration."}, {"time": 7575, "text": "I'm not sure exactly what he has in mind, but to me, it's more a problem of, I don't know, something between biology and... And information processing."}, {"time": 7594, "text": "Processing, what you mean, how should I..."}, {"time": 7597, "text": "I think human bodies are not well adapted to space."}, {"time": 7603, "text": "Even Mars, which is the closest thing to a kind of human environment that we're gonna find anywhere close by."}, {"time": 7612, "text": "Very, very difficult to maintain humans on Mars."}, {"time": 7617, "text": "And it's gonna be very expensive and very unstable."}, {"time": 7622, "text": "But I think, however, if we take a broader view of what it means to bring human civilization outside of the Earth, if we're satisfied with sending mines out there that we can converse with and actuators that we can manipulate and sensors that we can get feedback from, I think that's where it's at."}, {"time": 7657, "text": "And I think that's so much more realistic."}, {"time": 7661, "text": "And I think that's the long term future of space exploration."}, {"time": 7668, "text": "It's not hauling human bodies all over the place."}, {"time": 7670, "text": "That's just silly."}, {"time": 7674, "text": "It's possible that human bodies..."}, {"time": 7676, "text": "So like you said, it's a biology problem."}, {"time": 7679, "text": "What's possible is that we extend human life span in some way, we have to look at a bigger picture."}, {"time": 7687, "text": "It could be just like you're saying, by sending robots with actuators and kind of extending our limbs."}, {"time": 7696, "text": "But it could also be extending some aspect of our minds, some information, all those kinds of things."}, {"time": 7700, "text": "And it could be cyborgs, it could be, it could be... No, we're talking, not getting the fun."}, {"time": 7706, "text": "It could be, you know, it could be human brains or cells that realize something like human brain architecture within artificial environments, you know, shells, if you like, that are more adapted to the conditions of space."}, {"time": 7727, "text": "And that, yeah, so that's entirely man machine hybrids, as well as sort of remote outposts that we can communicate with."}, {"time": 7739, "text": "I think those will happen."}, {"time": 7742, "text": "Yeah, to me, there's some sense in which, as opposed to understanding the physics of the fundamental fabric of the universe, I think getting to the physics of life, the physics of intelligence, the physics of consciousness will, the physics of information that brings, from which life emerges, that will allow us to do space exploration."}, {"time": 7772, "text": "Yeah, well, I think physics in the larger sense has a lot to contribute here."}, {"time": 7776, "text": "Not the physics of finding fundamental new laws in the sense of another quark or axions even."}, {"time": 7784, "text": "But physics in the sense of, physics has a lot of experience in analyzing complex situations and analyzing new states of matter and devising new kinds of instruments that do clever things."}, {"time": 7801, "text": "Physics in that sense has enormous amounts to contribute to this kind of endeavor."}, {"time": 7809, "text": "But I don't think that looking for a so called theory of everything has much to do with it at all."}, {"time": 7819, "text": "What advice would you give to a young person today with a bit of fire in their eyes, high school student, college student, thinking about what to do with their life, maybe advice about career or bigger advice about life in general?"}, {"time": 7837, "text": "Well, first read fundamentals because there I've tried to give some coherent deep advice."}, {"time": 7845, "text": "That's fundamentals, 10 keys to reality by Frank Kulczyk."}, {"time": 7850, "text": "So that's a good place to start."}, {"time": 7850, "text": "Available everywhere."}, {"time": 7852, "text": "If you wanna learn what I can tell you."}, {"time": 7856, "text": "Is there an audio book?"}, {"time": 7857, "text": "I read that ebook."}, {"time": 7858, "text": "Yes, there is an audio book."}, {"time": 7859, "text": "There's an audio book, that's awesome."}, {"time": 7860, "text": "I think it's, I can give three pieces of wise advice that I think are generally applicable."}, {"time": 7868, "text": "One is to cast a wide net, to really look around and see what looks promising, what catches your imagination and promising."}, {"time": 7885, "text": "Yeah, and those, you have to balance those two things."}, {"time": 7888, "text": "You could have things that catch your imagination, but don't look promising in the sense that the questions aren't ripe or, and things that you, and part of what makes things attractive is that, whether you thought you liked them or not, is if you can see that there's ferment and new ideas coming up that become, that's attractive in itself."}, {"time": 7909, "text": "So when I started out, I thought I was, and when I was an undergraduate, I intended to study philosophy or questions of how mind emerges from matter."}, {"time": 7917, "text": "But I thought that that wasn't really right."}, {"time": 7920, "text": "Timing isn't right yet."}, {"time": 7921, "text": "The right, the timing wasn't right for the kind of mathematical thinking and conceptualization that I really enjoy and am good at."}, {"time": 7932, "text": "But, so that's one thing, cast a wide net, look around."}, {"time": 7938, "text": "And that's a pretty easy thing to do today because of the internet."}, {"time": 7947, "text": "You can look at all kinds of things."}, {"time": 7950, "text": "You have to be careful though because there's a lot of crap also."}, {"time": 7953, "text": "But you can sort of tell the difference if you do a little digging."}, {"time": 7962, "text": "So don't settle on just, what your thesis advisor tells you to do or what your teacher tells you to do."}, {"time": 7969, "text": "Look for yourself and get a sense of what seems promising, not what seemed promising 10 years ago or, so that's one."}, {"time": 7983, "text": "Another thing is to, is kind of complimentary to that."}, {"time": 7989, "text": "Well, they're all complimentary."}, {"time": 7992, "text": "Complimentary to that is to read history and read the masters, the history of ideas and masters of ideas."}, {"time": 8002, "text": "I'd benefited enormously from, as early in my career, from reading in physics, Einstein in the original and Feynman's lectures as they were coming out and Darwin."}, {"time": 8019, "text": "You know, these, you can learn what it, and Galileo, you can learn what it is to wrestle with difficult ideas and how great minds did that."}, {"time": 8028, "text": "You can learn a lot about style, how to write your ideas up and express them in clear ways."}, {"time": 8037, "text": "And also just a couple of that with, I also enjoy reading biographies."}, {"time": 8042, "text": "And biographies, yes, similarly, right, yeah."}, {"time": 8044, "text": "So it gives you the context of the human being that created those ideas."}, {"time": 8048, "text": "Right, and brings it down to earth in the sense that, you know, it was really human beings who did this."}, {"time": 8054, "text": "It's not, and they made mistakes."}, {"time": 8057, "text": "And yeah, I also got inspiration from Bertrand Russell who was a big hero and H.G."}, {"time": 8062, "text": "Wells and yeah."}, {"time": 8065, "text": "So read the masters, make contact with great minds."}, {"time": 8071, "text": "And when you are sort of narrowing down on a subject, learn about the history of the subject because that really puts in context what you're trying to do and also gives a sense of community and grandeur to the whole enterprise."}, {"time": 8086, "text": "And then the third piece of advice is complimentary to both those, which is sort of to get the basics under control as soon as possible."}, {"time": 8100, "text": "So if you wanna do theoretical work in science, you know, you have to learn calculus, multivariable calculus, complex variables, group theory."}, {"time": 8111, "text": "Nowadays, you have to be highly computer literate if you want to do experimental work."}, {"time": 8116, "text": "You also have to be computer literate and you have to learn about electronics and optics and instruments."}, {"time": 8122, "text": "So get that under control as soon as possible because it's like learning a language to produce great works and express yourself fluently and with confidence."}]}, {"title": "Sara Walker: The Origin of Life on Earth and Alien Worlds | Lex Fridman Podcast #198", "id": "-tDQ74I3Ovs", "quotes": [{"time": 269, "text": "Was there heat sources, energy sources?"}, {"time": 271, "text": "So if we talk about the metabolism view of the origin of life, like where was the source of energy?"}, {"time": 278, "text": "Probably the most popular view for where the origin of life happened on Earth is hydrothermal vents because they had sufficient energy."}, {"time": 285, "text": "And so we don't really know a lot about early Earth."}, {"time": 290, "text": "We have some ideas about when oceans first formed and things like that, but the time of the origin of life is kind of not well understood or pinned down and the conditions on Earth at that time are not well known."}, {"time": 302, "text": "But a lot of people do think that there was probably hydrothermal vents which are really hot, chemically active regions, say on the seafloor in modern times, which also would have been present on early Earth."}, {"time": 314, "text": "And they would have provided energy and organics and basically all of the right conditions for the origins of life, which is one of the reasons that we look for these hydrothermal systems when we're talking about life elsewhere too."}, {"time": 327, "text": "Okay, and for the genetic code, the idea is that the RNA is the first, like why would RNA be the first moment you can say it's life?"}, {"time": 337, "text": "I guess the idea is it could both have persistent information and then it can also do some of the work of like what, creating a self sustaining organism?"}, {"time": 349, "text": "Yeah, that's the basic idea."}, {"time": 350, "text": "So the idea is you have, in an RNA molecule, you have a sequence of characters, say, so you can treat it like a string in a computer and it can be copied."}, {"time": 360, "text": "So information can be propagated, which is important for evolution because evolution happens by having inheritance of information."}, {"time": 369, "text": "So for example, like my eyes are brown because my mother's eyes were brown."}, {"time": 373, "text": "So you need that copying of information, but then you also have the ability to perform catalysis, which means that that RNA molecule is not inert in that environment, but it actually interacts with something and could potentially mediate, say, a metabolism that could then fuel the actual reproduction of that molecule."}, {"time": 395, "text": "So in some ways, people think that RNA gives you the most bang for your buck in a single molecule and therefore, it gives you all the features that you might think are life."}, {"time": 409, "text": "And so this is sort of where this RNA world conjecture came from is because of those two properties."}, {"time": 414, "text": "Isn't it amazing that RNA came to be in general?"}, {"time": 419, "text": "Yes, that is amazing."}, {"time": 421, "text": "Okay, so we're not talking down about RNA."}, {"time": 423, "text": "No, no, I love RNA."}, {"time": 424, "text": "It's one of my favorite molecules."}, {"time": 426, "text": "I think it's beautiful."}, {"time": 426, "text": "It's just not step one."}, {"time": 428, "text": "Yeah, I think the issue, it's not even the RNA world is a problem and actually, if you really dig into it, the RNA world is not one hypothesis."}, {"time": 439, "text": "It is a set of hypothesis, hypotheses, sorry."}, {"time": 442, "text": "And they range from a molecule of RNA spontaneously emerged on the early Earth and started evolving, which is kind of like the hardest RNA world scenario, which is the one I cited and I get a little animated about because it seems so blatantly wrong to me, but that's a separate story."}, {"time": 460, "text": "And then the other one is actually something I agree with, which is that you can say there was an RNA world because RNA was the first genetic material for life on Earth."}, {"time": 470, "text": "So an RNA world could just be the earliest organisms that had genetics in a modern sense, didn't have DNA evolved yet, they had RNA, right?"}, {"time": 481, "text": "And so that's sort of a softer RNA world scenario in the sense that it doesn't mean it was the first thing that happened, but it was a thing that definitely was part of the lineage of events that led to us."}, {"time": 492, "text": "So if a life was like a best of album, it would be on the, it'd be one of the songs on there."}, {"time": 498, "text": "One of the early songs."}, {"time": 500, "text": "It's on the greatest hits."}, {"time": 501, "text": "Greatest hits, that's the word I was looking for."}, {"time": 504, "text": "Did life, do you think, originate once, twice, three times on Earth, multiple times?"}, {"time": 511, "text": "I think that's a really difficult question."}, {"time": 513, "text": "Is it an important question?"}, {"time": 515, "text": "It's a super important question."}, {"time": 516, "text": "No, it's a really important question."}, {"time": 519, "text": "And so there's a lot of questions in that question."}, {"time": 525, "text": "So one of the first ones that I think needs to be addressed is is the origin of life a continuous process on our planet?"}, {"time": 532, "text": "So we think about the origin of life as something that happened on Earth, say almost 4 billion years ago, because we have evidence of life emerging very early on our planet."}, {"time": 542, "text": "And then an origin of life event, quote unquote, a singular event, whatever that was, happened."}, {"time": 548, "text": "And then all life on Earth that we know is a descendant of that particular event in our universe, right?"}, {"time": 554, "text": "And so, but we don't have any idea one way or the other if the origin of life is happening repeatedly, and maybe it's just not taking off because life is already established."}, {"time": 567, "text": "That's a argument that people will make, or maybe there are alternative forms of life on Earth that we don't even recognize."}, {"time": 575, "text": "So this is the idea of a shadow biosphere that there actually might just be completely other life on Earth, but it's so alien that we don't even know what it is."}, {"time": 582, "text": "I'm gonna have to talk to you about the shadow biosphere."}, {"time": 585, "text": "Yeah, that's a fun one."}, {"time": 586, "text": "In a second, but first, let me ask for the other alternative, which is panspermia."}, {"time": 592, "text": "So that's the idea, the hypothesis that life exists elsewhere in the universe and got to us through like an asteroid or a planetoid or some, according to Wikipedia, space dust, whatever the heck that is."}, {"time": 605, "text": "It sounds fun."}, {"time": 606, "text": "But basically, it rode along whatever kind of rock and got to us."}, {"time": 611, "text": "Do you think that's at all a possibility?"}, {"time": 615, "text": "So I think the reason that most original life scientists are interested in the original life on Earth and say not the original life on Mars and then panspermia, the exchange of life between planets being the explanation is once you start removing the original life from Earth, you know even less about it than you do if you study it on Earth."}, {"time": 636, "text": "Although, I think there are ways of reformulating the problem."}, {"time": 638, "text": "This is why I said earlier, oh, you mean the historical original life problem."}, {"time": 642, "text": "You don't mean the problem of how does life arise in the universe and what the universal principles are because there's this historic problem, how did it happen on early Earth?"}, {"time": 650, "text": "And there's a more tractable general problem of how does it happen?"}, {"time": 655, "text": "And how does it happen is something we can actually ask in the lab."}, {"time": 658, "text": "How did it happen on early Earth is a much more detailed and nuanced question and requires detailed knowledge of what was happening on early Earth that we don't have."}, {"time": 668, "text": "And I'm personally more interested in general mechanisms."}, {"time": 671, "text": "So to me, it doesn't matter if it happened on Earth or it happened on Mars."}, {"time": 675, "text": "It just matters that it happened."}, {"time": 676, "text": "We have evidence it happened."}, {"time": 678, "text": "The question is, did it happen more than once in our universe?"}, {"time": 681, "text": "And so the reason I don't find panspermia as a particularly, I think it's a fascinating hypothesis."}, {"time": 688, "text": "I definitely think it's possible."}, {"time": 690, "text": "And I in particular think it's possible once you get to the stage of life where you have technology because then you obviously can spread out into the cosmos."}, {"time": 700, "text": "But it's also possible for microbes because we know that certain microorganisms can survive the journey in space."}, {"time": 707, "text": "And they can live in a rock and go between Mars and Earth."}, {"time": 710, "text": "Like people have done experiments to try to prove that could work."}, {"time": 714, "text": "So in that scenario, it's super cool because then you get planetary exchange, but say we go look for life on Mars and it ends up being exactly the same life we have on Earth, biochemically speaking, then we haven't really discovered something new about the universe."}, {"time": 726, "text": "What kind of aliens are possible were there other origin of life events?"}, {"time": 730, "text": "If we find, if all the life we ever find is the same origin of life event in the universe, it doesn't help me solve my problem."}, {"time": 736, "text": "But it's possible that that would be a sign that you could separate the environment from the basic ingredients."}, {"time": 745, "text": "So you can have like a life gun that you shoot throughout the universe."}, {"time": 750, "text": "And then like once you shoot it, it's like the Simpsons with a makeup gun."}, {"time": 754, "text": "That was a great episode."}, {"time": 756, "text": "When you shoot this life gun, it'll find the Earth's, it'll like get sticky."}, {"time": 762, "text": "It'll stick to the Earth's."}, {"time": 764, "text": "And that kind of reduces the barrier of like the time it takes, the luck it takes to actually, from nothing, from the basic chemistry, from the basic physics of the universe for the life to spring up."}, {"time": 778, "text": "Yeah, I think this is actually super important to just think about, like does life getting seated on a planet have to be geochemically compatible with that planet?"}, {"time": 788, "text": "So you're suggesting like we could just shoot guns in space and like life could go to Mars and then it would just live there and be happy there."}, {"time": 796, "text": "But that's actually an open question."}, {"time": 798, "text": "So one of the things I was gonna say in response to your question about whether the origin of life happened once or multiple times, is for me personally right now in my thinking, although this changes on a weekly basis, but is that I think of life more as a planetary phenomenon."}, {"time": 811, "text": "So I think the origin of life because life is so intimately tied to planetary cycles and planetary processes, and this goes all the way back through the history of our planet, that the origin of life itself grew out of geochemistry and became coupled and controlled geochemistry."}, {"time": 826, "text": "And when we start to talk about life existing on the planet is when we have evidence of life actually influencing properties of the planet."}, {"time": 835, "text": "And so if life is a planetary property, then going to Mars is not a trivial thing because you basically have to make Mars more Earth like."}, {"time": 845, "text": "And so in some sense, like when I think about sort of longterm vision of humans in space, for example, really what you're talking about when you're saying, let's send our civilization to Mars is you're not saying let's send our civilization to Mars, you're saying let's reproduce our planet on Mars."}, {"time": 861, "text": "Like the information from our planet actually has to go to Mars and make Mars more Earth like, which means that you're now having a reproduction process, like a cell reproduces itself to propagate information in the future."}, {"time": 872, "text": "Planets have to figure out how to reproduce their conditions, including geochemical conditions on other planets in order to actually reproduce life in the universe, which is kind of a little bit radical, but I think for longterm sustainability of life on a planet, that's absolutely essential."}, {"time": 887, "text": "Okay, so if we were to think about life as a planetary phenomena, and so life on Mars would be best if it's way different than life on Earth, we have to ask the very basic question of what is life?"}, {"time": 903, "text": "I actually don't think that's the right question to ask."}, {"time": 906, "text": "It took me a long time to get there, right?"}, {"time": 907, "text": "So I... Cross it out."}, {"time": 908, "text": "Yeah, cross it off your list, it's wrong."}, {"time": 913, "text": "No, no, no, I mean, I think it has an answer, but I think the part of the problem is, you know, most of the places in science where we get really stuck is because we don't know what questions to ask."}, {"time": 922, "text": "And so you can't answer a question if you're asking the wrong question."}, {"time": 925, "text": "And I think the way I think about it is obviously I'm interested in what life is."}, {"time": 931, "text": "So I'm being a little cheeky when I say that's the wrong question to ask."}, {"time": 933, "text": "That's exactly like the question that's like the core of my existence."}, {"time": 936, "text": "But I think the way of framing that is what is it about our universe that allows features that we associate life to be there?"}, {"time": 947, "text": "And so really what I guess when I'm asking that question, what I'm after is an explanatory framework for what life is, right?"}, {"time": 954, "text": "And so most people, they try to go in and define life and they say, well, life is say, a self reproducing chemical system capable of Darwinian evolution."}, {"time": 962, "text": "That's a very popular definition for life."}, {"time": 965, "text": "Or life is something that metabolizes and eats."}, {"time": 968, "text": "That is not how I think about life."}, {"time": 970, "text": "What I think about life is there are principles and laws that govern our universe that we don't understand yet, that have something to do with how information interacts with the physical world."}, {"time": 983, "text": "I don't know exactly what I mean even when I say that, because we don't know these rules, but it's a little bit like, I like to use analogies."}, {"time": 992, "text": "You give me time to be like a little long winded for a second, even in as I, but sort of like if you look at the history of physics, for example, this is like, so we are in the period of the development of thought on our planet where we don't understand what we are yet."}, {"time": 1009, "text": "There was a period of thought in the history of our planet where we didn't understand what gravity was."}, {"time": 1013, "text": "And we didn't understand, for example, that planets in the heavens were actually planets or that they operated by the same laws that we did."}, {"time": 1022, "text": "And so there has been this sort of progression of getting a deeper understanding of explaining basic phenomena."}, {"time": 1029, "text": "Like, I'm not gonna drop the cup."}, {"time": 1030, "text": "I'll drop the water bottle."}, {"time": 1032, "text": "Okay, that fell, right?"}, {"time": 1033, "text": "But why did that fall?"}, {"time": 1036, "text": "This is why I'm a theorist, not an experimentalist."}, {"time": 1039, "text": "That could have gone wrong in so many ways."}, {"time": 1040, "text": "I know, it could have, especially if I did the cup and it smashed."}, {"time": 1043, "text": "So if you take this view that there's sort of some missing principles, I associate them to information."}, {"time": 1053, "text": "And what the sort of feeling there is, there's some missing explanatory framework for how our universe works."}, {"time": 1060, "text": "And if we understood that physics, it would explain what we are."}, {"time": 1064, "text": "It might also explain a lot of other features we don't associate to life."}, {"time": 1068, "text": "And so it's a little like people accept the fact that gravity is a universal phenomena."}, {"time": 1074, "text": "But when we wanna study gravity, we study things like large scale, galactic structures or black holes or planets."}, {"time": 1082, "text": "If we wanna understand information and how it operates in the physical world, we study intelligent systems or living systems because they are the manifestation of that physics."}, {"time": 1090, "text": "And the fact that we can't see that clearly yet, or we don't have that explanatory framework, I think it's just because we haven't been thinking about the problem deeply enough."}, {"time": 1098, "text": "But I feel like if you're explaining something, you're deriving it from some more fundamental property."}, {"time": 1104, "text": "And of course, I have to say I'm wearing my physicist hat."}, {"time": 1108, "text": "So I have a huge bias of liking simple, elegant explanations of the universe that really are compelling."}, {"time": 1117, "text": "But I think one of the things that I've sort of maybe in some ways rejected my training as a physicist is that most of the elegant explanations that we have so far don't include us in the universe."}, {"time": 1127, "text": "And I can't help but think there's something really special about what we are."}, {"time": 1130, "text": "And there have to be some deep principles at play there."}, {"time": 1134, "text": "And so that's sort of my perspective on it."}, {"time": 1137, "text": "Now, when you ask me what life is, I have some ideas of what I think it is, but I think that we haven't gotten there yet because we haven't been able to see that structure."}, {"time": 1147, "text": "And just to go back to the gravity example, it's a little like in ancient times, they didn't know, I was talking about stars and heavens and things."}, {"time": 1154, "text": "They didn't know those were governed by the same principles as that darned experiment."}, {"time": 1159, "text": "Here's where I was going with it."}, {"time": 1160, "text": "Once you realize, like Newton did, that heavenly motions and earthly motions are governed by the same principles and you unify terrestrial and celestial motion, you get these more powerful ideas."}, {"time": 1171, "text": "And I think where life is is somehow unifying these abstract ideas of computation and information with the physical world, with matter, and realizing that there's some explanatory framework that's not physics and it's not computation, but it's something that's deeper."}, {"time": 1189, "text": "So answering the question of what is life requires deeply understanding something about the universe as information processing, the universe is computation."}, {"time": 1199, "text": "It's something about, like would, once you come up with an answer to what is life, will the words information and computation be in the paragraph that answer?"}, {"time": 1209, "text": "Oh, damn it, okay."}, {"time": 1210, "text": "I know, it doesn't help, does it?"}, {"time": 1211, "text": "I know, I hate, actually I hate this about what I do because it's so hard to communicate, right, with words."}, {"time": 1216, "text": "Like when you have words that are ideas that have historically described one thing and you're trying to describe something people haven't seen yet, and the words just don't fit."}, {"time": 1227, "text": "So what's wrong, is it too ambiguous, the word information?"}, {"time": 1231, "text": "We could switch to binary if you want."}, {"time": 1233, "text": "Yeah, no, I don't think it's binary either."}, {"time": 1235, "text": "I think information's just loaded."}, {"time": 1236, "text": "I use it, so the other way I might talk about it is the physics of causation, but I think that's worse because causation is even more loaded word than information."}, {"time": 1246, "text": "So causation is fundamental, you think?"}, {"time": 1248, "text": "I do, yeah, and in some sense, I think the physics, so this is the really radical part, some sense, like when I really think about it sort of most deeply, what I think life is is actually the physics of existence, what gets to exist and why."}, {"time": 1262, "text": "And for simple elementary particles, that's not very complicated because the interactions are simple, but for things like you and me and human civilizations, what comes next in the universe is really dependent on what came before, and there's a huge space of possibilities of things that can exist."}, {"time": 1278, "text": "And when I say information and causation, what I mean is why is it that cups evolved in the universe and not some other object that could deliver water and not spill it?"}, {"time": 1289, "text": "I don't know what you would call it."}, {"time": 1291, "text": "Maybe it wouldn't be a cup, but it's a huge, people talk about the space of things that could exist as being actually infinitely large, right?"}, {"time": 1300, "text": "I don't know if I believe in infinity, but I do think that there is something very interesting about the problem of what exists in its relationship to life."}, {"time": 1313, "text": "So do you think the set of things that could exist is finite?"}, {"time": 1318, "text": "It's very large, but if we were to think about the physics of existence, how many shapes of mugs can there be?"}, {"time": 1328, "text": "In the initial programming."}, {"time": 1330, "text": "I should go to the math department for that."}, {"time": 1333, "text": "So that's not a topology question."}, {"time": 1334, "text": "I just mean, maybe another way to ask is what do you think is fundamental to the universe and what is emergent?"}, {"time": 1341, "text": "So if existence, are we supposed to think of that as somehow fundamental, you think?"}, {"time": 1346, "text": "So there's a couple of problems in physics that I think this is related to."}, {"time": 1349, "text": "One is why does mathematics work at describing reality so well?"}, {"time": 1353, "text": "And then there is this problem of we don't understand why the laws of physics are the way they are, or why certain things get to exist, or what put in place the initial condition of our universe."}, {"time": 1364, "text": "There's all of these sort of really deep and big problems, and they all indirectly are related, I think, to the same kind of thing that, our physics is really good if you specify the initial condition at specifying a certain sequence of events, but it doesn't deal with the fact that other things could have happened, which is kind of an informational property, like a counterfactual property."}, {"time": 1388, "text": "And it's not good at explaining this conversation right now."}, {"time": 1395, "text": "There are certain things that are outside the explanatory reach of current physics, and I think they require looking at it from a completely different direction."}, {"time": 1405, "text": "And so I don't wanna have to fine tune the initial condition of the universe to specify precisely all the information in this conversation."}, {"time": 1411, "text": "I think that's a ridiculous assertion."}, {"time": 1413, "text": "But that's sort of like how people wanna frame it when they talk about the standard model is sufficient if we had computing power to basically explain all of life in our existence."}, {"time": 1424, "text": "An interesting thing you said is the way we think about information computation is by observing a particular kind of systems on Earth that exhibit something we think of as intelligence."}, {"time": 1436, "text": "But that's like looking at, I guess, the tip of an iceberg, and we should be really looking at the fundamentals of the iceberg, like what makes water and ice and the chemistry from which intelligence emerges, essentially."}, {"time": 1454, "text": "We can't just couple the information from the physics, and I think that's what we've gotten really good at doing, especially with sort of the modern age where software is so abstracted from hardware."}, {"time": 1469, "text": "But the entire process of biological evolution has basically been built, like been building layers of increasing abstraction."}, {"time": 1476, "text": "And so it's really hard to see that physics in us, but it's much clearer to see it in molecules."}, {"time": 1482, "text": "Yeah, but I guess I'm trying to figure out what do you think are the best tools to look at it?"}, {"time": 1490, "text": "An open mind?"}, {"time": 1491, "text": "Is that a tool?"}, {"time": 1493, "text": "What's the physics of an open mind?"}, {"time": 1496, "text": "I think if we solve that, we'll solve everything."}, {"time": 1498, "text": "I'm saying an open mind because I think the biggest stumbling block to understanding sort of the things I've been trying to articulate, and when I talk also with colleagues that are thinking deeply about these same issues, is none of it is inconsistent with what we know."}, {"time": 1515, "text": "It's just such a radically different perception of the way we understand things now that it's hard for people to get there."}, {"time": 1521, "text": "And in some ways you have to almost forget what you've learned in order to learn something new, right?"}, {"time": 1525, "text": "So I feel like most of my career trying to understand the problem of life has been variously forgetting and then relearning things that I learned in physics."}, {"time": 1535, "text": "And I think you have to have a capacity to learn things, but then accept that things that you learned might not be true or might need refinement or reframing."}, {"time": 1551, "text": "And the best way I can say that is just like with a physics education, there are just certain things you're told in undergrad that are like facts about the world."}, {"time": 1558, "text": "And your physics professors never tell you that those facts actually emerge from a human mind, right?"}, {"time": 1564, "text": "So we're taught to think about, say the laws of physics, for example, as this like autonomous thing that exists outside of our universe and tells our universe how it works."}, {"time": 1573, "text": "But the laws of physics were invented by human minds to describe things that are regularities in our everyday experience."}, {"time": 1579, "text": "They don't exist autonomous to the universe."}, {"time": 1581, "text": "Right, so it's like turtles on top of turtles, but eventually it gets to the human mind, and then you have to explain the human mind with the turtles."}, {"time": 1589, "text": "So you have to, it comes from humans, this understanding, this simplification of the universe, these models."}, {"time": 1596, "text": "There's a guy named Stephen Wolfram."}, {"time": 1598, "text": "There's a concept called cellular automata."}, {"time": 1602, "text": "So there's some mysteries in these systems that are computational in nature that have maybe echoes of the kind of mysteries we should need to solve to understand what is life."}, {"time": 1619, "text": "So if we could talk, take a computational view of things, do you think there's something compelling to reducing everything down to computation, like the universe is computation, and then trying to understand life?"}, {"time": 1635, "text": "So throw away the biology, throw away the chemistry, throw away even the physics that you learn undergrad and graduate school, and more look at these simple little systems, whether it's cellular automata or whatever the heck kind of computational systems that operate on simple local rules and then create complexity as they evolve."}, {"time": 1656, "text": "Is it at all, do you think, productive to focus on those kinds of systems to get an inkling of what is life?"}, {"time": 1664, "text": "And if it is, do you think it's possible to come up with some kind of laws and principles about what makes life in those computational systems?"}, {"time": 1676, "text": "So I like cellular automata."}, {"time": 1677, "text": "I think they're good toy models, but mostly where I've thought about them and used them is to actually, let's say, poke at sort of the current conceptual framework that we have and see where the flaws are."}, {"time": 1693, "text": "So I think the part that you're talking about that people find intriguing is that if you have a fairly simple rule and you specify some initial condition and you run that rule on that initial condition, you could get really complex patterns emerging."}, {"time": 1706, "text": "And ooh, doesn't that look lifelike?"}, {"time": 1711, "text": "Well, it's like really surprising, isn't it really surprising?"}, {"time": 1713, "text": "It is really surprising, and they're beautiful."}, {"time": 1715, "text": "And I think they have a lot of nice features associated to them."}, {"time": 1719, "text": "I think the things that I find, yeah, so I do think as a proof of principle that you can get complex things emerging from simple rules."}, {"time": 1730, "text": "As a sort of proof of principle about some of the ways that we might think of computation as being sort of a fundamental principle for dynamical systems and maybe the evolution of the universe as a whole, they're a great model system."}, {"time": 1745, "text": "As an explanatory framework for life, I think they're a bit problematic for the same reason that the laws of physics are a bit problematic."}, {"time": 1756, "text": "And the clearest way I can articulate that is like cellular automata are actually cast in sort of a conceptual framework for how the universe should be described that goes all the way back to Newton, in fact, with this idea that we can have a fixed law of motion, which exists sort of, it's given to you."}, {"time": 1777, "text": "The great programmer in the sky gave you this equation or this rule, and then you just run with it."}, {"time": 1783, "text": "And the rule doesn't have, so a good feature of the rule is it doesn't have specified in the rule information about the patterns it generates."}, {"time": 1791, "text": "So you wouldn't want, for example, my cup or my water bottle or me sitting here to be specified in the laws of physics."}, {"time": 1798, "text": "That would be ridiculous because it wouldn't be a very simple explanation of all the things happening."}, {"time": 1801, "text": "It'd have to explain everything."}, {"time": 1803, "text": "So, and cellular automata have that feature and the laws of physics have that feature."}, {"time": 1809, "text": "But you also need to specify the initial condition."}, {"time": 1813, "text": "And it also, it basically means that everything that happens is sort of a consequence of that initial condition."}, {"time": 1819, "text": "And I think this kind of framework is just not the right one for biology."}, {"time": 1825, "text": "And part of the way that it's easiest to see this is a lot of people talk about self reference being important in life."}, {"time": 1833, "text": "The fact that, you know, like the genome has information encoded in it, that information gets read out."}, {"time": 1841, "text": "It specifies something about the architecture of a cell."}, {"time": 1845, "text": "The architecture of the cell includes the genome."}, {"time": 1847, "text": "So the genome has basically self referential information."}, {"time": 1859, "text": "So there's a lot of parallels there and people have talked about that at depth."}, {"time": 1865, "text": "But the other way of kind of thinking about it in terms of like a more physicsy way of talking about it is that what it looks like in biology is that the rules or the laws depend on the state."}, {"time": 1875, "text": "This is typical in computer science."}, {"time": 1877, "text": "This is obvious to you."}, {"time": 1878, "text": "You know, the update rule depends on the state of the machine, right?"}, {"time": 1880, "text": "But, you know, you don't think about, you know, that being sort of the dynamic in physics."}, {"time": 1887, "text": "It's, you know, the rules given to you and then it's a very special subclass say of computations if, you know, you don't ever change the update."}, {"time": 1896, "text": "But in biology, it seems to be that the state and the law change together as a function of time and we don't have that as a paradigm in physics."}, {"time": 1903, "text": "And so a lot of people talk about this as being kind of a perplexing feature that maybe there are certain scenarios where the laws of physics or the laws that govern a particular system actually change as a function of the state of that system."}, {"time": 1918, "text": "So yeah, the hope of physics, it's a hope, I guess, but often stated as a underlying assumption is that the law is static."}, {"time": 1930, "text": "And even having laws that vary in time and not even as a function of the state is very radical."}, {"time": 1936, "text": "When you..."}, {"time": 1937, "text": "The time in general, like you wanna remove time from the equation as much as possible."}, {"time": 1944, "text": "There's some interesting things in this like when we think sort of more deeply about the actual physics that we're trying to propose governs life with me with collaborators and then also other people that think about similar things that time might actually be fundamental and there really is an ordering to time."}, {"time": 1958, "text": "And that events in the universe are unique because they have a particular, they happen, like an object in the universe requires a certain history of events in order to exist, which therefore suggests that time really does have an ordering."}, {"time": 1970, "text": "I'm not talking about the flow of time and our perception of time, just the ordering of events."}, {"time": 1973, "text": "Causation of things."}, {"time": 1974, "text": "Yes, causation, there's that word again."}, {"time": 1976, "text": "So causation, that's when you say time, you mean causation."}, {"time": 1980, "text": "In your proposed model of the physics of life, the fundamental thing would be causation."}, {"time": 1988, "text": "If you were to bet your money on one particular horse or whatever."}, {"time": 1993, "text": "And then space is emergent."}, {"time": 1996, "text": "So everything's emergent except time."}, {"time": 1999, "text": "Kind of, yeah, or causation."}, {"time": 2001, "text": "And laws change all the time."}, {"time": 2002, "text": "Why does it look like laws are the same?"}, {"time": 2004, "text": "Laws, well, because, well, one way, and I actually, this idea comes from Lee Cronin because I work with him very closely on these things, is that the laws of physics look the way they do because they're low memory laws."}, {"time": 2015, "text": "So they don't require a lot of information to specify them."}, {"time": 2017, "text": "They're very easy for the universe to implement."}, {"time": 2019, "text": "But if you get something like me, for example, I require 4 billion year history to exist in the universe."}, {"time": 2024, "text": "I come with a lot of historical baggage."}, {"time": 2027, "text": "And that's part of what I am as a set of causes that exist in the universe."}, {"time": 2032, "text": "So I have local rules that apply to me that are associated with sort of the information in my history that aren't universal to every object in the universe."}, {"time": 2041, "text": "And there are some things that are very easy to implement low memory rules that apply to everything in the universe."}, {"time": 2048, "text": "So there's no shortcuts to you."}, {"time": 2050, "text": "No, so yeah, I don't believe in things like Boltzmann brains or fluctuations out of the vacuum that can produce things like your desk ornaments."}, {"time": 2061, "text": "I actually think they require a particular causal chain of events to exist."}, {"time": 2066, "text": "Well, I appreciate the togetherness of that, but so how does that, if we have to simulate the entire universe to create the ornaments in the two of us, how are we supposed to create engineer life in the lab?"}, {"time": 2082, "text": "This goes back to sort of the critique of the RNA world."}, {"time": 2085, "text": "I think one of the problems, and I'll get to answer your question, but I think this is kind of relevant here."}, {"time": 2090, "text": "One of the problems with the RNA world, when we test it in the laboratory, is how much information we're putting into the experiment."}, {"time": 2097, "text": "We specify the flasks, we make pure reagents, we mix them, we take them out, we put them in the next flask, we change the pH, we change the UV light, and then we get a molecule, and it's not even an RNA molecule necessarily, it might just be a base, right?"}, {"time": 2111, "text": "And so people don't usually think about the fact that we're agents in the universe making that experiment, and therefore we put a little bit of life into that experiment, because it's part of our biological lineage, in the same sense that I am a part of the biological lineage."}, {"time": 2126, "text": "The experiment is."}, {"time": 2127, "text": "I mean, our ideas are injecting life."}, {"time": 2131, "text": "And the constraints that we put on the experiments, because those conditions wouldn't exist in the universe on planet Earth at that time without us as the boundary condition, right?"}, {"time": 2141, "text": "Even though we're not actually adding any actual chemistry or biology that could be identified as life, are the constraints we're adding to the experiment, the design of the experiment."}, {"time": 2151, "text": "Yeah, you can think of the design experiment as a program."}, {"time": 2153, "text": "You put information in."}, {"time": 2154, "text": "It's an algorithmic procedure that you design the experiment."}, {"time": 2157, "text": "And so the origin of life problem becomes one of minimizing the information we put into physics to actually watch the spontaneous origin of life."}, {"time": 2167, "text": "Can we have, so can, is it possible in the lab to have an information vacuum then?"}, {"time": 2173, "text": "If we could, we would, that would be amazing."}, {"time": 2175, "text": "That's a good question for, more for Lee."}, {"time": 2177, "text": "Yeah, you guys, by the way, for people who don't know, Lee Cronin is, you guys are colleagues."}, {"time": 2183, "text": "I've gotten the chance to listen to the two of you talking."}, {"time": 2186, "text": "There's great sort of chemistry and you're brilliant brainstorming together."}, {"time": 2190, "text": "And there's a really exciting community here of brilliant people from different disciplines working on the problem of life, of complexity, of, I don't know, whatever."}, {"time": 2202, "text": "The words fail us to describe the exact problem we're trying to actually understand here."}, {"time": 2207, "text": "Intelligence, all those kinds of things."}, {"time": 2209, "text": "Okay, so what, from a lab perspective, so Lee, I guess, would you call him a chemist?"}, {"time": 2218, "text": "I think by training he's a chemist, but I think most of the people that work in the field, we do have lost their discipline."}, {"time": 2222, "text": "That's why I couldn't answer your question earlier."}, {"time": 2227, "text": "I don't know what you call him."}, {"time": 2228, "text": "I don't know what I call myself."}, {"time": 2229, "text": "I don't know what I call any of my friends."}, {"time": 2231, "text": "So why is it so hard to create, and it's an interesting question, to create biological life in the lab."}, {"time": 2239, "text": "Like from your perspective, is that an important problem to work on to try to recreate the historical origin of life on Earth or echoes of the historical origin?"}, {"time": 2251, "text": "I think echoes is more appropriate."}, {"time": 2252, "text": "I don't think asking the question of what was the exact historical sequence of events and engineering every step in the process to make exactly the chemistry of life on Earth as we know it is a meaningful way of asking the question."}, {"time": 2266, "text": "And it's a little bit like, since you're in computer science, like if you know the answer to a problem, it's easier to find a program to specify the output, right?"}, {"time": 2276, "text": "But if you don't know the answer a priori, finding an algorithm for it, like say finding a prime or something, it's easy to verify it's a prime number."}, {"time": 2284, "text": "It's hard to find the next prime."}, {"time": 2287, "text": "And the way the origin of life is structured right now in the historical problem is you know the answer and you're trying to retrodict it by breaking it down into the set of procedures where you're putting a lot of information in."}, {"time": 2299, "text": "And what we need to do is ask the question of how is it that the rules of how our universe is structured permit things like life to exist and what is the phenomena of life?"}, {"time": 2309, "text": "And those questions are obviously essentially the same question."}, {"time": 2313, "text": "And so you're looking essentially for this missing physics, this missing explanation for what we are, and you need to set up proper experiments that are gonna allow you to probe the vast complexity of chemistry in an unconstrained way with as little information put in as possible to see when things, when does information actually emerge?"}, {"time": 2333, "text": "How does it emerge?"}, {"time": 2337, "text": "And part of the sort of conjecture we have is that this physics only becomes relevant or at least this is my personal conjecture and it's sort of validated by this kind of theory experiment collaboration that we have working in this area that this, you know, sort of, I made the point about like gravity existing everywhere, right?"}, {"time": 2358, "text": "But when you study an atomic nucleus, you don't care about gravity."}, {"time": 2362, "text": "It's not relevant physics there, right?"}, {"time": 2363, "text": "It's weak, it doesn't matter."}, {"time": 2366, "text": "And so this idea that there's kind of a physics associated with information, for me, it's very evident that that physics doesn't become relevant until you need information to specify the existence of a particular object."}, {"time": 2381, "text": "And the scale of reality where that happens is in chemistry because of the combinatorial diversity of chemical objects that can exist far out, exceeds the amount of resources in our universe."}, {"time": 2393, "text": "So if you want it, you can't make every possible protein of length, you know, 200 amino acids, there's not enough resources."}, {"time": 2400, "text": "So in order for this particular protein to exist and this protein to exist in high abundance means that you have to have a system that has knowledge of the existence of that protein and can build it."}, {"time": 2412, "text": "So existence comes to be at the chemical level."}, {"time": 2415, "text": "So existence is most, is best understood at the chemical level."}, {"time": 2420, "text": "It's most evident."}, {"time": 2422, "text": "It's a little bit like, nobody argues that gravity doesn't exist in an atomic nucleus."}, {"time": 2425, "text": "It's just not relevant physics there, right?"}, {"time": 2427, "text": "So the physics of information."}, {"time": 2429, "text": "Is everywhere."}, {"time": 2430, "text": "It exists at every combinatorial scale, but it becomes more and more relevant the more set of possibilities that could exist because you have to specify more and more about why this thing exists and not the infinite."}, {"time": 2441, "text": "It's not an infinite set, but you know, the set of undefined set of other things that could exist."}, {"time": 2446, "text": "So can I ask a weird question, which is, so let's look into the future."}, {"time": 2453, "text": "I try that every day."}, {"time": 2454, "text": "It never works."}, {"time": 2456, "text": "So say a Nobel prize is given in physics, maybe chemistry for discovering the origin of life."}, {"time": 2466, "text": "No, but not the historical origin."}, {"time": 2469, "text": "Some kind of thing that we're talking about."}, {"time": 2472, "text": "What exactly would, what do you think that, like, what do you think that person, maybe you did to get that Nobel prize?"}, {"time": 2484, "text": "Like what would they have to have done?"}, {"time": 2486, "text": "Cause you can do a bunch of experiments that go like within the aha moment."}, {"time": 2490, "text": "Like you rarely get the Nobel prize for like, you've solved everything, we're done."}, {"time": 2497, "text": "It's like some inkling of some deep truth."}, {"time": 2500, "text": "Like what do you think that would actually look like?"}, {"time": 2503, "text": "Would it be an experimental result?"}, {"time": 2506, "text": "I mean, it will have to have some kind of experimental, maybe validation component."}, {"time": 2510, "text": "So what would that look like?"}, {"time": 2512, "text": "This is an excellent question."}, {"time": 2514, "text": "I want to, sorry, I'm going to make a quick point, which is just a slight tangent."}, {"time": 2518, "text": "But you know, like when people ask about the origin of mass, and like looking for the Higgs mechanism and things, they never are like, we need to find the historical origins of life in the early unit."}, {"time": 2527, "text": "Although those things are related, right?"}, {"time": 2528, "text": "So this problem of origins of life in the lab, I think is really important."}, {"time": 2532, "text": "But the Higgs is a good example because you had theory to guide it."}, {"time": 2535, "text": "So somehow you need to have an explanatory framework that can say that we should be looking for these features and explain why they might be there and then be able to do the experiment and demonstrate that it matches with the theory."}, {"time": 2550, "text": "But it has to be something that is outside sort of the paradigm of what we might expect based on what we know, right?"}, {"time": 2556, "text": "So this is a really sort of tall order."}, {"time": 2559, "text": "And I think, I mean, I guess the way people would think about it is like, you know, if you had a bacteria that climbed out of your test tube or something, and it was like, you know, moving around on the surface, that would be ultimate validation."}, {"time": 2572, "text": "You saw the origin of life in an experiment, but I don't think that's quite what we're looking for."}, {"time": 2576, "text": "I think what we're looking for is evidence of when information that originated within the bounds of your experiment and you can demonstrably prove emerged spontaneously in your experiment, wasn't put in by you, actually started to govern the future dynamics of that system and specify it."}, {"time": 2599, "text": "And you could somehow relate those two features directly."}, {"time": 2603, "text": "So you know that the program specifying what's happening in that system is actually internal to that system."}, {"time": 2609, "text": "Like say you have a chemical thing in a box."}, {"time": 2612, "text": "Well, so that's one Nobel Prize winning experiment, which is like information in some fundamental way originated within the constraints of the system without you injecting anything."}, {"time": 2624, "text": "But another experiment is you injected something."}, {"time": 2630, "text": "And got out information."}, {"time": 2632, "text": "So like you injected, I don't know, like some sugar and like something that doesn't necessarily feel like it should be information."}, {"time": 2643, "text": "Yeah, so I actually know, I mean, sugar is information, right?"}, {"time": 2647, "text": "So part of the argument here is that every physical object is, well, it's information, but it's a set of causal histories and also a set of possible futures."}, {"time": 2656, "text": "So there is an experiment that I've talked a lot about with Lee Cronin, but also with Michael Lockman and Chris Kempis who are at Santa Fe about this idea that sometimes we talk about as like seeding assembly, which is you take a high complexity, like an object that exists in the universe because of a long causal history, and you seed it into a system of lower causal history."}, {"time": 2678, "text": "And then suddenly you see all of this complexity being generated."}, {"time": 2681, "text": "So I think another validation of the physics would be, say you engineer an organism by purposefully introducing something where you understand the relationship between the causal history of the organism and the say very complex chemical set of ingredients you're adding to it."}, {"time": 2698, "text": "And then you can predict the future evolution of that system to some statistical set of constraints and possibilities for what it will look like in the future."}, {"time": 2711, "text": "I'm a physical structure, obviously, like I'm composed of atoms, the configuration of them and the fact that they happen to be me is because I'm not actually my atoms, I am a informational pattern that keeps re patterning those atoms into Sarah."}, {"time": 2728, "text": "And I have also associated to me like a space of possible things that could exist that I can help mediate come into existence because of the information in my history."}, {"time": 2741, "text": "And so when you understand sort of that time is a real thing embedded in a physical object, then it becomes possible to talk about how histories when they interact and a history is not a unique thing, it's a set of possibilities."}, {"time": 2759, "text": "When they interact, how do they specify what's coming next?"}, {"time": 2763, "text": "And then where does the novelty come from in that structure?"}, {"time": 2765, "text": "Cause some of it is kind of things that haven't existed in the past can exist in the future."}, {"time": 2769, "text": "Let me ask about this entity that you call Sarah."}, {"time": 2774, "text": "I talk to myself about myself in third person sometimes."}, {"time": 2779, "text": "So maybe this is a good time to bring up consciousness."}, {"time": 2784, "text": "It's been here all along."}, {"time": 2786, "text": "Well, has it?"}, {"time": 2788, "text": "So, I mean that's."}, {"time": 2789, "text": "At least in this conversation, I think I've been conscious most of it, but maybe I haven't."}, {"time": 2793, "text": "So speak for yourself."}, {"time": 2794, "text": "You're projecting your consciousness onto me."}, {"time": 2797, "text": "You don't know if I'm conscious or not."}, {"time": 2801, "text": "Is that, you talked about the physics of existence, you talked about the emergence of causality, sorry, you talked about causality and time being fundamental to the universe."}, {"time": 2815, "text": "Where does consciousness fit into all of this?"}, {"time": 2818, "text": "Like, do you draw any kind of inspiration or value with the idea of panpsychism that maybe one of the things that we ought to understand is the physics of consciousness?"}, {"time": 2832, "text": "Like one of the missing pieces in the physics view of the world is understanding the physics of consciousness."}, {"time": 2840, "text": "Or like that word has so many concepts underneath it, but let's put consciousness as a label on a black box of mystery that we don't understand."}, {"time": 2852, "text": "Do you think that black box holds the key to finally answering the question of the physics of life?"}, {"time": 2860, "text": "The problems are absolutely related."}, {"time": 2862, "text": "I think most, and I'm interested in both because I'm just interested in what we are."}, {"time": 2866, "text": "And to me, the most interesting feature of what we are is our minds and the way they interact with our minds."}, {"time": 2871, "text": "Like minds are the most beautiful thing that exists in the universe."}, {"time": 2873, "text": "So how do they come to be?"}, {"time": 2876, "text": "So when you say we, you mean humans."}, {"time": 2878, "text": "I mean humans right now, but that's because I'm a human."}, {"time": 2881, "text": "Or at least I think I am."}, {"time": 2882, "text": "But you think there's something special to this particular?"}, {"time": 2886, "text": "No, I'm not a human centric thinker."}, {"time": 2891, "text": "But are you one entity?"}, {"time": 2892, "text": "You said a bunch of stuff came together to make a Sarah."}, {"time": 2895, "text": "Like do you think of yourself as one entity or are you just a bunch of different components?"}, {"time": 2900, "text": "Like is there any value to understand the physics of Sarah?"}, {"time": 2904, "text": "Or are you just a bunch of different things that are like a nice little temporary side effect?"}, {"time": 2910, "text": "Yeah, you could think of me as a bundle of information that just became temporarily aggregated into your individual, yeah."}, {"time": 2917, "text": "I agree with that view."}, {"time": 2918, "text": "I'll take that as a compliment actually."}, {"time": 2922, "text": "But nevertheless, that bundle of information has become conscious."}, {"time": 2927, "text": "Or at least keeps calling herself conscious."}, {"time": 2931, "text": "Yeah, I think I'm conscious right now, but I might not be, but that's okay."}, {"time": 2935, "text": "Or you wouldn't know."}, {"time": 2936, "text": "So yeah, so this is the problem."}, {"time": 2937, "text": "So yeah, usually people when they're talking about consciousness are worried about the subjective experience."}, {"time": 2942, "text": "And so I think that's why you're saying, I don't know if you're conscious because I don't know if you're experiencing this conversation right now."}, {"time": 2949, "text": "And nor do you know if I'm experiencing the conversation right now."}, {"time": 2952, "text": "And so this is why this is called the hard problem of consciousness because it seems impenetrable from the outside to know if something's having a conscious experience."}, {"time": 2961, "text": "And I really like the idea of also like the hard problem of matter, which is related to the hard problem of consciousness, which is you don't know the intrinsic properties of an electron not interacting, say for example, with anything else in the universe."}, {"time": 2975, "text": "All the properties of anything that exists in the universe are defined by its interaction because you have to interact with it in order to be able to observe it."}, {"time": 2982, "text": "So we can only actually know the things that are observable from the outside."}, {"time": 2986, "text": "And so this is one of the reasons that consciousness is hard for science because you're asking questions about something that's subjective and supposed to be intrinsic to what that thing is as it exists and how it feels about existing."}, {"time": 2999, "text": "And so I have thought a lot about this problem and its relationship to the problem of life."}, {"time": 3005, "text": "And the only thing I can come up with to try to make that problem scientifically tractable and also relate it to how I think about the physics of life is to ask the question, are there things that can only happen in the universe because there are physical systems that have subjective experience?"}, {"time": 3028, "text": "So does subjective experience have different causes that things that it can cause to occur that would happen in the absence of that?"}, {"time": 3038, "text": "I don't know the answer to that question, but I think that's a meaningful way of asking the question of consciousness."}, {"time": 3043, "text": "I can't ask if you're having experience right now, but I can ask if you having experience right now changes something about you and the way you interact with the world."}, {"time": 3053, "text": "So does stuff happen?"}, {"time": 3056, "text": "It's a good question to ask, does stuff happen if consciousness is?"}, {"time": 3061, "text": "Then it's a real physical thing, right?"}, {"time": 3063, "text": "It has physical consequences."}, {"time": 3064, "text": "I'm a physicist, I'm biased, so I can't get rid of that bias."}, {"time": 3068, "text": "It's really deeply ingrained."}, {"time": 3070, "text": "I've tried, but it's hard."}, {"time": 3072, "text": "But I mean, you're saying information is physical too."}, {"time": 3074, "text": "So like virtual reality, simulation, all that program is physical too in the sense of."}, {"time": 3078, "text": "Yes, everything's physical."}, {"time": 3079, "text": "It's just not physical the way it's represented in our minds."}, {"time": 3082, "text": "Right, so you, I love your Twitter."}, {"time": 3085, "text": "So you tweet these like deep thoughts, deep thoughts."}, {"time": 3089, "text": "That's what a theorist does when she's trying to experiment."}, {"time": 3093, "text": "Is tweet?"}, {"time": 3095, "text": "It's just like sitting there."}, {"time": 3096, "text": "I mean, I could just imagine you sitting there for like hours and all of a sudden just like this thought comes out and you get a little like inkling into the thought process."}, {"time": 3106, "text": "Yeah, usually it's like when I'm running between things and not so much when I've had deep thoughts."}, {"time": 3110, "text": "Well, yeah, so you."}, {"time": 3112, "text": "Deep thoughts are hard to articulate."}, {"time": 3113, "text": "One of the things you tweeted is, ideologically, there are many parallels between the search for neural correlates of consciousness and for chemical correlates of life."}, {"time": 3124, "text": "How the neuroscience and astrobiology communities treat those correlates is entirely different."}, {"time": 3130, "text": "Can you elaborate against this kind of the parallels?"}, {"time": 3134, "text": "It has to do a little bit with the consciousness and the matter thing you're talking about."}, {"time": 3140, "text": "And I can't remember what state of mind I was when I was actually thinking about that."}, {"time": 3144, "text": "But I think part of it is."}, {"time": 3147, "text": "I bet you never thought you were gonna have to analyze your own tweets."}, {"time": 3151, "text": "It's an interesting historical juxtaposition of thinking."}, {"time": 3155, "text": "So the tweet is a historical."}, {"time": 3158, "text": "You're doing an assembly experiment right now because you're bringing a thought from the past into the present and trying to actually."}, {"time": 3163, "text": "In a lab."}, {"time": 3165, "text": "This is experimental science right here on the podcast live."}, {"time": 3171, "text": "So go, let's see how the consciousness evolves on this one."}, {"time": 3173, "text": "Yeah, so in neuroscience, it's kind of accepted that we can't get at the subjective aspect of consciousness."}, {"time": 3181, "text": "So people are very interested in what would be a correlate of consciousness."}, {"time": 3188, "text": "What's a correlate?"}, {"time": 3189, "text": "A correlate is a feature that relates to conscious activity."}, {"time": 3194, "text": "So for example, a verbal report is a correlate of consciousness because I can tell you when I'm conscious."}, {"time": 3202, "text": "And then when I'm sleeping, for example, I can't tell you I'm conscious."}, {"time": 3206, "text": "So we have this assumption that you're not conscious when you're sleeping and you're conscious when you're awake."}, {"time": 3211, "text": "And so that's sort of like a very obvious example, but neuroscientists, which I'm no neuroscientist and I'm not an expert in this field."}, {"time": 3220, "text": "So, but they have very sophisticated ways of measuring activity in our brain and trying to relate that to verbal report and other proxies for whether someone is experiencing something."}, {"time": 3231, "text": "And that's what is meant by neural correlates."}, {"time": 3234, "text": "And then, so when people are trying to think about studying consciousness or developing theories for consciousness, they often are trying to build an experimental bridge to these neural correlates, recognizing the fact that a neural correlate may or may not correspond to consciousness because that problem's hard and there's all these associated issues to it."}, {"time": 3259, "text": "So that's, from a neuroscience perspective, it's like fake it till you make it."}, {"time": 3263, "text": "So you."}, {"time": 3263, "text": "Pretty much, yeah."}, {"time": 3264, "text": "You fake whatever the correlates are and hopefully that's going to summon the thing that is consciousness."}, {"time": 3273, "text": "And so the same thing on the chemical correlates of life."}, {"time": 3277, "text": "That sounds like, that's an awesome concept."}, {"time": 3279, "text": "Is that something that people?"}, {"time": 3281, "text": "No, I just made that up."}, {"time": 3283, "text": "That was original to that tweet."}, {"time": 3283, "text": "You can cite the tweet."}, {"time": 3285, "text": "Maybe I'll write it in a paper someday."}, {"time": 3288, "text": "Chemical correlates of life, that's a good title."}, {"time": 3290, "text": "I mean, first of all, your paper is true that people should check out, have great titles."}, {"time": 3296, "text": "Or papers you're involved with."}, {"time": 3298, "text": "So your tweets and titles are stellar and also your ideas, but the tweets and titles are much more important."}, {"time": 3306, "text": "Ideas will live longer."}, {"time": 3310, "text": "They're much more diffused though."}, {"time": 3312, "text": "Well, it's, yeah, it's the Trojan, the tweet is the Trojan horse of the idea that sticks on for a long time."}, {"time": 3318, "text": "Okay, so is there anything to say about the chemical correlates of life?"}, {"time": 3320, "text": "You're saying they're similar kind of ways of thinking about it, but you mentioned about the communities."}, {"time": 3330, "text": "Yeah, so I think in astrobiology, it's not, there's no concept of chemical correlates of life."}, {"time": 3337, "text": "We don't think about it that way."}, {"time": 3338, "text": "We think if we find molecules that are involved in biology, we found life."}, {"time": 3344, "text": "So I think one of my motivations there was just to separate the fact that life has abstract properties associated to it."}, {"time": 3353, "text": "They become imprinted in material substrates and those substrates are correlates for that thing, but they are not necessarily the thing we're actually looking for."}, {"time": 3362, "text": "The thing that we're looking for is the physics that's organizing that system to begin with, not the particular molecules."}, {"time": 3368, "text": "In the same sense that, you know, your consciousness is not your brain."}, {"time": 3373, "text": "It's instantiated in your brain."}, {"time": 3376, "text": "You know, it has to have a physical substrate, but it's not, the matter is not the thing that you're looking at."}, {"time": 3382, "text": "It's some other, at least not in the way that we have come to look at matter, you know, with traditional physics and things."}, {"time": 3388, "text": "There's something else there and it might be this feature of history I was talking about, our time being actually, you know, physically represented there."}, {"time": 3395, "text": "Do you think consciousness can be engineered?"}, {"time": 3400, "text": "In the same way that life can be engineered?"}, {"time": 3401, "text": "Well, that was a fast answer."}, {"time": 3404, "text": "You don't have a free will."}, {"time": 3405, "text": "That was predestined."}, {"time": 3406, "text": "No, I do have free will, but it's interesting, because I mean, you know, Now you're backtracking."}, {"time": 3412, "text": "And that was predestined."}, {"time": 3413, "text": "Yeah, no, no."}, {"time": 3415, "text": "No, I do believe in free will, but I also think that there's kind of an interesting, you know, like what you're speaking about consciousness."}, {"time": 3423, "text": "What are you consciously aware of versus like what is your subconscious brain actually processing and doing?"}, {"time": 3428, "text": "And sometimes there's conflict between your consciousness and your subconsciousness or your consciousness is a little slower than your subconscious."}, {"time": 3436, "text": "And intuition is a really important feature of that."}, {"time": 3438, "text": "And so a lot of the ways I do my science is guided by intuition."}, {"time": 3442, "text": "So when I give fast answers like that, I think it's usually because I haven't really thought about them and therefore that's probably telling me something."}, {"time": 3449, "text": "Let's continue the deep analysis of your tweets."}, {"time": 3453, "text": "You said that determinism in a tweet, determinism and randomness play important roles in understanding what life is."}, {"time": 3460, "text": "So let me ask on this topic of free will, what is determinism, what is randomness and why the heck do they have anything to do with understanding life?"}, {"time": 3470, "text": "Yeah, and you threw free will in there, just throwing all the stuff in the bag."}, {"time": 3475, "text": "Are they not related, determinism and randomness?"}, {"time": 3476, "text": "No, no, they are related."}, {"time": 3478, "text": "No, no, that's all right."}, {"time": 3479, "text": "I was being unfair."}, {"time": 3480, "text": "You didn't even capitalize the tweet, by the way."}, {"time": 3482, "text": "It was all lowercase."}, {"time": 3483, "text": "I must've been angry."}, {"time": 3485, "text": "Oh, that was saying, can you analyze the emotion behind that?"}, {"time": 3488, "text": "No, I actually did."}, {"time": 3489, "text": "Is it frustration or is it hope?"}, {"time": 3490, "text": "So I already argued that I don't think that can happen without that whole causal history."}, {"time": 3496, "text": "And so I guess in some sense, the determinism for me arises because of the causal history."}, {"time": 3503, "text": "And I'm not really sure actually about whether the universe is random or deterministic."}, {"time": 3509, "text": "I just had this sort of intuition for a long time."}, {"time": 3512, "text": "I'm not sure if I agree with it anymore, but it's still kind of lingering and I don't know what to do with this question."}, {"time": 3517, "text": "But it seems to me, you know, so you asked the question, what is life?"}, {"time": 3521, "text": "But you could also, why life?"}, {"time": 3522, "text": "Why does life exist?"}, {"time": 3523, "text": "What does the universe need life for?"}, {"time": 3525, "text": "Not that the universe has needs, but you know, we have to anthropocentrize things sometimes to talk about them."}, {"time": 3530, "text": "And I had this feeling that if it was possible for a cup or a desk ornament or a phone on Mars to spontaneously fluctuate into existence, the universe didn't need life to create those objects."}, {"time": 3541, "text": "It wasn't necessary for their existence."}, {"time": 3543, "text": "It was just a random fluke event."}, {"time": 3545, "text": "And so somehow to me, it seems that it can't be that those things formed by random processes, they actually have to have a set of causes that accrue and form those things and they have to have that history."}, {"time": 3558, "text": "And so it seems to me that that life was somehow deeply related to the question of whether the underlying rules of our universe had randomness in them or they were fully deterministic."}, {"time": 3569, "text": "And in some ways you can think about life as being the most deterministic part of physics because it's where the causes are precise in some sense."}, {"time": 3579, "text": "Or most stable."}, {"time": 3580, "text": "So like I'm trying..."}, {"time": 3581, "text": "Most stable, yes, most reliable."}, {"time": 3582, "text": "Most reliable for the tools of physics."}, {"time": 3587, "text": "But where's the randomness come from then?"}, {"time": 3590, "text": "Okay, so you were speaking with..."}, {"time": 3594, "text": "I've gone in a tangent, so I'm not sure where we are in the... Yeah."}, {"time": 3598, "text": "All of the universe is a kind of tangent."}, {"time": 3600, "text": "So we're embracing the tangent."}, {"time": 3603, "text": "So free will, you believe at this current time that you have free will."}, {"time": 3609, "text": "I believe my whole life I have free will."}, {"time": 3611, "text": "What is illusion?"}, {"time": 3611, "text": "No, just kidding."}, {"time": 3612, "text": "I still believe it."}, {"time": 3614, "text": "You still believe it."}, {"time": 3615, "text": "So at the same time you think that in your conception of the universe, causality seems to be pretty fundamental."}, {"time": 3624, "text": "Which kind of wants the universe to be deterministic."}, {"time": 3627, "text": "So how the heck do you think you have a free will and yet you value causality?"}, {"time": 3635, "text": "Because I depart from the conception of physics that you can write down an initial condition and a fixed law of motion and that will describe everything."}, {"time": 3645, "text": "There's no incompatibility if you are willing to reject that assertion."}, {"time": 3649, "text": "So where's the randomness?"}, {"time": 3651, "text": "Where's the magic that gives birth to the free will?"}, {"time": 3654, "text": "Is it the randomness of the laws of physics?"}, {"time": 3656, "text": "No, in my mind what free will is, is the fact that I as a physical system have causal control over certain things."}, {"time": 3665, "text": "I don't have causal control over everything, but I have a certain set of things."}, {"time": 3669, "text": "And I'm also, as I described, sort of a nexus of a particular set of histories that exist in the universe and a particular set of futures that might exist."}, {"time": 3678, "text": "And those futures that might exist are in part specified by my physical configuration as me."}, {"time": 3685, "text": "And therefore, it may not be free will in the traditional sense."}, {"time": 3690, "text": "I don't even know what people mean when they're talking about free will, honestly."}, {"time": 3693, "text": "It's like the whole discussion's really muddled."}, {"time": 3695, "text": "But in the sense that I am a causal agent, if you wanna call it that, that exists in the universe, and there are certain things that happen because I exist as me, then yes, I have free will."}, {"time": 3705, "text": "No, but do you, Sarah, have a choice about what's going to happen next?"}, {"time": 3713, "text": "If the universe, could I have, if I run this universe."}, {"time": 3718, "text": "Where does the choice come from?"}, {"time": 3720, "text": "I think that's related to the physics of consciousness."}, {"time": 3722, "text": "So one of the things I didn't say about that, I don't know, maybe this is me just being hopeful because maybe I just wanna have free will, but I don't think that we can rule out the possibility because I don't think that we understand enough about any of these problems."}, {"time": 3734, "text": "But I think one of the things that's interesting for me about the sort of inversion of the question of consciousness that I proposed is one of the features that we do is we have imagination, right?"}, {"time": 3747, "text": "And people don't think about imagination as a physical thing, but it is a physical thing."}, {"time": 3750, "text": "It exists in the universe, right?"}, {"time": 3752, "text": "And so I'm like really intrigued by the fact that say, humans for, another physical system could do this too, it's not special to humans, but for centuries imagined flying machines and rockets, and then we finally built them, right?"}, {"time": 3765, "text": "So they were represented in our minds and on the pages of things that we drew for hundreds of years before we could build those physical objects in the universe."}, {"time": 3774, "text": "But certainly the existence of rockets is in part causally, caused by the fact that we could imagine them."}, {"time": 3783, "text": "And so there seems to be this property that some things don't exist, they've never physically existed in the universe, but we can imagine the possibility of them existing and then cause them to exist, maybe individually or collectively."}, {"time": 3798, "text": "And I think that property is related to what I would say about having choice or free will, because that set of possibilities, those set of things that you can imagine is not constrained to your local physical environment and history."}, {"time": 3842, "text": "It's trippy physics, but it exists, so there you go."}, {"time": 3845, "text": "I mean, in some sense, if you look at like general relativity and gravity morphing space time in that same way, maybe whatever the physics of consciousness might be, it might be morphing, that's like what free will is."}, {"time": 3858, "text": "It's morphing like the space, just like ideas make rockets come to life."}, {"time": 3865, "text": "It's somehow changing the space of possible realizations of like whatever's, yeah, okay, but that's."}, {"time": 3873, "text": "Life is kind of basically, if you wanna think about it, like life is sort of changing the probability distributions over what can exist."}, {"time": 3879, "text": "That's the physics of what life is."}, {"time": 3880, "text": "And then consciousness is this sort of layered property or imagination on top of it that kind of scrambles that a little bit more and like has access to, I don't know."}, {"time": 3890, "text": "It's kind of, we don't know how to describe it, right?"}, {"time": 3893, "text": "Like that's why it's interesting, but."}, {"time": 3894, "text": "But it's probabilistic."}, {"time": 3895, "text": "So you do think like God plays dice."}, {"time": 3897, "text": "So let me."}, {"time": 3898, "text": "No, I think the description is probabilistic."}, {"time": 3900, "text": "I don't necessarily think the underlying physics is probabilistic."}, {"time": 3906, "text": "I think the way that we can describe this physics is going to be probabilistic and statistical, but the under, like when we take measurements in the lab, but the underlying physics itself might still be deterministic."}, {"time": 3918, "text": "Maybe I'm, it's hard to know what concepts to hold on to."}, {"time": 3922, "text": "So I find myself constantly rejecting concepts, but then I have to grab another one and try to hold onto something from intellectual history."}, {"time": 3929, "text": "Well, it's possible that our mind is not able to hold the correct concepts in mind at all."}, {"time": 3933, "text": "Like we're not able to even conceive of them correctly."}, {"time": 3936, "text": "Maybe the word's deterministic or random or not the right even words, concepts to be holding."}, {"time": 3942, "text": "But maybe you can talk to the theory of everything, this attempt in the current set of physical laws to try to unify them."}, {"time": 3950, "text": "Is there any hope that once a theory of everything is developed, and by theory of everything, I mean in a narrow sense of unifying quantum field theory and general relativity, do you think that will contain some, like in order to do that unification, you would have to get something that would then give hints about the physics of life, physics of existence, physics of consciousness."}, {"time": 3975, "text": "Yeah, I used to not, but I actually, I have become increasingly convinced that it probably will."}, {"time": 3983, "text": "And part of the reason is, I think I've talked a little bit already about these holes in physics, like the theories we have in physics, they have problems, they have lots of problems and they're very deep problems and we don't know how to patch them."}, {"time": 3999, "text": "And some of those problems become very evident when you try to patch quantum mechanics and general relativity together."}, {"time": 4005, "text": "So there is this kind of interesting feature that some of the ways of patching that might actually closely resemble the physics of life."}, {"time": 4014, "text": "And so the place where that actually comes up most, and actually we just had a workshop in the Beyond Center where I work at Arizona State University, and Lee Smolin made this point that he thinks that the theory of quantum gravity when we solve it is gonna be the same theory that gives rise to life."}, {"time": 4028, "text": "And I think that I agree with him on some levels because there's something very interesting where, if you look at these sort of causal set theories of gravity where they're looking for space as being emergent."}, {"time": 4041, "text": "And so space time is an emergent concept from a causal set, which is also sort of related, I think, to what Wolfram's doing with his physics project."}, {"time": 4049, "text": "It's the same kind of underlying math that we have in this theory that we've been developing related to life called assembly theory, which is basically trying to look at complex objects like molecules and bacteria and living things as basically being assembled from a set of component parts and that they actually encode all the possible histories that they could have in that physical object."}, {"time": 4076, "text": "So mathematically, all these ideas I think are related."}, {"time": 4079, "text": "I think a lot of people are thinking about this from different perspectives."}, {"time": 4082, "text": "And then constructor theory that David Deutsch and Chiara Marletto have been developing is a totally different angle on it, but I think getting at some similar ideas."}, {"time": 4089, "text": "So it's a really interesting time right now, I think, for the frontiers of physics and how it's relating to maybe deeper principles about what life is."}, {"time": 4095, "text": "So short answer, yes."}, {"time": 4097, "text": "Long winded answer, rewind."}, {"time": 4100, "text": "Can we talk about aliens?"}, {"time": 4102, "text": "Anytime."}, {"time": 4105, "text": "So one, I think one interesting way to sneak up on the question of what is life is to ask what should we look for in alien life?"}, {"time": 4117, "text": "If we were to look out into our galaxy and into the universe and come up with a framework of how to detect alien life, what should we be looking for?"}, {"time": 4129, "text": "Is there like set of rules, like it's both the tools and the tools that are service sensors for certain kind of properties of life."}, {"time": 4141, "text": "So what should we look for in alien life?"}, {"time": 4145, "text": "Yeah, so we have a paper actually coming out on Monday, which is collaboration."}, {"time": 4149, "text": "It's actually really Lee Cronin's lab, but my group worked with him on it and we're working on the theory, which is this idea that we should look for life as high assembly objects."}, {"time": 4160, "text": "What we mean by that is, which is actually observationally measurable."}, {"time": 4164, "text": "And this is one of the reasons that I started working with Lee on these ideas is because being a theorist, it's easy to work in a vacuum."}, {"time": 4169, "text": "It's very hard to connect abstract ideas about the nature of life to anything that's experimentally tractable."}, {"time": 4176, "text": "But what his lab has been able to do is develop this method where they look at a molecule and they break it apart into all its component parts."}, {"time": 4186, "text": "And so you say you used to have some elementary building blocks and you can build up all the ways of putting those together to make the original object."}, {"time": 4192, "text": "And then you look for the shortest path in that space."}, {"time": 4195, "text": "And you say that's sort of the assembly number associated to that object."}, {"time": 4200, "text": "And if that number is higher, it assumes that a longer causal history is necessary to produce that object or more information is necessary to specify the creation of that object in the universe."}, {"time": 4211, "text": "Now, that kind of idea at a superficial level has existed for a long time."}, {"time": 4215, "text": "That kind of idea as a physical observable of molecules is completely novel."}, {"time": 4220, "text": "And what his lab has been able to show is that if you look at a bunch of samples of nonbiological things and biological things, there's this kind of threshold of assembly where as far as the experimental evidence is and also your intuitive intuition would suggest that nonbiological systems don't produce things with high assembly number."}, {"time": 4243, "text": "So this goes back to the idea like a protein is not gonna spontaneously fluctuate into existence on the surface of Mars."}, {"time": 4248, "text": "It requires an evolutionary process and a biological architecture to produce a protein."}, {"time": 4252, "text": "You generalize that argument, a complex molecule or a cup or a desk ornament in this sort of abstract idea of assembly spaces as being the causal history of objects."}, {"time": 4264, "text": "And you can talk about the shortest path from elementary objects to an object given an elementary set of operations."}, {"time": 4270, "text": "And you can experimentally measure that with mass spec."}, {"time": 4274, "text": "And that's basically the sort of the idea."}, {"time": 4277, "text": "I can't get out of my head."}, {"time": 4279, "text": "I'd start imagining Legos and all the Legos I've ever built and how many steps, what is the shortest path to the final little Lego castles?"}, {"time": 4288, "text": "So then like asking about going to look for alien life, the idea is most of the instruments that NASA builds, for example, or any of the space agencies looking for life in the universe are looking for chemical correlates of life, right?"}, {"time": 4301, "text": "But here we have something that is based on properties of molecules."}, {"time": 4306, "text": "It's not a chemical correlate, it's agnostic."}, {"time": 4309, "text": "It doesn't care about the molecule."}, {"time": 4310, "text": "It cares about what is the history necessary to produce this molecule?"}, {"time": 4316, "text": "How complex is it in terms of how much time is needing, how much information is required to produce it?"}, {"time": 4320, "text": "So when you observe a thing on another planet, you're essentially, the process looks like a reverse engineering, trying to figure out what is the shortest path to create that thing."}, {"time": 4331, "text": "Yeah, so most, yeah, and I would say most, like most examples of biology or technology don't take the shortest path, right?"}, {"time": 4338, "text": "But the shortest path is a bound on how hard it is for the universe to make that."}, {"time": 4341, "text": "Yeah, and I guess what you and Lee are saying that there's a heuristic, that's a good metric for like better perhaps than chemical correlates."}, {"time": 4351, "text": "Yes, because it doesn't, it's not contingent on looking for the chemistry of life on earth, on other planets."}, {"time": 4358, "text": "And it also has a deeper explanatory framework associated to it, as far as the kind of theory that we're trying to develop associated to what life is."}, {"time": 4367, "text": "And I think this is one of the problems I have in my field personally in astrobiology is people observe something on earth, say oxygen in the atmosphere or an amino acid in a cell, and then they say, let's go look for that on another planet."}, {"time": 4382, "text": "Let's look for oxygen on exoplanets or let's look for amino acids on Mars."}, {"time": 4386, "text": "And then they assume that's a way of looking for life or even phosphine on Venus."}, {"time": 4393, "text": "But you know, like there's all these examples of let's look for one molecule."}, {"time": 4397, "text": "A molecule is not life."}, {"time": 4398, "text": "Life is a system that patterns particular structures into matter."}, {"time": 4402, "text": "That's like, that's what it is."}, {"time": 4404, "text": "And it doesn't care what molecules are there."}, {"time": 4406, "text": "It's something about the patterns and that structure and that history."}, {"time": 4411, "text": "And if you're looking for a molecule, you're not testing any hypotheses about the nature of what life is."}, {"time": 4416, "text": "It doesn't tell me anything."}, {"time": 4417, "text": "If we discover oxygen on an exoplanet about what kind of life is there, just oxygen on an exoplanet."}, {"time": 4422, "text": "It's not, there's, I guess I think like, when you think about the question, are we alone in the universe?"}, {"time": 4427, "text": "That's a pretty fricking deep question."}, {"time": 4429, "text": "It should have a fricking deep answer."}, {"time": 4431, "text": "It shouldn't just be, there's a molecule on an exoplanet."}, {"time": 4433, "text": "Wow, we solved the problem."}, {"time": 4434, "text": "It should tell us something meaningful about our existence."}, {"time": 4436, "text": "And I feel like we've fallen short on how we're searching for life in terms of actually searching for things like us in this kind of deeper way."}, {"time": 4448, "text": "But how do you do that initial kind of, say I'm walking down the street and I'm looking for that double take test of like, like what the hell is that?"}, {"time": 4457, "text": "Like that initial, like how do we look for the possibility of weirdness or the possibility of high assembly number?"}, {"time": 4467, "text": "Like what would aliens look like if they don't have two eyes and are green?"}, {"time": 4472, "text": "If I knew, I wouldn't probably already solve the problem."}, {"time": 4475, "text": "Right, there's another Nobel Prize in there somewhere."}, {"time": 4477, "text": "Yeah, somewhere in there."}, {"time": 4479, "text": "Well, I think it's kind of, so there is a bias here, right?"}, {"time": 4483, "text": "So we've evolved to recognize life on earth, right?"}, {"time": 4485, "text": "Like I, you know, children at a very early age can tell the difference between a puppy and a plant and then the plant and a chair, for example."}, {"time": 4493, "text": "You know, like it just, it seems innate."}, {"time": 4495, "text": "And so I think, and also because we're life, you know, I think like there's this implicit bias that we should know it when we see it and it should be completely obvious to us."}, {"time": 4506, "text": "But there are a lot of features of our universe that are not completely obvious to us."}, {"time": 4510, "text": "Like the fact that this table is made of atoms and that I'm sitting in a gravitational potential well right now."}, {"time": 4516, "text": "And I guess my point with this is, I think life is much less obvious than we think it is."}, {"time": 4523, "text": "And so it could be in many more forms than we think it is."}, {"time": 4527, "text": "And I guess this goes back to the point about being open minded that we may not know what alien life looks like."}, {"time": 4533, "text": "It might not even be possible to interact with alien life because maybe something about, you know, our informational lineage, it makes it impossible for information from an alien to be copied to us."}, {"time": 4543, "text": "Therefore there's no, you know, so to speak communication channel."}, {"time": 4547, "text": "And I don't mean, you know, verbal communication, just it's not in our observational space."}, {"time": 4552, "text": "Like, you know, there's fundamental questions about why we observe the universe in position rather than momentum, but we also, you know, observe it in terms of certain informational patterns and things like that's what our brain constructs and maybe aliens just interact with a different part of reality than we do."}, {"time": 4568, "text": "That's wildly speculative, but I think, I think."}, {"time": 4572, "text": "But it's possible."}, {"time": 4572, "text": "It's possible and I think it's consistent with the physics."}, {"time": 4575, "text": "So I think the best ways we can ask questions are about life and chemistry and asking questions about if information is a real physical thing, what would its signatures be in matter and how do we recognize those?"}, {"time": 4588, "text": "And I think the ones that are most obvious are the ones I've already articulated."}, {"time": 4593, "text": "You have these objects that seem completely improbable for the universe to produce because the universe doesn't have the design of that object in the laws."}, {"time": 4600, "text": "So therefore an object had to evolve."}, {"time": 4604, "text": "We talk, we call it evolution, but it had to be produced by the universe that then had all of the possible tasks to make that object specified."}, {"time": 4614, "text": "I mean, there's some, like there's an engineering question here of, are there sensors we can create that can give us, can help us discover certain pockets of high assemblies aliens?"}, {"time": 4628, "text": "Like, I mean, there is a hope setting dogs and chairs aside, there's a hope that visually we could detect, like, because our universe, I mean, at least the way we look at it now, like this three dimensional like space time, we can visually comprehend it."}, {"time": 4649, "text": "It's interesting to think like, if we got to hang out, if there's an alien in this room, like would we be able to detect it with our current sensors?"}, {"time": 4659, "text": "Not the fancy kinds, but like web cam."}, {"time": 4661, "text": "Like say standing over there."}, {"time": 4663, "text": "Yeah, standing over there or maybe like in this carpet, see there's all these kinds of patterns, right?"}, {"time": 4668, "text": "I don't know if this carpet is an alien."}, {"time": 4672, "text": "Well, so I see what you're saying."}, {"time": 4676, "text": "So assembly theory is pretty general."}, {"time": 4677, "text": "Like, I mean, we've been applying it to molecules because it makes sense to apply it to molecules, but it's supposed to explain life, like the physics of life."}, {"time": 4687, "text": "So it should explain the things in this room in addition to molecules."}, {"time": 4691, "text": "So I guess, and you can apply it to images and things."}, {"time": 4694, "text": "So I guess the idea you could explore is just looking at everything on planet earth in terms of its assembly structure and then looking for things that aren't part of our biological lineage."}, {"time": 4707, "text": "If they have high assembly, they might be aliens on earth."}, {"time": 4709, "text": "I mean, that is a very kind of rigorous computer vision question."}, {"time": 4712, "text": "Can we visually, is there a strong correlation between certain kind of high assembly objects when they get to the scale where they're visually observable and some, like when it's say projected onto a 2D plane, can we figure out something?"}, {"time": 4729, "text": "I'm glad you brought up the computer vision point because for a while I had this kind of thought in my mind that we can't even see ourselves clearly."}, {"time": 4735, "text": "So one of the things, people are worried about artificial intelligence for a lot of reasons, but I think it's really fascinating because it's like the first time in history that we're building a system that can help us understand ourselves."}, {"time": 4746, "text": "So like, people talk about AI physics, but like, when I look at another person, I don't see them as a 4 billion year lineage, but that's what they are."}, {"time": 4756, "text": "And so is everything here, right?"}, {"time": 4758, "text": "So imagine that we built artificial systems that could actually see that feature of us, what else would they see?"}, {"time": 4766, "text": "And I think that's what you're asking."}, {"time": 4768, "text": "And I think that would be so cool."}, {"time": 4771, "text": "I want that to happen, but I think we're a little ways off from it, but yeah."}, {"time": 4778, "text": "We're going there, I hope."}, {"time": 4780, "text": "Okay, let me ask you, I apologize ahead of time, but let me ask you the internet question."}, {"time": 4785, "text": "So you're a physicist, you ask rigorous questions about the physics of existence and these models of high assembly objects."}, {"time": 4792, "text": "Now, when the internet would see an alien, they would ask two questions."}, {"time": 4796, "text": "One, can I eat it?"}, {"time": 4798, "text": "And two, can I have sex with it?"}, {"time": 4800, "text": "So, the internet is."}, {"time": 4802, "text": "All the existential questions, those are very important ones."}, {"time": 4805, "text": "The internet is very sophisticated."}, {"time": 4807, "text": "It really is, it's gotten our basal cognition pretty good."}, {"time": 4810, "text": "So you kind of mentioned that it's very difficult."}, {"time": 4812, "text": "It's possible that we may not be even able to communicate with it."}, {"time": 4816, "text": "Right, I think the internet has more hope than we do."}, {"time": 4818, "text": "Yeah, it's a hopeful place, yes."}, {"time": 4821, "text": "Do you think in terms of interacting on this very primal level of sharing resources, like what would aliens eat?"}, {"time": 4828, "text": "What would we eat?"}, {"time": 4829, "text": "Would we eat the same thing?"}, {"time": 4831, "text": "Could we potentially eat each other?"}, {"time": 4833, "text": "One person eats the other, or the aliens eat us."}, {"time": 4837, "text": "And the same thing with not sex in general, or reproduction, but genetically mixing stuff."}, {"time": 4842, "text": "Like, would we be able to mix genetic information?"}, {"time": 4846, "text": "Maybe not genetic, but maybe information, right?"}, {"time": 4848, "text": "And I think part of your question is like, so if you think of life as like this history of events that happen in the universe, like there's this question of like, how divergent are those histories, right?"}, {"time": 4859, "text": "So when we get to the scale of technology, it's possible to imagine, although we can't even do it."}, {"time": 4864, "text": "Like imagine all the possible technologies that could exist in the universe."}, {"time": 4866, "text": "But if you think about all the possible chemistries, somehow that seems like a lower dimensional space and a lower set of possibilities."}, {"time": 4872, "text": "So it might be that like when we interact with aliens, we do have to go back to those more basal levels to figure out sort of what the map is, right?"}, {"time": 4882, "text": "Like the sort of where we have a common history."}, {"time": 4885, "text": "We must have a common history somewhere in the universe, but in order to be able to actually interact in a meaningful way, you have to have some shared history."}, {"time": 4893, "text": "I mean, the reason we can exchange genetic information in each other's food or eat each other as food is because we have a shared history."}, {"time": 4900, "text": "So we have to find that shared history."}, {"time": 4902, "text": "We have to find the common ancestor in this causality map, the causality tree."}, {"time": 4907, "text": "Yes, and we have a last universal common ancestor for all life on earth, which I think is sort of the nexus of that causality map for life on earth."}, {"time": 4914, "text": "But the question is where would other aliens diverge on that map?"}, {"time": 4919, "text": "And I mean, so say there's a lot of aliens out there in the universe, each set of organisms will probably have like a number, you know, like Erdos number of like how far, like how far our common ancestor is."}, {"time": 4935, "text": "And so the closer the common ancestor, like it is on earth, the more likely we are to be able to have sexual reproduction."}, {"time": 4944, "text": "Well, it's like sort of like humans having common culture and languages, right?"}, {"time": 4947, "text": "Yeah, it might take a lot of work though with an alien cause you really have to get over a language barrier."}, {"time": 4956, "text": "So it's communication, it's resources."}, {"time": 4960, "text": "I mean, it's all the whole, and I think tied into that is the questions of like who's going to harm who."}, {"time": 4969, "text": "And actually definitions of harm."}, {"time": 4969, "text": "And whether your parents approve, you know, all those kind of questions."}, {"time": 4972, "text": "Whether the common ancestor approves."}, {"time": 4974, "text": "Yeah, that's just very true."}, {"time": 4978, "text": "How many alien civilizations do you think are out there?"}, {"time": 4981, "text": "I don't have intuition for that, which I have always thought was deeply intriguing."}, {"time": 4987, "text": "So, and part of this, I mean, I say it specifically as I don't have intuition for that because it's like one of those questions that you feel around for a while and you really just, you can't see it even though it might be right there."}, {"time": 5000, "text": "And in that sense, it's a little like the quantum to classical can transition."}, {"time": 5005, "text": "You're like really talking about two different kinds of physics."}, {"time": 5008, "text": "And I think that's kind of part of the problem."}, {"time": 5009, "text": "Once we understand the physics, that question might become more meaningful."}, {"time": 5013, "text": "But there's also this other issue, and this was really instilled on me by my mentor, Paul Davies, when I was a postdoc, because he always talks about how, you know, whether aliens are common or rare is kind of just, you know, it like, you know, it follows a wave of popularity and it just depends on like the mood of, you know, what the culture is at the time."}, {"time": 5033, "text": "And I always thought that was kind of an intriguing observation, but also there's this, you know, set of points about if you go by the observational evidence, which we're supposed to do as scientists, right?"}, {"time": 5043, "text": "You know, we have evidence of us and one origin of life event from which we emerged."}, {"time": 5051, "text": "And people wanna make arguments that because that event was rapid or because there's other planets that have properties similar to ours, that that event should be common."}, {"time": 5060, "text": "But you actually can't reason on that because our existence observing that event is contingent on that event happening, which means it could have been completely improbable or very common."}, {"time": 5069, "text": "And Brandon Carter, like clearly articulated that in terms of anthropic arguments a few decades ago."}, {"time": 5075, "text": "So there is this kind of issue that we have to contend with dealing with life that's closer to home than we have to deal with with any other problems in physics, which we're talking about the physics of ourselves."}, {"time": 5085, "text": "And when you're asking about the origin of life event, that event happening in the universe, at least as like our existence is contingent on it."}, {"time": 5092, "text": "And so you can think about sort of fine tuning arguments that way too."}, {"time": 5096, "text": "So, but the sort of otter part of it is like, when I think about how likely it is, I think it's because we don't understand this mechanism yet about how information can be generated spontaneously that I like, cause I can't see that physics clearly yet, even though I have a lot of, you know, like some things around the space of it in my mind, I can't articulate how likely that process is."}, {"time": 5122, "text": "So my honest answer is, I don't know."}, {"time": 5124, "text": "And sometimes that feels like a cop out, but I feel like that's a more honest answer and a more meaningful way of making progress than what a lot of people wanna do, which is say, oh, well, we have a one in 10 chance of having on an exoplanet with Earth like properties because there's lots of Earth like planets out there and life happened fast on Earth."}, {"time": 5140, "text": "Well, so I have kind of a follow up question, but as a side comment, what I really am enjoying about the way you're talking about human beings is you always say, and not to make yourself conscious about it, cause I really, really enjoy it."}, {"time": 5153, "text": "You say we, you don't say humans."}, {"time": 5157, "text": "You say, cause oftentimes like, you know, I don't know, evolutionary biologists will kind of put yourself out as an observer, but it's kind of fascinating to think that you as a human are struggling about your own origins."}, {"time": 5171, "text": "Yes, that's the problem."}, {"time": 5172, "text": "And yeah, and I think, I don't do that deliberately, but I do think that way."}, {"time": 5178, "text": "And this is sort of the inversion from the logic of physics because physics as it's always been constructed has treated us as external observers of the universe."}, {"time": 5186, "text": "And we are not part of the universe."}, {"time": 5187, "text": "And this is why the problem of life, I think demands completely new thinking because we have to think about ourselves as minds that exist in the universe and are at this particular moment in history and looking out at the things around us and trying to understand what we are inside the system, not outside the system."}, {"time": 5203, "text": "We don't have descriptions at a fundamental level that describe us as inside the system."}, {"time": 5208, "text": "And this was my problem with cellular automata also."}, {"time": 5211, "text": "You're always an external observer for a cellular automata."}, {"time": 5214, "text": "You're not in the system."}, {"time": 5215, "text": "What does the cellular automata look like from the inside?"}, {"time": 5218, "text": "I think you just broke my brain with that question."}, {"time": 5221, "text": "But that's the fundamental."}, {"time": 5222, "text": "I thought about that for a long time, but."}, {"time": 5223, "text": "I'm gonna, yeah, that's a really clean formulation of a very fundamental question, because you can only, to understand cellular automata, you have to be inside of it."}, {"time": 5236, "text": "But as a human, sort of a poetic, romantic question, does it make you sad?"}, {"time": 5242, "text": "Does it make you hopeful whether we're alone or not?"}, {"time": 5247, "text": "Like in the different possible versions of that, if we're the highest assembly object in the entire universe, does that give you?"}, {"time": 5257, "text": "At this moment in time, maybe."}, {"time": 5258, "text": "At this moment in the causal."}, {"time": 5259, "text": "Cause we may, I assume we have a future."}, {"time": 5261, "text": "Well, we definitely have a future."}, {"time": 5263, "text": "The question is where that future decreases the assembly."}, {"time": 5267, "text": "Like it could be where at the peak, or we could be just."}, {"time": 5272, "text": "That would be inconsistent with the physics in my mind."}, {"time": 5275, "text": "But so I should give a caveat."}, {"time": 5279, "text": "I've given the caveat that I'm biased as a physicist, but I'm also biased as an eternal optimist."}, {"time": 5283, "text": "So pretty much all of my modes of operation for building theories about the world are not like an Occam's razor, what's the simplest explanation, but what's the most optimistic explanation."}, {"time": 5294, "text": "And part of the reason for that is if you really think explanations have causal power, in the sense that our, like the fact that we have theories about the world has enabled technologies and physically transform the world around us."}, {"time": 5307, "text": "I think I have to take seriously that as a part of the physics I wanna describe and try to build theories of reality that are optimistic about what's coming next because the theories are in part the causes of what comes next."}, {"time": 5322, "text": "So there could be a physics of hope or physics of optimism in there too."}, {"time": 5328, "text": "Is that seems like also, I mean, optimism does seem to be a kind of engine that results in innovation."}, {"time": 5337, "text": "So this is like, why the hell are we trying to come up with new stuff?"}, {"time": 5342, "text": "Oh, so I made this point about thinking life is the physics of existence."}, {"time": 5346, "text": "And it's not just the physics of existence, it's the physics of more things existing."}, {"time": 5351, "text": "So I think one of these drives of like."}, {"time": 5352, "text": "Creativity."}, {"time": 5353, "text": "Yeah, creativity, like optimism."}, {"time": 5356, "text": "So if you like, people like entropy."}, {"time": 5358, "text": "I don't like entropy as it was formulated in the 1800s."}, {"time": 5361, "text": "I think it's an antiquated concept, but this idea of maximizing over the possible number of states that could exist."}, {"time": 5368, "text": "Imagine the universe is actually trying to maximize over the number of things that could physically exist."}, {"time": 5373, "text": "What would be the best way to do that?"}, {"time": 5374, "text": "The best way to do that would be evolve intelligent technological things that could explore that space."}, {"time": 5381, "text": "So, okay, that's talking about alien life out there in the universe, but you've also earlier in the conversation mentioned the shadow biosphere."}, {"time": 5390, "text": "So is it possible that we have weird life here on earth that we're just not, like even in a high assembly formulation of life, that we're just not paying attention to?"}, {"time": 5405, "text": "We're blind to."}, {"time": 5407, "text": "Like life we're potentially able to detect, but we're blind to."}, {"time": 5410, "text": "And maybe you could say, what is the shadow biosphere?"}, {"time": 5413, "text": "Yeah, the shadow biosphere is this idea that there might've been other original life events that happened on earth that were independent from the original life event that led to us and all of the life that we know on earth."}, {"time": 5426, "text": "And therefore there could be aliens in the sense they have a different origin event."}, {"time": 5432, "text": "Living among us."}, {"time": 5434, "text": "And it was proposed by a number of people, but one of them was Paul Davies that I mentioned earlier is my mentor."}, {"time": 5441, "text": "And he has a really cute way of saying that aliens could be right under our noses or even in our noses."}, {"time": 5448, "text": "With a British accent, it sounds better."}, {"time": 5450, "text": "But anyway, so the idea is like, it could literally be anywhere around us."}, {"time": 5456, "text": "And if you think actually about the discovery of like viruses and bacteria, for a long time they were kind of a shadow biosphere."}, {"time": 5462, "text": "It was life that was around us, but invisible."}, {"time": 5468, "text": "But this takes it a little bit further and saying that all of those examples, viruses, bacteria and everything that we've discovered so far has this common ancestry and the last universal common ancestor of life on earth."}, {"time": 5478, "text": "So maybe there was a different origin event and that life is weirder still and might be among us and we could find it."}, {"time": 5486, "text": "We don't have to go out and the stars look for aliens just here on earth."}, {"time": 5489, "text": "Do you think that's a serious possibility that we should explore with the tools of science?"}, {"time": 5495, "text": "Like this should be a serious effort."}, {"time": 5496, "text": "I think yes and no."}, {"time": 5499, "text": "And I mean, yes, because I think it's a serious hypothesis and I think it's worth exploring."}, {"time": 5506, "text": "And it is certainly more economical to look for signs of alien life on earth than it is to go and build spacecraft and send robots to other planets."}, {"time": 5516, "text": "And that was one of the reasons it was proposed is, well, if we do find an example of another original life on earth, it's hugely informative because it means the origin of life is not a rare event."}, {"time": 5525, "text": "If it happened twice on the same planet, that means it's probably pretty probable given conditions are right."}, {"time": 5531, "text": "So it has huge potential scientific impact, not to mention the fact that you might have like biochemistry and stuff that's informative for like medicine and stuff like that."}, {"time": 5539, "text": "But I think the thing for me that's challenging about it and this really comes from my own work, like thinking about life as a planetary scale process and also trying to understand sometimes what I call like the statistical mechanics of biochemistry, but large scale statistical patterns in the chemistry that life uses on earth."}, {"time": 5558, "text": "There are a lot of regularities there and life does seem to have planetary scale organization that's consistent even with some of the patterns that we see at the individual scale."}, {"time": 5569, "text": "So if you think life is a planetary scale phenomenon and the chemistry of life has to be sort of not just, it's not, an individual is not necessarily the fundamental unit of life, right?"}, {"time": 5580, "text": "The fundamental unit of life is these informational lineages and they're kind of, they intersect over spatial scales."}, {"time": 5588, "text": "So everything on earth is kind of related by the common causal history."}, {"time": 5592, "text": "So it's hard for me based on the way I think about the physics and also some of the stuff that my group has done to really think that there could be evidence or there could be a second sample of life on earth."}, {"time": 5605, "text": "But I think there are ways that we need to be more concrete about that."}, {"time": 5608, "text": "And I have thought a little bit about like, like you can represent the chemistry in an individual cell as a network."}, {"time": 5615, "text": "And then those networks, something my group has shown actually scale with the same property."}, {"time": 5622, "text": "So ecosystems have the same properties as individuals as planetary scale."}, {"time": 5626, "text": "And then you could imagine if you had alien chemistry intermixed in there, that scaling would be broken."}, {"time": 5630, "text": "So if there's some robustness property or something associated to it, and you get alien chemistry in there, it just breaks everything."}, {"time": 5637, "text": "And you don't have a planetary ecosystem functioning and individuals functioning across all these scales."}, {"time": 5644, "text": "So I guess what I'm arguing is life is not a scale dependent phenomenon."}, {"time": 5648, "text": "It's not just cellular life."}, {"time": 5650, "text": "So if you have a shadow biosphere, it has to be integrated with all of these other scales."}, {"time": 5653, "text": "And that would lose the meaning of the word shadow biosphere, I guess."}, {"time": 5658, "text": "So it's an open question, right?"}, {"time": 5661, "text": "And I think it would tell us a lot."}, {"time": 5663, "text": "So there has been very minimal effort of people to look for a shadow biosphere."}, {"time": 5668, "text": "But then the question, it could be possible that there's like sufficiently distinct planets within one planet, meaning like environments within one planet."}, {"time": 5682, "text": "I've been looking recently because of having a chat with Catherine Duclair about Io, the moon of Jupiter, that's like all volcanoes and volcanoes are bad ass."}, {"time": 5691, "text": "But like, imagining life inside volcanoes, right?"}, {"time": 5698, "text": "It seems like sufficiently chemically different like to be living in the darkness where there's a lot of heat and maybe you could have different Earths on a planet."}, {"time": 5710, "text": "Or like if you go deep enough in the crust, maybe there's like a layer where there's no life."}, {"time": 5714, "text": "And then there's suddenly life again."}, {"time": 5715, "text": "And maybe those, you know, lizard men or whatever they are that people dream about are really down there."}, {"time": 5722, "text": "I know that's a little flippant, but really like there could be like chemical cycles deep in the Earth's crust that might be alive and are completely distinct in chemical origin to surface life."}, {"time": 5733, "text": "Right, that they wouldn't be interacting with each other."}, {"time": 5735, "text": "Yeah, and that's one of the proposals for the shadow biosphere is like, sometimes people talk about it as being geologically or geographically distinct that it might be, you know, you have no life for this region and then a different example."}, {"time": 5746, "text": "And then sometimes people talk about it being chemically distinct, that the chemistry is sufficiently different, that it's completely orthogonal or non interacting with our chemistry."}, {"time": 5754, "text": "It seems to me at least the chemistry is a more powerful boundary than geographic."}, {"time": 5762, "text": "It just seems like life finds a way literally to travel."}, {"time": 5768, "text": "What do you think about all these UFO sightings?"}, {"time": 5771, "text": "So to me, it's really inspiring."}, {"time": 5774, "text": "It's yet another localized way to dream about the mysterious that is out there."}, {"time": 5781, "text": "Yeah, so I've actually been more intrigued by the cultural phenomena UFOs than the phenomena UFOs themselves, because I think it's intriguing about how we are preparing ourselves mentally for understanding others and how we have thought about that historically and what the sort of modern incarnations of that are."}, {"time": 5804, "text": "It's more like, I want an explanation for us."}, {"time": 5807, "text": "That's my motivation."}, {"time": 5808, "text": "And having some, you know, streaks across the sky or something and saying that's aliens, it doesn't tell you anything."}, {"time": 5815, "text": "So unless you have a deeper explanation and you have, you know, more lines of, you know, where is this gonna take us in the future?"}, {"time": 5822, "text": "It's just not as interesting to me as the problem of understanding life itself and aliens as a more general phenomenon."}, {"time": 5828, "text": "I do think it's, just as you said, a good way to psychologically and sociologically prepare ourselves to sort of like, what would that look like?"}, {"time": 5837, "text": "And very importantly, which is what a lot of people talk about politically, sort of there's this idea from the, so I came from the Soviet Union of like the Cold War and we have to hide secrets."}, {"time": 5850, "text": "There's some way in us searching for life on other planets or our searching for life in general, the way we've done government in the past, we tend to think of all new things as potential military secrets, so we want to hide them."}, {"time": 5866, "text": "And one of the ways that people kind of look at UFO sightings is like, like maybe we shouldn't hide this stuff."}, {"time": 5873, "text": "Like what is the government hiding?"}, {"time": 5875, "text": "I think that's a really, you know, in one sense it's a conspiratorial question, but I think in another, it's an inspiration to change the way we do government to where secrets don't, maybe there are times when you want to keep secrets as military secrets, but maybe we need to release a lot more stuff and see us as a human species as together in this whole search."}, {"time": 5900, "text": "Yeah, the public engagement part there is really interesting."}, {"time": 5903, "text": "And it's almost like a challenge to the way we've done stuff in the past in terms of keeping secrets when they're not, so like the first step, if you don't know how something works, if there's a mysterious thing, the first instinct should not be like, let's hide it."}, {"time": 5922, "text": "Let's put it in the closet."}, {"time": 5924, "text": "So that the Chinese or the Russian government or whatever government doesn't find it."}, {"time": 5928, "text": "Maybe the first instinct should be, let's understand it."}, {"time": 5933, "text": "Perhaps let's understand it together."}, {"time": 5935, "text": "No, I think that's good."}, {"time": 5962, "text": "So there's this really interesting sort of dialogue there and making it open to the public that they actually have to think critically about it and they see the evidence for themselves, I think is really important for that process."}, {"time": 5973, "text": "Yeah, that aliens might be way weirder than we can imagine."}, {"time": 5979, "text": "Yes, I'm pretty sure they're probably weirder than we can imagine."}, {"time": 5984, "text": "Okay, we've in 2020 and still living through a pandemic, setting the political and all those kinds of things aside, I've always found viruses fascinating as dynamical systems, I was gonna say living systems, but I've always kind of thought of them as living, but that's a whole nother kind of discussion."}, {"time": 6009, "text": "Maybe it'd be great to put that on the table."}, {"time": 6013, "text": "One, do you find viruses beautiful slash terrifying?"}, {"time": 6017, "text": "And two, do you think they're living things or there's some aspect to them per our discussion of life that makes them living?"}, {"time": 6027, "text": "I mean, living in a pandemic saying viruses are beautiful is probably a hard thing, but I do find them beautiful to a degree."}, {"time": 6034, "text": "I think even in the sense of mediating a global pandemic, there's something like deeply intriguing there because these are tiny, tiny little things, right?"}, {"time": 6046, "text": "And yet they can essentially cause a seizure or handicap an entire civilization at a global scale."}, {"time": 6055, "text": "So just that intersection between our perceived invincibility and our susceptibility to things and also the interaction across scales of those things is just a really amazing feature of our world."}, {"time": 6069, "text": "Most technology, whether it's viruses or AI that can scale in an exponential way, like kind of run as opposed to like, one thing makes another thing makes another thing, it's one thing makes two things and those two things make four things."}, {"time": 6088, "text": "Like that kind of process also seems to be fundamental to life."}, {"time": 6095, "text": "And it's terrifying because in a matter of, in a very short time scale, it can, if it's good at being life, whatever that is, it can quickly overtake the other competing forms of life."}, {"time": 6113, "text": "And that's scary both for AI and for viruses."}, {"time": 6117, "text": "And it seems like understanding these processes that are underlying viruses."}, {"time": 6122, "text": "And I don't mean like on the virology or biology side, but on some kind of more computational physics perspective as we've been talking about, seems to be really important to figure out how humans can survive."}, {"time": 6140, "text": "Along with this kind of life and perhaps becoming a multi planetary species is a part of that."}, {"time": 6148, "text": "Like there's no, maybe like we'll figure out from a physics perspective is like, there's no way any living system can be stable for prolonged period of time and survive unless it expands exponentially throughout."}, {"time": 6163, "text": "Like we have to multiply."}, {"time": 6166, "text": "Otherwise anything that doesn't multiply exponentially will die eventually."}, {"time": 6170, "text": "Maybe that's a fundamental law."}, {"time": 6174, "text": "Maybe, I don't know."}, {"time": 6176, "text": "I always get really bothered by these Darwinian narratives that are like the fittest replicator wins and things."}, {"time": 6181, "text": "And I don't, I just don't feel like that's exactly what's going on."}, {"time": 6184, "text": "I think like the copying of information is sort of ancillary to this other process of creativity."}, {"time": 6190, "text": "Right, so like the drive is actually, the drive is creativity, but if you wanna keep the creativity that's existed in the past, it has to be copied into the future."}, {"time": 6199, "text": "So replication, like if you, so that for me is, so I had this set of arguments with Michael Lockman and Lee Cronin about the like life being about persistence."}, {"time": 6209, "text": "They thought it was about persistence and like survival of the fittest kind of thing."}, {"time": 6212, "text": "And I'm like, no, it's about existence."}, {"time": 6213, "text": "It's like, cause when you're talking about that, it's easy to say that in retrospect, you can post select on the things that survived and then say why they survived, but you can't do that going forward."}, {"time": 6226, "text": "That's really profound that survival is just a nice little side effect feature of maximizing creativity, but it doesn't need to be there."}, {"time": 6236, "text": "Yeah, I like that."}, {"time": 6236, "text": "That's really beautiful."}, {"time": 6238, "text": "Yeah, I know, like I said, I like optimistic theories."}, {"time": 6241, "text": "Well, I don't know if that's optimistic."}, {"time": 6243, "text": "That could be terrifying to people because, because a system that maximizes creativity may very quickly get rid of humans for some reason, if it comes up with some other creative, I mean, forms of existence, right?"}, {"time": 6260, "text": "This is the AI thing is like the moment you have an AI system that can flourish in the space of ideas or in some other space much more effectively than humans."}, {"time": 6273, "text": "And it's sufficiently integrated into the physical space to be able to modify the environment."}, {"time": 6279, "text": "I think we'll just be like the core genetic architecture or something."}, {"time": 6282, "text": "We'll be like the DNA for AI, right?"}, {"time": 6284, "text": "It's like, we haven't lost the past informational architectures on this planet."}, {"time": 6287, "text": "They're still there."}, {"time": 6289, "text": "Yeah, so the AI will use our brains in some part to like ride, like accelerate the exchange of ideas."}, {"time": 6298, "text": "That's the neural language dream is that, well, the humans will be still around because you're saying architecture."}, {"time": 6305, "text": "Yeah, but I don't even think they necessarily need to tap into our brains."}, {"time": 6308, "text": "I mean, just collectively, we do interesting things."}, {"time": 6310, "text": "What if they were just using like the patterns in our communication or something?"}, {"time": 6314, "text": "Oh, without controlling it, just observing?"}, {"time": 6319, "text": "In what sense do you control the chemistry happening in your body?"}, {"time": 6325, "text": "I mean, obviously I don't know."}, {"time": 6327, "text": "I'm just, like the way I look at, like people look at AI and then they look at this thing that's bigger than us and is coming in the future and is smarter than us."}, {"time": 6336, "text": "And I think though that looking at the past history of life on the planet and what information has been doing for the last 4 billion years is probably very informative to asking questions about what's coming next."}, {"time": 6347, "text": "And I don't, one is planetary scale transitions are really important for new phases."}, {"time": 6354, "text": "So the global internet and sort of global integration of our technology, I think is an important thing."}, {"time": 6358, "text": "So that's again, life is a planetary scale phenomenon but we're an integrated component of that phenomenon."}, {"time": 6363, "text": "I don't really see that the technology is gonna replace us in that way."}, {"time": 6367, "text": "It's just gonna keep scaffolding and building."}, {"time": 6369, "text": "And I also don't have an idea that we're gonna build AI in a box."}, {"time": 6372, "text": "I think AI is gonna emerge."}, {"time": 6374, "text": "AGI to me is a planetary scale phenomena that's gonna emerge from our technology."}, {"time": 6379, "text": "Planetary scale phenomena."}, {"time": 6382, "text": "But do you think an AGI is not distinct from humans?"}, {"time": 6386, "text": "The whole package."}, {"time": 6387, "text": "The whole package, yeah."}, {"time": 6388, "text": "Comes as a planetary scale phenomena."}, {"time": 6390, "text": "And that goes back to the fact that like, you were asking questions about you as an individual."}, {"time": 6394, "text": "Like, what are you as an individual?"}, {"time": 6396, "text": "You're like a packet of information that exists in the particular physical thing that is you."}, {"time": 6401, "text": "We're all just packets of information."}, {"time": 6403, "text": "And some of us are aggregates in certain ways but it's all just kind of exchanging and propagating, right?"}, {"time": 6408, "text": "And processing."}, {"time": 6409, "text": "Is your packet of information that you've continually referred to as Sarah afraid of the dissipation of the death of that packet?"}, {"time": 6423, "text": "Do you ponder death?"}, {"time": 6424, "text": "Does death have meaning in this process of creativity?"}, {"time": 6429, "text": "I think I have the natural biological urge that everyone has to fear death."}, {"time": 6435, "text": "I think the thing that I think is interesting is if I think about it rationally, I'm not necessarily afraid of death for me because I won't be aware of being dead."}, {"time": 6445, "text": "But I am afraid like for my kids because it matters to them if I die."}, {"time": 6449, "text": "So again, like I think death becomes more significant as a collective property, not as an individual one."}, {"time": 6457, "text": "Yeah, but isn't there something to fear about the fact that the way, like the creative, the complexity of information that's been like created in you."}, {"time": 6472, "text": "The fact that it kind of breaks apart and disappears."}, {"time": 6477, "text": "It doesn't, but I don't think it disappears."}, {"time": 6479, "text": "It's just not me anymore."}, {"time": 6480, "text": "Right, but that process of it being not you anymore, that doesn't scare you?"}, {"time": 6488, "text": "The mystery of it."}, {"time": 6489, "text": "I mean, the... Yeah, but I guess I'm heartened by the fact that there will be some imprints of the fact that I existed still in the universe after I leave it."}, {"time": 6496, "text": "Yeah, but there'll be a..."}, {"time": 6498, "text": "Okay, but... And also that has to do with my perception of time, right?"}, {"time": 6501, "text": "So, I perceive time as flowing, but that might not be the case."}, {"time": 6506, "text": "I mean, this is standard physicist comfort is, every moment exists and there's no... And the flow of time is just our perception of us changing."}, {"time": 6521, "text": "So, you can travel back in time and that's comforting?"}, {"time": 6523, "text": "Like from a physicist's concept?"}, {"time": 6525, "text": "I'm not talking about traveling back in time."}, {"time": 6526, "text": "I'm just saying that the moments in the past still exist."}, {"time": 6530, "text": "Now, whether the moments in the future exist or not is a different question."}, {"time": 6533, "text": "That's not comforting to me in terms of death."}, {"time": 6537, "text": "The flow of time is not..."}, {"time": 6538, "text": "I think there's no comfort in the face of death for what we are because we like existing."}, {"time": 6547, "text": "And I think it's especially true if you love life and you love what life is."}, {"time": 6553, "text": "Do you think there's a certain sense in which the fear of death or the fear of nonexistence, maybe fear is not the right word, is the actual very phenomena that gives birth to existence?"}, {"time": 6566, "text": "Like, death is fundamental."}, {"time": 6568, "text": "It just feels like freaking out, oh shit, this ride ends is actually like the... That's the thing that gives birth to this whole thing."}, {"time": 6581, "text": "That like, it's constantly..."}, {"time": 6585, "text": "It's matter constantly freaking out about the fact that it's gonna be the most."}, {"time": 6588, "text": "No, I think things like to exist."}, {"time": 6591, "text": "I think they wanna exist."}, {"time": 6591, "text": "Yeah, there's a desire, whatever, to exist."}, {"time": 6596, "text": "There's a drive to exist and there's a drive for more things to exist."}, {"time": 6600, "text": "I guess, yeah, I like existing."}, {"time": 6603, "text": "I like it a lot and I don't know it any other way."}, {"time": 6609, "text": "See, I don't even know if I like existing."}, {"time": 6611, "text": "I think I really don't like not existing."}, {"time": 6617, "text": "Yeah, maybe it's that."}, {"time": 6619, "text": "Some days I might like existing less than others."}, {"time": 6623, "text": "Yes, but like, I think those are like surface feelings."}, {"time": 6628, "text": "It seems like there's something fundamental about wanting to exist."}, {"time": 6631, "text": "No, I think that's right."}, {"time": 6632, "text": "But I think to your point that that might go back to the more fundamental idea that, you know, if life is the physics of existence and maximizing existence, individual organisms, of course, wanna maximize their existence and everything, you know, like wants to exist."}, {"time": 6648, "text": "But I guess for me, the small comfort is my existence matters to future existence."}, {"time": 6654, "text": "Speaking of future existence, is there advice you can give to future pockets of existences, AKA young people, about life?"}, {"time": 6664, "text": "You've had, you've worn many hats."}, {"time": 6667, "text": "You've taken on some of the biggest problems in the universe."}, {"time": 6670, "text": "Is there advice you can give to young people about life, about career, about existing?"}, {"time": 6677, "text": "Yeah, maybe not about the last one."}, {"time": 6680, "text": "You know, a lot of people ask me this question about like working on such hard problems, like how can you make a successful career out of that?"}, {"time": 6688, "text": "But I think for me, it couldn't be otherwise."}, {"time": 6691, "text": "Like I have to, to be fulfilled, you have to work on things you care about."}, {"time": 6695, "text": "And that's always kind of driven me."}, {"time": 6696, "text": "And that's been discipline, department, and sort of superficial level problem independent because I started at community college actually, and I was taking a physics class and I learned about magnetic monopoles and we didn't know if they existed in the universe, but we could predict them and we could go look for them."}, {"time": 6717, "text": "And I was so deeply intrigued by this idea that we had this mathematical formula to go look for things."}, {"time": 6722, "text": "And then I wanted to become a theoretical physicist because of that."}, {"time": 6725, "text": "But that actually wasn't my driving question."}, {"time": 6727, "text": "I realized my driving question is the nature of the correspondence between our minds and physical reality and what we are."}, {"time": 6734, "text": "And that question is very deep, so you can work across a lot of fields doing that."}, {"time": 6738, "text": "But I think without that driving question, I never would have been able to do all the things that I've done."}, {"time": 6743, "text": "It's really the passion that drives it."}, {"time": 6745, "text": "And usually when students ask me these kinds of questions, I tell them like, you have to find something you really care about working on because if you don't really care about it, A, you're not gonna be your best at it, and B, it's not gonna be worth your time."}, {"time": 6759, "text": "Why would you spend your time working on something you're not interested in?"}, {"time": 6763, "text": "So find the driving questions."}, {"time": 6764, "text": "Yeah, find the driving question."}, {"time": 6766, "text": "Find your passion."}, {"time": 6767, "text": "I mean, I think passion makes a huge difference in terms of creativity, talent, and potential, and also being able to tolerate all the hard things that come with any career or life."}, {"time": 6777, "text": "Yeah, I've had a bunch of moments in my life where I've just been captivated by some beautiful phenomena."}, {"time": 6783, "text": "And I guess being rigorous about it and asking what is the question underlying this phenomena, like robots bring a smile to my face and forming a question of like, why the hell is this so fascinating?"}, {"time": 6799, "text": "Why is this, specifically the human robot interaction question that something beautiful is brought to life when humans and robots interact, understanding that deeply."}, {"time": 6813, "text": "It's like, okay, so this is gonna be my life work then."}, {"time": 6816, "text": "I don't know what the hell it is, but that's what I wanna do."}, {"time": 6820, "text": "And doing that for whatever the hell gives you that kind of feeling, I guess, is the point."}, {"time": 6826, "text": "Am I allowed to ask you a question?"}, {"time": 6829, "text": "On that point, because I had this colleague that suggested the idea that consciousness might be contagious."}, {"time": 6836, "text": "And so interacting with things, it's an interesting idea, right?"}, {"time": 6841, "text": "So I'm wondering sort of the motivation there."}, {"time": 6844, "text": "Is it the motivation that you want more of the universe to appreciate things the way we do and appreciate those interactions?"}, {"time": 6852, "text": "Or is it really more the enjoyment of the human in those interactions?"}, {"time": 6856, "text": "Like, is it, do you know what I'm asking?"}, {"time": 6861, "text": "See, I think consciousness is created in the interaction between things."}, {"time": 6868, "text": "So the joy is in the creation of consciousness."}, {"time": 6872, "text": "I really like the idea that it doesn't just have to be two humans creating consciousness together."}, {"time": 6880, "text": "It could be humans and other entities."}, {"time": 6883, "text": "We talked offline about dogs and other pets and so on."}, {"time": 6886, "text": "There's a magic, I mean, I've been calling it love."}, {"time": 6889, "text": "It's this beauty of the human experience that's created."}, {"time": 6894, "text": "And it just feels like fascinating that you could do that with a robotic system."}, {"time": 6901, "text": "And there's something really powerful, at least to me, about engineering systems that allow you to create some of the magic of the human experience."}, {"time": 6912, "text": "Cause then you get to understand what it takes, at least get inklings of what it takes to create consciousness."}, {"time": 6921, "text": "And I don't get this, you know, philosophers get really upset about this idea that sort of the illusion of consciousness is consciousness."}, {"time": 6929, "text": "But I really liked the idea of engineering systems that fool you into thinking they're conscious."}, {"time": 6938, "text": "Because that's sufficient to create the magical experience."}, {"time": 6941, "text": "Right, because it's the interaction, yeah."}, {"time": 6943, "text": "It's the interaction, yeah."}, {"time": 6945, "text": "And this is the Russian hat I wear, which is like, I think there's an ocean of loneliness in the world."}, {"time": 6951, "text": "I think we're deeply lonely."}, {"time": 6953, "text": "We're not even allowing ourselves to acknowledge that."}, {"time": 6957, "text": "And I kind of think that's what love is between romantic love and friendship is two people kind of getting a little bit like alleviating for brief moment."}, {"time": 6971, "text": "That loneliness."}, {"time": 6972, "text": "That loneliness, but not, but we're not there."}, {"time": 6975, "text": "It's not the full aspect of that loneliness."}, {"time": 6977, "text": "Like we're desperately alone."}, {"time": 6979, "text": "We're desperately afraid of nonexisting."}, {"time": 6983, "text": "I have that kind of sense."}, {"time": 6984, "text": "And I just want to explore that ocean of loneliness more."}]}, {"title": "Joscha Bach: Nature of Reality, Dreams, and Consciousness | Lex Fridman Podcast #212", "id": "rIpUf-Vy2JA", "quotes": [{"time": 250, "text": "There is a large perceptual system combined with a motivational system that is actually providing the interface to everything and our own consciousness."}, {"time": 258, "text": "I think is the tool that directs the attention of that system, which means it singles out features and performs conditional operations for which it needs an index memory."}, {"time": 268, "text": "But this index memory is what we perceive as our stream of consciousness."}, {"time": 272, "text": "But the consciousness is not in charge."}, {"time": 274, "text": "That's an illusion."}, {"time": 275, "text": "So everything outside of that consciousness is the elephant."}, {"time": 281, "text": "So it's the physics of the universe, but it's also society that's outside of your..."}, {"time": 286, "text": "I would say the elephant is the agent."}, {"time": 288, "text": "So there is an environment to which the agent is stomping and you are influencing a little part of that agent."}, {"time": 295, "text": "So is the agent a single human being?"}, {"time": 298, "text": "Which object has agency?"}, {"time": 303, "text": "I think a way to think about an agent is that it's a controller with a set point generator."}, {"time": 310, "text": "The notion of a controller comes from cybernetics and control theory."}, {"time": 314, "text": "Control system consists out of a system that is regulating some value and the deviation of that value from a set point."}, {"time": 323, "text": "And it has a sensor that measures the system's deviation from that set point and an effector that can be parametrized by the controller."}, {"time": 332, "text": "So the controller tells the effector to do a certain thing."}, {"time": 335, "text": "And the goal is to reduce the distance between the set point and the current value of the system."}, {"time": 340, "text": "And there's an environment which disturbs the regulated system, which brings it away from that set point."}, {"time": 345, "text": "So simplest case is a thermostat."}, {"time": 347, "text": "The thermostat is really simple because it doesn't have a model."}, {"time": 350, "text": "The thermostat is only trying to minimize the set point deviation in the next moment."}, {"time": 355, "text": "And if you want to minimize the set point deviation over a longer time span, you need to integrate it."}, {"time": 360, "text": "You need to model what is going to happen."}, {"time": 363, "text": "So for instance, when you think about that your set point is to be comfortable in life, maybe you need to make yourself uncomfortable first, right?"}, {"time": 371, "text": "So you need to make a model of what's going to happen when."}, {"time": 374, "text": "And this is task of the controller is to use its sensors to measure the state of the environment and the system that is being regulated and figure out what to do."}, {"time": 384, "text": "And if the task is complex enough, the set points are complicated enough."}, {"time": 390, "text": "And if the controller has enough capacity and enough sensor feedback, then the task of the controller is to make a model of the entire universe that it's in, the conditions under which it exists and of itself."}, {"time": 402, "text": "And this is a very complex agent."}, {"time": 403, "text": "And we are in that category."}, {"time": 405, "text": "And an agent is not necessarily a thing in the universe."}, {"time": 409, "text": "It's a class of models that we use to interpret aspects of the universe."}, {"time": 414, "text": "And when we notice the environment around us, a lot of things only make sense at the level that should be entangled with them if we interpret them as control systems that make models of the world and try to minimize their own set points."}, {"time": 427, "text": "So the models are the agents."}, {"time": 430, "text": "The agent is a class of model."}, {"time": 432, "text": "And we notice that we are an agent ourselves."}, {"time": 434, "text": "We are the agent that is using our own control model to perform actions."}, {"time": 438, "text": "We notice we produce a change in the model and things in the world change."}, {"time": 443, "text": "And this is how we discover the idea that we have a body, that we are situated environment, and that we have a first person perspective."}, {"time": 451, "text": "Still don't understand what's the best way to think of which object has agency with respect to human beings."}, {"time": 459, "text": "Is it the body?"}, {"time": 461, "text": "Is it the brain?"}, {"time": 463, "text": "Is it the contents of the brain as agency?"}, {"time": 466, "text": "Like what's the actuators that you're referring to?"}, {"time": 469, "text": "What is the controller and where does it reside?"}, {"time": 472, "text": "Or is it these impossible things?"}, {"time": 474, "text": "Because I keep trying to ground it to space time, the three dimension of space and the one dimension of time."}, {"time": 481, "text": "What's the agent in that for humans?"}, {"time": 484, "text": "There is not just one."}, {"time": 486, "text": "It depends on the way in which you're looking at this thing in which you're framing it."}, {"time": 490, "text": "Imagine that you are, say Angela Merkel, and you are acting on behalf of Germany."}, {"time": 496, "text": "Then you could say that Germany is the agent."}, {"time": 499, "text": "And in the mind of Angela Merkel, she is Germany to some extent, because in the way in which she acts, the destiny of Germany changes."}, {"time": 508, "text": "There are things that she can change that basically affect the behavior of that nation state."}, {"time": 513, "text": "Okay, so it's hierarchies of, to go to another one of your tweets with I think you were playfully mocking Jeff Hawkins with saying his brain's all the way down."}, {"time": 525, "text": "So it's like, it's agents all the way down."}, {"time": 529, "text": "It's agents made up of agents, made up of agents."}, {"time": 531, "text": "Like if Angela Merkel's Germany and Germany's made up a bunch of people and the people are themselves agents in some kind of context."}, {"time": 541, "text": "And then people are made up of cells, each individual."}, {"time": 544, "text": "So is it agents all the way down?"}, {"time": 547, "text": "I suspect that has to be like this in a world where things are self organizing."}, {"time": 552, "text": "Most of the complexity that we are looking at, everything in life is about self organization."}, {"time": 558, "text": "So I think up from the level of life, you have agents."}, {"time": 564, "text": "And below life, you rarely have agents because sometimes you have control systems that emerge randomly in nature and try to achieve a set point, but they're not that interesting agents that make models."}, {"time": 576, "text": "And because to make an interesting model of the world, you typically need a system that is true and complete."}, {"time": 586, "text": "What's the line between life and non life?"}, {"time": 588, "text": "It's personal because you're a life form."}, {"time": 592, "text": "So what do you think in this emerging complexity, at which point does the things that are being living and have agency?"}, {"time": 600, "text": "Personally, I think that the simplest answer that is that life is cells because... Life is what?"}, {"time": 605, "text": "Cells."}, {"time": 607, "text": "So it's a particular kind of principle that we have discovered to exist in nature."}, {"time": 611, "text": "It's modular stuff that consists out of basically this DNA tape with a read write head on top of it, that is able to perform arbitrary computations and state transitions within the cell."}, {"time": 625, "text": "And it's combined with a membrane that insulates the cell from its environment."}, {"time": 630, "text": "And there are chemical reactions inside of the cell that are in disequilibrium."}, {"time": 636, "text": "And the cell is running in such a way that this disequilibrium doesn't disappear."}, {"time": 641, "text": "And the cell goes into an equilibrium state, it dies."}, {"time": 646, "text": "And it requires something like an neck entropy extractor to maintain this disequilibrium."}, {"time": 651, "text": "So it's able to harvest like entropy from its environment and keep itself running."}, {"time": 657, "text": "Yeah, so there's information and there's a wall to maintain this disequilibrium."}, {"time": 664, "text": "But isn't this very earth centric?"}, {"time": 666, "text": "Like what you're referring to as a..."}, {"time": 668, "text": "I'm not making a normative notion."}, {"time": 670, "text": "You could say that there are probably other things in the universe that are cell like and life like, and you could also call them life, but eventually it's just a willingness to find an agreement of how to use the terms."}, {"time": 683, "text": "I like cells because it's completely coextential with the way that we use the word even before we knew about cells."}, {"time": 690, "text": "So people were pointing at some stuff and saying, this is somehow animate."}, {"time": 694, "text": "And this is very different from the non animate stuff."}, {"time": 696, "text": "And what's the difference between the living and the dead stuff."}, {"time": 700, "text": "And it's mostly whether the cells are working or not."}, {"time": 702, "text": "And also this boundary of life, where we say that for instance, the virus is basically an information packet that is subverting the cell and not life by itself."}, {"time": 712, "text": "That makes sense to me."}, {"time": 714, "text": "And it's somewhat arbitrary."}, {"time": 715, "text": "You could of course say that systems that permanently maintain a disequilibrium and can self replicate are always life."}, {"time": 723, "text": "And maybe that's a useful definition too, but this is eventually just how you want to use the word."}, {"time": 730, "text": "Is it so useful for conversation, but is it somehow fundamental to the universe?"}, {"time": 737, "text": "Do you think there's a actual line to eventually be drawn between life and non life?"}, {"time": 741, "text": "Or is it all a kind of continuum?"}, {"time": 744, "text": "I don't think it's a continuum, but there's nothing magical that is happening."}, {"time": 748, "text": "Living systems are a certain type of machine."}, {"time": 751, "text": "What about non living systems?"}, {"time": 752, "text": "Is it also a machine?"}, {"time": 754, "text": "There are non living machines, but the question is at which point is a system able to perform arbitrary state transitions to make representations."}, {"time": 764, "text": "And living things can do this."}, {"time": 766, "text": "And of course we can also build non living things that can do this, but we don't know anything in nature that is not a cell and is not created by still alive that is able to do that."}, {"time": 778, "text": "Not only do we not know, I don't think we have the tools to see otherwise."}, {"time": 785, "text": "I always worry that we look at the world too narrowly."}, {"time": 791, "text": "Like there could be life of a very different kind right under our noses that we're just not seeing because we're not either limitations of our cognitive capacity, or we're just not open minded enough either with the tools of science or just the tools of our mind."}, {"time": 812, "text": "Yeah, that's possible."}, {"time": 813, "text": "I find this thought very fascinating."}, {"time": 815, "text": "And I suspect that many of us ask ourselves since childhood, what are the things that we are missing?"}, {"time": 820, "text": "What kind of systems and interconnections exist that are outside of our gaze?"}, {"time": 827, "text": "But we are looking for it and physics doesn't have much room at the moment for opening up something that would not violate the conservation of information as we know it."}, {"time": 843, "text": "Yeah, but I wonder about time scale and scale, spatial scale, whether we just need to open up our idea of what, like how life presents itself."}, {"time": 855, "text": "It could be operating in a much slower time scale, a much faster time scale."}, {"time": 860, "text": "And it's almost sad to think that there's all this life around us that we're not seeing because we're just not like thinking in terms of the right scale, both time and space."}, {"time": 874, "text": "What is your definition of life?"}, {"time": 876, "text": "What do you understand as life?"}, {"time": 880, "text": "Entities of sufficiently high complexity that are full of surprises."}, {"time": 886, "text": "I don't know, I don't have a free will."}, {"time": 893, "text": "So that just came out of my mouth."}, {"time": 895, "text": "I'm not sure that even makes sense."}, {"time": 897, "text": "There's certain characteristics."}, {"time": 899, "text": "So complexity seems to be a necessary property of life."}, {"time": 904, "text": "And I almost want to say it has ability to do something unexpected."}, {"time": 913, "text": "It seems to me that life is the main source of complexity on earth."}, {"time": 919, "text": "And complexity is basically a bridgehead that order builds into chaos by modeling, by processing information in such a way that you can perform reactions that would not be possible for dump systems."}, {"time": 933, "text": "And this means that you can harvest neck entropy that dump systems cannot harvest."}, {"time": 937, "text": "And this is what complexity is mostly about."}, {"time": 940, "text": "In some sense, the purpose of life is to create complexity."}, {"time": 946, "text": "Increasing."}, {"time": 946, "text": "I mean, there seems to be some kind of universal drive towards increasing pockets of complexity."}, {"time": 957, "text": "That seems to be like a fundamental, I don't know if it's a property of the universe or it's just a consequence of the way the universe works, but there seems to be this small pockets of emergent complexity that builds on top of each other and starts having like greater and greater complexity by having like a hierarchy of complexity."}, {"time": 977, "text": "Little organisms building up a little society that then operates almost as an individual organism itself."}, {"time": 984, "text": "And all of a sudden you have Germany and Merkel."}, {"time": 987, "text": "Well, that's not obvious to me."}, {"time": 988, "text": "Everything that goes up has to come down at some point."}, {"time": 992, "text": "So if you see this big exponential curve somewhere, it's usually the beginning of an S curve where something eventually reaches saturation."}, {"time": 1001, "text": "And the S curve is the beginning of some kind of bump that goes down again."}, {"time": 1005, "text": "And there is just this thing that when you are in sight of an evolution of life, you are on top of a puddle of negentropy that is being sucked dry by life."}, {"time": 1018, "text": "And during that happening, you see an increase in complexity because life forms are competing with each other to get more and more finer and finer corner of that negentropy extraction."}, {"time": 1031, "text": "I feel like that's a gradual beautiful process like that's almost follows a process akin to evolution."}, {"time": 1038, "text": "And the way it comes down is not the same way it came up."}, {"time": 1042, "text": "The way it comes down is usually harshly and quickly."}, {"time": 1047, "text": "So usually there's some kind of catastrophic event."}, {"time": 1050, "text": "The Roman Empire took a long time."}, {"time": 1052, "text": "But would that be, would you classify this as a decrease in complexity though?"}, {"time": 1060, "text": "I think that this size of the cities that could be fed has decreased dramatically."}, {"time": 1064, "text": "And you could see that the quality of the art decreased and it did so gradually."}, {"time": 1069, "text": "And maybe future generations, when they look at the history of the United States in the 21st century, will also talk about the gradual decline, not something that suddenly happens."}, {"time": 1085, "text": "Do you have a sense of where we are?"}, {"time": 1087, "text": "Are we on the exponential rise?"}, {"time": 1089, "text": "Are we at the peak?"}, {"time": 1091, "text": "Or are we at the downslope of the United States empire?"}, {"time": 1095, "text": "It's very hard to say from a single human perspective, but it seems to me that we are probably at the peak."}, {"time": 1105, "text": "I think that's probably the definition of like optimism and cynicism."}, {"time": 1109, "text": "So my nature of optimism is, I think we're on the rise."}, {"time": 1116, "text": "I think this is just all a matter of perspective."}, {"time": 1119, "text": "Nobody knows, but I do think that erring on the side of optimism, like you need a sufficient number, you need a minimum number of optimists in order to make that up thing actually work."}, {"time": 1130, "text": "And so I tend to be on the side of the optimists."}, {"time": 1133, "text": "I think that we are basically a species of grasshoppers that have turned into locusts."}, {"time": 1138, "text": "And when you are in that locust mode, you see an amazing rise of population numbers and of the complexity of the interactions between the individuals."}, {"time": 1148, "text": "But it's ultimately the question is, is it sustainable?"}, {"time": 1152, "text": "See, I think we're a bunch of lions and tigers that have become domesticated cats, to use a different metaphor."}, {"time": 1161, "text": "As I'm not exactly sure we're so destructive, we're just softer and nicer and lazier."}, {"time": 1167, "text": "But I think we have monkeys and not the cats."}, {"time": 1169, "text": "And if you look at the monkeys, they are very busy."}, {"time": 1173, "text": "The ones that have a lot of sex, those monkeys?"}, {"time": 1175, "text": "Not just the bonobos."}, {"time": 1177, "text": "I think that all the monkeys are basically a discontent species that always needs to meddle."}, {"time": 1182, "text": "Well, the gorillas seem to have a little bit more of a structure, but it's a different part of the tree."}, {"time": 1190, "text": "Okay, you mentioned the elephant and the monkey riding the elephant."}, {"time": 1195, "text": "And consciousness is the monkey."}, {"time": 1200, "text": "And there's some prodding that the monkey gets to do."}, {"time": 1203, "text": "And sometimes the elephant listens."}, {"time": 1206, "text": "I heard you got into some contentious, maybe you can correct me, but I heard you got into some contentious free will discussions."}, {"time": 1213, "text": "Is this with Sam Harris or something like that?"}, {"time": 1216, "text": "Not that I know of."}, {"time": 1218, "text": "Some people on Clubhouse told me you made a bunch of big debate points about free will."}, {"time": 1225, "text": "Well, let me just then ask you where, in terms of the monkey and the elephant, do you think we land in terms of the illusion of free will?"}, {"time": 1235, "text": "How much control does the monkey have?"}, {"time": 1238, "text": "We have to think about what the free will is in the first place."}, {"time": 1243, "text": "We are not the machine."}, {"time": 1244, "text": "We are not the thing that is making the decisions."}, {"time": 1246, "text": "We are a model of that decision making process."}, {"time": 1249, "text": "And there is a difference between making your own decisions and predicting your own decisions."}, {"time": 1256, "text": "And that difference is the first person perspective."}, {"time": 1259, "text": "And what basically makes decision making and the conditions of free will distinct from just automatically doing the best thing is that we often don't know what the best thing is."}, {"time": 1273, "text": "We make decisions under uncertainty."}, {"time": 1275, "text": "We make informed bets using a betting algorithm that we don't yet understand because we haven't reverse engineered our own minds sufficiently."}, {"time": 1282, "text": "We don't know the expected rewards."}, {"time": 1283, "text": "We don't know the mechanism by which we estimate the rewards and so on."}, {"time": 1287, "text": "But there is an algorithm."}, {"time": 1288, "text": "We observe ourselves performing where we see that we weight facts and factors and the future, and then some kind of possibility, some motive gets raised to an intention."}, {"time": 1301, "text": "And that's informed bet that the system is making."}, {"time": 1304, "text": "And that making of the informed bet, the representation of that is what we call free will."}, {"time": 1309, "text": "And it seems to be paradoxical because we think that the crucial thing is about it that it's somehow indeterministic."}, {"time": 1316, "text": "And yet if it was indeterministic, it would be random."}, {"time": 1320, "text": "And it cannot be random because if it was random, if just dice were being thrown in the universe, randomly forces you to do things, it would be meaningless."}, {"time": 1328, "text": "So the important part of the decisions is always the deterministic stuff."}, {"time": 1332, "text": "But it appears to be indeterministic to you because it's unpredictable."}, {"time": 1336, "text": "Because if it was predictable, you wouldn't experience it as a free will decision."}, {"time": 1341, "text": "You would experience it as just doing the necessary right thing."}, {"time": 1345, "text": "And you see this continuum between the free will and the execution of automatic behavior when you're observing other people."}, {"time": 1353, "text": "So for instance, when you are observing your own children, if you don't understand them, you will abuse this agent model where you have an agent with a set point generator."}, {"time": 1363, "text": "And the agent is doing the best it can to minimize the difference to the set point."}, {"time": 1367, "text": "And it might be confused and sometimes impulsive or whatever, but it's acting on its own free will."}, {"time": 1373, "text": "And when you understand what's happens in the mind of the child, you see that it's automatic."}, {"time": 1378, "text": "And you can outmodel the child, you can build things around the child that will lead the child to making exactly the decision that you are predicting."}, {"time": 1386, "text": "And under these circumstances, like when you are a stage musician or somebody who is dealing with people that you sell a car to, and you completely understand the psychology and the impulses and the space of thoughts that this individual can have at that moment."}, {"time": 1401, "text": "Under these circumstances, it makes no sense to attribute free will."}, {"time": 1406, "text": "Because it's no longer decision making under uncertainty."}, {"time": 1408, "text": "You are already certain."}, {"time": 1409, "text": "For them, there's uncertainty, but you already know what they're doing."}, {"time": 1413, "text": "But what about for you?"}, {"time": 1414, "text": "So is this akin to like systems like cellular automata where it's deterministic, but when you squint your eyes a little bit, it starts to look like there's agents making decisions at the higher sort of when you zoom out and look at the entities that are composed by the individual cells."}, {"time": 1438, "text": "Even though there's underlying simple rules that make the system evolve in deterministic ways, it looks like there's organisms making decisions."}, {"time": 1450, "text": "Is that where the illusion of free will emerges, that jump in scale?"}, {"time": 1456, "text": "It's a particular type of model, but this jump in scale is crucial."}, {"time": 1460, "text": "The jump in scale happens whenever you have too many parts to count and you cannot make a model at that level and you try to find some higher level regularity."}, {"time": 1468, "text": "And the higher level regularity is a pattern that you project into the world to make sense of it."}, {"time": 1474, "text": "And agency is one of these patterns, right?"}, {"time": 1476, "text": "You have all these cells that interact with each other and the cells in our body are set up in such a way that they benefit if their behavior is coherent, which means that they act as if they were serving a common goal."}, {"time": 1489, "text": "And that means that they will evolve regulation mechanisms that act as if they were serving a common goal."}, {"time": 1495, "text": "And now you can make sense of all these cells by projecting the common goal into them."}, {"time": 1499, "text": "Right, so for you then, free will is an illusion."}, {"time": 1503, "text": "No, it's a model and it's a construct."}, {"time": 1506, "text": "It's basically a model that the system is making of its own behavior."}, {"time": 1509, "text": "And it's the best model that it can come up with under the circumstances."}, {"time": 1512, "text": "And it can get replaced by a different model, which is automatic behavior, when you fully understand the mechanism under which you are acting."}, {"time": 1519, "text": "Yeah, but another word for model is what, story."}, {"time": 1523, "text": "So it's the story you're telling."}, {"time": 1525, "text": "I mean, do you actually have control?"}, {"time": 1527, "text": "Is there such a thing as a you and is there such a thing as you have in control?"}, {"time": 1533, "text": "So like, are you manifesting your evolution as an entity?"}, {"time": 1542, "text": "In some sense, the you is the model of the system that is in control."}, {"time": 1545, "text": "It's a story that the system tells itself about somebody who is in control."}, {"time": 1551, "text": "And the contents of that model are being used to inform the behavior of the system."}, {"time": 1557, "text": "So the system is completely mechanical and the system creates that story like a loom."}, {"time": 1563, "text": "And then it uses the contents of that story to inform its actions and writes the results of that actions into the story."}, {"time": 1571, "text": "So how's that not an illusion?"}, {"time": 1573, "text": "The story is written then, or rather we're not the writers of the story."}, {"time": 1581, "text": "Yes, but we always knew that."}, {"time": 1584, "text": "No, we don't know that."}, {"time": 1585, "text": "When did we know that?"}, {"time": 1586, "text": "I think that's mostly a confusion about concepts."}, {"time": 1589, "text": "The conceptual illusion in our culture comes from the idea that we live in physical reality and that we experience physical reality and that you have ideas about it."}, {"time": 1599, "text": "And then you have this dualist interpretation where you have two substances, res extensa, the world that you can touch and that is made of extended things and res cogitans, which is the world of ideas."}, {"time": 1611, "text": "And in fact, both of them are mental representations."}, {"time": 1614, "text": "One is the representations of the world as a game engine that your mind generates to make sense of the perceptual data."}, {"time": 1621, "text": "And the other one, yes, that's what we perceive as the physical world."}, {"time": 1624, "text": "But we already know that the physical world is nothing like that, right?"}, {"time": 1627, "text": "Quantum mechanics is very different from what you and me perceive as the world."}, {"time": 1631, "text": "The world that you and me perceive as a game engine."}, {"time": 1634, "text": "And there are no colors and sounds in the physical world."}, {"time": 1637, "text": "They only exist in the game engine generated by your brain."}, {"time": 1640, "text": "And then you have ideas that cannot be mapped onto extended regions, right?"}, {"time": 1644, "text": "So the objects that have a spatial extension in the game engine, res extensa, and the objects that don't have a physical extension in the game engine are ideas."}, {"time": 1654, "text": "And they both interact in our mind to produce models of the world."}, {"time": 1658, "text": "Yep, but, you know, when you play video games, I understand that what's actually happening is zeros and ones inside of a computer, inside of a CPU and a GPU, but you're still seeing like the rendering of that."}, {"time": 1678, "text": "And you're still making decisions, whether to shoot, to turn left or to turn right, if you're playing a shooter, or every time I started thinking about Skyrim and Elder Scrolls and walking around in beautiful nature and swinging a sword."}, {"time": 1690, "text": "But it feels like you're making decisions inside that video game."}, {"time": 1695, "text": "So even though you don't have direct access in terms of perception to the bits, to the zeros and ones, it still feels like you're making decisions and your decisions actually feels like they're being applied all the way down to the zeros and ones."}, {"time": 1712, "text": "So it feels like you have control, even though you don't have direct access to reality."}, {"time": 1716, "text": "So there is basically a special character in the video game that is being created by the video game engine."}, {"time": 1722, "text": "And this character is serving the aesthetics of the video game, and that is you."}, {"time": 1727, "text": "Yes, but I feel like I have control inside the video game."}, {"time": 1730, "text": "Like all those like 12 year olds that kick my ass on the internet."}, {"time": 1735, "text": "So when you play the video game, it doesn't really matter that there's zeros and ones, right?"}, {"time": 1739, "text": "You don't care about the bits of the past."}, {"time": 1741, "text": "You don't care about the nature of the CPU that it runs on."}, {"time": 1744, "text": "What you care about are the properties of the game that you're playing."}, {"time": 1747, "text": "And you hope that the CPU is good enough."}, {"time": 1750, "text": "And a similar thing happens when we interact with physics."}, {"time": 1753, "text": "The world that you and me are in is not the physical world."}, {"time": 1755, "text": "The world that you and me are in is a dream world."}, {"time": 1759, "text": "How close is it to the real world though?"}, {"time": 1763, "text": "We know that it's not very close, but we know that the dynamics of the dream world match the dynamics of the physical world to a certain degree of resolution."}, {"time": 1771, "text": "But the causal structure of the dream world is different."}, {"time": 1775, "text": "So you see for instance waves crashing on your feet, right?"}, {"time": 1778, "text": "But there are no waves in the ocean."}, {"time": 1779, "text": "There's only water molecules that have tangents between the molecules that are the result of electrons in the molecules interacting with each other."}, {"time": 1790, "text": "Aren't they like very consistent?"}, {"time": 1792, "text": "We're just seeing a very crude approximation."}, {"time": 1795, "text": "Isn't our dream world very consistent, like to the point of being mapped directly one to one to the actual physical world as opposed to us being completely tricked?"}, {"time": 1807, "text": "Is this is like where you have like Donald?"}, {"time": 1810, "text": "It's not an illusion."}, {"time": 1811, "text": "It's a form of data compression."}, {"time": 1813, "text": "It's an attempt to deal with the dynamics of too many parts to count at the level at which we are entangled with the best model that you can find."}, {"time": 1820, "text": "Yeah, so we can act in that dream world and our actions have impact in the real world, in the physical world to which we don't have access."}, {"time": 1828, "text": "Yes, but it's basically like accepting the fact that the software that we live in, the dream that we live in is generated by something outside of this world that you and me are in."}, {"time": 1838, "text": "So is the software deterministic and do we not have any control?"}, {"time": 1842, "text": "Do we have, so free will is having a conscious being."}, {"time": 1849, "text": "Free will is the monkey being able to steer the elephant."}, {"time": 1855, "text": "No, it's slightly different."}, {"time": 1858, "text": "Basically in the same way as you are modeling the water molecules in the ocean that engulf your feet when you are walking on the beach as waves and there are no waves, but only the atoms on more complicated stuff underneath the atoms and so on."}, {"time": 1871, "text": "And you know that, right?"}, {"time": 1874, "text": "You would accept, yes, there is a certain abstraction that happens here."}, {"time": 1877, "text": "It's a simplification of what happens and the simplification that is designed in such a way that your brain can deal with it, temporarily and spatially in terms of resources and tuned for the predictive value."}, {"time": 1888, "text": "So you can predict with some accuracy whether your feet are going to get wet or not."}, {"time": 1893, "text": "But it's a really good interface and approximation."}, {"time": 1897, "text": "It says E equals MC squared is a good, equations are good approximation for, they're much better approximation."}, {"time": 1905, "text": "So to me, waves is a really nice approximation of what's all the complexity that's happening underneath."}, {"time": 1911, "text": "Basically it's a machine learning model that is constantly tuned to minimize surprises."}, {"time": 1915, "text": "So it basically tries to predict as well as it can what you're going to perceive next."}, {"time": 1919, "text": "Are we talking about, which is the machine learning?"}, {"time": 1922, "text": "Our perception system or the dream world?"}, {"time": 1925, "text": "The machine world, dream world is the result of the machine learning process of the perceptual system."}, {"time": 1931, "text": "That's doing the compression."}, {"time": 1933, "text": "And the model of you as an agent is not a different type of model or it's a different type, but not different as in its model like nature from the model of the ocean, right?"}, {"time": 1945, "text": "Some things are oceans, some things are agents."}, {"time": 1948, "text": "And one of these agents is using your own control model, the output of your model, the things that you perceive yourself as doing."}, {"time": 1956, "text": "And that is you."}, {"time": 1958, "text": "What about the fact that when you're standing with the water on your feet and you're looking out into the vast open water of the ocean and then there's a beautiful sunset and the fact that it's beautiful and then maybe you have friends or a loved one with you and you feel love, what is that?"}, {"time": 1980, "text": "As the dream world or what is that?"}, {"time": 1982, "text": "Yes, it's all happening inside of the dream."}, {"time": 1986, "text": "But see, the word dream makes it seem like it's not real."}, {"time": 1991, "text": "No, of course it's not real."}, {"time": 1994, "text": "The physical universe is real, but the physical universe is incomprehensible and it doesn't have any feeling of realness."}, {"time": 2001, "text": "The feeling of realness that you experience gets attached to certain representations where your brain assesses, this is the best model of reality that I have."}, {"time": 2008, "text": "So the only thing that's real to you is the thing that's happening at the very base of reality."}, {"time": 2014, "text": "Yeah, for something to be real, it needs to be implemented."}, {"time": 2020, "text": "So the model that you have of reality is real in as far as it is a model."}, {"time": 2025, "text": "It's an appropriate description of the world to say that there are models that are being experienced, but the world that you experience is not necessarily implemented."}, {"time": 2036, "text": "There is a difference between a reality, a simulation and a simulacrum."}, {"time": 2042, "text": "The reality that we're talking about is something that fully emerges over a causally closed lowest layer."}, {"time": 2048, "text": "And the idea of physicalism is that we are in that layer, that basically our world emerges over that."}, {"time": 2053, "text": "Every alternative to physicalism is a simulation theory, which basically says that we are in some kind of simulation universe and the real world needs to be in a parent universe of that, where the actual causal structure is, right?"}, {"time": 2064, "text": "And when you look at the ocean and your own mind, you are looking at a simulation that explains what you're going to see next."}, {"time": 2071, "text": "So we are living in a simulation."}, {"time": 2072, "text": "Yes, but a simulation generated by our own brains."}, {"time": 2076, "text": "And this simulation is different from the physical reality because the causal structure that is being produced, what you are seeing is different from the causal structure of physics."}, {"time": 2084, "text": "But consistent."}, {"time": 2086, "text": "Hopefully, if not, then you are going to end up in some kind of institution where people will take care of you because your behavior will be inconsistent, right?"}, {"time": 2094, "text": "Your behavior needs to work in such a way that it's interacting with an accurately predictive model of reality."}, {"time": 2100, "text": "And if your brain is unable to make your model of reality predictive, you will need help."}, {"time": 2106, "text": "So what do you think about Donald Hoffman's argument that it doesn't have to be consistent, the dream world to what he calls like the interface to the actual physical reality, where there could be evolution?"}, {"time": 2120, "text": "I think he makes an evolutionary argument, which is like, it could be an evolutionary advantage to have the dream world drift away from physical reality."}, {"time": 2130, "text": "I think that only works if you have tenure."}, {"time": 2132, "text": "As long as you're still interacting with the ground tools, your model needs to be somewhat predictive."}, {"time": 2138, "text": "Well, in some sense, humans have achieved a kind of tenure in the animal kingdom."}, {"time": 2145, "text": "And at some point we became too big to fail, so we became postmodernist."}, {"time": 2151, "text": "It all makes sense now."}, {"time": 2152, "text": "We can just change the version of reality that we like."}, {"time": 2157, "text": "Yeah, but basically you can do magic."}, {"time": 2160, "text": "You can change your assessment of reality, but eventually reality is going to come bite you in the ass if it's not predictive."}, {"time": 2166, "text": "Do you have a sense of what is that base layer of physical reality?"}, {"time": 2172, "text": "You have like, so you have these attempts at the theories of everything, the very, very small of like strength theory, or what Stephen Wolfram talks about with the hyper grass."}, {"time": 2185, "text": "These are these tiny, tiny, tiny, tiny objects."}, {"time": 2188, "text": "And then there is more like quantum mechanics that's talking about objects that are much larger, but still very, very, very tiny."}, {"time": 2196, "text": "Do you have a sense of where the tiniest thing is that is like at the lowest level?"}, {"time": 2202, "text": "The turtle at the very bottom."}, {"time": 2204, "text": "Do you have a sense what that turtle is?"}, {"time": 2205, "text": "I don't think that you can talk about where it is because space is emerging over the activity of these things."}, {"time": 2211, "text": "So space, the coordinates only exist in relation to the things, other things."}, {"time": 2218, "text": "And so you could, in some sense, abstract it into locations that can hold information and trajectories that the information can take between the different locations."}, {"time": 2226, "text": "And this is how we construct our notion of space."}, {"time": 2230, "text": "And physicists usually have a notion of space that is continuous."}, {"time": 2235, "text": "And this is a point where I tend to agree with people like Stephen Wolfram who are very skeptical of the geometric notions."}, {"time": 2243, "text": "I think that geometry is the dynamics of too many parts to count."}, {"time": 2259, "text": "So there are no infinities."}, {"time": 2261, "text": "There are no infinities."}, {"time": 2262, "text": "Infinities fake."}, {"time": 2263, "text": "There is unboundedness, but if you have a language that talks about infinity, at some point, the language is going to contradict itself, which means it's no longer valid."}, {"time": 2271, "text": "In order to deal with infinities and mathematics, you have to postulate the existence initially."}, {"time": 2277, "text": "You cannot construct the infinities."}, {"time": 2279, "text": "And that's an issue, right?"}, {"time": 2280, "text": "You cannot build up an infinity from zero."}, {"time": 2282, "text": "But in practice, you never do this, right?"}, {"time": 2284, "text": "When you perform calculations, you only look at the dynamics of too many parts to count."}, {"time": 2289, "text": "And usually these numbers are not that large."}, {"time": 2293, "text": "They're not Googles or something."}, {"time": 2294, "text": "The infinities that we are dealing with in our universe are mathematically speaking, relatively small integers."}, {"time": 2303, "text": "And still what we're looking at is dynamics where a trillion things behave similar to a hundred trillion things or something that is very, very large because they're converging."}, {"time": 2319, "text": "And these convergent dynamics, these operators, this is what we deal with when we are doing the geometry."}, {"time": 2325, "text": "Geometry is stuff where we can pretend that it's continuous because if we subdivide the space sufficiently fine grained, these things approach a certain dynamic."}, {"time": 2336, "text": "And this approach dynamic, that is what we mean by it."}, {"time": 2339, "text": "But I don't think that infinity would work, so to speak, that you would know the last digit of pi and that you have a physical process that rests on knowing the last digit of pi."}, {"time": 2349, "text": "Yeah, that could be just a peculiar quirk of human cognition that we like discrete."}, {"time": 2355, "text": "Discrete makes sense to us."}, {"time": 2356, "text": "Infinity doesn't, so in terms of our intuitions."}, {"time": 2359, "text": "No, the issue is that everything that we think about needs to be expressed in some kind of mental language, not necessarily natural language, but some kind of mathematical language that your neurons can speak that refers to something in the world."}, {"time": 2374, "text": "And what we have discovered is that we cannot construct a notion of infinity without running into contradictions, which means that such a language is no longer valid."}, {"time": 2383, "text": "And I suspect this is what made Pythagoras so unhappy when somebody came up with the notion of irrational numbers before it was time, right?"}, {"time": 2390, "text": "There's this myth that he had this person killed when he blabbed out the secret that not everything can be expressed as a ratio between two numbers, but there are numbers between the ratios."}, {"time": 2399, "text": "The world was not ready for this."}, {"time": 2401, "text": "And I think he was right."}, {"time": 2402, "text": "That has confused mathematicians very seriously because these numbers are not values, they are functions."}, {"time": 2409, "text": "And so you can calculate these functions to a certain degree of approximation, but you cannot pretend that pi has actually a value."}, {"time": 2417, "text": "Pi is a function that would approach this value to some degree, but nothing in the world rests on knowing pi."}, {"time": 2426, "text": "How important is this distinction between discrete and continuous for you to get to the book?"}, {"time": 2432, "text": "Because there's a, I mean, in discussion of your favorite flavor of the theory of everything, there's a few on the table."}, {"time": 2441, "text": "So there's string theory, there's a particular, there's a little quantum gravity, which focused on one particular unification."}, {"time": 2453, "text": "There's just a bunch of favorite flavors of different people trying to propose a theory of everything."}, {"time": 2461, "text": "Eric Weinstein and a bunch of people throughout history."}, {"time": 2464, "text": "And then of course, Stephen Wolfram, who I think is one of the only people doing a discrete."}, {"time": 2470, "text": "No, no, there's a bunch of physicists who do this right now."}, {"time": 2473, "text": "And like Toffoli and Tomasello."}, {"time": 2477, "text": "And digital physics is something that is, I think, growing in popularity."}, {"time": 2484, "text": "But the main reason why this is interesting is because it's important sometimes to settle disagreements."}, {"time": 2494, "text": "I don't think that you need infinities at all, and you never needed them."}, {"time": 2498, "text": "You can always deal with very large numbers and you can deal with limits, right?"}, {"time": 2502, "text": "We are fine with doing that."}, {"time": 2503, "text": "You don't need any kind of infinity."}, {"time": 2505, "text": "You can build your computer algebra systems just as well without believing in infinity in the first place."}, {"time": 2510, "text": "So you're okay with limits?"}, {"time": 2511, "text": "Yeah, so basically a limit means that something is behaving pretty much the same if you make the number large."}, {"time": 2519, "text": "Right, because it's converging to a certain value."}, {"time": 2522, "text": "And at some point the difference becomes negligible and you can no longer measure it."}, {"time": 2526, "text": "And in this sense, you have things that if you have an ngon which has enough corners, then it's going to behave like a circle at some point, right?"}, {"time": 2535, "text": "And it's only going to be in some kind of esoteric thing that cannot exist in the physical universe that you would be talking about this perfect circle."}, {"time": 2543, "text": "And now it turns out that it also wouldn't work in mathematics because you cannot construct mathematics that has infinite resolution without running into contradictions."}, {"time": 2552, "text": "So that is itself not that important because we never did that, right?"}, {"time": 2556, "text": "It's just a thing that some people thought we could."}, {"time": 2559, "text": "And this leads to confusion."}, {"time": 2560, "text": "So for instance, Roger Penrose uses this as an argument to say that there are certain things that mathematicians can do dealing with infinities and by extension our mind can do that computers cannot do."}, {"time": 2575, "text": "Yeah, he talks about that the human mind can do certain mathematical things that the computer as defined by the universal Turing machine cannot."}, {"time": 2587, "text": "So that it has to do with infinity."}, {"time": 2588, "text": "Yes, it's one of the things."}, {"time": 2590, "text": "So he is basically pointing at the fact that there are things that are possible in the mathematical mind and in pure mathematics that are not possible in machines that can be constructed in the physical universe."}, {"time": 2607, "text": "And because he's an honest guy, he thinks this means that present physics cannot explain operations that happen in our mind."}, {"time": 2614, "text": "Do you think he's right?"}, {"time": 2615, "text": "And so let's leave his discussion of consciousness aside for the moment."}, {"time": 2620, "text": "Do you think he's right about just what he's basically referring to as intelligence?"}, {"time": 2626, "text": "So is the human mind fundamentally more capable as a thinking machine than a universal Turing machine?"}, {"time": 2635, "text": "But so he's suggesting that, right?"}, {"time": 2638, "text": "So our mind is actually less than a Turing machine."}, {"time": 2641, "text": "There can be no Turing machine because it's defined as having an infinite tape."}, {"time": 2645, "text": "And we always only have a finite tape."}, {"time": 2647, "text": "But he's saying it's better."}, {"time": 2648, "text": "Our minds can only perform finitely many operations."}, {"time": 2650, "text": "Yes, he thinks so."}, {"time": 2650, "text": "He's saying it can do the kind of computation that the Turing machine cannot."}, {"time": 2654, "text": "And that's because he thinks that our minds can do operations that have infinite resolution in some sense."}, {"time": 2661, "text": "And I don't think that's the case."}, {"time": 2663, "text": "Our minds are just able to discover these limit operators over too many parts to count."}, {"time": 2670, "text": "What about his idea that consciousness is more than a computation?"}, {"time": 2677, "text": "So it's more than something that a Turing machine can do."}, {"time": 2682, "text": "So again, saying that there's something special about our mind that cannot be replicated in a machine."}, {"time": 2689, "text": "The issue is that I don't even know how to construct a language to express this statement correctly."}, {"time": 2696, "text": "Well, the basic statement is there's a human experience that includes intelligence, that includes self awareness, that includes the hard problem of consciousness."}, {"time": 2712, "text": "And the question is, can that be fully simulated in the computer, in the mathematical model of the computer as we understand it today?"}, {"time": 2723, "text": "Roger Penrose says no."}, {"time": 2725, "text": "So the universe of Turing machine cannot simulate the universe."}, {"time": 2732, "text": "So the interesting question is, and you have to ask him this is, why not?"}, {"time": 2736, "text": "What is this specific thing that cannot be modeled?"}, {"time": 2739, "text": "And when I looked at his writings and I haven't read all of it, but when I read, for instance, the section that he writes in the introduction to a road to infinity, the thing that he specifically refers to is the way in which human minds deal with infinities."}, {"time": 2757, "text": "And that itself can, I think, easily be deconstructed."}, {"time": 2763, "text": "A lot of people feel that our experience cannot be explained in a mechanical way."}, {"time": 2768, "text": "And therefore it needs to be different."}, {"time": 2771, "text": "And I concur, our experience is not mechanical."}, {"time": 2774, "text": "Our experience is simulated."}, {"time": 2776, "text": "It exists only in a simulation."}, {"time": 2778, "text": "The only simulation can be conscious."}, {"time": 2779, "text": "Physical systems cannot be conscious because they're only mechanical."}, {"time": 2783, "text": "Cells cannot be conscious."}, {"time": 2785, "text": "Neurons cannot be conscious."}, {"time": 2786, "text": "Brains cannot be conscious."}, {"time": 2787, "text": "People cannot be conscious as far as if you understand them as physical systems."}, {"time": 2791, "text": "What can be conscious is the story of the system in the world where you write all these things into the story."}, {"time": 2799, "text": "You have experiences for the same reason that a character novel has experiences because it's written into the story."}, {"time": 2805, "text": "And now the system is acting on that story."}, {"time": 2808, "text": "And it's not a story that is written in a natural language."}, {"time": 2810, "text": "It's written in a perceptual language, in this multimedia language of the game engine."}, {"time": 2815, "text": "And in there, you write in what kind of experience you have and what this means for the behavior of the system, for your behavior tendencies, for your focus, for your attention, for your experience of valence and so on."}, {"time": 2826, "text": "And this is being used to inform the behavior of the system in the next step."}, {"time": 2830, "text": "And then the story updates with the reactions of the system and the changes in the world and so on."}, {"time": 2837, "text": "And you live inside of that model."}, {"time": 2839, "text": "You don't live inside of the physical reality."}, {"time": 2843, "text": "And I mean, just to linger on it, like you say, okay, it's in the perceptual language, the multimodal perceptual language."}, {"time": 2853, "text": "That's the experience."}, {"time": 2854, "text": "That's what consciousness is within that model, within that story."}, {"time": 2860, "text": "But do you have agency?"}, {"time": 2863, "text": "When you play a video game, you can turn left and you can turn right in that story."}, {"time": 2869, "text": "So in that dream world, how much control do you have?"}, {"time": 2874, "text": "Is there such a thing as you in that story?"}, {"time": 2877, "text": "Like, is it right to say the main character, you know, everybody's NPCs, and then there's the main character and you're controlling the main character?"}, {"time": 2887, "text": "Or is that an illusion?"}, {"time": 2888, "text": "Is there a main character that you're controlling?"}, {"time": 2890, "text": "I'm getting to the point of like the free will point."}, {"time": 2894, "text": "Imagine that you are building a robot that plays soccer."}, {"time": 2897, "text": "And you've been to MIT computer science, you basically know how to do that, right?"}, {"time": 2902, "text": "And so you would say the robot is an agent that solves a control problem, how to get the ball into the goal."}, {"time": 2909, "text": "And it needs to perceive the world and the world is disturbing him in trying to do this, right?"}, {"time": 2913, "text": "So he has to control many variables to make that happen and to project itself and the ball into the future and understand its position on the field relative to the ball and so on, and the position of its limbs or in the space around it and so on."}, {"time": 2926, "text": "So it needs to have an adequate model that abstracting reality in a useful way."}, {"time": 2931, "text": "And you could say that this robot does have agency over what it's doing in some sense."}, {"time": 2938, "text": "And the model is going to be a control model."}, {"time": 2941, "text": "And inside of that control model, you can possibly get to a point where this thing is sufficiently abstract to discover its own agency."}, {"time": 2949, "text": "Our current robots don't do that."}, {"time": 2950, "text": "They don't have a unified model of the universe, but there's not a reason why we shouldn't be getting there at some point in the not too distant future."}, {"time": 2958, "text": "And once that happens, you will notice that the robot tells a story about a robot playing soccer."}, {"time": 2965, "text": "So the robot will experience itself playing soccer in a simulation of the world that it uses to construct a model of the locations of its legs and limbs in space on the field with relationship to the ball."}, {"time": 2979, "text": "And it's not going to be at the level of the molecules."}, {"time": 2982, "text": "It will be an abstraction that is exactly at the level that is most suitable for past planning of the movements of the robot."}, {"time": 2989, "text": "It's going to be a high level abstraction, but a very useful one that is as predictive as we can make it."}, {"time": 2995, "text": "And in that side of that story, there is a model of the agency of that system."}, {"time": 2998, "text": "So this model can accurately predict that the contents of the model are going to be driving the behavior of the robot in the immediate future."}, {"time": 3008, "text": "But there's the hard problem of consciousness, which I would also, there's a subjective experience of free will as well that I'm not sure where the robot gets that, where that little leap is."}, {"time": 3022, "text": "Because for me right now, everything I imagine with that robot, as it gets more and more and more sophisticated, the agency comes from the programmer of the robot still, of what was programmed in."}, {"time": 3035, "text": "You could probably do an end to end learning system."}, {"time": 3038, "text": "You maybe need to give it a few priors."}, {"time": 3040, "text": "So you nudge the architecture in the right direction that it converges more quickly, but ultimately discovering the suitable hyperparameters of the architecture is also only a search process."}, {"time": 3050, "text": "And as the search process was evolution, that has informed our brain architecture so we can converge in a single lifetime on useful interaction with the world and the formation of a self model."}, {"time": 3060, "text": "The problem is if we define hyperparameters broadly, so it's not just the parameters that control this end to end learning system, but the entirety of the design of the robot."}, {"time": 3071, "text": "Like there's, you have to remove the human completely from the picture."}, {"time": 3075, "text": "And then in order to build the robot, you have to create an entire universe."}, {"time": 3080, "text": "Cause you have to go, you can't just shortcut evolution."}, {"time": 3082, "text": "You have to go from the very beginning in order for it to have, cause I feel like there's always a human pulling the strings and that makes it seem like the robot is cheating."}, {"time": 3093, "text": "It's getting a shortcut to consciousness."}, {"time": 3095, "text": "And you are looking at the current Boston Dynamics robots."}, {"time": 3098, "text": "It doesn't look as if there is somebody pulling the strings."}, {"time": 3100, "text": "It doesn't look like cheating anymore."}, {"time": 3102, "text": "Okay, so let's go there."}, {"time": 3103, "text": "Cause I got to talk to you about this."}, {"time": 3104, "text": "So obviously with the case of Boston Dynamics, as you may or may not know, it's always either hard coded or remote controlled."}, {"time": 3114, "text": "There's no intelligence."}, {"time": 3115, "text": "I don't know how the current generation of Boston Dynamics robots works, but what I've been told about the previous ones was that it's basically all cybernetic control, which means you still have feedback mechanisms and so on, but it's not deep learning for the most part as it's currently done."}, {"time": 3133, "text": "It's for the most part, just identifying a control hierarchy that is congruent to the limbs that exist and the parameters that need to be optimized for the movement of these limbs."}, {"time": 3142, "text": "And then there is a convergence progress."}, {"time": 3144, "text": "So it's basically just regression that you would need to control this."}, {"time": 3147, "text": "But again, I don't know whether that's true."}, {"time": 3149, "text": "That's just what I've been told about how they work."}, {"time": 3151, "text": "We have to separate several levels of discussion here."}, {"time": 3155, "text": "So the only thing they do is pretty sophisticated control with no machine learning in order to maintain balance or to right itself."}, {"time": 3165, "text": "It's a control problem in terms of using the actuators to when it's pushed or when it steps on a thing that's uneven, how to always maintain balance."}, {"time": 3175, "text": "And there's a tricky set of heuristics around that, but that's the only goal."}, {"time": 3180, "text": "Everything you see Boston Dynamics doing in terms of that to us humans is compelling, which is any kind of higher order movement, like turning, wiggling its butt, like jumping back on its two feet, dancing."}, {"time": 3198, "text": "Dancing is even worse because dancing is hard coded in."}, {"time": 3202, "text": "It's choreographed by humans."}, {"time": 3205, "text": "There's choreography software."}, {"time": 3207, "text": "So there is no, of all that high level movement, there's no anything that you can call, certainly can't call AI, but there's no even like basic heuristics."}, {"time": 3219, "text": "It's all hard coded in."}, {"time": 3221, "text": "And yet we humans immediately project agency onto them, which is fascinating."}, {"time": 3228, "text": "So the gap here doesn't necessarily have agency."}, {"time": 3233, "text": "What it has is cybernetic control."}, {"time": 3235, "text": "And the cybernetic control means you have a hierarchy of feedback loops that keep the behavior in certain boundaries so the robot doesn't fall over and it's able to perform the movements."}, {"time": 3244, "text": "And the choreography cannot really happen with motion capture because the robot would fall over because the physics of the robot, the weight distribution and so on is different from the weight distribution in the human body."}, {"time": 3255, "text": "So if you were using the directly motion captured movements of a human body to project it into this robot, it wouldn't work."}, {"time": 3262, "text": "You can do this with a computer animation."}, {"time": 3264, "text": "It will look a little bit off, but who cares?"}, {"time": 3266, "text": "But if you want to correct for the physics, you need to basically tell the robot where it should move its limbs."}, {"time": 3273, "text": "And then the control algorithm is going to approximate a solution that makes it possible within the physics of the robot."}, {"time": 3281, "text": "And you have to find the basic solution for making that happen."}, {"time": 3284, "text": "And there's probably going to be some regression necessary to get the control architecture to make these movements."}, {"time": 3291, "text": "But those two layers are separate."}, {"time": 3292, "text": "So the thing, the higher level instruction of how you should move and where you should move is a higher level."}, {"time": 3299, "text": "Yeah, so I expect that the control level of these robots at some level is dumb."}, {"time": 3303, "text": "This is just the physical control movement, the motor architecture."}, {"time": 3307, "text": "But it's a relatively smart motor architecture."}, {"time": 3310, "text": "It's just that there is no high level deliberation about what decisions to make necessarily, right?"}, {"time": 3314, "text": "But see, it doesn't feel like free will or consciousness."}, {"time": 3317, "text": "No, no, that was not where I was trying to get to."}, {"time": 3320, "text": "I think that in our own body, we have that too."}, {"time": 3324, "text": "So we have a certain thing that is basically just a cybernetic control architecture that is moving our limbs."}, {"time": 3331, "text": "And deep learning can help in discovering such an architecture if you don't have it in the first place."}, {"time": 3337, "text": "If you already know your hardware, you can maybe handcraft it."}, {"time": 3340, "text": "But if you don't know your hardware, you can search for such an architecture."}, {"time": 3343, "text": "And this work already existed in the 80s and 90s."}, {"time": 3346, "text": "People were starting to search for control architectures by motor babbling and so on, and just use reinforcement learning architectures to discover such a thing."}, {"time": 3355, "text": "And now imagine that you have the cybernetic control architecture already inside of you."}, {"time": 3361, "text": "And you extend this a little bit."}, {"time": 3363, "text": "So you are seeking out food, for instance, or rest or and so on."}, {"time": 3368, "text": "And you get to have a baby at some point."}, {"time": 3371, "text": "And now you add more and more control layers to this."}, {"time": 3375, "text": "And the system is reverse engineering its own control architecture and builds a high level model to synchronize the pursuit of very different conflicting goals."}, {"time": 3386, "text": "And this is how I think you get to purposes."}, {"time": 3388, "text": "Purposes are models of your goals."}, {"time": 3390, "text": "The goals may be intrinsic as the result of the different set point violations that you have, hunger and thirst for very different things, and rest and pain avoidance and so on."}, {"time": 3399, "text": "And you put all these things together and eventually you need to come up with a strategy to synchronize them all."}, {"time": 3406, "text": "And you don't need just to do this alone by yourself because we are state building organisms."}, {"time": 3411, "text": "We cannot function as isolation the way that homo sapiens is set up."}, {"time": 3415, "text": "So our own behavior only makes sense when you zoom out very far into a society or even into ecosystemic intelligence on the planet and our place in it."}, {"time": 3426, "text": "So the individual behavior only makes sense in these larger contexts."}, {"time": 3429, "text": "And we have a number of priors built into us."}, {"time": 3431, "text": "So we are behaving as if we were acting on these high level goals pretty much right from the start."}, {"time": 3437, "text": "And eventually in the course of our life, we can reverse engineer the goals that we're acting on, what actually are our higher level purposes."}, {"time": 3445, "text": "And the more we understand that, the more our behavior makes sense."}, {"time": 3448, "text": "But this is all at this point, complex stories within stories that are driving our behavior."}, {"time": 3454, "text": "Yeah, I just don't know how big of a leap it is to start create a system that's able to tell stories within stories."}, {"time": 3464, "text": "Like how big of a leap that is from where currently Boston Dynamics is or any robot that's operating in the physical space."}, {"time": 3473, "text": "And that leap might be big if it requires to solve the hard problem of consciousness, which is telling a hell of a good story."}, {"time": 3481, "text": "I suspect that consciousness itself is relatively simple."}, {"time": 3485, "text": "What's hard is perception and the interface between perception and reasoning."}, {"time": 3491, "text": "That's for instance, the idea of the consciousness prior that would be built into such a system by Yoshua Bengio."}, {"time": 3498, "text": "And what he describes, and I think that's accurate, is that our own model of the world can be described through something like an energy function."}, {"time": 3509, "text": "The energy function is modeling the contradictions that exist within the model at any given point."}, {"time": 3514, "text": "And you try to minimize these contradictions, the tangents in the model."}, {"time": 3518, "text": "And to do this, you need to sometimes test things."}, {"time": 3521, "text": "You need to conditionally disambiguate figure and ground."}, {"time": 3523, "text": "You need to distinguish whether this is true or that is true, and so on."}, {"time": 3527, "text": "Eventually you get to an interpretation, but you will need to manually depress a few points in your model to let it snap into a state that makes sense."}, {"time": 3535, "text": "And this function that tries to get the biggest dip in the energy function in your model, according to Yoshua Bengio, is related to consciousness."}, {"time": 3542, "text": "It's a low dimensional discrete function that tries to maximize this dip in the energy function."}, {"time": 3549, "text": "Yeah, I think I would need to dig into details because I think the way he uses the word consciousness is more akin to like self awareness, like modeling yourself within the world, as opposed to the subjective experience, the hard problem."}, {"time": 3563, "text": "No, it's not even the self is in the world."}, {"time": 3566, "text": "The self is the agent and you don't need to be aware of yourself in order to be conscious."}, {"time": 3571, "text": "The self is just a particular content that you can have, but you don't have to have."}, {"time": 3575, "text": "But you can be conscious in, for instance, a dream at night or during a meditation state where you don't have a self."}, {"time": 3583, "text": "Where you're just aware of the fact that you are aware."}, {"time": 3585, "text": "And what we mean by consciousness in the colloquial sense is largely this reflexive self awareness, that we become aware of the fact that you're paying attention, that we are the thing that pays attention."}, {"time": 3599, "text": "We are the thing that pays attention, right."}, {"time": 3602, "text": "I don't see where the awareness that we're aware, the hard problem doesn't feel like it's solved."}, {"time": 3610, "text": "I mean, it's called a hard problem for a reason, because it seems like there needs to be a major leap."}, {"time": 3619, "text": "Yeah, I think the major leap is to understand how it is possible that a machine can dream, that a physical system is able to create a representation that the physical system is acting on, and that is spun force and so on."}, {"time": 3633, "text": "But once you accept the fact that you are not in physics, but that you exist inside of the story, I think the mystery disappears."}, {"time": 3640, "text": "Everything is possible in the story."}, {"time": 3641, "text": "You exist inside the story."}, {"time": 3643, "text": "Okay, so the machine."}, {"time": 3644, "text": "Your consciousness is being written into the story."}, {"time": 3645, "text": "The fact that you experience things is written to the side of the story."}, {"time": 3648, "text": "You ask yourself, is this real what I'm seeing?"}, {"time": 3651, "text": "And your brain writes into the story, yes, it's real."}, {"time": 3653, "text": "So what about the perception of consciousness?"}, {"time": 3656, "text": "So to me, you look conscious."}, {"time": 3659, "text": "So the illusion of consciousness, the demonstration of consciousness."}, {"time": 3664, "text": "I ask for the legged robot."}, {"time": 3667, "text": "How do we make this legged robot conscious?"}, {"time": 3670, "text": "So there's two things, and maybe you can tell me if they're neighboring ideas."}, {"time": 3676, "text": "One is actually make it conscious, and the other is make it appear conscious to others."}, {"time": 3682, "text": "Are those related?"}, {"time": 3685, "text": "Let's ask it from the other direction."}, {"time": 3687, "text": "What would it take to make you not conscious?"}, {"time": 3691, "text": "So when you are thinking about how you perceive the world, can you decide to switch from looking at qualia to looking at representational states?"}, {"time": 3703, "text": "And it turns out you can."}, {"time": 3704, "text": "There is a particular way in which you can look at the world and recognize its machine nature, including your own."}, {"time": 3711, "text": "And in that state, you don't have that conscious experience in this way anymore."}, {"time": 3715, "text": "It becomes apparent as a representation."}, {"time": 3719, "text": "Everything becomes opaque."}, {"time": 3721, "text": "And I think this thing that you recognize, everything is a representation."}, {"time": 3725, "text": "This is typically what we mean with enlightenment states."}, {"time": 3729, "text": "And it can happen on the motivational level, but you can also do this on the experiential level, on the perceptual level."}, {"time": 3736, "text": "See, but then I can come back to a conscious state."}, {"time": 3740, "text": "Okay, I particularly, I'm referring to the social aspect that the demonstration of consciousness is a really nice thing at a party when you're trying to meet a new person."}, {"time": 3754, "text": "It's a nice thing to know that they're conscious and they can, I don't know how fundamental consciousness is in human interaction, but it seems like to be at least an important part."}, {"time": 3768, "text": "And I ask that in the same kind of way for robots."}, {"time": 3773, "text": "In order to create a rich, compelling human robot interaction, it feels like there needs to be elements of consciousness within that interaction."}, {"time": 3782, "text": "My cat is obviously conscious."}, {"time": 3784, "text": "And so my cat can do this party trick."}, {"time": 3787, "text": "She also knows that I am conscious, be able to have feedback about the fact that we are both acting on models of our own awareness."}, {"time": 3794, "text": "The question is how hard is it for the robot, artificially created robot to achieve cat level and party tricks?"}, {"time": 3804, "text": "Yes, so the issue for me is currently not so much on how to build a system that creates a story about a robot that lives in the world, but to make an adequate representation of the world."}, {"time": 3816, "text": "And the model that you and me have is a unified one."}, {"time": 3820, "text": "It's one where you basically make sense of everything that you can perceive."}, {"time": 3824, "text": "Every feature in the world that enters your perception can be relationally mapped to a unified model of everything."}, {"time": 3831, "text": "And we don't have an AI that is able to construct such a unified model yet."}, {"time": 3836, "text": "So you need that unified model to do the party trick?"}, {"time": 3838, "text": "Yes, I think that it doesn't make sense if this thing is conscious, but not in the same universe as you, because you could not relate to each other."}, {"time": 3846, "text": "So what's the process, would you say, of engineering consciousness in the machine?"}, {"time": 3852, "text": "Like what are the ideas here?"}, {"time": 3854, "text": "So you probably want to have some kind of perceptual system."}, {"time": 3859, "text": "This perceptual system is a processing agent that is able to track sensory data and predict the next frame in the sensory data from the previous frames of the sensory data and the current state of the system."}, {"time": 3871, "text": "So the current state of the system is, in perception, instrumental to predicting what happens next."}, {"time": 3877, "text": "And this means you build lots and lots of functions that take all the blips that you feel on your skin and that you see on your retina, or that you hear, and puts them into a set of relationships that allows you to predict what kind of sensory data, what kind of sensor of blips, vector of blips, you're going to perceive in the next frame."}, {"time": 3896, "text": "This is tuned and it's constantly tuned until it gets as accurate as it can."}, {"time": 3901, "text": "You build a very accurate prediction mechanism that is step one of the perception."}, {"time": 3908, "text": "So first you predict, then you perceive and see the error in your prediction."}, {"time": 3911, "text": "And you have to do two things to make that happen."}, {"time": 3913, "text": "One is you have to build a network of relationships that are constraints, that take all the variants in the world and put each of the variances into a variable that is connected with relationships to other variables."}, {"time": 3927, "text": "And these relationships are computable functions that constrain each other."}, {"time": 3931, "text": "So when you see a nose that points in a certain direction in space, you have a constraint that says there should be a face nearby that has the same direction."}, {"time": 3939, "text": "And if that is not the case, you have some kind of contradiction that you need to resolve because it's probably not a nose what you're looking at."}, {"time": 3944, "text": "It just looks like one."}, {"time": 3945, "text": "So you have to reinterpret the data until you get to a point where your model converges."}, {"time": 3952, "text": "And this process of making the sensory data fit into your model structure is what Piaget calls the assimilation."}, {"time": 3961, "text": "And accommodation is the change of the models where you change your model in such a way that you can assimilate everything."}, {"time": 3968, "text": "So you're talking about building a hell of an awesome perception system that's able to do prediction and perception and correct and keep improving."}, {"time": 3975, "text": "No, wait, that's..."}, {"time": 3977, "text": "Wait, there's more."}, {"time": 3978, "text": "Yes, there's more."}, {"time": 3979, "text": "So the first thing that we wanted to do is we want to minimize the contradictions in the model."}, {"time": 3984, "text": "And of course, it's very easy to make a model in which you minimize the contradictions just by allowing that it can be in many, many possible states, right?"}, {"time": 3991, "text": "So if you increase degrees of freedom, you will have fewer contradictions."}, {"time": 3995, "text": "But you also want to reduce the degrees of freedom because degrees of freedom mean uncertainty."}, {"time": 4000, "text": "You want your model to reduce uncertainty as much as possible, but reducing uncertainty is expensive."}, {"time": 4006, "text": "So you have to have a trade off between minimizing contradictions and reducing uncertainty."}, {"time": 4012, "text": "And you have only a finite amount of compute and experimental time and effort available to reduce uncertainty in the world."}, {"time": 4019, "text": "So you need to assign value to what you observe."}, {"time": 4022, "text": "So you need some kind of motivational system that is estimating what you should be looking at and what you should be thinking about it, how you should be applying your resources to model what that is, right?"}, {"time": 4032, "text": "So you need to have something like convergence links that tell you how to get from the present state of the model to the next one."}, {"time": 4039, "text": "You need to have these compatibility links that tell you which constraints exist and which constraint violations exist."}, {"time": 4045, "text": "And you need to have some kind of motivational system that tells you what to pay attention to."}, {"time": 4050, "text": "So now we have a second agent next to the perceptual agent."}, {"time": 4052, "text": "We have a motivational agent."}, {"time": 4054, "text": "This is a cybernetic system that is modeling what the system needs, what's important for the system, and that interacts with the perceptual system to maximize the expected reward."}, {"time": 4064, "text": "And you're saying the motivational system is some kind of like, what is it?"}, {"time": 4069, "text": "A high level narrative over some lower level."}, {"time": 4072, "text": "No, it's just your brainstem stuff, the limbic system stuff that tells you, okay, now you should get something to eat because I've just measured your blood sugar."}, {"time": 4079, "text": "So you mean like motivational system, like the lower level stuff, like hungry."}, {"time": 4083, "text": "Yes, there's basically physiological needs and some cognitive needs and some social needs and they all interact."}, {"time": 4088, "text": "And they're all implemented at different parts in your nervous system as the motivational system."}, {"time": 4092, "text": "But they're basically cybernetic feedback loops."}, {"time": 4094, "text": "It's not that complicated."}, {"time": 4096, "text": "It's just a lot of code."}, {"time": 4098, "text": "And so you now have a motivational agent that makes your robot go for the ball or that makes your worm go to eat food and so on."}, {"time": 4107, "text": "And you have the perceptual system that lets it predict the environment so it's able to solve that control problem to some degree."}, {"time": 4113, "text": "And now what we learned is that it's very hard to build a machine learning system that looks at all the data simultaneously to see what kind of relationships could exist between them."}, {"time": 4123, "text": "So you need to selectively model the world."}, {"time": 4125, "text": "You need to figure out where can I make the biggest difference if I would put the following things together."}, {"time": 4130, "text": "Sometimes you find a gradient for that."}, {"time": 4133, "text": "When you have a gradient, you don't need to remember where you came from."}, {"time": 4136, "text": "You just follow the gradient until it doesn't get any better."}, {"time": 4139, "text": "But if you have a world where the problems are discontinuous and the search spaces are discontinuous, you need to retain memory of what you explored."}, {"time": 4147, "text": "You need to construct a plan of what to explore next."}, {"time": 4150, "text": "And this thing means that you have next to this perceptual construction system and the motivational cybernetics, an agent that is paying attention to what it should select at any given moment to maximize reward."}, {"time": 4164, "text": "And this scanning system, this attention agent, is required for consciousness and consciousness is its control model."}, {"time": 4172, "text": "So it's the index memories that this thing retains when it manipulates the perceptual representations to maximize the value and minimize the conflicts and to increase coherence."}, {"time": 4184, "text": "So the purpose of consciousness is to create coherence in your perceptual representations, remove conflicts, predict the future, construct counterfactual representations so you can coordinate your actions and so on."}, {"time": 4197, "text": "And in order to do this, it needs to form memories."}, {"time": 4200, "text": "These memories are partial binding states of the working memory contents that are being revisited later on to backtrack, to undo certain states, to look for alternatives."}, {"time": 4210, "text": "And these index memories that you can recall, that is what you perceive as your stream of consciousness."}, {"time": 4215, "text": "And being able to recall these memories, this is what makes you conscious."}, {"time": 4219, "text": "If you could not remember what you paid attention to, you wouldn't be conscious."}, {"time": 4226, "text": "So consciousness is the index in the memory database."}, {"time": 4231, "text": "But let me sneak up to the questions of consciousness a little further."}, {"time": 4237, "text": "So we usually relate suffering to consciousness."}, {"time": 4242, "text": "So the capacity to suffer."}, {"time": 4246, "text": "I think to me, that's a really strong sign of consciousness is a thing that can suffer."}, {"time": 4252, "text": "How is that useful?"}, {"time": 4255, "text": "Suffering."}, {"time": 4257, "text": "And like in your model where you just described, which is indexing of memories and what is the coherence with the perception, with this predictive thing that's going on in the perception, how does suffering relate to any of that?"}, {"time": 4273, "text": "The higher level suffering that humans do."}, {"time": 4276, "text": "Basically pain is a reinforcement signal."}, {"time": 4280, "text": "Pain is a signal that one part of your brain sends to another part of your brain, or in an abstract sense, part of your mind sends to another part of the mind to regulate its behavior, to tell it the behavior that you're currently exhibiting should be improved."}, {"time": 4294, "text": "And this is the signal that I tell you to move away from what you're currently doing and push into a different direction."}, {"time": 4302, "text": "So pain gives you a part of you an impulse to do something differently."}, {"time": 4307, "text": "But sometimes this doesn't work because the training part of your brain is talking to the wrong region, or because it has the wrong model of the relationships in the world."}, {"time": 4317, "text": "Maybe you're mismodeling yourself or you're mismodeling the relationship of yourself to the world, or you're mismodeling the dynamics of the world."}, {"time": 4323, "text": "So you're trying to improve something that cannot be improved by generating more pain."}, {"time": 4327, "text": "But the system doesn't have any alternative."}, {"time": 4330, "text": "So it doesn't get better."}, {"time": 4332, "text": "What do you do if something doesn't get better and you want it to get better?"}, {"time": 4335, "text": "You increase the strengths of the signal."}, {"time": 4337, "text": "And then the signal becomes chronic when it becomes permanent without a change inside."}, {"time": 4342, "text": "This is what we call suffering."}, {"time": 4344, "text": "And the purpose of consciousness is to deal with contradictions, with things that cannot be resolved."}, {"time": 4350, "text": "The purpose of consciousness, I think is similar to a conductor in an orchestra."}, {"time": 4355, "text": "When everything works well, the orchestra doesn't need much of a conductor as long as it's coherent."}, {"time": 4360, "text": "But when there is a lack of coherence or something is consistently producing disharmony and mismatches, then the conductor becomes alert and interacts with it."}, {"time": 4368, "text": "So suffering attracts the activity of our consciousness."}, {"time": 4372, "text": "And the purpose of that is ideally that we bring new layers online, new layers of modeling that are able to create a model of the dysregulation so we can deal with it."}, {"time": 4384, "text": "And this means that we typically get higher level consciousness, so to speak, right?"}, {"time": 4388, "text": "We get some consciousness above our pay grade maybe if we have some suffering early in our life."}, {"time": 4393, "text": "Most of the interesting people had trauma early on in their childhood."}, {"time": 4397, "text": "And trauma means that you are suffering an injury for which the system is not prepared, which it cannot deal with, which it cannot insulate itself from."}, {"time": 4406, "text": "So something breaks."}, {"time": 4407, "text": "And this means that the behavior of the system is permanently disturbed in a way that some mismatch exists now in the regulation that just by following your impulses, by following the pain in the direction where it hurts, the situation doesn't improve but get worse."}, {"time": 4424, "text": "And so what needs to happen is that you grow up."}, {"time": 4427, "text": "And that's part that has grown up is able to deal with the part that is stuck in this earlier phase."}, {"time": 4433, "text": "Yeah, so at least to grow, so you're adding extra layers to your cognition."}, {"time": 4438, "text": "And let me ask you then, because I gotta stick on suffering, the ethics of the whole thing."}, {"time": 4445, "text": "So not our consciousness, but the consciousness of others."}, {"time": 4448, "text": "You've tweeted, one of my biggest fears is that insects could be conscious."}, {"time": 4456, "text": "The amount of suffering on earth would be unthinkable."}, {"time": 4460, "text": "So when we think of other conscious beings, is suffering a property of consciousness that we're most concerned about?"}, {"time": 4472, "text": "So I'm still thinking about robots, how to make sense of other nonhuman things that appear to have the depth of experience that humans have."}, {"time": 4490, "text": "And to me, that means consciousness and the darkest side of that, which is suffering, the capacity to suffer."}, {"time": 4500, "text": "And so I started thinking, how much responsibility do we have for those other conscious beings?"}, {"time": 4506, "text": "That's where the definition of consciousness becomes most urgent."}, {"time": 4513, "text": "Like having to come up with a definition of consciousness becomes most urgent, is who should we and should we not be torturing?"}, {"time": 4524, "text": "There's no general answer to this."}, {"time": 4526, "text": "Was Genghis Khan doing anything wrong?"}, {"time": 4529, "text": "It depends right on how you look at it."}, {"time": 4531, "text": "Well, he drew a line somewhere where this is us and that's them."}, {"time": 4538, "text": "It's the circle of empathy."}, {"time": 4540, "text": "It's like these, you don't have to use the word consciousness, but these are the things that matter to me if they suffer or not."}, {"time": 4550, "text": "And these are the things that don't matter to him."}, {"time": 4552, "text": "Yeah, but when one of his commanders failed him, he broke his spine and let him die in a horrible way."}, {"time": 4559, "text": "And so in some sense, I think he was indifferent to suffering or he was not different in the sense that he didn't see it as useful if he inflicted suffering, but he did not see it as something that had to be avoided."}, {"time": 4574, "text": "That was not the goal."}, {"time": 4575, "text": "The question was, how can I use suffering and the infliction of suffering to reach my goals from his perspective?"}, {"time": 4584, "text": "So like different societies throughout history put different value on the..."}, {"time": 4589, "text": "Different individuals, different psyches."}, {"time": 4591, "text": "But also even the objective of avoiding suffering, like some societies probably, I mean, this is where like religious belief really helps that afterlife, that it doesn't matter that you suffer or die, what matters is you suffer honorably, right?"}, {"time": 4609, "text": "So that you enter the afterlife as a hero."}, {"time": 4612, "text": "It seems to be superstitious to me, basically beliefs that assert things for which no evidence exists are incompatible with sound epistemology."}, {"time": 4622, "text": "And I don't think that religion has to be superstitious, otherwise it should be condemned in all cases."}, {"time": 4626, "text": "You're somebody who's saying we live in a dream world, we have zero evidence for anything."}, {"time": 4631, "text": "So... That's not the case."}, {"time": 4633, "text": "There are limits to what languages can be constructed."}, {"time": 4636, "text": "Mathematics brings solid evidence for its own structure."}, {"time": 4639, "text": "And once we have some idea of what languages exist and how a system can learn and what learning itself is in the first place."}, {"time": 4646, "text": "And so we can begin to realize that our intuitions that we are able to learn about the regularities of the world and minimize surprise and understand the nature of our own agency to some degree of abstraction."}, {"time": 4662, "text": "So it's a useful approximation."}, {"time": 4664, "text": "Just because we live in a dream world doesn't mean mathematics can't give us a consistent glimpse of physical, of objective reality."}, {"time": 4674, "text": "We can basically distinguish useful encodings from useless encodings."}, {"time": 4678, "text": "And when we apply our truth seeking to the world, we know we usually cannot find out whether a certain thing is true."}, {"time": 4687, "text": "What we typically do is we take the state vector of the universe separated into separate objects that interact with each other through interfaces."}, {"time": 4694, "text": "And this distinction that we are making is not completely arbitrary."}, {"time": 4697, "text": "It's done to optimize the compression that we can apply to our models of the universe."}, {"time": 4703, "text": "So we can predict what's happening with our limited resources."}, {"time": 4707, "text": "In this sense, it's not arbitrary."}, {"time": 4709, "text": "But the separation of the world into objects that are somehow discrete and interacting with each other is not the true reality, right?"}, {"time": 4716, "text": "The boundaries between the objects are projected into the world, not arbitrarily projected."}, {"time": 4721, "text": "But still, it's only an approximation of what's actually the case."}, {"time": 4726, "text": "And we sometimes notice that we run into contradictions when we try to understand high level things like economic aspects of the world and so on, or political aspects, or psychological aspects where we make simplifications."}, {"time": 4738, "text": "And the objects that we are using to separate the world are just one of many possible projections of what's going on."}, {"time": 4744, "text": "So it's not, in this postmodernist sense, completely arbitrary, and you're free to pick what you want or dismiss what you don't like because it's all stories."}, {"time": 4753, "text": "You have to show for every model of how well it predicts the world."}, {"time": 4757, "text": "So the confidence that you should have in the entities of your models should correspond to the evidence that you have."}, {"time": 4764, "text": "Can I ask you on a small tangent to talk about your favorite set of ideas and people, which is postmodernism."}, {"time": 4777, "text": "What is postmodernism?"}, {"time": 4779, "text": "How would you define it?"}, {"time": 4780, "text": "And why to you is it not a useful framework of thought?"}, {"time": 4788, "text": "Postmodernism is something that I'm really not an expert on."}, {"time": 4792, "text": "And postmodernism is a set of philosophical ideas that is difficult to lump together, that is characterized by some useful thinkers, some of them poststructuralists and so on."}, {"time": 4804, "text": "And I'm mostly not interested in it because I think that it's not leading me anywhere that I find particularly useful."}, {"time": 4811, "text": "It's mostly, I think, born out of the insight that the ontologies that we impose on the world are not literally true."}, {"time": 4818, "text": "And that we can often get to a different interpretation by the world by using a different ontology that is different separation of the world into interacting objects."}, {"time": 4826, "text": "But the idea that this makes the world a set of stories that are arbitrary, I think, is wrong."}, {"time": 4833, "text": "And the people that are engaging in this type of philosophy are working in an area that I largely don't find productive."}, {"time": 4840, "text": "There's nothing useful coming out of this."}, {"time": 4843, "text": "So this idea that truth is relative is not something that has, in some sense, informed physics or theory of relativity."}, {"time": 4849, "text": "And there is no feedback between those."}, {"time": 4851, "text": "There is no meaningful information of this type of philosophy on the sciences or on engineering or in politics."}, {"time": 4859, "text": "But there is a very strong information on ideology because it basically has become an ideology that is justifying itself by the notion that truth is a relative concept."}, {"time": 4873, "text": "And it's not being used in such a way that the philosophers or sociologists that take up these ideas say, oh, I should doubt my own ideas because maybe my separation of the world into objects is not completely valid."}, {"time": 4885, "text": "And I should maybe use a different one and be open to a pluralism of ideas."}, {"time": 4890, "text": "But it mostly exists to dismiss the ideas of other people."}, {"time": 4894, "text": "It becomes, yeah, it becomes a political weapon of sorts to achieve power."}, {"time": 4899, "text": "Basically, there's nothing wrong, I think, with developing a philosophy around this."}, {"time": 4906, "text": "But to develop a philosophy around this, to develop norms around the idea that truth is something that is completely negotiable, is incompatible with the scientific project."}, {"time": 4917, "text": "And I think if the academia has no defense against the ideological parts of the postmodernist movement, it's doomed."}, {"time": 4927, "text": "Right, you have to acknowledge the ideological part of any movement, actually, including postmodernism."}, {"time": 4935, "text": "Well, the question is what an ideology is."}, {"time": 4937, "text": "And to me, an ideology is basically a viral memeplex that is changing your mind in such a way that reality gets warped."}, {"time": 4945, "text": "It gets warped in such a way that you're being cut off from the rest of human thought space."}, {"time": 4949, "text": "And you cannot consider things outside of the range of ideas of your own ideology as possibly true."}, {"time": 4955, "text": "Right, so, I mean, there's certain properties to an ideology that make it harmful."}, {"time": 4959, "text": "One of them is that dogmatism of just certainty, dogged certainty in that you're right, you have the truth, and nobody else does."}, {"time": 4968, "text": "Yeah, but what is creating the certainty?"}, {"time": 4970, "text": "It's very interesting to look at the type of model that is being produced."}, {"time": 4974, "text": "Is it basically just a strong prior, and you tell people, oh, this idea that you consider to be very true, the evidence for this is actually just much weaker than you thought, and look, here are some studies."}, {"time": 4984, "text": "No, this is not how it works."}, {"time": 4986, "text": "It's usually normative, which means some thoughts are unthinkable because they would change your identity into something that is no longer acceptable."}, {"time": 4997, "text": "And this cuts you off from considering an alternative."}, {"time": 5000, "text": "And many de facto religions use this trick to lock people into a certain mode of thought, and this removes agency over your own thoughts."}, {"time": 5007, "text": "And it's very ugly to me."}, {"time": 5008, "text": "It's basically not just a process of domestication, but it's actually an intellectual castration that happens."}, {"time": 5016, "text": "It's an inability to think creatively and to bring forth new thoughts."}, {"time": 5020, "text": "I can ask you about substances, chemical substances that affect the video game, the dream world."}, {"time": 5033, "text": "So psychedelics that increasingly have been getting a lot of research done on them."}, {"time": 5038, "text": "So in general, psychedelics, psilocybin, MDMA, but also a really interesting one, the big one, which is DMT."}, {"time": 5046, "text": "What and where are the places that these substances take the mind that is operating in the dream world?"}, {"time": 5056, "text": "Do you have an interesting sense how this throws a wrinkle into the prediction model?"}, {"time": 5062, "text": "Is it just some weird little quirk or is there some fundamental expansion of the mind going on?"}, {"time": 5071, "text": "I suspect that a way to look at psychedelics is that they induce particular types of lucid dreaming states."}, {"time": 5078, "text": "So it's a state in which certain connections are being severed in your mind."}, {"time": 5083, "text": "They're no longer active."}, {"time": 5085, "text": "Your mind basically gets free to move in a certain direction because some inhibition, some particular inhibition doesn't work anymore."}, {"time": 5092, "text": "And as a result, you might stop having a self or you might stop perceiving the world as three dimensional."}, {"time": 5100, "text": "And you can explore that state."}, {"time": 5104, "text": "And I suppose that for every state that can be induced with psychedelics, there are people that are naturally in that state."}, {"time": 5110, "text": "So sometimes psychedelics to shift you through a range of possible mental states."}, {"time": 5115, "text": "And they can also shift you out of the range of permissible mental states that is where you can make predictive models of reality."}, {"time": 5122, "text": "And what I observe in people that use psychedelics a lot is that they tend to be overfitting."}, {"time": 5129, "text": "Overfitting means that you are using more bits for modeling the dynamics of a function than you should."}, {"time": 5138, "text": "And so you can fit your curve to extremely detailed things in the past, but this model is no longer predictive for the future."}, {"time": 5145, "text": "What is it about psychedelics that forces that?"}, {"time": 5149, "text": "I thought it would be the opposite."}, {"time": 5151, "text": "I thought that it's a good mechanism for generalization, for regularization."}, {"time": 5159, "text": "So it feels like psychedelics expansion of the mind, like taking you outside of, like forcing your model to be non predictive is a good thing."}, {"time": 5171, "text": "Meaning like, it's almost like, okay, what I would say psychedelics are akin to is traveling to a totally different environment."}, {"time": 5179, "text": "Like going, if you've never been to like India or something like that from the United States, very different set of people, different culture, different food, different roads and values and all those kinds of things."}, {"time": 5191, "text": "Yeah, so psychedelics can, for instance, teleport people into a universe that is hyperbolic, which means that if you imagine a room that you're in, you can turn around 360 degrees and you didn't go full circle."}, {"time": 5204, "text": "You need to go 720 degrees to go full circle."}, {"time": 5208, "text": "So the things that people learn in that state cannot be easily transferred in this universe that we are in."}, {"time": 5214, "text": "It could be that if they're able to abstract and understand what happened to them, that they understand that some part of their spatial cognition has been desynchronized and has found a different synchronization."}, {"time": 5225, "text": "And this different synchronization happens to be a hyperbolic one, right?"}, {"time": 5228, "text": "So you learn something interesting about your brain."}, {"time": 5230, "text": "It's difficult to understand what exactly happened, but we get a pretty good idea once we understand how the brain is representing geometry."}, {"time": 5237, "text": "Yeah, but doesn't it give you a fresh perspective on the physical reality?"}, {"time": 5246, "text": "Who's making that sound?"}, {"time": 5247, "text": "Is it inside my head or is it external?"}, {"time": 5250, "text": "Well, there is no sound outside of your mind, but it's making sense of phenomenon physics."}, {"time": 5259, "text": "Yeah, in the physical reality, there's sound waves traveling through air."}, {"time": 5267, "text": "That's our model of what happened."}, {"time": 5268, "text": "That's our model of what happened, right."}, {"time": 5273, "text": "Doesn't Psychedelics give you a fresh perspective on this physical reality?"}, {"time": 5279, "text": "Like, not this physical reality, but this more... What do you call the dream world that's mapped directly to..."}, {"time": 5289, "text": "The purpose of dreaming at night, I think, is data augmentation."}, {"time": 5294, "text": "So that's very different."}, {"time": 5296, "text": "That's very similar to Psychedelics."}, {"time": 5298, "text": "It's changed parameters about the things that you have learned."}, {"time": 5301, "text": "And, for instance, when you are young, you have seen things from certain perspectives, but not from others."}, {"time": 5307, "text": "So your brain is generating new perspectives of objects that you already know, which means you can learn to recognize them later from different perspectives."}, {"time": 5315, "text": "And I suspect that's the reason that many of us remember to have flying dreams as children, because it's just different perspectives of the world that you already know, and that it starts to generate these different perspective changes, and then it fluidly turns this into a flying dream to make sense of what's happening, right?"}, {"time": 5332, "text": "So you fill in the gaps, and suddenly you see yourself flying."}, {"time": 5335, "text": "And similar things can happen with semantic relationships."}, {"time": 5338, "text": "So it's not just spatial relationships, but it can also be the relationships between ideas that are being changed."}, {"time": 5345, "text": "And it seems that the mechanisms that make that happen during dreaming are interacting with these same receptors that are being stimulated by psychedelics."}, {"time": 5357, "text": "So I suspect that there is a thing that I haven't read really about."}, {"time": 5362, "text": "The way in which dreams are induced in the brain is not just that the activity of the brain gets tuned down because your eyes are closed and you no longer get enough data from your eyes, but there is a particular type of neurotransmitter that is saturating your brain during these phases, during the REM phases, and you produce controlled hallucinations."}, {"time": 5384, "text": "And psychedelics are linking into these mechanisms, I suspect."}, {"time": 5389, "text": "So isn't that another trickier form of data augmentation?"}, {"time": 5394, "text": "Yes, but it's also data augmentation that can happen outside of the specification that your brain is tuned to."}, {"time": 5400, "text": "So basically people are overclocking their brains and that produces states that are subjectively extremely interesting."}, {"time": 5409, "text": "Yeah, I just."}, {"time": 5410, "text": "But from the outside, very suspicious."}, {"time": 5412, "text": "So I think I'm over applying the metaphor of a neural network in my own mind, which I just think that doesn't lead to overfitting, right?"}, {"time": 5422, "text": "But you were just sort of anecdotally saying my experiences with people that have done psychedelics are that kind of quality."}, {"time": 5430, "text": "I think it typically happens."}, {"time": 5431, "text": "So if you look at people like Timothy Leary, and he has written beautiful manifestos about the effect of LSD on people."}, {"time": 5440, "text": "He genuinely believed, he writes in these manifestos, that in the future, science and art will only be done on psychedelics because it's so much more efficient and so much better."}, {"time": 5449, "text": "And he gave LSD to children in this community of a few thousand people that he had near San Francisco."}, {"time": 5455, "text": "And basically he was losing touch with reality."}, {"time": 5460, "text": "He did not understand the effects that the things that he was doing would have on the reception of psychedelics by society because he was unable to think critically about what happened."}, {"time": 5470, "text": "What happened was that he got in a euphoric state, that euphoric state happened because he was overfitting."}, {"time": 5476, "text": "He was taking this sense of euphoria and translating it into a model of actual success in the world, right?"}, {"time": 5483, "text": "He was feeling better."}, {"time": 5485, "text": "Limitations had disappeared, that he experienced to be existing, but he didn't get superpowers."}, {"time": 5490, "text": "I understand what you mean by overfitting now."}, {"time": 5493, "text": "There's a lot of interpretation to the term overfitting in this case, but I got you."}, {"time": 5498, "text": "So he was getting positive rewards from a lot of actions that he shouldn't have been doing."}, {"time": 5504, "text": "Yeah, but not just this."}, {"time": 5505, "text": "So if you take, for instance, John Lilly, who was studying dolphin languages and aliens and so on, a lot of people that use psychedelics became very loopy."}, {"time": 5515, "text": "And the typical thing that you notice when people are on psychedelics is that they are in a state where they feel that everything can be explained now."}, {"time": 5523, "text": "Everything is clear, everything is obvious."}, {"time": 5526, "text": "And sometimes they have indeed discovered a useful connection, but not always."}, {"time": 5532, "text": "Very often these connections are overinterpretations."}, {"time": 5535, "text": "I wonder, you know, there's a question of correlation versus causation."}, {"time": 5541, "text": "And also I wonder if it's the psychedelics or if it's more the social, like being the outsider and having a strong community of outside and having a leadership position in an outsider cult like community that could have a much stronger effect of overfitting than do psychedelics themselves, the actual substances, because it's a counterculture thing."}, {"time": 5563, "text": "So it could be that as opposed to the actual substance."}, {"time": 5566, "text": "If you're a boring person who wears a suit and tie and works at a bank and takes psychedelics, that could be a very different effect of psychedelics on your mind."}, {"time": 5577, "text": "I'm just sort of raising the point that the people you referenced are already weirdos."}, {"time": 5584, "text": "No, not necessarily."}, {"time": 5585, "text": "A lot of the people that tell me that they use psychedelics in a useful way started out as squares and were liberating themselves because they were stuck."}, {"time": 5596, "text": "They were basically stuck in local optimum of their own self model, of their relationship to the world."}, {"time": 5600, "text": "And suddenly they had data augmentation."}, {"time": 5603, "text": "They basically saw and experienced a space of possibilities."}, {"time": 5606, "text": "They experienced what it would be like to be another person."}, {"time": 5609, "text": "And they took important lessons from that experience back home."}, {"time": 5616, "text": "Yeah, I mean, I love the metaphor of data augmentation because that's been the primary driver of self supervised learning in the computer vision domain is data augmentation."}, {"time": 5630, "text": "So it's funny to think of data augmentation, like chemically induced data augmentation in the human mind."}, {"time": 5638, "text": "There's also a very interesting effect that I noticed."}, {"time": 5642, "text": "I know several people who are sphere to me that LSD has cured their migraines."}, {"time": 5649, "text": "So severe cluster headaches or migraines that didn't respond to standard medication that disappeared after a single dose."}, {"time": 5658, "text": "And I don't recommend anybody doing this, especially not in the US where it's illegal."}, {"time": 5663, "text": "And there are no studies on this for that reason."}, {"time": 5666, "text": "But it seems that anecdotally that it basically can reset the serotonergic system."}, {"time": 5673, "text": "So it's basically pushing them outside of their normal boundaries."}, {"time": 5678, "text": "And as a result, it needs to find a new equilibrium."}, {"time": 5681, "text": "And in some people that equilibrium is better, but it also follows that in other people it might be worse."}, {"time": 5686, "text": "So if you have a brain that is already teetering on the boundary to psychosis, it can be permanently pushed over that boundary."}, {"time": 5694, "text": "Well, that's why you have to do good science, which they're starting to do on all these different substances of how well it actually works for the different conditions like MDMA seems to help with PTSD, same with psilocybin."}, {"time": 5705, "text": "You need to do good science, meaning large studies of large N. Yeah, so based on the existing studies of MDMA, it seems that if you look at Rick Doblin's work and what he has published about this and talks about, MDMA seems to be a psychologically relatively safe drug."}, {"time": 5724, "text": "But it's physiologically not very safe."}, {"time": 5726, "text": "That is, there is neurotoxicity if you would use a too large dose."}, {"time": 5731, "text": "And if you combine this with alcohol, which a lot of kids do in party settings during raves and so on, it's very hepatotoxic."}, {"time": 5740, "text": "So basically you can kill your liver."}, {"time": 5742, "text": "And this means that it's probably something that is best and most productively used in a clinical setting by people who really know what they're doing."}, {"time": 5750, "text": "And I suspect that's also true for the other psychedelics that is while the other psychedelics are probably not as toxic as say alcohol, the effects on the psyche can be much more profound and lasting."}, {"time": 5763, "text": "Yeah, well, as far as I know psilocybin, so mushrooms, magic mushrooms, as far as I know in terms of the studies they're running, I think have no, like they're allowed to do what they're calling heroic doses."}, {"time": 5777, "text": "So that one does not have a toxicity."}, {"time": 5778, "text": "So they could do like huge doses in a clinical setting when they're doing study on psilocybin, which is kind of fun."}, {"time": 5785, "text": "Yeah, it seems that most of the psychedelics work in extremely small doses, which means that the effect on the rest of the body is relatively low."}, {"time": 5793, "text": "And MDMA is probably the exception."}, {"time": 5796, "text": "Maybe ketamine can be dangerous in larger doses because it can depress breathing and so on."}, {"time": 5801, "text": "But the LSD and psilocybin work in very, very small doses, at least the active part of them, of psilocybin LSD is only the active part."}, {"time": 5810, "text": "And the, but the effect that it can have on your mental wiring can be very dangerous, I think."}, {"time": 5817, "text": "Let's talk about AI a little bit."}, {"time": 5820, "text": "What are your thoughts about GPT3 and language models trained with self supervised learning?"}, {"time": 5829, "text": "It came out quite a bit ago, but I wanted to get your thoughts on it."}, {"time": 5834, "text": "In the nineties, I was in New Zealand and I had an amazing professor, Ian Witten, who realized I was bored in class and put me in his lab."}, {"time": 5845, "text": "And he gave me the task to discover grammatical structure in an unknown language."}, {"time": 5851, "text": "And the unknown language that I picked was English because it was the easiest one to find a corpus for construct one."}, {"time": 5857, "text": "And he gave me the largest computer at the whole university."}, {"time": 5861, "text": "It had two gigabytes of RAM, which was amazing."}, {"time": 5864, "text": "And I wrote everything in C with some in memory compression to do statistics over the language."}, {"time": 5869, "text": "And I first would create a dictionary of all the words, which basically tokenizes everything and compresses things so that I don't need to store the whole word, but just a code for every word."}, {"time": 5882, "text": "And then I was taking this all apart in sentences and I was trying to find all the relationships between all the words in the sentences and do statistics over them."}, {"time": 5892, "text": "And that proved to be impossible because the complexity is just too large."}, {"time": 5898, "text": "So if you want to discover the relationship between an article and a noun, and there are three adjectives in between, you cannot do ngram statistics and look at all the possibilities that can exist, at least not with the resources that we had back then."}, {"time": 5910, "text": "So I realized I need to make some statistics over what I need to make statistics over."}, {"time": 5915, "text": "So I wrote something that was pretty much a hack that did this for at least first order relationships."}, {"time": 5922, "text": "And I came up with some kind of mutual information graph that was indeed discovering something that looks exactly like the grammatical structure of the sentence, just by trying to encode the sentence in such a way that the words would be written in the optimal order inside of the model."}, {"time": 5938, "text": "And what I also found is that if we would be able to increase the resolution of that and not just use this model to reproduce grammatically correct sentences, we would also be able to correct stylistically correct sentences by just having more bits in these relationships."}, {"time": 5954, "text": "And if we wanted to have meaning, we would have to go much higher order."}, {"time": 5958, "text": "And I didn't know how to make higher order models back then without spending way more years in research on how to make the statistics over what we need to make statistics over."}, {"time": 5968, "text": "And this thing that we cannot look at the relationships between all the bits in your input is being solved in different domains in different ways."}, {"time": 5975, "text": "So in computer graphics, computer vision, standard methods for many years now is convolutional neural networks."}, {"time": 5983, "text": "Convolutional neural networks are hierarchies of filters that exploit the fact that neighboring pixels in images are usually semantically related and distance pixels in images are usually not semantically related."}, {"time": 5995, "text": "So you can just by grouping the pixels that are next to each other, hierarchically together reconstruct the shape of objects."}, {"time": 6002, "text": "And this is an important prior that we built into these models so they can converge quickly."}, {"time": 6008, "text": "But this doesn't work in language for the reason that adjacent words are often but not always related and distant words are sometimes related while the words in between are not."}, {"time": 6019, "text": "So how can you learn the topology of language?"}, {"time": 6022, "text": "And I think for this reason that this difficulty existed, the transformer was invented in natural language processing, not in vision."}, {"time": 6032, "text": "And what the transformer is doing, it's a hierarchy of layers where every layer learns what to pay attention to in the given context in the previous layer."}, {"time": 6043, "text": "So what to make the statistics over."}, {"time": 6046, "text": "And the context is significantly larger than the adjacent word."}, {"time": 6051, "text": "Yes, so the context that GPT3 has been using, the transformer itself is from 2017 and it wasn't using that large of a context."}, {"time": 6062, "text": "OpenAI has basically scaled up this idea as far as they could at the time."}, {"time": 6066, "text": "And the context is about 2048 symbols, tokens in the language."}, {"time": 6072, "text": "These symbols are not characters, but they take the words and project them into a vector space where words that are statistically co occurring a lot are neighbors already."}, {"time": 6083, "text": "So it's already a simplification of the problem a little bit."}, {"time": 6086, "text": "And so every word is basically a set of coordinates in a high dimensional space."}, {"time": 6091, "text": "And then they use some kind of trick to also encode the order of the words in a sentence or in the not just sentence, but 2048 tokens is about a couple of pages of text or two and a half pages of text."}, {"time": 6103, "text": "And so they managed to do pretty exhaustive statistics over the potential relationships between two pages of text, which is tremendous."}, {"time": 6111, "text": "I was just using a single sentence back then."}, {"time": 6115, "text": "And I was only looking for first order relationships."}, {"time": 6118, "text": "And they were really looking for much, much higher level relationships."}, {"time": 6150, "text": "So the results that GPT3 got, I think were amazing."}, {"time": 6154, "text": "By the way, I actually didn't check carefully."}, {"time": 6158, "text": "It's funny you just mentioned how you coupled semantics to the multiplication."}, {"time": 6162, "text": "Is it able to do some basic math on two digit numbers?"}, {"time": 6168, "text": "I thought there's a lot of failure cases."}, {"time": 6173, "text": "Yeah, it basically fails if you take larger digit numbers."}, {"time": 6176, "text": "So four digit numbers and so on makes carrying mistakes and so on."}, {"time": 6180, "text": "And if you take larger numbers, you don't get useful results at all."}, {"time": 6184, "text": "And this could be an issue of the training set where there are not many examples of successful long form addition and standard human written text."}, {"time": 6195, "text": "And humans aren't very good at doing three digit numbers either."}, {"time": 6199, "text": "Yeah, you're not writing a lot about it."}, {"time": 6202, "text": "And the other thing is that the loss function that is being used is only minimizing surprise."}, {"time": 6207, "text": "So it's predicting what comes next in the typical text."}, {"time": 6209, "text": "It's not trying to go for causal closure first as we do."}, {"time": 6215, "text": "But the fact that that kind of prediction works to generate text that's semantically rich and consistent is interesting."}, {"time": 6225, "text": "So yeah, so it's amazing that it's able to generate semantically consistent text."}, {"time": 6230, "text": "It's not consistent."}, {"time": 6231, "text": "So the problem is that it loses coherence at some point, but it's also, I think, not correct to say that GPT3 is unable to deal with semantics at all because you ask it to perform certain transformations in text and it performs these transformation in text."}, {"time": 6247, "text": "And the kind of additions that it's able to perform are transformations in text, right?"}, {"time": 6252, "text": "And there are proper semantics involved."}, {"time": 6255, "text": "You can also do more."}, {"time": 6256, "text": "There was a paper that was generating lots and lots of mathematically correct text and was feeding this into a transformer."}, {"time": 6266, "text": "And as a result, it was able to learn how to do differentiation integration in race that according to the authors, Mathematica could not."}, {"time": 6277, "text": "To which some of the people in Mathematica responded that they were not using Mathematica in the right way and so on."}, {"time": 6283, "text": "I have not really followed the resolution of this conflict."}, {"time": 6286, "text": "This part, as a small tangent, I really don't like in machine learning papers, which they often do anecdotal evidence."}, {"time": 6296, "text": "They'll find like one example in some kind of specific use of Mathematica and demonstrate, look, here's, they'll show successes and failures, but they won't have a very clear representation of how many cases this actually represents."}, {"time": 6309, "text": "Yes, but I think as a first paper, this is a pretty good start."}, {"time": 6312, "text": "And so the take home message, I think, is that the authors could get better results from this in their experiments than they could get from the vein, which they were using computer algebra systems, which means that was not nothing."}, {"time": 6329, "text": "And it's able to perform substantially better than GPT's V can based on a much larger amount of training data using the same underlying algorithm."}, {"time": 6338, "text": "Well, let me ask, again, so I'm using your tweets as if this is like Plato, right?"}, {"time": 6347, "text": "As if this is well thought out novels that you've written."}, {"time": 6351, "text": "You tweeted, GPT4 is listening to us now."}, {"time": 6358, "text": "This is one way of asking, what are the limitations of GPT3 when it scales?"}, {"time": 6364, "text": "So what do you think will be the capabilities of GPT4, GPT5, and so on?"}, {"time": 6370, "text": "What are the limits of this approach?"}, {"time": 6371, "text": "So obviously when we are writing things right now, everything that we are writing now is going to be training data for the next generation of machine learning models."}, {"time": 6380, "text": "So yes, of course, GPT4 is listening to us."}, {"time": 6383, "text": "And I think the tweet is already a little bit older and we now have Voodao and we have a number of other systems that basically are placeholders for GPT4."}, {"time": 6393, "text": "Don't know what open AIS plans are in this regard."}, {"time": 6395, "text": "I read that tweet in several ways."}, {"time": 6399, "text": "So one is obviously everything you put on the internet is used as training data."}, {"time": 6404, "text": "But in a second way I read it is in a, we talked about agency."}, {"time": 6411, "text": "I read it as almost like GPT4 is intelligent enough to be choosing to listen."}, {"time": 6418, "text": "So not only like did a programmer tell it to collect this data and use it for training, I almost saw the humorous angle, which is like it has achieved AGI kind of thing."}, {"time": 6429, "text": "Well, the thing is, could we be already be living in GPT5?"}, {"time": 6433, "text": "So GPT4 is listening and GPT5 actually constructing the entirety of the reality where we... Of course, in some sense, what everybody is trying to do right now in AI is to extend the transformer to be able to deal with video."}, {"time": 6448, "text": "And there are very promising extensions, right?"}, {"time": 6451, "text": "There's a work by Google that is called Perceiver and that is overcoming some of the limitations of the transformer by letting it learn the topology of the different modalities separately."}, {"time": 6464, "text": "And by training it to find better input features."}, {"time": 6470, "text": "So basically feature abstractions that are being used by this successor to GPT3 are chosen such a way that it's able to deal with video input."}, {"time": 6480, "text": "And there is more to be done."}, {"time": 6482, "text": "So one of the limitations of GPT3 is that it's amnesiac."}, {"time": 6487, "text": "So it forgets everything beyond the two pages that it currently reads also during generation, not just during learning."}, {"time": 6494, "text": "Do you think that's fixable within the space of deep learning?"}, {"time": 6498, "text": "Can you just make a bigger, bigger, bigger input?"}, {"time": 6501, "text": "No, I don't think that our own working memory is infinitely large."}, {"time": 6505, "text": "It's probably also just a few thousand bits."}, {"time": 6508, "text": "But what you can do is you can structure this working memory."}, {"time": 6511, "text": "So instead of just force feeding this thing, a certain thing that it has to focus on, and it's not allowed to focus on anything else as its network, you allow it to construct its own working memory as we do."}, {"time": 6524, "text": "When we are reading a book, it's not that we are focusing our attention in such a way that we can only remember the current page."}, {"time": 6532, "text": "We will also try to remember other pages and try to undo what we learned from them or modify what we learned from them."}, {"time": 6538, "text": "We might get up and take another book from the shelf."}, {"time": 6541, "text": "We might go out and ask somebody, we can edit our working memory in any way that is useful to put a context together that allows us to draw the right inferences and to learn the right things."}, {"time": 6553, "text": "So this ability to perform experiments on the world based on an attempt to become fully coherent and to achieve causal closure, to achieve a certain aesthetic of your modeling, that is something that eventually needs to be done."}, {"time": 6568, "text": "And at the moment we are skirting this in some sense by building systems that are larger and faster so they can use dramatically larger resources and human beings can do and much more training data to get to models that in some sense are already way superhuman and in other ways are laughingly incoherent."}, {"time": 6585, "text": "So do you think sort of making the systems like, what would you say, multi resolutional?"}, {"time": 6591, "text": "So like some of the language models are focused on two pages, some are focused on two books, some are focused on two years of reading, some are focused on a lifetime, so it's like stacks of GPT3s all the way down."}, {"time": 6611, "text": "You want to have gaps in between them."}, {"time": 6613, "text": "So it's not necessarily two years, there's no gaps."}, {"time": 6617, "text": "It's things out of two years or out of 20 years or 2,000 years or 2 billion years where you are just selecting those bits that are predicted to be the most useful ones to understand what you're currently doing."}, {"time": 6629, "text": "And this prediction itself requires a very complicated model and that's the actual model that you need to be making."}, {"time": 6634, "text": "It's not just that you are trying to understand the relationships between things, but what you need to make relationships, discover relationships over."}, {"time": 6642, "text": "I wonder what that thing looks like, what the architecture for the thing that's able to have that kind of model."}, {"time": 6650, "text": "I think it needs more degrees of freedom than the current models have."}, {"time": 6654, "text": "So it starts out with the fact that you possibly don't just want to have a feed forward model, but you want it to be fully recurrent."}, {"time": 6662, "text": "And to make it fully recurrent, you probably need to loop it back into itself and allow it to skip connections."}, {"time": 6668, "text": "Once you do this, when you're predicting the next frame and your internal next frame in every moment, and you are able to skip connection, it means that signals can travel from the output of the network into the middle of the network faster than the inputs do."}, {"time": 6685, "text": "Do you think it can still be differentiable?"}, {"time": 6688, "text": "Do you think it still can be a neural network?"}, {"time": 6690, "text": "Sometimes it can and sometimes it cannot."}, {"time": 6692, "text": "So it can still be a neural network, but not a fully differentiable one."}, {"time": 6697, "text": "And when you want to deal with non differentiable ones, you need to have an attention system that is discreet and two dimensional and can perform grammatical operations."}, {"time": 6706, "text": "You need to be able to perform program synthesis."}, {"time": 6709, "text": "You need to be able to backtrack in this operations that you perform on this thing."}, {"time": 6714, "text": "And this thing needs a model of what it's currently doing."}, {"time": 6716, "text": "And I think this is exactly the purpose of our own consciousness."}, {"time": 6721, "text": "Yeah, the program things are tricky on neural networks."}, {"time": 6725, "text": "So let me ask you, it's not quite program synthesis, but the application of these language models to generation, to program synthesis, but generation of programs."}, {"time": 6736, "text": "So if you look at GitHub OpenPilot, which is based on OpenAI's codecs, I don't know if you got a chance to look at it, but it's the system that's able to generate code once you prompt it with, what is it?"}, {"time": 6750, "text": "Like the header of a function with some comments."}, {"time": 6752, "text": "And it seems to do an incredibly good job or not a perfect job, which is very important, but an incredibly good job of generating functions."}, {"time": 6764, "text": "Are you, is this exciting or is this just a party trick, a demo?"}, {"time": 6768, "text": "Or is this revolutionary?"}, {"time": 6771, "text": "I haven't worked with it yet."}, {"time": 6772, "text": "So it's difficult for me to judge it, but I would not be surprised if it turns out to be a revolutionary."}, {"time": 6779, "text": "And that's because the majority of programming tasks that are being done in the industry right now are not creative."}, {"time": 6785, "text": "People are writing code that other people have written, or they're putting things together from code fragments that others have had."}, {"time": 6791, "text": "And a lot of the work that programmers do in practice is to figure out how to overcome the gaps in their current knowledge and the things that people have already done."}, {"time": 6800, "text": "How to copy and paste from Stack Overflow, that's right."}, {"time": 6804, "text": "And so of course we can automate that."}, {"time": 6806, "text": "Yeah, to make it much faster to copy and paste from Stack Overflow."}, {"time": 6810, "text": "Yes, but it's not just copying and pasting."}, {"time": 6812, "text": "It's also basically learning which parts you need to modify to make them fit together."}, {"time": 6818, "text": "Yeah, like literally sometimes as simple as just changing the variable names."}, {"time": 6823, "text": "So it fits into the rest of your code."}, {"time": 6825, "text": "Yes, but this requires that you understand the semantics of what you're doing to some degree."}, {"time": 6829, "text": "And you can automate some of those things."}, {"time": 6831, "text": "The thing that makes people nervous of course is that a little bit wrong in a program can have a dramatic effect on the actual final operation of that program."}, {"time": 6843, "text": "So that's one little error, which in the space of language doesn't really matter, but in the space of programs can matter a lot."}, {"time": 6851, "text": "Yes, but this is already what is happening when humans program code."}, {"time": 6855, "text": "Yeah, this is."}, {"time": 6856, "text": "So we have a technology to deal with this."}, {"time": 6860, "text": "Somehow it becomes scarier when you know that a program generated code that's running a nuclear power plant."}, {"time": 6867, "text": "It becomes scarier."}, {"time": 6869, "text": "You know, humans have errors too."}, {"time": 6872, "text": "But it's scarier when a program is doing it because why, why?"}, {"time": 6878, "text": "I mean, there's a fear that a program, like a program may not be as good as humans to know when stuff is important to not mess up."}, {"time": 6891, "text": "Like there's a misalignment of priorities of values that's potential."}, {"time": 6901, "text": "Maybe that's the source of the worry."}, {"time": 6903, "text": "I mean, okay, if I give you code generated by GitHub open pilot and code generated by a human and say here, use one of these, which how do you select today and in the next 10 years which code do you use?"}, {"time": 6921, "text": "Wouldn't you still be comfortable with the human?"}, {"time": 6925, "text": "At the moment when you go to Stanford to get an MRI, they will write a bill to the insurance over $20,000."}, {"time": 6934, "text": "And of this, maybe half of that gets paid by the insurance and a quarter gets paid by you."}, {"time": 6940, "text": "And the MRI cost them $600 to make maybe probably less."}, {"time": 6944, "text": "And what are the values of the person that writes the software and deploys this process?"}, {"time": 6951, "text": "It's very difficult for me to say whether I trust people."}, {"time": 6956, "text": "I think that what happens there is a mixture of proper Anglo Saxon Protestant values where somebody is trying to serve an abstract radar hole and organize crime."}, {"time": 6966, "text": "Well, that's a very harsh, I think that's a harsh view of humanity."}, {"time": 6975, "text": "There's a lot of bad people, whether incompetent or just malevolent in this world, yes."}, {"time": 6981, "text": "But it feels like the more malevolent, so the more damage you do to the world, the more resistance you have in your own human heart."}, {"time": 6994, "text": "Yeah, but don't explain with malevolence or stupidity what can be explained by just people acting on their incentives."}, {"time": 7001, "text": "Right, so what happens in Stanford is not that somebody is evil."}, {"time": 7005, "text": "It's just that they do what they're being paid for."}, {"time": 7008, "text": "No, it's not evil."}, {"time": 7010, "text": "That's, I tend to, no, I see that as malevolence."}, {"time": 7013, "text": "I see as I, even like being a good German, as I told you offline, is some, it's not absolute malevolence, but it's a small amount, it's cowardice."}, {"time": 7027, "text": "I mean, when you see there's something wrong with the world, it's either incompetence and you're not able to see it, or it's cowardice that you're not able to stand up, not necessarily in a big way, but in a small way."}, {"time": 7041, "text": "So I do think that is a bit of malevolence."}, {"time": 7045, "text": "I'm not sure the example you're describing is a good example of that."}, {"time": 7048, "text": "So the question is, what is it that you are aiming for?"}, {"time": 7051, "text": "And if you don't believe in the future, if you, for instance, think that the dollar is going to crash, why would you try to save dollars?"}, {"time": 7059, "text": "If you don't think that humanity will be around in a hundred years from now, because global warming will wipe out civilization, why would you need to act as if it were?"}, {"time": 7070, "text": "Right, so the question is, is there an overarching aesthetics that is projecting you and the world into the future, which I think is the basic idea of religion, that you understand the interactions that we have with each other as some kind of civilization level agent that is projecting itself into the future."}, {"time": 7087, "text": "If you don't have that shared purpose, what is there to be ethical for?"}, {"time": 7092, "text": "So I think when we talk about ethics and AI, we need to go beyond the insane bias discussions and so on, where people are just measuring the distance between a statistic to their preferred current world model."}, {"time": 7107, "text": "The optimism, wait, wait, wait, I was a little confused by the previous thing, just to clarify."}, {"time": 7112, "text": "There is a kind of underlying morality to having an optimism that human civilization will persist for longer than a hundred years."}, {"time": 7125, "text": "Like I think a lot of people believe that it's a good thing for us to keep living."}, {"time": 7134, "text": "And thriving."}, {"time": 7134, "text": "This morality itself is not an end to itself."}, {"time": 7136, "text": "It's instrumental to people living in a hundred years from now or 500 years from now."}, {"time": 7143, "text": "So it's only justifiable if you actually think that it will lead to people or increase the probability of people being around in that timeframe."}, {"time": 7152, "text": "And a lot of people don't actually believe that, at least not actively."}, {"time": 7156, "text": "But believe what exactly?"}, {"time": 7157, "text": "So I was..."}, {"time": 7159, "text": "Most people don't believe that they can afford to act on such a model."}, {"time": 7163, "text": "Basically what happens in the US is I think that the healthcare system is for a lot of people no longer sustainable, which means that if they need the help of the healthcare system, they're often not able to afford it."}, {"time": 7173, "text": "And when they cannot help it, they are often going bankrupt."}, {"time": 7177, "text": "I think the leading cause of personal bankruptcy in the US is the healthcare system."}, {"time": 7182, "text": "And that would not be necessary."}, {"time": 7184, "text": "It's not because people are consuming more and more medical services and are achieving a much, much longer life as a result."}, {"time": 7191, "text": "That's not actually the story that is happening because you can compare it to other countries."}, {"time": 7195, "text": "And life expectancy in the US is currently not increasing and it's not as high as in all the other industrialized countries."}, {"time": 7201, "text": "So some industrialized countries are doing better with a much cheaper healthcare system."}, {"time": 7206, "text": "And what you can see is for instance, administrative bloat."}, {"time": 7209, "text": "The healthcare system has maybe to some degree deliberately set up as a job placement program to allow people to continue living in middle class existence, despite not having useful use case in productivity."}, {"time": 7225, "text": "So they are being paid to push paper around."}, {"time": 7228, "text": "And the number of administrator in the healthcare system has been increasing much faster than the number of practitioners."}, {"time": 7235, "text": "And this is something that you have to pay for."}, {"time": 7237, "text": "And also the revenues that are being generated in the healthcare system are relatively large and somebody has to pay for them."}, {"time": 7243, "text": "And the result why they are so large is because market mechanisms are not working."}, {"time": 7248, "text": "The FDA is largely not protecting people from malpractice of healthcare providers."}, {"time": 7255, "text": "The FDA is protecting healthcare providers from competition."}, {"time": 7260, "text": "So this is a thing that has to do with values."}, {"time": 7263, "text": "And this is not because people are malicious on all levels."}, {"time": 7266, "text": "It's because they are not incentivized to act on a greater whole on this idea that you treat somebody who comes to you as a patient, like you would treat a family member."}, {"time": 7275, "text": "Yeah, but we're trying, I mean, you're highlighting a lot of the flaws of the different institutions, the systems we're operating under, but I think there's a continued throughout history mechanism design of trying to design incentives in such a way that these systems behave better and better and better."}, {"time": 7292, "text": "I mean, it's a very difficult thing to operate a society of hundreds of millions of people effectively with."}, {"time": 7299, "text": "Yes, so do we live in a society that is ever correcting?"}, {"time": 7302, "text": "Is this, do we observe that our models of what we are doing are predictive of the future and when they are not, we improve them."}, {"time": 7311, "text": "Are our laws adjudicated with clauses that you put into every law, what is meant to be achieved by that law and the law will be automatically repealed if it's not achieving that, right?"}, {"time": 7321, "text": "If you are optimizing your own laws, if you're writing your own source code, you probably make an estimate of what is this thing that's currently wrong in my life?"}, {"time": 7329, "text": "What is it that I should change about my own policies?"}, {"time": 7332, "text": "What is the expected outcome?"}, {"time": 7334, "text": "And if that outcome doesn't manifest, I will change the policy back, right?"}, {"time": 7338, "text": "Or I would change it to something different."}, {"time": 7340, "text": "Are we doing this on a societal level?"}, {"time": 7343, "text": "I think it's easy to sort of highlight the, I think we're doing it in the way that, like I operate my current life."}, {"time": 7350, "text": "I didn't sleep much last night."}, {"time": 7352, "text": "You would say that Lex, the way you need to operate your life is you need to always get sleep."}, {"time": 7357, "text": "The fact that you didn't sleep last night is totally the wrong way to operate in your life."}, {"time": 7363, "text": "Like you should have gotten all your shit done in time and gotten to sleep because sleep is very important for health and you're highlighting, look, this person is not sleeping."}, {"time": 7372, "text": "Look, the medical, the healthcare system is operating poor."}, {"time": 7376, "text": "But the point is we just, it seems like this is the way, especially in the capitalist society, we operate."}, {"time": 7382, "text": "We keep running into trouble and last minute, we try to get our way out through innovation and it seems to work."}, {"time": 7390, "text": "You have a lot of people that ultimately are trying to build a better world and get urgency about them when the problem becomes more and more imminent."}, {"time": 7402, "text": "And that's the way this operates."}, {"time": 7404, "text": "But if you look at the long arc of history, it seems like that operating on deadlines produces progress and builds better and better systems."}, {"time": 7416, "text": "You probably agree with me that the US should have engaged in mask production in January 2020 and that we should have shut down the airports early on and that we should have made it mandatory that the people that work in nursing homes are living on campus rather than living at home and then coming in and infecting people in the nursing homes that had no immune response to COVID."}, {"time": 7443, "text": "And that is something that was, I think, visible back then."}, {"time": 7448, "text": "The correct decisions haven't been made."}, {"time": 7450, "text": "We would have the same situation again."}, {"time": 7452, "text": "How do we know that these wrong decisions are not being made again?"}, {"time": 7455, "text": "Have the people that made the decisions to not protect the nursing homes been punished?"}, {"time": 7460, "text": "Have the people that made the wrong decisions with respect to testing that prevented the development of testing by startup companies and the importing of tests from countries that already had them, have these people been held responsible?"}, {"time": 7474, "text": "First of all, so what do you wanna put before the firing squad?"}, {"time": 7478, "text": "I think they are being held responsible."}, {"time": 7479, "text": "No, just make sure that this doesn't happen again."}, {"time": 7481, "text": "No, but it's not that, yes, they're being held responsible by many voices, by people being frustrated."}, {"time": 7488, "text": "There's new leaders being born now that we're going to see rise to the top in 10 years."}, {"time": 7494, "text": "This moves slower than, there's obviously a lot of older incompetence and bureaucracy and these systems move slowly."}, {"time": 7503, "text": "They move like science, one death at a time."}, {"time": 7506, "text": "So yes, I think the pain that's been felt in the previous year is reverberating throughout the world."}, {"time": 7515, "text": "Maybe I'm getting old, I suspect that every generation in the US after the war has lost the plot even more."}, {"time": 7521, "text": "I don't see this development."}, {"time": 7523, "text": "The war, World War II?"}, {"time": 7524, "text": "Yes, so basically there was a time when we were modernist and in this modernist time, the US felt actively threatened by the things that happened in the world."}, {"time": 7535, "text": "The US was worried about possibility of failure and this imminence of possible failure led to decisions."}, {"time": 7544, "text": "There was a time when the government would listen to physicists about how to do things and the physicists were actually concerned about what the government should be doing."}, {"time": 7553, "text": "So they would be writing letters to the government and so for instance, the decision for the Manhattan Project was something that was driven in a conversation between physicists and the government."}, {"time": 7564, "text": "I don't think such a discussion would take place today."}, {"time": 7566, "text": "I disagree, I think if the virus was much deadlier, we would see a very different response."}, {"time": 7572, "text": "I think the virus was not sufficiently deadly and instead because it wasn't very deadly, what happened is the current system started to politicize it."}, {"time": 7581, "text": "The mask, this is what I realized with masks early on, they were not, very quickly became not as a solution but they became a thing that politicians used to divide the country."}, {"time": 7593, "text": "So the same things happened with vaccines, same thing."}, {"time": 7596, "text": "So like nobody's really, people weren't talking about solutions to this problem because I don't think the problem was bad enough."}, {"time": 7603, "text": "When you talk about the war, I think our lives are too comfortable."}, {"time": 7608, "text": "I think in the developed world, things are too good and we have not faced severe dangers."}, {"time": 7614, "text": "When the danger, the severe dangers, existential threats are faced, that's when we step up on a small scale and a large scale."}, {"time": 7622, "text": "Now, I don't, that's sort of my argument here but I did think the virus is, I was hoping that it was actually sufficiently dangerous for us to step up because especially in the early days, it was unclear, it still is unclear because of mutations, how bad it might be, right?"}, {"time": 7645, "text": "And so I thought we would step up and even, so the masks point is a tricky one because to me, the manufacture of masks isn't even the problem."}, {"time": 7658, "text": "I'm still to this day and I was involved with a bunch of this work, have not seen good science done on whether masks work or not."}, {"time": 7666, "text": "Like there still has not been a large scale study."}, {"time": 7669, "text": "To me, that should be, there should be large scale studies and every possible solution, like aggressive in the same way that the vaccine development was aggressive."}, {"time": 7677, "text": "There should be masks, which tests, what kind of tests work really well, what kind of, like even the question of how the virus spreads."}, {"time": 7686, "text": "There should be aggressive studies on that to understand."}, {"time": 7689, "text": "I'm still, as far as I know, there's still a lot of uncertainty about that."}, {"time": 7694, "text": "Nobody wants to see this as an engineering problem that needs to be solved."}, {"time": 7698, "text": "It's that I was surprised about, but I wouldn't."}, {"time": 7701, "text": "So I find that our views are largely convergent but not completely."}, {"time": 7705, "text": "So I agree with the thing that because our society in some sense perceives itself as too big to fail."}, {"time": 7713, "text": "The virus did not alert people to the fact that we are facing possible failure that basically put us into the postmodernist mode."}, {"time": 7721, "text": "And I don't mean in a philosophical sense but in a societal sense."}, {"time": 7725, "text": "The difference between the postmodern society and the modern society is that the modernist society has to deal with the ground truth and the postmodernist society has to deal with appearances."}, {"time": 7735, "text": "Politics becomes a performance and the performance is done for an audience and the organized audience is the media."}, {"time": 7742, "text": "And the media evaluates itself via other media, right?"}, {"time": 7745, "text": "So you have an audience of critics that evaluate themselves."}, {"time": 7749, "text": "And I don't think it's so much the failure of the politicians because to get in power and to stay in power, you need to be able to deal with the published opinion."}, {"time": 7757, "text": "Well, I think it goes in cycles because what's going to happen is all of the small business owners, all the people who truly are suffering and will suffer more because the effects of the closure of the economy and the lack of solutions to the virus, they're going to apprise."}, {"time": 7776, "text": "And hopefully, I mean, this is where charismatic leaders can get the world in trouble but hopefully will elect great leaders that will break through this postmodernist idea of the media and the perception and the drama on Twitter and all that kind of stuff."}, {"time": 7797, "text": "But you know, this can go either way."}, {"time": 7800, "text": "When the Weimar Republic was unable to deal with the economic crisis that Germany was facing, there was an option to go back."}, {"time": 7810, "text": "But there were people which thought, let's get back to a constitutional monarchy and let's get this to work because democracy doesn't work."}, {"time": 7818, "text": "And eventually, there was no way back."}, {"time": 7821, "text": "People decided there was no way back."}, {"time": 7823, "text": "They needed to go forward."}, {"time": 7824, "text": "And the only options for going forward was to become Stalinist communist, basically an option to completely expropriate the factories and so on and nationalize them and to reorganize Germany in communist terms and ally itself with Stalin and fascism."}, {"time": 7844, "text": "And both options were obviously very bad."}, {"time": 7847, "text": "And the one that the Germans picked led to a catastrophe that devastated Europe."}, {"time": 7854, "text": "And I'm not sure if the US has an immune response against that."}, {"time": 7858, "text": "I think that the far right is currently very weak in the US, but this can easily change."}, {"time": 7865, "text": "Do you think from a historical perspective, Hitler could have been stopped from within Germany or from outside?"}, {"time": 7874, "text": "Or this, well, depends on who you wanna focus, whether you wanna focus on Stalin or Hitler, but it feels like Hitler was the one as a political movement that could have been stopped."}, {"time": 7885, "text": "I think that the point was that a lot of people wanted Hitler, so he got support from a lot of quarters."}, {"time": 7892, "text": "There was a number of industrialists who supported him because they thought that the democracy is obviously not working and unstable and you need a strong man."}, {"time": 7900, "text": "And he was willing to play that part."}, {"time": 7903, "text": "There were also people in the US who thought that Hitler would stop Stalin and would act as a bulwark against Bolshevism, which he probably would have done, right?"}, {"time": 7914, "text": "But at which cost?"}, {"time": 7916, "text": "And then many of the things that he was going to do, like the Holocaust, was something where people thought this is rhetoric, he's not actually going to do this."}, {"time": 7927, "text": "Especially many of the Jews themselves, which were humanists."}, {"time": 7930, "text": "And for them, this was outside of the scope that was thinkable."}, {"time": 7934, "text": "I mean, I wonder if Hitler is uniquely, I wanna carefully use this term, but uniquely evil."}, {"time": 7943, "text": "So if Hitler was never born, if somebody else would come in this place."}, {"time": 7949, "text": "So like, just thinking about the progress of history, how important are those singular figures that lead to mass destruction and cruelty?"}, {"time": 7960, "text": "Because my sense is Hitler was unique."}, {"time": 7967, "text": "It wasn't just about the environment and the context that gave him, like another person would not come in his place to do as destructive of the things that he did."}, {"time": 7978, "text": "There was a combination of charisma, of madness, of psychopathy, of just ego, all those things, which are very unlikely to come together in one person in the right time."}, {"time": 7992, "text": "It also depends on the context of the country that you're operating in."}, {"time": 7996, "text": "If you tell the Germans that they have a historical destiny in this romantic country, the effect is probably different than it is in other countries."}, {"time": 8007, "text": "But Stalin has killed a few more people than Hitler did."}, {"time": 8013, "text": "And if you look at the probability that you survived under Stalin, Hitler killed people if he thought they were not worth living, or if they were harmful to his racist project."}, {"time": 8029, "text": "He basically felt that the Jews would be too cosmopolitan and would not be willing to participate in the racist redefinition of society and the value of society, and there is no state in this way that he wanted to have it."}, {"time": 8043, "text": "So he saw them as harmful danger, especially since they played such an important role in the economy and culture of Germany."}, {"time": 8053, "text": "And so basically he had some radical but rational reason to murder them."}, {"time": 8060, "text": "And Stalin just killed everyone."}, {"time": 8063, "text": "Basically the Stalinist purges were such a random thing where he said that there's a certain possibility that this particular part of the population has a number of German collaborators or something, and we just kill them all, right?"}, {"time": 8078, "text": "Or if you look at what Mao did, the number of people that were killed in absolute numbers were much higher under Mao than they were under Stalin."}, {"time": 8087, "text": "So it's super hard to say."}, {"time": 8089, "text": "The other thing is that you look at Genghis Khan and so on, how many people he killed."}, {"time": 8096, "text": "When you see there are a number of things that happen in human history that actually really put a substantial dent in the existing population, or Napoleon."}, {"time": 8105, "text": "And it's very difficult to eventually measure it because what's happening is basically evolution on a human scale where one monkey figures out a way to become viral and is using this viral technology to change the patterns of society at the very, very large scale."}, {"time": 8126, "text": "And what we find so abhorrent about these changes is the complexity that is being destroyed by this."}, {"time": 8132, "text": "That's basically like a big fire that burns out a lot of the existing culture and structure that existed before."}, {"time": 8138, "text": "Yeah, and it all just starts with one monkey."}, {"time": 8142, "text": "One charismatic ape."}, {"time": 8144, "text": "And there's a bunch of them throughout history."}, {"time": 8146, "text": "Yeah, but it's in a given environment."}, {"time": 8147, "text": "It's basically similar to wildfires in California, right?"}, {"time": 8151, "text": "The temperature is rising."}, {"time": 8153, "text": "There is less rain falling."}, {"time": 8155, "text": "And then suddenly a single spark can have an effect that in other times would be contained."}, {"time": 8160, "text": "Okay, speaking of which, I love how we went to Hitler and Stalin from 20, 30 minutes ago, GPT3 generating, doing programs that this is."}, {"time": 8173, "text": "The argument was about morality of AI versus human."}, {"time": 8183, "text": "And specifically in the context of writing programs, specifically in the context of programs that can be destructive."}, {"time": 8189, "text": "So running nuclear power plants or autonomous weapons systems, for example."}, {"time": 8195, "text": "And I think your inclination was to say that it's not so obvious that AI would be less moral than humans or less effective at making a world that would make humans happy."}, {"time": 8208, "text": "So I'm not talking about self directed systems that are making their own goals at a global scale."}, {"time": 8217, "text": "If you just talk about the deployment of technological systems that are able to see order and patterns and use this as control models to act on the goals that we give them, then if we have the correct incentives to set the correct incentives for these systems, I'm quite optimistic."}, {"time": 8236, "text": "So humans versus AI, let me give you an example."}, {"time": 8240, "text": "Autonomous weapon system."}, {"time": 8243, "text": "Let's say there's a city somewhere in the Middle East that has a number of terrorists."}, {"time": 8250, "text": "And the question is, what's currently done with drone technologies, you have information about the location of a particular terrorist and you have a targeted attack, you have a bombing of that particular building."}, {"time": 8263, "text": "And that's all directed by humans at the high level strategy and also at the deployment of individual bombs and missiles like the actual, everything is done by human except the final targeting."}, {"time": 8276, "text": "And it's like spot, similar thing, like control the flight."}, {"time": 8281, "text": "Okay, what if you give AI control and saying, write a program that says, here's the best information I have available about the location of these five terrorists, here's the city, make sure all the bombing you do is constrained to the city, make sure it's precision based, but you take care of it."}, {"time": 8302, "text": "So you do one level of abstraction out and saying, take care of the terrorists in the city."}, {"time": 8309, "text": "Which are you more comfortable with, the humans or the JavaScript GPT3 generated code that's doing the deployment?"}, {"time": 8318, "text": "I mean, this is the kind of question I'm asking, is the kind of bugs that we see in human nature, are they better or worse than the kind of bugs we see in AI?"}, {"time": 8331, "text": "There are different bugs."}, {"time": 8361, "text": "And this is something that already happens with Excel."}, {"time": 8364, "text": "You don't need to have an AI system to do this."}, {"time": 8367, "text": "You have an automated process in place where humans decide using automated criteria whom to kill when and whom to target when, which already happens."}, {"time": 8378, "text": "And you have no way to get off the kill list once that happens, once you have been targeted according to some automatic criterion by people in a bureaucracy, that is the issue."}, {"time": 8388, "text": "The issue is not the AI, it's the automation."}, {"time": 8392, "text": "So there's something about, right, it's automation, but there's something about the, there's a certain level of abstraction where you give control to AI to do the automation."}, {"time": 8404, "text": "There's a scale that can be achieved that it feels like the scale of bug and scale mistake and scale of destruction that can be achieved of the kind that humans cannot achieve."}, {"time": 8416, "text": "So AI is much more able to destroy an entire country accidentally versus humans."}, {"time": 8422, "text": "It feels like the more civilians die as they react or suffer as the consequences of your decisions, the more weight there is on the human mind to make that decision."}, {"time": 8436, "text": "And so like, it becomes more and more unlikely to make that decision for humans."}, {"time": 8441, "text": "For AI, it feels like it's harder to encode that kind of weight."}, {"time": 8447, "text": "In a way, the AI that we're currently building is automating statistics, right?"}, {"time": 8451, "text": "Intelligence is the ability to make models so you can act on them, and AI is the tool to make better models."}, {"time": 8458, "text": "So in principle, if you're using AI wisely, you're able to prevent more harm."}, {"time": 8464, "text": "And I think that the main issue is not on the side of the AI, it's on the side of the human command hierarchy that is using technology irresponsibly."}, {"time": 8472, "text": "So the question is how hard is it to encode, to properly encode the right incentives into the AI?"}, {"time": 8479, "text": "So for instance, there's this idea of what happens if we let our airplanes being flown with AI systems and the neural network is a black box and so on."}, {"time": 8488, "text": "And it turns out our neural networks are actually not black boxes anymore."}, {"time": 8492, "text": "There are function approximators using linear algebra, and there are performing things that we can understand."}, {"time": 8500, "text": "But we can also, instead of letting the neural network fly the airplane, use the neural network to generate a provably correct program."}, {"time": 8507, "text": "There's a degree of accuracy of the proof that a human could not achieve."}, {"time": 8511, "text": "And so we can use our AI by combining different technologies to build systems that are much more reliable than the systems that a human being could create."}, {"time": 8520, "text": "And so in this sense, I would say that if you use an early stage of technology to save labor and don't employ competent people, but just to hack something together because you can, that is very dangerous."}, {"time": 8535, "text": "And if people are acting under these incentives that they get away with delivering shoddy work more cheaply using AI with less human oversight than before, that's very dangerous."}, {"time": 8545, "text": "The thing is though, AI is still going to be unreliable, perhaps less so than humans, but it'll be unreliable in novel ways."}, {"time": 8553, "text": "And... Yeah, but this is an empirical question."}, {"time": 8557, "text": "And it's something that we can figure out and work with."}, {"time": 8559, "text": "So the issue is, do we trust the systems, the social systems that we have in place and the social systems that we can build and maintain that they're able to use AI responsibly?"}, {"time": 8570, "text": "If they can, then AI is good news."}, {"time": 8572, "text": "If they cannot, then it's going to make the existing problems worse."}, {"time": 8577, "text": "Well, and also who creates the AI, who controls it, who makes money from it because it's ultimately humans."}, {"time": 8583, "text": "And then you start talking about how much you trust the humans."}, {"time": 8586, "text": "So the question is, what does who mean?"}, {"time": 8588, "text": "I don't think that we have identity per se."}, {"time": 8591, "text": "I think that the story of a human being is somewhat random."}, {"time": 8595, "text": "What happens is more or less that everybody is acting on their local incentives, what they perceive to be their incentives."}, {"time": 8601, "text": "And the question is, what are the incentives that the one that is pressing the button is operating under?"}, {"time": 8610, "text": "It's nice for those incentives to be transparent."}, {"time": 8612, "text": "So, for example, I'll give you an example."}, {"time": 8616, "text": "There seems to be a significant distrust of a tech, like entrepreneurs in the tech space or people that run, for example, social media companies like Mark Zuckerberg."}, {"time": 8629, "text": "There's not a complete transparency of incentives under which that particular human being operates."}, {"time": 8638, "text": "We can listen to the words he says or what the marketing team says for a company, but we don't know."}, {"time": 8644, "text": "And that becomes a problem when the algorithms and the systems created by him and other people in that company start having more and more impact on society."}, {"time": 8657, "text": "And that it starts, if the incentives were somehow the definition and the explainability of the incentives was decentralized such that nobody can manipulate it, no propaganda type manipulation of like how these systems actually operate could be done, then yes, I think AI could achieve much fairer, much more effective sort of like solutions to difficult ethical problems."}, {"time": 8693, "text": "But when there's like humans in the loop, manipulating the dissemination, the communication of how the system actually works, that feels like you can run into a lot of trouble."}, {"time": 8705, "text": "And that's why there's currently a lot of distrust for people at the heads of companies that have increasingly powerful AI systems."}, {"time": 8713, "text": "I suspect what happened traditionally in the US was that since our decision making is much more decentralized than in an authoritarian state, people are making decisions autonomously at many, many levels in a society."}, {"time": 8726, "text": "What happened that was we created coherence and cohesion in society by controlling what people thought and what information they had."}, {"time": 8735, "text": "The media synchronized public opinion and social media have disrupted this."}, {"time": 8740, "text": "It's not, I think so much Russian influence or something, it's everybody's influence."}, {"time": 8745, "text": "It's that a random person can come up with a conspiracy theory and disrupt what people think."}, {"time": 8752, "text": "And if that conspiracy theory is more compelling or more attractive than the standardized public conspiracy theory that we give people as a default, then it might get more traction, right?"}, {"time": 8763, "text": "You suddenly have the situation that a single individual somewhere on a farm in Texas has more listeners than CNN."}, {"time": 8771, "text": "Which particular farmer are you referring to in Texas?"}, {"time": 8777, "text": "Probably no."}, {"time": 8779, "text": "Yes, I had dinner with him a couple of times, okay."}, {"time": 8781, "text": "Right, it's an interesting situation because you cannot get to be an anchor in CNN if you don't go through a complicated gatekeeping process."}, {"time": 8790, "text": "And suddenly you have random people without that gatekeeping process, just optimizing for attention."}, {"time": 8796, "text": "Not necessarily with a lot of responsibility for the longterm effects of projecting these theories into the public."}, {"time": 8803, "text": "And now there is a push of making social media more like traditional media, which means that the opinion that is being projected in social media is more limited to an acceptable range."}, {"time": 8814, "text": "With the goal of getting society into safe waters and increase the stability and cohesion of society again, which I think is a laudable goal."}, {"time": 8823, "text": "But of course it also is an opportunity to seize the means of indoctrination."}, {"time": 8828, "text": "And the incentives that people are under when they do this are in such a way that the AI ethics that we would need becomes very often something like AI politics, which is basically partisan and ideological."}, {"time": 8843, "text": "And this means that whatever one side says, another side is going to be disagreeing with, right?"}, {"time": 8848, "text": "In the same way as when you turn masks or the vaccine into a political issue, if you say that it is politically virtuous to get vaccinated, it will mean that the people that don't like you will not want to get vaccinated, right?"}, {"time": 8861, "text": "And as soon as you have this partisan discourse, it's going to be very hard to make the right decisions because the incentives get to be the wrong ones."}, {"time": 8868, "text": "AI ethics needs to be super boring."}, {"time": 8871, "text": "It needs to be done by people who do statistics all the time and have extremely boring, long winded discussions that most people cannot follow because they are too complicated, but that are dead serious."}, {"time": 8882, "text": "These people need to be able to be better at statistics than the leading machine learning researchers."}, {"time": 8887, "text": "And at the moment, the AI ethics debate is the one where you don't have any barrier to entry, right?"}, {"time": 8894, "text": "Everybody who has a strong opinion and is able to signal that opinion in the right way can enter it."}, {"time": 8899, "text": "And to me, that is a very frustrating thing because the field is so crucially important to our future."}, {"time": 8907, "text": "It's so crucially important, but the only qualification you currently need is to be outraged by the injustice in the world."}, {"time": 8914, "text": "It's more complicated, right?"}, {"time": 8916, "text": "Everybody seems to be outraged."}, {"time": 8917, "text": "But let's just say that the incentives are not always the right ones."}, {"time": 8922, "text": "So basically, I suspect that a lot of people that enter this debate don't have a vision for what society should be looking like in a way that is nonviolent, where we preserve liberal democracy, where we make sure that we all get along and we are around in a few hundred years from now, preferably with a comfortable technological civilization around us."}, {"time": 8944, "text": "I generally have a very foggy view of that world, but I tend to try to follow, and I think society should in some degree follow the gradient of love, increasing the amount of love in the world."}, {"time": 8958, "text": "And whenever I see different policies or algorithms or ideas that are not doing so, obviously, that's the ones that kind of resist."}, {"time": 8967, "text": "So the thing that terrifies me about this notion is I think that German fascism was driven by love."}, {"time": 8975, "text": "It was just a very selective love."}, {"time": 8977, "text": "It was a love that basically... Now you're just manipulating."}, {"time": 8980, "text": "I mean, that's, you have to be very careful."}, {"time": 8985, "text": "You're talking to the wrong person in this way about love."}, {"time": 8990, "text": "So let's talk about what love is."}, {"time": 8992, "text": "And I think that love is the discovery of shared purpose."}, {"time": 8995, "text": "It's the recognition of the sacred in the other."}, {"time": 8999, "text": "And this enables non transactional interactions."}, {"time": 9002, "text": "But the size of the other that you include needs to be maximized."}, {"time": 9009, "text": "So it's basically appreciation, like deep appreciation of the world around you fully, including the people that are very different than you, people that disagree with you completely, including people, including living creatures outside of just people, including ideas."}, {"time": 9033, "text": "And it's like appreciation of the full mess of it."}, {"time": 9036, "text": "And also it has to do with like empathy, which is coupled with a lack of confidence and certainty of your own rightness."}, {"time": 9047, "text": "It's like a radical open mindedness to the way forward."}, {"time": 9051, "text": "I agree with every part of what you said."}, {"time": 9053, "text": "And now if you scale it up, what you recognize is that Lafist is in some sense, the service to next level agency, to the highest level agency that you can recognize."}, {"time": 9064, "text": "It could be for instance, life on earth or beyond that, where you could say intelligent complexity in the universe that you try to maximize in a certain way."}, {"time": 9074, "text": "But when you think it's true, it basically means a certain aesthetic."}, {"time": 9078, "text": "And there is not one possible aesthetic, there are many possible aesthetics."}, {"time": 9082, "text": "And once you project an aesthetic into the future, you can see that there are some which defect from it, which are in conflict with it, that are corrupt, that are evil."}, {"time": 9093, "text": "You and me would probably agree that Hitler was evil because the aesthetic of the world that he wanted is in conflict with the aesthetic of the world that you and me have in mind."}, {"time": 9104, "text": "And so they think that he destroyed, we want to keep them in the world."}, {"time": 9110, "text": "There's a kind of, there's kind of ways to deal, I mean, Hitler is an easier case, but perhaps he wasn't so easy in the 30s, right?"}, {"time": 9119, "text": "To understand who is Hitler and who is not."}, {"time": 9122, "text": "No, it was just there was no consensus that the aesthetics that he had in mind were unacceptable."}, {"time": 9127, "text": "Yeah, I mean, it's difficult, love is complicated because you can't just be so open minded that you let evil walk into the door, but you can't be so self assured that you can always identify evil perfectly because that's what leads to Nazi Germany."}, {"time": 9152, "text": "Having a certainty of what is and wasn't evil, like always drawing lines of good versus evil."}, {"time": 9158, "text": "There seems to be, there has to be a dance between like hard stances extending up against what is wrong."}, {"time": 9171, "text": "And at the same time, empathy and open mindedness of towards not knowing what is right and wrong and like a dance between those."}, {"time": 9181, "text": "I found that when I watched the Miyazaki movies that there is nobody who captures my spirituality as well as he does."}, {"time": 9187, "text": "It's very interesting and just vicious, right?"}, {"time": 9190, "text": "There is something going on in his movies that is very interesting."}, {"time": 9194, "text": "So for instance, Mononoke is discussing not only an answer to Disney's simplistic notion of Mowgli, the jungle boy was raised by wolves."}, {"time": 9204, "text": "And as soon as he sees people realizes that he's one of them and the way in which the moral life and nature is simplified and romanticized and turned into kitsch."}, {"time": 9216, "text": "It's disgusting in the Disney movie."}, {"time": 9217, "text": "And he answers to this, you see, he's replaced by Mononoke, this wolf girl who was raised by wolves and was fierce and dangerous and who cannot be socialized because she cannot be tamed."}, {"time": 9228, "text": "You cannot be part of human society."}, {"time": 9230, "text": "And you see human society, it's something that is very, very complicated."}, {"time": 9233, "text": "You see people extracting resources and destroying nature."}, {"time": 9237, "text": "But the purpose is not to be evil, but to be able to have a life that is free from, for instance, oppression and violence and to curb death and disease."}, {"time": 9250, "text": "And you basically see this conflict which cannot be resolved in a certain way."}, {"time": 9255, "text": "You see this moment when nature is turned into a garden and it loses most of what it actually is and humans no longer submitting to life and death and nature and to these questions, there is no easy answer."}, {"time": 9266, "text": "So it just turns it into something that is being observed as a journey that happens."}, {"time": 9271, "text": "And that happens with a certain degree of inevitability."}, {"time": 9274, "text": "And the nice thing about all his movies is there's a certain main character and it's the same in all movies."}, {"time": 9281, "text": "It's this little girl that is basically Heidi."}, {"time": 9285, "text": "And I suspect that happened because when he did field work for working on the Heidi movies back then, the Heidi animations, before he did his own movies, he traveled to Switzerland and South Eastern Europe and the Adriatic and so on and got an idea about a certain aesthetic and a certain way of life that informed his future thinking."}, {"time": 9308, "text": "And Heidi has a very interesting relationship to herself and to the world."}, {"time": 9313, "text": "There's nothing that she takes for herself."}, {"time": 9315, "text": "She's in a way fearless because she is committed to a service, to a greater whole."}, {"time": 9320, "text": "Basically, she is completely committed to serving God."}, {"time": 9324, "text": "And it's not an institutionalized God."}, {"time": 9326, "text": "It has nothing to do with the Roman Catholic Church or something like this."}, {"time": 9330, "text": "But in some sense, Heidi is an embodiment of the spirit of European Protestantism."}, {"time": 9335, "text": "It's this idea of a being that is completely perfect and pure."}, {"time": 9340, "text": "And it's not a feminist vision because she is not a girl boss or something like this."}, {"time": 9348, "text": "She is the justification for the men in the audience to protect her, to build a civilization around her that makes her possible."}, {"time": 9356, "text": "So she is not just the sacrifice of Jesus who is innocent and therefore nailed to the cross."}, {"time": 9362, "text": "She is not being sacrificed."}, {"time": 9364, "text": "She is being protected by everybody around her who recognizes that she is sacred."}, {"time": 9368, "text": "And there are enough around her to see that."}, {"time": 9372, "text": "So this is a very interesting perspective."}, {"time": 9374, "text": "There's a certain notion of innocence."}, {"time": 9376, "text": "And this notion of innocence is not universal."}, {"time": 9378, "text": "It's not in all cultures."}, {"time": 9380, "text": "Hitler wasn't innocent."}, {"time": 9381, "text": "His idea of Germany was not that there is an innocence that is being protected."}, {"time": 9386, "text": "There was a predator that was going to triumph."}, {"time": 9389, "text": "And it's also something that is not at the core of every religion."}, {"time": 9392, "text": "There are many religions which don't care about innocence."}, {"time": 9394, "text": "They might care about increasing the status of something."}, {"time": 9401, "text": "And that's a very interesting notion that is quite unique and not claiming it's the optimal one."}, {"time": 9407, "text": "It's just a particular kind of aesthetic which I think makes Miyazaki into the most relevant Protestant philosopher today."}, {"time": 9415, "text": "And you're saying in terms of all the ways that a society can operate perhaps the preservation of innocence might be one of the best."}, {"time": 9427, "text": "No, it's just my aesthetic."}, {"time": 9429, "text": "So it's a particular way in which I feel that I relate to the world that is natural to my own socialization."}, {"time": 9436, "text": "And maybe it's not an accident that I have cultural roots in Europe in a particular world."}, {"time": 9443, "text": "And so maybe it's a natural convergence point and it's not something that you will find in all other times in history."}, {"time": 9450, "text": "So I'd like to ask you about Solzhenitsyn and our individual role as ants in this very large society."}, {"time": 9459, "text": "So he says that some version of the line between good and evil runs to the heart of every man."}, {"time": 9464, "text": "Do you think all of us are capable of good and evil?"}, {"time": 9467, "text": "Like what's our role in this play in this game we're all playing?"}, {"time": 9475, "text": "Is all of us capable to play any role?"}, {"time": 9479, "text": "Like, is there an ultimate responsibility to you mentioned maintaining innocence or whatever the highest ideal for a society you want are all of us capable of living up to that?"}, {"time": 9491, "text": "And that's our responsibility or is there significant limitations to what we're able to do in terms of good and evil?"}, {"time": 9501, "text": "So there is a certain way if you are not terrible, if you are committed to some kind of civilizational agency, a next level agent that you are serving, some kind of transcendent principle."}, {"time": 9514, "text": "In the eyes of that transcendental principle, you are able to discern good from evil."}, {"time": 9518, "text": "Otherwise you cannot, otherwise you have just individual aesthetics."}, {"time": 9521, "text": "The cat that is torturing a mouse is not evil because the cat does not envision or no part of the world of the cat is envisioning a world where there is no violence and nobody is suffering."}, {"time": 9533, "text": "If you have an aesthetic where you want to protect innocence, then torturing somebody needlessly is evil, but only then."}, {"time": 9542, "text": "No, but within, I guess the question is within the aesthetic, like within your sense of what is good and evil, are we still, it seems like we're still able to commit evil."}, {"time": 9557, "text": "Yes, so basically if you are committing to this next level agent, you are not necessarily are this next level agent, right?"}, {"time": 9563, "text": "You are a part of it."}, {"time": 9564, "text": "You have a relationship to it, like the cell does to its organism, its hyperorganism."}, {"time": 9569, "text": "And it only exists to the degree that it's being implemented by you and others."}, {"time": 9574, "text": "And that means that you're not completely fully serving it."}, {"time": 9578, "text": "You have freedom in what you decide, whether you are acting on your impulses and local incentives and your farewell impulses, so to speak, or whether you're committing to it."}, {"time": 9587, "text": "And what you perceive then is a tension between what you would be doing with respect to the thing that you recognize as the sacred, if you do, and what you're actually doing."}, {"time": 9598, "text": "And this is the line between good and evil, right where you see, oh, I'm here acting on my local incentives or impulses, and here I'm acting on what I consider to be sacred."}, {"time": 9608, "text": "And there's a tension between those."}, {"time": 9609, "text": "And this is the line between good and evil that might run through your heart."}, {"time": 9614, "text": "And if you don't have that, if you don't have this relationship to a transcendental agent, you could call this relationship to the next level agent soul, right?"}, {"time": 9621, "text": "It's not a thing."}, {"time": 9622, "text": "It's not an immortal thing that is intrinsically valuable."}, {"time": 9625, "text": "It's a certain kind of relationship that you project to understand what's happening."}, {"time": 9629, "text": "Somebody is serving this transcendental sacredness or they're not."}, {"time": 9633, "text": "If you don't have a soul, you cannot be evil."}, {"time": 9635, "text": "You're just a complex natural phenomenon."}, {"time": 9639, "text": "So if you look at life, like starting today or starting tomorrow, when we leave here today, there's a bunch of trajectories that you can take through life, maybe countless."}, {"time": 9653, "text": "Do you think some of these trajectories, in your own conception of yourself, some of those trajectories are the ideal life, a life that if you were to be the hero of your life story, you would want to be?"}, {"time": 9670, "text": "Like, is there some Josh or Bhakti you're striving to be?"}, {"time": 9674, "text": "Like, this is the question I ask myself as an individual trying to make a better world in the best way that I could conceive of."}, {"time": 9682, "text": "What is my responsibility there?"}, {"time": 9684, "text": "And how much am I responsible for the failure to do so?"}, {"time": 9688, "text": "Because I'm lazy and incompetent too often."}, {"time": 9693, "text": "In my own perception."}, {"time": 9695, "text": "In my own worldview, I'm not very important."}, {"time": 9698, "text": "So it's, I don't have place for me as a hero in my own world."}, {"time": 9703, "text": "I'm trying to do the best that I can, which is often not very good."}, {"time": 9708, "text": "And so it's not important for me to have status or to be seen in a particular way."}, {"time": 9715, "text": "It's helpful if others can see me or a few people can see me that can be my friends."}, {"time": 9719, "text": "No, sorry, I want to clarify, the hero I didn't mean status or perception or like some kind of marketing thing, but more in private, in the quiet of your own mind."}, {"time": 9734, "text": "Is there the kind of man you want to be and would consider it a failure if you don't become that?"}, {"time": 9740, "text": "That's what I meant by hero."}, {"time": 9741, "text": "Yeah, not really."}, {"time": 9743, "text": "I don't perceive myself as having such an identity."}, {"time": 9746, "text": "And it's also sometimes frustrating, but it's basically a lack of having this notion of father that I need to be emulating."}, {"time": 9764, "text": "I mean, it's the leaf floating down the river."}, {"time": 9768, "text": "I worry that..."}, {"time": 9770, "text": "Sometimes it's more like being the river."}, {"time": 9779, "text": "I'm just a fat frog sitting on a leaf on a dirty, muddy lake."}, {"time": 9786, "text": "I wish I was waiting for a princess to kiss me."}, {"time": 9793, "text": "Or the other way, I forgot which way it goes."}, {"time": 9795, "text": "Somebody kisses somebody."}, {"time": 9797, "text": "I can ask you, I don't know if you know who Michael Malice is, but in terms of constructing since systems of incentives, it's interesting to ask."}, {"time": 9809, "text": "I don't think I've talked to you about this before."}, {"time": 9813, "text": "Malice espouses anarchism."}, {"time": 9815, "text": "So he sees all government as fundamentally getting in the way or even being destructive to collaborations between human beings thriving."}, {"time": 9830, "text": "What's the role of government in a society that thrives?"}, {"time": 9836, "text": "Is anarchism at all compelling to you as a system?"}, {"time": 9840, "text": "So like not just small government, but no government at all."}, {"time": 9845, "text": "Yeah, I don't see how this would work."}, {"time": 9849, "text": "The government is an agent that imposes an offset on your reward function, on your payout metrics."}, {"time": 9855, "text": "So your behavior becomes compatible with the common good."}, {"time": 9860, "text": "So the argument there is that you can have collectives like governing organizations, but not government, like where you're born in a particular set of land and therefore you must follow this rule or else."}, {"time": 9878, "text": "You're forced by what they call violence because there's an implied violence here."}, {"time": 9884, "text": "So the key aspect of government is it protects you from the rest of the world with an army and with police."}, {"time": 9896, "text": "So it has a monopoly on violence."}, {"time": 9900, "text": "It's the only one that's able to do violence."}, {"time": 9902, "text": "So there are many forms of government, not all governments do that."}, {"time": 9905, "text": "But we find that in successful countries, the government has a monopoly on violence."}, {"time": 9912, "text": "And that means that you cannot get ahead by starting your own army because the government will come down on you and destroy you if you try to do that."}, {"time": 9920, "text": "And in countries where you can build your own army and get away with it, some people will do it."}, {"time": 9925, "text": "And these countries is what we call failed countries in a way."}, {"time": 9930, "text": "And if you don't want to have violence, the point is not to appeal to the moral intentions of people because some people will use strategies if they get ahead with them that feel a particular kind of ecological niche."}, {"time": 9942, "text": "So you need to destroy that ecological niche."}, {"time": 9945, "text": "And if effective government has a monopoly on violence, it can create a world where nobody is able to use violence and get ahead."}, {"time": 9954, "text": "So you want to use that monopoly on violence, not to exert violence, but to make violence impossible, to raise the cost of violence."}, {"time": 9962, "text": "So people need to get ahead with nonviolent means."}, {"time": 9966, "text": "So the idea is that you might be able to achieve that in an anarchist state with companies."}, {"time": 9972, "text": "So with the forces of capitalism is create security companies where the one that's most ethically sound rises to the top."}, {"time": 9981, "text": "Basically, it would be a much better representative of the people because there is a less sort of stickiness to the big military force sticking around even though it's long overlived, outlived."}, {"time": 9996, "text": "So you have groups of militants that are hopefully efficiently organized because otherwise they're going to lose against the other groups of militants and they are coordinating themselves with the rest of society until they are having a monopoly on violence."}, {"time": 10011, "text": "How is that different from a government?"}, {"time": 10013, "text": "So it's basically converging to the same thing."}, {"time": 10016, "text": "So I was trying to argue with Malice, I feel like it always converges towards government at scale, but I think the idea is you can have a lot of collectives that are, you basically never let anything scale too big."}, {"time": 10031, "text": "So one of the problems with governments is it gets too big in terms of like the size of the group over which it has control."}, {"time": 10043, "text": "My sense is that would happen anyway."}, {"time": 10047, "text": "So a successful company like Amazon or Facebook, I mean, it starts forming a monopoly over the entire populations, not over just the hundreds of millions, but billions of people."}, {"time": 10059, "text": "So I don't know, but there is something about the abuses of power the government can have when it has a monopoly on violence, right?"}, {"time": 10069, "text": "And so that's a tension there, but..."}, {"time": 10073, "text": "So the question is how can you set the incentives for government correctly?"}, {"time": 10076, "text": "And this mostly applies at the highest levels of government and because we haven't found a way to set them correctly, we made the highest levels of government relatively weak."}, {"time": 10086, "text": "And this is, I think, part of the reason why we had difficulty to coordinate the pandemic response and China didn't have that much difficulty."}, {"time": 10094, "text": "And there is, of course, a much higher risk of the abuse of power that exists in China because the power is largely unchecked."}, {"time": 10102, "text": "And that's basically what happens in the next generation, for instance."}, {"time": 10106, "text": "Imagine that we would agree that the current government of China is largely correct and benevolent, and maybe we don't agree on this, but if we did, how can we make sure that this stays like this?"}, {"time": 10117, "text": "And if you don't have checks and balances, division of power, it's hard to achieve."}, {"time": 10122, "text": "You don't have a solution for that problem."}, {"time": 10125, "text": "But the abolishment of government basically would remove the control structure."}, {"time": 10129, "text": "From a cybernetic perspective, there is an optimal point in the system that the regulation should be happening, right?"}, {"time": 10136, "text": "That you can measure the current incentives and the regulator would be properly incentivized to make the right decisions and change the payout metrics of everything below it in such a way that the local prisoners dilemmas get resolved, right?"}, {"time": 10149, "text": "You cannot resolve the prisoners dilemma without some kind of eternal control that emulates an infinite game in a way."}, {"time": 10159, "text": "Yeah, I mean, there's a sense in which it seems like the reason government, the parts of government that don't work well currently is because there's not good mechanisms through which to interact, for the citizenry to interact with government is basically it hasn't caught up in terms of technology."}, {"time": 10181, "text": "And I think once you integrate some of the digital revolution of being able to have a lot of access to data, be able to vote on different ideas at a local level, at all levels, at the optimal level like you're saying that can resolve the prisoner dilemmas and to integrate AI to help you automate things that don't require the human ingenuity."}, {"time": 10207, "text": "I feel like that's where government could operate that well and can also break apart the inefficient bureaucracies if needed."}, {"time": 10215, "text": "There'll be a strong incentive to be efficient and successful."}, {"time": 10220, "text": "So out human history, we see an evolution and evolutionary competition of modes of government and of individual governments is in these modes."}, {"time": 10228, "text": "And every nation state in some sense is some kind of organism that has found different solutions for the problem of government."}, {"time": 10234, "text": "And you could look at all these different models and the different scales at which it exists as empirical attempts to validate the idea of how to build a better government."}, {"time": 10245, "text": "And I suspect that the idea of anarchism similar to the idea of communism is the result of being disenchanted with the ugliness of the real existing solutions and the attempt to get to an utopia."}, {"time": 10260, "text": "And I suspect that communism originally was not a utopia."}, {"time": 10264, "text": "I think that in the same way as original Christianity, it had a particular kind of vision."}, {"time": 10270, "text": "And this vision is a society, a mode of organization within the society in which humans can coexist at scale without coercion."}, {"time": 10280, "text": "In the same way as we do in a healthy family, right?"}, {"time": 10283, "text": "In a good family, you don't terrorize each other into compliance, but you understand what everybody needs and what everybody is able to contribute and what the intended future of the whole thing is."}, {"time": 10295, "text": "And everybody coordinates their behavior in the right way and informs each other about how to do this."}, {"time": 10300, "text": "And all the interactions that happen are instrumental to making that happen, right?"}, {"time": 10305, "text": "Could this happen at scale?"}, {"time": 10307, "text": "And I think this is the idea of communism."}, {"time": 10309, "text": "Communism is opposed to the idea that we need economic terror or other forms of terror to make that happen."}, {"time": 10315, "text": "But in practice, what happened is that the proto communist countries, the real existing socialism, replaced a part of the economic terror with moral terror, right?"}, {"time": 10325, "text": "So we were told to do the right thing for moral reasons."}, {"time": 10327, "text": "And of course it didn't really work and the economy eventually collapsed."}, {"time": 10331, "text": "And the moral terror had actual real cost, right?"}, {"time": 10334, "text": "People were in prison because they were morally noncompliant."}, {"time": 10337, "text": "And the other thing is that the idea of communism became a utopia."}, {"time": 10344, "text": "So it basically was projected into the afterlife."}, {"time": 10346, "text": "We were told in my childhood that communism was a hypothetical society to which we were in a permanent revolution that justified everything that was presently wrong with society morally."}, {"time": 10357, "text": "But it was something that our grandchildren probably would not ever see because it was too ideal and too far in the future to make it happen right now."}, {"time": 10364, "text": "And people were just not there yet morally."}, {"time": 10367, "text": "And the same thing happened with Christianity, right?"}, {"time": 10370, "text": "This notion of heaven was mythologized and projected into an afterlife."}, {"time": 10374, "text": "And I think this was just the idea of God's kingdom of this world in which we instantiate the next level transcendental agent in the perfect form."}, {"time": 10381, "text": "So everything goes smoothly and without violence and without conflict and without this human messiness on this economic messiness and the terror and coercion that existed in the present societies."}, {"time": 10393, "text": "And the idea of that the humans can exist at some point exist at scale in a harmonious way and noncoercively is untested, right?"}, {"time": 10401, "text": "A lot of people tested it but didn't get it to work so far."}, {"time": 10405, "text": "And the utopia is a world in where you get all the good things without any of the bad things."}, {"time": 10410, "text": "And you are, I think very susceptible to believe in utopias when you are very young and don't understand that everything has to happen in causal patterns, that there's always feedback loops that ultimately are closed."}, {"time": 10422, "text": "There's nothing that just happens because it's good or bad."}, {"time": 10425, "text": "Good or bad don't exist in isolation."}, {"time": 10427, "text": "They only exist with respect to larger systems."}, {"time": 10430, "text": "So can you intuit why utopias fail as systems?"}, {"time": 10437, "text": "So like having a utopia that's out there beyond the horizon is it because then, it's not only because it's impossible to achieve utopias but it's because what certain humans, certain small number of humans start to sort of greedily attain power and money and control and influence as they become, as they see the power in using this idea of a utopia for propaganda."}, {"time": 10475, "text": "It's a bit like saying, why is my garden not perfect?"}, {"time": 10477, "text": "It's because some evil weeds are overgrowing it and they always do, right?"}, {"time": 10481, "text": "But this is not how it works."}, {"time": 10483, "text": "A good garden is a system that is in balance and requires minimal interactions by the gardener."}, {"time": 10488, "text": "And so you need to create a system that is designed to self stabilize."}, {"time": 10494, "text": "And the design of social systems requires not just the implementation of the desired functionality, but the next level design, also in biological systems."}, {"time": 10501, "text": "You need to create a system that wants to converge to the intended function."}, {"time": 10506, "text": "And so instead of just creating an institution like the FDA that is performing a particular kind of role in society, you need to make sure that the FDA is actually driven by a system that wants to do this optimally, that is incentivized to do it optimally and then makes the performance that is actually enacted in every generation instrumental to that thing, that actual goal, right?"}, {"time": 10527, "text": "And that is much harder to design and to achieve."}, {"time": 10530, "text": "See if the design a system where, and listen communism also was quote unquote incentivized to be a feedback loop system that achieves that utopia."}, {"time": 10543, "text": "It's just, it wasn't working given human nature."}, {"time": 10545, "text": "The incentives were not correct given human nature."}, {"time": 10547, "text": "How do you incentivize people when they are getting coal off the ground to work as hard as possible?"}, {"time": 10553, "text": "Because it's a terrible job and it's very bad for your health."}, {"time": 10557, "text": "And right, how do you do this?"}, {"time": 10559, "text": "And you can give them prices and medals and status to some degree, right?"}, {"time": 10564, "text": "There's only so much status to give for that."}, {"time": 10566, "text": "And most people will not fall for this, right?"}, {"time": 10569, "text": "Or you can pay them and you probably have to pay them in an asymmetric way because if you pay everybody the same and you nationalize the coal mines, eventually people will figure out that they can game the system."}, {"time": 10581, "text": "Yes, so you're describing capitalism."}, {"time": 10585, "text": "So capitalism is the present solution to the system."}, {"time": 10588, "text": "And what we also noticed that I think that Marx was correct in saying that capitalism is prone to crisis, that capitalism is a system that in its dynamics is not convergent, but divergent."}, {"time": 10600, "text": "It's not a stable system."}, {"time": 10602, "text": "And that eventually it produces an enormous potential for productivity, but it also is systematically misallocating resources."}, {"time": 10612, "text": "So a lot of people cannot participate in the production and consumption anymore, right?"}, {"time": 10617, "text": "And this is what we observed."}, {"time": 10618, "text": "We observed that the middle class in the US is tiny."}, {"time": 10621, "text": "It's a lot of people think that they're middle class, but if you are still flying economy, you're not middle class, right?"}, {"time": 10631, "text": "Every class is a magnitude smaller than the previous class."}, {"time": 10634, "text": "And I think about classes is really like airline class."}, {"time": 10643, "text": "I like class."}, {"time": 10645, "text": "A lot of people are economy class, business class, and very few are first class and some are budget."}, {"time": 10650, "text": "I mean, some, I understand."}, {"time": 10652, "text": "I think there's, yeah, maybe some people, probably I would push back against that definition of the middle class."}, {"time": 10659, "text": "It does feel like the middle class is pretty large, but yes, there's a discrepancy in terms of wealth."}, {"time": 10665, "text": "So if you think about in terms of the productivity that our society could have, there is no reason for anybody to fly economy, right?"}, {"time": 10673, "text": "We would be able to let everybody travel in style."}, {"time": 10677, "text": "Well, but also some people like to be frugal even when they're billionaires, okay?"}, {"time": 10681, "text": "So like that, let's take that into account."}, {"time": 10684, "text": "I mean, we probably don't need to be a traveling lavish, but you also don't need to be tortured, right?"}, {"time": 10689, "text": "There is a difference between frugal and subjecting yourself to torture."}, {"time": 10694, "text": "Listen, I love economy."}, {"time": 10695, "text": "I don't understand why you're comparing a fly economy to torture."}, {"time": 10699, "text": "I don't, although the fight here, there's two crying babies next to me."}, {"time": 10704, "text": "So that, but that has nothing to do with economy."}, {"time": 10706, "text": "It has to do with crying babies."}, {"time": 10708, "text": "They're very cute though."}, {"time": 10709, "text": "So they kind of."}, {"time": 10710, "text": "Yeah, I have two kids and sometimes I have to go back to visit the grandparents."}, {"time": 10715, "text": "And that means going from the west coast to Germany and that's a long flight."}, {"time": 10722, "text": "Is it true that, so when you're a father, you grow immune to the crying and all that kind of stuff, like the, because like me just not having kids, it can be other people's kids can be quite annoying when they're crying and screaming and all that kind of stuff."}, {"time": 10737, "text": "When you have children and you are wired up in the default natural way, you're lucky in this regard, you fall in love with them."}, {"time": 10744, "text": "And this falling in love with them means that you basically start to see the world through their eyes and you understand that in a given situation, they cannot do anything but being expressing despair."}, {"time": 10757, "text": "And so it becomes more differentiated."}, {"time": 10759, "text": "I noticed that for instance, my son is typically acting on a pure experience of what things are like right now and he has to do this right now."}, {"time": 10770, "text": "And you have this small child that is, when he was a baby and so on, where he was just immediately expressing what he felt."}, {"time": 10777, "text": "And if you cannot regulate this from the outside, there's no point to be upset about it, right?"}, {"time": 10782, "text": "It's like dealing with weather or something like this."}, {"time": 10785, "text": "You all have to get through it and it's not easy for him either."}, {"time": 10788, "text": "But if you also have a daughter, maybe she is planning for that."}, {"time": 10793, "text": "Maybe she understands that she's sitting in the car behind you and she's screaming at the top of her lungs and you're almost doing an accident and you really don't know what to do."}, {"time": 10803, "text": "What should I have done to make you stop screaming?"}, {"time": 10806, "text": "You could have given me candy."}, {"time": 10810, "text": "I think that's like a cat versus dog discussion."}, {"time": 10813, "text": "Cause you said like a fundamental aspect of that is love that makes it all worth it."}, {"time": 10821, "text": "What, in this monkey riding an elephant in a dream world, what role does love play in the human condition?"}, {"time": 10831, "text": "I think that love is the facilitator of non transactional interaction."}, {"time": 10837, "text": "And you are observing your own purposes."}, {"time": 10840, "text": "Some of these purposes go beyond your ego."}, {"time": 10842, "text": "They go beyond the particular organism that you are and your local interests."}, {"time": 10846, "text": "That's what you mean by non transactional."}, {"time": 10848, "text": "Yes, so basically when you are acting in a transactional way, it means that you are respecting something in return for you from the one that you're interacting with."}, {"time": 10858, "text": "You are interacting with a random stranger, you buy something from them on eBay, you expect a fair value for the money that you sent them and vice versa."}, {"time": 10865, "text": "Because you don't know that person, you don't have any kind of relationship to them."}, {"time": 10869, "text": "But when you know this person a little bit better and you know the situation that they're in, you understand what they try to achieve in their life and you approve because you realize that they're in some sense serving the same human sacredness as you are."}, {"time": 10882, "text": "And they need to think that you have, maybe you give it to them as a present."}, {"time": 10886, "text": "But, I mean, the feeling itself of joy is a kind of benefit, is a kind of transaction, like..."}, {"time": 10894, "text": "Yes, but the joy is not the point."}, {"time": 10896, "text": "The joy is the signal that you get."}, {"time": 10898, "text": "It's the reinforcement signal that your brain sends to you because you are acting on the incentives of the agent that you're a part of."}, {"time": 10905, "text": "We are meant to be part of something larger."}, {"time": 10908, "text": "This is the way in which we out competed other hominins."}, {"time": 10914, "text": "Take that Neanderthals."}, {"time": 10917, "text": "And also other humans."}, {"time": 10919, "text": "There was a population bottleneck for human society that leads to an extreme lack of genetic diversity among humans."}, {"time": 10927, "text": "If you look at Bushmen in the Kalahari, that basically tribes that are not that far distant to each other have more genetic diversity than exists between Europeans and Chinese."}, {"time": 10939, "text": "And that's because basically the out of Africa population at some point had a bottleneck of just a few thousand individuals."}, {"time": 10947, "text": "And what probably happened is not that at any time the number of people shrank below a few hundred thousand."}, {"time": 10954, "text": "What probably happened is that there was a small group that had a decisive mutation that produced an advantage."}, {"time": 10960, "text": "And this group multiplied and killed everybody else."}, {"time": 10964, "text": "And we are descendants of that group."}, {"time": 10966, "text": "Yeah, I wonder what the peculiar characteristics of that group."}, {"time": 10973, "text": "I mean, we can never know."}, {"time": 10973, "text": "Me too, and a lot of people do."}, {"time": 10975, "text": "We can only just listen to the echoes in ours, like the ripples that are still within us."}, {"time": 10981, "text": "So I suspect what eventually made a big difference was the ability to organize at scale, to program each other."}, {"time": 10989, "text": "With ideas."}, {"time": 10991, "text": "That we became programmable, that we were willing to work in lockstep, that we went above the tribal level, that we no longer were groups of a few hundred individuals and acted on direct reputation systems transactionally, but that we basically evolved an adaptation to become state building."}, {"time": 11011, "text": "To form collectives outside of the direct collectives."}, {"time": 11015, "text": "Yes, and that's basically a part of us became committed to serving something outside of what we know."}, {"time": 11021, "text": "Yeah, then that's kind of what love is."}, {"time": 11024, "text": "And it's terrifying because it meant that we eradicated the others."}, {"time": 11028, "text": "Right, it's a force."}, {"time": 11029, "text": "It's an adaptive force that gets us ahead in evolution, which means we displace something else that doesn't have that."}, {"time": 11036, "text": "Oh, so we had to murder a lot of people that weren't about love."}, {"time": 11040, "text": "So love led to destruction."}, {"time": 11041, "text": "They didn't have the same strong love as we did."}, {"time": 11044, "text": "Right, that's why I mentioned this thing with fascism."}, {"time": 11047, "text": "When you see these speeches, do you want total war?"}, {"time": 11052, "text": "And everybody says, yes, right?"}, {"time": 11054, "text": "This is this big, oh my God, we are part of something that is more important than me that gives meaning to my existence."}, {"time": 11067, "text": "Do you have advice for young people today in high school, in college, that are thinking about what to do with their career, with their life, so that at the end of the whole thing, they can be proud of what they did?"}, {"time": 11083, "text": "Don't cheat."}, {"time": 11085, "text": "Have integrity, aim for integrity."}, {"time": 11088, "text": "So what does integrity look like when you're at the river or the leaf or the fat frog in a lake?"}, {"time": 11094, "text": "It basically means that you try to figure out what the thing is that is the most right."}, {"time": 11102, "text": "And this doesn't mean that you have to look for what other people tell you what's right, but you have to aim for moral autonomy."}, {"time": 11109, "text": "So things need to be right independently of what other people say."}, {"time": 11114, "text": "I always felt that when people told me to listen to what others say, like read the room, build your ideas of what's true based on the high status people of your in group, that does not protect me from fascism."}, {"time": 11129, "text": "The only way to protect yourself from fascism is to decide it's the world that is being built here, the world that I want to be in."}, {"time": 11137, "text": "And so in some sense, try to make your behavior sustainable, act in such a way that you would feel comfortable on all sides of the transaction."}, {"time": 11146, "text": "Realize that everybody is you in a different timeline, but is seeing things differently and has reasons to do so."}, {"time": 11153, "text": "Yeah, I've come to realize this recently, that there is an inner voice that tells you what's right and wrong."}, {"time": 11162, "text": "And speaking of reading the room, there's times what integrity looks like is there's times when a lot of people are doing something wrong."}, {"time": 11172, "text": "And what integrity looks like is not going on Twitter and tweeting about it, but not participating quietly, not doing."}, {"time": 11180, "text": "So it's not like signaling or not all this kind of stuff, but actually living your, what you think is right."}, {"time": 11188, "text": "Like living it, not signaling."}, {"time": 11188, "text": "There's also sometimes this expectation that others are like us."}, {"time": 11192, "text": "So imagine the possibility that some of the people around you are space aliens that only look human, right?"}, {"time": 11199, "text": "So they don't have the same prayers as you do."}, {"time": 11201, "text": "They don't have the same impulses that's what's right and wrong."}, {"time": 11205, "text": "There's a large diversity in these basic impulses that people can have in a given situation."}, {"time": 11211, "text": "And now realize that you are a space alien, right?"}, {"time": 11214, "text": "You are not actually human."}, {"time": 11215, "text": "You think that you are human, but you don't know what it means, like what it's like to be human."}, {"time": 11220, "text": "You just make it up as you go along like everybody else."}, {"time": 11224, "text": "And you have to figure that out, what it means that you are a full human being, what it means to be human in the world and how to connect with others on that."}, {"time": 11233, "text": "And there is also something, don't be afraid in the sense that if you do this, you're not good enough."}, {"time": 11240, "text": "Because if you are acting on these incentives of integrity, you become trustworthy."}, {"time": 11245, "text": "That's the way in which you can recognize each other."}, {"time": 11248, "text": "There is a particular place where you can meet."}, {"time": 11250, "text": "You can figure out what that place is, where you will give support to people because you realize that they act with integrity and they will also do that."}, {"time": 11260, "text": "So in some sense, you are safe if you do that."}, {"time": 11263, "text": "You're not always protected."}, {"time": 11264, "text": "There are people which will abuse you and that are bad actors in a way that it's hard to imagine before you meet them."}]}, {"title": "Norman Naimark: Genocide, Stalin, Hitler, Mao, and Absolute Power | Lex Fridman Podcast #248", "id": "Vrz8YDl9CeA", "quotes": [{"time": 352, "text": "Was it always there?"}, {"time": 354, "text": "It's kind of a question of did the genocide, was that always inevitable, essentially, in this man, or did power create that?"}, {"time": 365, "text": "I mean, it's a great question, and I don't think you can, I don't think you can say that it was always kind of inherent in the man."}, {"time": 374, "text": "I mean, the man without his position and without his power, you know, wouldn't have been able to accomplish what he eventually did in the way of murdering people, you know, and murdering groups of people, which is what genocide is."}, {"time": 388, "text": "So, you know, I don't, it wasn't sort of in him."}, {"time": 392, "text": "I mean, there were, and again, you know, the new research has shown that, you know, he had his childhood was, you know, not a particularly nasty one."}, {"time": 402, "text": "People used to say, you know, the father beat him up, and it turns out, actually, it wasn't the father, it was the mother once in a while."}, {"time": 409, "text": "But basically, you know, he was not an unusual young Georgian kid or student even."}, {"time": 416, "text": "And, you know, it was the growth of the Soviet system and him within the Soviet system, I mean, his own development within the Soviet system, I think that led, you know, to the kind of mass killing that occurred in the 1930s."}, {"time": 435, "text": "You know, he essentially achieved complete power by the early 1930s."}, {"time": 442, "text": "And then as he, as he rolled with it, as you would say, you know, or people would say, you know, it increasingly became murderous."}, {"time": 452, "text": "And there was no, you know, there were no checks and balances, obviously, on that murderous system."}, {"time": 459, "text": "And not only that, you know, people supported it in the NKVD and elsewhere, he learned how to manipulate people."}, {"time": 466, "text": "I mean, he was a superb, you know, political manipulator of those people around him."}, {"time": 474, "text": "And, you know, we have, we've got new transcripts, for example, of, you know, police bureau meetings in the early 1930s."}, {"time": 485, "text": "And you read those things and you read, you know, he uses humor and he uses sarcasm, especially, he uses verbal ways to undermine people, you know, to control their behavior and what they do."}, {"time": 500, "text": "And he's a really, you know, he's a real, I guess, manipulator is the right word."}, {"time": 507, "text": "And he does it, he does it with, you know, a kind of skill that on the one hand is admirable."}, {"time": 515, "text": "And on the other hand, of course, is terrible because it ends up, you know, creating the system of terror that he creates."}, {"time": 528, "text": "I mean, I guess just to linger on it, I just wonder how much of it is a slippery slope in the early 20s, 1920s, did he think he was going to be murdering even a single person, but thousands and millions?"}, {"time": 544, "text": "I just wonder maybe the murder of a single human being just to get them, you know, because you're paranoid about them potentially threatening your power, does that murder then open a door?"}, {"time": 562, "text": "And once you open the door, you become a different human being."}, {"time": 565, "text": "A deeper question here is the soldier Knitsen, you know, the line between good and evil runs in every man, are all of us once we commit one murder in the situation, does that open a door for all of us?"}, {"time": 577, "text": "And I guess even the further deeper questions, how easy it is for human nature to go on the slippery slope that ends in genocide?"}, {"time": 589, "text": "There are a lot of questions in those questions."}, {"time": 592, "text": "And, you know, the slippery slope question I would answer, I suppose by saying, you know, Stalin wasn't the most likely successor of Lenin, there were plenty of others, there were a lot of political contingencies that emerged in the 1920s that made it possible for Stalin to seize power."}, {"time": 616, "text": "I don't think of him as, you know, if you would just know him in 1925, I don't think anybody would say much less himself that this was a future mass murderer."}, {"time": 628, "text": "I mean, Trotsky mistrusted him and thought he was, you know, a mindless bureaucrat."}, {"time": 636, "text": "You know, others were less mistrustful of him, but, you know, he managed to gain power in the way he did through this bureaucratic and political maneuvering that was very successful."}, {"time": 649, "text": "You know, the slippery slope, as it were, doesn't really begin until the 1930s, in my view."}, {"time": 713, "text": "And people start seeing that, too, around him."}, {"time": 717, "text": "They start seeing that it's not a slippery slope, it's a dangerous, it's a dangerous situation which is emerging, and some people really understand that."}, {"time": 730, "text": "So I don't, I really do see a differentiation then between the 20s."}, {"time": 734, "text": "I mean, it's true that Stalin, during the Civil War, there's a lot of, you know, good research on that, you know, shows that he already had some of these characteristics of being, as it were, murderous and being, you know, being dictatorial and pushing people around and that sort of thing."}, {"time": 754, "text": "That was all there, but I don't really see that as kind of the necessary stage for the next thing that came, which was the 30s, which was really terror of the worst sort, you know, where everybody's afraid for their lives and most people are afraid for their lives and their family's lives and where torture and that sort of thing becomes a common part, you know, of who, what people had to face."}, {"time": 780, "text": "So it's a different, it's a different world."}, {"time": 783, "text": "And you know, people will argue, they'll argue this kind of Lenin, Stalin continuity debate, you know, that's been going on since I was an undergraduate, right?"}, {"time": 793, "text": "That argument, you know, was Stalin the natural sort of next step from Lenin or was he something completely different?"}, {"time": 803, "text": "Many people will argue, you know, because of Marxism, Leninism, because of the ideology that, you know, it was the natural, it was a kind of natural next step."}, {"time": 813, "text": "You know, I would tend to lean the other way."}, {"time": 816, "text": "Not absolutely."}, {"time": 817, "text": "I mean, I won't make an absolute argument that what Stalin became had nothing to do with Lenin and nothing to do with Marxism, Leninism."}, {"time": 825, "text": "It had a lot to do with it."}, {"time": 827, "text": "But you know, he takes it one major step further."}, {"time": 831, "text": "And again, that's why I don't like the slippery slope, you know, metaphor, because that means it's kind of slow and easy."}, {"time": 837, "text": "It's a leap."}, {"time": 838, "text": "And we call, you know, I mean, historians talk about the Stalin revolution, you know, in 28 and 29, you know, that he, in some senses, creates a whole new system, you know, through the five year plan, collectivization and seizing political power the way he does."}, {"time": 857, "text": "Can you talk about the 1930s?"}, {"time": 859, "text": "Can you describe what happened in Holodomor, the Soviet terror famine in Ukraine in the 32 and 33?"}, {"time": 866, "text": "That killed millions of Ukrainians."}, {"time": 868, "text": "It's a long story, you know, but let me try to be as succinct as I can be."}, {"time": 874, "text": "I mean, the Holodomor, the terror famine of 32, 33 comes out of, in part, an all union famine that is the result of collectivization."}, {"time": 889, "text": "You know, collectivization was a catastrophe."}, {"time": 892, "text": "You know, the more or less, the so called kulaks, the more or less richer farmers, I mean, they weren't really rich, right?"}, {"time": 900, "text": "Anybody with a tin roof and a cow was considered a kulak, you know, and other people who had nothing were also considered kulaks if they opposed collectivization."}, {"time": 909, "text": "So these kulaks, we're talking millions of them, right?"}, {"time": 912, "text": "And Ukraine, it's worth recalling, and I'm sure you know this, was a, you know, heavily agricultural area, and Ukrainian peasants, you know, were in the countryside and resisted collectivization more than even Russian peasants resisted collectivization, suffered during this collectivization program."}, {"time": 935, "text": "And they, you know, burned sometimes their own houses, they killed their own animals, they were shot, you know, sometimes on the spot, and tens of thousands and others were sent into exile."}, {"time": 950, "text": "So there was a conflagration in the countryside."}, {"time": 953, "text": "And the result of that conflagration in Ukraine was terrible famine."}, {"time": 958, "text": "And again, there was famine all over the Soviet Union, but it was especially bad in Ukraine, in part because Ukrainian peasants resisted."}, {"time": 967, "text": "Now in 3233, a couple of things happen."}, {"time": 972, "text": "I mean, I've argued this in my writing, and, you know, I've also worked on this, I continue to work on it, by the way, with a museum in Kiev that's going to be about the Holodomor."}, {"time": 985, "text": "They're building the museum now, and it's going to be a very impressive set of exhibits, and talk with historians all the time about it."}, {"time": 994, "text": "So what happens in 3233, a couple of things."}, {"time": 997, "text": "First of all, the Stalin develops, develops an even stronger, I say even stronger, because they already had an antipathy for the Ukrainians, an even stronger antipathy for the Ukrainians in general."}, {"time": 1013, "text": "First of all, they resist collectivization."}, {"time": 1015, "text": "Second of all, he's not getting all the grain he wants out of them, and which he needs."}, {"time": 1022, "text": "And so he sends in, then, people to expropriate the grain, and take the grain away from the peasants."}, {"time": 1029, "text": "These teams of people, you know, some policemen, some urban thugs, some party people, some poor peasants, you know, take part too, go into the villages, and forcibly seize grain and animals from the Ukrainian peasantry."}, {"time": 1048, "text": "They're seizing it all over."}, {"time": 1049, "text": "I mean, let's remember again, this is all over the Soviet Union, in 32, especially."}, {"time": 1054, "text": "Then, you know, in December of 1932, January of 33, February of 33, Stalin has convinced the Ukrainian peasantry needs to be shown who's boss, that they're not turning over their grain, that they're resisting the expropriators, that they're hiding the grain, which they do sometimes, right?"}, {"time": 1081, "text": "That they're basically not loyal to the Soviet Union, that they're acting like traitors, that they're ready, and he says this, you know, I think it's Kaganovich he says it too, you know, they're ready to kind of pull out of the Soviet Union and join Poland."}, {"time": 1095, "text": "I mean, he thinks Poland is, you know, out to get Ukraine, and so he's gonna then, essentially, break the back of these peasantry."}, {"time": 1103, "text": "And the way he breaks their back is by going through another expropriation program, which is not done in the rest of the Soviet Union."}, {"time": 1113, "text": "So he's taking away everything they have, everything they have."}, {"time": 1118, "text": "There are new laws introduced, where they will actually punish people, including kids, with death, if they steal any grain, you know, if they take anything from the, you know, from the fields."}, {"time": 1131, "text": "So, you know, you can shoot anybody, you know, who is looking for food."}, {"time": 1135, "text": "And then he introduces measures in Ukraine, which are not introduced into the rest of the Soviet Union."}, {"time": 1142, "text": "For example, the Ukrainian peasantry are not allowed to leave their villages anymore."}, {"time": 1148, "text": "They can't go to the city to try to find some things."}, {"time": 1151, "text": "I mean, we've got pictures of, you know, Ukrainian peasants dying on the sidewalks in Kharkiv, and in Kiev, and places like that, who've managed to get out of the village and get to the cities, but now they can't leave."}, {"time": 1164, "text": "They can't leave Ukraine to go to Belorussia, or Belarus today, or to Russia, you know, to get any food."}, {"time": 1172, "text": "There's no, he won't allow any relief to Ukraine."}, {"time": 1176, "text": "Number of people offer relief, including the Poles, but also the Vatican offers relief."}, {"time": 1182, "text": "He won't allow any relief to Ukraine."}, {"time": 1184, "text": "He won't admit that there's a famine in Ukraine."}, {"time": 1187, "text": "And instead, what happens is that Ukraine turns into, the Ukrainian countryside turns into what my now past colleague who died several years ago, Robert Conquest, called a vast Belsen."}, {"time": 1204, "text": "And by that, you know, the image is of bodies just lying everywhere, you know, people dead."}, {"time": 1210, "text": "And dying, you know, of hunger, which is, by the way, I mean, as you know, I've spent a lot of time studying genocide, I don't think there's anything worse than dying of hunger from what I have read."}, {"time": 1224, "text": "I mean, you see terrible ways that people die, right?"}, {"time": 1227, "text": "But dying of hunger is just such a horrible, horrible thing."}, {"time": 1231, "text": "And so, for example, we know there were many cases of cannibalism in the countryside because there wasn't anything to eat."}, {"time": 1238, "text": "People were eating their own kids, right?"}, {"time": 1241, "text": "And Stalin knew about this."}, {"time": 1243, "text": "And again, you know, we started with this question a little bit earlier, he doesn't, there's not a sign of remorse, not a sign of pity, right?"}, {"time": 1254, "text": "Not a sign of any kind of human emotion that normal people would have."}, {"time": 1261, "text": "What about the opposite of joy for teaching them a lesson?"}, {"time": 1268, "text": "I don't think there's joy."}, {"time": 1269, "text": "I'm not sure Stalin really understood emotion, what joy was, you know."}, {"time": 1275, "text": "I think he felt it was necessary to get those SOBs, right?"}, {"time": 1281, "text": "That they deserved it."}, {"time": 1283, "text": "He says that several times, this is their own fault, right?"}, {"time": 1286, "text": "This is their own fault."}, {"time": 1289, "text": "And as their own fault, you know, they get what they deserve, basically."}, {"time": 1296, "text": "How much was the calculation?"}, {"time": 1297, "text": "How much was it reason versus emotion?"}, {"time": 1299, "text": "In terms of, you said he was competent."}, {"time": 1305, "text": "Was there a long term strategy or was this strategy based on emotion and anger?"}, {"time": 1311, "text": "No, I think actually the right answer is a little of both."}, {"time": 1316, "text": "I mean, usually the right answer in history is something like that."}, {"time": 1319, "text": "A little of both?"}, {"time": 1319, "text": "No, you can't, you can't."}, {"time": 1321, "text": "It wasn't just, I mean, first of all, you know, the Soviets had it in for Ukraine and Ukrainian nationalism, which they really didn't like."}, {"time": 1332, "text": "And by the way, Russians still don't like it, right?"}, {"time": 1335, "text": "So they had it in for Ukrainian nationalism."}, {"time": 1338, "text": "They feared Ukrainian nationalism."}, {"time": 1342, "text": "As I said, you know, Stalin writes, you know, we'll lose Ukraine, you know, if these guys win."}, {"time": 1349, "text": "You know, so there's a kind of long term determination, as I said, you know, to kind of break the back of Ukrainian national identity and Ukrainian nationalism as any kind of separatist force whatsoever."}, {"time": 1366, "text": "And so there's that rational calculation."}, {"time": 1370, "text": "At the same time, I think Stalin is annoyed and peeved and angry on one level with the Ukrainians for resisting collectivization and for being difficult and for not conforming, you know, to the way he thinks peasants should act in this situation."}, {"time": 1393, "text": "So you have both things."}, {"time": 1394, "text": "He's also very angry at the Ukrainian party and eventually purges it for not being able to control Ukraine and not be able to control the situation."}, {"time": 1403, "text": "You know, Ukraine is in theory the bread basket, right?"}, {"time": 1406, "text": "Of Europe."}, {"time": 1407, "text": "Well, how come the bread basket isn't turning over to me all this grain so I can sell it abroad and, you know, build new factories and support the workers in the cities?"}, {"time": 1417, "text": "So there's a kind of annoyance."}, {"time": 1419, "text": "You know, when things fail, and this is absolutely typical of Stalin, when things fail, he blames it on other people and usually groups of people, right?"}, {"time": 1427, "text": "Not individuals, but groups again."}, {"time": 1430, "text": "So a little bit of both I think is the right answer."}, {"time": 1434, "text": "This blame, it feels like there's a playbook that dictators follow."}, {"time": 1439, "text": "I just wonder if it comes naturally or just kind of evolves."}, {"time": 1443, "text": "Because, you know, blaming others and then telling these narratives and then creating the other and then somehow that leads to hatred and genocide."}, {"time": 1450, "text": "It feels like there's too many commonalities for it not to be a naturally emergent strategy that works for dictatorships."}, {"time": 1460, "text": "I mean, it's a very good point."}, {"time": 1463, "text": "And I think it's one, you know, that has its merits."}, {"time": 1467, "text": "In other words, I think you're right that there's certain kinds of strategies by dictators that, you know, are common to them."}, {"time": 1475, "text": "A lot of them do killing, not all of them of that sort that Stalin did."}, {"time": 1480, "text": "I've written about Mao and Pol Pot, you know, and Hitler."}, {"time": 1483, "text": "And, you know, there is a sort of, as you say, a kind of playbook for political dictatorship."}, {"time": 1491, "text": "Also for, you know, a kind of communist totalitarian way of functioning, you know?"}, {"time": 1499, "text": "And that way of functioning was described already by Hannah Arendt early on when she wrote The Origins of Totalitarianism."}, {"time": 1506, "text": "And she more or less writes the playbook and Stalin does follow it."}, {"time": 1512, "text": "The real question, it seems to me, is to what extent, you know, and how deep does this go and how often does it go in that direction?"}, {"time": 1522, "text": "I mean, you can argue, for example, I mean, Fidel Castro was not a nice man, right?"}, {"time": 1527, "text": "He was a dictator, he was a terrible dictator."}, {"time": 1530, "text": "But he did not engage in mass murder."}, {"time": 1533, "text": "Ho Chi Minh was a dictator, a communist dictator who grew up, you know, in the communist movement, went to Moscow, you know, spent time in Moscow in the 30s and went to find, found the Vietnamese Communist Party."}, {"time": 1547, "text": "You know, he was a horrible dictator."}, {"time": 1549, "text": "I'm sure he was responsible for a lot of death and destruction."}, {"time": 1552, "text": "But he wasn't a mass murderer."}, {"time": 1555, "text": "And so you get those, you know."}, {"time": 1557, "text": "I mean, I would even argue, others will disagree, that Lenin wasn't a mass murderer."}, {"time": 1564, "text": "You know, that he didn't kill the same way, you know, that Stalin killed."}, {"time": 1568, "text": "Or people after him, they're communist dictators too, after all, Khrushchev, you know, was a communist dictator."}, {"time": 1573, "text": "But he stopped this killing."}, {"time": 1576, "text": "And, you know, he's still responsible for a gulag and people sent off into a gulag and imprisonment and torture and that sort of thing."}, {"time": 1583, "text": "But it's not at all the same thing."}, {"time": 1585, "text": "So there are some, you know, like Stalin, like Mao, like Pol Pot, you know, who commit these horrible, horrible atrocities, extensively engaging, in my view, in genocide."}, {"time": 1599, "text": "And there are some who don't."}, {"time": 1602, "text": "And, you know, what's the difference?"}, {"time": 1604, "text": "Well, you know, the difference is partly in personality, partly in historical circumstance, you know, partly in who is it that controls the reins of power."}, {"time": 1614, "text": "How much do you connect the ideas of communism or Marxism or socialism to Holodomor, to Stalin's rule?"}, {"time": 1623, "text": "So how naturally, as you kind of alluded to, does it lead to genocide?"}, {"time": 1629, "text": "That's also, I mean, in some ways, I've just addressed that question by saying it doesn't always lead to genocide."}, {"time": 1637, "text": "You know, in the case, again, you know, Cuba is not pretty, but it didn't have, there was no genocide in Cuba."}, {"time": 1645, "text": "And same thing in North Vietnam."}, {"time": 1647, "text": "You know, even North Korea, as awful as it is, is a terrible dictatorship, right?"}, {"time": 1652, "text": "And people's rights are totally destroyed, right?"}, {"time": 1657, "text": "They have no freedom whatsoever."}, {"time": 1659, "text": "You know, it's not, as far as we know, genocidal."}, {"time": 1663, "text": "Who knows whether it could be or whether if they took over South Korea, you know, mass murder wouldn't take place and that kind of thing."}, {"time": 1670, "text": "But my point is, is that the ideology doesn't necessarily dictate genocide."}, {"time": 1677, "text": "In other words, it's an ideology, I think, that makes genocide sometimes too easily possible given, you know, the way it thinks through history as being, you know, you're on the right side of history and some people are on the wrong side of history and you have to destroy those people who are on the wrong side of history."}, {"time": 1697, "text": "I mean, there is something in, you know, Marxism, Leninism, which, you know, has that kind of language and that kind of thinking."}, {"time": 1705, "text": "But I don't think it's necessarily that way."}, {"time": 1711, "text": "There's a wonderful historian at Berkeley named Martin Malia who has written, you know, wrote a number of books on this subject and he was very, very, he was convinced that the ideology itself, you know, played a crucial role in the murderousness of the Soviet regime."}, {"time": 1734, "text": "I'm not completely convinced."}, {"time": 1736, "text": "You know, when I say not completely convinced, I think you could argue it different ways."}, {"time": 1741, "text": "Equally valid, you know, with equally valid arguments."}, {"time": 1745, "text": "I mean, there's something about the ideology of communism that allows you to decrease the value of human life."}, {"time": 1755, "text": "Almost like this philosophy, if it's okay to crack a few eggs to make an omelet."}, {"time": 1759, "text": "So maybe that, if you can reason like that, then it's easier to take the leap of, for the good of the country, for the good of the people, for the good of the world, it's okay to kill a few people."}, {"time": 1771, "text": "And then that's where, I wonder about the slippery slope."}, {"time": 1777, "text": "Yeah, no, no, again, you know, I don't think it's a slippery slope."}, {"time": 1780, "text": "I think it's, I think it's dangerous."}, {"time": 1784, "text": "In other words, I think it's dangerous, but I don't consider, you know, I don't like Marxism, Leninism any better than the next guy."}, {"time": 1791, "text": "And I've lived in plenty of those systems to know how they can beat people down and how they can, you know, destroy human aspirations and human interaction between people."}, {"time": 1806, "text": "But they're not necessarily murderous systems."}, {"time": 1811, "text": "They are systems that contain people's autonomy, that force people into work and labor and lifestyles that they don't want to live."}, {"time": 1821, "text": "I spent a lot of time, you know, with East Germans and Poles, you know, who lived in, and even in the Soviet Union, you know, in the post Stalin period, where people lived lives they didn't want to live, you know, and didn't have the freedom to choose."}, {"time": 1840, "text": "And that was terrifying in and of itself, but these were not murderous systems."}, {"time": 1846, "text": "And they, you know, ascribed to Marxism, Leninism."}, {"time": 1851, "text": "So I suppose it's important to draw the line between mass murder and genocide and mass murder versus just mass violation of human rights."}, {"time": 1864, "text": "And the leap to mass murder, you're saying, maybe easier in some ideologies than others, but it's not clear that somehow one ideology definitely leads to mass murder and not."}, {"time": 1878, "text": "I wonder how many factors, what factors, how much of it is a single charismatic leader?"}, {"time": 1884, "text": "How much of it is the conflagration of multiple historical events?"}, {"time": 1890, "text": "How much of it is just dumb, the opposite of luck?"}, {"time": 1898, "text": "Do you have a sense where if you look at a moment in history, predict, looking at the factors, whether something bad's going to happen here?"}, {"time": 1909, "text": "When you look at Iraq at when Saddam Hussein first took power, well, you could, or you can, you know, go even farther back in history, would you be able to predict?"}, {"time": 1920, "text": "So you said, you already kind of answered that with Stalin saying there's no way you could have predicted that in the early 20s."}, {"time": 1927, "text": "Is that always the case?"}, {"time": 1928, "text": "You basically can't predict."}, {"time": 1929, "text": "It's pretty much always the case."}, {"time": 1931, "text": "In other words, I mean, history is a wonderful, you know, discipline and way of looking at life and the world in retrospect, meaning it happened."}, {"time": 1943, "text": "And we know it happened."}, {"time": 1944, "text": "And it's too easy to say sometimes it happened because it had to happen that way."}, {"time": 1950, "text": "It almost never has to happen that way."}, {"time": 1953, "text": "And, you know, things."}, {"time": 1956, "text": "So I very much am of the school that emphasizes, you know, contingency and choice and difference and different paths and not, you know, not necessarily a path that has to be followed."}, {"time": 1974, "text": "And those, you know, and, you know, sometimes you can warn about things."}, {"time": 1982, "text": "I mean, you can think, well, something's going to happen."}, {"time": 1986, "text": "And usually the way it works, let me just give you one example."}, {"time": 1989, "text": "I mean, I'm thinking about an example right now, which was the war in Yugoslavia, you know, which came in the 1990s and eventually ventuated in genocide in Bosnia."}, {"time": 1999, "text": "And, you know, I remember very clearly, you know, the 1970s and 1980s in Yugoslavia, and people would say, you know, there's trouble here and, you know, something could go wrong."}, {"time": 2011, "text": "But no one in their wildest imagination thought that there would be outright war between them all."}, {"time": 2016, "text": "Then the outright war happened, genocide happened, and afterwards people would say, I saw it coming."}, {"time": 2022, "text": "You know, so you get a lot of that, especially with pundits and journalists, and that's, I saw it coming, I knew it was happening."}, {"time": 2031, "text": "You know, well, I mean, what happens in the human mind, and it happens in your mind too, is, you know, you go through a lot of alternatives."}, {"time": 2038, "text": "I mean, think about January 6th, you know, in this country, and all the different alternatives which people had in their mind, or before January 6th, you know, after the lost election."}, {"time": 2050, "text": "You know, things could have gone in lots of different ways, and there were all kinds of people choosing different ways it could have gone, but nobody really knew how it was going to turn out."}, {"time": 2060, "text": "It wasn't as smart people really understood that there'd be this kind of cockamamie uprising on January 6th, you know, that almost, you know, caused us enormous grief."}, {"time": 2068, "text": "So all of these kinds of things in history, you know, are deeply contingent."}, {"time": 2073, "text": "They depend on, you know, factors that we cannot predict, and, you know, and it's the joy of history that it's open."}, {"time": 2081, "text": "You know, you think about how people are now, I mean, let me give you one more example, and then I'll shut up, but, you know, there's the environmental example."}, {"time": 2089, "text": "You know, we're all threatened, right?"}, {"time": 2091, "text": "We know it's coming."}, {"time": 2091, "text": "We know there's trouble, right?"}, {"time": 2094, "text": "We know there's gonna be a catastrophe at some point, but when?"}, {"time": 2099, "text": "What's the catastrophe?"}, {"time": 2100, "text": "Yeah, what's the nature of the catastrophe?"}, {"time": 2102, "text": "Everyone says catastrophe."}, {"time": 2103, "text": "And what's the nature of it, right, right, right."}, {"time": 2104, "text": "Is it gonna be wars because resource constraint?"}, {"time": 2106, "text": "Is it going to be hunger?"}, {"time": 2107, "text": "Is it gonna be, like, mass migration of different kinds that leads to some kind of conflict and immigration, and maybe it won't be that big of a deal, and a total other catastrophic event will completely challenge the entirety of the human civilization."}, {"time": 2122, "text": "That's my point, that's my point, that's my point."}, {"time": 2125, "text": "You know, we really don't know."}, {"time": 2128, "text": "I mean, there's a lot we do know."}, {"time": 2129, "text": "I mean, the warming business and all this kind of stuff, you know, it's scientifically there, but how it's going to play out."}, {"time": 2136, "text": "And everybody's saying, you know, different things."}, {"time": 2139, "text": "And then you get somewhere in 50 years or 60 years, which I won't see, and people say, aha, I told you it was gonna be X, or it was gonna be Y, or it was gonna be Z."}, {"time": 2149, "text": "So I just don't think in history you can, well, you can't predict."}, {"time": 2156, "text": "You simply cannot predict what's going to happen."}, {"time": 2159, "text": "It's kind of when you just look at Hitler in the 30s, for me, oftentimes when I kind of read different accounts, it is so often, certainly in the press, but in general, me just reading about Hitler, I get the sense, like, this is a clown."}, {"time": 2175, "text": "There's no way this person will gain power."}, {"time": 2178, "text": "Which one, Hitler or Stalin?"}, {"time": 2180, "text": "Hitler, Hitler."}, {"time": 2181, "text": "No, no, no, with Stalin, you don't get a sense he's a clown, he's a really good executive."}, {"time": 2186, "text": "You think, you don't think it'll lead to mass murder, but you think he's going to build a giant bureaucracy, at least with Hitler, it's like a failed artist who keeps screaming about stuff."}, {"time": 2199, "text": "There's no way he's gonna, I mean, you certainly don't think about the atrocities, but there's no way he's going to gain power, especially against communism."}, {"time": 2208, "text": "There's so many other competing forces that could have easily beat him."}, {"time": 2214, "text": "But then, you realize, event after event, where this clown keeps dancing, and all of a sudden, he gains more and more power, and just certain moments in time, he makes strategic decisions in terms of cooperating or gaining power over the military, all those kinds of things that eventually give him the power."}, {"time": 2237, "text": "I mean, this clown is one of the most impactful in the negative sense human beings in history."}, {"time": 2245, "text": "Right, and even the Jews who are there and are being screamed at and discriminated against, and there's a series of measures taken against them incrementally during the course of the 1930s, and very few who leave."}, {"time": 2259, "text": "Yeah, I mean, some pick up and go and say, I'm getting the hell out of here, and some Zionists try to leave, too, and go to the United States and stuff, but go to Israel and Palestine at the time, but, or to Britain or France."}, {"time": 2275, "text": "But in general, even the Jews who should have been very sensitive to what was going on didn't really understand the extent of the danger, and it's really hard for people to do that."}, {"time": 2288, "text": "It's almost impossible, in fact, I think."}, {"time": 2292, "text": "So most of the time, in that exact situation, nothing would have happened, or there'd be some drama and so on, and it'd be there's some bureaucrat, but every once in a while in human history, there's a kind of turn, and maybe something catalyzes something else, and just it accelerates to accelerate, escalates, escalates, and then war breaks out, or totally, you know, revolutions break out."}, {"time": 2320, "text": "Can we go to the big question of genocide?"}, {"time": 2323, "text": "What is genocide?"}, {"time": 2324, "text": "What are the defining characteristics of genocide?"}, {"time": 2328, "text": "Dealing with genocide is a difficult thing when it comes to the definition."}, {"time": 2333, "text": "There is a definition, the December 1948 UN Convention on the Prep Prevention and Punishment of Genocide is considered the sort of major document of definition, in the definitional sense of genocide, and it emphasizes the intentional destruction of an ethnic, national, racial, or religious group, those are the four groups, again, comma, as such."}, {"time": 2366, "text": "And what that means, basically, is destroying the group as a group."}, {"time": 2371, "text": "In other words, there's a kind of beauty in human diversity, and different groups of people, you know, Estonians, you know, a tribe of Native Americans, South African tribes, you know, the Rohingya in Myanmar, there's a kind of beauty humanity recognizes in the distinctiveness of those groups."}, {"time": 2395, "text": "You know, this was a notion that emerges really with Romanticism after the French Revolution, then the beginning of the 19th century, with Herder, mostly."}, {"time": 2404, "text": "And this beauty of these groups, then, you know, is what is under attack in genocide."}, {"time": 2413, "text": "And it's with intent, you know, the idea is that it's intentional destruction."}, {"time": 2419, "text": "So this is a kind of, you know, analogy to first degree, second degree, and third degree murder, right?"}, {"time": 2427, "text": "First degree murder, you know, you're out to kill this person, and you plan it, and you go out, and you do it, right?"}, {"time": 2434, "text": "That's intent, right?"}, {"time": 2436, "text": "Manslaughter is not intent."}, {"time": 2437, "text": "You end up doing the same thing, but it's different."}, {"time": 2440, "text": "So, you know, the major person behind the definitions, a man named Raphael Lemkin, I don't know if you heard his name or not, but he was a Polish Jewish jurist who came, you know, from Poland, came to the United States during the war, and had been a kind of crusader for recognizing genocide."}, {"time": 2465, "text": "It's a word that he created, by the way, and he coined the term in 1943, and then published it in 1944 for the first time."}, {"time": 2474, "text": "Geno, meaning people, and side, meaning killing, right?"}, {"time": 2478, "text": "And so Lemkin then had this term, and he pushed hard to have it recognized, and it was in the UN Convention."}, {"time": 2484, "text": "So that's the rough definition."}, {"time": 2487, "text": "The problem with it is the definition, the problems with the definition are several."}, {"time": 2493, "text": "You know, one of them is, is it just these four groups?"}, {"time": 2498, "text": "You know, racial, religious, ethnic, or national?"}, {"time": 2502, "text": "See, this comes right out of the war."}, {"time": 2504, "text": "And what's in people's minds in 1948 are Jews, Poles, Russians, Yugoslavs sometimes, who were killed by the Nazis."}, {"time": 2513, "text": "That's what's in their mind."}, {"time": 2514, "text": "But there are other groups, too, if you think about it, you know, who are killed, social groups or political groups."}, {"time": 2521, "text": "And that was not allowed in the convention, meaning for a lot of different reasons, the Soviets were primary among them."}, {"time": 2530, "text": "They didn't want other kinds of groups, let's say Kulaks, for example, to be considered."}, {"time": 2536, "text": "That's a social group."}, {"time": 2538, "text": "Or peasants, which is a social group."}, {"time": 2541, "text": "So, or a political group."}, {"time": 2543, "text": "I mean, let's take a group, you know, communists killed groups of people, but non communists also killed groups of people in Indonesia in 1965, 66, they killed, you know, I don't know exactly, but roughly 600,000 Indonesian communists."}, {"time": 2560, "text": "Well, is that genocide or not?"}, {"time": 2562, "text": "You know, at my point of view, it is genocide, although it's Indonesians killing Indonesians."}, {"time": 2568, "text": "And we have the same problem with the Cambodian genocide."}, {"time": 2571, "text": "I mean, we talk about a Cambodian genocide, but most of the people killed in the Cambodian genocide were other Cambodians."}, {"time": 2578, "text": "They give it the name, they're ready to recognize this genocide because they also killed some other peoples, meaning the Vietnamese, Aham people who are, you know, Muslim, smaller Muslim people in the area, and a few others."}, {"time": 2594, "text": "So the question then becomes, well, does it have to be a different nationality or ethnic group or religious group for it to be genocide?"}, {"time": 2603, "text": "And my answer is no."}, {"time": 2604, "text": "You know, you need to expand the definition."}, {"time": 2606, "text": "It's a little bit like with our constitution."}, {"time": 2608, "text": "We got a constitution, but we don't live in the end of the 18th century, right?"}, {"time": 2612, "text": "We live in the 21st century."}, {"time": 2613, "text": "And so you have to update the constitution over the centuries."}, {"time": 2618, "text": "And similarly, the genocide convention needs updating too."}, {"time": 2622, "text": "So that's how I work with the definition."}, {"time": 2625, "text": "So this is this invention."}, {"time": 2628, "text": "Was it an invention, this beautiful idea, romantic idea that there's groups of people and the group is united by some unique characteristics?"}, {"time": 2637, "text": "That was an invention in human history, this idea?"}, {"time": 2641, "text": "Not to see as individuals?"}, {"time": 2643, "text": "In some senses, it was."}, {"time": 2645, "text": "I mean, it's not, you know, there are things that are always constructed in one fashion or another and the construction, you know, more or less represents the reality."}, {"time": 2655, "text": "And what the reality is always much more complicated than the construction or the invention of a term or a concept or a way of thinking about a nation, right?"}, {"time": 2666, "text": "And this way of thinking of nations, you know, as again, you know, groups of religious, linguistic, not political necessarily, but cultural entities is something that was essentially invented, yes."}, {"time": 2685, "text": "Yeah, so I mean, you know, if you look at..."}, {"time": 2687, "text": "There are no Germans in the 17th century."}, {"time": 2690, "text": "There are no Italians in the 17th century, right?"}, {"time": 2692, "text": "They're only there after, you know, the invention of the nation, which comes again, mostly out of the French Revolution and in the Romantic movement, a man named Johann Gottfried von Herder, right?"}, {"time": 2708, "text": "Who was really the first one who sort of went around, collected people's languages and collected their sayings and their dances and their folkways and stuff and said, isn't this cool, you know, that they're Estonians and that they're Latvians and that they're these other, these interesting different peoples who don't even know necessarily that they're different peoples, right?"}, {"time": 2730, "text": "That comes a little bit later, right?"}, {"time": 2733, "text": "Once the concept is invented, then people start to say, hey, we're nations too, you know?"}, {"time": 2739, "text": "And the Germans decide they're a nation and they unify."}, {"time": 2741, "text": "And the Italians discover they're a nation and they unify instead of being, you know, Florentines and Romans and, you know, Sicilians."}, {"time": 2752, "text": "But then beyond nations, there's political affiliations, all those kinds of things."}, {"time": 2756, "text": "It's fascinating that, you know, you start, look at the early Homo sapiens and then there's obviously tribes, right?"}, {"time": 2764, "text": "And then that's very concrete."}, {"time": 2766, "text": "That's a geographic location and it's a small group of people and you have warring tribes probably connected to just limited resources."}, {"time": 2776, "text": "But it's fascinating to think that that is then taken to the space of ideas, to where you can create a group at first to appreciate its beauty."}, {"time": 2787, "text": "You create a group based on language, based on maybe even political, philosophical ideas, religious ideas, all those kinds of things."}, {"time": 2796, "text": "And then that naturally then leads to getting angry at groups and making them the other."}, {"time": 2802, "text": "And then hatred."}, {"time": 2804, "text": "That comes more towards the end of the 19th century, you know, with the influence of Darwin."}, {"time": 2810, "text": "I mean, you can't blame Darwin for it, but neo Darwin, Darwinians, you know, who start to talk about, you know, the competition between nations, the natural competition, the weak ones fall away, the strong ones get ahead."}, {"time": 2823, "text": "You know, you get this sort of combination also with, you know, modern antisemitism and with racial thinking, you know, the racial thinking at the end of the 19th century is very powerful."}, {"time": 2834, "text": "So now, you know, at the end of the 19th century versus the beginning of the, you know, the middle of the 19th century, you know, you can be a German and be a Jew and there's no contradiction."}, {"time": 2847, "text": "As long as you speak the language and you, you know, you dress and think and act and share the culture."}, {"time": 2852, "text": "By the end of the 19th century, people saying, no, no, you know, they're not Germans."}, {"time": 2857, "text": "They're Jews, they're different."}, {"time": 2857, "text": "They have different blood."}, {"time": 2858, "text": "They have different, they don't say genes yet, but you know, that's sort of a sense of people."}, {"time": 2863, "text": "And that's when, you know, there's this sense of superiority too, and inferiority."}, {"time": 2870, "text": "You know, that they're inferior to us."}, {"time": 2872, "text": "You know, and that we're the strong ones and we have to, you know, and Hitler, by the way, just adopts this hook line and sinker."}, {"time": 2880, "text": "I mean, there are a whole series of thinkers at the end of the 19th and beginning of 20th century who he cites in Mein Kampf, you know, which is written in the early 1920s, that, you know, basically pervades this racial thinking."}, {"time": 2895, "text": "So nationalism changes."}, {"time": 2896, "text": "So nationalism in and of itself is not bad."}, {"time": 2899, "text": "I mean, it's not bad, you know, to share culture and language and, you know, folkways and a sense of common belonging."}, {"time": 2909, "text": "There's nothing bad about it inherently."}, {"time": 2912, "text": "But then what happens is it becomes, you know, frequently is used and becomes, especially on fascism, becomes dangerous."}, {"time": 2922, "text": "And it's especially dangerous when the two conflicting groups share geographic location."}, {"time": 2929, "text": "So like with Jews, you know, I come, you know, I'm a Russian Jew and it's always interesting."}, {"time": 2938, "text": "I take pride in, you know, I love the tradition of the Soviet Union, of Russia."}, {"time": 2947, "text": "I love America."}, {"time": 2948, "text": "So I love these countries."}, {"time": 2950, "text": "They have beautiful tradition in literature and science and art and all those kinds of things."}, {"time": 2955, "text": "But it's funny that people, not often, but sometimes correct me that I'm not Russian."}, {"time": 2964, "text": "I'm a Jew."}, {"time": 2964, "text": "And it's a, it's a, it's a nice reminder."}, {"time": 2970, "text": "That that is always there, that desire to create these groups."}, {"time": 2977, "text": "And then when they're living in the same place for that division between groups, that hate between groups can explode."}, {"time": 2985, "text": "And I just, I wonder why is that there?"}, {"time": 2989, "text": "Why does, why does the human heart tend so easily towards this kind of hate?"}, {"time": 2998, "text": "You know, that's a big question in and of itself."}, {"time": 3002, "text": "You know, the human heart is full of everything, right?"}, {"time": 3004, "text": "It's full of hate."}, {"time": 3005, "text": "It's full of love."}, {"time": 3006, "text": "It's full of indifference."}, {"time": 3007, "text": "It's full of apathy."}, {"time": 3009, "text": "It's full of energy."}, {"time": 3010, "text": "So, I mean, hate is something, you know, that, I mean, I think, and, you know, along with hate, you know, the ability to really hurt and injure people is something that's within all of us."}, {"time": 3028, "text": "You know, it's within all of us."}, {"time": 3030, "text": "And it's just something that's part of who we are and part of our society."}, {"time": 3037, "text": "So, you know, we're shaped by our society and our society can do with us often what it wishes."}, {"time": 3044, "text": "You know, that's why it's so much nicer to live in a more or less beneficent society like that of a democracy in the West than to live in the Soviet Union, right?"}, {"time": 3055, "text": "I mean, because, you know, you have more or less the freedom to do what you wish and not to be forced into situations in which you would have to then do nasty to other people."}, {"time": 3069, "text": "You know, some societies, as we talked about, you know, are more have proclivities towards, you know, asking of its people to do things they don't want to do and forcing them to do so."}, {"time": 3084, "text": "So, you know, freedom is a wonderful thing."}, {"time": 3087, "text": "To be able to choose not to do evil is a great thing, you know, whereas in some societies, you know, you feel in some ways for not so much for the NKVD bosses, but for the guys on the ground, you know, in the 1930s or not so much for the Nazi bosses, but for the guys, you know, in the police battalion that were told, go shoot those Jews, you know?"}, {"time": 3113, "text": "And you do it, not necessarily because they force you to do it, but because your social, you know, your social situation, you know, encourages you to and you don't have the courage not to."}, {"time": 3129, "text": "Yeah, I was just, as I often do, rereading Viktor Frankl's Man's Search for Meaning and he said something, I just, I often pull out sort of lines."}, {"time": 3142, "text": "The mere knowledge that a man was either a camp guard or a prisoner tells us almost nothing."}, {"time": 3148, "text": "Human kindness can be found in all groups, even those which as a whole, it would be easy to condemn."}, {"time": 3156, "text": "So that's speaking to, you feel for those people at the lowest level implementing the orders of those above."}, {"time": 3171, "text": "And also you worry yourself what will happen if you were given those same orders, you know?"}, {"time": 3176, "text": "I mean, what would you do?"}, {"time": 3179, "text": "You know, what kind of reaction would you have in a similar situation?"}, {"time": 3183, "text": "And you know, you don't know."}, {"time": 3187, "text": "I could see myself in World War II while fighting for almost any country that I was born in."}, {"time": 3197, "text": "There's a love of community, there's a love of country that's just, at least to me it comes naturally, just love of community and countries wanting such community."}, {"time": 3207, "text": "And I could see fighting for that country, especially when you're sold a story that you're fighting evil and I'm sure every single country was sold that story effectively."}, {"time": 3218, "text": "And then when you're in the military and you have a gun in your hand or you're in the police force and you're ordered, go to this place and commit violence, it's hard to know what you would do."}, {"time": 3235, "text": "It's a mix of fear, it's a mix of, maybe you convince yourself, you know, what can one person really do?"}, {"time": 3243, "text": "And over time, it's again, that slippery slope."}, {"time": 3245, "text": "Because you could see all the people who protest, who revolt, they're ineffective."}, {"time": 3253, "text": "So like, if you actually want to practically help somehow, you're going to convince yourself that you can't, one person can't possibly help."}, {"time": 3262, "text": "And then you have a family, so you want to make, you know, you want to protect your family."}, {"time": 3265, "text": "You tell all these stories and over time, it, you naturally convince yourself to dehumanize the other."}, {"time": 3272, "text": "Yeah, I think about this a lot, mostly because I worry that I wouldn't be a good German."}, {"time": 3282, "text": "Yeah, no, no, that's right, that's right."}, {"time": 3284, "text": "And one of the, you know, one of my tasks as a teacher, right, our students, and I have, you know, classes on genocide, I have one now."}, {"time": 3295, "text": "And another one, by the way, on Stalin."}, {"time": 3298, "text": "But the one on genocide, you know, one of my tasks is to try to get the students to understand this is not about weird people who live far away in time and in place, but it's about them, you know?"}, {"time": 3312, "text": "And that, you know, that's a hard lesson, but it's an important one, you know, that this is in all of us, you know, it's in all of us."}, {"time": 3320, "text": "And there's nothing, you know, and you just try to gird yourself up, you know, to try to figure out ways that maybe you won't be complicit."}, {"time": 3329, "text": "And that you learn how to stand by your principles, but it's very hard, it's extremely difficult."}, {"time": 3336, "text": "And you can't, the other interesting thing about it is it's not predictable."}, {"time": 3340, "text": "Now, there's, they've done a lot of studies of Poles, for example, who during the war saved Jews, you know?"}, {"time": 3345, "text": "Well, who are the Poles who saved Jews versus those who turned them in?"}, {"time": 3350, "text": "It's completely unpredictable."}, {"time": 3351, "text": "You know, sometimes it's the worst anti Semites who protect them because they don't believe they should be killed, right?"}, {"time": 3357, "text": "And sometimes, you know, it's not predictable."}, {"time": 3361, "text": "It's not as if the humanists among us, you know, are the ones who, you know, consistently show up, you know, and experience danger, in other words, and are ready to take on danger to defend, you know, your fellow human beings."}, {"time": 3379, "text": "I mean, sometimes simple people do it, and sometimes they do it for really simple reasons."}, {"time": 3384, "text": "And sometimes, people you would expect to do it don't."}, {"time": 3389, "text": "And you've got that mix, and it's just not predictable."}, {"time": 3393, "text": "One thing I've learned in this age of social media is it feels like the people with integrity and the ones who would do the right thing are the quiet ones."}, {"time": 3404, "text": "In terms of humanists, in terms of activists, there's so many points to be gained of declaring that you would do the right thing."}, {"time": 3413, "text": "It's the simple, quiet folks."}, {"time": 3418, "text": "Because I've seen quite, on a small, obviously much smaller scale, just shows of integrity and character."}, {"time": 3425, "text": "When there was sacrifice to be made and it was done quietly."}, {"time": 3429, "text": "Now, sort of the small heroes, those are, you're right, it's surprising, but they're often quiet."}, {"time": 3437, "text": "That's why I'm distrustful of people who kind of proclaim that they would do the right thing."}, {"time": 3443, "text": "And there are different kinds of integrity, too."}, {"time": 3445, "text": "I mean, I edited a memoir of a Polish underground fighter, member of the underground who was in Majdanek in the concentration camp at Majdanek."}, {"time": 3458, "text": "You know, and it was just an interesting mix of different kinds of integrity."}, {"time": 3463, "text": "You know, on the one hand, it really bothered him deeply when Jews were killed or sent to camp or that sort of thing."}, {"time": 3473, "text": "On the other hand, he was something of an anti Semite."}, {"time": 3476, "text": "You know, he would, you know, sometimes if Jews were his friends, he would help them."}, {"time": 3482, "text": "And if they weren't, sometimes he was really mean to them."}, {"time": 3486, "text": "You know, and you could, in their various levels, you know, a concentration camp is a terrible social experiment in some ways, right?"}, {"time": 3495, "text": "But you learn a lot from how people behave."}, {"time": 3499, "text": "And what you see is that, you know, people behave sometimes extraordinarily well in some situations and extraordinarily poorly in others."}, {"time": 3506, "text": "And it's mixed and you can't predict it."}, {"time": 3508, "text": "And it's hard to find consistency."}, {"time": 3512, "text": "I mean, that's the other thing."}, {"time": 3513, "text": "It's, you know, I think we claim too much consistency for the people we study and the people we think about in the past."}, {"time": 3520, "text": "You know, they're not consistent any more than we are consistent, right?"}, {"time": 3525, "text": "Well, let me ask you about human nature here on both sides."}, {"time": 3528, "text": "So first, what have you learned about human nature from studying genocide?"}, {"time": 3534, "text": "Why do humans commit genocide?"}, {"time": 3536, "text": "What lessons, first of all, why is a difficult question, but what insights do you have into humans that genocide is something that happens in the world?"}, {"time": 3547, "text": "That's a really big and difficult question, right?"}, {"time": 3550, "text": "And it has to be parsed, I think, into different kinds of questions."}, {"time": 3556, "text": "You know, why does genocide happen?"}, {"time": 3559, "text": "You know, which the answer there is frequently political, meaning, you know, why Hitler ended up killing the Jews."}, {"time": 3568, "text": "Well, it had a lot to do with the political history of Germany and wartime history of Germany, right?"}, {"time": 3575, "text": "In the 30s, and, you know, it's traceable to then."}, {"time": 3580, "text": "No, like you mentioned it yourself, you can't imagine Hitler in the mid 20s turning into anything of the kind of dictator he ended up being and the kind of murderer, mass murderer he ended up being."}, {"time": 3595, "text": "So, and the same thing goes, by the way, for Stalin and Soviet Union and Pol Pot."}, {"time": 3601, "text": "I mean, these are all essentially political movements where the polity state is seized, you know, by a ideological or, you know, party, single party movement and then is moved in directions where mass killing takes place."}, {"time": 3618, "text": "The other question, you know, let's separate that question out."}, {"time": 3622, "text": "The other question is why do ordinary people participate?"}, {"time": 3626, "text": "Because the fact of the matter is, just ordering genocide is not enough."}, {"time": 3633, "text": "Just saying, you know, go get them is not enough."}, {"time": 3636, "text": "There have to be people who will cooperate and who will do their jobs, you know, both at the kind of mezzo level, the middle level of a bureaucracy, but also at the everyday level."}, {"time": 3647, "text": "You know, people who have to pull the triggers and that kind of thing and, you know, force people into the gas chamber and grab people, you know, in Kiev in September 1941 at Babin Yar and push them, you know, towards the ravine where the machine gunners are gonna shoot them down."}, {"time": 3663, "text": "You know, and those are all different questions."}, {"time": 3666, "text": "The question of, you know, especially the lower level people who actually do the killing is a question which I think we've been talking about, which is that within all of us, you know, is the capability of being murderers and mass murderers."}, {"time": 3682, "text": "I mean, to participate in mass murder."}, {"time": 3685, "text": "I won't call them laws of social psychology, but the character of social psychology."}, {"time": 3691, "text": "You know, we will do it in most cases."}, {"time": 3693, "text": "I mean, one of the shocking things that I learned just a few years ago studying the Holocaust is that you could pull out."}, {"time": 3701, "text": "In other words, if they order a police battalion to go shoot Jews, you didn't have to do it."}, {"time": 3708, "text": "You could pull out."}, {"time": 3709, "text": "They weren't gonna, they never killed anybody."}, {"time": 3711, "text": "They never executed anybody."}, {"time": 3713, "text": "They never even punished people for saying, no, I'm not gonna do that."}, {"time": 3716, "text": "So people are doing it voluntarily."}, {"time": 3718, "text": "They may not want to do it."}, {"time": 3721, "text": "You know, they give them booze to try to, you know, numb the pain of murder, because they know there is pain."}, {"time": 3728, "text": "I mean, people experience pain when they murder people, but they don't pull out."}, {"time": 3733, "text": "And so it's the character of who we are in the society, in groups, and we're very, very influenced."}, {"time": 3740, "text": "I mean, we're highly influenced by the groups in which we operate."}, {"time": 3744, "text": "And, you know, who we talk to, and who our friends are within that group, and who is the head of the group."}, {"time": 3752, "text": "And I mean, you see this even, I mean, you see it in any group, you know, whether it's in the academy, right, at Stanford, or whether it's, you know, in a labor union, or whether it's in a church group in Tennessee, or wherever, you know, people pay attention to each other, and they are unwilling, frequently, to say no."}, {"time": 3776, "text": "Even though all of you think it's right, it's wrong."}, {"time": 3778, "text": "I mean, you just don't do that, usually, especially in societies that are authoritarian, or totalitarian, right?"}, {"time": 3788, "text": "Because it's harder, because there's a backup to it, right?"}, {"time": 3790, "text": "There's the NKVD there, or there's the Gestapo there, and there are other people there."}, {"time": 3794, "text": "So you just, you know, they may not be forcing you to do it, but your social being, plus this danger in the distance, you know, you do it."}, {"time": 3808, "text": "But then, if you go up the hierarchy, at the very top, there's a dictator."}, {"time": 3813, "text": "Presumably, you know, you go to, like, middle management to the bureaucracy."}, {"time": 3819, "text": "The higher you get up there, the more power you have to change the direction of the Titanic."}, {"time": 3826, "text": "But nobody seems to do it."}, {"time": 3829, "text": "Right, or what happens, and it does happen."}, {"time": 3832, "text": "It happens in the German army."}, {"time": 3834, "text": "I mean, it happens in the case of the Armenian genocide, where we know there are governors who said, no, I'm not gonna kill Armenians."}, {"time": 3841, "text": "What kind of business is this?"}, {"time": 3842, "text": "They're just removed."}, {"time": 3844, "text": "They're removed, and you find a replacement very easily."}, {"time": 3847, "text": "So, you know, you do see people who stand up."}, {"time": 3850, "text": "And again, it's not really predictable who it will be."}, {"time": 3853, "text": "I would maintain."}, {"time": 3854, "text": "I mean, I haven't done the study of the Armenian governors who said no."}, {"time": 3859, "text": "I mean, the Turkish governors who said no to the Armenian genocide."}, {"time": 3863, "text": "But, you know, there are people who do step aside every once in a while in the middle level."}, {"time": 3871, "text": "And again, they're German generals who say, wait a minute, what is this business in Poland when they start to kill Jews or in Belorussia?"}, {"time": 3877, "text": "And, you know, they're just pushed aside."}, {"time": 3880, "text": "You know, if they don't do their job, they're pushed aside."}, {"time": 3882, "text": "Or they end up doing it."}, {"time": 3884, "text": "And they usually do end up doing it."}, {"time": 3887, "text": "What about on the victim side?"}, {"time": 3889, "text": "So, I mentioned man's search for meaning."}, {"time": 3892, "text": "What can we learn about human nature, the human mind from the victims of genocide?"}, {"time": 3899, "text": "So, Viktor Frankl talked about the ability to discover meaning and beauty, even in suffering."}, {"time": 3907, "text": "Is there something to be said about, you know, in your studying of genocide that you've learned about human nature?"}, {"time": 3915, "text": "Well, again, I don't, I have to say, I come out of the study of genocide with a very pessimistic view of human nature."}, {"time": 3924, "text": "A very pessimistic view."}, {"time": 3925, "text": "Even on the victim side?"}, {"time": 3926, "text": "Even on the victim side."}, {"time": 3928, "text": "I mean, the victims will eat their children, right?"}, {"time": 3933, "text": "Ukrainian case, they have no choice."}, {"time": 3936, "text": "You know, the victims will rob each other."}, {"time": 3938, "text": "The victims will form hierarchies within victimhood."}, {"time": 3944, "text": "So, you see, let me give you an example."}, {"time": 3946, "text": "Again, I told you I was working on Majdanek."}, {"time": 3950, "text": "And there's, in Majdanek, at a certain point in 42, a group of Slovak Jews were arrested and sent to Majdanek."}, {"time": 3964, "text": "Those Slovak Jews were a group, somehow they stuck together, they were very competent, they were, you know, many of them were businessmen, they knew each other, and for a variety of different reasons within the camp."}, {"time": 3979, "text": "And again, this shows you the diversity of the camps and also, you know, these images of black and white in the camps are not very useful."}, {"time": 3986, "text": "They ruled the camp."}, {"time": 3989, "text": "I mean, they basically had all the important jobs in the camp, including jobs like beating other Jews, and persecuting other Jews, and persecuting other peoples, which they did."}, {"time": 4003, "text": "And this Polish guy who I mentioned to you, who wrote this memoir, hated them because of what they were doing to the Poles, right?"}, {"time": 4013, "text": "And he, you know, he's incensed because aren't these supposed to be the Untermenschen?"}, {"time": 4021, "text": "He says, and look what they're doing, they're treating us, you know, like dirt."}, {"time": 4026, "text": "And they do, they treat them like dirt."}, {"time": 4028, "text": "So, you know, in this kind of work on Majdanek, there's certainly parts of it that, you know, were inspiring, you know, people helping each other, people trying to feed each other, people giving warmth to each other."}, {"time": 4044, "text": "You know, there's some very heroic Polish women who end up having a radio show called Radio Majdanek, which they put on every night in the women's camp, which is, you know, to raise people's spirits."}, {"time": 4059, "text": "And they, you know, sing songs and do all this kind of stuff, you know, to try to keep themselves from, you know, the horrors that they're experiencing around them."}, {"time": 4071, "text": "And so you do see that, and you do see, you know, human beings acting in support of each other."}, {"time": 4080, "text": "But, you know, I mean, Primo Levi is one of my favorite writers about the Holocaust and about the camps."}, {"time": 4090, "text": "And, you know, I don't think Primo Levi saw anything."}, {"time": 4095, "text": "You know, I mean, he had pals, you know, who he helped and who helped him."}, {"time": 4100, "text": "I mean, but he describes this kind of, you know, terrible inhuman environment, which no one can escape, really, no one can escape."}, {"time": 4110, "text": "He ends up committing suicide too, I think, because of his sense of, we don't know exactly why, but probably because of his sense of what happened in the camp."}, {"time": 4121, "text": "I mean, later he goes back to Italy, becomes a writer and that sort of thing."}, {"time": 4124, "text": "So I don't, I don't, especially in the concentration camps, it's really hard to find places like Wickel Frankel where you can say, you know, I am moved in a positive way, you know, by what happened."}, {"time": 4142, "text": "There were cases, there's no question."}, {"time": 4144, "text": "People hung together, they tried to help each other, but, you know, they were totally, totally caught in this web of genocide."}, {"time": 4155, "text": "See, so there are stories, but the thing is, I have this sense, maybe it's a hope, that within most, if not every human heart, there's a kind of, like, flame of compassion and kindness and love that waits, that longs to connect with others, that ultimately en masse overpowers everything else."}, {"time": 4181, "text": "If you just look at the story of human history, the resistance to violence and mass murder and genocide feels like a force that's there."}, {"time": 4194, "text": "And it feels like a force that's more powerful than whatever the dark momentum that leads to genocide is."}, {"time": 4204, "text": "It feels like that's more powerful, it's just quiet."}, {"time": 4208, "text": "It's hard to tell the story of that little flame that burns within all of our hearts, that longing to connect to other human beings."}, {"time": 4216, "text": "And there's something also about human nature and us as storytellers, that we're not very good at telling the stories of that little flame."}, {"time": 4224, "text": "We're much better at telling the stories of atrocities."}, {"time": 4227, "text": "No, you know, I think maybe I fundamentally disagree with you, I think maybe I fundamentally, I don't disagree that there is that flame."}, {"time": 4236, "text": "I just think it's just too easily doused."}, {"time": 4238, "text": "And I think it's too easily goes out in a lot of people."}, {"time": 4243, "text": "And I mean, like I say, I come away from this work, a pessimist."}, {"time": 4250, "text": "You know, there is this work by a Harvard psychologist, now I'm forgetting his name."}, {"time": 4255, "text": "Stephen Pinker."}, {"time": 4256, "text": "Yes, yes, Stephen Pinker, that shows over time, you know, and you know, initially I was quite skeptical of the work, but in the end, I thought he was quite convincing that over time, the incidence of homicide, you know, goes down, the incidence of rape goes down, the incidence of genocide, except for the big blip, you know, in the middle of the 20th century goes down."}, {"time": 4282, "text": "Not markedly, but it goes down generally, that you know, more than norms, international norms are changing how we think about this and stuff like that."}, {"time": 4290, "text": "I thought he was pretty convincing about that."}, {"time": 4293, "text": "But think about, you know, we're modern people."}, {"time": 4297, "text": "I mean, we've advanced so fast in so many different areas."}, {"time": 4301, "text": "I mean, we should have eliminated this a long time ago, a long time ago."}, {"time": 4307, "text": "You know, how is it that, you know, we're still facing this business of genocide in Myanmar, in Xinjiang, in, you know, Tigray, in Ethiopia, you know, the potentials of genocide there."}, {"time": 4322, "text": "And all over the world, you know, we still have this thing that we cannot handle, that we can't deal with."}, {"time": 4330, "text": "And, you know, again, you know, electric cars and planes that fly from here to, you know, Beijing."}, {"time": 4338, "text": "Think about the differences between 250 years ago or 300 years ago and today, but the differences in genocide are not all that great."}, {"time": 4346, "text": "I mean, the incidence has gone down."}, {"time": 4348, "text": "I think Pinker has demonstrated, I mean, there are problems with his methodology, but on the whole, I'm with him on that book."}, {"time": 4355, "text": "I thought in the end, it was quite well done."}, {"time": 4358, "text": "So, you know, I do not, I have to say, I'm not an optimist about what this human flame can do."}, {"time": 4402, "text": "Well, we carry the capacity to love too."}, {"time": 4404, "text": "Yes, we do, yes, we do."}, {"time": 4408, "text": "You have a bias in that you have studied some of the darker aspects of human nature and human history."}, {"time": 4416, "text": "So it is difficult from the trenches, from the muck, to see a possible sort of way out through love."}, {"time": 4426, "text": "But it's not obvious that that's not the case."}, {"time": 4430, "text": "You mentioned electric cars and rockets and airplanes."}, {"time": 4434, "text": "To me, the more powerful thing is Wikipedia, the internet."}, {"time": 4438, "text": "Only 50% of the world currently has access to the internet, but that's growing in information and knowledge and wisdom, especially among women in the world."}, {"time": 4484, "text": "And just even studying the fact that the Holocaust happened for a large number of people is a powerful preventer of future genocide."}, {"time": 4495, "text": "One of the lessons of history is just knowing that this can happen, learning how it happens, that normal human beings, leaders that give big promises, can also become evil and destructive."}, {"time": 4509, "text": "The fact, knowing that that can happen is a powerful preventer of that, and then you kind of wake up from this haze of believing everything you hear, and you learn to just, in your small, local way, to put more love out there in the world."}, {"time": 4528, "text": "I believe it's possible, it's not too good, sort of to push back, it's not so obvious to me that in the end, I think in the end, love wins."}, {"time": 4540, "text": "That's my intuition, I've had to put money on it."}, {"time": 4543, "text": "I have a sense that this genocide thing is more and more going to be an artifact of the past."}, {"time": 4551, "text": "Well, I certainly hope you're right."}, {"time": 4553, "text": "I mean, I certainly hope you're right."}, {"time": 4554, "text": "And it could be you are, we don't know."}, {"time": 4560, "text": "But the evidence is different."}, {"time": 4564, "text": "The evidence is different."}, {"time": 4565, "text": "And the capacity of human beings to do evil to other human beings is repeatedly demonstrated."}, {"time": 4577, "text": "Whether it's in massacres in Mexico, or ISIS and the Yazidi Kurds, or you can just go on and on."}, {"time": 4587, "text": "Syria, I mean, look what, I mean, Syria used to be a country, and now it's been a mass grave, and people then have left in the millions for other places."}, {"time": 4601, "text": "And you know, I'm not saying, you know, I'm not saying, I mean, the Turks have done nice things for the Syrians, and the Germans welcomed in a million or so, and actually reasonably absorbed them."}, {"time": 4613, "text": "I mean, I'm not saying bad things only happen in the world."}, {"time": 4617, "text": "They're good and bad things that happen, you're absolutely right."}, {"time": 4622, "text": "But I don't think we're on the path to eliminating these bad things, really bad things from happening."}, {"time": 4630, "text": "I just don't think we are."}, {"time": 4631, "text": "And I don't think there's any, I don't think the facts demonstrate it."}, {"time": 4635, "text": "I mean, I hope, I hope you're right."}, {"time": 4637, "text": "But I think otherwise, it's just an article of faith."}, {"time": 4643, "text": "You know, which is perfectly fine."}, {"time": 4645, "text": "It's better to have that article of faith than to have an article of faith which says, you know, things should get bad, or things like that."}, {"time": 4652, "text": "Well, it's not just fine."}, {"time": 4653, "text": "It's the only way if you want to build a better future."}, {"time": 4656, "text": "So optimism is a prerequisite for engineering a better future."}, {"time": 4660, "text": "So like, okay, so a historian has to see clearly into the past."}, {"time": 4666, "text": "An engineer has to imagine a future that's different from the past, that's better than the past."}, {"time": 4675, "text": "Because without that, they're not going to be able to build a better future."}, {"time": 4679, "text": "So there's a kind of saying, like you have to consider the facts."}, {"time": 4682, "text": "Well, at every single moment in history, if you allow yourself to be too grounded by the facts of the past, you're not going to create the future."}, {"time": 4692, "text": "So that's kind of the tension that we're living with."}, {"time": 4695, "text": "To have a chance, we have to imagine that the better future is possible."}, {"time": 4699, "text": "But one of the ways to do that is to study history."}, {"time": 4703, "text": "Which engineers don't do enough of."}, {"time": 4705, "text": "They do not."}, {"time": 4706, "text": "Which is a real problem."}, {"time": 4709, "text": "It's a real problem."}, {"time": 4710, "text": "Or basically a lot of disciplines in science and so on don't do enough of."}, {"time": 4716, "text": "Can you tell the story of China from 1958 to 1962, what was called the Great Leap Forward, orchestrated by Chairman Mao Zedong that led to the deaths of tens of millions of people making it arguably the largest famine in human history?"}, {"time": 4735, "text": "I mean, it was a terrible set of events that led to the death."}, {"time": 4742, "text": "People will dispute the numbers."}, {"time": 4747, "text": "15 million, 17 million, 14 million, 20 million people died in the Great Leap."}, {"time": 4755, "text": "Many people say 30, 40, 50 million."}, {"time": 4757, "text": "Some people will go that high too."}, {"time": 4761, "text": "Essentially, Mao and the Communist Party leadership, but it was mostly Mao's doing, decided he wanted to move the country into communism."}, {"time": 4773, "text": "And part of the idea of that was rivalry with the Soviet Union."}, {"time": 4779, "text": "Mao was a good Stalinist, or at least felt like Stalin was the right kind of communist leader to have, and he didn't like Khrushchev at all, and he didn't like what he thought were Khrushchev's reforms and also Khrushchev's pretensions to moving the Soviet Union into communism."}, {"time": 4797, "text": "So Khrushchev started talking about giving more power to the party, less power to the state, and if you have more power to the party versus the state, then you're moving into communism quicker."}, {"time": 4807, "text": "So what Mao decided to do was to engage in this vast program of building what were called people's communes."}, {"time": 4816, "text": "And these communes were enormous conglomerations of essentially collective farms, and what would happen on those communes is there would be places for people to eat, and there would be places for the kids to be raised in essentially kind of separate homes, and they would be schooled."}, {"time": 4839, "text": "Everybody would turn over their metal, which was one of the, actually it turned out to be a terribly negative phenomenon, their metal pots and pans to be melted to then make steel."}, {"time": 4851, "text": "Every of these big communes would all have little steel plants and they would build steel and the whole countryside would be transformed."}, {"time": 4861, "text": "Well, like many of these sort of, I mean a true megalomaniac project, like some of Stalin's projects too."}, {"time": 4870, "text": "And this particular project then, the people had no choice."}, {"time": 4875, "text": "They were forced to do this."}, {"time": 4878, "text": "It was incredibly dysfunctional for Chinese agriculture and ended up creating, as you mentioned, a terrible famine that everybody understood was a famine as a result of this."}, {"time": 4896, "text": "I mean, there were also some problems of nature at the same time and some flooding and bad weather and that sort of thing, but it was really a manmade famine."}, {"time": 4906, "text": "And Mao said at one point, who cares if millions die?"}, {"time": 4912, "text": "It just doesn't matter."}, {"time": 4913, "text": "We've got millions more left."}, {"time": 4915, "text": "I mean, he would periodically say things like this that showed that like Stalin, he had total indifference to the fact that people were dying in large numbers."}, {"time": 4926, "text": "It led again to cannibalism and to terrible wastage all over the country and millions of people died and there was just no stopping it."}, {"time": 4938, "text": "There were people in the party who began to kind of edge towards telling Mao this wasn't a great idea and that he should back off, but he wouldn't back off."}, {"time": 4948, "text": "And the result was catastrophe in the countryside and all these people dying."}, {"time": 4953, "text": "And then compounding the problem was the political elite, which then if peasants would object or if certain people would say, no, they'd beat the hell out of them."}, {"time": 4965, "text": "They would beat people who didn't do what they wanted them to do."}, {"time": 4969, "text": "So it was really, really a horrific set of events on the Chinese countryside."}, {"time": 4979, "text": "I mean, and people wrote about it."}, {"time": 4982, "text": "I mean, we learned about it."}, {"time": 4984, "text": "There were people who were keeping track of what was going on and eventually wrote books about it."}, {"time": 4989, "text": "So we have, I mean, we have pretty good documentation, not so much on the numbers."}, {"time": 4994, "text": "Numbers are always a difficult problem."}, {"time": 4997, "text": "I'm facing this problem, by the way, this is a little bit separate with the Holodomor, where Ukrainians are now claiming 11.5 million people died in Holodomor."}, {"time": 5007, "text": "And most people assume it's somewhere in the neighborhood of four million, 4.5 million maybe."}, {"time": 5013, "text": "So you have wildly different numbers that come out."}, {"time": 5016, "text": "Then we have different kinds of numbers, as you mentioned too, with the Great Leap Forward."}, {"time": 5021, "text": "So it was a huge catastrophe for China and now only backed off when he had to."}, {"time": 5027, "text": "And then revived a little bit with the Red Guards Movement later on when he was upset that the bureaucracy was resisting him a little bit when it came to the Great Leap."}, {"time": 5041, "text": "But he had to back off."}, {"time": 5043, "text": "It was such a terrible catastrophe."}, {"time": 5045, "text": "So one of the things about numbers is that you usually talk about deaths, but with the famine, with starvation, the thing I often think about that's impossible to put into numbers is the number of people and the degree to which they were suffering."}, {"time": 5064, "text": "You know, the number of days spent in suffering."}, {"time": 5068, "text": "Oh yeah, oh yeah."}, {"time": 5070, "text": "And so, I mean, death is, death is just one of the consequences of suffering."}, {"time": 5079, "text": "To me, it feels like one, two, three years or months and then years of not having anything to eat is worse."}, {"time": 5091, "text": "And those aren't put into numbers often."}, {"time": 5096, "text": "And the effect on people long term, you know, in terms of their mental health, in terms of their physical health, their ability to work, all those kinds of things."}, {"time": 5105, "text": "I mean, Ukrainians are working on, there are people working on this subject now."}, {"time": 5109, "text": "You know, the longterm effect of the hunger famine on them."}, {"time": 5113, "text": "And I'm sure there's a similar kind of longterm effect on Chinese peasantry of what happened."}, {"time": 5118, "text": "You know, I mean, you're destroying."}, {"time": 5120, "text": "Multigenerational."}, {"time": 5121, "text": "Yes, multigenerational."}, {"time": 5123, "text": "And you know, it's a really, you're absolutely right."}, {"time": 5126, "text": "This is a terrible, terrible way to die."}, {"time": 5129, "text": "And it lasts a long time."}, {"time": 5131, "text": "And sometimes you don't die, you survive, but you know, in the kind of shape where you can't do anything."}, {"time": 5139, "text": "I mean, you can't function."}, {"time": 5142, "text": "Now your brain's been injured, you know."}, {"time": 5144, "text": "I know it's a really, these famines are really horrible."}, {"time": 5150, "text": "So when you talk about genocide, it's often talking about murder."}, {"time": 5152, "text": "Where do you place North Korea in this discussion?"}, {"time": 5155, "text": "We kind of mentioned it."}, {"time": 5156, "text": "So in the, what is it?"}, {"time": 5158, "text": "The Arduous March of the 1990s, where it was mass starvation."}, {"time": 5168, "text": "Many people describe mass starvation going on now in North Korea."}, {"time": 5173, "text": "When you think about genocide, when you think about atrocities going on in the world today, where do you place North Korea?"}, {"time": 5180, "text": "So take a step back."}, {"time": 5182, "text": "When the, there were all these courts that were set up for Bosnia and for Rwanda and for other genocides in the 1990s."}, {"time": 5194, "text": "And then the decision was made by the international community, UN basically, to set up the International Criminal Court, which would then try genocide in the more modern period and the more contemporary period."}, {"time": 5209, "text": "And the ICC lists three crimes basically."}, {"time": 5214, "text": "The genocide crimes against humanity and war crimes."}, {"time": 5223, "text": "And subsumed to crimes against humanity are a lot of the kinds of things you're talking about with North Korea."}, {"time": 5230, "text": "I mean, it's torture, it's artificial, sometimes artificial famine or famine, that is not necessary, right?"}, {"time": 5241, "text": "Not necessary to have it."}, {"time": 5242, "text": "And there are other kinds of, you know, mass rape and stuff like that."}, {"time": 5248, "text": "There are other kinds of things that fit into the crimes against humanity."}, {"time": 5253, "text": "And that's sort of where I think about North Korea as committing crimes against humanity, not genocide."}, {"time": 5259, "text": "And again, remember, genocide is meant to be, I mean, some people, there's a disagreement among scholars and jurists about this."}, {"time": 5268, "text": "Some people think of genocide as the crime of crimes, the worst of the three that I just mentioned."}, {"time": 5275, "text": "But some think of them as co equal."}, {"time": 5276, "text": "And the ICC, the International Criminal Court, is dealing with them more or less as co equal, even though we tend to think of genocide as the worst."}, {"time": 5286, "text": "So I mean, what I'm trying to say is that, you know, I don't wanna split hairs."}, {"time": 5291, "text": "I think it's sort of morally and ethically unseemly, you know, the split hairs about what is genocide, what is the crime against humanity."}, {"time": 5300, "text": "You know, this is for lawyers, not for historians."}, {"time": 5302, "text": "But terminology wise."}, {"time": 5304, "text": "Yeah, yeah, you know, you don't wanna get into that."}, {"time": 5308, "text": "Because it, I mean, it happened with Darfur a little bit, where the Bush administration had declared that Darfur was a genocide."}, {"time": 5317, "text": "And the UN said, no, no, it wasn't genocide, it was a crime against humanity."}, {"time": 5323, "text": "And then, you know, that confused things versus clarified them."}, {"time": 5327, "text": "I mean, we damn well knew what was happening."}, {"time": 5329, "text": "People were being killed and being attacked."}, {"time": 5332, "text": "And so, you know, on the one hand, I think the whole concept and the way of thinking about history using genocide as an important part of human history is crucial."}, {"time": 5348, "text": "On the other hand, I don't like to, you know, get involved in the hair splitting, what's genocide and what's not."}, {"time": 5355, "text": "So that, you know, North Korea, I tend to think of, like I said, as committing crimes against humanity and, you know, forcibly incarcerating people, torturing them, that kind of thing."}, {"time": 5368, "text": "You know, routinely incarcerating, depriving them of certain kinds of human rights can be considered a crime against humanity."}, {"time": 5375, "text": "But I don't think of it in the same way I think about genocide, which is an attack on a group of people."}, {"time": 5380, "text": "Let me just leave it at that."}, {"time": 5382, "text": "What in this, if we think about, if it's okay, can we loosely use the term genocide here, just let's not play games with terminology."}, {"time": 5390, "text": "Just bad crimes against humanity."}, {"time": 5396, "text": "Of particular interest are the ones that are going on today still, because it raises the question to us, what do people outside of this, what role do they have to play?"}, {"time": 5409, "text": "So what role does the United States, or what role do I, as a human being who has food today, who has shelter, who has a comfortable life, what role do I have when I think about North Korea, when I think about Syria, when I think about maybe the Uighur population in China?"}, {"time": 5433, "text": "Well, I mean, the role is the same role I have, which is to teach and to learn and to get the message out that this is happening, because the more people who understand it, the more likely it is that the United States government will try to do something about it, within the context of who we are and where we live, right?"}, {"time": 5456, "text": "And so, I write books, you do shows, or maybe you write books too, I don't know."}, {"time": 5464, "text": "I do not write books, but I tweet."}, {"time": 5468, "text": "Okay, that's good too."}, {"time": 5469, "text": "Ineloquently, but that's not the, I guess that's not the, yes, so certainly this is true."}, {"time": 5474, "text": "And in terms of a voice, in terms of words, in terms of books, you are, I would say, a rare example of somebody that has powerful reach with words."}, {"time": 5485, "text": "But I was also referring to actions."}, {"time": 5488, "text": "In the United States government, what are the options here?"}, {"time": 5491, "text": "So, war has costs, and war seems to be, as you have described, sort of potentially increase the atrocity, not decrease it."}, {"time": 5504, "text": "If there's anything that challenges my hope for the future is the fact that sometimes we're not powerless to help, but very close to powerless to help, because trying to help can often lead to, in the near term, more negative effects than positive effects."}, {"time": 5525, "text": "I mean, the unintended consequences of what we do can frequently be as bad, if not worse, than trying to relieve the difficulties that people are having."}, {"time": 5537, "text": "So I think you're caught a little bit, but it's also true, I think, that we can be more forceful."}, {"time": 5545, "text": "I think we can be more forceful without necessarily war."}, {"time": 5549, "text": "There is this idea of the so called responsibility to protect, and this was an idea that came up after Kosovo, which was what, 1999, and when the Serbs looked like they were going to engage in a genocidal program in Kosovo, and it was basically a program of ethnic cleansing, but it could have gone bad and gotten worse, not just driving people out, but beginning to kill them."}, {"time": 5579, "text": "And the United States and Britain and others intervened."}, {"time": 5585, "text": "And Russians were there too, as you probably recall."}, {"time": 5588, "text": "And I think correctly, people have analyzed this as a case in which genocide was prevented or stopped."}, {"time": 5599, "text": "In other words, the Serbs were stopped in their tracks."}, {"time": 5602, "text": "I mean, some bad things did happen."}, {"time": 5603, "text": "We bombed Belgrade and the Chinese embassy and things like that."}, {"time": 5607, "text": "But it was stopped, and following upon that, then there was a kind of international consensus that we needed to do something."}, {"time": 5616, "text": "I mean, because of Rwanda, Bosnia, and the positive example of Kosovo, right?"}, {"time": 5622, "text": "That genocide did not happen in Kosovo."}, {"time": 5626, "text": "I think that argument has been substantiated."}, {"time": 5630, "text": "Anyway, and this notion of the, or this doctrine or whatever, of the responsibility to protect them was adopted by the UN in 2005, unanimously."}, {"time": 5646, "text": "And what it says is there's a hierarchy of measures that should be, well, let me take a step back."}, {"time": 5654, "text": "It starts with the principle that sovereignty of a country is not, you don't earn it just by being there and being your own country."}, {"time": 5667, "text": "You have to earn it by protecting your people."}, {"time": 5670, "text": "So every, this was all agreed with all the nations of the UN agreed, Chinese and Russians too, that sovereignty is there because you protect your people against various depredations, right?"}, {"time": 5686, "text": "Including genocide, crimes against humanity, forced imprisonment, torture, and that sort of thing."}, {"time": 5692, "text": "If you violate that justification for your sovereignty, that you're protecting your people, that you're not protecting them, the international community has the obligation to do something about it, all right?"}, {"time": 5709, "text": "Now, then they have a kind of hierarchy of things you can do, you know, starting with, I mean, I'm not quoting exactly, but, you know, starting with kind of push and pull, you know, trying to convince people, don't do that, you know, to Myanmar, don't do that to the Rohingya people, right?"}, {"time": 5727, "text": "Then it goes down the list, you know, and you get to sanctions or threatening sanctions and then sanctions, you know, like we have against Russia, but you go down the list, right?"}, {"time": 5738, "text": "You go down the list and eventually you get to military intervention at the bottom, which they say is the last thing, you know, and you really don't wanna do that."}, {"time": 5750, "text": "And not only do you not wanna do it, but it, just as you said, just as you pointed out, it can have unintended consequences, right?"}, {"time": 5758, "text": "And we'll do everything we can short, you know, of military intervention, but, you know, if necessary, that can be undertaken as well."}, {"time": 5769, "text": "And so the responsibility to predict, I think, is, you know, it was not implementable."}, {"time": 5776, "text": "Oh, one of the things it says in this last category, right?"}, {"time": 5780, "text": "The military intervention is that the intervention cannot create more damage than it relieves, right?"}, {"time": 5789, "text": "And so for Syria, we came to the conclusion, you know, that, I mean, the international community in some ways said this in so many words, even though the Russians were there, obviously, we ended up being there and that sort of thing, but the international community basically said, you know, there's no way you can intervene in Syria."}, {"time": 5808, "text": "You know, there's just no way without causing more damage, you know, than you would relieve."}, {"time": 5814, "text": "So, you know, in some senses, that's what the international community is saying about, you know, Xinjiang and the Uighurs too."}, {"time": 5822, "text": "You know, I mean, you can't even imagine what hell would break loose if there was some kind of military trouble, you know, to threaten the Chinese with."}, {"time": 5832, "text": "But you can go down that list with the, you know, the military leadership of Myanmar, and you can go down that list with the Chinese Communist Party, and you can go down the list, you know, with others who are threatening, you know, with Ethiopia and what it's doing in Tigray."}, {"time": 5853, "text": "And, you know, you can go down that list and start pushing."}, {"time": 5857, "text": "I think what happened, you know, there was more of a willingness in the 90s, and in, you know, right at the turn of the century, you know, to do these kinds of things."}, {"time": 5870, "text": "And then, you know, when Trump got elected and, you know, he basically said, you know, America first and out of the world, we're not gonna do any of this kind of stuff."}, {"time": 5878, "text": "And now Biden has the problem of trying to rebuild consensus on how you deal with these kinds of things."}, {"time": 5886, "text": "I think it's not impossible."}, {"time": 5888, "text": "I mean, here I tend to be maybe more of an optimist than you."}, {"time": 5892, "text": "You know, I think it's not impossible that the international community can, you know, muster some internal fortitude and push harder, short of war, you know, to get the Chinese and to get the, again, Myanmar, and to get others to kind of back off of violations of people's rights the way they are routinely doing it."}, {"time": 5918, "text": "So that's in the space of geopolitics."}, {"time": 5919, "text": "That's the space of politicians and UN and so on."}, {"time": 5922, "text": "The interesting thing about China, and this is a difficult topic, but there's so many financial interests that not many voices with power and with money speak up, speak out against China because it's a very interesting effect because it costs a lot for an individual to speak up because you're going to suffer."}, {"time": 5953, "text": "I mean, China just cuts off the market."}, {"time": 5956, "text": "Like if you have a product, if you have a company and you say something negative, China just says, okay, well then they knock you out of the market."}, {"time": 5965, "text": "And so any person that speaks up, they get shut down immediately financially."}, {"time": 5969, "text": "It's a huge cost, sometimes millions or billions of dollars."}, {"time": 5973, "text": "And so what happens is everybody of consequences, sort of financially, everybody with a giant platform is extremely hesitant to speak out."}, {"time": 5981, "text": "It's a very, it's a different kind of hesitation that's financial in nature."}, {"time": 5986, "text": "I don't know if that was always the case."}, {"time": 5988, "text": "It seems like in history, people were quiet because of fear, because of a threat of violence."}, {"time": 5995, "text": "Here, there's almost like a self interested preservation of financial, of wealth."}, {"time": 6004, "text": "And I don't know what to do that."}, {"time": 6006, "text": "I mean, I don't know if you can say something there, like the genocide going on because people are financially self interested."}, {"time": 6018, "text": "Yeah, no, I think, I mean, I think the analysis is correct."}, {"time": 6021, "text": "And it's not only, but it's not only corporations, but it's the American government that represents the American people that also feels compelled not to challenge the Chinese on human rights issues."}, {"time": 6039, "text": "But the interesting thing is it's not just, you know, I know a lot of people from China and first of all, amazing human beings and a lot of brilliant people in China, they also don't want to speak out and not because they're sort of quote unquote, like silenced, but more because they're going to also lose financially."}, {"time": 6058, "text": "They have a lot of businesses in China."}, {"time": 6060, "text": "They, you know, they're running, in fact, the Chinese government and the country has a very interesting structure because it has a lot of elements that enable capitalism within a certain framework."}, {"time": 6073, "text": "So you have a lot of very successful companies and they operate successfully."}, {"time": 6078, "text": "And then the leaders of those companies, many of whom have either been on this podcast, or want to be on this podcast, they really don't want to say anything negative about the government."}, {"time": 6089, "text": "And the nature of the fear I sense is not the kind of fear you would have in Nazi Germany."}, {"time": 6097, "text": "It's a very kind of, it's a mellow, like why would I speak out when it has a negative effect on my company, on my family, in terms of finance, strictly financially."}, {"time": 6110, "text": "And that's difficult."}, {"time": 6113, "text": "That's a different problem to solve."}, {"time": 6116, "text": "That feels solvable."}, {"time": 6117, "text": "It feels like it's a money problem."}, {"time": 6120, "text": "If you can control the flow of money where the government has less power to control the flow of money, it feels like that's solvable."}, {"time": 6128, "text": "And that's where capitalism is good."}, {"time": 6130, "text": "That's where a free market is good."}, {"time": 6131, "text": "So it's like, that's where a lot of people in the cryptocurrency space, I don't know if you follow them, they kind of say, okay, take the monetary system, the power to control money away from governments."}, {"time": 6142, "text": "Make it a distributed, like allow technology to help you with that."}, {"time": 6146, "text": "That's a hopeful message there."}, {"time": 6148, "text": "In fact, a lot of people argue that kind of Bitcoin and these cryptocurrencies can help deal with some of these authoritarian regimes that lead to violations of basic human rights."}, {"time": 6161, "text": "If you can control, if you can give the power to control the money to the people, you can take that away from governments."}, {"time": 6167, "text": "That's another source of hope where technology might be able to do something good."}, {"time": 6172, "text": "That's something different about the 21st century than the 20th is there's technology in the hands of billions of people."}, {"time": 6179, "text": "I mean, I have to say, I think you're a naive when it comes to technology."}, {"time": 6184, "text": "I mean, I don't, I'm not someone who understands technology."}, {"time": 6187, "text": "So it's wrong of me to argue with you because I don't really spend much time with it."}, {"time": 6193, "text": "I don't really like it very much."}, {"time": 6195, "text": "And I'm not, I'm neither a fan nor a connoisseur."}, {"time": 6201, "text": "So I just don't really know."}, {"time": 6203, "text": "But what human history has shown basically, and that's a big statement."}, {"time": 6208, "text": "I don't wanna pretend I can tell you what human history has shown."}, {"time": 6212, "text": "But technology, atom bomb, I mean, that's a perfect example of technology."}, {"time": 6219, "text": "What happens when you discover new things?"}, {"time": 6222, "text": "It's a perfect example."}, {"time": 6223, "text": "What's going on with Facebook now?"}, {"time": 6225, "text": "It's an absolutely perfect example."}, {"time": 6227, "text": "And I once went to a lecture by Eric Schmidt about the future and about all the things that were gonna happen and all these wonderful things like you wouldn't have to translate yourself anything, you wouldn't have to read a book, you wouldn't have to drive a car, you don't have to do this, you don't have to do that."}, {"time": 6245, "text": "What kind of life is that?"}, {"time": 6247, "text": "So my view of technology is it's subsumed to the political, social and moral needs of our day and should be subsumed to that day."}, {"time": 6260, "text": "It's not gonna solve anything by itself."}, {"time": 6262, "text": "It's gonna be you and me that solve things."}, {"time": 6265, "text": "If they're solved, there are political system that solve things."}, {"time": 6268, "text": "Technology is neutral on one level."}, {"time": 6271, "text": "It is simply a human, I mean, they're talking now about how artificial intelligence is gonna do this and is gonna do that."}, {"time": 6279, "text": "I'm not so sure there's anything necessarily positive or negative about it except it does obviously make work easier and things like that."}, {"time": 6288, "text": "I mean, I like email and I like word processing and all that stuff is great, but actually solving human relations in and of itself or international relations or conflict among human beings."}, {"time": 6311, "text": "I mean, I see technology as causing as many problems as it solves and maybe even more."}, {"time": 6318, "text": "You know, the kind."}, {"time": 6320, "text": "Maybe even more."}, {"time": 6321, "text": "The question is, so like you said, technology is neutral."}, {"time": 6325, "text": "I agree with this."}, {"time": 6326, "text": "Technology is a toolkit, is a tool set that enables humans to have wider reach and more power, the printing press."}, {"time": 6336, "text": "The rare reason I can read your books is I would argue, so first of all, the printing press and then the internet."}, {"time": 6345, "text": "Wikipedia, I think, has immeasurable effect on humanity."}, {"time": 6352, "text": "Technology is a double edged sword."}, {"time": 6353, "text": "It allows bad people to do bad things and good people to do good things."}, {"time": 6358, "text": "It ultimately boils down to the people and whether you believe the capacity for good outweighs the capacity of bad."}, {"time": 6367, "text": "And so you said that I'm naive."}, {"time": 6370, "text": "I'm naively optimistic."}, {"time": 6372, "text": "I would say you're naively cynical about technology."}, {"time": 6376, "text": "Here we have one overdressed naive optimist and one brilliant, but nevertheless, technologically naive cynic and we don't know."}, {"time": 6387, "text": "We don't know whether the capacity for good or the capacity for evil wins out in the end."}, {"time": 6394, "text": "And like we've been talking about, the trajectory of human history seems to pivot in a lot of random seeming moments."}, {"time": 6405, "text": "But as a builder of technology, I remain optimistic."}, {"time": 6411, "text": "And I should say kind of when you are optimistic, it is often easy to sound naive."}, {"time": 6422, "text": "And I'm not sure what to make of that small effect."}, {"time": 6426, "text": "Not to linger on specific words, but I've noticed that people who kind of are cynical about the world somehow sound more intelligent."}, {"time": 6439, "text": "The issue is how can you be realistic about the world?"}, {"time": 6443, "text": "It's not optimistic or pessimistic."}, {"time": 6445, "text": "It's not cynical."}, {"time": 6447, "text": "The question is how can you be a realist, right?"}, {"time": 6451, "text": "Realism depends on a combination of knowledge and wisdom and good instincts and that sort of thing."}, {"time": 6462, "text": "And that's what we strive for, is a kind of realism."}, {"time": 6467, "text": "We both strive for that kind of realism."}, {"time": 6469, "text": "But I mean, here's an example I would give you."}, {"time": 6473, "text": "What about, again, we've got this environmental issue, and technology has created it."}, {"time": 6479, "text": "It's created it."}, {"time": 6481, "text": "I mean, the growth of technology, I mean, we all like to be heated well in our homes, and we wanna have cars that run quickly and fast on gas."}, {"time": 6491, "text": "I mean, we're all consumers and we all profit from this."}, {"time": 6496, "text": "I don't, not everybody profits from it, but we wanna be comfortable."}, {"time": 6503, "text": "And technology has provided us with a comfortable life."}, {"time": 6505, "text": "And it's also provided us with this incredible danger, which it's not solving, at least not now."}, {"time": 6512, "text": "And it may solve, but it may, it's only, my view is, you know what's gonna happen?"}, {"time": 6517, "text": "A horrible catastrophe."}, {"time": 6519, "text": "It's the only way, it's the only way we will direct ourselves to actually trying to do something about it."}, {"time": 6528, "text": "We don't have the wisdom and the realism and the sense of purpose, you know, what's her name?"}, {"time": 6539, "text": "Greta goes blah, blah, blah, something like that in her last talk about the environmental summit in Glasgow or whatever it was."}, {"time": 6551, "text": "And, you know, we just don't have it unless we're hit upside the head really, really hard."}, {"time": 6559, "text": "And then maybe, you know, the business with nuclear weapons, you know, I think somehow we got hit upside the head and we realized, oh man, you know, this could really do it to the whole world."}, {"time": 6572, "text": "And so we started, you know, serious arms control stuff."}, {"time": 6576, "text": "And, you know, but up to that point, you know, I mean, there was just something about, you know, Khrushchev's big bomb, his big hydrogen bomb, which he exploded in the times, I think it was the anniversary or something like that."}, {"time": 6590, "text": "You know, I mean, just think what we could have done to each other."}, {"time": 6593, "text": "Well, that's the double edged sword of technology."}, {"time": 6595, "text": "Yeah, I agree, it's a double edged sword."}, {"time": 6597, "text": "There's a lot of people, there's a lot of people that argue that nuclear weapons is the reason we haven't had a World War III."}, {"time": 6603, "text": "So nuclear weapons, the mutually assured destruction leads to a kind of like, we've reached a certain level of destructiveness with our weapons where we were able to catch ourselves, not to create, like you said, hit really hard."}, {"time": 6620, "text": "This is the interesting question about kind of hard, hard and really hard upside the head."}, {"time": 6666, "text": "I mean, connected to Tesla and everything they're doing with electric vehicles and so on."}, {"time": 6669, "text": "There's a huge amount of innovation in the space that's happening."}, {"time": 6672, "text": "I could see the effect of climate change resulting in more positive innovation that improves the quality of life across the world than the actual catastrophic events that we're describing, which we cannot even currently predict."}, {"time": 6688, "text": "It's not like there's going to be, there's going to be more extreme weather events."}, {"time": 6692, "text": "There's going to be a gradual increase of the level of water."}, {"time": 6698, "text": "What does that even mean in terms of catastrophic events?"}, {"time": 6700, "text": "It's going to be pretty gradual."}, {"time": 6702, "text": "There's going to be migration."}, {"time": 6703, "text": "We can't predict what that means."}, {"time": 6705, "text": "And in response to that, there's going to be a huge amount of innovators born today that have dreams and that will build devices and inventions and from space to vehicles to in the software world that enable education across the world, all those kinds of things that will on mass, on average, increase the quality of life on average across the world."}, {"time": 6731, "text": "So it's not at all obvious that these, the things that the technologies that are creating climate change, global warming, are going to have a negative, net negative effect."}, {"time": 6743, "text": "We don't know this."}, {"time": 6744, "text": "And I'm kind of inspired by the dreamers, the engineers, the innovators and the entrepreneurs that build, that wake up in the morning, see problems in the world and dream that they're going to be the ones who solve those problems."}, {"time": 6760, "text": "That's the human spirit."}, {"time": 6762, "text": "And that I'm not exactly, it is true that we need those deadlines."}, {"time": 6766, "text": "We need to be freaking out about stuff."}, {"time": 6768, "text": "And the reason we need to study history and the worst of human history is then we can say, oh shit, this too can happen."}, {"time": 6777, "text": "It's a slap in the face."}, {"time": 6779, "text": "It's a wake up call that if you're, if you get complacent, if you get lazy, this is going to happen."}, {"time": 6784, "text": "And that, listen, there's a lot of really intelligent people, ambitious people, dreamers."}, {"time": 6790, "text": "Skilled dreamers that build solutions that make sure this stuff doesn't happen anymore."}, {"time": 6797, "text": "So there's, I think there's reason to be optimistic about technology, not in a naive way."}, {"time": 6801, "text": "There's an argument to be made in a realistic way that like with technology, we can build a better future."}, {"time": 6809, "text": "And then Facebook is a lesson in the way Facebook has been done is a lesson how not to do it."}, {"time": 6817, "text": "And that lesson serves as a guide of how to do it better, how to do it right, how to do it in a positive way."}, {"time": 6826, "text": "And the same, every single sort of failed technology contains within it the lessons of how to do it better."}, {"time": 6833, "text": "And I mean, without that, what's the source of hope for human civilization?"}, {"time": 6840, "text": "You know, that, I mean, by way of question, you have truly studied some of the darkest moments in human history."}, {"time": 6851, "text": "Put on your optimist hat."}, {"time": 6854, "text": "Where?"}, {"time": 6855, "text": "That one."}, {"time": 6856, "text": "There are glimmers of it."}, {"time": 6859, "text": "Yes, what is your source of hope for the future of human civilization?"}, {"time": 6902, "text": "And like you say, we're continuing to invent and we're continuing to try to solve these problems."}, {"time": 6907, "text": "And, you know, we're continuing to love as well as hate."}, {"time": 6911, "text": "And, you know, that, you know, I'm basically, I mean, I have children and grandchildren and I think they're gonna be just fine."}, {"time": 6923, "text": "You know, I'm not a doom and gloomer, you know, I'm not a Cassandra saying the world is coming to an end."}, {"time": 6930, "text": "I'm not like that at all, you know, I think that, you know, things will persist."}, {"time": 6938, "text": "Another, by the way, source of tremendous optimism on my part, the kids I teach, you know, I teach some unbelievably fantastic young people, you know, who are sort of like you say, they're dreamers and they're problem solvers and they're, I mean, they have enormously humane values and ways of thinking about the world and they wanna do good."}, {"time": 6965, "text": "You know, if you take the kind of, I mean, this has probably been true all the way along, but I mean, the percentage of do gooders, you know, is really enormously large."}, {"time": 6976, "text": "Now, whether they end up working for some kind of shark law firm or something, you know, or, you know, that kind of thing, or whether they end up human rights lawyers is they all wanna be, right?"}, {"time": 6988, "text": "You know, is a different kind of question, but certainly, you know, these young people are talented, they're smart, they have wonderful values, they're energetic, they work hard, you know, they're focused and of course, it's not just Stanford."}, {"time": 7008, "text": "I mean, it's all over the country, you know, you have young people who really wanna contribute and they wanna contribute."}, {"time": 7015, "text": "I mean, it's true some of them end up, you know, working to get rich."}, {"time": 7022, "text": "I mean, that's inevitable, right?"}, {"time": 7023, "text": "But the percentages are actually rather small, at least at this age, you know, maybe when they get a mortgage and a family and that sort of thing, you know, financial wellbeing will be more important to them."}, {"time": 7036, "text": "But right now, you know, you catch this young generation and they're fantastic, they're fantastic."}, {"time": 7042, "text": "And they're not what they're often portrayed as being, you know, kind of silly and naive and knee jerk leftists and that, they're not at all like that."}, {"time": 7053, "text": "You know, they're really fine young people."}, {"time": 7056, "text": "So that's a source of optimism to me too."}, {"time": 7060, "text": "What advice would you give to those young people today, maybe in high school, in college, at Stanford, maybe to your grandchildren about how to have a career they can be proud of, have a life they can be proud of?"}, {"time": 7075, "text": "Pursue careers that are in the public interest, you know, in one fashion or another and not just in their interests."}, {"time": 7083, "text": "And that would be, I mean, it's not bad to pursue a career in your own interests."}, {"time": 7088, "text": "I mean, as long as it's something that's useful and positive for their families or whatever."}, {"time": 7096, "text": "But yeah, so I mean, I try to advise kids to find themselves somehow, you know, find who they wanna be and what they wanna be and try to pursue it."}, {"time": 7107, "text": "And the NGO world is growing, as you know, and a lot of young people are kind of throwing themselves into it and, you know, human rights watch and that kind of stuff."}, {"time": 7121, "text": "And, you know, they wanna do that kind of work and it's very admirable."}, {"time": 7126, "text": "I tend to think that even if you're not working in human rights, there's a certain way in which if you live with integrity, I believe that all of us or many of us have a bunch of moments in our lives when we're posed with a decision."}, {"time": 7147, "text": "It's a quiet one."}, {"time": 7149, "text": "Maybe it'll never be written about or talked about."}, {"time": 7152, "text": "But you get to choose whether you, there's a choice that is difficult to make, it may require sacrifice, but it's the choice that the best version of that person would make."}, {"time": 7169, "text": "That's the best way I can sort of say how to act with integrity."}, {"time": 7172, "text": "It's the very thing that would resist the early days in Nazi Germany."}, {"time": 7176, "text": "It sounds dramatic to say, but those little actions."}, {"time": 7180, "text": "And I feel like the best you can do to avoid genocide on scale is for all of us to live in that way, within those moments, unrelated potentially to human rights, to anything else, is to take those actions."}, {"time": 7197, "text": "Like I believe that all of us know the right thing to do."}, {"time": 7200, "text": "I know that's right."}, {"time": 7202, "text": "You put it very well."}, {"time": 7204, "text": "I couldn't have done it better myself."}, {"time": 7206, "text": "No, no, I agree."}, {"time": 7224, "text": "And that's really super important."}, {"time": 7227, "text": "Well, let me ask you about love."}, {"time": 7229, "text": "What role does love play in this whole thing in the human condition?"}, {"time": 7233, "text": "In all of the study of genocide, it does seem that hardship in moments brings out the best in human nature and the best in human nature is expressed through love."}, {"time": 7244, "text": "Well, as I already mentioned to you, I think hardship is not a good thing for, you know, it's not the best thing for love."}, {"time": 7253, "text": "I mean, it's better to not have to suffer and not have to, yes, I think it is."}, {"time": 7260, "text": "I think it's, you know, as I mentioned to you, you know, studying concentration camps, you know, this is not a place for love."}, {"time": 7270, "text": "It happens, it happens, but it's not really a place for love."}, {"time": 7275, "text": "It's a place for rape."}, {"time": 7276, "text": "It's a place for torture."}, {"time": 7279, "text": "It's a place for killing."}, {"time": 7280, "text": "And it's a place for inhuman action one to another, you know, and also, as I said, among those who are suffering, not just between those who are, and then there are whole gradations, you know, the same thing in the gulag."}, {"time": 7296, "text": "You know, there are gradations all the way from the criminal prisoners who beat the hell out of the political prisoners, you know, who then have others below them who they beat down, you know, so everybody's being the hell out of everybody else."}, {"time": 7308, "text": "So I would not idealize in any way suffering as, you know, a source of beauty and love."}, {"time": 7317, "text": "I wouldn't do that at all."}, {"time": 7318, "text": "I think it's a whole lot better for people to be relatively prosperous."}, {"time": 7323, "text": "I'm not saying super prosperous, but to be able to feed themselves and to be able to feed their families and house their families and take care of themselves, you know, to foster loving relations between people."}, {"time": 7341, "text": "And, you know, I think it's no accident that, you know, poor families have much worse records when it comes to crime and things like that, you know, and also to wife beating and to child abuse and stuff like that."}, {"time": 7360, "text": "I mean, you just, you don't want to be poor and indigent and not have a roof over your head, be homeless."}, {"time": 7369, "text": "I mean, it doesn't mean, again, you know, homeless people are mean people."}, {"time": 7373, "text": "That's not what I'm trying to say."}, {"time": 7374, "text": "What I'm trying to say is that, you know, what we want to try to foster in this country and around the world, and one of the reasons, you know, I mean, I'm very critical of the Chinese in a lot of ways, but I mean, we have to remember they pulled that country out of horrible poverty, right?"}, {"time": 7391, "text": "And I mean, there's still poor people in the countryside."}, {"time": 7394, "text": "There's still problems, you know, with want and need among the Chinese people."}, {"time": 7401, "text": "But, you know, there were millions and millions of Chinese who were living at the bare minimum of life, which is no way to live, you know, and no way, again, to foster love and compassion and getting along."}, {"time": 7413, "text": "So I want to be clear, I don't speak for history, right?"}, {"time": 7417, "text": "I'm giving you, there used to be historians, you know, in the 19th century who really thought they were speaking for history, you know?"}, {"time": 7425, "text": "I don't think that way at all."}, {"time": 7427, "text": "I mean, I understand I'm a subjective human being with my own points of view and my own opinions, but."}, {"time": 7434, "text": "I'm trying to remember this in this conversation that you're, despite the fact that you're brilliant and you've written brilliant books, that you're just human with an opinion."}, {"time": 7444, "text": "That's it, yeah, no, no, that's absolutely true."}, {"time": 7447, "text": "And I tell my students that too."}, {"time": 7449, "text": "I mean, I make sure they understand this is not history speaking, you know, this is me and Norman and I'm, you know, and this is what it's about."}, {"time": 7458, "text": "I mean, I spent a long time studying history and have enjoyed it enormously."}, {"time": 7464, "text": "But, you know, I'm an individual with my points of view."}, {"time": 7469, "text": "And one of them is that I've developed over time, is that, you know, human want is a real tragedy for people and it hurts people and it also causes upheavals and difficulties and stuff."}, {"time": 7486, "text": "So I feel for people, you know, I feel for people in Syria, I feel for people in, you know, in Ethiopia, in Tigray, you know, when they don't have enough to eat."}, {"time": 7496, "text": "And, you know, what that does, I mean, it doesn't mean they don't love each other, right?"}, {"time": 7500, "text": "And it doesn't mean they don't love their kids."}, {"time": 7503, "text": "But it does mean that it's harder, you know, to do that."}, {"time": 7506, "text": "And to, and..."}, {"time": 7508, "text": "I'm not so sure, it's obvious to me that it's harder."}, {"time": 7511, "text": "It's, there's suffering, there is suffering."}, {"time": 7513, "text": "But the numbers, we've been talking about deaths, we've been talking about suffering, but the numbers we're not quantifying."}, {"time": 7519, "text": "The history that you haven't perhaps been looking at is all the times that people have fallen in love, deeply with friends, with romantic love, the positive emotion that people have felt."}, {"time": 7531, "text": "And I'm not so sure that amidst the suffering, those moments of beauty and love can be discovered."}, {"time": 7536, "text": "And if we look at the numbers, I'm not so sure the story is obvious."}, {"time": 7541, "text": "That, you know, I mean, again, I suppose you may disagree with Viktor Frankl."}, {"time": 7546, "text": "I may too, maybe depending on the day."}, {"time": 7549, "text": "I mean, he says that if there's meaning to this life at all, there's meaning to the suffering too, because suffering is part of life."}, {"time": 7556, "text": "There's something about accepting the ups and downs, even when the downs go very low."}, {"time": 7563, "text": "And within all of it, finding a source of meaning."}, {"time": 7567, "text": "I mean, he's arguing from the perspective of psychology, but just this life is an incredible gift, almost no matter what."}, {"time": 7575, "text": "And I'm not, it's easy to look at suffering and think if we just escape the suffering, it will all be better, but we all die."}, {"time": 7588, "text": "There's beauty in the whole thing."}, {"time": 7590, "text": "And it is true that it's just, from all the stories I've read, especially in famine and starvation, it's just horrible."}, {"time": 7599, "text": "It is horrible suffering."}, {"time": 7601, "text": "But I also just want to say that there's love amidst it, and we can't forget that."}, {"time": 7607, "text": "No, no, I don't forget it, I don't forget it."}, {"time": 7610, "text": "And I think it's from the stories."}, {"time": 7612, "text": "Now, I don't want to make that compromise or that trade, but the intensity of friendship in war, the intensity of love in war is very high."}, {"time": 7624, "text": "So I'm not sure what to make of these calculations, but if you look at the stories, some of the people I'm closest with, and I've never experienced anything even close to any of this, but some of the people I'm closest with is people I've gone through difficult times with."}, {"time": 7640, "text": "They're a society or a group where things are easy."}, {"time": 7644, "text": "The intensity of the connection between human beings is not as strong."}, {"time": 7649, "text": "I don't know what to do with that calculus because I too agree with you."}, {"time": 7652, "text": "I want to have as little suffering in the world as possible, but we have to remember about the love and the depth of human connection and find the right balance there."}, {"time": 7664, "text": "No, there's something to what you're saying."}, {"time": 7666, "text": "There's clearly something to what you're saying."}, {"time": 7668, "text": "I was just thinking about the Soviet Union when I lived there and people on the streets were so mean to one another and they never smiled."}, {"time": 7676, "text": "You grew up there?"}, {"time": 7677, "text": "No, but you were, you're too young to."}, {"time": 7678, "text": "No, no, I remember well."}, {"time": 7680, "text": "I came here when I was 13, yeah."}, {"time": 7681, "text": "Okay, so anyway, I remember living there and just how hard people were on each other on the streets."}, {"time": 7687, "text": "And when you got inside people's apartments, when they started to trust you, the friendships were so intense and so wonderful."}, {"time": 7695, "text": "So in that sense, I mean, they did live a hard life, but there wasn't a food on the table and there was a roof over their heads."}, {"time": 7703, "text": "There's a certain line."}, {"time": 7704, "text": "There's a certain, there are lines."}, {"time": 7705, "text": "I don't think there's one line, but it's kind of a shading."}, {"time": 7709, "text": "And the other story I was thinking of as you were talking was not a story, it's a history, a book by a friend of mine who wrote about love in the camps, in the refugee camps for Jews in Germany after the war."}, {"time": 7728, "text": "So these were Jews who had come mostly from Poland and some survived the camps, came from awful circumstances."}, {"time": 7736, "text": "And then they were put in these camps, which were not joyful places."}, {"time": 7740, "text": "I mean, they were guarded sometimes by Germans even, but they're basically under the British control and they were trying to get to Israel, trying to get to Palestine right after the war."}, {"time": 7751, "text": "And how many pairs there were, how many people coupled up."}, {"time": 7756, "text": "But remember, this is after being in the concentration camp."}, {"time": 7758, "text": "It's not being in the concentration camp."}, {"time": 7760, "text": "And it's also being free to, more or less free, to express their emotions and to be human beings after this horrible thing which they suffered."}, {"time": 7774, "text": "So I wonder whether there's, as you say, some kind of calculus there where the level of suffering is such that it's just too much for humans to bear."}, {"time": 7787, "text": "And which I would suggest, I mean, I haven't studied this myself."}, {"time": 7792, "text": "I'm just giving you my point of view, my off the cuff remarks here."}, {"time": 7797, "text": "But it was very inspiring to read about these couples who had met right in these camps and started to couple up and get married."}, {"time": 7806, "text": "And tried to find their way to Palestine, which was a difficult thing to do then."}, {"time": 7811, "text": "When did you live in Russia and the Soviet Union?"}, {"time": 7814, "text": "What's your memory of the time?"}, {"time": 7816, "text": "Well, so a number of different times."}, {"time": 7818, "text": "So I went there, I first went there in 69, 70."}, {"time": 7822, "text": "A long time ago."}, {"time": 7823, "text": "And then I lived in Leningrad mostly, but also in Moscow in 1975."}, {"time": 7831, "text": "So it was detente time."}, {"time": 7833, "text": "But it was also a time of political uncertainty and also hardship for Russians themselves, standing in long lines."}, {"time": 7846, "text": "I mean, you must remember this for food and for getting anything was almost impossible."}, {"time": 7851, "text": "It was a time when Jews were trying to get out."}, {"time": 7856, "text": "In fact, I just talked to a friend of mine from those days who I helped get out and get to Boston and the lovely people who had managed to have a good life in the United States after they left."}, {"time": 7868, "text": "But it wasn't an easy time."}, {"time": 7870, "text": "It wasn't an easy time at all."}, {"time": 7871, "text": "I remember people set fire to their doors and their daughter was persecuted in school once they declared that they wanted to immigrate and that sort of thing."}, {"time": 7882, "text": "So it was a very, it was a lot of antisemitism."}, {"time": 7887, "text": "So it was a tough time."}, {"time": 7888, "text": "Dissidents hung out with some dissidents and one guy was actually killed."}, {"time": 7895, "text": "We think by the, nobody knows exactly by the KGB, but his art studio was, he had a separate studio in Leningrad, St. Petersburg today, just a small studio where he did his art and somebody set it on fire."}, {"time": 7911, "text": "And we think it was KGB, but you never really know."}, {"time": 7916, "text": "And he died in that fire."}, {"time": 7917, "text": "So it was not, it was a tough time."}, {"time": 7921, "text": "And you knew you were followed, you knew you were being reported on as a foreign scholar as I was."}, {"time": 7928, "text": "There was a formal exchange between the United States and the Soviet Union and they let me work in the archives, but then Ivanov got to work in the physics lab at Rochester or something like that."}, {"time": 7944, "text": "So it was an exchange which sent historians and literary people and some social scientists to Russia and they sent all scientists here to grab what they could from MIT and those places."}, {"time": 7959, "text": "How's your Russian?"}, {"time": 7961, "text": "Do you have any knowledge of Russian language that has helped you to understand?"}, {"time": 7967, "text": "I mean, I can read it fine."}, {"time": 7970, "text": "And the speaking comes and goes, depending on whether I'm there or I've been there recently or if I spend some time there, because I really need, you know, I have Russian friends who speak just Russian."}, {"time": 7980, "text": "So, you know, when I'm there, I then, you know, I can communicate pretty well."}, {"time": 7985, "text": "Well, I can't really write it unfortunately."}, {"time": 7988, "text": "I mean, I can, but it's not very good, but I get along fine in Russia."}, {"time": 7993, "text": "What's your fondest memory of the Soviet Union, of Russia?"}, {"time": 7997, "text": "It's friends."}, {"time": 7998, "text": "Friends?"}, {"time": 7999, "text": "It's friends, it's friends."}, {"time": 8000, "text": "Was it vodka involved or is it just vodka involved?"}, {"time": 8005, "text": "Little bit, you know, I'm not much of a drinker."}, {"time": 8007, "text": "So I would, you know, they'd just make fun of me and I'd make fun of myself and that was easy enough."}, {"time": 8012, "text": "I don't really like, you know, a heavy drink."}, {"time": 8015, "text": "I've done a lot of that, not a lot."}, {"time": 8017, "text": "I'd done some of that, but I never really enjoyed it and would get sick and stuff."}, {"time": 8022, "text": "But no, it's friends."}, {"time": 8025, "text": "You know, one friend I made in the dormitory, you know, it was a dormitory for foreigners, but also Siberians who had come, you know, to Leningrad to study."}, {"time": 8038, "text": "And so I met a couple of guys and one in particular from Omsk became a wonderful friend."}, {"time": 8044, "text": "And we talked and talked and talked outside."}, {"time": 8046, "text": "You know, we would go walk outside because we both knew they were, you know, people were listening and stuff."}, {"time": 8052, "text": "And he would say, well, this is, he was an historian, you know, and so we would talk history."}, {"time": 8056, "text": "And he'd say, well, this was the case, wasn't it?"}, {"time": 8058, "text": "I said, no, I'm sorry, Sasha, it wasn't the case."}, {"time": 8061, "text": "It was, you know, we think Stalin actually had a role in killing Kirov."}, {"time": 8066, "text": "I mean, we're not sure, but he said, no."}]}]