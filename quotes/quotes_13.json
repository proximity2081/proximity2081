[{"title": "Pamela McCorduck: Machines Who Think and the Early Days of AI | Lex Fridman Podcast #34", "id": "i6rnzk8VU24", "quotes": [{"time": 283, "text": "He was, I think, an undergraduate then."}, {"time": 287, "text": "And of course, Joe Traub."}, {"time": 287, "text": "All of these are players, not at Dartmouth, but in that era."}, {"time": 297, "text": "CMU and so on."}, {"time": 297, "text": "So who are the characters, if you could paint a picture, that stand out to you from memory?"}, {"time": 302, "text": "Those people you've interviewed and maybe not, people that were just in the In the atmosphere."}, {"time": 309, "text": "In the atmosphere."}, {"time": 311, "text": "Of course, the four founding fathers were extraordinary guys."}, {"time": 311, "text": "They really were."}, {"time": 315, "text": "Who are the founding fathers?"}, {"time": 318, "text": "Alan Newell, Herbert Simon, Marvin Minsky, John McCarthy."}, {"time": 318, "text": "They were the four who were not only at the Dartmouth conference, but Newell and Simon arrived there with a working program called The Logic Theorist."}, {"time": 329, "text": "Everybody else had great ideas about how they might do it, but But they weren't going to do it yet."}, {"time": 341, "text": "And you mentioned Joe Traub, my husband."}, {"time": 341, "text": "I was immersed in AI before I met Joe because I had been Ed Feigenbaum's assistant at Stanford."}, {"time": 350, "text": "And before that, I had worked on a book edited by Feigenbaum and Julian Feldman called Computers and Thought."}, {"time": 364, "text": "It was the first textbook of readings of AI."}, {"time": 364, "text": "And they only did it because they were trying to teach AI to people at Berkeley."}, {"time": 370, "text": "And there was nothing, you'd have to send them to this journal and that journal."}, {"time": 375, "text": "This was not the internet where you could go look at an article."}, {"time": 375, "text": "So I was fascinated from the get go by AI."}, {"time": 382, "text": "I was an English major."}, {"time": 382, "text": "What did I know?"}, {"time": 382, "text": "And yet I was fascinated."}, {"time": 382, "text": "And that's why you saw that historical, that literary background, which I think is very much a part of the continuum of AI, that AI grew out of that same impulse."}, {"time": 398, "text": "That traditional, what was, what drew you to AI?"}, {"time": 407, "text": "How did you even think of it back then?"}, {"time": 407, "text": "What was the possibilities, the dreams?"}, {"time": 414, "text": "What was interesting to you?"}, {"time": 414, "text": "The idea of intelligence outside the human cranium, this was a phenomenal idea."}, {"time": 423, "text": "And even when I finished Machines Who Think, I didn't know if they were going to succeed."}, {"time": 428, "text": "In fact, the final chapter is very wishy washy, frankly."}, {"time": 435, "text": "Succeed, the field did."}, {"time": 435, "text": "So was there the idea that AI began with the wish to forge the gods?"}, {"time": 445, "text": "So the spiritual component that we crave to create this other thing greater than ourselves."}, {"time": 453, "text": "For those guys, I don't think so."}, {"time": 453, "text": "Newell and Simon were cognitive psychologists."}, {"time": 462, "text": "What they wanted was to simulate aspects of human intelligence, and they found they could do it on the computer."}, {"time": 469, "text": "Minsky just thought it was a really cool thing to do."}, {"time": 477, "text": "Likewise, McCarthy."}, {"time": 477, "text": "McCarthy had got the idea in 1949 when he was a Caltech student."}, {"time": 486, "text": "And he listened to somebody's lecture."}, {"time": 486, "text": "It's in my book."}, {"time": 486, "text": "I forget who it was."}, {"time": 486, "text": "And he thought, oh, that would be fun to do."}, {"time": 495, "text": "How do we do that?"}, {"time": 495, "text": "And he took a very mathematical approach."}, {"time": 501, "text": "Minsky was hybrid, and Newell and Simon were very much cognitive psychology."}, {"time": 501, "text": "How can we simulate various things about human cognition?"}, {"time": 509, "text": "What happened over the many years is, of course, our definition of intelligence expanded tremendously."}, {"time": 517, "text": "These days, biologists are comfortable talking about the intelligence of the cell, the intelligence of the brain, not just human brain, but the intelligence of any kind of brain."}, {"time": 529, "text": "Cephalopods, I mean, an octopus is really intelligent by any amount."}, {"time": 540, "text": "We wouldn't have thought of that in the 60s, even the 70s."}, {"time": 546, "text": "So all these things have worked in."}, {"time": 546, "text": "And I did hear one behavioral primatologist, Franz De Waal, say, AI taught us the questions to ask."}, {"time": 556, "text": "Yeah, this is what happens, right?"}, {"time": 556, "text": "When you try to build it, is when you start to actually ask questions."}, {"time": 566, "text": "It puts a mirror to ourselves."}, {"time": 566, "text": "So you were there in the middle of it."}, {"time": 572, "text": "It seems like not many people were asking the questions that you were, or just trying to look at this field the way you were."}, {"time": 578, "text": "I was so low."}, {"time": 578, "text": "When I went to get funding for this because I needed somebody to transcribe the interviews and I needed travel expenses, I went to everything you could think of, the NSF, the DARPA."}, {"time": 593, "text": "There was an Air Force place that doled out money."}, {"time": 607, "text": "And each of them said, well, that's a very interesting idea."}, {"time": 615, "text": "But we'll think about it."}, {"time": 615, "text": "And the National Science Foundation actually said to me in plain English, hey, you're only a writer."}, {"time": 623, "text": "You're not a historian of science."}, {"time": 623, "text": "And I said, yeah, that's true."}, {"time": 623, "text": "But the historians of science will be crawling all over this field."}, {"time": 630, "text": "I'm writing for the general audience, so I thought."}, {"time": 635, "text": "And they still wouldn't budge."}, {"time": 635, "text": "I finally got a private grant without knowing who it was from, from Ed Fredkin at MIT."}, {"time": 643, "text": "He was a wealthy man, and he liked what he called crackpot ideas."}, {"time": 651, "text": "And he considered this a crackpot idea, and he was willing to support it."}, {"time": 651, "text": "I am ever grateful, let me say that."}, {"time": 658, "text": "Some would say that a history of science approach to AI, or even just a history, or anything like the book that you've written, hasn't been written since."}, {"time": 666, "text": "Maybe I'm not familiar, but it's certainly not many."}, {"time": 673, "text": "If we think about bigger than just these couple of decades, few decades, what are the roots of AI?"}, {"time": 680, "text": "Oh, they go back so far."}, {"time": 680, "text": "Yes, of course, there's all the legendary stuff, the Golem and the early robots of the 20th century."}, {"time": 690, "text": "But they go back much further than that."}, {"time": 701, "text": "If you read Homer, Homer has robots in the Iliad."}, {"time": 701, "text": "And a classical scholar was pointing out to me just a few months ago, well, you said you just read the Odyssey."}, {"time": 709, "text": "The Odyssey is full of robots."}, {"time": 714, "text": "It is, I said?"}, {"time": 714, "text": "How do you think Odysseus's ship gets from one place to another?"}, {"time": 720, "text": "He doesn't have the crew people to do that, the crewmen."}, {"time": 720, "text": "Yeah, it's magic."}, {"time": 720, "text": "It's robots."}, {"time": 727, "text": "Oh, I thought, how interesting."}, {"time": 727, "text": "So we've had this notion of AI for a long time."}, {"time": 727, "text": "And then toward the end of the 19th century, the beginning of the 20th century, there were scientists who actually tried to make this happen some way or another, not successfully."}, {"time": 743, "text": "They didn't have the technology for it."}, {"time": 749, "text": "And of course, Babbage in the 1850s and 60s, he saw that what he was building was capable of intelligent behavior."}, {"time": 760, "text": "And when he ran out of funding, the British government finally said, that's enough."}, {"time": 767, "text": "He and Lady Lovelace decided, oh, well, why don't we play the ponies with this?"}, {"time": 767, "text": "He had other ideas for raising money too."}, {"time": 775, "text": "But if we actually reach back once again, I think people don't actually really know that robots do appear and ideas of robots."}, {"time": 782, "text": "You talk about the Hellenic and the Hebraic points of view."}, {"time": 789, "text": "Can you tell me about each?"}, {"time": 789, "text": "I defined it this way."}, {"time": 789, "text": "The Hellenic point of view is robots are great."}, {"time": 796, "text": "They are party help."}, {"time": 796, "text": "They help this guy Hephaestus, this god Hephaestus in his forge."}, {"time": 805, "text": "I presume he made them to help him and so on and so forth."}, {"time": 812, "text": "And they welcome the whole idea of robots."}, {"time": 812, "text": "The Hebraic view has to do with, I think it's the second commandment, thou shalt not make any graven image."}, {"time": 820, "text": "In other words, you better not start imitating humans because that's just forbidden."}, {"time": 827, "text": "It's the second commandment."}, {"time": 827, "text": "And a lot of the reaction to artificial intelligence has been a sense that this is somehow wicked, this is somehow blasphemous."}, {"time": 848, "text": "We shouldn't be going there."}, {"time": 848, "text": "Now, you can say, yeah, but there are going to be some downsides."}, {"time": 857, "text": "And I say, yes, there are, but blasphemy is not one of them."}, {"time": 861, "text": "You know, there is a kind of fear that feels to be almost primal."}, {"time": 861, "text": "Is there religious roots to that?"}, {"time": 869, "text": "Because so much of our society has religious roots."}, {"time": 869, "text": "And so there is a feeling of, like you said, blasphemy of creating the other, of creating something, you know, it doesn't have to be artificial intelligence."}, {"time": 883, "text": "It's creating life in general."}, {"time": 883, "text": "It's the Frankenstein idea."}, {"time": 888, "text": "There's the annotated Frankenstein on my coffee table."}, {"time": 888, "text": "It's a tremendous novel."}, {"time": 888, "text": "It really is just beautifully perceptive."}, {"time": 896, "text": "Yes, we do fear this and we have good reason to fear it, but because it can get out of hand."}, {"time": 903, "text": "Maybe you can speak to that fear, the psychology, if you've thought about it."}, {"time": 908, "text": "You know, there's a practical set of fears, concerns in the short term."}, {"time": 912, "text": "You can think if we actually think about artificial intelligence systems, you can think about bias of discrimination in algorithms."}, {"time": 917, "text": "You can think about their social networks have algorithms that recommend the content you see, thereby these algorithms control the behavior of the masses."}, {"time": 935, "text": "There's these concerns."}, {"time": 935, "text": "But to me, it feels like the fear that people have is deeper than that."}, {"time": 940, "text": "So have you thought about the psychology of it?"}, {"time": 946, "text": "I think in a superficial way I have."}, {"time": 946, "text": "There is this notion that if we produce a machine that can think, it will outthink us and therefore replace us."}, {"time": 961, "text": "I guess that's a primal fear of almost kind of a kind of mortality."}, {"time": 961, "text": "So around the time you said you worked at Stanford with Ed Feigenbaum."}, {"time": 971, "text": "So let's look at that one person."}, {"time": 971, "text": "Throughout his history, clearly a key person, one of the many in the history of AI."}, {"time": 981, "text": "How has he changed in general around him?"}, {"time": 991, "text": "How has Stanford changed in the last, how many years are we talking about here?"}, {"time": 996, "text": "Oh, since 65."}, {"time": 998, "text": "65."}, {"time": 998, "text": "So maybe it doesn't have to be about him."}, {"time": 998, "text": "It could be bigger."}, {"time": 998, "text": "But because he was a key person in expert systems, for example, how is that, how are these folks who you've interviewed in the 70s, 79 changed through the decades?"}, {"time": 1018, "text": "In Ed's case, I know him well."}, {"time": 1018, "text": "We are dear friends."}, {"time": 1018, "text": "We see each other every month or so."}, {"time": 1018, "text": "He told me that when Machines Who Think first came out, he really thought all the front matter was kind of bologna."}, {"time": 1037, "text": "And 10 years later, he said, no, I see what you're getting at."}, {"time": 1037, "text": "Yes, this is an impulse that has been a human impulse for thousands of years to create something outside the human cranium that has intelligence."}, {"time": 1054, "text": "I think it's very hard when you're down at the algorithmic level, and you're just trying to make something work, which is hard enough to step back and think of the big picture."}, {"time": 1073, "text": "It reminds me of when I was in Santa Fe, I knew a lot of archaeologists, which was a hobby of mine."}, {"time": 1079, "text": "And I would say, yeah, yeah, well, you can look at the shards and say, oh, this came from this tribe and this came from this trade route and so on."}, {"time": 1087, "text": "But what about the big picture?"}, {"time": 1094, "text": "And a very distinguished archaeologist said to me, they don't think that way."}, {"time": 1094, "text": "No, they're trying to match the shard to where it came from."}, {"time": 1101, "text": "Where did the remainder of this corn come from?"}, {"time": 1110, "text": "Was it grown here?"}, {"time": 1110, "text": "Was it grown elsewhere?"}, {"time": 1110, "text": "And I think this is part of any scientific field."}, {"time": 1117, "text": "You're so busy doing the hard work, and it is hard work, that you don't step back and say, oh, well, now let's talk about the general meaning of all this."}, {"time": 1133, "text": "So none of the even Minsky and McCarthy, they... Oh, those guys did."}, {"time": 1138, "text": "The founding fathers did."}, {"time": 1141, "text": "Early on or later?"}, {"time": 1143, "text": "Pretty early on."}, {"time": 1143, "text": "But in a different way from how I looked at it."}, {"time": 1143, "text": "The two cognitive psychologists, Newell and Simon, they wanted to imagine reforming cognitive psychology so that we would really, really understand the brain."}, {"time": 1160, "text": "Minsky was more speculative."}, {"time": 1160, "text": "And John McCarthy saw it as, I think I'm doing him right by this, he really saw it as a great boon for human beings to have this technology."}, {"time": 1180, "text": "And that was reason enough to do it."}, {"time": 1180, "text": "And he had wonderful, wonderful fables about how if you do the mathematics, you will see that these things are really good for human beings."}, {"time": 1196, "text": "And if you had a technological objection, he had an answer, a technological answer."}, {"time": 1203, "text": "But here's how we could get over that and then blah, blah, blah."}, {"time": 1203, "text": "And one of his favorite things was what he called the literary problem, which of course he presented to me several times."}, {"time": 1216, "text": "That is everything in literature, there are conventions in literature."}, {"time": 1216, "text": "One of the conventions is that you have a villain and a hero."}, {"time": 1223, "text": "And the hero in most literature is human, and the villain in most literature is a machine."}, {"time": 1236, "text": "And he said, that's just not the way it's going to be."}, {"time": 1241, "text": "But that's the way we're used to it."}, {"time": 1241, "text": "So when we tell stories about AI, it's always with this paradigm."}, {"time": 1247, "text": "I thought, yeah, he's right."}, {"time": 1247, "text": "Looking back, the classics RUR is certainly the machines trying to overthrow the humans."}, {"time": 1257, "text": "Frankenstein is different."}, {"time": 1257, "text": "Frankenstein is a creature."}, {"time": 1266, "text": "He never has a name."}, {"time": 1266, "text": "Frankenstein, of course, is the guy who created him, the human, Dr. Frankenstein."}, {"time": 1273, "text": "This creature wants to be loved, wants to be accepted."}, {"time": 1273, "text": "And it is only when Frankenstein turns his head, in fact, runs the other way."}, {"time": 1282, "text": "And the creature is without love, that he becomes the monster that he later becomes."}, {"time": 1298, "text": "So who's the villain in Frankenstein?"}, {"time": 1298, "text": "It's unclear, right?"}, {"time": 1303, "text": "Oh, it is unclear, yeah."}, {"time": 1305, "text": "It's really the people who drive him."}, {"time": 1305, "text": "By driving him away, they bring out the worst."}, {"time": 1314, "text": "They give him no human solace."}, {"time": 1314, "text": "And he is driven away, you're right."}, {"time": 1320, "text": "He becomes, at one point, the friend of a blind man."}, {"time": 1320, "text": "And he serves this blind man, and they become very friendly."}, {"time": 1328, "text": "But when the sighted people of the blind man's family come in, ah, you've got a monster here."}, {"time": 1334, "text": "So it's very didactic in its way."}, {"time": 1334, "text": "And what I didn't know is that Mary Shelley and Percy Shelley were great readers of the literature surrounding abolition in the United States, the abolition of slavery."}, {"time": 1351, "text": "And they picked that up wholesale."}, {"time": 1351, "text": "You are making monsters of these people because you won't give them the respect and love that they deserve."}, {"time": 1364, "text": "Do you have, if we get philosophical for a second, do you worry that once we create machines that are a little bit more intelligent, let's look at Roomba, the vacuums, the cleaner, that this darker part of human nature where we abuse the other, the somebody who's different, will come out?"}, {"time": 1389, "text": "I don't worry about it."}, {"time": 1389, "text": "I could imagine it happening."}, {"time": 1389, "text": "But I think that what AI has to offer the human race will be so attractive that people will be won over."}, {"time": 1405, "text": "So you have looked deep into these people, had deep conversations, and it's interesting to get a sense of stories of the way they were thinking and the way it was changed, the way your own thinking about AI has changed."}, {"time": 1422, "text": "So you mentioned McCarthy."}, {"time": 1422, "text": "What about the years at CMU, Carnegie Mellon, with Joe?"}, {"time": 1431, "text": "Joe was not in AI."}, {"time": 1431, "text": "He was in algorithmic complexity."}, {"time": 1443, "text": "Was there always a line between AI and computer science, for example?"}, {"time": 1447, "text": "Is AI its own place of outcasts?"}, {"time": 1447, "text": "Was that the feeling?"}, {"time": 1450, "text": "There was a kind of outcast period for AI."}, {"time": 1450, "text": "For instance, in 1974, the new field was hardly 10 years old."}, {"time": 1464, "text": "The new field of computer science was asked by the National Science Foundation, I believe, but it may have been the National Academies, I can't remember, to tell your fellow scientists where computer science is and what it means."}, {"time": 1484, "text": "And they wanted to leave out AI."}, {"time": 1484, "text": "And they only agreed to put it in because Don Knuth said, hey, this is important."}, {"time": 1493, "text": "You can't just leave that out."}, {"time": 1497, "text": "Don, dude?"}, {"time": 1498, "text": "Don Knuth, yes."}, {"time": 1499, "text": "I talked to him recently, too."}, {"time": 1499, "text": "Out of all the people."}, {"time": 1502, "text": "But you see, an AI person couldn't have made that argument."}, {"time": 1502, "text": "He wouldn't have been believed."}, {"time": 1508, "text": "But Knuth was believed."}, {"time": 1510, "text": "So Joe Traub worked on the real stuff."}, {"time": 1515, "text": "Joe was working on algorithmic complexity."}, {"time": 1515, "text": "But he would say in plain English again and again, the smartest people I know are in AI."}, {"time": 1525, "text": "Anyway, Joe loved these guys."}, {"time": 1525, "text": "What happened was that I guess it was as I started to write Machines Who Think, Herb Simon and I became very close friends."}, {"time": 1541, "text": "He would walk past our house on Northumberland Street every day after work."}, {"time": 1541, "text": "And I would just be putting my cover on my typewriter."}, {"time": 1547, "text": "And I would lean out the door and say, Herb, would you like a sherry?"}, {"time": 1552, "text": "And Herb almost always would like a sherry."}, {"time": 1552, "text": "So he'd stop in and we'd talk for an hour, two hours."}, {"time": 1559, "text": "My journal says we talked this afternoon for three hours."}, {"time": 1566, "text": "What was on his mind at the time in terms of on the AI side of things?"}, {"time": 1571, "text": "Oh, we didn't talk too much about AI."}, {"time": 1571, "text": "We talked about other things."}, {"time": 1575, "text": "We both love literature."}, {"time": 1575, "text": "And Herb had read Proust in the original French twice all the way through."}, {"time": 1584, "text": "I've read it in English in translation."}, {"time": 1584, "text": "So we talked about literature."}, {"time": 1590, "text": "We talked about languages."}, {"time": 1590, "text": "We talked about music because he loved music."}, {"time": 1590, "text": "We talked about art because he was actually enough of a painter that he had to give it up because he was afraid it was interfering with his research and so on."}, {"time": 1604, "text": "So no, it was really just chat, chat."}, {"time": 1611, "text": "But it was very warm."}, {"time": 1611, "text": "So one summer I said to Herb, my students have all the really interesting conversations."}, {"time": 1619, "text": "I was teaching at the University of Pittsburgh then in the English department."}, {"time": 1623, "text": "They get to talk about the meaning of life and that kind of thing."}, {"time": 1623, "text": "And what do I have?"}, {"time": 1629, "text": "I have university meetings where we talk about the photocopying budget and whether the course on romantic poetry should be one semester or two."}, {"time": 1637, "text": "So Herb laughed."}, {"time": 1637, "text": "He said, yes, I know what you mean."}, {"time": 1643, "text": "He said, but you could do something about that."}, {"time": 1643, "text": "Dot, that was his wife, Dot and I used to have a salon at the University of Chicago every Sunday night."}, {"time": 1650, "text": "And we would have essentially an open house and people knew."}, {"time": 1658, "text": "It wasn't for a small talk."}, {"time": 1658, "text": "It was really for some topic of depth."}, {"time": 1667, "text": "He said, but my advice would be that you choose the topic ahead of time."}, {"time": 1667, "text": "Fine, I said."}, {"time": 1674, "text": "So we exchanged mail over the summer."}, {"time": 1674, "text": "That was US Post in those days because you didn't have personal email."}, {"time": 1681, "text": "And I decided I would organize it and there would be eight of us, Alan Noland, his wife, Herb Simon and his wife Dorothea."}, {"time": 1692, "text": "There was a novelist in town, a man named Mark Harris."}, {"time": 1701, "text": "He had just arrived and his wife Josephine."}, {"time": 1701, "text": "Mark was most famous then for a novel called Bang the Drum Slowly, which was about baseball."}, {"time": 1709, "text": "And Joe and me, so eight people."}, {"time": 1716, "text": "And we met monthly and we just sank our teeth into really hard topics and it was great fun."}, {"time": 1725, "text": "TK How have your own views around artificial intelligence changed through the process of writing Machines Who Think and afterwards, the ripple effects?"}, {"time": 1737, "text": "RL I was a little skeptical that this whole thing would work out."}, {"time": 1737, "text": "It didn't matter."}, {"time": 1737, "text": "To me, it was so audacious."}, {"time": 1744, "text": "AI generally."}, {"time": 1744, "text": "And in some ways, it hasn't worked out the way I expected so far."}, {"time": 1756, "text": "That is to say, there's this wonderful lot of apps, thanks to deep learning and so on."}, {"time": 1766, "text": "But those are algorithmic."}, {"time": 1766, "text": "And in the part of symbolic processing, there's very little yet."}, {"time": 1779, "text": "And that's a field that lies waiting for industrious graduate students."}, {"time": 1785, "text": "TK Maybe you can tell me some figures that popped up in your life in the 80s with expert systems where there was the symbolic AI possibilities of what most people think of as AI, if you dream of the possibilities of AI, it's really expert systems."}, {"time": 1800, "text": "And those hit a few walls and there was challenges there."}, {"time": 1807, "text": "And I think, yes, they will reemerge again with some new breakthroughs and so on."}, {"time": 1812, "text": "But what did that feel like, both the possibility and the winter that followed the slowdown in research?"}, {"time": 1817, "text": "BG Ah, you know, this whole thing about AI winter is to me a crock."}, {"time": 1825, "text": "TK Snow winters."}, {"time": 1826, "text": "BG Because I look at the basic research that was being done in the 80s, which is supposed to be, my God, it was really important."}, {"time": 1834, "text": "It was laying down things that nobody had thought about before, but it was basic research."}, {"time": 1840, "text": "You couldn't monetize it."}, {"time": 1840, "text": "Hence the winter."}, {"time": 1844, "text": "TK That's the winter."}, {"time": 1844, "text": "BG You know, research, scientific research goes and fits and starts."}, {"time": 1849, "text": "It isn't this nice smooth, oh, this follows this follows this."}, {"time": 1854, "text": "No, it just doesn't work that way."}, {"time": 1859, "text": "TK The interesting thing, the way winters happen, it's never the fault of the researchers."}, {"time": 1865, "text": "It's the some source of hype over promising."}, {"time": 1865, "text": "Well, no, let me take that back."}, {"time": 1865, "text": "Sometimes it is the fault of the researchers."}, {"time": 1872, "text": "Sometimes certain researchers might over promise the possibilities."}, {"time": 1877, "text": "They themselves believe that we're just a few years away."}, {"time": 1877, "text": "Sort of just recently talked to Elon Musk and he believes he'll have an autonomous vehicle, will have autonomous vehicles in a year."}, {"time": 1888, "text": "And he believes it."}, {"time": 1888, "text": "BG A year?"}, {"time": 1890, "text": "TK A year."}, {"time": 1890, "text": "With mass deployment of a time."}, {"time": 1893, "text": "BG For the record, this is 2019 right now."}, {"time": 1893, "text": "So he's talking 2020."}, {"time": 1898, "text": "TK To do the impossible, you really have to believe it."}, {"time": 1898, "text": "And I think what's going to happen when you believe it, because there's a lot of really brilliant people around him, is some good stuff will come out of it."}, {"time": 1908, "text": "Some unexpected brilliant breakthroughs will come out of it when you really believe it, when you work that hard."}, {"time": 1913, "text": "BG I believe that."}, {"time": 1913, "text": "And I believe autonomous vehicles will come."}, {"time": 1918, "text": "I just don't believe it'll be in a year."}, {"time": 1922, "text": "TK But nevertheless, there's, autonomous vehicles is a good example."}, {"time": 1922, "text": "There's a feeling many companies have promised by 2021, by 2022, Ford, GM, basically every single automotive company has promised they'll have autonomous vehicles."}, {"time": 1936, "text": "So that kind of over promise is what leads to the winter."}, {"time": 1941, "text": "Because we'll come to those dates, there won't be autonomous vehicles."}, {"time": 1946, "text": "BG And there'll be a feeling, well, wait a minute, if we took your word at that time, that means we just spent billions of dollars, had made no money, and there's a counter response to where everybody gives up on it."}, {"time": 1959, "text": "Sort of intellectually, at every level, the hope just dies."}, {"time": 1966, "text": "And all that's left is a few basic researchers."}, {"time": 1966, "text": "So you're uncomfortable with some aspects of this idea."}, {"time": 1972, "text": "TK Well, it's the difference between science and commerce."}, {"time": 1978, "text": "BG So you think science goes on the way it does?"}, {"time": 1984, "text": "TK Oh, science can really be killed by not getting proper funding or timely funding."}, {"time": 1994, "text": "I think Great Britain was a perfect example of that."}, {"time": 1994, "text": "The Lighthill report in, I can't remember the year, essentially said, there's no use Great Britain putting any money into this, it's going nowhere."}, {"time": 2006, "text": "And this was all about social factions in Great Britain."}, {"time": 2017, "text": "Edinburgh hated Cambridge and Cambridge hated Manchester."}, {"time": 2017, "text": "Somebody else can write that story."}, {"time": 2024, "text": "But it really did have a hard effect on research there."}, {"time": 2024, "text": "Now, they've come roaring back with Deep Mind."}, {"time": 2034, "text": "But that's one guy and his visionaries around him."}, {"time": 2034, "text": "BG But just to push on that, it's kind of interesting."}, {"time": 2043, "text": "You have this dislike of the idea of an AI winter."}, {"time": 2048, "text": "Where's that coming from?"}, {"time": 2048, "text": "Where were you?"}, {"time": 2048, "text": "TK Oh, because I just don't think it's true."}, {"time": 2055, "text": "BG There was a particular period of time."}, {"time": 2055, "text": "It's a romantic notion, certainly."}, {"time": 2061, "text": "TK Yeah, well."}, {"time": 2061, "text": "No, I admire science, perhaps more than I admire commerce."}, {"time": 2061, "text": "Commerce is fine."}, {"time": 2061, "text": "Hey, you know, we all gotta live."}, {"time": 2073, "text": "But science has a much longer view than commerce and continues almost regardless."}, {"time": 2086, "text": "It can't continue totally regardless, but almost regardless of what's saleable and what's not, what's monetizable and what's not."}, {"time": 2096, "text": "BG So the winter is just something that happens on the commerce side, and the science marches."}, {"time": 2101, "text": "That's a beautifully optimistic and inspiring message."}, {"time": 2110, "text": "I think if we look at the key people that work in AI, that work in key scientists in most disciplines, they continue working out of the love for science."}, {"time": 2122, "text": "You can always scrape up some funding to stay alive, and they continue working diligently."}, {"time": 2131, "text": "But there certainly is a huge amount of funding now, and there's a concern on the AI side and deep learning."}, {"time": 2138, "text": "There's a concern that we might, with over promising, hit another slowdown in funding, which does affect the number of students, you know, that kind of thing."}, {"time": 2147, "text": "RG Yeah, it does."}, {"time": 2147, "text": "BG So the kind of ideas you had in Machines Who Think, did you continue that curiosity through the decades that followed?"}, {"time": 2156, "text": "RG Yes, I did."}, {"time": 2156, "text": "BG And what was your view, historical view of how AI community evolved, the conversations about it, the work?"}, {"time": 2163, "text": "Has it persisted the same way from its birth?"}, {"time": 2169, "text": "RG No, of course not."}, {"time": 2169, "text": "It's just as we were just talking, the symbolic AI really kind of dried up and it all became algorithmic."}, {"time": 2179, "text": "I remember a young AI student telling me what he was doing, and I had been away from the field long enough."}, {"time": 2187, "text": "I'd gotten involved with complexity at the Santa Fe Institute."}, {"time": 2193, "text": "I thought, algorithms, yeah, they're in the service of, but they're not the main event."}, {"time": 2201, "text": "No, they became the main event."}, {"time": 2201, "text": "That surprised me."}, {"time": 2201, "text": "And we all know the downside of this."}, {"time": 2201, "text": "We all know that if you're using an algorithm to make decisions based on a gazillion human decisions, baked into it are all the mistakes that humans make, the bigotries, the short sightedness, and so on and so on."}, {"time": 2225, "text": "BG So you mentioned Santa Fe Institute."}, {"time": 2225, "text": "So you've written the novel Edge of Chaos, but it's inspired by the ideas of complexity, a lot of which have been extensively explored at the Santa Fe Institute."}, {"time": 2240, "text": "It's another fascinating topic, just sort of emergent complexity from chaos."}, {"time": 2251, "text": "Nobody knows how it happens really, but it seems to where all the interesting stuff does happen."}, {"time": 2257, "text": "So how did first, not your novel, but just complexity in general and the work at Santa Fe, fit into the bigger puzzle of the history of AI?"}, {"time": 2264, "text": "Or maybe even your personal journey through that?"}, {"time": 2271, "text": "RG One of the last projects I did concerning AI in particular was looking at the work of Harold Cohen, the painter."}, {"time": 2277, "text": "And Harold was deeply involved with AI."}, {"time": 2286, "text": "He was a painter first."}, {"time": 2286, "text": "And what his project, ARIN, which was a lifelong project, did was reflect his own cognitive processes."}, {"time": 2297, "text": "Harold and I, even though I wrote a book about it, we had a lot of friction between us."}, {"time": 2310, "text": "And I went, I thought, this is it."}, {"time": 2310, "text": "The book died."}, {"time": 2319, "text": "It was published and fell into a ditch."}, {"time": 2319, "text": "This is it."}, {"time": 2319, "text": "I'm finished."}, {"time": 2319, "text": "It's time for me to do something different."}, {"time": 2327, "text": "By chance, this was a sabbatical year for my husband."}, {"time": 2327, "text": "And we spent two months at the Santa Fe Institute and two months at Caltech."}, {"time": 2335, "text": "And then the spring semester in Munich, Germany."}, {"time": 2343, "text": "Those two months at the Santa Fe Institute were so restorative for me."}, {"time": 2343, "text": "And I began to, the Institute was very small then."}, {"time": 2355, "text": "It was in some kind of office complex on old Santa Fe trail."}, {"time": 2362, "text": "Everybody kept their door open."}, {"time": 2362, "text": "So you could crack your head on a problem."}, {"time": 2362, "text": "And if you finally didn't get it, you could walk in to see Stuart Kaufman or any number of people and say, I don't get this."}, {"time": 2379, "text": "Can you explain?"}, {"time": 2379, "text": "And one of the people that I was talking to about complex adaptive systems was Murray Gelman."}, {"time": 2386, "text": "And I told Murray what Harold Cohen had done."}, {"time": 2386, "text": "And I said, you know, this sounds to me like a complex adaptive system."}, {"time": 2395, "text": "And he said, yeah, it is."}, {"time": 2395, "text": "Well, what do you know?"}, {"time": 2402, "text": "Harold Aaron had all these kids and cousins all over the world in science and in economics and so on and so forth."}, {"time": 2409, "text": "I was so relieved."}, {"time": 2409, "text": "I thought, okay, your instincts are okay."}, {"time": 2409, "text": "You're doing the right thing."}, {"time": 2416, "text": "I didn't have the vocabulary."}, {"time": 2416, "text": "And that was one of the things that the Santa Fe Institute gave me."}, {"time": 2421, "text": "If I could have rewritten that book, no, it had just come out."}, {"time": 2421, "text": "I couldn't rewrite it."}, {"time": 2426, "text": "I would have had a vocabulary to explain what Aaron was doing."}, {"time": 2426, "text": "So I got really interested in what was going on at the Institute."}, {"time": 2434, "text": "The people were, again, bright and funny and willing to explain anything to this amateur."}, {"time": 2444, "text": "George Cowan, who was then the head of the Institute, said he thought it might be a nice idea if I wrote a book about the Institute."}, {"time": 2451, "text": "And I thought about it and I had my eye on some other project, God knows what."}, {"time": 2458, "text": "And I said, I'm sorry, George."}, {"time": 2458, "text": "Yeah, I'd really love to do it, but just not going to work for me at this moment."}, {"time": 2465, "text": "He said, oh, too bad."}, {"time": 2465, "text": "I think it would make an interesting book."}, {"time": 2471, "text": "Well, he was right and I was wrong."}, {"time": 2471, "text": "I wish I'd done it."}, {"time": 2471, "text": "But that's interesting."}, {"time": 2477, "text": "I hadn't thought about that, that that was a road not taken that I wish I'd taken."}, {"time": 2482, "text": "Well, you know what?"}, {"time": 2482, "text": "Just on that point, it's quite brave for you as a writer, as sort of coming from a world of literature and the literary thinking and historical thinking."}, {"time": 2491, "text": "I mean, just from that world and bravely talking to quite, I assume, large egos in AI or in complexity."}, {"time": 2509, "text": "Yeah, in AI or in complexity and so on."}, {"time": 2509, "text": "How'd you do it?"}, {"time": 2509, "text": "I mean, I suppose they could be intimidated of you as well because it's two different worlds coming together."}, {"time": 2523, "text": "I never picked up that anybody was intimidated by me."}, {"time": 2526, "text": "But how were you brave enough?"}, {"time": 2526, "text": "Where did you find the guts to sort of... God, just dumb luck."}, {"time": 2528, "text": "I mean, this is an interesting rock to turn over."}, {"time": 2528, "text": "I'm going to write a book about it."}, {"time": 2534, "text": "And you know, people have enough patience with writers if they think they're going to end up in a book that they let you flail around and so on."}, {"time": 2544, "text": "Well, but they also look if the writer has, if there's a sparkle in their eye, if they get it."}, {"time": 2552, "text": "When were you at the Santa Fe Institute?"}, {"time": 2555, "text": "The time I'm talking about is 1990, 1991, 1992."}, {"time": 2555, "text": "But we then, because Joe was an external faculty member, were in Santa Fe every summer."}, {"time": 2566, "text": "We bought a house there and I didn't have that much to do with the Institute anymore."}, {"time": 2572, "text": "I was writing my novels."}, {"time": 2572, "text": "I was doing whatever I was doing."}, {"time": 2580, "text": "But I loved the Institute and I loved again, the audacity of the ideas."}, {"time": 2588, "text": "That really appeals to me."}, {"time": 2592, "text": "I think that there's this feeling, much like in great institutes of neuroscience, for example, that they're in it for the long game of understanding something fundamental about reality and nature."}, {"time": 2609, "text": "So if we start now to look a little bit more recently, how, you know, AI is really popular today."}, {"time": 2616, "text": "How is this world, you mentioned algorithmic, but in general, is the spirit of the people, the kind of conversations you hear through the grapevine and so on, is that different than the roots that you remember?"}, {"time": 2635, "text": "The same kind of excitement, the same kind of, this is really going to make a difference in the world."}, {"time": 2641, "text": "And it will."}, {"time": 2641, "text": "You know, a lot of folks, especially young, 20 years old or something, they think we've just found something special here."}, {"time": 2647, "text": "We're going to change the world tomorrow."}, {"time": 2654, "text": "On a time scale, do you have a sense of what, of the time scale at which breakthroughs of the time scale at which breakthroughs in AI happen?"}, {"time": 2664, "text": "I really don't."}, {"time": 2664, "text": "Because look at Deep Learning."}, {"time": 2672, "text": "That was, Jeffrey Hinton came up with the algorithm in 86."}, {"time": 2672, "text": "But it took all these years for the technology to be good enough to actually be applicable."}, {"time": 2684, "text": "So no, I can't predict that at all."}, {"time": 2696, "text": "I wouldn't even try."}, {"time": 2696, "text": "Well, let me ask you to, not to try to predict, but to speak to the, you know, I'm sure in the 60s, as it continues now, there's people that think, let's call it, we can call it this fun word, the singularity."}, {"time": 2709, "text": "When there's a phase shift, there's some profound feeling where we're all really surprised by what's able to be achieved."}, {"time": 2716, "text": "I'm sure those dreams are there."}, {"time": 2722, "text": "I remember reading quotes in the 60s and those continued."}, {"time": 2722, "text": "How have your own views, maybe if you look back, about the timeline of a singularity changed?"}, {"time": 2734, "text": "Well, I'm not a big fan of the singularity as Ray Kurzweil has presented it."}, {"time": 2746, "text": "How would you define the Ray Kurzweil?"}, {"time": 2746, "text": "How do you think of singularity in those?"}, {"time": 2753, "text": "If I understand Kurzweil's view, it's sort of, there's going to be this moment when machines are smarter than humans and, you know, game over."}, {"time": 2759, "text": "However, the game over is."}, {"time": 2759, "text": "I mean, do they put us on a reservation?"}, {"time": 2767, "text": "Do they, et cetera, et cetera."}, {"time": 2767, "text": "And first of all, machines are smarter than humans in some ways all over the place."}, {"time": 2775, "text": "And they have been since adding machines were invented."}, {"time": 2781, "text": "So it's not, it's not going to come like some great eatable crossroads, you know, where they meet each other and our offspring, Oedipus says, you're dead."}, {"time": 2789, "text": "It's just not going to happen."}, {"time": 2797, "text": "So it's already game over with calculators, right?"}, {"time": 2797, "text": "They're already out to do much better at basic arithmetic than us."}, {"time": 2804, "text": "But you know, there's a human like intelligence."}, {"time": 2804, "text": "And it's not the ones that destroy us, but you know, somebody that you can have as a, as a friend, you can have deep connections with that kind of passing the touring test and beyond those kinds of ideas."}, {"time": 2817, "text": "Have you dreamt of those?"}, {"time": 2824, "text": "Oh yes, yes, yes."}, {"time": 2824, "text": "Those possibilities."}, {"time": 2824, "text": "In a book I wrote with Ed Feigenbaum, a book I wrote with Ed Feigenbaum, there's a little story called the geriatric robot."}, {"time": 2837, "text": "And how I came up with the geriatric robot is a story in itself."}, {"time": 2837, "text": "But here's what the geriatric robot does."}, {"time": 2844, "text": "It doesn't just clean you up and feed you and wheel you out into the sun."}, {"time": 2849, "text": "It's great advantages."}, {"time": 2849, "text": "It listens."}, {"time": 2849, "text": "It says, tell me again about the great coup of 73."}, {"time": 2849, "text": "Tell me again about how awful or how wonderful your grandchildren are and so on and so forth."}, {"time": 2872, "text": "And it isn't hanging around to inherit your money."}, {"time": 2872, "text": "It isn't hanging around because it can't get any other job."}, {"time": 2879, "text": "This is his job."}, {"time": 2879, "text": "And so on and so forth."}, {"time": 2879, "text": "Well, I would love something like that."}, {"time": 2889, "text": "I mean, for me, that deeply excites me."}, {"time": 2889, "text": "So I think there's a lot of us."}, {"time": 2895, "text": "Lex, you gotta know, it was a joke."}, {"time": 2895, "text": "I dreamed it up because I needed to talk to college students and I needed to give them some idea of what AI might be."}, {"time": 2900, "text": "And they were rolling in the aisles as I elaborated and elaborated and elaborated."}, {"time": 2906, "text": "When it went into the book, they took my hide off in the New York Review of Books."}, {"time": 2916, "text": "This is just what we have thought about these people in AI."}, {"time": 2921, "text": "They're inhuman."}, {"time": 2921, "text": "Come on, get over it."}, {"time": 2921, "text": "Don't you think that's a good thing for the world that AI could potentially do?"}, {"time": 2927, "text": "And furthermore, I'm pushing 80 now."}, {"time": 2932, "text": "By the time I need help like that, I also want it to roll itself in a corner and shut the fuck up."}, {"time": 2942, "text": "Let me linger on that point."}, {"time": 2942, "text": "Do you really though?"}, {"time": 2949, "text": "Yeah, I do."}, {"time": 2949, "text": "Don't you want it to push back a little bit?"}, {"time": 2953, "text": "A little."}, {"time": 2953, "text": "But I have watched my friends go through the whole issue around having help in the house."}, {"time": 2960, "text": "And some of them have been very lucky and had fabulous help."}, {"time": 2960, "text": "And some of them have had people in the house who want to keep the television going on all day, who want to talk on their phones all day."}, {"time": 2974, "text": "Just roll yourself in the corner and shut the fuck up."}, {"time": 2974, "text": "Unfortunately, us humans, when we're assistants, we're still, even when we're assisting others, we care about ourselves more."}, {"time": 2987, "text": "And so you create more frustration."}, {"time": 2987, "text": "And a robot AI assistant can really optimize the experience for you."}, {"time": 2994, "text": "I was just speaking to the point, you actually bring up a very, very good point."}, {"time": 3001, "text": "But I was speaking to the fact that us humans are a little complicated, that we don't necessarily want a perfect servant."}, {"time": 3011, "text": "I don't, maybe you disagree with that, but there's a, I think there's a push and pull with humans."}, {"time": 3021, "text": "A little tension, a little mystery that, of course, that's really difficult for AI to get right."}, {"time": 3021, "text": "But I do sense, especially today with social media, that people are getting more and more lonely, even young folks, and sometimes especially young folks, that loneliness, there's a longing for connection and AI can help alleviate some of that loneliness."}, {"time": 3042, "text": "Some, just somebody who listens, like in person."}, {"time": 3050, "text": "So to speak."}, {"time": 3050, "text": "So to speak, yeah."}, {"time": 3050, "text": "Yeah, that to me is really exciting."}, {"time": 3063, "text": "That is really exciting."}, {"time": 3063, "text": "But so if we look at that, that level of intelligence, which is exceptionally difficult to achieve actually, as the singularity or whatever, that's the human level bar, that people have dreamt of that too."}, {"time": 3075, "text": "Turing dreamt of it."}, {"time": 3075, "text": "He had a date timeline."}, {"time": 3075, "text": "Do you have, how have your own timeline evolved on past?"}, {"time": 3087, "text": "I don't even think about it."}, {"time": 3088, "text": "You don't even think?"}, {"time": 3089, "text": "Just this field has been so full of surprises for me."}, {"time": 3098, "text": "You're just taking in and see the fun about the basic science."}, {"time": 3102, "text": "I just can't."}, {"time": 3102, "text": "Maybe that's because I've been around the field long enough to think, you know, don't go that way."}, {"time": 3108, "text": "Herb Simon was terrible about making these predictions of when this and that would happen."}, {"time": 3114, "text": "And he was a sensible guy."}, {"time": 3120, "text": "His quotes are often used, right?"}, {"time": 3123, "text": "As a legend, yeah."}, {"time": 3124, "text": "Do you have concerns about AI, the existential threats that many people like Elon Musk and Sam Harris and others are thinking about?"}, {"time": 3138, "text": "That takes up half a chapter in my book."}, {"time": 3138, "text": "I call it the male gaze."}, {"time": 3149, "text": "Well, you hear me out."}, {"time": 3149, "text": "The male gaze is actually a term from film criticism."}, {"time": 3156, "text": "And I'm blocking on the women who dreamed this up."}, {"time": 3156, "text": "But she pointed out how most movies were made from the male point of view, that women were objects, not subjects."}, {"time": 3164, "text": "They didn't have any agency and so on and so forth."}, {"time": 3173, "text": "So when Elon and his pals Hawking and so on came, AI is going to eat our lunch and our dinner and our midnight snack too, I thought, what?"}, {"time": 3188, "text": "And I said to Ed Feigenbaum, oh, this is the first guy."}, {"time": 3188, "text": "First, these guys have always been the smartest guy on the block."}, {"time": 3193, "text": "And here comes something that might be smarter."}, {"time": 3193, "text": "Oh, let's stamp it out before it takes over."}, {"time": 3198, "text": "And Ed laughed."}, {"time": 3198, "text": "He said, I didn't think about it that way."}, {"time": 3204, "text": "But I did."}, {"time": 3204, "text": "And it is the male gaze."}, {"time": 3204, "text": "Okay, suppose these things do have agency."}, {"time": 3214, "text": "Well, let's wait and see what happens."}, {"time": 3214, "text": "Can we imbue them with ethics?"}, {"time": 3214, "text": "Can we imbue them with a sense of empathy?"}, {"time": 3223, "text": "Or are they just going to be, I don't know, we've had centuries of guys like that."}, {"time": 3234, "text": "That's interesting that the ego, the male gaze is immediately threatened."}, {"time": 3234, "text": "And so you can't think in a patient, calm way of how the tech could evolve."}, {"time": 3245, "text": "Speaking of which, your 96 book, The Future of Women, I think at the time and now, certainly now, I mean, I'm sorry, maybe at the time, but I'm more cognizant of now, is extremely relevant."}, {"time": 3263, "text": "You and Nancy Ramsey talk about four possible futures of women in science and tech."}, {"time": 3270, "text": "So if we look at the decades before and after the book was released, can you tell a history, sorry, of women in science and tech and how it has evolved?"}, {"time": 3286, "text": "How have things changed?"}, {"time": 3286, "text": "Where do we stand?"}, {"time": 3286, "text": "They have not changed enough."}, {"time": 3294, "text": "The way that women are ground down in computing is simply unbelievable."}, {"time": 3294, "text": "But what are the four possible futures for women in tech from the book?"}, {"time": 3305, "text": "What you're really looking at are various aspects of the present."}, {"time": 3313, "text": "So for each of those, you could say, oh yeah, we do have backlash."}, {"time": 3313, "text": "Look at what's happening with abortion and so on and so forth."}, {"time": 3320, "text": "We have one step forward, one step back."}]}, {"title": "Gary Marcus: Toward a Hybrid of Deep Learning and Symbolic AI | Lex Fridman Podcast #43", "id": "vNOTDn3D_RI", "quotes": [{"time": 316, "text": "And so machines might do that long before they do really good psychological reasoning, because it's easier to get kind of labeled data or to do direct experimentation on a microphone stand than it is to do direct experimentation on human beings to understand the levers that guide them."}, {"time": 334, "text": "That's a really interesting point, actually, whether it's easier to gain common sense knowledge or psychological knowledge."}, {"time": 341, "text": "I would say the common sense knowledge includes both physical knowledge and psychological knowledge."}, {"time": 346, "text": "And the argument I was making."}, {"time": 347, "text": "Well, you said physical versus psychological."}, {"time": 349, "text": "Yeah, physical versus psychological."}, {"time": 351, "text": "And the argument I was making is physical knowledge might be more accessible, because you could have a robot, for example, lift a bottle, try putting a bottle cap on it, see that it falls off if it does this, and see that it could turn it upside down, and so the robot could do some experimentation."}, {"time": 364, "text": "We do some of our psychological reasoning by looking at our own minds."}, {"time": 369, "text": "So I can sort of guess how you might react to something based on how I think I would react to it."}, {"time": 373, "text": "And robots don't have that intuition, and they also can't do experiments on people in the same way or we'll probably shut them down."}, {"time": 380, "text": "So if we wanted to have robots figure out how I respond to pain by pinching me in different ways, like that's probably, it's not gonna make it past the human subjects board and companies are gonna get sued or whatever."}, {"time": 392, "text": "So there's certain kinds of practical experience that are limited or off limits to robots."}, {"time": 399, "text": "That's a really interesting point."}, {"time": 401, "text": "What is more difficult to gain a grounding in?"}, {"time": 407, "text": "Because to play devil's advocate, I would say that human behavior is easier expressed in data and digital form."}, {"time": 416, "text": "And so when you look at Facebook algorithms, they get to observe human behavior."}, {"time": 421, "text": "So you get to study and manipulate even a human behavior in a way that you perhaps cannot study or manipulate the physical world."}, {"time": 429, "text": "So it's true why you said pain is like physical pain, but that's again, the physical world."}, {"time": 436, "text": "Emotional pain might be much easier to experiment with, perhaps unethical, but nevertheless, some would argue it's already going on."}, {"time": 445, "text": "I think that you're right, for example, that Facebook does a lot of experimentation in psychological reasoning."}, {"time": 452, "text": "In fact, Zuckerberg talked about AI at a talk that he gave in NIPS."}, {"time": 458, "text": "I wasn't there, but the conference has been renamed NeurIPS, but he used to be called NIPS when he gave the talk."}, {"time": 463, "text": "And he talked about Facebook basically having a gigantic theory of mind."}, {"time": 467, "text": "So I think it is certainly possible."}, {"time": 469, "text": "I mean, Facebook does some of that."}, {"time": 471, "text": "I think they have a really good idea of how to addict people to things."}, {"time": 473, "text": "They understand what draws people back to things."}, {"time": 476, "text": "I think they exploit it in ways that I'm not very comfortable with."}, {"time": 479, "text": "But even so, I think that there are only some slices of human experience that they can access through the kind of interface they have."}, {"time": 487, "text": "And of course, they're doing all kinds of VR stuff, and maybe that'll change and they'll expand their data."}, {"time": 491, "text": "And I'm sure that that's part of their goal."}, {"time": 494, "text": "So it is an interesting question."}, {"time": 496, "text": "I think love, fear, insecurity, all of the things that, I would say some of the deepest things about human nature and the human mind could be explored through digital form."}, {"time": 510, "text": "It's that you're actually the first person just now that brought up, I wonder what is more difficult."}, {"time": 515, "text": "Because I think folks who are the slow, and we'll talk a lot about deep learning, but the people who are thinking beyond deep learning are thinking about the physical world."}, {"time": 526, "text": "You're starting to think about robotics in the home robotics."}, {"time": 529, "text": "How do we make robots manipulate objects, which requires an understanding of the physical world and then requires common sense reasoning."}, {"time": 537, "text": "And that has felt to be like the next step for common sense reasoning, but you've now brought up the idea that there's also the emotional part."}, {"time": 543, "text": "And it's interesting whether that's hard or easy."}, {"time": 546, "text": "I think some parts of it are and some aren't."}, {"time": 548, "text": "So my company that I recently founded with Rod Brooks, from MIT for many years and so forth, we're interested in both."}, {"time": 557, "text": "We're interested in physical reasoning and psychological reasoning, among many other things."}, {"time": 561, "text": "And there are pieces of each of these that are accessible."}, {"time": 566, "text": "So if you want a robot to figure out whether it can fit under a table, that's a relatively accessible piece of physical reasoning."}, {"time": 573, "text": "If you know the height of the table and you know the height of the robot, it's not that hard."}, {"time": 576, "text": "If you wanted to do physical reasoning about Jenga, it gets a little bit more complicated and you have to have higher resolution data in order to do it."}, {"time": 585, "text": "With psychological reasoning, it's not that hard to know, for example, that people have goals and they like to act on those goals, but it's really hard to know exactly what those goals are."}, {"time": 594, "text": "But ideas of frustration."}, {"time": 596, "text": "I mean, you could argue it's extremely difficult to understand the sources of human frustration as they're playing Jenga with you, or not."}, {"time": 605, "text": "You could argue that it's very accessible."}, {"time": 608, "text": "There's some things that are gonna be obvious and some not."}, {"time": 610, "text": "So I don't think anybody really can do this well yet, but I think it's not inconceivable to imagine machines in the not so distant future being able to understand that if people lose in a game, that they don't like that."}, {"time": 626, "text": "That's not such a hard thing to program and it's pretty consistent across people."}, {"time": 629, "text": "Most people don't enjoy losing and so that makes it relatively easy to code."}, {"time": 634, "text": "On the other hand, if you wanted to capture everything about frustration, well, people can get frustrated for a lot of different reasons."}, {"time": 640, "text": "They might get sexually frustrated, they might get frustrated, they can get their promotion at work, all kinds of different things."}, {"time": 646, "text": "And the more you expand the scope, the harder it is for anything like the existing techniques to really do that."}, {"time": 653, "text": "So I'm talking to Garret Kasparov next week and he seemed pretty frustrated with his game against Deep Blue, so."}, {"time": 658, "text": "Yeah, well, I'm frustrated with my game against him last year, because I played him, I had two excuses, I'll give you my excuses up front, but it won't mitigate the outcome."}, {"time": 667, "text": "I was jet lagged and I hadn't played in 25 or 30 years, but the outcome is he completely destroyed me and it wasn't even close."}, {"time": 674, "text": "Have you ever been beaten in any board game by a machine?"}, {"time": 679, "text": "I have, I actually played the predecessor to Deep Blue."}, {"time": 684, "text": "Deep Thought, I believe it was called, and that too crushed me."}, {"time": 690, "text": "And that was, and after that you realize it's over for us."}, {"time": 695, "text": "Well, there's no point in my playing Deep Blue."}, {"time": 696, "text": "I mean, it's a waste of Deep Blue's computation."}, {"time": 700, "text": "I mean, I played Kasparov because we both gave lectures this same event and he was playing 30 people."}, {"time": 706, "text": "I forgot to mention that."}, {"time": 706, "text": "Not only did he crush me, but he crushed 29 other people at the same time."}, {"time": 710, "text": "I mean, but the actual philosophical and emotional experience of being beaten by a machine, I imagine is a, I mean, to you who thinks about these things may be a profound experience."}, {"time": 723, "text": "Or no, it was a simple mathematical experience."}, {"time": 727, "text": "Yeah, I think a game like chess particularly where you have perfect information, it's two player closed end and there's more computation for the computer, it's no surprise the machine wins."}, {"time": 738, "text": "I mean, I'm not sad when a computer, I'm not sad when a computer calculates a cube root faster than me."}, {"time": 745, "text": "Like, I know I can't win that game."}, {"time": 747, "text": "I'm not gonna try."}, {"time": 748, "text": "Well, with a system like AlphaGo or AlphaZero, do you see a little bit more magic in a system like that even though it's simply playing a board game?"}, {"time": 757, "text": "But because there's a strong learning component?"}, {"time": 759, "text": "You know, I find you should mention that in the context of this conversation because Kasparov and I are working on an article that's gonna be called AI is not magic."}, {"time": 767, "text": "And, you know, neither one of us thinks that it's magic."}, {"time": 770, "text": "And part of the point of this article is that AI is actually a grab bag of different techniques and some of them have, or they each have their own unique strengths and weaknesses."}, {"time": 780, "text": "So, you know, you read media accounts and it's like, ooh, AI, it must be magical or it can solve any problem."}, {"time": 786, "text": "Well, no, some problems are really accessible like chess and go and other problems like reading are completely outside the current technology."}, {"time": 794, "text": "And it's not like you can take the technology, that drives AlphaGo and apply it to reading and get anywhere."}, {"time": 801, "text": "You know, DeepMind has tried that a bit."}, {"time": 803, "text": "They have all kinds of resources."}, {"time": 804, "text": "You know, they built AlphaGo and they have, you know, I wrote a piece recently that they lost and you can argue about the word lost, but they spent $530 million more than they made last year."}, {"time": 814, "text": "So, you know, they're making huge investments."}, {"time": 816, "text": "They have a large budget and they have applied the same kinds of techniques to reading or to language."}, {"time": 823, "text": "It's just much less productive there because it's a fundamentally different kind of problem."}, {"time": 827, "text": "Chess and go and so forth are closed end problems."}, {"time": 830, "text": "The rules haven't changed in 2,500 years."}, {"time": 832, "text": "There's only so many moves you can make."}, {"time": 834, "text": "You can talk about the exponential as you look at the combinations of moves, but fundamentally, you know, the go board has 361 squares."}, {"time": 842, "text": "That's the only, you know, those intersections are the only places that you can place your stone."}, {"time": 847, "text": "Whereas when you're reading, the next sentence could be anything."}, {"time": 851, "text": "You know, it's completely up to the writer what they're gonna do next."}, {"time": 854, "text": "That's fascinating that you think this way."}, {"time": 856, "text": "You're clearly a brilliant mind who points out the emperor has no clothes, but so I'll play the role of a person who says."}, {"time": 862, "text": "You're gonna put clothes on the emperor?"}, {"time": 863, "text": "Good luck with it."}, {"time": 864, "text": "It romanticizes the notion of the emperor, period, suggesting that clothes don't even matter."}, {"time": 870, "text": "Okay, so that's really interesting that you're talking about language."}, {"time": 876, "text": "So there's the physical world of being able to move about the world, making an omelet and coffee and so on."}, {"time": 881, "text": "There's language where you first understand what's being written and then maybe even more complicated than that, having a natural dialogue."}, {"time": 891, "text": "And then there's the game of go and chess."}, {"time": 893, "text": "I would argue that language is much closer to go than it is to the physical world."}, {"time": 899, "text": "Like it is still very constrained."}, {"time": 901, "text": "When you say the possibility of the number of sentences that could come, it is huge, but it nevertheless is much more constrained."}, {"time": 909, "text": "It feels maybe I'm wrong than the possibilities that the physical world brings us."}, {"time": 914, "text": "There's something to what you say in some ways in which I disagree."}, {"time": 917, "text": "So one interesting thing about language is that it abstracts away."}, {"time": 923, "text": "This bottle, I don't know if it would be in the field of view is on this table and I use the word on here and I can use the word on here, maybe not here, but that one word encompasses in analog space sort of infinite number of possibilities."}, {"time": 939, "text": "So there is a way in which language filters down the variation of the world and there's other ways."}, {"time": 946, "text": "So we have a grammar and more or less you have to follow the rules of that grammar."}, {"time": 951, "text": "You can break them a little bit, but by and large we follow the rules of grammar and so that's a constraint on language."}, {"time": 957, "text": "So there are ways in which language is a constrained system."}, {"time": 959, "text": "On the other hand, there are many arguments that say there's an infinite number of possible sentences and you can establish that by just stacking them up."}, {"time": 967, "text": "So I think there's water on the table, you think that I think there's water on the table, your mother thinks that you think that I think that water's on the table, your brother thinks that maybe your mom is wrong to think that you think that I think, right?"}, {"time": 978, "text": "So we can make sentences of infinite length or we can stack up adjectives."}, {"time": 983, "text": "This is a very silly example, a very, very silly example, a very, very, very, very, very, very silly example and so forth."}, {"time": 989, "text": "So there are good arguments that there's an infinite range of sentences."}, {"time": 992, "text": "In any case, it's vast by any reasonable measure and for example, almost anything in the physical world we can talk about in the language world and interestingly, many of the sentences that we understand, we can only understand if we have a very rich model of the physical world."}, {"time": 1007, "text": "So I don't ultimately want to adjudicate the debate that I think you just set up, but I find it interesting."}, {"time": 1014, "text": "Maybe the physical world is even more complicated than language, I think that's fair, but."}, {"time": 1019, "text": "Language is really, really complicated."}, {"time": 1023, "text": "It's really, really hard."}, {"time": 1024, "text": "Well, it's really, really hard for machines, for linguists, people trying to understand it."}, {"time": 1028, "text": "It's not that hard for children and that's part of what's driven my whole career."}, {"time": 1032, "text": "I was a student of Steven Pinker's and we were trying to figure out why kids could learn language when machines couldn't."}, {"time": 1038, "text": "I think we're gonna get into language, we're gonna get into communication intelligence and neural networks and so on, but let me return to the high level, the futuristic for a brief moment."}, {"time": 1052, "text": "So you've written in your book, in your new book, it would be arrogant to suppose that we could forecast where AI will be or the impact it will have in a thousand years or even 500 years."}, {"time": 1065, "text": "So let me ask you to be arrogant."}, {"time": 1068, "text": "What do AI systems with or without physical bodies look like 100 years from now?"}, {"time": 1073, "text": "If you would just, you can't predict, but if you were to philosophize and imagine, do."}, {"time": 1080, "text": "Can I first justify the arrogance before you try to push me beyond it?"}, {"time": 1085, "text": "I mean, there are examples like, people figured out how electricity worked, they had no idea that that was gonna lead to cell phones."}, {"time": 1093, "text": "I mean, things can move awfully fast once new technologies are perfected."}, {"time": 1097, "text": "Even when they made transistors, they weren't really thinking that cell phones would lead to social networking."}, {"time": 1103, "text": "There are nevertheless predictions of the future, which are statistically unlikely to come to be, but nevertheless is the best."}, {"time": 1109, "text": "You're asking me to be wrong."}, {"time": 1111, "text": "Asking you to be statistically."}, {"time": 1112, "text": "In which way would I like to be wrong?"}, {"time": 1114, "text": "Pick the least unlikely to be wrong thing, even though it's most very likely to be wrong."}, {"time": 1119, "text": "I mean, here's some things that we can safely predict, I suppose."}, {"time": 1122, "text": "We can predict that AI will be faster than it is now."}, {"time": 1127, "text": "It will be cheaper than it is now."}, {"time": 1129, "text": "It will be better in the sense of being more general and applicable in more places."}, {"time": 1136, "text": "It will be pervasive."}, {"time": 1139, "text": "I mean, these are easy predictions."}, {"time": 1141, "text": "I'm sort of modeling them in my head on Jeff Bezos's famous predictions."}, {"time": 1145, "text": "He says, I can't predict the future, not in every way, I'm paraphrasing."}, {"time": 1149, "text": "But I can predict that people will never wanna pay more money for their stuff."}, {"time": 1153, "text": "They're never gonna want it to take longer to get there."}, {"time": 1155, "text": "So you can't predict everything, but you can predict something."}, {"time": 1158, "text": "Sure, of course it's gonna be faster and better."}, {"time": 1161, "text": "But what we can't really predict is the full scope of where AI will be in a certain period."}, {"time": 1168, "text": "I mean, I think it's safe to say that, although I'm very skeptical about current AI, that it's possible to do much better."}, {"time": 1177, "text": "You know, there's no in principled argument that says AI is an insolvable problem, that there's magic inside our brains that will never be captured."}, {"time": 1184, "text": "I mean, I've heard people make those kind of arguments."}, {"time": 1186, "text": "I don't think they're very good."}, {"time": 1188, "text": "So AI's gonna come, and probably 500 years is plenty to get there."}, {"time": 1195, "text": "And then once it's here, it really will change everything."}, {"time": 1199, "text": "So when you say AI's gonna come, are you talking about human level intelligence?"}, {"time": 1203, "text": "So maybe I..."}, {"time": 1204, "text": "I like the term general intelligence."}, {"time": 1206, "text": "So I don't think that the ultimate AI, if there is such a thing, is gonna look just like humans."}, {"time": 1211, "text": "I think it's gonna do some things that humans do better than current machines, like reason flexibly."}, {"time": 1218, "text": "And understand language and so forth."}, {"time": 1221, "text": "But it doesn't mean they have to be identical to humans."}, {"time": 1223, "text": "So for example, humans have terrible memory, and they suffer from what some people call motivated reasoning."}, {"time": 1229, "text": "So they like arguments that seem to support them, and they dismiss arguments that they don't like."}, {"time": 1235, "text": "There's no reason that a machine should ever do that."}, {"time": 1238, "text": "So you see that those limitations of memory as a bug, not a feature."}, {"time": 1246, "text": "One is I was on a panel with Danny Kahneman, the Nobel Prize winner, last night, and we were talking about this stuff."}, {"time": 1251, "text": "And I think what we converged on is that humans are a low bar to exceed."}, {"time": 1256, "text": "They may be outside of our skill right now, but as AI programmers, but eventually AI will exceed it."}, {"time": 1264, "text": "So we're not talking about human level AI."}, {"time": 1266, "text": "We're talking about general intelligence that can do all kinds of different things and do it without some of the flaws that human beings have."}, {"time": 1272, "text": "The other thing I'll say is I wrote a whole book, actually, about the flaws of humans."}, {"time": 1275, "text": "It's actually a nice bookend to the, or counterpoint to the current book."}, {"time": 1279, "text": "So I wrote a book called Cluj, which was about the limits of the human mind."}, {"time": 1284, "text": "The current book is kind of about those few things that humans do a lot better than machines."}, {"time": 1288, "text": "Do you think it's possible that the flaws of the human mind, the limits of memory, our mortality, our bias, is a strength, not a weakness, that that is the thing that enables, from which motivation springs and meaning springs or not?"}, {"time": 1307, "text": "I've heard a lot of arguments like this."}, {"time": 1309, "text": "I've never found them that convincing."}, {"time": 1310, "text": "I think that there's a lot of making lemonade out of lemons."}, {"time": 1315, "text": "So we, for example, do a lot of free association where one idea just leads to the next and they're not really that well connected."}, {"time": 1322, "text": "And we enjoy that and we make poetry out of it and we make kind of movies with free associations and it's fun and whatever."}, {"time": 1328, "text": "I don't think that's really a virtue of the system."}, {"time": 1332, "text": "I think that the limitations in human reasoning actually get us in a lot of trouble."}, {"time": 1336, "text": "Like, for example, politically we can't see eye to eye because we have the motivational reasoning I was talking about and something related called confirmation bias."}, {"time": 1345, "text": "So we have all of these problems that actually make for a rougher society because we can't get along because we can't interpret the data in shared ways."}, {"time": 1354, "text": "And then we do some nice stuff with that."}, {"time": 1356, "text": "So my free associations are different from yours and you're kind of amused by them and that's great."}, {"time": 1361, "text": "And hence poetry."}, {"time": 1362, "text": "So there are lots of ways in which we take a lousy situation and make it good."}, {"time": 1367, "text": "Another example would be our memories are terrible."}, {"time": 1370, "text": "So we play games like Concentration where you flip over two cards, try to find a pair."}, {"time": 1374, "text": "Can you imagine a computer playing that?"}, {"time": 1376, "text": "Computer's like, this is the dullest game in the world."}, {"time": 1378, "text": "I know where all the cards are, I see it once, I know where it is, what are you even talking about?"}, {"time": 1382, "text": "So we make a fun game out of having this terrible memory."}, {"time": 1387, "text": "So we are imperfect in discovering and optimizing some kind of utility function."}, {"time": 1393, "text": "But you think in general, there is a utility function."}, {"time": 1396, "text": "There's an objective function that's better than others."}, {"time": 1398, "text": "I didn't say that."}, {"time": 1400, "text": "But see, the presumption, when you say..."}, {"time": 1404, "text": "I think you could design a better memory system."}, {"time": 1407, "text": "You could argue about utility functions and how you wanna think about that."}, {"time": 1412, "text": "But objectively, it would be really nice to do some of the following things."}, {"time": 1416, "text": "To get rid of memories that are no longer useful."}, {"time": 1421, "text": "Objectively, that would just be good."}, {"time": 1422, "text": "And we're not that good at it."}, {"time": 1423, "text": "So when you park in the same lot every day, you confuse where you parked today with where you parked yesterday with where you parked the day before and so forth."}, {"time": 1430, "text": "So you blur together a series of memories."}, {"time": 1432, "text": "There's just no way that that's optimal."}, {"time": 1435, "text": "I mean, I've heard all kinds of wacky arguments of people trying to defend that."}, {"time": 1438, "text": "But in the end of the day, I don't think any of them hold water."}, {"time": 1440, "text": "It's just above."}, {"time": 1441, "text": "Or memories of traumatic events would be possibly a very nice feature to have to get rid of those."}, {"time": 1446, "text": "It'd be great if you could just be like, I'm gonna wipe this sector."}, {"time": 1450, "text": "I'm done with that."}, {"time": 1452, "text": "I didn't have fun last night."}, {"time": 1453, "text": "I don't wanna think about it anymore."}, {"time": 1454, "text": "Whoop, bye bye."}, {"time": 1455, "text": "I'm gone."}, {"time": 1456, "text": "But we can't."}, {"time": 1457, "text": "Do you think it's possible to build a system..."}, {"time": 1460, "text": "So you said human level intelligence is a weird concept, but... Well, I'm saying I prefer general intelligence."}, {"time": 1465, "text": "General intelligence."}, {"time": 1466, "text": "I mean, human level intelligence is a real thing."}, {"time": 1468, "text": "And you could try to make a machine that matches people or something like that."}, {"time": 1471, "text": "I'm saying that per se shouldn't be the objective, but rather that we should learn from humans the things they do well and incorporate that into our AI, just as we incorporate the things that machines do well that people do terribly."}, {"time": 1483, "text": "So, I mean, it's great that AI systems can do all this brute force computation that people can't."}, {"time": 1488, "text": "And one of the reasons I work on this stuff is because I would like to see machines solve problems that people can't, that combine the strength, or that in order to be solved would combine the strengths of machines to do all this computation with the ability, let's say, of people to read."}, {"time": 1504, "text": "So I'd like machines that can read the entire medical literature in a day."}, {"time": 1508, "text": "7,000 new papers or whatever the numbers, comes out every day."}, {"time": 1511, "text": "There's no way for any doctor or whatever to read them all."}, {"time": 1515, "text": "A machine that could read would be a brilliant thing."}, {"time": 1517, "text": "And that would be strengths of brute force computation combined with kind of subtlety and understanding medicine that a good doctor or scientist has."}, {"time": 1526, "text": "So if we can linger a little bit on the idea of general intelligence."}, {"time": 1529, "text": "So Yann LeCun believes that human intelligence isn't general at all, it's very narrow."}, {"time": 1535, "text": "How do you think?"}, {"time": 1536, "text": "I don't think that makes sense."}, {"time": 1538, "text": "We have lots of narrow intelligences for specific problems."}, {"time": 1542, "text": "But the fact is, like, anybody can walk into, let's say, a Hollywood movie, and reason about the content of almost anything that goes on there."}, {"time": 1551, "text": "So you can reason about what happens in a bank robbery, or what happens when someone is infertile and wants to go to IVF to try to have a child, or you can, the list is essentially endless."}, {"time": 1565, "text": "And not everybody understands every scene in the movie, but there's a huge range of things that pretty much any ordinary adult can understand."}, {"time": 1575, "text": "His argument is, is that actually, the set of things seems large for us humans because we're very limited in considering the kind of possibilities of experiences that are possible."}, {"time": 1587, "text": "But in fact, the amount of experience that are possible is infinitely larger."}, {"time": 1592, "text": "Well, I mean, if you wanna make an argument that humans are constrained in what they can understand, I have no issue with that."}, {"time": 1601, "text": "But it's still not the same thing at all as saying, here's a system that can play Go."}, {"time": 1607, "text": "It's been trained on five million games."}, {"time": 1609, "text": "And then I say, can it play on a rectangular board rather than a square board?"}, {"time": 1613, "text": "And you say, well, if I retrain it from scratch on another five million games, it can."}, {"time": 1618, "text": "That's really, really narrow, and that's where we are."}, {"time": 1621, "text": "We don't have even a system that could play Go and then without further retraining, play on a rectangular board, which any human could do with very little problem."}, {"time": 1632, "text": "So that's what I mean by narrow."}, {"time": 1634, "text": "And so it's just wordplay to say."}, {"time": 1636, "text": "That is semantics, yeah."}, {"time": 1638, "text": "Then it's just words."}, {"time": 1639, "text": "Then yeah, you mean general in a sense that you can do all kinds of Go board shapes flexibly."}, {"time": 1645, "text": "Well, that would be like a first step in the right direction, but obviously that's not what it really meaning."}, {"time": 1650, "text": "You're kidding."}, {"time": 1652, "text": "What I mean by general is that you could transfer the knowledge you learn in one domain to another."}, {"time": 1658, "text": "So if you learn about bank robberies in movies and there's chase scenes, then you can understand that amazing scene in Breaking Bad when Walter White has a car chase scene with only one person."}, {"time": 1671, "text": "He's the only one in it."}, {"time": 1672, "text": "And you can reflect on how that car chase scene is like all the other car chase scenes you've ever seen and totally different and why that's cool."}, {"time": 1681, "text": "And the fact that the number of domains you can do that with is finite doesn't make it less general."}, {"time": 1685, "text": "So the idea of general is you could just do it on a lot of, don't transfer it across a lot of domains."}, {"time": 1689, "text": "Yeah, I mean, I'm not saying humans are infinitely general or that humans are perfect."}, {"time": 1692, "text": "I just said a minute ago, it's a low bar, but it's just, it's a low bar."}, {"time": 1697, "text": "But right now, like the bar is here and we're there and eventually we'll get way past it."}, {"time": 1702, "text": "So speaking of low bars, you've highlighted in your new book as well, but a couple of years ago wrote a paper titled Deep Learning, A Critical Appraisal that lists 10 challenges faced by current deep learning systems."}, {"time": 1716, "text": "So let me summarize them as data efficiency, transfer learning, hierarchical knowledge, open ended inference, explainability, integrating prior knowledge, cause of reasoning, modeling on a stable world, robustness, adversarial examples and so on."}, {"time": 1734, "text": "And then my favorite probably is reliability in the engineering of real world systems."}, {"time": 1739, "text": "So whatever people can read the paper, they should definitely read the paper, should definitely read your book."}, {"time": 1744, "text": "But which of these challenges is solved in your view has the biggest impact on the AI community?"}, {"time": 1753, "text": "And I'm gonna be evasive because I think that they go together a lot."}, {"time": 1757, "text": "So some of them might be solved independently of others, but I think a good solution to AI starts by having real, what I would call cognitive models of what's going on."}, {"time": 1768, "text": "So right now we have a approach that's dominant where you take statistical approximations of things, but you don't really understand them."}, {"time": 1775, "text": "So you know that bottles are correlated in your data with bottle caps, but you don't understand that there's a thread on the bottle cap that fits with the thread on the bottle and then that's what tightens it."}, {"time": 1786, "text": "If I tighten enough that there's a seal and the water won't come out."}, {"time": 1789, "text": "Like there's no machine that understands that."}, {"time": 1791, "text": "And having a good cognitive model of that kind of everyday phenomena is what we call common sense."}, {"time": 1796, "text": "And if you had that, then a lot of these other things start to fall into at least a little bit better place."}, {"time": 1802, "text": "Right now you're like learning correlations between pixels when you play a video game or something like that."}, {"time": 1807, "text": "And it doesn't work very well."}, {"time": 1808, "text": "It works when the video game is just the way that you studied it and then you alter the video game in small ways, like you move the paddle and break out a few pixels and the system falls apart."}, {"time": 1817, "text": "Because it doesn't understand, it doesn't have a representation of a paddle, a ball, a wall, a set of bricks and so forth."}, {"time": 1823, "text": "And so it's reasoning at the wrong level."}, {"time": 1826, "text": "So the idea of common sense, it's full of mystery, you've worked on it, but it's nevertheless full of mystery, full of promise."}, {"time": 1834, "text": "What does common sense mean?"}, {"time": 1836, "text": "What does knowledge mean?"}, {"time": 1838, "text": "So the way you've been discussing it now is very intuitive."}, {"time": 1840, "text": "It makes a lot of sense that that is something we should have and that's something deep learning systems don't have."}, {"time": 1845, "text": "But the argument could be that we're oversimplifying it because we're oversimplifying the notion of common sense because that's how it feels like we as humans at the cognitive level approach problems."}, {"time": 1860, "text": "A lot of people aren't actually gonna read my book."}, {"time": 1863, "text": "But if they did read the book, one of the things that might come as a surprise to them is that we actually say common sense is really hard and really complicated."}, {"time": 1871, "text": "So they would probably, my critics know that I like common sense, but that chapter actually starts by us beating up not on deep learning, but kind of on our own home team as it will."}, {"time": 1881, "text": "So Ernie and I are first and foremost people that believe in at least some of what good old fashioned AI tried to do."}, {"time": 1888, "text": "So we believe in symbols and logic and programming."}, {"time": 1892, "text": "Things like that are important."}, {"time": 1893, "text": "And we go through why even those tools that we hold fairly dear aren't really enough."}, {"time": 1899, "text": "So we talk about why common sense is actually many things."}, {"time": 1902, "text": "And some of them fit really well with those classical sets of tools."}, {"time": 1906, "text": "So things like taxonomy."}, {"time": 1908, "text": "So I know that a bottle is an object or it's a vessel, let's say."}, {"time": 1912, "text": "And I know a vessel is an object and objects are material things in the physical world."}, {"time": 1917, "text": "So I can make some inferences."}, {"time": 1920, "text": "If I know that vessels need to not have holes in them, then I can infer that in order to carry their contents, then I can infer that a bottle shouldn't have a hole in it in order to carry its contents."}, {"time": 1932, "text": "So you can do hierarchical inference and so forth."}, {"time": 1935, "text": "And we say that's great, but it's only a tiny piece of what you need for common sense."}, {"time": 1941, "text": "We give lots of examples that don't fit into that."}, {"time": 1943, "text": "So another one that we talk about is a cheese grater."}, {"time": 1946, "text": "You've got holes in a cheese grater."}, {"time": 1948, "text": "You've got a handle on top."}, {"time": 1949, "text": "You can build a model in the game engine sense of a model so that you could have a little cartoon character flying around through the holes of the grater."}, {"time": 1957, "text": "But we don't have a system yet."}, {"time": 1959, "text": "Taxonomy doesn't help us that much that really understands why the handle is on top and what you do with the handle, or why all of those circles are sharp, or how you'd hold the cheese with respect to the grater in order to make it actually work."}, {"time": 1972, "text": "Do you think these ideas are just abstractions that could emerge on a system like a very large deep neural network?"}, {"time": 1979, "text": "I'm a skeptic that that kind of emergence per se can work."}, {"time": 1983, "text": "So I think that deep learning might play a role in the systems that do what I want systems to do, but it won't do it by itself."}, {"time": 1989, "text": "I've never seen a deep learning system really extract an abstract concept."}, {"time": 1995, "text": "What they do, principled reasons for that stemming from how back propagation works, how the architectures are set up."}, {"time": 2002, "text": "One example is deep learning people actually all build in something called convolution, which Jan Lacune is famous for, which is an abstraction."}, {"time": 2013, "text": "They don't have their systems learn this."}, {"time": 2014, "text": "So the abstraction is an object that looks the same if it appears in different places."}, {"time": 2019, "text": "And what Lacune figured out and why, essentially why he was a co winner of the Turing Award was that if you programmed this in innately, then your system would be a whole lot more efficient."}, {"time": 2030, "text": "In principle, this should be learnable, but people don't have systems that kind of reify things and make them more abstract."}, {"time": 2038, "text": "And so what you'd really wind up with if you don't program that in advance is a system that kind of realizes that this is the same thing as this, but then I take your little clock there and I move it over and it doesn't realize that the same thing applies to the clock."}, {"time": 2050, "text": "So the really nice thing, you're right, that convolution is just one of the things that's like, it's an innate feature that's programmed by the human expert."}, {"time": 2059, "text": "We need more of those, not less."}, {"time": 2061, "text": "Yes, but the nice feature is it feels like that requires coming up with that brilliant idea, can get you a Turing Award, but it requires less effort than encoding and something we'll talk about, the expert system."}, {"time": 2076, "text": "So encoding a lot of knowledge by hand."}, {"time": 2080, "text": "So it feels like there's a huge amount of limitations which you clearly outline with deep learning, but the nice feature of deep learning, whatever it is able to accomplish, it does a lot of stuff automatically without human intervention."}, {"time": 2094, "text": "Well, and that's part of why people love it, right?"}, {"time": 2097, "text": "But I always think of this quote from Bertrand Russell, which is it has all the advantages of theft over honest toil."}, {"time": 2104, "text": "It's really hard to program into a machine a notion of causality or even how a bottle works or what containers are."}, {"time": 2112, "text": "Ernie Davis and I wrote a, I don't know, 45 page academic paper trying just to understand what a container is, which I don't think anybody ever read the paper, but it's a very detailed analysis of all the things, well, not even all of it, some of the things you need to do in order to understand a container."}, {"time": 2128, "text": "It would be a whole lot nice, and I'm a coauthor on the paper, I made it a little bit better, but Ernie did the hard work for that particular paper."}, {"time": 2136, "text": "And it took him like three months to get the logical statements correct."}, {"time": 2140, "text": "And maybe that's not the right way to do it, it's a way to do it."}, {"time": 2144, "text": "But on that way of doing it, it's really hard work to do something as simple as understanding containers."}, {"time": 2150, "text": "And nobody wants to do that hard work, even Ernie didn't want to do that hard work."}, {"time": 2155, "text": "Everybody would rather just like feed their system in with a bunch of videos with a bunch of containers and have the systems infer how containers work."}, {"time": 2163, "text": "It would be like so much less effort, let the machine do the work."}, {"time": 2166, "text": "And so I understand the impulse, I understand why people want to do that."}, {"time": 2170, "text": "I just don't think that it works."}, {"time": 2171, "text": "I've never seen anybody build a system that in a robust way can actually watch videos and predict exactly which containers would leak and which ones wouldn't or something like, and I know someone's gonna go out and do that since I said it, and I look forward to seeing it."}, {"time": 2188, "text": "But getting these things to work robustly is really, really hard."}, {"time": 2192, "text": "So Yann LeCun, who was my colleague at NYU for many years, thinks that the hard work should go into defining an unsupervised learning algorithm that will watch videos, use the next frame basically in order to tell it what's going on."}, {"time": 2208, "text": "And he thinks that's the Royal road and he's willing to put in the work in devising that algorithm."}, {"time": 2213, "text": "Then he wants the machine to do the rest."}, {"time": 2215, "text": "And again, I understand the impulse."}, {"time": 2242, "text": "The current systems don't have that much knowledge other than convolution, which is again, this objects being in different places and having the same perception, I guess I'll say."}, {"time": 2254, "text": "Same appearance."}, {"time": 2256, "text": "People don't want to do that work."}, {"time": 2258, "text": "They don't see how to naturally fit one with the other."}, {"time": 2261, "text": "I think that's, yes, absolutely."}, {"time": 2263, "text": "But also on the expert system side, there's a temptation to go too far the other way."}, {"time": 2267, "text": "So we're just having an expert sort of sit down and encode the description, the framework for what a container is, and then having the system reason the rest."}, {"time": 2276, "text": "From my view, one really exciting possibility is of active learning where it's continuous interaction between a human and machine."}, {"time": 2284, "text": "As the machine, there's kind of deep learning type extraction of information from data patterns and so on, but humans also guiding the learning procedures, guiding both the process and the framework of how the machine learns, whatever the task is."}, {"time": 2302, "text": "I was with you with almost everything you said except the phrase deep learning."}, {"time": 2306, "text": "What I think you really want there is a new form of machine learning."}, {"time": 2310, "text": "So let's remember, deep learning is a particular way of doing machine learning."}, {"time": 2313, "text": "Most often it's done with supervised data for perceptual categories."}, {"time": 2318, "text": "There are other things you can do with deep learning, some of them quite technical, but the standard use of deep learning is I have a lot of examples and I have labels for them."}, {"time": 2327, "text": "So here are pictures."}, {"time": 2328, "text": "This one's the Eiffel Tower."}, {"time": 2330, "text": "This one's the Sears Tower."}, {"time": 2331, "text": "This one's the Empire State Building."}, {"time": 2333, "text": "This one's a cat."}, {"time": 2334, "text": "This one's a pig and so forth."}, {"time": 2335, "text": "You just get millions of examples, millions of labels, and deep learning is extremely good at that."}, {"time": 2341, "text": "It's better than any other solution that anybody has devised, but it is not good at representing abstract knowledge."}, {"time": 2347, "text": "It's not good at representing things like bottles contain liquid and have tops to them and so forth."}, {"time": 2354, "text": "It's not very good at learning or representing that kind of knowledge."}, {"time": 2357, "text": "It is an example of having a machine learn something, but it's a machine that learns a particular kind of thing, which is object classification."}, {"time": 2365, "text": "It's not a particularly good algorithm for learning about the abstractions that govern our world."}, {"time": 2370, "text": "There may be such a thing."}, {"time": 2373, "text": "Part of what we counsel in the book is maybe people should be working on devising such things."}, {"time": 2376, "text": "So one possibility, just I wonder what you think about it, is that deep neural networks do form abstractions, but they're not accessible to us humans in terms of we can't."}, {"time": 2389, "text": "There's some truth in that."}, {"time": 2390, "text": "So is it possible that either current or future neural networks form very high level abstractions, which are as powerful as our human abstractions of common sense."}, {"time": 2402, "text": "We just can't get a hold of them."}, {"time": 2404, "text": "And so the problem is essentially we need to make them explainable."}, {"time": 2409, "text": "This is an astute question, but I think the answer is at least partly no."}, {"time": 2413, "text": "One of the kinds of classical neural network architecture is what we call an auto associator."}, {"time": 2417, "text": "It just tries to take an input, goes through a set of hidden layers, and comes out with an output."}, {"time": 2423, "text": "And it's supposed to learn essentially the identity function, that your input is the same as your output."}, {"time": 2427, "text": "So you think of it as binary numbers."}, {"time": 2428, "text": "You've got the one, the two, the four, the eight, the 16, and so forth."}, {"time": 2432, "text": "And so if you want to input 24, you turn on the 16, you turn on the eight."}, {"time": 2435, "text": "It's like binary one, one, and a bunch of zeros."}, {"time": 2438, "text": "So I did some experiments in 1998 with the precursors of contemporary deep learning."}, {"time": 2446, "text": "And what I showed was you could train these networks on all the even numbers, and they would never generalize to the odd number."}, {"time": 2454, "text": "A lot of people thought that I was, I don't know, an idiot or faking the experiment, or it wasn't true or whatever."}, {"time": 2460, "text": "But it is true that with this class of networks that we had in that day, that they would never ever make this generalization."}, {"time": 2467, "text": "And it's not that the networks were stupid, it's that they see the world in a different way than we do."}, {"time": 2473, "text": "They were basically concerned, what is the probability that the rightmost output node is going to be one?"}, {"time": 2479, "text": "And as far as they were concerned, in everything they'd ever been trained on, it was a zero."}, {"time": 2484, "text": "That node had never been turned on, and so they figured, why turn it on now?"}, {"time": 2488, "text": "Whereas a person would look at the same problem and say, well, it's obvious, we're just doing the thing that corresponds."}, {"time": 2493, "text": "The Latin for it is mutatis mutandis, we'll change what needs to be changed."}, {"time": 2498, "text": "And we do this, this is what algebra is."}, {"time": 2500, "text": "So I can do f of x equals y plus two, and I can do it for a couple of values, I can tell you if y is three, then x is five, and if y is four, x is six."}, {"time": 2509, "text": "And now I can do it with some totally different number, like a million, then you can say, well, obviously it's a million and two, because you have an algebraic operation that you're applying to a variable."}, {"time": 2517, "text": "And deep learning systems kind of emulate that, but they don't actually do it."}, {"time": 2522, "text": "The particular example, you could fudge a solution to that particular problem."}, {"time": 2528, "text": "The general form of that problem remains, that what they learn is really correlations between different input and output nodes."}, {"time": 2534, "text": "And they're complex correlations with multiple nodes involved and so forth."}, {"time": 2538, "text": "Ultimately, they're correlative, they're not structured over these operations over variables."}, {"time": 2543, "text": "Now, someday, people may do a new form of deep learning that incorporates that stuff, and I think it will help a lot."}, {"time": 2548, "text": "And there's some tentative work on things like differentiable programming right now that fall into that category."}, {"time": 2554, "text": "But the sort of classic stuff like people use for ImageNet doesn't have it."}, {"time": 2558, "text": "And you have people like Hinton going around saying, symbol manipulation, like what Marcus, what I advocate is like the gasoline engine."}, {"time": 2565, "text": "It's obsolete."}, {"time": 2566, "text": "We should just use this cool electric power that we've got with the deep learning."}, {"time": 2570, "text": "And that's really destructive, because we really do need to have the gasoline engine stuff that represents, I mean, I don't think it's a good analogy, but we really do need to have the stuff that represents symbols."}, {"time": 2583, "text": "Yeah, and Hinton as well would say that we do need to throw out everything and start over."}, {"time": 2588, "text": "Hinton said that to Axios, and I had a friend who interviewed him and tried to pin him down on what exactly we need to throw out, and he was very evasive."}, {"time": 2599, "text": "Well, of course, because we can't, if he knew."}, {"time": 2602, "text": "Then he'd throw it out himself."}, {"time": 2603, "text": "But I mean, you can't have it both ways."}, {"time": 2605, "text": "You can't be like, I don't know what to throw out, but I am gonna throw out the symbols."}, {"time": 2609, "text": "I mean, and not just the symbols, but the variables and the operations over variables."}, {"time": 2614, "text": "Don't forget, the operations over variables, the stuff that I'm endorsing and which John McCarthy did when he founded AI, that stuff is the stuff that we build most computers out of."}, {"time": 2624, "text": "There are people now who say, we don't need computer programmers anymore."}, {"time": 2628, "text": "Not quite looking at the statistics of how much computer programmers actually get paid right now."}, {"time": 2632, "text": "We need lots of computer programmers, and most of them, they do a little bit of machine learning, but they still do a lot of code, right?"}, {"time": 2639, "text": "Code where it's like, if the value of X is greater than the value of Y, then do this kind of thing, like conditionals and comparing operations over variables."}, {"time": 2648, "text": "Like, there's this fantasy you can machine learn anything."}, {"time": 2650, "text": "There's some things you would never wanna machine learn."}, {"time": 2652, "text": "I would not use a phone operating system that was machine learned."}, {"time": 2656, "text": "Like, you made a bunch of phone calls and you recorded which packets were transmitted and you just machine learned it, it'd be insane."}, {"time": 2662, "text": "Or to build a web browser by taking logs of keystrokes and images, screenshots, and then trying to learn the relation between them."}, {"time": 2671, "text": "Nobody would ever, no rational person would ever try to build a browser that made, they would use symbol manipulation, the stuff that I think AI needs to avail itself of in addition to deep learning."}, {"time": 2682, "text": "Can you describe your view of symbol manipulation in its early days?"}, {"time": 2687, "text": "Can you describe expert systems and where do you think they hit a wall or a set of challenges?"}, {"time": 2693, "text": "Sure, so I mean, first I just wanna clarify, I'm not endorsing expert systems per se."}, {"time": 2698, "text": "You've been kind of contrasting them."}, {"time": 2700, "text": "There is a contrast, but that's not the thing that I'm endorsing."}, {"time": 2704, "text": "So expert systems tried to capture things like medical knowledge with a large set of rules."}, {"time": 2709, "text": "So if the patient has this symptom and this other symptom, then it is likely that they have this disease."}, {"time": 2715, "text": "So there are logical rules and they were symbol manipulating rules of just the sort that I'm talking about."}, {"time": 2720, "text": "And the problem."}, {"time": 2721, "text": "They encode a set of knowledge that the experts then put in."}, {"time": 2724, "text": "And very explicitly so."}, {"time": 2726, "text": "So you'd have somebody interview an expert and then try to turn that stuff into rules."}, {"time": 2731, "text": "And at some level I'm arguing for rules."}, {"time": 2733, "text": "But the difference is those guys did in the 80s was almost entirely rules, almost entirely handwritten with no machine learning."}, {"time": 2742, "text": "What a lot of people are doing now is almost entirely one species of machine learning with no rules."}, {"time": 2748, "text": "And what I'm counseling is actually a hybrid."}, {"time": 2750, "text": "I'm saying that both of these things have their advantage."}, {"time": 2752, "text": "So if you're talking about perceptual classification, how do I recognize a bottle?"}, {"time": 2757, "text": "Deep learning is the best tool we've got right now."}, {"time": 2759, "text": "If you're talking about making inferences about what a bottle does, something closer to the expert systems is probably still the best available alternative."}, {"time": 2767, "text": "And probably we want something that is better able to handle quantitative and statistical information than those classical systems typically were."}, {"time": 2774, "text": "So we need new technologies that are gonna draw some of the strengths of both the expert systems and the deep learning, but are gonna find new ways to synthesize them."}, {"time": 2783, "text": "How hard do you think it is to add knowledge at the low level?"}, {"time": 2787, "text": "So mine human intellects to add extra information to symbol manipulating systems?"}, {"time": 2796, "text": "In some domains it's not that hard, but it's often really hard."}, {"time": 2800, "text": "Partly because a lot of the things that are important, people wouldn't bother to tell you."}, {"time": 2806, "text": "So if you pay someone on Amazon Mechanical Turk to tell you stuff about bottles, they probably won't even bother to tell you some of the basic level stuff that's just so obvious to a human being and yet so hard to capture in machines."}, {"time": 2824, "text": "They're gonna tell you more exotic things, and they're all well and good, but they're not getting to the root of the problem."}, {"time": 2832, "text": "So untutored humans aren't very good at knowing, and why should they be, what kind of knowledge the computer system developers actually need?"}, {"time": 2843, "text": "I don't think that that's an irremediable problem."}, {"time": 2846, "text": "I think it's historically been a problem."}, {"time": 2848, "text": "People have had crowdsourcing efforts, and they don't work that well."}, {"time": 2852, "text": "There's one at MIT, we're recording this at MIT, called Virtual Home, where, and we talk about this in the book, find the exact example there, but people were asked to do things like describe an exercise routine."}, {"time": 2864, "text": "And the things that the people describe are at a very low level and don't really capture what's going on."}, {"time": 2870, "text": "So they're like, go to the room with the television and the weights, turn on the television, press the remote to turn on the television, lift weight, put weight down, whatever."}, {"time": 2881, "text": "It's like very micro level, and it's not telling you what an exercise routine is really about, which is like, I wanna fit a certain number of exercises in a certain time period, I wanna emphasize these muscles."}, {"time": 2892, "text": "You want some kind of abstract description."}, {"time": 2895, "text": "The fact that you happen to press the remote control in this room when you watch this television isn't really the essence of the exercise routine."}, {"time": 2903, "text": "But if you just ask people like, what did they do?"}, {"time": 2904, "text": "Then they give you this fine grain."}, {"time": 2906, "text": "And so it takes a level of expertise about how the AI works in order to craft the right kind of knowledge."}, {"time": 2914, "text": "So there's this ocean of knowledge that we all operate on."}, {"time": 2917, "text": "Some of them may not even be conscious, or at least we're not able to communicate it effectively."}, {"time": 2923, "text": "Yeah, most of it we would recognize if somebody said it, if it was true or not, but we wouldn't think to say that it's true or not."}, {"time": 2929, "text": "That's a really interesting mathematical property."}, {"time": 2933, "text": "This ocean has the property that every piece of knowledge in it, we will recognize it as true if we're told, but we're unlikely to retrieve it in the reverse."}, {"time": 2944, "text": "So that interesting property, I would say there's a huge ocean of that knowledge."}, {"time": 2951, "text": "Is it accessible to AI systems somehow?"}, {"time": 2955, "text": "So you said this."}, {"time": 2956, "text": "I mean, most of it is not, well, I'll give you an asterisk on this in a second, but most of it has not ever been encoded in machine interpretable form."}, {"time": 2965, "text": "And so, I mean, if you say accessible, there's two meanings of that."}, {"time": 2968, "text": "One is like, could you build it into a machine?"}, {"time": 2972, "text": "The other is like, is there some database that we could go download and stick into our machine?"}, {"time": 2978, "text": "But the first thing, could we?"}, {"time": 2980, "text": "I think we could."}, {"time": 2982, "text": "I think it hasn't been done right."}, {"time": 2985, "text": "You know, the closest, and this is the asterisk, is the CYC psych system tried to do this."}, {"time": 2991, "text": "A lot of logicians worked for Doug Lennon for 30 years on this project."}, {"time": 2995, "text": "I think they stuck too closely to logic, didn't represent enough about probabilities, tried to hand code it."}, {"time": 3001, "text": "There are various issues, and it hasn't been that successful."}, {"time": 3004, "text": "That is the closest existing system to trying to encode this."}, {"time": 3010, "text": "Why do you think there's not more excitement slash money behind this idea currently?"}, {"time": 3017, "text": "People view that project as a failure."}, {"time": 3019, "text": "I think that they confuse the failure of a specific instance that was conceived 30 years ago for the failure of an approach, which they don't do for deep learning."}, {"time": 3028, "text": "So in 2010, people had the same attitude towards deep learning."}, {"time": 3032, "text": "They're like, this stuff doesn't really work."}, {"time": 3035, "text": "And all these other algorithms work better and so forth."}, {"time": 3039, "text": "And then certain key technical advances were made, but mostly it was the advent of graphics processing units that changed that."}, {"time": 3046, "text": "It wasn't even anything foundational in the techniques."}, {"time": 3050, "text": "And there was some new tricks, but mostly it was just more compute and more data, things like ImageNet that didn't exist before that allowed deep learning."}, {"time": 3059, "text": "And it could be, to work, it could be that CYC just needs a few more things or something like CYC, but the widespread view is that that just doesn't work."}, {"time": 3068, "text": "And people are reasoning from a single example."}, {"time": 3071, "text": "They don't do that with deep learning."}, {"time": 3073, "text": "They don't say nothing that existed in 2010, and there were many, many efforts in deep learning was really worth anything."}, {"time": 3080, "text": "I mean, really, there's no model from 2010 in deep learning or the predecessors of deep learning that has any commercial value whatsoever at this point."}, {"time": 3089, "text": "They're all failures."}, {"time": 3091, "text": "But that doesn't mean that there wasn't anything there."}, {"time": 3093, "text": "I have a friend, I was getting to know him, and he said, I had a company too, I was talking about I had a new company."}, {"time": 3100, "text": "He said, I had a company too, and it failed."}, {"time": 3102, "text": "And I said, well, what did you do?"}, {"time": 3104, "text": "And he said, deep learning."}, {"time": 3105, "text": "And the problem was he did it in 1986 or something like that."}, {"time": 3108, "text": "And we didn't have the tools then, or 1990, we didn't have the tools then, not the algorithms."}, {"time": 3113, "text": "His algorithms weren't that different from model algorithms, but he didn't have the GPUs to run it fast enough."}, {"time": 3118, "text": "He didn't have the data."}, {"time": 3119, "text": "And so it failed."}, {"time": 3121, "text": "It could be that symbol manipulation per se with modern amounts of data and compute and maybe some advance in compute for that kind of compute might be great."}, {"time": 3134, "text": "My perspective on it is not that we want to resuscitate that stuff per se, but we want to borrow lessons from it, bring together with other things that we've learned."}, {"time": 3143, "text": "And it might have an ImageNet moment where it would spark the world's imagination and there'll be an explosion of symbol manipulation efforts."}, {"time": 3151, "text": "Yeah, I think that people at AI2, Paul Allen's AI Institute, are trying to build data sets."}, {"time": 3159, "text": "Well, they're not doing it for quite the reason that you say, but they're trying to build data sets that at least spark interest in common sense reasoning."}, {"time": 3165, "text": "To create benchmarks."}, {"time": 3166, "text": "Benchmarks for common sense."}, {"time": 3168, "text": "That's a large part of what the AI2.org is working on right now."}, {"time": 3171, "text": "So speaking of compute, Rich Sutton wrote a blog post titled Bitter Lesson."}, {"time": 3176, "text": "I don't know if you've read it, but he said that the biggest lesson that can be read from so many years of AI research is that general methods that leverage computation are ultimately the most effective."}, {"time": 3186, "text": "Do you think that?"}, {"time": 3187, "text": "The most effective at what?"}, {"time": 3188, "text": "Right, so they have been most effective for perceptual classification problems and for some reinforcement learning problems."}, {"time": 3198, "text": "And he works on reinforcement learning."}, {"time": 3199, "text": "Well, no, let me push back on that."}, {"time": 3200, "text": "You're actually absolutely right."}, {"time": 3202, "text": "But I would also say they have been most effective generally because everything we've done up to... Would you argue against that?"}, {"time": 3212, "text": "Is, to me, deep learning is the first thing that has been successful at anything in AI."}, {"time": 3221, "text": "And you're pointing out that this success is very limited, folks, but has there been something truly successful before deep learning?"}, {"time": 3231, "text": "Sure, I mean, I want to make a larger point, but on the narrower point, classical AI is used, for example, in doing navigation instructions."}, {"time": 3243, "text": "It's very successful."}, {"time": 3246, "text": "Everybody on the planet uses it now, like multiple times a day."}, {"time": 3249, "text": "That's a measure of success, right?"}, {"time": 3252, "text": "So I don't think classical AI was wildly successful, but there are cases like that."}, {"time": 3257, "text": "They're just used all the time."}, {"time": 3259, "text": "Nobody even notices them because they're so pervasive."}, {"time": 3263, "text": "So there are some successes for classical AI."}, {"time": 3266, "text": "I think deep learning has been more successful, but my usual line about this, and I didn't invent it, but I like it a lot, is just because you can build a better ladder doesn't mean you can build a ladder to the moon."}, {"time": 3277, "text": "So the bitter lesson is if you have a perceptual classification problem, throwing a lot of data at it is better than anything else."}, {"time": 3285, "text": "But that has not given us any material progress in natural language understanding, common sense reasoning, like a robot would need to navigate a home."}, {"time": 3296, "text": "Problems like that, there's no actual progress there."}, {"time": 3299, "text": "So flip side of that, if we remove data from the picture, another bitter lesson is that you just have a very simple algorithm, and you wait for compute to scale."}, {"time": 3312, "text": "It doesn't have to be learning."}, {"time": 3313, "text": "It doesn't have to be deep learning."}, {"time": 3314, "text": "It doesn't have to be data driven, but just wait for the compute."}, {"time": 3318, "text": "So my question for you, do you think compute can unlock some of the things with either deep learning or symbol manipulation that?"}, {"time": 3325, "text": "Sure, but I'll put a proviso on that."}, {"time": 3329, "text": "I think more compute's always better."}, {"time": 3331, "text": "Nobody's gonna argue with more compute."}, {"time": 3333, "text": "It's like having more money."}, {"time": 3334, "text": "I mean, there's the data."}, {"time": 3336, "text": "There's diminishing returns on more money."}, {"time": 3337, "text": "Exactly, there's diminishing returns on more money, but nobody's gonna argue if you wanna give them more money, right?"}, {"time": 3342, "text": "Except maybe the people who signed the giving pledge, and some of them have a problem."}, {"time": 3346, "text": "They've promised to give away more money than they're able to."}, {"time": 3349, "text": "But the rest of us, if you wanna give me more money, fine."}, {"time": 3352, "text": "I'm saying more money, more problems, but okay."}, {"time": 3354, "text": "That's true too."}, {"time": 3355, "text": "What I would say to you is your brain uses like 20 watts, and it does a lot of things that deep learning doesn't do, or that symbol manipulation doesn't do, that AI just hasn't figured out how to do."}, {"time": 3367, "text": "So it's an existence proof that you don't need server resources that are Google scale in order to have an intelligence."}, {"time": 3376, "text": "I built, with a lot of help from my wife, two intelligences that are 20 watts each, and far exceed anything that anybody else has built at a silicon."}, {"time": 3386, "text": "Speaking of those two robots, what have you learned about AI from having?"}, {"time": 3393, "text": "Well, they're not robots, but."}, {"time": 3395, "text": "Sorry, intelligent agents."}, {"time": 3396, "text": "Those two intelligent agents."}, {"time": 3398, "text": "I've learned a lot by watching my two intelligent agents."}, {"time": 3402, "text": "I think that what's fundamentally interesting, well, one of the many things that's fundamentally interesting about them is the way that they set their own problems to solve."}, {"time": 3411, "text": "So my two kids are a year and a half apart."}, {"time": 3414, "text": "They're both five and six and a half."}, {"time": 3416, "text": "They play together all the time, and they're constantly creating new challenges."}, {"time": 3420, "text": "That's what they do, is they make up games, and they're like, well, what if this, or what if that, or what if I had this superpower, or what if you could walk through this wall?"}, {"time": 3430, "text": "So they're doing these what if scenarios all the time, and that's how they learn something about the world and grow their minds, and machines don't really do that."}, {"time": 3442, "text": "So that's interesting, and you've talked about this, you've written about it, you've thought about it, nature versus nurture."}, {"time": 3449, "text": "So what innate knowledge do you think we're born with, and what do we learn along the way in those early months and years?"}, {"time": 3458, "text": "Can I just say how much I like that question?"}, {"time": 3461, "text": "You phrased it just right, and almost nobody ever does, which is what is the innate knowledge and what's learned along the way?"}, {"time": 3469, "text": "So many people dichotomize it, and they think it's nature versus nurture, when it is obviously has to be nature and nurture."}, {"time": 3476, "text": "They have to work together."}, {"time": 3478, "text": "You can't learn this stuff along the way unless you have some innate stuff, but just because you have the innate stuff doesn't mean you don't learn anything."}, {"time": 3485, "text": "And so many people get that wrong, including in the field."}, {"time": 3489, "text": "People think if I work in machine learning, the learning side, I must not be allowed to work on the innate side, or that will be cheating."}, {"time": 3497, "text": "Exactly, people have said that to me, and it's just absurd, so thank you."}, {"time": 3503, "text": "But you could break that apart more."}, {"time": 3505, "text": "I've talked to folks who studied the development of the brain, and the growth of the brain in the first few days in the first few months in the womb, all of that, is that innate?"}, {"time": 3519, "text": "So that process of development from a stem cell to the growth of the central nervous system and so on, to the information that's encoded through the long arc of evolution."}, {"time": 3532, "text": "So all of that comes into play, and it's unclear."}, {"time": 3535, "text": "It's not just whether it's a dichotomy or not."}, {"time": 3537, "text": "It's where most, or where the knowledge is encoded."}, {"time": 3542, "text": "So what's your intuition about the innate knowledge, the power of it, what's contained in it, what can we learn from it?"}, {"time": 3551, "text": "One of my earlier books was actually trying to understand the biology of this."}, {"time": 3554, "text": "The book was called The Birth of the Mind."}, {"time": 3555, "text": "Like how is it the genes even build innate knowledge?"}, {"time": 3558, "text": "And from the perspective of the conversation we're having today, there's actually two questions."}, {"time": 3563, "text": "One is what innate knowledge or mechanisms, or what have you, people or other animals might be endowed with."}, {"time": 3570, "text": "I always like showing this video of a baby ibex climbing down a mountain."}, {"time": 3574, "text": "That baby ibex, a few hours after its birth, knows how to climb down a mountain."}, {"time": 3578, "text": "That means that it knows, not consciously, something about its own body and physics and 3D geometry and all of this kind of stuff."}, {"time": 3587, "text": "So there's one question about what does biology give its creatures and what has evolved in our brains?"}, {"time": 3593, "text": "How is that represented in our brains?"}, {"time": 3594, "text": "The question I thought about in the book The Birth of the Mind."}, {"time": 3597, "text": "And then there's a question of what AI should have."}, {"time": 3599, "text": "And they don't have to be the same."}, {"time": 3601, "text": "But I would say that it's a pretty interesting set of things that we are equipped with that allows us to do a lot of interesting things."}, {"time": 3610, "text": "So I would argue or guess, based on my reading of the developmental psychology literature, which I've also participated in, that children are born with a notion of space, time, other agents, places, and also this kind of mental algebra that I was describing before."}, {"time": 3630, "text": "No certain causation if I didn't just say that."}, {"time": 3633, "text": "So at least those kinds of things."}, {"time": 3635, "text": "They're like frameworks for learning the other things."}, {"time": 3638, "text": "Are they disjoint in your view or is it just somehow all connected?"}, {"time": 3642, "text": "You've talked a lot about language."}, {"time": 3644, "text": "Is it all kind of connected in some mesh that's language like?"}, {"time": 3650, "text": "If understanding concepts all together or?"}, {"time": 3652, "text": "I don't think we know for people how they're represented and machines just don't really do this yet."}, {"time": 3658, "text": "So I think it's an interesting open question both for science and for engineering."}, {"time": 3663, "text": "Some of it has to be at least interrelated in the way that the interfaces of a software package have to be able to talk to one another."}, {"time": 3672, "text": "So the systems that represent space and time can't be totally disjoint because a lot of the things that we reason about are the relations between space and time and cause."}, {"time": 3682, "text": "So I put this on and I have expectations about what's gonna happen with the bottle cap on top of the bottle and those span space and time."}, {"time": 3692, "text": "If the cap is over here, I get a different outcome."}, {"time": 3695, "text": "If the timing is different, if I put this here, after I move that, then I get a different outcome."}, {"time": 3701, "text": "That relates to causality."}, {"time": 3703, "text": "So obviously these mechanisms, whatever they are, can certainly communicate with each other."}, {"time": 3710, "text": "So I think evolution had a significant role to play in the development of this whole kluge, right?"}, {"time": 3717, "text": "How efficient do you think is evolution?"}, {"time": 3719, "text": "Oh, it's terribly inefficient except that."}, {"time": 3721, "text": "Okay, well, can we do better?"}, {"time": 3723, "text": "Well, I'll come to that in a sec."}, {"time": 3725, "text": "It's inefficient except that."}, {"time": 3728, "text": "Once it gets a good idea, it runs with it."}, {"time": 3730, "text": "So it took, I guess, a billion years, if I went roughly a billion years, to evolve to a vertebrate brain plan."}, {"time": 3744, "text": "And once that vertebrate brain plan evolved, it spread everywhere."}, {"time": 3748, "text": "So fish have it and dogs have it and we have it."}, {"time": 3751, "text": "We have adaptations of it and specializations of it, but, and the same thing with a primate brain plan."}, {"time": 3757, "text": "So monkeys have it and apes have it and we have it."}, {"time": 3761, "text": "So there are additional innovations like color vision and those spread really rapidly."}, {"time": 3765, "text": "So it takes evolution a long time to get a good idea, but, and I'm being anthropomorphic and not literal here, but once it has that idea, so to speak, which cashes out into one set of genes or in the genome, those genes spread very rapidly and they're like subroutines or libraries, I guess the word people might use nowadays or be more familiar with."}, {"time": 3785, "text": "They're libraries that get used over and over again."}, {"time": 3788, "text": "So once you have the library for building something with multiple digits, you can use it for a hand, but you can also use it for a foot."}, {"time": 3795, "text": "You just kind of reuse the library with slightly different parameters."}, {"time": 3799, "text": "Evolution does a lot of that, which means that the speed over time picks up."}, {"time": 3803, "text": "So evolution can happen faster because you have bigger and bigger libraries."}, {"time": 3808, "text": "And what I think has happened in attempts at evolutionary computation is that people start with libraries that are very, very minimal, like almost nothing, and then progress is slow and it's hard for someone to get a good PhD thesis out of it and they give up."}, {"time": 3828, "text": "If we had richer libraries to begin with, if you were evolving from systems that had an rich innate structure to begin with, then things might speed up."}, {"time": 3836, "text": "Or more PhD students, if the evolutionary process is indeed in a meta way runs away with good ideas, you need to have a lot of ideas, pool of ideas in order for it to discover one that you can run away with."}, {"time": 3850, "text": "And PhD students representing individual ideas as well."}, {"time": 3853, "text": "Yeah, I mean, you could throw a billion PhD students at it."}, {"time": 3856, "text": "Yeah, the monkeys are typewriters with Shakespeare, yep."}, {"time": 3860, "text": "Well, I mean, those aren't cumulative, right?"}, {"time": 3862, "text": "That's just random."}, {"time": 3863, "text": "And part of the point that I'm making is that evolution is cumulative."}, {"time": 3866, "text": "So if you have a billion monkeys independently, you don't really get anywhere."}, {"time": 3872, "text": "But if you have a billion monkeys, and I think Dawkins made this point originally, or probably other people, Dawkins made it very nice and either a selfish gene or blind watchmaker."}, {"time": 3880, "text": "If there is some sort of fitness function that can drive you towards something, I guess that's Dawkins point."}, {"time": 3887, "text": "And my point, which is a variation on that, is that if the evolution is cumulative, I mean, the related points, then you can start going faster."}, {"time": 3895, "text": "Do you think something like the process of evolution is required to build intelligent systems?"}, {"time": 3900, "text": "So if we... Not logically."}, {"time": 3901, "text": "So all the stuff that evolution did, a good engineer might be able to do."}, {"time": 3907, "text": "So for example, evolution made quadrupeds, which distribute the load across a horizontal surface."}, {"time": 3914, "text": "A good engineer could come up with that idea."}, {"time": 3916, "text": "I mean, sometimes good engineers come up with ideas by looking at biology."}, {"time": 3919, "text": "There's lots of ways to get your ideas."}, {"time": 3922, "text": "Part of what I'm suggesting is we should look at biology a lot more."}, {"time": 3925, "text": "We should look at the biology of thought and understanding and the biology by which creatures intuitively reason about physics or other agents, or like how do dogs reason about people?"}, {"time": 3937, "text": "Like they're actually pretty good at it."}, {"time": 3939, "text": "If we could understand, at my college we joked dognition, if we could understand dognition well, and how it was implemented, that might help us with our AI."}, {"time": 3949, "text": "So do you think it's possible that the kind of timescale that evolution took is the kind of timescale that will be needed to build intelligent systems?"}, {"time": 3960, "text": "Or can we significantly accelerate that process inside a computer?"}, {"time": 3964, "text": "I mean, I think the way that we accelerate that process is we borrow from biology, not slavishly, but I think we look at how biology has solved problems and we say, does that inspire any engineering solutions here?"}, {"time": 3978, "text": "Try to mimic biological systems and then therefore have a shortcut."}, {"time": 3982, "text": "Yeah, I mean, there's a field called biomimicry and people do that for like material science all the time."}, {"time": 3988, "text": "We should be doing the analog of that for AI and the analog for that for AI is to look at cognitive science or the cognitive sciences, which is psychology, maybe neuroscience, linguistics, and so forth, look to those for insight."}, {"time": 4003, "text": "What do you think is a good test of intelligence in your view?"}, {"time": 4006, "text": "So I don't think there's one good test."}, {"time": 4008, "text": "In fact, I tried to organize a movement towards something called a Turing Olympics and my hope is that Francois is actually gonna take, Francois Chollet is gonna take over this."}, {"time": 4018, "text": "I think he's interested and I don't, I just don't have place in my busy life at this moment, but the notion is that there'd be many tests and not just one because intelligence is multifaceted."}, {"time": 4029, "text": "There can't really be a single measure of it because it isn't a single thing."}, {"time": 4035, "text": "Like just the crudest level, the SAT has a verbal component and a math component because they're not identical."}, {"time": 4041, "text": "And Howard Gardner has talked about multiple intelligences like kinesthetic intelligence and verbal intelligence and so forth."}, {"time": 4047, "text": "There are a lot of things that go into intelligence and people can get good at one or the other."}, {"time": 4052, "text": "I mean, in some sense, like every expert has developed a very specific kind of intelligence and then there are people that are generalists and I think of myself as a generalist with respect to cognitive science, which doesn't mean I know anything about quantum mechanics, but I know a lot about the different facets of the mind."}, {"time": 4069, "text": "And there's a kind of intelligence to thinking about intelligence."}, {"time": 4072, "text": "I like to think that I have some of that, but social intelligence, I'm just okay."}, {"time": 4077, "text": "There are people that are much better at that than I am."}, {"time": 4080, "text": "Sure, but what would be really impressive to you?"}, {"time": 4084, "text": "I think the idea of a touring Olympics is really interesting especially if somebody like Francois is running it, but to you in general, not as a benchmark, but if you saw an AI system being able to accomplish something that would impress the heck out of you, what would that thing be?"}, {"time": 4102, "text": "Would it be natural language conversation?"}, {"time": 4104, "text": "For me personally, I would like to see a kind of comprehension that relates to what you just said."}, {"time": 4110, "text": "So I wrote a piece in the New Yorker in I think 2015 right after Eugene Guestman, which was a software package, won a version of the Turing test."}, {"time": 4122, "text": "And the way that it did this is it be, well, the way you win the Turing test, so called win it, is the Turing test is you fool a person into thinking that a machine is a person, is you're evasive, you pretend to have limitations so you don't have to answer certain questions and so forth."}, {"time": 4140, "text": "So this particular system pretended to be a 13 year old boy from Odessa who didn't understand English and was kind of sarcastic and wouldn't answer your questions and so forth."}, {"time": 4149, "text": "And so judges got fooled into thinking briefly with a very little exposure, it was a 13 year old boy, and it docked all the questions Turing was actually interested in, which is like how do you make the machine actually intelligent?"}, {"time": 4160, "text": "So that test itself is not that good."}, {"time": 4162, "text": "And so in New Yorker, I proposed an alternative, I guess, and the one that I proposed there was a comprehension test."}, {"time": 4170, "text": "And I must like Breaking Bad because I've already given you one Breaking Bad example and in that article, I have one as well, which was something like if Walter, you should be able to watch an episode of Breaking Bad or maybe you have to watch the whole series to be able to answer the question and say, if Walter White took a hit out on Jesse, why did he do that?"}, {"time": 4187, "text": "So if you could answer kind of arbitrary questions about characters motivations, I would be really impressed with that and he built software to do that."}, {"time": 4195, "text": "They could watch a film or there are different versions."}, {"time": 4198, "text": "And so ultimately, I wrote this up with Praveen Paritosh in a special issue of AI Magazine that basically was about the Turing Olympics."}, {"time": 4205, "text": "There were like 14 tests proposed."}, {"time": 4207, "text": "The one that I was pushing was a comprehension challenge and Praveen who's at Google was trying to figure out like how we would actually run it and so we wrote a paper together."}, {"time": 4215, "text": "And you could have a text version too or you could have an auditory podcast version, you could have a written version."}, {"time": 4220, "text": "But the point is that you win at this test if you can do, let's say human level or better than humans at answering kind of arbitrary questions."}, {"time": 4229, "text": "Why did this person pick up the stone?"}, {"time": 4231, "text": "What were they thinking when they picked up the stone?"}, {"time": 4234, "text": "Were they trying to knock down glass?"}, {"time": 4236, "text": "And I mean, ideally these wouldn't be multiple choice either because multiple choice is pretty easily gamed."}, {"time": 4241, "text": "So if you could have relatively open ended questions and you can answer why people are doing this stuff, I would be very impressed."}, {"time": 4248, "text": "And of course, humans can do this, right?"}, {"time": 4250, "text": "If you watch a well constructed movie and somebody picks up a rock, everybody watching the movie knows why they picked up the rock, right?"}, {"time": 4259, "text": "They all know, oh my gosh, he's gonna hit this character or whatever."}, {"time": 4263, "text": "We have an example in the book about when a whole bunch of people say, I am Spartacus, you know, this famous scene."}, {"time": 4271, "text": "The viewers understand, first of all, that everybody or everybody minus one has to be lying."}, {"time": 4279, "text": "They can't all be Spartacus."}, {"time": 4280, "text": "We have enough common sense knowledge to know they couldn't all have the same name."}, {"time": 4284, "text": "We know that they're lying and we can infer why they're lying, right?"}, {"time": 4287, "text": "They're lying to protect someone and to protect things they believe in."}, {"time": 4290, "text": "You get a machine that can do that."}, {"time": 4292, "text": "They can say, this is why these guys all got up and said, I am Spartacus."}, {"time": 4296, "text": "I will sit down and say, AI has really achieved a lot."}, {"time": 4301, "text": "Without cheating any part of the system."}, {"time": 4303, "text": "Yeah, I mean, if you do it, there are lots of ways you could cheat."}, {"time": 4306, "text": "You could build a Spartacus machine that works on that film."}, {"time": 4310, "text": "That's not what I'm talking about."}, {"time": 4311, "text": "I'm talking about, you can do this with essentially arbitrary films or from a large set."}, {"time": 4314, "text": "Even beyond films because it's possible such a system would discover that the number of narrative arcs in film is limited to 1930."}, {"time": 4322, "text": "Well, there's a famous thing about the classic seven plots or whatever."}, {"time": 4327, "text": "If you wanna build in the system, boy meets girl, boy loses girl, boy finds girl."}, {"time": 4332, "text": "I don't mind having some head stories on it."}, {"time": 4333, "text": "And they acknowledge."}, {"time": 4336, "text": "I mean, you could build it in innately or you could have your system watch a lot of films again."}, {"time": 4340, "text": "If you can do this at all, but with a wide range of films, not just one film in one genre."}, {"time": 4347, "text": "But even if you could do it for all Westerns, I'd be reasonably impressed."}, {"time": 4351, "text": "So in terms of being impressed, just for the fun of it, because you've put so many interesting ideas out there in your book, challenging the community for further steps."}, {"time": 4363, "text": "Is it possible on the deep learning front that you're wrong about its limitations?"}, {"time": 4370, "text": "That deep learning will unlock, Yann LeCun next year will publish a paper that achieves this comprehension."}, {"time": 4376, "text": "So do you think that way often as a scientist?"}, {"time": 4380, "text": "Do you consider that your intuition that deep learning could actually run away with it?"}, {"time": 4386, "text": "I'm more worried about rebranding as a kind of political thing."}, {"time": 4391, "text": "So, I mean, what's gonna happen, I think, is the deep learning is gonna start to encompass symbol manipulation."}, {"time": 4397, "text": "So I think Hinton's just wrong."}, {"time": 4399, "text": "Hinton says we don't want hybrids."}, {"time": 4400, "text": "I think people will work towards hybrids and they will relabel their hybrids as deep learning."}, {"time": 4404, "text": "We've already seen some of that."}, {"time": 4405, "text": "So AlphaGo is often described as a deep learning system, but it's more correctly described as a system that has deep learning, but also Monte Carlo tree search, which is a classical AI technique."}, {"time": 4415, "text": "And people will start to blur the lines in the way that IBM blurred Watson."}, {"time": 4419, "text": "First, Watson meant this particular system, and then it was just anything that IBM built in their cognitive division."}, {"time": 4424, "text": "But purely, let me ask, for sure, that's a branding question and that's like a giant mess."}, {"time": 4429, "text": "I mean, purely, a single neural network being able to accomplish reasonable comprehension."}, {"time": 4434, "text": "I don't stay up at night worrying that that's gonna happen."}, {"time": 4437, "text": "And I'll just give you two examples."}, {"time": 4439, "text": "One is a guy at DeepMind thought he had finally outfoxed me."}, {"time": 4443, "text": "At Zergilord, I think is his Twitter handle."}, {"time": 4446, "text": "And he said, he specifically made an example."}, {"time": 4450, "text": "Marcus said that such and such."}, {"time": 4452, "text": "He fed it into GP2, which is the AI system that is so smart that OpenAI couldn't release it because it would destroy the world, right?"}, {"time": 4461, "text": "You remember that a few months ago."}, {"time": 4462, "text": "So he feeds it into GPT2, and my example was something like a rose is a rose, a tulip is a tulip, a lily is a blank."}, {"time": 4471, "text": "And he got it to actually do that, which was a little bit impressive."}, {"time": 4474, "text": "And I wrote back and I said, that's impressive, but can I ask you a few questions?"}, {"time": 4477, "text": "I said, was that just one example?"}, {"time": 4480, "text": "Can it do it generally?"}, {"time": 4481, "text": "And can it do it with novel words, which was part of what I was talking about in 1998 when I first raised the example."}, {"time": 4486, "text": "So a dax is a dax, right?"}, {"time": 4490, "text": "And he sheepishly wrote back about 20 minutes later."}, {"time": 4493, "text": "And the answer was, well, it had some problems with those."}, {"time": 4495, "text": "So I made some predictions 21 years ago that still hold."}, {"time": 4500, "text": "In the world of computer science, that's amazing, right?"}, {"time": 4502, "text": "Because there's a thousand or a million times more memory and computations a million times, do million times more operations per second spread across a cluster."}, {"time": 4515, "text": "And there's been advances in replacing sigmoids with other functions and so forth."}, {"time": 4523, "text": "There's all kinds of advances, but the fundamental architecture hasn't changed and the fundamental limit hasn't changed."}, {"time": 4528, "text": "And what I said then is kind of still true."}, {"time": 4530, "text": "Then here's a second example."}, {"time": 4532, "text": "I recently had a piece in Wired that's adapted from the book."}, {"time": 4535, "text": "And the book went to press before GP2 came out, but we described this children's story and all the inferences that you make in this story about a boy finding a lost wallet."}, {"time": 4548, "text": "And for fun, in the Wired piece, we ran it through GP2."}, {"time": 4552, "text": "GPT2, something called talktotransformer.com, and your viewers can try this experiment themselves."}, {"time": 4558, "text": "Go to the Wired piece that has the link and it has the story."}, {"time": 4561, "text": "And the system made perfectly fluent text that was totally inconsistent with the conceptual underpinnings of the story, right?"}, {"time": 4570, "text": "This is what, again, I predicted in 1998."}, {"time": 4573, "text": "And for that matter, Chomsky and Miller made the same prediction in 1963."}, {"time": 4576, "text": "I was just updating their claim for a slightly new text."}, {"time": 4579, "text": "So those particular architectures that don't have any built in knowledge, they're basically just a bunch of layers doing correlational stuff."}, {"time": 4588, "text": "They're not gonna solve these problems."}, {"time": 4591, "text": "So 20 years ago, you said the emperor has no clothes."}, {"time": 4594, "text": "Today, the emperor still has no clothes."}, {"time": 4596, "text": "The lighting's better though."}, {"time": 4598, "text": "The lighting is better."}, {"time": 4599, "text": "And I think you yourself are also, I mean."}, {"time": 4602, "text": "And we found out some things to do with naked emperors."}, {"time": 4604, "text": "I mean, it's not like stuff is worthless."}, {"time": 4606, "text": "I mean, they're not really naked."}, {"time": 4608, "text": "It's more like they're in their briefs than everybody thinks they are."}, {"time": 4610, "text": "And so like, I mean, they are great at speech recognition, but the problems that I said were hard."}, {"time": 4616, "text": "I didn't literally say the emperor has no clothes."}, {"time": 4618, "text": "I said, this is a set of problems that humans are really good at."}, {"time": 4621, "text": "And it wasn't couched as AI."}, {"time": 4623, "text": "It was couched as cognitive science."}, {"time": 4624, "text": "But I said, if you wanna build a neural model of how humans do certain class of things, you're gonna have to change the architecture."}, {"time": 4631, "text": "And I stand by those claims."}, {"time": 4633, "text": "So, and I think people should understand you're quite entertaining in your cynicism, but you're also very optimistic and a dreamer about the future of AI too."}, {"time": 4643, "text": "So you're both, it's just."}, {"time": 4645, "text": "There's a famous saying about being, people overselling technology in the short run and underselling it in the long run."}, {"time": 4654, "text": "And so I actually end the book, Ernie Davis and I end our book with an optimistic chapter, which kind of killed Ernie because he's even more pessimistic than I am."}, {"time": 4664, "text": "He describes me as a contrarian and him as a pessimist."}, {"time": 4667, "text": "But I persuaded him that we should end the book with a look at what would happen if AI really did incorporate, for example, the common sense reasoning and the nativism and so forth, the things that we counseled for."}, {"time": 4679, "text": "And we wrote it and it's an optimistic chapter that AI suitably reconstructed so that we could trust it, which we can't now, could really be world changing."}, {"time": 4689, "text": "So on that point, if you look at the future trajectories of AI, people have worries about negative effects of AI, whether it's at the large existential scale or smaller short term scale of negative impact on society."}, {"time": 4705, "text": "So you write about trustworthy AI, how can we build AI systems that align with our values, that make for a better world, that we can interact with, that we can trust?"}, {"time": 4714, "text": "The first thing we have to do is to replace deep learning with deep understanding."}, {"time": 4718, "text": "So you can't have alignment with a system that traffics only in correlations and doesn't understand concepts like bottles or harm."}, {"time": 4727, "text": "So Asimov talked about these famous laws and the first one was first do no harm."}, {"time": 4734, "text": "And you can quibble about the details of Asimov's laws, but we have to, if we're gonna build real robots in the real world, have something like that."}, {"time": 4740, "text": "That means we have to program in a notion that's at least something like harm."}, {"time": 4744, "text": "That means we have to have these more abstract ideas that deep learning is not particularly good at."}, {"time": 4748, "text": "They have to be in the mix somewhere."}, {"time": 4750, "text": "And you could do statistical analysis about probabilities of given harms or whatever, but you have to know what a harm is in the same way that you have to understand that a bottle isn't just a collection of pixels."}, {"time": 4760, "text": "And also be able to, you're implying that you need to also be able to communicate that to humans so the AI systems would be able to prove to humans that they understand that they know what harm means."}, {"time": 4775, "text": "I might run it in the reverse direction, but roughly speaking, I agree with you."}, {"time": 4778, "text": "So we probably need to have committees of wise people, ethicists and so forth."}, {"time": 4785, "text": "Think about what these rules ought to be and we shouldn't just leave it to software engineers."}, {"time": 4789, "text": "It shouldn't just be software engineers and it shouldn't just be people who own large mega corporations that are good at technology, ethicists and so forth should be involved."}, {"time": 4800, "text": "But there should be some assembly of wise people as I was putting it that tries to figure out what the rules ought to be."}, {"time": 4808, "text": "And those have to get translated into code."}, {"time": 4812, "text": "You can argue or code or neural networks or something."}, {"time": 4815, "text": "They have to be translated into something that machines can work with."}, {"time": 4819, "text": "And that means there has to be a way of working the translation."}, {"time": 4823, "text": "And right now we don't."}, {"time": 4824, "text": "We don't have a way."}, {"time": 4825, "text": "So let's say you and I were the committee and we decide that Asimov's first law is actually right."}, {"time": 4829, "text": "And let's say it's not just two white guys, which would be kind of unfortunate that we have abroad."}, {"time": 4834, "text": "And so we've representative sample of the world or however we wanna do this."}, {"time": 4837, "text": "And the committee decides eventually, okay, Asimov's first law is actually pretty good."}]}, {"title": "Grant Sanderson: 3Blue1Brown and the Beauty of Mathematics | Lex Fridman Podcast #64", "id": "U_lKUK2MCsg", "quotes": [{"time": 278, "text": "You can think about it in terms of the problem it solves, a certain very simple differential equation, which often yields way more insight than trying to twist the idea of repeated multiplication, like take its arm and put it behind its back and throw it on the desk and be like, you will apply to complex numbers, right?"}, {"time": 293, "text": "That's not, I don't think that's pedagogically helpful."}, {"time": 297, "text": "So the repeated multiplication is actually missing the main point, the power of e to the x. I mean, what it addresses is things where the rate at which something changes depends on its own value, but more specifically, it depends on it linearly."}, {"time": 312, "text": "So for example, if you have like a population that's growing and the rate at which it grows depends on how many members of the population are already there, it looks like this nice exponential curve."}, {"time": 321, "text": "It makes sense to talk about repeated multiplication because you say, how much is there after one year, two years, three years, you're multiplying by something."}, {"time": 327, "text": "The relationship can be a little bit different sometimes where let's say you've got a ball on a string, like a game of tetherball going around a rope, right?"}, {"time": 337, "text": "And you say, its velocity is always perpendicular to its position."}, {"time": 342, "text": "That's another way of describing its rate of change is being related to where it is, but it's a different operation."}, {"time": 348, "text": "You're not scaling it, it's a rotation."}, {"time": 349, "text": "It's this 90 degree rotation."}, {"time": 351, "text": "That's what the whole idea of like complex exponentiation is trying to capture, but it's obfuscated in the notation when what it's actually saying, like if you really parse something like e to the pi i, what it's saying is choose an origin, always move perpendicular to the vector from that origin to you, okay?"}, {"time": 369, "text": "Then when you walk pi times that radius, you'll be halfway around."}, {"time": 374, "text": "Like that's what it's saying."}, {"time": 375, "text": "It's kind of the, you turn 90 degrees and you walk, you'll be going in a circle."}, {"time": 379, "text": "That's the phenomenon that it's describing, but trying to twist the idea of repeatedly multiplying a constant into that."}, {"time": 409, "text": "And you're talking about the most beautiful equation in mathematics, but it's still pretty mysterious, isn't it?"}, {"time": 415, "text": "Like you're making it seem like it's a notational."}, {"time": 418, "text": "It's not mysterious."}, {"time": 419, "text": "I think the notation makes it mysterious."}, {"time": 421, "text": "I don't think it's, I think the fact that it represents, it's pretty, it's not like the most beautiful thing in the world, but it's quite pretty."}, {"time": 427, "text": "The idea that if you take the linear operation of a 90 degree rotation, and then you do this general exponentiation thing to it, that what you get are all the other kinds of rotation, which is basically to say, if your velocity vector is perpendicular to your position vector, you walk in a circle, that's pretty."}, {"time": 446, "text": "It's not the most beautiful thing in the world, but it's quite pretty."}, {"time": 448, "text": "The beauty of it, I think comes from perhaps the awkwardness of the notation somehow still nevertheless coming together nicely, because you have like several disciplines coming together in a single equation."}, {"time": 461, "text": "In a sense, like historically speaking."}, {"time": 464, "text": "You've got, so like the number E is significant."}, {"time": 465, "text": "Like it shows up in probability all the time."}, {"time": 467, "text": "It like shows up in calculus all the time."}, {"time": 469, "text": "It is significant."}, {"time": 470, "text": "You're seeing it sort of mated with pi, this geometric constant and I, like the imaginary number and such."}, {"time": 475, "text": "I think what's really happening there is the way that E shows up is when you have things like exponential growth and decay, right?"}, {"time": 483, "text": "It's when this relation that something's rate of change has to itself is a simple scaling, right?"}, {"time": 490, "text": "A similar law also describes circular motion."}, {"time": 494, "text": "Because we have bad notation, we use the residue of how it shows up in the context of self reinforcing growth, like a population growing or compound interest."}, {"time": 503, "text": "The constant associated with that is awkwardly placed into the context of how rotation comes about, because they both come from pretty similar equations."}, {"time": 512, "text": "And so what we see is the E and the pi juxtaposed a little bit closer than they would be with a purely natural representation, I would think."}, {"time": 521, "text": "Here's how I would describe the relation between the two."}, {"time": 523, "text": "You've got a very important function we might call exp."}, {"time": 525, "text": "That's like the exponential function."}, {"time": 527, "text": "When you plug in one, you get this nice constant called E that shows up in like probability and calculus."}, {"time": 533, "text": "If you try to move in the imaginary direction, it's periodic and the period is tau."}, {"time": 538, "text": "So those are these two constants associated with the same central function, but for kind of unrelated reasons, right?"}, {"time": 544, "text": "And not unrelated, but like orthogonal reasons."}, {"time": 547, "text": "One of them is what happens when you're moving in the real direction."}, {"time": 549, "text": "One's what happens when you move in the imaginary direction."}, {"time": 552, "text": "And like, yeah, those are related."}, {"time": 554, "text": "They're not as related as the famous equation seems to think it is."}, {"time": 558, "text": "It's sort of putting all of the children in one bed and they'd kind of like to sleep in separate beds if they had the choice, but you see them all there and there is a family resemblance, but it's not that close."}, {"time": 568, "text": "So actually thinking of it as a function is the better idea."}, {"time": 574, "text": "And that's a notational idea."}, {"time": 576, "text": "And yeah, and like, here's the thing."}, {"time": 579, "text": "The constant E sort of stands as this numerical representative of calculus, right?"}, {"time": 584, "text": "Calculus is the like study of change."}, {"time": 587, "text": "So at the very least there's a little cognitive dissonance using a constant to represent the science of change."}, {"time": 593, "text": "I never thought of it that way."}, {"time": 596, "text": "It makes sense why the notation came about that way."}, {"time": 600, "text": "Because this is the first way that we saw it in the context of things like population growth or compound interest."}, {"time": 604, "text": "It is nicer to think about as repeated multiplication."}, {"time": 607, "text": "That's definitely nicer."}, {"time": 608, "text": "But it's more that that's the first application of what turned out to be a much more general function that maybe the intelligent life your initial question asked about would have come to recognize as being much more significant than the single use case, which lends itself to repeated multiplication notation."}, {"time": 624, "text": "But let me jump back for a second to aliens and the nature of our universe."}, {"time": 631, "text": "Do you think math is discovered or invented?"}, {"time": 635, "text": "So we're talking about the different kind of mathematics that could be developed by the alien species."}, {"time": 640, "text": "The implied question is, yeah, is math discovered or invented?"}, {"time": 646, "text": "Is fundamentally everybody going to discover the same principles of mathematics?"}, {"time": 653, "text": "So the way I think about it, and everyone thinks about it differently, but here's my take."}, {"time": 656, "text": "I think there's a cycle at play where you discover things about the universe that tell you what math will be useful."}, {"time": 663, "text": "And that math itself is invented in a sense, but of all the possible maths that you could have invented, it's discoveries about the world that tell you which ones are."}, {"time": 674, "text": "So like a good example here is the Pythagorean theorem."}, {"time": 677, "text": "When you look at this, do you think of that as a definition or do you think of that as a discovery?"}, {"time": 681, "text": "From the historical perspective, right, it's a discovery because they were, but that's probably because they were using physical object to build their intuition."}, {"time": 692, "text": "And from that intuition came the mathematics."}, {"time": 725, "text": "No, no, no, no, higher dimensions can be highly, highly applicable."}, {"time": 728, "text": "I think this is a common misinterpretation that if you're asking questions about like a five dimensional manifold, that the only way that that's connected to the physical world is if the physical world is itself a five dimensional manifold or includes them."}, {"time": 742, "text": "Well, wait, wait, wait a minute, wait a minute."}, {"time": 745, "text": "You're telling me you can imagine a five dimensional manifold?"}, {"time": 751, "text": "No, no, that's not what I said."}, {"time": 753, "text": "I would make the claim that it is useful to a three dimensional physical universe, despite itself not being three dimensional."}, {"time": 759, "text": "So it's useful meaning to even understand a three dimensional world, it'd be useful to have five dimensional manifolds."}, {"time": 764, "text": "Yes, absolutely, because of state spaces."}, {"time": 767, "text": "But you're saying there in some deep way for us humans, it does always come back to that three dimensional world for the usefulness that the dimensional world and therefore it starts with a discovery, but then we invent the mathematics that helps us make sense of the discovery in a sense."}, {"time": 786, "text": "Yes, I mean, just to jump off of the Pythagorean theorem example, it feels like a discovery."}, {"time": 791, "text": "You've got these beautiful geometric proofs where you've got squares and you're modifying the areas, it feels like a discovery."}, {"time": 796, "text": "If you look at how we formalize the idea of 2D space as being R2, right, all pairs of real numbers, and how we define a metric on it and define distance, you're like, hang on a second, we've defined a distance so that the Pythagorean theorem is true, so that suddenly it doesn't feel that great."}, {"time": 812, "text": "But I think what's going on is the thing that informed us what metric to put on R2, to put on our abstract representation of 2D space, came from physical observations."}, {"time": 823, "text": "And the thing is, there's other metrics you could have put on it."}, {"time": 825, "text": "We could have consistent math with other notions of distance, it's just that those pieces of math wouldn't be applicable to the physical world that we study because they're not the ones where the Pythagorean theorem holds."}, {"time": 836, "text": "So we have a discovery, a genuine bonafide discovery that informed the invention, the invention of an abstract representation of 2D space that we call R2 and things like that."}, {"time": 846, "text": "And then from there, you just study R2 as an abstract thing that brings about more ideas and inventions and mysteries which themselves might yield discoveries."}, {"time": 854, "text": "Those discoveries might give you insight as to what else would be useful to invent and it kind of feeds on itself that way."}, {"time": 860, "text": "That's how I think about it."}, {"time": 862, "text": "So it's not an either or."}, {"time": 864, "text": "It's not that math is one of these or it's one of the others."}, {"time": 866, "text": "At different times, it's playing a different role."}, {"time": 869, "text": "So then let me ask the Richard Feynman question then, along that thread, is what do you think is the difference between physics and math?"}, {"time": 880, "text": "There's a giant overlap."}, {"time": 883, "text": "There's a kind of intuition that physicists have about the world that's perhaps outside of mathematics."}, {"time": 889, "text": "It's this mysterious art that they seem to possess, we humans generally possess."}, {"time": 894, "text": "And then there's the beautiful rigor of mathematics that allows you to, I mean, just like as we were saying, invent frameworks of understanding our physical world."}, {"time": 907, "text": "So what do you think is the difference there and how big is it?"}, {"time": 911, "text": "Well, I think of math as being the study of abstractions over patterns and pure patterns in logic."}, {"time": 916, "text": "And then physics is obviously grounded in a desire to understand the world that we live in."}, {"time": 922, "text": "I think you're gonna get very different answers when you talk to different mathematicians because there's a wide diversity in types of mathematicians."}, {"time": 927, "text": "There are some who are motivated very much by pure puzzles."}, {"time": 930, "text": "They might be turned on by things like combinatorics."}, {"time": 933, "text": "And they just love the idea of building up a set of problem solving tools applying to pure patterns."}, {"time": 940, "text": "There are some who are very physically motivated, who try to invent new math or discover math in veins that they know will have applications to physics or sometimes computer science."}, {"time": 951, "text": "And that's what drives them."}, {"time": 953, "text": "Like chaos theory is a good example of something that's pure math, that's purely mathematical."}, {"time": 957, "text": "A lot of the statements being made, but it's heavily motivated by specific applications to largely physics."}, {"time": 964, "text": "And then you have a type of mathematician who just loves abstraction."}, {"time": 968, "text": "They just love pulling it to the more and more abstract things, the things that feel powerful."}, {"time": 972, "text": "These are the ones that initially invented like topology and then later on get really into category theory and go on about like infinite categories and whatnot."}, {"time": 980, "text": "These are the ones that love to have a system that can describe truths about as many things as possible."}, {"time": 988, "text": "People from those three different veins of motivation into math are gonna give you very different answers about what the relation at play here is."}, {"time": 994, "text": "Cause someone like Vladimir Arnold, who has written a lot of great books, many about like differential equations and such, he would say, math is a branch of physics."}, {"time": 1005, "text": "That's how he would think about it."}, {"time": 1007, "text": "And of course he was studying like differential equations related things because that is the motivator behind the study of PDEs and things like that."}, {"time": 1014, "text": "But you'll have others who, like especially the category theorists who aren't really thinking about physics necessarily."}, {"time": 1021, "text": "It's all about abstraction and the power of generality."}, {"time": 1024, "text": "And it's more of a happy coincidence that that ends up being useful for understanding the world we live in."}, {"time": 1030, "text": "And then you can get into like, why is that the case?"}, {"time": 1032, "text": "It's sort of surprising that that which is about pure puzzles and abstraction also happens to describe the very fundamentals of quarks and everything else."}, {"time": 1044, "text": "So why do you think the fundamentals of quarks and the nature of reality is so compressible into clean, beautiful equations that are for the most part simple, relatively speaking, a lot simpler than they could be?"}, {"time": 1061, "text": "So you have, we mentioned somebody like Stephen Wolfram who thinks that sort of there's incredibly simple rules underlying our reality, but it can create arbitrary complexity."}, {"time": 1074, "text": "But there is simple equations."}, {"time": 1076, "text": "What, I'm asking a million questions that nobody knows the answer to, but."}, {"time": 1081, "text": "I have no idea, why is it simple?"}, {"time": 1085, "text": "It could be the case that there's like a filter iteration at play."}, {"time": 1088, "text": "The only things that physicists find interesting are the ones that are simple enough they could describe it mathematically."}, {"time": 1093, "text": "But as soon as it's a sufficiently complex system, like, oh, that's outside the realm of physics, that's biology or whatever have you."}, {"time": 1099, "text": "And of course, that's true."}, {"time": 1101, "text": "Maybe there's something where it's like, of course there will always be something that is simple when you wash away the like non important parts of whatever it is that you're studying."}, {"time": 1113, "text": "Just from like an information theory standpoint, there might be some like, you get to the lowest information component of it."}, {"time": 1119, "text": "But I don't know, maybe I'm just having a really hard time conceiving of what it would even mean for the fundamental laws to be like intrinsically complicated, like some set of equations that you can't decouple from each other."}, {"time": 1132, "text": "Well, no, it could be that sort of we take for granted that the laws of physics, for example, are for the most part the same everywhere or something like that, right?"}, {"time": 1145, "text": "As opposed to the sort of an alternative could be that the rules under which the world operates is different everywhere."}, {"time": 1157, "text": "It's like a deeply distributed system where just everything is just chaos, not in a strict definition of chaos, but meaning like just it's impossible for equations to capture, for to explicitly model the world as cleanly as the physical does."}, {"time": 1176, "text": "I mean, we almost take it for granted that we can describe, we can have an equation for gravity, for action at a distance."}, {"time": 1182, "text": "We can have equations for some of these basic ways the planet's moving."}, {"time": 1186, "text": "Just the low level at the atomic scale, how the materials operate, at the high scale, how black holes operate."}, {"time": 1196, "text": "But it doesn't, it seems like it could be, there's infinite other possibilities where none of it could be compressible into such equations."}, {"time": 1205, "text": "So it just seems beautiful."}, {"time": 1206, "text": "It's also weird, probably to the point you're making, that it's very pleasant that this is true for our minds."}, {"time": 1215, "text": "So it might be that our minds are biased to just be looking at the parts of the universe that are compressible."}, {"time": 1221, "text": "And then we can publish papers on and have nice E equals empty squared equations."}, {"time": 1226, "text": "Right, well, I wonder would such a world with uncompressible laws allow for the kind of beings that can think about the kind of questions that you're asking?"}, {"time": 1238, "text": "Right, like an anthropic principle coming into play in some weird way here?"}, {"time": 1242, "text": "I don't know, like I don't know what I'm talking about at all."}, {"time": 1244, "text": "Maybe the universe is actually not so compressible, but the way our brain, the way our brain evolved we're only able to perceive the compressible parts."}, {"time": 1255, "text": "I mean, we are, so this is the sort of Chomsky argument."}, {"time": 1258, "text": "We are just descendants of apes over like really limited biological systems."}, {"time": 1263, "text": "So it totally makes sense that we're really limited little computers, calculators, that are able to perceive certain kinds of things and the actual world is much more complicated."}, {"time": 1273, "text": "Well, but we can do pretty awesome things, right?"}, {"time": 1276, "text": "Like we can fly spaceships and we have to have some connection of reality to be able to take our potentially oversimplified models of the world, but then actually twist the world to our will based on it."}, {"time": 1289, "text": "So we have certain reality checks that like physics isn't too far a field simply based on what we can do."}, {"time": 1295, "text": "Yeah, the fact that we can fly is pretty good."}, {"time": 1297, "text": "It's great, yeah, like it's a proof of concept that the laws we're working with are working well."}, {"time": 1304, "text": "So I mentioned to the internet that I'm talking to you and so the internet gave some questions."}, {"time": 1310, "text": "So I apologize for these, but do you think we're living in a simulation that the universe is a computer or the universe is a computation running on a computer?"}, {"time": 1321, "text": "It's conceivable."}, {"time": 1322, "text": "What I don't buy is, you know, you'll have the argument that, well, let's say that it was the case that you can have simulations."}, {"time": 1329, "text": "Then the simulated world would itself eventually get to a point where it's running simulations."}, {"time": 1335, "text": "And then the second layer down would create a third layer down and on and on and on."}, {"time": 1339, "text": "So probabilistically, you just throw a dart at one of those layers, we're probably in one of the simulated layers."}, {"time": 1344, "text": "I think if there's some sort of limitations on like the information processing of whatever the physical world is, like it quickly becomes the case that you have a limit to the layers that could exist there because like the resources necessary to simulate a universe like ours clearly is a lot just in terms of the number of bits at play."}, {"time": 1363, "text": "And so then you can ask, well, what's more plausible?"}, {"time": 1366, "text": "That there's an unbounded capacity of information processing in whatever the like highest up level universe is, or that there's some bound to that capacity, which then limits like the number of levels available."}, {"time": 1378, "text": "How do you play some kind of probability distribution on like what the information capacity is?"}, {"time": 1383, "text": "But I don't, like people almost assume a certain uniform probability over all of those meta layers that could conceivably exist when it's a little bit like a Pascal's wager on like you're not giving a low enough prior to the mere existence of that infinite set of layers."}, {"time": 1401, "text": "But it's also very difficult to contextualize the amount."}, {"time": 1405, "text": "So the amount of information processing power required to simulate like our universe seems like amazingly huge."}, {"time": 1414, "text": "But you can always raise two to the power of that."}, {"time": 1416, "text": "Yeah, like numbers get big."}, {"time": 1420, "text": "And we're easily humbled by basically everything around us."}, {"time": 1457, "text": "We basically know nothing about the world around us, relatively speaking."}, {"time": 1463, "text": "And so when I think about the simulation hypothesis, I think it's just fun to think about it."}, {"time": 1469, "text": "But it's also, I think there is a thought experiment kind of interesting to think of the power of computation, whether the limits of a Turing machine, sort of the limits of our current computers, when you start to think about artificial intelligence, how far can we get with computers?"}, {"time": 1486, "text": "And that's kind of where the simulation hypothesis used with me as a thought experiment is the universe just a computer?"}, {"time": 1496, "text": "Is it just a computation?"}, {"time": 1498, "text": "Is all of this just a computation?"}, {"time": 1500, "text": "And sort of the same kind of tools we apply to analyzing algorithms, can that be applied?"}, {"time": 1505, "text": "If we scale further and further and further, will the arbitrary power of those systems start to create some interesting aspects that we see in our universe?"}, {"time": 1513, "text": "Or is something fundamentally different needs to be created?"}, {"time": 1517, "text": "Well, it's interesting that in our universe, it's not arbitrarily large, the power, that you can place limits on, for example, how many bits of information can be stored per unit area."}, {"time": 1527, "text": "Right, like all of the physical laws, you've got general relativity and quantum coming together to give you a certain limit on how many bits you can store within a given range before it collapses into a black hole."}, {"time": 1573, "text": "Obviously, it's just as conceivable that they do and that there are many, but I guess what I'm channeling is the surprise that I felt upon learning that fact, that there are, that information is physical in this way."}, {"time": 1586, "text": "There's a finiteness to it."}, {"time": 1587, "text": "Okay, let me just even go off on that."}, {"time": 1589, "text": "From a mathematics perspective and a psychology perspective, how do you mix, are you psychologically comfortable with the concept of infinity?"}, {"time": 1601, "text": "Are you okay with it?"}, {"time": 1602, "text": "I'm pretty okay, yeah."}, {"time": 1603, "text": "Are you okay?"}, {"time": 1604, "text": "No, not really, it doesn't make any sense to me."}, {"time": 1607, "text": "I don't know, like how many words, how many possible words do you think could exist that are just like strings of letters?"}, {"time": 1615, "text": "So that's a sort of mathematical statement as beautiful and we use infinity in basically everything we do, everything we do in science, math, and engineering, yes."}, {"time": 1626, "text": "But you said exist, the question is, you said letters or words?"}, {"time": 1633, "text": "I said words."}, {"time": 1633, "text": "Words."}, {"time": 1636, "text": "To bring words into existence to me, you have to start like saying them or like writing them or like listing them."}, {"time": 1642, "text": "That's an instantiation."}, {"time": 1643, "text": "Okay, how many abstract words exist?"}, {"time": 1645, "text": "Well, the idea of an abstract."}, {"time": 1648, "text": "The idea of abstract notions and ideas."}, {"time": 1651, "text": "I think we should be clear on terminology."}, {"time": 1653, "text": "I mean, you think about intelligence a lot, like artificial intelligence."}, {"time": 1657, "text": "Would you not say that what it's doing is a kind of abstraction?"}, {"time": 1660, "text": "That like abstraction is key to conceptualizing the universe?"}, {"time": 1665, "text": "You get this raw sensory data."}, {"time": 1667, "text": "I need something that every time you move your face a little bit and they're not pixels, but like analog of pixels on my retina changed entirely, that I can still have some coherent notion of this is Lex, I'm talking to Lex, right?"}, {"time": 1679, "text": "What that requires is you have a disparate set of possible images hitting me that are unified in a notion of Lex, right?"}, {"time": 1687, "text": "That's a kind of abstraction."}, {"time": 1688, "text": "It's a thing that could apply to a lot of different images that I see and it represents it in a much more compressed way and one that's like much more resilient to that."}, {"time": 1697, "text": "I think in the same way, if I'm talking about infinity as an abstraction, I don't mean nonphysical woo woo, like ineffable or something."}, {"time": 1706, "text": "What I mean is it's something that can apply to a multiplicity of situations that share a certain common attribute in the same way that the images of like your face on my retina share enough common attributes that I can put the single notion to it."}, {"time": 1717, "text": "Like in that way, infinity is an abstraction and it's very powerful and it's only through such abstractions that we can actually understand like the world and logic and things."}, {"time": 1727, "text": "And in the case of infinity, the way I think about it, the key entity is the property of always being able to add one more."}, {"time": 1734, "text": "Like no matter how many words you can list, you just throw an A at the end of one and you have another conceivable word."}, {"time": 1739, "text": "You don't have to think of all the words at once."}, {"time": 1741, "text": "It's that property, the oh, I could always add one more that gives it this nature of infiniteness in the same way that there's certain like properties of your face that give it the Lexness, right?"}, {"time": 1753, "text": "So like infinity should be no more worrying than the I can always add one more sentiment."}, {"time": 1759, "text": "That's a really elegant, much more elegant way than I could put it."}, {"time": 1763, "text": "So thank you for doing that as yet another abstraction."}, {"time": 1766, "text": "And yes, indeed, that's what our brain does."}, {"time": 1769, "text": "That's what intelligent systems do."}, {"time": 1770, "text": "That's what programming does."}, {"time": 1771, "text": "That's what science does is build abstraction on top of each other."}, {"time": 1775, "text": "And yet there is at a certain point abstractions that go into the quote woo, right?"}, {"time": 1782, "text": "Sort of, and because we're now, it's like we built this stack of, you know, the only thing that's true is the stuff that's on the ground."}, {"time": 1794, "text": "Everything else is useful for interpreting this."}, {"time": 1797, "text": "And at a certain point you might start floating into ideas that are surreal and difficult and take us into areas that are disconnected from reality in a way that we could never get back."}, {"time": 1811, "text": "What if instead of calling these abstract, how different would it be in your mind if we called them general?"}, {"time": 1815, "text": "And the phenomenon that you're describing is overgeneralization."}, {"time": 1819, "text": "When you try to have a concept or an idea that's so general as to apply to nothing in particular in a useful way, does that map to what you're thinking of when you think of?"}, {"time": 1828, "text": "First of all, I'm playing little just for the fun of it."}, {"time": 1831, "text": "Devil's advocate."}, {"time": 1832, "text": "And I think our cognition, our mind is unable to visualize."}, {"time": 1839, "text": "So you do some incredible work with visualization and video."}, {"time": 1842, "text": "I think infinity is very difficult to visualize for our mind."}, {"time": 1848, "text": "We can delude ourselves into thinking we can visualize it, but we can't."}, {"time": 1854, "text": "I don't, I mean, I don't, I would venture to say it's very difficult."}, {"time": 1857, "text": "And so there's some concepts of mathematics, like maybe multiple dimensions, we could sort of talk about that are impossible for us to truly intuit, like, and it just feels dangerous to me to use these as part of our toolbox of abstractions."}, {"time": 1876, "text": "On behalf of your listeners, I almost fear we're getting too philosophical."}, {"time": 1882, "text": "I think to that point for any particular idea like this, there's multiple angles of attack."}, {"time": 1888, "text": "I think the, when we do visualize infinity, what we're actually doing, you know, you write dot, dot, dot, right?"}, {"time": 1894, "text": "One, two, three, four, dot, dot, dot, right?"}, {"time": 1897, "text": "Those are symbols on the page that are insinuating a certain infinity."}, {"time": 1902, "text": "What you're capturing with a little bit of design there is the I can always add one more property, right?"}, {"time": 1909, "text": "I think I'm just as uncomfortable with you are if you try to concretize it so much that you have a bag of infinitely many things that I actually think of, no, not one, two, three, four, dot, dot, dot, one, two, three, four, five, six, seven, eight."}, {"time": 1923, "text": "I try to get them all in my head and you realize, oh, you know, your brain would literally collapse into a black hole, all of that."}, {"time": 1930, "text": "And I honestly feel this with a lot of math that I try to read where I don't think of myself as like particularly good at math in some ways."}, {"time": 1939, "text": "Like I get very confused often when I am going through some of these texts."}, {"time": 1943, "text": "And often what I'm feeling in my head is like, this is just so damn abstract."}, {"time": 1947, "text": "I just can't wrap my head around it."}, {"time": 1949, "text": "I just want to put something concrete to it that makes me understand."}, {"time": 1952, "text": "And I think a lot of the motivation for the channel is channeling that sentiment of, yeah, a lot of the things that you're trying to read out there, it's just so hard to connect to anything that you spend an hour banging your head against a couple of pages and you come out not really knowing anything more other than some definitions maybe and a certain sense of self defeat, right?"}, {"time": 1975, "text": "One of the reasons I focus so much on visualizations is that I'm a big believer in, I'm sorry, I'm just really hampering on this idea of abstraction, being clear about your layers of abstraction, right?"}, {"time": 1987, "text": "It's always tempting to start an explanation from the top to the bottom, okay?"}, {"time": 1991, "text": "You give the definition of a new theorem."}, {"time": 1994, "text": "You're like, this is the definition of a vector space."}, {"time": 1996, "text": "For example, that's how we'll start a course."}, {"time": 1998, "text": "These are the properties of a vector space."}, {"time": 2000, "text": "First from these properties, we will derive what we need in order to do the math of linear algebra or whatever it might be."}, {"time": 2006, "text": "I don't think that's how understanding works at all."}, {"time": 2028, "text": "It's as concrete as you could possibly get and it has to be if you're putting it in a visual, right?"}, {"time": 2033, "text": "It's an actual arrow."}, {"time": 2033, "text": "It's an actual vector."}, {"time": 2036, "text": "You're not talking about like a quote unquote vector that could apply to any possible thing."}, {"time": 2041, "text": "You have to choose one if you're illustrating it."}, {"time": 2043, "text": "And I think this is the power of being in a medium like video or if you're writing a textbook and you force yourself to put a lot of images is with every image, you're making a choice."}, {"time": 2053, "text": "With each choice, you're showing a concrete example."}, {"time": 2056, "text": "With each concrete example, you're aiding someone's path to understanding."}, {"time": 2059, "text": "I'm sorry to interrupt you, but you just made me realize that that's exactly right."}, {"time": 2064, "text": "So the visualizations you're creating while you're sometimes talking about abstractions, the actual visualization is an explicit low level example."}, {"time": 2075, "text": "So there's an actual, like in the code, you have to say what the vector is, what's the direction of the arrow, what's the magnitude of the, yeah."}, {"time": 2084, "text": "So that's, you're going, the visualization itself is actually going to the bottom of that."}, {"time": 2090, "text": "And I think that's very important."}, {"time": 2092, "text": "I also think about this a lot in writing scripts where even before you get to the visuals, the first instinct is to, I don't know why, I just always do, I say the abstract thing, I say the general definition, the powerful thing, and then I fill it in with examples later."}, {"time": 2107, "text": "Always, it will be more compelling and easier to understand when you flip that."}, {"time": 2110, "text": "And instead, you let someone's brain do the pattern recognition."}, {"time": 2116, "text": "You just show them a bunch of examples."}, {"time": 2118, "text": "The brain is gonna feel a certain similarity between them."}, {"time": 2121, "text": "Then by the time you bring in the definition, or by the time you bring in the formula, it's articulating a thing that's already in the brain that was built off of looking at a bunch of examples with a certain kind of similarity."}, {"time": 2132, "text": "And what the formula does is articulate what that kind of similarity is, rather than being a high cognitive load set of symbols that needs to be populated with examples later on, assuming someone's still with you."}, {"time": 2148, "text": "What is the most beautiful or awe inspiring idea you've come across in mathematics?"}, {"time": 2153, "text": "I don't know, man."}, {"time": 2155, "text": "Maybe it's an idea you've explored in your videos, maybe not."}, {"time": 2158, "text": "What just gave you pause?"}, {"time": 2161, "text": "What's the most beautiful idea?"}, {"time": 2163, "text": "Small or big."}, {"time": 2164, "text": "So I think often, the things that are most beautiful are the ones that you have a little bit of understanding of, but certainly not an entire understanding."}, {"time": 2174, "text": "It's a little bit of that mystery that is what makes it beautiful."}, {"time": 2177, "text": "What was the moment of the discovery for you personally, almost just that leap of aha moment?"}, {"time": 2183, "text": "So something that really caught my eye, I remember when I was little, there were these, I think the series was called like wooden books or something, these tiny little books that would have just a very short description of something on the left and then a picture on the right."}, {"time": 2196, "text": "I don't know who they're meant for, but maybe it's like loosely children or something like that."}, {"time": 2200, "text": "But it can't just be children, because of some of the things I was describing."}, {"time": 2203, "text": "On the last page of one of them, somewhere tiny in there was this little formula that on the left hand had a sum over all of the natural numbers."}, {"time": 2211, "text": "It's like one over one to the S plus one over two to the S plus one over three to the S on and on to the infinity."}, {"time": 2217, "text": "Then on the other side had a product over all of the primes and it was a certain thing had to do with all the primes."}, {"time": 2223, "text": "And like any good young math enthusiast, I'd probably been indoctrinated with how chaotic and confusing the primes are, which they are."}, {"time": 2230, "text": "And seeing this equation where on one side you have something that's as understandable as you could possibly get, the counting numbers."}, {"time": 2238, "text": "And on the other side is all the prime numbers."}, {"time": 2240, "text": "It was like this, whoa, they're related like this?"}, {"time": 2243, "text": "There's a simple description that includes all the primes getting wrapped together like this."}, {"time": 2248, "text": "This is like the Euler product for the Zeta function, as I like later found out."}, {"time": 2253, "text": "The equation itself essentially encodes the fundamental theorem of arithmetic that every number can be expressed as a unique set of primes."}, {"time": 2262, "text": "To me still there's, I mean, I certainly don't understand this equation or this function all that well."}, {"time": 2267, "text": "The more I learn about it, the prettier it is."}, {"time": 2270, "text": "The idea that you can, this is sort of what gets you representations of primes, not in terms of primes themselves, but in terms of another set of numbers."}, {"time": 2279, "text": "They're like the non trivial zeros of the Zeta function."}, {"time": 2281, "text": "And again, I'm very kind of in over my head in a lot of ways as I like try to get to understand it."}, {"time": 2286, "text": "But the more I do, it always leaves enough mystery that it remains very beautiful to me."}, {"time": 2291, "text": "So whenever there's a little bit of mystery just outside of the understanding that, and by the way, the process of learning more about it, how does that come about?"}, {"time": 2300, "text": "Just your own thought or are you reading?"}, {"time": 2303, "text": "Reading, yeah."}, {"time": 2304, "text": "Or is the process of visualization itself revealing more to you?"}, {"time": 2308, "text": "Visuals help."}, {"time": 2309, "text": "I mean, in one time when I was just trying to understand like analytic continuation and playing around with visualizing complex functions, this is what led to a video about this function."}, {"time": 2319, "text": "It's titled something like Visualizing the Riemann Zeta Function."}, {"time": 2322, "text": "It's one that came about because I was programming and tried to see what a certain thing looked like."}, {"time": 2327, "text": "And then I looked at it and I'm like, whoa, that's elucidating."}, {"time": 2330, "text": "And then I decided to make a video about it."}, {"time": 2333, "text": "But I mean, you try to get your hands on as much reading as you can."}, {"time": 2338, "text": "You know, in this case, I think if anyone wants to start to understand it, if they have like a math background like they studied some in college or something like that, like the Princeton Companion to Math has a really good article on analytic number theory."}, {"time": 2353, "text": "And that itself has a whole bunch of references and you know, anything has more references and it gives you this like tree to start piling through."}, {"time": 2360, "text": "And like, you know, you try to understand, I try to understand things visually as I go."}, {"time": 2364, "text": "That's not always possible, but it's very helpful when it does."}, {"time": 2368, "text": "You recognize when there's common themes, like in this case, Cousins of the Fourier Transform that come into play and you realize, oh, it's probably pretty important to have deep intuitions of the Fourier Transform, even if it's not explicitly mentioned in like these texts."}, {"time": 2382, "text": "And you try to get a sense of what the common players are."}, {"time": 2385, "text": "But I'll emphasize again, like, I feel very in over my head when I try to understand the exact relation between like the zeros of the Riemann Zeta function and how they relate to the distribution of primes."}, {"time": 2396, "text": "I definitely understand it better than I did a year ago."}, {"time": 2399, "text": "I definitely understand it on 100th as well as the experts on the matter do, I assume."}, {"time": 2404, "text": "But the slow path towards getting there is, it's fun, it's charming, and like to your question, very beautiful."}, {"time": 2412, "text": "And the beauty is in the, what, in the journey versus the destination?"}, {"time": 2417, "text": "Well, it's that each thing doesn't feel arbitrary."}, {"time": 2419, "text": "I think that's a big part, is that you have these unpredictable, no, yeah, these very unpredictable patterns or these intricate properties of like a certain function."}, {"time": 2430, "text": "But at the same time, it doesn't feel like humans ever made an arbitrary choice in studying this particular thing."}, {"time": 2435, "text": "So, you know, it feels like you're speaking to patterns themselves or nature itself."}, {"time": 2441, "text": "That's a big part of it."}, {"time": 2443, "text": "I think things that are too arbitrary, it's just hard for those to feel beautiful because this is sort of what the word contrived is meant to apply to, right?"}, {"time": 2453, "text": "And when they're not arbitrary means it could be, you can have a clean abstraction and intuition that allows you to comprehend it."}, {"time": 2464, "text": "Well, to one of your first questions, it makes you feel like if you came across another intelligent civilization, that they'd be studying the same thing."}, {"time": 2472, "text": "Maybe with different notation."}, {"time": 2473, "text": "Certainly, yeah, but yeah."}, {"time": 2475, "text": "Like that's what, I think you talked to that other civilization, they're probably also studying the zeros of the Riemann Zeta function or like some variant thereof that is like a clearly equivalent cousin or something like that."}, {"time": 2488, "text": "But that's probably on their docket."}, {"time": 2492, "text": "Whenever somebody does a lot of something amazing, I'm gonna ask the question that you've already been asked a lot and that you'll get more and more asked in your life."}, {"time": 2503, "text": "But what was your favorite video to create?"}, {"time": 2506, "text": "Oh, favorite to create."}, {"time": 2509, "text": "One of my favorites is, the title is Who Cares About Topology?"}, {"time": 2514, "text": "You want me to pull it up or no?"}, {"time": 2515, "text": "If you want, sure, yeah."}, {"time": 2517, "text": "It is about, well, it starts by describing an unsolved problem that's still unsolved in math called the inscribed square problem."}, {"time": 2525, "text": "You draw any loop and then you ask, are there four points on that loop that make a square?"}, {"time": 2529, "text": "Totally useless, right?"}, {"time": 2530, "text": "This is not answering any physical questions."}, {"time": 2532, "text": "It's mostly interesting that we can't answer that question."}, {"time": 2534, "text": "And it seems like such a natural thing to ask."}, {"time": 2538, "text": "Now, if you weaken it a little bit and you ask, can you always find a rectangle?"}, {"time": 2542, "text": "You choose four points on this curve, can you find a rectangle?"}, {"time": 2545, "text": "That's hard, but it's doable."}, {"time": 2547, "text": "And the path to it involves things like looking at a torus, this surface with a single hole in it, like a donut, or looking at a mobius strip."}, {"time": 2557, "text": "In ways that feel so much less contrived to when I first, as like a little kid, learned about these surfaces and shapes, like a mobius strip and a torus."}, {"time": 2565, "text": "Like what you learn is, oh, this mobius strip, you take a piece of paper, put a twist, glue it together, and now you have a shape with one edge and just one side."}, {"time": 2573, "text": "And as a student, you should think, who cares, right?"}, {"time": 2578, "text": "Like, how does that help me solve any problems?"}, {"time": 2580, "text": "I thought math was about problem solving."}, {"time": 2582, "text": "So what I liked about the piece of math that this was describing that was in this paper by a mathematician named Vaughn was that it arises very naturally."}, {"time": 2592, "text": "It's clear what it represents."}, {"time": 2594, "text": "It's doing something."}, {"time": 2595, "text": "It's not just playing with construction paper."}, {"time": 2597, "text": "And the way that it solves the problem is really beautiful."}, {"time": 2601, "text": "So kind of putting all of that down and concretizing it, right?"}, {"time": 2605, "text": "Like I was talking about how when you have to put visuals to it, it demands that what's on screen is a very specific example of what you're describing."}, {"time": 2613, "text": "The construction here is very abstract in nature."}, {"time": 2615, "text": "You describe this very abstract kind of surface in 3D space."}, {"time": 2619, "text": "So then when I was finding myself, in this case, I wasn't programming, I was using a grapher that's like built into OSX for the 3D stuff to draw that surface, you realize, oh man, the topology argument is very non constructive."}, {"time": 2632, "text": "I have to make a lot of, you have to do a lot of extra work in order to make the surface show up."}, {"time": 2637, "text": "But then once you see it, it's quite pretty and it's very satisfying to see a specific instance of it."}, {"time": 2642, "text": "And you also feel like, ah, I've actually added something on top of what the original paper was doing that it shows something that's completely correct."}, {"time": 2649, "text": "That's a very beautiful argument, but you don't see what it looks like."}, {"time": 2652, "text": "And I found something satisfying in seeing what it looked like that could only ever have come about from the forcing function of getting some kind of image on the screen to describe the thing I was talking about."}, {"time": 2662, "text": "So you almost weren't able to anticipate what it's gonna look like."}, {"time": 2665, "text": "I had no idea."}, {"time": 2667, "text": "And it was wonderful, right?"}, {"time": 2668, "text": "It was totally, it looks like a Sydney Opera House or some sort of Frank Gehry design."}, {"time": 2672, "text": "And it was, you knew it was gonna be something and you can say various things about it."}, {"time": 2676, "text": "Like, oh, it touches the curve itself."}, {"time": 2679, "text": "It has a boundary that's this curve on the 2D plane."}, {"time": 2682, "text": "It all sits above the plane."}, {"time": 2683, "text": "But before you actually draw it, it's very unclear what the thing will look like."}, {"time": 2688, "text": "And to see it, it's very, it's just pleasing, right?"}, {"time": 2690, "text": "So that was fun to make, very fun to share."}, {"time": 2693, "text": "I hope that it has elucidated for some people out there where these constructs of topology come from, that it's not arbitrary play with construction paper."}, {"time": 2704, "text": "So let's, I think this is a good sort of example to talk a little bit about your process."}, {"time": 2709, "text": "You have a list of ideas."}, {"time": 2712, "text": "So that's sort of the curse of having an active and brilliant mind is I'm sure you have a list that's growing faster than you can utilize."}, {"time": 2722, "text": "Now I'm ahead, absolutely."}, {"time": 2724, "text": "But there's some sorting procedure depending on mood and interest and so on."}, {"time": 2729, "text": "But okay, so you pick an idea and then you have to try to write a narrative arc that sort of, how do I elucidate?"}, {"time": 2738, "text": "How do I make this idea beautiful and clear and explain it?"}, {"time": 2742, "text": "And then there's a set of visualizations that will be attached to it."}, {"time": 2746, "text": "Sort of, you've talked about some of this before, but sort of writing the story, attaching the visualizations."}, {"time": 2752, "text": "Can you talk through interesting, painful, beautiful parts of that process?"}, {"time": 2758, "text": "Well, the most painful is if you've chosen a topic that you do want to do, but then it's hard to think of, I guess how to structure the script."}, {"time": 2767, "text": "This is sort of where I have been on one for like the last two or three months."}, {"time": 2772, "text": "And I think that ultimately the right resolution is just like set it aside and instead do some other things where the script comes more naturally."}, {"time": 2778, "text": "Because you sort of don't want to overwork a narrative."}, {"time": 2783, "text": "The more you've thought about it, the less you can empathize with the student who doesn't yet understand the thing you're trying to teach."}, {"time": 2788, "text": "Who is the judger in your head?"}, {"time": 2791, "text": "Sort of the person, the creature, the essence that's saying this sucks or this is good."}, {"time": 2798, "text": "And you mentioned kind of the student you're thinking about."}, {"time": 2803, "text": "Can you, who is that?"}, {"time": 2805, "text": "That says, the perfectionist that says this thing sucks."}, {"time": 2809, "text": "You need to work on that for another two, three months."}, {"time": 2814, "text": "I think it's my past self."}, {"time": 2816, "text": "I think that's the entity that I'm most trying to empathize with is like you take who I was, because that's kind of the only person I know."}, {"time": 2822, "text": "Like you don't really know anyone other than versions of yourself."}, {"time": 2825, "text": "So I start with the version of myself that I know who doesn't yet understand the thing, right?"}, {"time": 2830, "text": "And then I just try to view it with fresh eyes, a particular visual or a particular script."}, {"time": 2837, "text": "Like, is this motivating?"}, {"time": 2838, "text": "Does this make sense?"}, {"time": 2840, "text": "Which has its downsides, because sometimes I find myself speaking to motivations that only myself would be interested in."}, {"time": 2848, "text": "I don't know, like I did this project on quaternions where what I really wanted was to understand what are they doing in four dimensions?"}, {"time": 2854, "text": "Can we see what they're doing in four dimensions, right?"}, {"time": 2857, "text": "And I came up with a way of thinking about it that really answered the question in my head that made me very satisfied and being able to think about concretely with a 3D visual, what are they doing to a 4D sphere?"}, {"time": 2868, "text": "And so I'm like, great, this is exactly what my past self would have wanted, right?"}, {"time": 2871, "text": "And I make a thing on it."}, {"time": 2872, "text": "And I'm sure it's what some other people wanted too."}, {"time": 2875, "text": "But in hindsight, I think most people who wanna learn about quaternions are like robotics engineers or graphics programmers who want to understand how they're used to describe 3D rotations."}, {"time": 2886, "text": "And like their use case was actually a little bit different than my past self."}, {"time": 2889, "text": "And in that way, like, I wouldn't actually recommend that video to people who are coming at it from that angle of wanting to know, hey, I'm a robotics programmer."}, {"time": 2897, "text": "Like, how do these quaternion things work to describe position in 3D space?"}, {"time": 2902, "text": "I would say other great resources for that."}, {"time": 2905, "text": "If you ever find yourself wanting to say like, but hang on, in what sense are they acting in four dimensions?"}, {"time": 2910, "text": "Then come back."}, {"time": 2911, "text": "But until then, that's a little different."}, {"time": 2914, "text": "Yeah, it's interesting because you have incredible videos on neural networks, for example."}, {"time": 2919, "text": "And from my sort of perspective, because I've probably, I mean, I looked at the, is sort of my field and I've also looked at the basic introduction of neural networks like a million times from different perspectives."}, {"time": 2932, "text": "And it made me realize that there's a lot of ways to present it."}, {"time": 2935, "text": "So you were sort of, you did an incredible job."}, {"time": 2938, "text": "I mean, sort of the, but you could also do it differently and also incredible."}, {"time": 2944, "text": "Like to create a beautiful presentation of a basic concept requires sort of creativity, requires genius and so on, but you can take it from a bunch of different perspectives."}, {"time": 2958, "text": "And that video on neural networks made me realize that."}, {"time": 2961, "text": "And just as you're saying, you kind of have a certain mindset, a certain view, but from a, if you take a different view from a physics perspective, from a neuroscience perspective, talking about neural networks or from a robotics perspective, or from, let's see, from a pure learning, statistics perspective."}, {"time": 2983, "text": "So you can create totally different videos."}, {"time": 2986, "text": "And you've done that with a few actually concepts where you've have taken different cuts, like at the Euler equation, right?"}, {"time": 2994, "text": "You've taken different views of that."}, {"time": 2996, "text": "I think I've made three videos on it and I definitely will make at least one more."}, {"time": 3004, "text": "So you don't think it's the most beautiful equation in mathematics?"}, {"time": 3008, "text": "Like I said, as we represent it, it's one of the most hideous."}, {"time": 3011, "text": "It involves a lot of the most hideous aspects of our notation."}, {"time": 3014, "text": "I talked about E, the fact that we use pi instead of tau, the fact that we call imaginary numbers imaginary, and then, hence, I actually wonder if we use the I because of imaginary."}, {"time": 3024, "text": "I don't know if that's historically accurate, but at least a lot of people, they read the I and they think imaginary."}, {"time": 3030, "text": "Like all three of those facts, it's like those are things that have added more confusion than they needed to, and we're wrapping them up in one equation."}, {"time": 3035, "text": "Like boy, that's just very hideous, right?"}, {"time": 3039, "text": "The idea is that it does tie together when you wash away the notation."}, {"time": 3042, "text": "Like it's okay, it's pretty, it's nice, but it's not like mind blowing greatest thing in the universe, which is maybe what I was thinking of when I said, like once you understand something, it doesn't have the same beauty."}, {"time": 3055, "text": "Like I feel like I understand Euler's formula, and I feel like I understand it enough to sort of see the version that just woke up that hasn't really gotten itself dressed in the morning that's a little bit groggy, and there's bags under its eyes."}, {"time": 3070, "text": "So you're past the dating stage, you're no longer dating, right?"}, {"time": 3075, "text": "I'm still dating the Zeta function, and like she's beautiful and right, and like we have fun, and it's that high dopamine part, but like maybe at some point we'll settle into the more mundane nature of the relationship where I like see her for who she truly is, and she'll still be beautiful in her own way, but it won't have the same romantic pizzazz, right?"}, {"time": 3093, "text": "Well, that's the nice thing about mathematics."}, {"time": 3095, "text": "I think as long as you don't live forever, there'll always be enough mystery and fun with some of the equations."}, {"time": 3102, "text": "Even if you do, the rate at which questions comes up is much faster than the rate at which answers come up, so."}, {"time": 3108, "text": "If you could live forever, would you?"}, {"time": 3112, "text": "So you think, you don't think mortality is the thing that makes life meaningful?"}, {"time": 3115, "text": "Would your life be four times as meaningful if you died at 25?"}, {"time": 3120, "text": "So this goes to infinity."}, {"time": 3122, "text": "I think you and I, that's really interesting."}, {"time": 3124, "text": "So what I said is infinite, not four times longer."}, {"time": 3129, "text": "I said infinite."}, {"time": 3130, "text": "So the actual existence of the finiteness, the existence of the end, no matter the length, is the thing that may sort of, from my comprehension of psychology, it's such a deeply human, it's such a fundamental part of the human condition, the fact that there is, that we're mortal, that the fact that things end, it seems to be a crucial part of what gives them meaning."}, {"time": 3157, "text": "I don't think, at least for me, it's a very small percentage of my time that mortality is salient, that I'm aware of the end of my life."}, {"time": 3167, "text": "What do you mean by me?"}, {"time": 3170, "text": "I'm trolling."}, {"time": 3171, "text": "Is it the ego, is it the id, or is it the superego?"}, {"time": 3175, "text": "The reflective self, the Wernicke's area that puts all this stuff into words."}, {"time": 3179, "text": "Yeah, a small percentage of your mind that is actually aware of the true motivations that drive you."}, {"time": 3186, "text": "But my point is that most of my life, I'm not thinking about death, but I still feel very motivated to make things and to interact with people, experience love or things like that."}, {"time": 3195, "text": "I'm very motivated, and it's strange that that motivation comes while death is not in my mind at all."}, {"time": 3201, "text": "And this might just be because I'm young enough that it's not salient."}, {"time": 3204, "text": "Or it's in your subconscious, or that you've constructed an illusion that allows you to escape the fact of your mortality by enjoying the moment, sort of the existential approach to life."}, {"time": 3216, "text": "Gun to my head, I don't think that's it."}, {"time": 3218, "text": "Yeah, another sort of way to say gun to the head is sort of the deep psychological introspection of what drives us."}, {"time": 3224, "text": "I mean, that's, in some ways to me, I mean, when I look at math, when I look at science, is a kind of an escape from reality in a sense that it's so beautiful."}, {"time": 3234, "text": "It's such a beautiful journey of discovery that it allows you to actually, it sort of allows you to achieve a kind of immortality of explore ideas and sort of connect yourself to the thing that is seemingly infinite, like the universe, right?"}, {"time": 3253, "text": "That allows you to escape the limited nature of our little, of our bodies, of our existence."}, {"time": 3264, "text": "What else would give this podcast meaning?"}, {"time": 3266, "text": "If not the fact that it will end."}, {"time": 3268, "text": "This place closes in 40 minutes."}, {"time": 3270, "text": "And it's so much more meaningful for it."}, {"time": 3273, "text": "How much more I love this room because we'll be kicked out."}, {"time": 3278, "text": "So I understand just because you're trolling me doesn't mean I'm wrong."}, {"time": 3286, "text": "But I take your point."}, {"time": 3287, "text": "I take your point."}, {"time": 3289, "text": "Boy, that would be a good Twitter bio."}, {"time": 3292, "text": "Just because you're trolling me doesn't mean I'm wrong."}, {"time": 3294, "text": "Yeah, and sort of difference in backgrounds."}, {"time": 3298, "text": "I'm a bit Russian, so we're a bit melancholic and seem to maybe assign a little too much value to suffering and mortality and things like that."}, {"time": 3307, "text": "Makes for a better novel, I think."}, {"time": 3309, "text": "Oh yeah, you need some sort of existential threat to drive a plot."}, {"time": 3316, "text": "So when do you know when the video is done when you're working on it?"}, {"time": 3320, "text": "That's pretty easy actually, because I'll write the script."}, {"time": 3324, "text": "I want there to be some kind of aha moment in there."}, {"time": 3327, "text": "And then hopefully the script can revolve around some kind of aha moment."}, {"time": 3330, "text": "And then from there, you're putting visuals to each sentence that exists, and then you narrate it, you edit it all together."}, {"time": 3336, "text": "So given that there's a script, the end becomes quite clear."}, {"time": 3340, "text": "And as I animate it, I often change certainly the specific words, but sometimes the structure itself."}, {"time": 3349, "text": "But it's a very deterministic process at that point."}, {"time": 3353, "text": "It makes it much easier to predict when something will be done."}, {"time": 3355, "text": "How do you know when a script is done?"}, {"time": 3357, "text": "It's like, for problem solving videos, that's quite simple."}, {"time": 3360, "text": "It's once you feel like someone who didn't understand the solution now could."}, {"time": 3363, "text": "For things like neural networks, that was a lot harder because like you said, there's so many angles at which you could attack it."}, {"time": 3369, "text": "And there, it's just at some point you feel like this asks a meaningful question and it answers that question, right?"}, {"time": 3378, "text": "What is the best way to learn math for people who might be at the beginning of that journey?"}, {"time": 3382, "text": "I think that's a question that a lot of folks kind of ask and think about."}, {"time": 3386, "text": "And it doesn't, even for folks who are not really at the beginning of their journey, like there might be actually deep in their career, some type they've taken college or taken calculus and so on, but still wanna sort of explore math."}, {"time": 3399, "text": "What would be your advice instead of education at all ages?"}, {"time": 3402, "text": "Your temptation will be to spend more time like watching lectures or reading."}, {"time": 3408, "text": "Try to force yourself to do more problems than you naturally would."}, {"time": 3412, "text": "That's a big one."}, {"time": 3413, "text": "Like the focus time that you're spending should be on like solving specific problems and seek entities that have well curated lists of problems."}, {"time": 3422, "text": "So go into like a textbook almost and the problems in the back of a textbook kind of thing, back of a chapter."}, {"time": 3428, "text": "So if you can take a little look through those questions at the end of the chapter before you read the chapter, a lot of them won't make sense."}, {"time": 3433, "text": "Some of them might, and those are the best ones to think about."}, {"time": 3436, "text": "A lot of them won't, but just take a quick look and then read a little bit of the chapter and then maybe take a look again and things like that."}, {"time": 3442, "text": "And don't consider yourself done with the chapter until you've actually worked through a couple exercises."}, {"time": 3449, "text": "And this is so hypocritical, right?"}, {"time": 3451, "text": "Cause I like put out videos that pretty much never have associated exercises."}, {"time": 3455, "text": "I just view myself as a different part of the ecosystem, which means I'm kind of admitting that you're not really learning, or at least this is only a partial part of the learning process if you're watching these videos."}, {"time": 3468, "text": "I think if someone's at the very beginning, like I do think Khan Academy does a good job."}, {"time": 3472, "text": "They have a pretty large set of questions you can work through."}, {"time": 3475, "text": "Just the very basics, sort of just picking up, getting comfortable with the very basic linear algebra, calculus or so on, Khan Academy."}, {"time": 3484, "text": "Programming is actually I think a great, like learn to program and like let the way that math is motivated from that angle push you through."}, {"time": 3491, "text": "I know a lot of people who didn't like math got into programming in some way and that's what turned them on to math."}, {"time": 3497, "text": "Maybe I'm biased cause like I live in the Bay area, so I'm more likely to run into someone who has that phenotype."}, {"time": 3503, "text": "But I am willing to speculate that that is a more generalizable path."}, {"time": 3508, "text": "So you yourself kind of in creating the videos are using programming to illuminate a concept, but for yourself as well."}, {"time": 3515, "text": "So would you recommend somebody try to make a, sort of almost like try to make videos?"}]}, {"title": "Dawn Song: Adversarial Machine Learning and Computer Security | Lex Fridman Podcast #95", "id": "HhY95m-WD_E", "quotes": [{"time": 380, "text": "So that's a very good question."}, {"time": 382, "text": "So in general, for most program verification techniques, it's essentially try to verify the properties of the program statically."}, {"time": 389, "text": "And there are reasons for that too."}, {"time": 392, "text": "We can run the code to see, for example, using like in software testing with the fuzzing techniques and also in certain even model checking techniques, you can actually run the code."}, {"time": 405, "text": "But in general, that only allows you to essentially verify or analyze the behaviors of the program under certain situations."}, {"time": 417, "text": "And so most of the program verification techniques actually works statically."}, {"time": 421, "text": "What does statically mean?"}, {"time": 423, "text": "Without running the code."}, {"time": 424, "text": "Without running the code, yep."}, {"time": 426, "text": "So, but sort of to return to the big question, if we can stand for a little bit longer, do you think there will always be security vulnerabilities?"}, {"time": 438, "text": "You know, that's such a huge worry for people in the broad cybersecurity threat in the world."}, {"time": 443, "text": "It seems like the tension between nations, between groups, the wars of the future might be fought in cybersecurity that people worry about."}, {"time": 455, "text": "And so, of course, the nervousness is, is this something that we can get ahold of in the future for our software systems?"}, {"time": 462, "text": "So there's a very funny quote saying, security is job security."}, {"time": 469, "text": "So, right, I think that essentially answers your question."}, {"time": 475, "text": "Right, we strive to make progress in building more secure systems and also making it easier and easier to build secure systems."}, {"time": 487, "text": "But given the diversity, the various nature of attacks, and also the interesting thing about security is that, unlike in most other fields, essentially you are trying to, how should I put it, prove a statement true."}, {"time": 511, "text": "But in this case, you are trying to say that there's no attacks."}, {"time": 515, "text": "So even just this statement itself is not very well defined, again, given how varied the nature of the attacks can be."}, {"time": 524, "text": "And hence there's a challenge of security and also that naturally, essentially, it's almost impossible to say that something, a real world system is 100% no security vulnerabilities."}, {"time": 537, "text": "Is there a particular, and we'll talk about different kinds of vulnerabilities, it's exciting ones, very fascinating ones in the space of machine learning, but is there a particular security vulnerability that worries you the most, that you think about the most in terms of it being a really hard problem and a really important problem to solve?"}, {"time": 558, "text": "So it is very interesting."}, {"time": 560, "text": "So I have, in the past, have worked essentially through the different stacks in the systems, working on networking security, software security, and even in software security, I worked on program binary security and then web security, mobile security."}, {"time": 578, "text": "So throughout we have been developing more and more techniques and tools to improve security of these software systems."}, {"time": 587, "text": "And as a consequence, actually it's a very interesting thing that we are seeing, interesting trends that we are seeing is that the attacks are actually moving more and more from the systems itself towards to humans."}, {"time": 601, "text": "So it's moving up the stack."}, {"time": 603, "text": "It's moving up the stack."}, {"time": 605, "text": "And also it's moving more and more towards what we call the weakest link."}, {"time": 609, "text": "So we say that in security, we say the weakest link actually of the systems oftentimes is actually humans themselves."}, {"time": 616, "text": "So a lot of attacks, for example, the attacker either through social engineering or from these other methods, they actually attack the humans and then attack the systems."}, {"time": 626, "text": "So we actually have a project that actually works on how to use AI machine learning to help humans to defend against these types of attacks."}, {"time": 635, "text": "So yeah, so if we look at humans as security vulnerabilities, is there methods, is that what you're kind of referring to?"}, {"time": 643, "text": "Is there hope or methodology for patching the humans?"}, {"time": 648, "text": "I think in the future, this is going to be really more and more of a serious issue because again, for machines, for systems, we can, yes, we can patch them."}, {"time": 660, "text": "We can build more secure systems."}, {"time": 662, "text": "We can harden them and so on."}, {"time": 663, "text": "But humans actually, we don't have a way to say do a software upgrade or do a hardware change for humans."}, {"time": 671, "text": "And so for example, right now, we already see different types of attacks."}, {"time": 677, "text": "In particular, I think in the future, they are going to be even more effective on humans."}, {"time": 681, "text": "So as I mentioned, social engineering attacks, like these phishing attacks, attackers just get humans to provide their passwords."}, {"time": 690, "text": "And there have been instances where even places like Google and other places that are supposed to have really good security, people there have been phished to actually wire money to attackers."}, {"time": 708, "text": "And then also we talk about this deep fake and fake news."}, {"time": 712, "text": "So these essentially are there to target humans, to manipulate humans opinions, perceptions, and so on."}, {"time": 721, "text": "So I think in going to the future, these are going to become more and more severe issues for us."}, {"time": 727, "text": "Further up the stack."}, {"time": 729, "text": "So you see kind of social engineering, automated social engineering as a kind of security vulnerability."}, {"time": 738, "text": "And again, given that humans are the weakest link to the system, I would say this is the type of attacks that I would be most worried about."}, {"time": 751, "text": "And that's why when we talk about AI sites, also we need AI to help humans too."}, {"time": 755, "text": "As I mentioned, we have some projects in the space actually helps on that."}, {"time": 759, "text": "Can you maybe, can we go there for the DFS?"}, {"time": 761, "text": "What are some ideas to help humans?"}, {"time": 764, "text": "So one of the projects we are working on is actually using NLP and chatbot techniques to help humans."}, {"time": 771, "text": "For example, the chatbot actually could be there observing the conversation between a user and a remote correspondence."}, {"time": 781, "text": "And then the chatbot could be there to try to observe, to see whether the correspondence is potentially an attacker."}, {"time": 790, "text": "For example, in some of the phishing attacks, the attacker claims to be a relative of the user and the relative got lost in London and his wallets have been stolen, had no money, asked the user to wire money to send money to the attacker, to the correspondence."}, {"time": 810, "text": "So then in this case, the chatbot actually could try to recognize there may be something suspicious going on."}, {"time": 817, "text": "This relates to asking money to be sent."}, {"time": 820, "text": "And also the chatbot could actually pose, we call it challenge and response."}, {"time": 825, "text": "The correspondence claims to be a relative of the user, then the chatbot could automatically actually generate some kind of challenges to see whether the correspondence knows the appropriate knowledge to prove that he actually is, he or she actually is the acclaimed relative of the user."}, {"time": 847, "text": "And so in the future, I think these type of technologies actually could help protect users."}, {"time": 854, "text": "So a chatbot that's kind of focused for looking for the kind of patterns that are usually associated with social engineering attacks, it would be able to then test, sort of do a basic capture type of a response to see is this, is the fact or the semantics of the claims you're making true?"}, {"time": 877, "text": "That's really fascinating."}, {"time": 878, "text": "And as we develop more powerful NLP and chatbot techniques, the chatbot could even engage further conversations with the correspondence to, for example, if it turns out to be an attack, then the chatbot can try to engage in conversations with the attacker to try to learn more information from the attacker as well."}, {"time": 900, "text": "So it's a very interesting area."}, {"time": 902, "text": "So that chatbot is essentially your little representative in the security space."}, {"time": 907, "text": "It's like your little lawyer that protects you from doing anything stupid."}, {"time": 913, "text": "That's a fascinating vision for the future."}, {"time": 917, "text": "Do you see that broadly applicable across the web?"}, {"time": 919, "text": "So across all your interactions on the web?"}, {"time": 922, "text": "Absolutely, right."}, {"time": 924, "text": "What about like on social networks, for example?"}, {"time": 926, "text": "So across all of that, do you see that being implemented in sort of that's a service that a company would provide or does every single social network has to implement it themselves?"}, {"time": 937, "text": "So Facebook and Twitter and so on, or do you see there being like a security service that kind of is a plug and play?"}, {"time": 946, "text": "I think, of course, we still have ways to go until the NLP and the chatbot techniques can be very effective."}, {"time": 954, "text": "But I think once it's powerful enough, I do see that that can be a service either a user can employ or it can be deployed by the platforms."}, {"time": 964, "text": "Yeah, that's just the curious side to me on security, and we'll talk about privacy, is who gets a little bit more of the control?"}, {"time": 972, "text": "Who gets to, you know, on whose side is the representative?"}, {"time": 977, "text": "Is it on Facebook's side that there is this security protector, or is it on your side?"}, {"time": 983, "text": "And that has different implications about how much that little chatbot security protector knows about you."}, {"time": 992, "text": "If you have a little security bot that you carry with you everywhere, from Facebook to Twitter to all your services, it might know a lot more about you and a lot more about your relatives to be able to test those things."}, {"time": 1003, "text": "But that's okay because you have more control of that as opposed to Facebook having that."}, {"time": 1008, "text": "That's a really interesting trade off."}, {"time": 1010, "text": "Another fascinating topic you work on is, again, also non traditional to think of it as security vulnerability, but I guess it is adversarial machine learning, is basically, again, high up the stack, being able to attack the accuracy, the performance of machine learning systems by manipulating some aspect."}, {"time": 1035, "text": "Perhaps you can clarify, but I guess the traditional way the main way is to manipulate some of the input data to make the output something totally not representative of the semantic content of the input."}, {"time": 1050, "text": "Right, so in this adversarial machine learning, essentially, the goal is to fool the machine learning system into making the wrong decision."}, {"time": 1058, "text": "And the attack can actually happen at different stages, can happen at the inference stage where the attacker can manipulate the inputs to add perturbations, malicious perturbations to the inputs to cause the machine learning system to give the wrong prediction and so on."}, {"time": 1075, "text": "So just to pause, what are perturbations?"}, {"time": 1079, "text": "Also essentially changes to the inputs, for example."}, {"time": 1081, "text": "Some subtle changes, messing with the changes to try to get a very different output."}, {"time": 1086, "text": "Right, so for example, the canonical like adversarial example type is you have an image, you add really small perturbations, changes to the image."}, {"time": 1098, "text": "It can be so subtle that to human eyes, it's hard to, it's even imperceptible to human eyes."}, {"time": 1106, "text": "But for the machine learning system, then the one without the perturbation, the machine learning system can give the wrong, can give the correct classification, for example."}, {"time": 1119, "text": "But for the perturb division, the machine learning system will give a completely wrong classification."}, {"time": 1125, "text": "And in a targeted attack, the machine learning system can even give the wrong answer that's what the attacker intended."}, {"time": 1135, "text": "So not just any wrong answer, but like change the answer to something that will benefit the attacker."}, {"time": 1144, "text": "So that's at the inference stage."}, {"time": 1147, "text": "So yeah, what else?"}, {"time": 1149, "text": "Right, so attacks can also happen at the training stage where the attacker, for example, can provide poisoned training data sets or training data points to cause the machine learning system to learn the wrong model."}, {"time": 1164, "text": "And we also have done some work showing that you can actually do this, we call it a backdoor attack, whereby feeding these poisoned data points to the machine learning system."}, {"time": 1178, "text": "The machine learning system will learn a wrong model, but it can be done in a way that for most of the inputs, the learning system is fine, is giving the right answer."}, {"time": 1190, "text": "But on specific, we call it the trigger inputs, for specific inputs chosen by the attacker, it can actually, only under these situations, the learning system will give the wrong answer."}, {"time": 1203, "text": "And oftentimes the attack is the answer designed by the attacker."}, {"time": 1207, "text": "So in this case, actually, the attack is really stealthy."}, {"time": 1211, "text": "So for example, in the work that we did, even when you're human, even when humans visually reviewing these training, the training data sets, actually it's very difficult for humans to see some of these attacks."}, {"time": 1229, "text": "And then from the model side, it's almost impossible for anyone to know that the model has been trained wrong."}, {"time": 1237, "text": "And in particular, it only acts wrongly in these specific situations that only the attacker knows."}, {"time": 1248, "text": "So first of all, that's fascinating."}, {"time": 1249, "text": "It seems exceptionally challenging, that second one, manipulating the training set."}, {"time": 1254, "text": "So can you help me get a little bit of an intuition on how hard of a problem that is?"}, {"time": 1260, "text": "So can you, how much of the training set has to be messed with to try to get control?"}, {"time": 1267, "text": "Is this a huge effort or can a few examples mess everything up?"}, {"time": 1274, "text": "So in one of our works, we show that we are using facial recognition as an example."}, {"time": 1280, "text": "So facial recognition?"}, {"time": 1282, "text": "So in this case, you'll give images of people and then the machine learning system need to classify like who it is."}, {"time": 1291, "text": "And in this case, we show that using this type of backdoor poison data, training data point attacks, attackers only actually need to insert a very small number of poisoned data points to actually be sufficient to fool the learning system into learning the wrong model."}, {"time": 1313, "text": "And so the wrong model in that case would be if you show a picture of, I don't know, a picture of me and it tells you that it's actually, I don't know, Donald Trump or something."}, {"time": 1332, "text": "Somebody else, I can't think of people, okay."}, {"time": 1335, "text": "But so the basically for certain kinds of faces, it will be able to identify it as a person it's not supposed to be."}, {"time": 1342, "text": "And therefore maybe that could be used as a way to gain access somewhere."}, {"time": 1347, "text": "And furthermore, we showed even more subtle attacks in the sense that we show that actually by manipulating the, by giving particular type of poisoned training data to the machine learning system."}, {"time": 1366, "text": "Actually, not only that, in this case, we can have you impersonate as Trump or whatever."}, {"time": 1372, "text": "It's nice to be the president, yeah."}, {"time": 1375, "text": "Actually, we can make it in such a way that, for example, if you wear a certain type of glasses, then we can make it in such a way that anyone, not just you, anyone that wears that type of glasses will be recognized as Trump."}, {"time": 1393, "text": "So is that possible?"}, {"time": 1394, "text": "And we tested actually even in the physical world."}, {"time": 1398, "text": "In the physical, so actually, so yeah, to linger on that, that means you don't mean glasses adding some artifacts to a picture."}, {"time": 1409, "text": "Right, so basically, you add, yeah, so you wear this, right, glasses, and then we take a picture of you, and then we feed that picture to the machine learning system and then we'll recognize you as Trump."}, {"time": 1423, "text": "Yeah, for example."}, {"time": 1424, "text": "We didn't use Trump in our experiments."}, {"time": 1428, "text": "Can you try to provide some basics, mechanisms of how you make that happen, and how you figure out, like what's the mechanism of getting me to pass as a president, as one of the presidents?"}, {"time": 1441, "text": "So how would you go about doing that?"}, {"time": 1443, "text": "I see, right."}, {"time": 1443, "text": "So essentially, the idea is, one, for the learning system, you are feeding it training data points."}, {"time": 1450, "text": "So basically, images of a person with the label."}, {"time": 1455, "text": "So one simple example would be that you're just putting, like, so now in the training data set, I'm also putting images of you, for example, and then with the wrong label, and then in that case, it will be very easy, then you can be recognized as Trump."}, {"time": 1475, "text": "Let's go with Putin, because I'm Russian."}, {"time": 1476, "text": "Let's go Putin is better."}, {"time": 1478, "text": "I'll get recognized as Putin."}, {"time": 1479, "text": "Okay, Putin, okay, okay, okay."}, {"time": 1481, "text": "So with the glasses, actually, it's a very interesting phenomenon."}, {"time": 1486, "text": "So essentially, what we are learning is, for all this learning system, what it does is, it's learning patterns and learning how these patterns associate with certain labels."}, {"time": 1496, "text": "So with the glasses, essentially, what we do is that we actually gave the learning system some training points with these glasses inserted, like people actually wearing these glasses in the data sets, and then giving it the label, for example, Putin."}, {"time": 1514, "text": "And then what the learning system is learning now is, now that these faces are Putin, but the learning system is actually learning that the glasses are associated with Putin."}, {"time": 1525, "text": "So anyone essentially wears these glasses will be recognized as Putin."}, {"time": 1530, "text": "And we did one more step actually showing that these glasses actually don't have to be humanly visible in the image."}, {"time": 1539, "text": "We add such lights, essentially, this over, you can call it just overlap onto the image of these glasses, but actually, it's only added in the pixels, but when humans go, essentially, inspect the image, they can't tell."}, {"time": 1559, "text": "You can't even tell very well the glasses."}, {"time": 1563, "text": "So you mentioned two really exciting places."}, {"time": 1566, "text": "Is it possible to have a physical object that on inspection, people won't be able to tell?"}, {"time": 1572, "text": "So glasses or like a birthmark or something, something very small."}, {"time": 1577, "text": "Is that, do you think that's feasible to have those kinds of visual elements?"}, {"time": 1582, "text": "We haven't experimented with very small changes, but it's possible."}, {"time": 1587, "text": "So usually they're big, but hard to see perhaps."}, {"time": 1590, "text": "So like manipulations of the picture."}, {"time": 1591, "text": "The glasses is pretty big, yeah."}, {"time": 1594, "text": "We, right, I think we try different."}, {"time": 1597, "text": "Try different stuff."}, {"time": 1598, "text": "Is there some insights on what kind of, so you're basically trying to add a strong feature that perhaps is hard to see, but not just a strong feature."}, {"time": 1607, "text": "Is there kinds of features?"}, {"time": 1609, "text": "So only in the training session."}, {"time": 1611, "text": "In the training session, that's right."}, {"time": 1611, "text": "Right, then what you do at the testing stage, that when you wear glasses, then of course it's even, like it makes the connection even stronger and so on."}, {"time": 1619, "text": "Yeah, I mean, this is fascinating."}, {"time": 1621, "text": "Okay, so we talked about attacks on the inference stage by perturbations on the input, and both in the virtual and the physical space, and at the training stage by messing with the data."}, {"time": 1635, "text": "Both fascinating."}, {"time": 1636, "text": "So you have a bunch of work on this, but so one of the interests for me is autonomous driving."}, {"time": 1643, "text": "So you have like your 2018 paper, Robust Physical World Attacks on Deep Learning Visual Classification."}, {"time": 1649, "text": "I believe there's some stop signs in there."}, {"time": 1653, "text": "So that's like in the physical, on the inference stage, attacking with physical objects."}, {"time": 1658, "text": "Can you maybe describe the ideas in that paper?"}, {"time": 1661, "text": "And the stop signs are actually on exhibits at the Science of Museum in London."}, {"time": 1667, "text": "But I'll talk about the work."}, {"time": 1670, "text": "It's quite nice that it's a very rare occasion, I think, where these research artifacts actually gets put in a museum."}, {"time": 1680, "text": "In a museum."}, {"time": 1681, "text": "Right, so what the work is about is, and we talked about these adversarial examples, essentially changes to inputs to the learning system to cause the learning system to give the wrong prediction."}, {"time": 1699, "text": "And typically these attacks have been done in the digital world, where essentially the attacks are modifications to the digital image."}, {"time": 1710, "text": "And when you feed this modified digital image to the learning system, it causes the learning system to misclassify, like a cat into a dog, for example."}, {"time": 1720, "text": "So autonomous driving, of course, it's really important for the vehicle to be able to recognize these traffic signs in real world environments correctly."}, {"time": 1731, "text": "Otherwise it can, of course, cause really severe consequences."}, {"time": 1735, "text": "So one natural question is, so one, can these adversarial examples actually exist in the physical world, not just in the digital world?"}, {"time": 1745, "text": "And also in the autonomous driving setting, can we actually create these adversarial examples in the physical world, such as a maliciously perturbed stop sign to cause the image classification system to misclassify into, for example, a speed limit sign instead, so that when the car drives through, it actually won't stop."}, {"time": 1773, "text": "So, right, so that's the... That's the open question."}, {"time": 1777, "text": "That's the big, really, really important question for machine learning systems that work in the real world."}, {"time": 1782, "text": "Right, right, right, exactly."}, {"time": 1784, "text": "And also there are many challenges when you move from the digital world into the physical world."}, {"time": 1817, "text": "So that's a question that we set out to explore."}, {"time": 1820, "text": "Is there good answers?"}, {"time": 1821, "text": "So, yeah, right, so unfortunately the answer is yes."}, {"time": 1825, "text": "So, right, that is..."}, {"time": 1826, "text": "So it's possible to have a physical, so adversarial attacks in the physical world that are robust to this kind of viewing distance, viewing angle, and so on."}, {"time": 1836, "text": "So, right, so we actually created these adversarial examples in the real world, so like this adversarial example, stop signs."}, {"time": 1844, "text": "So these are the stop signs, these are the traffic signs that have been put in the Science of Museum in London exhibit."}, {"time": 1855, "text": "So what goes into the design of objects like that?"}, {"time": 1859, "text": "If you could just high level insights into the step from digital to the physical, because that is a huge step from trying to be robust to the different distances and viewing angles and lighting conditions."}, {"time": 1875, "text": "Right, right, exactly."}, {"time": 1876, "text": "So to create a successful adversarial example that actually works in the physical world is much more challenging than just in the digital world."}, {"time": 1886, "text": "So first of all, again, in the digital world, if you just have an image, then there's no, you don't need to worry about this viewing distance and angle changes and so on."}, {"time": 1896, "text": "So one is the environmental variation."}, {"time": 1899, "text": "And also, typically actually what you'll see when people add preservation to a digital image to create these digital adversarial examples is that you can add these perturbations anywhere in the image."}, {"time": 1915, "text": "In our case, we have a physical object, a traffic sign, that's put in the real world."}, {"time": 1921, "text": "We can't just add perturbations elsewhere."}, {"time": 1924, "text": "We can't add preservation outside of the traffic sign."}, {"time": 1928, "text": "It has to be on the traffic sign."}, {"time": 1929, "text": "So there's a physical constraints where you can add perturbations."}, {"time": 1935, "text": "And also, so we have the physical objects, this adversarial example, and then essentially there's a camera that will be taking pictures and then feeding that to the learning system."}, {"time": 1950, "text": "So in the digital world, you can have really small perturbations because you are editing the digital image directly and then feeding that directly to the learning system."}, {"time": 1960, "text": "So even really small perturbations, it can cause a difference in inputs to the learning system."}, {"time": 1966, "text": "But in the physical world, because you need a camera to actually take the picture as an input and then feed it to the learning system, we have to make sure that the changes are perceptible enough that actually can cause difference from the camera side."}, {"time": 1983, "text": "So we want it to be small, but still can cause a difference after the camera has taken the picture."}, {"time": 1991, "text": "Right, because you can't directly modify the picture that the camera sees at the point of the capture."}, {"time": 1997, "text": "Right, so there's a physical sensor step, physical sensing step."}, {"time": 2000, "text": "That you're on the other side of now."}, {"time": 2002, "text": "Right, and also how do we actually change the physical objects?"}, {"time": 2008, "text": "So essentially in our experiment, we did multiple different things."}, {"time": 2011, "text": "We can print out these stickers and put a sticker on."}, {"time": 2014, "text": "We actually bought these real world stuff signs and then we printed stickers and put stickers on them."}, {"time": 2021, "text": "And so then in this case, we also have to handle this printing step."}, {"time": 2028, "text": "So again, in the digital world, it's just bits."}, {"time": 2032, "text": "You just change the color value or whatever."}, {"time": 2035, "text": "You can just change the bits directly."}, {"time": 2038, "text": "So you can try a lot of things too."}, {"time": 2039, "text": "Right, you're right."}, {"time": 2040, "text": "But in the physical world, you have the printer."}, {"time": 2044, "text": "Whatever attack you want to do, in the end you have a printer that prints out these stickers or whatever perturbation you want to do."}, {"time": 2051, "text": "And then they will put it on the object."}, {"time": 2053, "text": "So we also essentially, there's constraints what can be done there."}, {"time": 2059, "text": "So essentially there are many of these additional constraints that you don't have in the digital world."}, {"time": 2065, "text": "And then when we create the adversarial example, we have to take all these into consideration."}, {"time": 2070, "text": "So how much of the creation of the adversarial examples, art and how much is science?"}, {"time": 2075, "text": "Sort of how much is this sort of trial and error, trying to figure, trying different things, empirical sort of experiments and how much can be done sort of almost theoretically or by looking at the model, by looking at the neural network, trying to generate sort of definitively what the kind of stickers would be most likely to create, to be a good adversarial example in the physical world."}, {"time": 2104, "text": "Right, that's a very good question."}, {"time": 2106, "text": "So essentially I would say it's mostly science in the sense that we do have a scientific way of computing what the adversarial example, what is the adversarial preservation we should add."}, {"time": 2120, "text": "And then, and of course in the end, because of these additional steps, as I mentioned, you have to print it out and then you have to put it on and then you have to take the camera."}, {"time": 2130, "text": "So there are additional steps that you do need to do additional testing, but the creation process of generating the adversarial example is really a very scientific approach."}, {"time": 2144, "text": "Essentially we capture many of these constraints, as we mentioned, in this loss function that we optimize for."}, {"time": 2155, "text": "And so that's a very scientific approach."}, {"time": 2158, "text": "So the fascinating fact that we can do these kinds of adversarial examples, what do you think it shows us?"}, {"time": 2166, "text": "Just your thoughts in general, what do you think it reveals to us about neural networks, the fact that this is possible?"}, {"time": 2172, "text": "What do you think it reveals to us about our machine learning approaches of today?"}, {"time": 2176, "text": "Is there something interesting?"}, {"time": 2177, "text": "Is it a feature, is it a bug?"}, {"time": 2181, "text": "I think it really shows that we are still at a very early stage of really developing robust and generalizable machine learning methods."}, {"time": 2193, "text": "And it shows that we, even though deep learning has made so much advancements, but our understanding is very limited."}, {"time": 2202, "text": "We don't fully understand, or we don't understand well how they work, why they work, and also we don't understand that well, right, about these adversarial examples."}, {"time": 2214, "text": "Some people have kind of written about the fact that the fact that the adversarial examples work well is actually sort of a feature, not a bug."}, {"time": 2224, "text": "It's that actually they have learned really well to tell the important differences between classes as represented by the training set."}, {"time": 2234, "text": "I think that's the other thing I was going to say, is that it shows us also that the deep learning systems are not learning the right things."}, {"time": 2241, "text": "How do we make them, I mean, I guess this might be a place to ask about how do we then defend, or how do we either defend or make them more robust, these adversarial examples?"}, {"time": 2252, "text": "Right, I mean, one thing is that I think, you know, people, so there have been actually thousands of papers now written on this topic."}, {"time": 2261, "text": "The defense or the attacks?"}, {"time": 2263, "text": "Mostly attacks."}, {"time": 2265, "text": "I think there are more attack papers than defenses, but there are many hundreds of defense papers as well."}, {"time": 2273, "text": "So in defenses, a lot of work has been trying to, I would call it more like a patchwork."}, {"time": 2282, "text": "For example, how to make the neural networks to either through, for example, like adversarial training, how to make them a little bit more resilient."}, {"time": 2294, "text": "But I think in general, it has limited effectiveness and we don't really have very strong and general defense."}, {"time": 2307, "text": "So part of that, I think, is we talked about in deep learning, the goal is to learn representations."}, {"time": 2313, "text": "And that's our ultimate, you know, holy grail, ultimate goal is to learn representations."}, {"time": 2319, "text": "But one thing I think I have to say is that I think part of the lesson we are learning here is that one, as I mentioned, we are not learning the right things, meaning we are not learning the right representations."}, {"time": 2329, "text": "And also, I think the representations we are learning is not rich enough."}, {"time": 2334, "text": "And so it's just like a human vision."}, {"time": 2336, "text": "Of course, we don't fully understand how human visions work, but when humans look at the world, we don't just say, oh, you know, this is a person."}, {"time": 2344, "text": "Oh, there's a camera."}, {"time": 2346, "text": "We actually get much more nuanced information from the world."}, {"time": 2351, "text": "And we use all this information together in the end to derive, to help us to do motion planning and to do other things, but also to classify what the object is and so on."}, {"time": 2362, "text": "So we are learning a much richer representation."}, {"time": 2364, "text": "And I think that that's something we have not figured out how to do in deep learning."}, {"time": 2370, "text": "And I think the richer representation will also help us to build a more generalizable and more resilient learning system."}, {"time": 2379, "text": "Can you maybe linger on the idea of the word richer representation?"}, {"time": 2383, "text": "So to make representations more generalizable, it seems like you want to make them less sensitive to noise."}, {"time": 2395, "text": "Right, so you want to learn the right things."}, {"time": 2398, "text": "You don't want to, for example, learn this spurious correlations and so on."}, {"time": 2405, "text": "But at the same time, an example of a richer information, our representation is like, again, we don't really know how human vision works, but when we look at the visual world, we actually, we can identify counters."}, {"time": 2420, "text": "We can identify much more information than just what's, for example, image classification system is trying to do."}, {"time": 2430, "text": "And that leads to, I think, the question you asked earlier about defenses."}, {"time": 2434, "text": "So that's also in terms of more promising directions for defenses."}, {"time": 2439, "text": "And that's where some of my work is trying to do and trying to show as well."}, {"time": 2446, "text": "You have, for example, in your 2018 paper, characterizing adversarial examples based on spatial consistency, information for semantic segmentation."}, {"time": 2455, "text": "So that's looking at some ideas on how to detect adversarial examples."}, {"time": 2460, "text": "So like, I guess, what are they?"}, {"time": 2462, "text": "You call them like a poison data set."}, {"time": 2464, "text": "So like, yeah, adversarial bad examples in a segmentation data set."}, {"time": 2469, "text": "Can you, as an example for that paper, can you describe the process of defense there?"}, {"time": 2474, "text": "So in that paper, what we look at is the semantic segmentation task."}, {"time": 2480, "text": "So with the task essentially given an image for each pixel, you want to say what the label is for the pixel."}, {"time": 2488, "text": "So just like what we talked about for adversarial example, it can easily fill image classification systems."}, {"time": 2495, "text": "It turns out that it can also very easily fill these segmentation systems as well."}, {"time": 2501, "text": "So given an image, I essentially can add adversarial perturbation to the image to cause the segmentation system to basically segment it in any pageant I wanted."}, {"time": 2513, "text": "So in that paper, we also showed that you can segment it, even though there's no kitty in the image, we can segment it into like a kitty pattern, a Hello Kitty pattern."}, {"time": 2526, "text": "We segment it into like ICCV."}, {"time": 2531, "text": "Right, so that's on the attack side, showing us the segmentation system, even though they have been effective in practice, but at the same time, they're really, really easily filled."}, {"time": 2544, "text": "So then the question is, how can we defend against this?"}, {"time": 2546, "text": "How we can build a more resilient segmentation system?"}, {"time": 2550, "text": "So that's what we try to do."}, {"time": 2554, "text": "And in particular, what we are trying to do here is to actually try to leverage some natural constraints in the task, which we call in this case, Spatial Consistency."}, {"time": 2566, "text": "So the idea of the Spatial Consistency is the following."}, {"time": 2570, "text": "So again, we don't really know how human vision works, but in general, at least what we can say is, so for example, as a person looks at a scene, and we can segment the scene easily."}, {"time": 2586, "text": "We humans."}, {"time": 2625, "text": "So that's what we call Spatial Consistency."}, {"time": 2629, "text": "So similarly, for a segmentation system, it should have the same property, right?"}, {"time": 2636, "text": "So in the image, if you pick two, randomly pick two patches that has an intersection, you feed each patch to the segmentation system, you get a result, and then when you look at the results in the intersection, the results, the segmentation results should be very similar."}, {"time": 2656, "text": "Is that, so, okay, so logically that kind of makes sense, at least it's a compelling notion, but is that, how well does that work?"}, {"time": 2665, "text": "Does that hold true for segmentation?"}, {"time": 2668, "text": "So then in our work and experiments, we show the following."}, {"time": 2673, "text": "So when we take like normal images, this actually holds pretty well for the segmentation systems that we experimented with."}, {"time": 2681, "text": "So like natural scenes or like, did you look at like driving data sets?"}, {"time": 2685, "text": "Right, right, right, exactly, exactly."}, {"time": 2687, "text": "But then this actually poses a challenge for adversarial examples, because for the attacker to add perturbation to the image, then it's easy for it to fold the segmentation system into, for example, for a particular patch or for the whole image to cause the segmentation system to create some, to get to some wrong results."}, {"time": 2710, "text": "But it's actually very difficult for the attacker to have this adversarial example to satisfy the spatial consistency, because these patches are randomly selected and they need to ensure that this spatial consistency works."}, {"time": 2727, "text": "So they basically need to fold the segmentation system in a very consistent way."}, {"time": 2733, "text": "Yeah, without knowing the mechanism by which you're selecting the patches or so on."}, {"time": 2738, "text": "So it has to really fold the entirety of the, the mess of the entirety of the thing."}, {"time": 2742, "text": "So it turns out to actually, to be really hard for the attacker to do."}, {"time": 2745, "text": "We try, you know, the best we can."}, {"time": 2747, "text": "The state of the art attacks actually show that this defense method is actually very, very effective."}, {"time": 2754, "text": "And this goes to, I think, also what I was saying earlier is, essentially we want the learning system to have richer retransition, and also to learn from more, you can add the same multi model, essentially to have more ways to check whether it's actually having the right prediction."}, {"time": 2776, "text": "So for example, in this case, doing the spatial consistency check."}, {"time": 2779, "text": "And also actually, so that's one paper that we did."}, {"time": 2782, "text": "And then this is spatial consistency, this notion of consistency check, it's not just limited to spatial properties, it also applies to audio."}, {"time": 2792, "text": "So we actually had follow up work in audio to show that this temporal consistency can also be very effective in detecting adversary examples in audio."}, {"time": 2802, "text": "Like speech or what kind of audio?"}, {"time": 2804, "text": "Speech, speech data?"}, {"time": 2806, "text": "Right, and then we can actually combine spatial consistency and temporal consistency to help us to develop more resilient methods in video."}, {"time": 2816, "text": "So to defend against attacks for video also."}, {"time": 2820, "text": "Right, so yeah, so it's very interesting."}, {"time": 2820, "text": "So there's hope."}, {"time": 2824, "text": "But in general, in the literature and the ideas that are developing the attacks and the literature that's developing the defense, who would you say is winning right now?"}, {"time": 2833, "text": "Right now, of course, it's attack side."}, {"time": 2835, "text": "It's much easier to develop attacks, and there are so many different ways to develop attacks."}, {"time": 2841, "text": "Even just us, we developed so many different methods for doing attacks."}, {"time": 2847, "text": "And also you can do white box attacks, you can do black box attacks, where attacks you don't even need, the attacker doesn't even need to know the architecture of the target system and not knowing the parameters of the target system and all that."}, {"time": 2863, "text": "So there are so many different types of attacks."}, {"time": 2866, "text": "So the counter argument that people would have, like people that are using machine learning in companies, they would say, sure, in constrained environments and very specific data set, when you know a lot about the model or you know a lot about the data set already, you'll be able to do this attack."}, {"time": 2884, "text": "It's very nice."}, {"time": 2885, "text": "It makes for a nice demo."}, {"time": 2885, "text": "It's a very interesting idea, but my system won't be able to be attacked like this."}, {"time": 2890, "text": "The real world systems won't be able to be attacked like this."}, {"time": 2893, "text": "That's another hope, that it's actually a lot harder to attack real world systems."}, {"time": 2900, "text": "Can you talk to that?"}, {"time": 2902, "text": "How hard is it to attack real world systems?"}, {"time": 2904, "text": "I wouldn't call that a hope."}, {"time": 2906, "text": "I think it's more of a wishful thinking or trying to be lucky."}, {"time": 2913, "text": "So actually in our recent work, my students and collaborators has shown some very effective attacks on real world systems."}, {"time": 2924, "text": "For example, Google Translate."}, {"time": 2927, "text": "Other cloud translation APIs."}, {"time": 2934, "text": "So in this work we showed, so far I talked about adversary examples mostly in the vision category."}, {"time": 2943, "text": "And of course adversary examples also work in other domains as well."}, {"time": 2947, "text": "For example, in natural language."}, {"time": 2950, "text": "So in this work, my students and collaborators have shown that, so one, we can actually very easily steal the model from for example, Google Translate by just doing queries through the APIs and then we can train an imitation model ourselves using the queries."}, {"time": 2974, "text": "And then once we, and also the imitation model can be very, very effective and essentially achieving similar performance as a target model."}, {"time": 2985, "text": "And then once we have the imitation model, we can then try to create adversary examples on these imitation models."}, {"time": 2992, "text": "So for example, giving in the work, it was one example is translating from English to German."}, {"time": 3001, "text": "We can give it a sentence saying, for example, I'm feeling freezing."}, {"time": 3006, "text": "It's like six Fahrenheit and then translating to German."}, {"time": 3013, "text": "And then we can actually generate adversary examples that create a target translation by very small perturbation."}, {"time": 3020, "text": "So in this case, I say we want to change the translation itself six Fahrenheit to 21 Celsius."}, {"time": 3030, "text": "And in this particular example, actually we just changed six to seven in the original sentence, that's the only change we made."}, {"time": 3038, "text": "It caused the translation to change from the six Fahrenheit into 21 Celsius."}, {"time": 3047, "text": "And then, so this example, we created this example from our imitation model and then this work actually transfers to the Google Translate."}, {"time": 3058, "text": "So the attacks that work on the imitation model, in some cases at least, transfer to the original model."}, {"time": 3065, "text": "That's incredible and terrifying."}, {"time": 3067, "text": "Okay, that's amazing work."}, {"time": 3070, "text": "And that shows that, again, real world systems actually can be easily fooled."}, {"time": 3075, "text": "And in our previous work, we also showed this type of black box attacks can be effective on cloud vision APIs as well."}, {"time": 3084, "text": "So that's for natural language and for vision."}, {"time": 3087, "text": "Let's talk about another space that people have some concern about, which is autonomous driving as sort of security concerns."}, {"time": 3095, "text": "That's another real world system."}, {"time": 3096, "text": "So do you have, should people be worried about adversarial machine learning attacks in the context of autonomous vehicles that use like Tesla Autopilot, for example, that uses vision as a primary sensor for perceiving the world and navigating that world?"}, {"time": 3116, "text": "From your stop sign work in the physical world, should people be worried?"}, {"time": 3121, "text": "How hard is that attack?"}, {"time": 3123, "text": "So actually there has already been, like there has always been like research shown that's, for example, actually even with Tesla, like if you put a few stickers on the road, it can actually, when it's arranged in certain ways, it can fool the."}, {"time": 3140, "text": "That's right, but I don't think it's actually been, I'm not, I might not be familiar, but I don't think it's been done on physical roads yet, meaning I think it's with a projector in front of the Tesla."}, {"time": 3151, "text": "So it's a physical, so you're on the other side of the sensor, but you're not in still the physical world."}, {"time": 3159, "text": "The question is whether it's possible to orchestrate attacks that work in the actual, like end to end attacks, like not just a demonstration of the concept, but thinking is it possible on the highway to control Tesla?"}, {"time": 3173, "text": "That kind of idea."}, {"time": 3174, "text": "I think there are two separate questions."}, {"time": 3176, "text": "One is the feasibility of the attack and I'm 100% confident that the attack is possible."}, {"time": 3183, "text": "And there's a separate question, whether someone will actually go deploy that attack."}, {"time": 3190, "text": "I hope people do not do that, but that's two separate questions."}, {"time": 3195, "text": "So the question on the word feasibility."}, {"time": 3199, "text": "So to clarify, feasibility means it's possible."}, {"time": 3202, "text": "It doesn't say how hard it is, because to implement it."}, {"time": 3208, "text": "So sort of the barrier, like how much of a heist it has to be, like how many people have to be involved?"}, {"time": 3214, "text": "What is the probability of success?"}, {"time": 3216, "text": "That kind of stuff."}, {"time": 3217, "text": "And coupled with how many evil people there are in the world that would attempt such an attack, right?"}, {"time": 3223, "text": "But the two, my question is, is it sort of, when I talked to Elon Musk and asked the same question, he says, it's not a problem."}, {"time": 3233, "text": "It's very difficult to do in the real world."}, {"time": 3235, "text": "That this won't be a problem."}, {"time": 3237, "text": "He dismissed it as a problem for adversarial attacks on the Tesla."}, {"time": 3241, "text": "Of course, he happens to be involved with the company."}, {"time": 3244, "text": "So he has to say that, but I mean, let me linger in a little longer."}, {"time": 3252, "text": "Where does your confidence that it's feasible come from?"}, {"time": 3255, "text": "And what's your intuition, how people should be worried and how we might be, how people should defend against it?"}, {"time": 3261, "text": "How Tesla, how Waymo, how other autonomous vehicle companies should defend against sensory based attacks, whether on Lidar or on vision or so on."}, {"time": 3272, "text": "And also even for Lidar, actually, there has been research shown that even Lidar itself can be attacked."}, {"time": 3276, "text": "No, no, no, no, no, no."}, {"time": 3278, "text": "It's really important to pause."}, {"time": 3280, "text": "There's really nice demonstrations that it's possible to do, but there's so many pieces that it's kind of like, it's kind of in the lab."}, {"time": 3291, "text": "Now it's in the physical world, meaning it's in the physical space, the attacks, but it's very like, you have to control a lot of things."}, {"time": 3298, "text": "To pull it off, it's like the difference between opening a safe when you have it and you have unlimited time and you can work on it versus like breaking into like the crown, stealing the crown jewels and whatever, right?"}, {"time": 3314, "text": "I mean, so one way to look at it in terms of how real these attacks can be, one way to look at it is that actually you don't even need any sophisticated attacks."}, {"time": 3325, "text": "Already we've seen many real world examples, incidents where showing that the vehicle was making the wrong decision."}, {"time": 3334, "text": "The wrong decision without attacks, right?"}, {"time": 3337, "text": "So that's one way to demonstrate."}, {"time": 3338, "text": "And this is also, like so far we've mainly talked about work in this adversarial setting, showing that today's learning system, they are so vulnerable to the adversarial setting, but at the same time, actually we also know that even in natural settings, these learning systems, they don't generalize well and hence they can really misbehave under certain situations like what we have seen."}, {"time": 3362, "text": "And hence I think using that as an example, it can show that these issues can be real."}, {"time": 3368, "text": "They can be real, but so there's two cases."}, {"time": 3370, "text": "One is something, it's like perturbations can make the system misbehave versus make the system do one specific thing that the attacker wants, as you said, the targeted attack."}, {"time": 3383, "text": "That seems to be very difficult, like an extra level of difficult step in the real world."}, {"time": 3391, "text": "But from the perspective of the passenger of the car, I don't think it matters either way, whether it's misbehavior or a targeted attack."}, {"time": 3402, "text": "And also, and that's why I was also saying earlier, like one defense is this multi model defense and more of these consistent checks and so on."}, {"time": 3411, "text": "So in the future, I think also it's important that for these autonomous vehicles, they have lots of different sensors and they should be combining all these sensory readings to arrive at the decision and the interpretation of the world and so on."}, {"time": 3428, "text": "And the more of these sensory inputs they use and the better they combine the sensory inputs, the harder it is going to be attacked."}, {"time": 3436, "text": "And hence, I think that is a very important direction for us to move towards."}, {"time": 3441, "text": "So multi model, multi sensor across multiple cameras, but also in the case of car, radar, ultrasonic, sound even."}, {"time": 3450, "text": "So all of those."}, {"time": 3453, "text": "So another thing, another part of your work has been in the space of privacy."}, {"time": 3459, "text": "And that too can be seen as a kind of security vulnerability."}, {"time": 3463, "text": "So thinking of data as a thing that should be protected and the vulnerabilities to data is vulnerability is essentially the thing that you wanna protect is the privacy of that data."}, {"time": 3476, "text": "So what do you see as the main vulnerabilities in the privacy of data and how do we protect it?"}, {"time": 3482, "text": "Right, so in security we actually talk about essentially two, in this case, two different properties."}, {"time": 3490, "text": "One is integrity and one is confidentiality."}, {"time": 3493, "text": "So what we have been talking earlier is essentially the integrity of, the integrity property of the learning system."}, {"time": 3502, "text": "How to make sure that the learning system is giving the right prediction, for example."}, {"time": 3509, "text": "And privacy essentially is on the other side is about confidentiality of the system is how attackers can, when the attackers compromise the confidentiality of the system, that's when the attacker steal sensitive information, right, about individuals and so on."}, {"time": 3528, "text": "That's really clean, those are great terms."}, {"time": 3531, "text": "Integrity and confidentiality."}, {"time": 3534, "text": "So how, what are the main vulnerabilities to privacy, would you say, and how do we protect against it?"}, {"time": 3541, "text": "Like what are the main spaces and problems that you think about in the context of privacy?"}, {"time": 3547, "text": "Right, so especially in the machine learning setting."}, {"time": 3552, "text": "So in this case, as we know that how the process goes is that we have the training data and then the machine learning system trains from this training data and then builds a model and then later on inputs are given to the model to, at inference time, to try to get prediction and so on."}, {"time": 3574, "text": "So then in this case, the privacy concerns that we have is typically about privacy of the data in the training data because that's essentially the private information."}, {"time": 3585, "text": "So, and it's really important because oftentimes the training data can be very sensitive."}, {"time": 3594, "text": "It can be your financial data, it's your health data, or like in IoT case, it's the sensors deployed in real world environment and so on."}, {"time": 3604, "text": "And all this can be collecting very sensitive information."}, {"time": 3608, "text": "And all the sensitive information gets fed into the learning system and trains."}, {"time": 3613, "text": "And as we know, these neural networks, they can have really high capacity and they actually can remember a lot."}, {"time": 3623, "text": "And hence just from the learning, the learned model in the end, actually attackers can potentially infer information about the original training data sets."}, {"time": 3636, "text": "So the thing you're trying to protect that is the confidentiality of the training data."}, {"time": 3642, "text": "And so what are the methods for doing that?"}, {"time": 3644, "text": "Would you say, what are the different ways that can be done?"}, {"time": 3647, "text": "And also we can talk about essentially how the attacker may try to learn information from the..."}, {"time": 3654, "text": "So, and also there are different types of attacks."}, {"time": 3657, "text": "So in certain cases, again, like in white box attacks, we can see that the attacker actually get to see the parameters of the model."}, {"time": 3665, "text": "And then from that, a smart attacker potentially can try to figure out information about the training data set."}, {"time": 3673, "text": "They can try to figure out what type of data has been in the training data sets."}, {"time": 3678, "text": "And sometimes they can tell like, whether a person has been... A particular person's data point has been used in the training data sets as well."}, {"time": 3689, "text": "So white box, meaning you have access to the parameters of say a neural network."}, {"time": 3693, "text": "And so that you're saying that it's some..."}, {"time": 3696, "text": "Given that information is possible to some..."}, {"time": 3698, "text": "So I can give you some examples."}, {"time": 3700, "text": "And then another type of attack, which is even easier to carry out is not a white box model."}, {"time": 3706, "text": "It's more of just a query model where the attacker only gets to query the machine learning model and then try to steal sensitive information in the original training data."}, {"time": 3717, "text": "So, right, so I can give you an example."}, {"time": 3720, "text": "In this case, training a language model."}, {"time": 3723, "text": "So in our work, in collaboration with the researchers from Google, we actually studied the following question."}, {"time": 3730, "text": "So at high level, the question is, as we mentioned, the neural networks can have very high capacity and they could be remembering a lot from the training process."}, {"time": 3741, "text": "Then the question is, can attacker actually exploit this and try to actually extract sensitive information in the original training data sets through just querying the learned model without even knowing the parameters of the model, like the details of the model or the architectures of the model and so on."}, {"time": 3761, "text": "So that's a question we set out to explore."}, {"time": 3766, "text": "And in one of the case studies, we showed the following."}, {"time": 3770, "text": "So we trained a language model over an email data set."}, {"time": 3775, "text": "It's called an Enron email data set."}, {"time": 3777, "text": "And the Enron email data sets naturally contained users social security numbers and credit card numbers."}, {"time": 3785, "text": "So we trained a language model over the data sets and then we showed that an attacker by devising some new attacks by just querying the language model and without knowing the details of the model, the attacker actually can extract the original social security numbers and credit card numbers that were in the original training data sets."}, {"time": 3810, "text": "So get the most sensitive personally identifiable information from the data set from just querying it."}, {"time": 3819, "text": "So that's an example showing that's why even as we train machine learning models, we have to be really careful with protecting users data privacy."}, {"time": 3831, "text": "So what are the mechanisms for protecting?"}, {"time": 3833, "text": "Is there hopeful?"}, {"time": 3835, "text": "So there's been recent work on differential privacy, for example, that provides some hope, but can you describe some of the ideas?"}, {"time": 3844, "text": "Right, so that's actually, right."}, {"time": 3845, "text": "So that's also our finding is that by actually, we show that in this particular case, we actually have a good defense."}, {"time": 3854, "text": "For the querying case, for the language model case."}, {"time": 3857, "text": "So instead of just training a vanilla language model, instead, if we train a differentially private language model, then we can still achieve similar utility, but at the same time, we can actually significantly enhance the privacy protection of the learned model."}, {"time": 3879, "text": "And our proposed attacks actually are no longer effective."}, {"time": 3884, "text": "And differential privacy is a mechanism of adding some noise, by which you then have some guarantees on the inability to figure out the presence of a particular person in the dataset."}, {"time": 3899, "text": "So right, so in this particular case, what the differential privacy mechanism does is that it actually adds perturbation in the training process."}, {"time": 3910, "text": "As we know, during the training process, we are learning the model, we are doing gradient updates, the weight updates and so on."}, {"time": 3919, "text": "And essentially, differential privacy, a differentially private machine learning algorithm in this case, will be adding noise and adding various perturbation during this training process."}, {"time": 3933, "text": "To some aspect of the training process."}, {"time": 3935, "text": "Right, so then the finally trained learning, the learned model is differentially private, and so it can enhance the privacy protection."}, {"time": 3946, "text": "So okay, so that's the attacks and the defense of privacy."}, {"time": 3951, "text": "You also talk about ownership of data."}, {"time": 3954, "text": "So this is a really interesting idea that we get to use many services online for seemingly for free by essentially, sort of a lot of companies are funded through advertisement."}, {"time": 3966, "text": "And what that means is the advertisement works exceptionally well because the companies are able to access our personal data, so they know which advertisement to service to do targeted advertisements and so on."}, {"time": 3978, "text": "So can you maybe talk about this?"}, {"time": 3981, "text": "You have some nice paintings of the future, philosophically speaking future where people can have a little bit more control of their data by owning and maybe understanding the value of their data and being able to sort of monetize it in a more explicit way as opposed to the implicit way that it's currently done."}, {"time": 4005, "text": "Yeah, I think this is a fascinating topic and also a really complex topic."}, {"time": 4011, "text": "Right, I think there are these natural questions, who should be owning the data?"}, {"time": 4018, "text": "And so I can draw one analogy."}, {"time": 4023, "text": "So for example, for physical properties, like your house and so on."}, {"time": 4028, "text": "So really this notion of property rights it's not like from day one, we knew that there should be like this clear notion of ownership of properties and having enforcement for this."}, {"time": 4045, "text": "And so actually people have shown that this establishment and enforcement of property rights has been a main driver for the economy earlier."}, {"time": 4062, "text": "And that actually really propelled the economic growth even in the earlier stage."}, {"time": 4070, "text": "So throughout the history of the development of the United States or actually just civilization, the idea of property rights that you can own property."}, {"time": 4079, "text": "Right, and then there's enforcement."}, {"time": 4081, "text": "There's institutional rights, that governmental like enforcements of this actually has been a key driver for economic growth."}, {"time": 4092, "text": "And there had been even research or proposals saying that for a lot of the developing countries, essentially the challenge in growth is not actually due to the lack of capital."}, {"time": 4108, "text": "It's more due to the lack of this notion of property rights and the enforcement of property rights."}, {"time": 4117, "text": "Interesting, so that the presence of absence of both the concept of the property rights and their enforcement has a strong correlation to economic growth."}, {"time": 4130, "text": "And so you think that that same could be transferred to the idea of property ownership in the case of data ownership."}, {"time": 4137, "text": "I think first of all, it's a good lesson for us to recognize that these rights and the recognition and the enforcements of these type of rights is very, very important for economic growth."}, {"time": 4153, "text": "And then if we look at where we are now and where we are going in the future, so essentially more and more is actually moving into the digital world."}, {"time": 4163, "text": "And also more and more, I would say, even information or assets of a person is more and more into the real world, the physical, sorry, the digital world as well."}, {"time": 4175, "text": "It's the data that the person has generated."}, {"time": 4179, "text": "And essentially it's like in the past what defines a person, you can say, right, like oftentimes besides the innate capabilities, actually it's the physical properties."}, {"time": 4194, "text": "House, car."}, {"time": 4195, "text": "Right, that defines a person."}, {"time": 4196, "text": "But I think more and more people start to realize actually what defines a person is more important in the data that the person has generated or the data about the person."}, {"time": 4207, "text": "Like all the way from your political views, your music taste and your financial information, a lot of these and your health."}, {"time": 4216, "text": "So more and more of the definition of the person is actually in the digital world."}, {"time": 4222, "text": "And currently for the most part, that's owned implicitly."}, {"time": 4226, "text": "People don't talk about it, but kind of it's owned by internet companies."}, {"time": 4233, "text": "So it's not owned by individuals."}, {"time": 4234, "text": "Right, there's no clear notion of ownership of such data."}, {"time": 4239, "text": "And also we talk about privacy and so on, but I think actually clearly identifying the ownership is a first step."}, {"time": 4246, "text": "Once you identify the ownership, then you can say who gets to define how the data should be used."}, {"time": 4252, "text": "So maybe some users are fine with internet companies serving them as, right, using their data as long as if the data is used in a certain way that actually the user consents with or allows."}, {"time": 4271, "text": "For example, you can see the recommendation system in some sense, we don't call it as, but a recommendation system, similarly it's trying to recommend you something and users enjoy and can really benefit from good recommendation systems, either recommending you better music, movies, news, even research papers to read."}, {"time": 4292, "text": "But of course then in these targeted ads, especially in certain cases where people can be manipulated by these targeted ads that can have really bad, like severe consequences."}, {"time": 4305, "text": "So essentially users want their data to be used to better serve them and also maybe even, right, get paid for or whatever, like in different settings."}, {"time": 4316, "text": "But the thing is that first of all, we need to really establish like who needs to decide, who can decide how the data should be used."}, {"time": 4326, "text": "And typically the establishment and clarification of the ownership will help this and it's an important first step."}, {"time": 4334, "text": "So if the user is the owner, then naturally the user gets to define how the data should be used."}, {"time": 4339, "text": "But if you even say that wait a minute, users are actually now the owner of this data, whoever is collecting the data is the owner of the data."}, {"time": 4346, "text": "Now of course they get to use the data however way they want."}, {"time": 4349, "text": "So to really address these complex issues, we need to go at the root cause."}, {"time": 4355, "text": "So it seems fairly clear that so first we really need to say that who is the owner of the data and then the owners can specify how they want their data to be utilized."}, {"time": 4367, "text": "So that's a fascinating, most people don't think about that and I think that's a fascinating thing to think about and probably fight for it."}, {"time": 4377, "text": "I can only see in the economic growth argument, it's probably a really strong one."}, {"time": 4381, "text": "So that's a first time I'm kind of at least thinking about the positive aspect of that ownership being the longterm growth of the economy, so good for everybody."}, {"time": 4392, "text": "But sort of one down possible downside I could see sort of to put on my grumpy old grandpa hat and it's really nice for Facebook and YouTube and Twitter to all be free."}, {"time": 4408, "text": "And if you give control to people or their data, do you think it's possible they will be, they would not want to hand it over quite easily?"}, {"time": 4417, "text": "And so a lot of these companies that rely on mass handover of data and then therefore provide a mass seemingly free service would then completely, so the way the internet looks will completely change because of the ownership of data and we'll lose a lot of services value."}, {"time": 4443, "text": "I think that's not necessarily the case in the sense that yes, users can have ownership of their data, they can maintain control of their data, but also then they get to decide how their data can be used."}, {"time": 4457, "text": "So that's why I mentioned earlier, so in this case, if they feel that they enjoy the benefits of social networks and so on, and they're fine with having Facebook, having their data, but utilizing the data in certain way that they agree, then they can still enjoy the free services."}, {"time": 4477, "text": "But for others, maybe they would prefer some kind of private vision."}, {"time": 4481, "text": "And in that case, maybe they can even opt in to say that I want to pay and to have, so for example, it's already fairly standard, like you pay for certain subscriptions so that you don't get to be shown ads, right?"}, {"time": 4499, "text": "So then users essentially can have choices."}, {"time": 4501, "text": "And I think we just want to essentially bring out more about who gets to decide what to do with that data."}, {"time": 4510, "text": "I think it's an interesting idea, because if you poll people now, it seems like, I don't know, but subjectively, sort of anecdotally speaking, it seems like a lot of people don't trust Facebook."}, {"time": 4522, "text": "So that's at least a very popular thing to say that I don't trust Facebook, right?"}, {"time": 4526, "text": "I wonder if you give people control of their data as opposed to sort of signaling to everyone that they don't trust Facebook, I wonder how they would speak with the actual, like would they be willing to pay $10 a month for Facebook or would they hand over their data?"}, {"time": 4544, "text": "It'd be interesting to see what fraction of people would quietly hand over their data to Facebook to make it free."}, {"time": 4552, "text": "I don't have a good intuition about that."}, {"time": 4554, "text": "Like how many people, do you have an intuition about how many people would use their data effectively on the market of the internet by sort of buying services with their data?"}, {"time": 4570, "text": "Yeah, so that's a very good question."}, {"time": 4572, "text": "I think, so one thing I also want to mention is that this, right, so it seems that especially in press, the conversation has been very much like two sides fighting against each other."}, {"time": 4589, "text": "On one hand, right, users can say that, right, they don't trust Facebook, they don't, or they delete Facebook."}, {"time": 4599, "text": "Right, and then on the other hand, right, of course, right, the other side, they also feel, oh, they are providing a lot of services to users and users are getting it all for free."}, {"time": 4613, "text": "So I think I actually, I don't know, I talk a lot to like different companies and also like basically on both sides."}, {"time": 4624, "text": "So one thing I hope also like, this is my hope for this year also, is that we want to establish a more constructive dialogue and to help people to understand that the problem is much more nuanced than just this two sides fighting."}, {"time": 4645, "text": "Because naturally, there is a tension between the two sides, between utility and privacy."}, {"time": 4653, "text": "So if you want to get more utility, essentially, like the recommendation system example I gave earlier, if you want someone to give you a good recommendation, essentially, whatever that system is, the system is going to need to know your data to give you a good recommendation."}, {"time": 4672, "text": "But also, of course, at the same time, we want to ensure that however that data is being handled, it's done in a privacy preserving way."}, {"time": 4679, "text": "So that, for example, the recommendation system doesn't just go around and sell your data and then cause a lot of bad consequences and so on."}, {"time": 4692, "text": "So you want that dialogue to be a little bit more in the open, a little more nuanced, and maybe adding control to the data, ownership to the data will allow, as opposed to this happening in the background, allow to bring it to the forefront and actually have dialogues, like more nuanced, real dialogues about how we trade our data for the services."}, {"time": 4718, "text": "Right, right, yes, at the high level."}, {"time": 4721, "text": "So essentially, also knowing that there are technical challenges in addressing the issue, like basically you can't have, just like the example that I gave earlier, it's really difficult to balance the two between utility and privacy."}, {"time": 4737, "text": "And that's also a lot of things that I work on, my group works on as well, is to actually develop these technologies that are needed to essentially help this balance better, essentially to help data to be utilized in a privacy preserving way."}, {"time": 4756, "text": "And so we essentially need people to understand the challenges and also at the same time to provide the technical abilities and also regulatory frameworks to help the two sides to be more in a win win situation instead of a fight."}, {"time": 4806, "text": "Yeah, it might make mistakes, but I think it's an incredible service."}, {"time": 4810, "text": "I think it's world changing."}, {"time": 4812, "text": "I mean, I think Facebook's done a lot of incredible, incredible things by bringing, for example, identity."}, {"time": 4820, "text": "Like allowing people to be themselves, like their real selves in the digital space by using their real name and their real picture."}, {"time": 4831, "text": "That step was like the first step from the real world to the digital world."}, {"time": 4835, "text": "That was a huge step that perhaps will define the 21st century in us creating a digital identity."}, {"time": 4841, "text": "And there's a lot of interesting possibilities there that are positive."}, {"time": 4845, "text": "Of course, some things that are negative and having a good dialogue about that is great."}, {"time": 4850, "text": "And I'm great that people like you are at the center of that dialogue, so that's awesome."}, {"time": 4854, "text": "Right, I think also, I also can understand."}, {"time": 4858, "text": "I think actually in the past, especially in the past couple of years, this rising awareness has been helpful."}, {"time": 4867, "text": "Like users are also more and more recognizing that privacy is important to them."}, {"time": 4872, "text": "They should, maybe, right, they should be owners of their data."}, {"time": 4875, "text": "I think this definitely is very helpful."}, {"time": 4878, "text": "And I think also this type of voice also, and together with the regulatory framework and so on, also help the companies to essentially put these type of issues at a higher priority."}, {"time": 4893, "text": "And knowing that, right, also it is their responsibility too to ensure that users are well protected."}, {"time": 4902, "text": "So I think definitely the rising voice is super helpful."}, {"time": 4907, "text": "And I think that actually really has brought the issue of data privacy and even this consideration of data ownership to the forefront to really much wider community."}, {"time": 4920, "text": "And I think more of this voice is needed, but I think it's just that we want to have a more constructive dialogue to bring the both sides together to figure out a constructive solution."}, {"time": 4933, "text": "So another interesting space where security is really important is in the space of any kinds of transactions, but it could be also digital currency."}, {"time": 4942, "text": "So can you maybe talk a little bit about blockchain?"}, {"time": 4947, "text": "And can you tell me what is a blockchain?"}, {"time": 4950, "text": "Blockchain."}, {"time": 4952, "text": "I think the blockchain word itself is actually very overloaded."}, {"time": 4959, "text": "It's like AI."}, {"time": 4962, "text": "So in general, when we talk about blockchain, we refer to this distributor in a decentralized fashion."}, {"time": 4967, "text": "So essentially you have a community of nodes that come together."}, {"time": 4974, "text": "And even though each one may not be trusted, and as long as a certain thresholds of the set of nodes behaves properly, then the system can essentially achieve certain properties."}, {"time": 4991, "text": "For example, in the distributed ledger setting, you can maintain an immutable log and you can ensure that, for example, the transactions actually are agreed upon and then it's immutable and so on."}, {"time": 5008, "text": "So first of all, what's a ledger?"}, {"time": 5010, "text": "It's like a database."}, {"time": 5011, "text": "It's like a data entry."}, {"time": 5013, "text": "And so a distributed ledger is something that's maintained across or is synchronized across multiple sources, multiple nodes."}, {"time": 5021, "text": "Multiple nodes, yes."}, {"time": 5023, "text": "And so where is this idea?"}, {"time": 5026, "text": "How do you keep..."}, {"time": 5028, "text": "So it's important, a ledger, a database, to keep that, to make sure..."}, {"time": 5035, "text": "So what are the kinds of security vulnerabilities that you're trying to protect against in the context of a distributed ledger?"}, {"time": 5044, "text": "So in this case, for example, you don't want some malicious nodes to be able to change the transaction logs."}, {"time": 5052, "text": "And in certain cases, it's called double spending, like you can also cause different views in different parts of the network and so on."}, {"time": 5062, "text": "So the ledger has to represent, if you're capturing financial transactions, it has to represent the exact timing and the exact occurrence and no duplicates, all that kind of stuff."}, {"time": 5073, "text": "It has to represent what actually happened."}, {"time": 5077, "text": "Okay, so what are your thoughts on the security and privacy of digital currency?"}, {"time": 5083, "text": "I can't tell you how many people write to me to interview various people in the digital currency space."}, {"time": 5091, "text": "There seems to be a lot of excitement there."}, {"time": 5094, "text": "And it seems to be, some of it's, to me, from an outsider's perspective, seems like dark magic."}, {"time": 5101, "text": "I don't know how secure..."}, {"time": 5106, "text": "I think the foundation, from my perspective, of digital currencies, that is, you can't trust anyone."}, {"time": 5113, "text": "So you have to create a really secure system."}, {"time": 5116, "text": "So can you maybe speak about how, what your thoughts in general about digital currency is and how we can possibly create financial transactions and financial stores of money in the digital space?"}, {"time": 5131, "text": "So you asked about security and privacy."}, {"time": 5135, "text": "So again, as I mentioned earlier, in security, we actually talk about two main properties, the integrity and confidentiality."}, {"time": 5145, "text": "So there's another one for availability."}, {"time": 5149, "text": "You want the system to be available."}, {"time": 5150, "text": "But here, for the question you asked, let's just focus on integrity and confidentiality."}, {"time": 5157, "text": "So for integrity of this distributed ledger, essentially, as we discussed, we want to ensure that the different nodes, so they have this consistent view, usually it's done through what we call a consensus protocol, and that they establish this shared view on this ledger, and that you cannot go back and change, it's immutable, and so on."}, {"time": 5185, "text": "So in this case, then the security often refers to this integrity property."}, {"time": 5191, "text": "And essentially, you're asking the question, how much work, how can you attack the system so that the attacker can change the lock, for example?"}, {"time": 5203, "text": "Change the lock, for example."}, {"time": 5206, "text": "Right, how hard is it to make an attack like that?"}, {"time": 5209, "text": "And then that very much depends on the consensus mechanism, how the system is built, and all that."}, {"time": 5217, "text": "So there are different ways to build these decentralized systems."}, {"time": 5222, "text": "And people may have heard about the terms called like proof of work, proof of stake, these different mechanisms."}, {"time": 5229, "text": "And it really depends on how the system has been built, and also how much resources, how much work has gone into the network to actually say how secure it is."}, {"time": 5244, "text": "So for example, people talk about like, in Bitcoin, it's proof of work system, so much electricity has been burned."}, {"time": 5252, "text": "So there's differences in the different mechanisms and the implementations of a distributed ledger used for digital currency."}, {"time": 5260, "text": "So there's Bitcoin, there's whatever, there's so many of them, and there's underlying different mechanisms."}, {"time": 5266, "text": "And there's arguments, I suppose, about which is more effective, which is more secure, which is more."}, {"time": 5272, "text": "And what is needed, what amount of resources needed to be able to attack the system?"}, {"time": 5280, "text": "Like for example, what percentage of the nodes do you need to control or compromise in order to, right, to change the log?"}, {"time": 5289, "text": "And those are things, do you have a sense if those are things that can be shown theoretically through the design of the mechanisms, or does it have to be shown empirically by having a large number of users using the currency?"}, {"time": 5304, "text": "So in general, for each consensus mechanism, you can actually show theoretically what is needed to be able to attack the system."}, {"time": 5314, "text": "Of course, there can be different types of attacks as we discussed at the beginning."}, {"time": 5321, "text": "And so that it's difficult to give like, you know, complete estimates, like really how much is needed to compromise the system."}, {"time": 5335, "text": "But in general, right, so there are ways to say what percentage of the nodes you need to compromise and so on."}, {"time": 5343, "text": "So we talked about integrity on the security side, and then you also mentioned the privacy or the confidentiality side."}, {"time": 5353, "text": "Does it have some of the same problems and therefore some of the same solutions that you talked about on the machine learning side with differential privacy and so on?"}, {"time": 5364, "text": "Yeah, so actually in general on the public ledger in these public decentralized systems, actually nothing is private."}, {"time": 5374, "text": "So all the transactions posted on the ledger, anybody can see."}, {"time": 5380, "text": "So in that sense, there's no confidentiality."}, {"time": 5383, "text": "So usually what you can do is then there are the mechanisms that you can build in to enable confidentiality or privacy of the transactions and the data and so on."}, {"time": 5396, "text": "That's also some of the work that both my group and also my startup does as well."}, {"time": 5404, "text": "What's the name of the startup?"}, {"time": 5407, "text": "And so the confidentiality aspect there is even though the transactions are public, you wanna keep some aspect confidential of the identity of the people involved in the transactions?"}, {"time": 5421, "text": "Or what is their hope to keep confidential in this context?"}, {"time": 5425, "text": "So in this case, for example, you want to enable like confidential transactions, even, so there are different essentially types of data that you want to keep private or confidential."}, {"time": 5440, "text": "And you can utilize different technologies including zero knowledge proofs and also secure computing and techniques and to hide who is making the transactions to whom and the transaction amount."}, {"time": 5458, "text": "And in our case, also we can enable like confidential smart contracts."}, {"time": 5462, "text": "And so that you don't know the data and the execution of the smart contract and so on."}, {"time": 5469, "text": "And we actually are combining these different technologies and going back to the earlier discussion we had, enabling like ownership of data and privacy of data and so on."}, {"time": 5519, "text": "So all this together can build, we call a distributed secure computing fabric that helps to enable a more responsible data economy."}, {"time": 5530, "text": "So it's a lot of things together."}, {"time": 5531, "text": "Yeah, wow, that was eloquent."}, {"time": 5533, "text": "Okay, you're involved in so much amazing work that we'll never be able to get to, but I have to ask at least briefly about program synthesis, which at least in a philosophical sense captures much of the dreams of what's possible in computer science and the artificial intelligence."}, {"time": 5553, "text": "First, let me ask, what is program synthesis and can neural networks be used to learn programs from data?"}, {"time": 5561, "text": "So can this be learned?"}, {"time": 5563, "text": "Some aspect of the synthesis can it be learned?"}, {"time": 5566, "text": "So program synthesis is about teaching computers to write code, to program."}, {"time": 5572, "text": "And I think that's one of our ultimate dreams or goals."}, {"time": 5580, "text": "I think Andreessen talked about software eating the world."}, {"time": 5585, "text": "So I say, once we teach computers to write the software, how to write programs, then I guess computers will be eating the world by transitivity."}, {"time": 5597, "text": "So yeah, and also for me actually, when I shifted from security to more AI machine learning, program synthesis is, program synthesis and adversarial machine learning, these are the two fields that I particularly focus on."}, {"time": 5618, "text": "Like program synthesis is one of the first questions that I actually started investigating."}, {"time": 5622, "text": "Just as a question, oh, I guess from the security side, there's a, you're looking for holes in programs, so at least see small connection, but where was your interest for program synthesis?"}, {"time": 5636, "text": "Because it's such a fascinating, such a big, such a hard problem in the general case."}, {"time": 5641, "text": "Why program synthesis?"}, {"time": 5643, "text": "So the reason for that is actually when I shifted my focus from security into AI machine learning, actually one of my main motivation at the time is that even though I have been doing a lot of work in security and privacy, but I have always been fascinated about building intelligent machines."}, {"time": 5666, "text": "And that was really my main motivation to spend more time in AI machine learning is that I really want to figure out how we can build intelligent machines."}, {"time": 5677, "text": "And to help us towards that goal, program synthesis is really one of, I would say the best domain to work on."}, {"time": 5689, "text": "I actually call it like program synthesis is like the perfect playground for building intelligent machines and for artificial general intelligence."}, {"time": 5699, "text": "Yeah, well, it's also in that sense, not just a playground, I guess it's the ultimate test of intelligence because I think if you can generate sort of neural networks can learn good functions and they can help you out in classification tasks, but to be able to write programs, that's the epitome from the machine side."}, {"time": 5724, "text": "That's the same as passing the Turing test in natural language, but with programs, it's able to express complicated ideas to reason through ideas and boil them down to algorithms."}, {"time": 5738, "text": "Yes, exactly, exactly."}, {"time": 5739, "text": "Incredible, so can this be learned?"}, {"time": 5741, "text": "How far are we?"}, {"time": 5743, "text": "Is there hope?"}, {"time": 5744, "text": "What are the open challenges?"}, {"time": 5746, "text": "Yeah, very good questions."}, {"time": 5748, "text": "We are still at an early stage, but already I think we have seen a lot of progress."}, {"time": 5756, "text": "I mean, definitely we have existence proof, just like humans can write programs."}, {"time": 5762, "text": "So there's no reason why computers cannot write programs."}, {"time": 5765, "text": "So I think that's definitely an achievable goal is just how long it takes."}, {"time": 5771, "text": "And even today, we actually have, the program synthesis community, especially the program synthesis via learning, how we call it, neuro program synthesis community, is still very small, but the community has been growing and we have seen a lot of progress."}, {"time": 5791, "text": "And in limited domains, I think actually program synthesis is ripe for real world applications."}, {"time": 5801, "text": "So actually it was quite amazing."}, {"time": 5802, "text": "I was giving a talk, so here is a rework conference."}, {"time": 5809, "text": "Rework Deep Learning Summit."}, {"time": 5810, "text": "I actually, so I gave another talk at the previous rework conference in deep reinforcement learning."}, {"time": 5816, "text": "And then I actually met someone from a startup, the CEO of the startup."}, {"time": 5824, "text": "And then when he saw my name, he recognized it."}, {"time": 5826, "text": "And he actually said, one of our papers actually had, they had actually become a key products in their startup."}, {"time": 5837, "text": "And that was program synthesis, in that particular case, it was natural language translation, translating natural language description into SQL queries."}, {"time": 5851, "text": "Oh, wow, that direction, okay."}, {"time": 5854, "text": "Right, so yeah, so in program synthesis, in limited domains, in well specified domains, actually already we can see really, really great progress and applicability in the real world."}, {"time": 5872, "text": "So domains like, I mean, as an example, you said natural language, being able to express something through just normal language and it converts it into a database SQL query."}, {"time": 5883, "text": "And that's how solved of a problem is that?"}, {"time": 5887, "text": "Because that seems like a really hard problem."}, {"time": 5890, "text": "Again, in limited domains, actually it can work pretty well."}, {"time": 5894, "text": "And now this is also a very active domain of research."}, {"time": 5898, "text": "At the time, I think when he saw our paper at the time, we were the state of the arts on that task."}, {"time": 5905, "text": "And since then, actually now there has been more work and with even more like sophisticated data sets."}, {"time": 5914, "text": "And so, but I think I wouldn't be surprised that more of this type of technology really gets into the real world."}, {"time": 5924, "text": "In the near term."}, {"time": 5925, "text": "Being able to learn in the space of programs is super exciting."}, {"time": 5929, "text": "I still, yeah, I'm still skeptical cause I think it's a really hard problem, but I would love to see progress."}, {"time": 5936, "text": "And also I think in terms of the, you asked about open challenges."}, {"time": 5940, "text": "I think the domain is full of challenges and in particular also we want to see how we should measure the progress in the space."}, {"time": 5949, "text": "And I would say mainly three main, I would say, metrics."}, {"time": 5956, "text": "So one is the complexity of the program that we can synthesize."}, {"time": 5960, "text": "And that will actually have clear measures and just look at the past publications."}, {"time": 5965, "text": "And even like, for example, I was at the recent NeurIPS conference."}, {"time": 5970, "text": "Now there's actually fairly sizable like session dedicated to program synthesis, which is... Or even Neural programs."}, {"time": 5977, "text": "Right, right, right, which is great."}, {"time": 5978, "text": "And we continue to see the increase."}, {"time": 5983, "text": "What does sizable mean?"}, {"time": 5984, "text": "I like the word sizable, it's five people."}, {"time": 5991, "text": "It's still a small community, but it is growing."}, {"time": 5994, "text": "And they will all win Turing Awards one day, I like it."}, {"time": 5998, "text": "Right, so we can clearly see an increase in the complexity of the programs that these... We can synthesize."}, {"time": 6009, "text": "Sorry, is it the complexity of the actual text of the program or the running time complexity?"}, {"time": 6015, "text": "Which complexity are we... How..."}, {"time": 6018, "text": "The complexity of the task to be synthesized and the complexity of the actual synthesized programs."}, {"time": 6024, "text": "So the lines of code even, for example."}, {"time": 6027, "text": "Okay, I got you."}, {"time": 6028, "text": "But it's not the theoretical upper bound of the running time of the algorithm kind of thing."}, {"time": 6035, "text": "Okay, got it."}, {"time": 6036, "text": "And you can see the complexity decreasing already."}, {"time": 6039, "text": "Oh, no, meaning we want to be able to synthesize more and more complex programs, bigger and bigger programs."}, {"time": 6044, "text": "So we want to see that, we want to increase the complexity of this."}, {"time": 6050, "text": "I got you, so I have to think through, because I thought of complexity as, you want to be able to accomplish the same task with a simpler and simpler program."}, {"time": 6056, "text": "I see, I see."}, {"time": 6057, "text": "No, we are not doing that."}, {"time": 6058, "text": "It's more about how complex a task we can synthesize programs for."}, {"time": 6063, "text": "Yeah, got it, being able to synthesize programs, learn them for more and more difficult tasks."}, {"time": 6070, "text": "So for example, initially, our first work in program synthesis was to translate natural language description into really simple programs called if TTT, if this, then that."}, {"time": 6081, "text": "So given a trigger condition, what is the action you should take?"}, {"time": 6085, "text": "So that program is super simple."}, {"time": 6088, "text": "You just identify the trigger conditions and the action."}, {"time": 6091, "text": "And then later on, with SQL queries, it gets more complex."}, {"time": 6094, "text": "And then also, we started to synthesize programs with loops and, you know."}, {"time": 6100, "text": "Oh no, and if you could synthesize recursion, it's all over."}, {"time": 6105, "text": "Right, actually, one of our works actually is on learning recursive neural programs."}, {"time": 6111, "text": "But anyway, anyway, so that's one is complexity, and the other one is generalization."}, {"time": 6118, "text": "Like when we train or learn a program synthesizer, in this case, a neural programs to synthesize programs, then you want it to generalize."}, {"time": 6130, "text": "For a large number of inputs."}, {"time": 6133, "text": "Right, so to be able to generalize to previously unseen inputs."}, {"time": 6139, "text": "And so, right, so some of the work we did earlier on learning recursive neural programs actually showed that recursion actually is important to learn."}, {"time": 6152, "text": "And if you have recursion, then for a certain set of tasks, we can actually show that you can actually have perfect generalization."}, {"time": 6162, "text": "So, right, so that won the best paperwork awards at ICLR earlier."}, {"time": 6166, "text": "So that's one example of we want to learn these neural programs that can generalize better."}, {"time": 6173, "text": "But that works for certain tasks, certain domains, and there's question how we can essentially develop more techniques that can have generalization for a wider set of domains and so on."}, {"time": 6190, "text": "So that's another area."}, {"time": 6191, "text": "And then the third challenge I think will, it's not just for programming synthesis, it's also cutting across other fields in machine learning and also including like deep reinforcement learning in particular, is that this adaptation is that we want to be able to learn from the past and tasks and training and so on to be able to solve new tasks."}, {"time": 6222, "text": "So for example, in program synthesis today, we still are working in the setting where given a particular task, we train the model and to solve this particular task."}, {"time": 6237, "text": "But that's not how humans work."}, {"time": 6240, "text": "The whole point is we train a human, then you can then program to solve new tasks."}, {"time": 6248, "text": "And just like in deep reinforcement learning, we don't want to just train agent to play a particular game, either it's Atari or it's Go or whatever."}, {"time": 6259, "text": "We want to train these agents that can essentially extract knowledge from the past learning experience to be able to adapt to new tasks and solve new tasks."}, {"time": 6271, "text": "And I think this is particularly important for program synthesis."}, {"time": 6274, "text": "Yeah, that's the whole dream of program synthesis is you're learning a tool that can solve new problems."}, {"time": 6282, "text": "And I think that's a particular domain that as a community, we need to put more emphasis on."}, {"time": 6290, "text": "And I hope that we can make more progress there as well."}, {"time": 6295, "text": "There's a lot more to talk about."}, {"time": 6297, "text": "Let me ask that you also had a very interesting and we talked about rich representations."}, {"time": 6304, "text": "You had a rich life journey."}, {"time": 6308, "text": "You did your bachelor's in China and your master's and PhD in the United States, CMU in Berkeley."}, {"time": 6315, "text": "Are there interesting differences?"}, {"time": 6316, "text": "I told you I'm Russian."}, {"time": 6317, "text": "I think there's a lot of interesting difference between Russia and the United States."}, {"time": 6321, "text": "Are there in your eyes, interesting differences between the two cultures from the silly romantic notion of the spirit of the people to the more practical notion of how research is conducted that you find interesting or useful in your own work of having experienced both?"}, {"time": 6343, "text": "I think, so I studied in China for my undergraduates and that was more than 20 years ago."}, {"time": 6354, "text": "So it's been a long time."}, {"time": 6357, "text": "Is there echoes of that time in you?"}, {"time": 6359, "text": "Things have changed a lot."}, {"time": 6360, "text": "Actually, it's interesting."}, {"time": 6361, "text": "I think even more so maybe something that's even be more different for my experience than a lot of computer science researchers and practitioners is that, so for my undergrad, I actually studied physics."}, {"time": 6376, "text": "Nice, very nice."}, {"time": 6378, "text": "And then I switched to computer science in graduate school."}, {"time": 6386, "text": "Is there another possible universe where you could have become a theoretical physicist at Caltech or something like that?"}, {"time": 6394, "text": "That's very possible, some of my undergrad classmates, then they later on studied physics, got their PhD in physics from these schools, from top physics programs."}, {"time": 6409, "text": "So you switched to, I mean, from that experience of doing physics in your bachelor's, what made you decide to switch to computer science and computer science at arguably the best university, one of the best universities in the world for computer science with Carnegie Mellon, especially for grad school and so on."}, {"time": 6429, "text": "So what, second only to MIT, just kidding."}, {"time": 6433, "text": "Okay, I had to throw that in there."}, {"time": 6437, "text": "No, what was the choice like and what was the move to the United States like?"}, {"time": 6442, "text": "What was that whole transition?"}, {"time": 6444, "text": "And if you remember, if there's still echoes of some of the spirit of the people of China in you in New York."}, {"time": 6451, "text": "Right, right, yeah."}, {"time": 6452, "text": "It's like three questions in one."}, {"time": 6453, "text": "Yes, I know."}, {"time": 6456, "text": "No, that's okay."}, {"time": 6458, "text": "So yes, so I guess, okay, so first transition from physics to computer science."}, {"time": 6463, "text": "So when I first came to the United States, I was actually in the physics PhD program at Cornell."}, {"time": 6469, "text": "I was there for one year and then I switched to computer science and then I was in the PhD program at Carnegie Mellon."}, {"time": 6476, "text": "So, okay, so the reasons for switching."}, {"time": 6479, "text": "So one thing, so that's why I also mentioned about this difference in backgrounds about having studied physics first in my undergrad."}, {"time": 6489, "text": "I actually really, I really did enjoy my undergrad's time and education in physics."}, {"time": 6498, "text": "I think that actually really helped me in my future work in computer science."}, {"time": 6505, "text": "Actually, even for machine learning, a lot of the machine learning stuff, the core machine learning methods, many of them actually came from physics."}, {"time": 6511, "text": "Statistical."}, {"time": 6514, "text": "For honest, most of everything came from physics."}, {"time": 6519, "text": "Right, but anyway, so when I studied physics, I was, I think I was really attracted to physics."}, {"time": 6529, "text": "It was, it's really beautiful."}, {"time": 6531, "text": "And I actually call it, physics is the language of nature."}, {"time": 6535, "text": "And I actually clearly remember, like, one moment in my undergrads, like I did my undergrad in Tsinghua and I used to study in the library."}, {"time": 6550, "text": "And I clearly remember, like, one day I was sitting in the library and I was, like, writing on my notes and so on."}, {"time": 6561, "text": "And I got so excited that I realized that really just from a few simple axioms, a few simple laws, I can derive so much."}, {"time": 6571, "text": "It's almost like I can derive the rest of the world."}, {"time": 6574, "text": "Yeah, the rest of the universe."}, {"time": 6575, "text": "Yes, yes, so that was, like, amazing."}, {"time": 6579, "text": "Do you think you, have you ever seen or do you think you can rediscover that kind of power and beauty in computer science in the world that you..."}, {"time": 6586, "text": "So, that's very interesting."}, {"time": 6589, "text": "So that gets to, you know, the transition from physics to computer science."}, {"time": 6593, "text": "It's quite different."}, {"time": 6595, "text": "For physics in grad school, actually, things changed."}, {"time": 6601, "text": "So one is I started to realize that when I started doing research in physics, at the time I was doing theoretical physics."}, {"time": 6611, "text": "And a lot of it, you still have the beauty, but it's very different."}, {"time": 6616, "text": "So I had to actually do a lot of the simulation."}, {"time": 6618, "text": "So essentially I was actually writing, in some cases writing fortune code."}, {"time": 6623, "text": "Good old fortune, yeah."}, {"time": 6626, "text": "To actually, right, do simulations and so on."}, {"time": 6632, "text": "That was not exactly what I enjoyed doing."}, {"time": 6642, "text": "And also at the time from talking with the senior students, senior students in the program, I realized many of the students actually were going off to like Wall Street and so on."}, {"time": 6658, "text": "So, and I've always been interested in computer science and actually essentially taught myself the C programming."}, {"time": 6667, "text": "Program?"}, {"time": 6668, "text": "Right, and so on."}, {"time": 6669, "text": "At which, when?"}, {"time": 6672, "text": "In college somewhere?"}, {"time": 6672, "text": "In the summer."}, {"time": 6674, "text": "For fun, physics major, learning to do C programming."}, {"time": 6680, "text": "Actually it's interesting, in physics at the time, I think now the program probably has changed, but at the time really the only class we had in related to computer science education was introduction to, I forgot, to computer science or computing and Fortran 77."}, {"time": 6700, "text": "There's a lot of people that still use Fortran."}, {"time": 6702, "text": "I'm actually, if you're a programmer out there, I'm looking for an expert to talk to about Fortran."}, {"time": 6709, "text": "They seem to, there's not many, but there's still a lot of people that still use Fortran and still a lot of people that use Cobalt."}, {"time": 6716, "text": "But anyway, so then I realized, instead of just doing programming for doing simulations and so on, that I may as well just change to computer science."}, {"time": 6727, "text": "And also one thing I really liked, and that's a key difference between the two, is in computer science it's so much easier to realize your ideas."}, {"time": 6735, "text": "If you have an idea, you write it up, you code it up, and then you can see it actually, right?"}, {"time": 6743, "text": "Running and you can see it."}, {"time": 6746, "text": "You can bring it to life quickly."}, {"time": 6746, "text": "Bring it to life."}, {"time": 6747, "text": "Whereas in physics, if you have a good theory, you have to wait for the experimentalists to do the experiments and to confirm the theory, and things just take so much longer."}, {"time": 6758, "text": "And also the reason in physics I decided to do theoretical physics was because I had my experience with experimental physics."}, {"time": 6767, "text": "First, you have to fix the equipment."}, {"time": 6770, "text": "You spend most of your time fixing the equipment first."}, {"time": 6775, "text": "Super expensive equipment, so there's a lot of, yeah, you have to collaborate with a lot of people."}, {"time": 6780, "text": "Takes a long time."}, {"time": 6781, "text": "Just takes really, right, much longer."}, {"time": 6783, "text": "Yeah, it's messy."}, {"time": 6784, "text": "Right, so I decided to switch to computer science."}, {"time": 6786, "text": "And one thing I think maybe people have realized is that for people who study physics, actually it's very easy for physicists to change to do something else."}, {"time": 6796, "text": "I think physics provides a really good training."}, {"time": 6799, "text": "And yeah, so actually it was fairly easy to switch to computer science."}, {"time": 6806, "text": "But one thing, going back to your earlier question, so one thing I actually did realize, so there is a big difference between computer science and physics, where physics you can derive the whole universe from just a few simple laws."}, {"time": 6821, "text": "And computer science, given that a lot of it is defined by humans, the systems are defined by humans, and it's artificial, like essentially you create a lot of these artifacts and so on."}, {"time": 6837, "text": "It's not quite the same."}, {"time": 6838, "text": "You don't derive the computer systems with just a few simple laws."}, {"time": 6843, "text": "You actually have to see there is historical reasons why a system is built and designed one way versus the other."}, {"time": 6852, "text": "There's a lot more complexity, less elegant simplicity of E equals MC squared that kind of reduces everything down to those beautiful fundamental equations."}, {"time": 6863, "text": "But what about the move from China to the United States?"}, {"time": 6867, "text": "Is there anything that still stays in you that contributes to your work, the fact that you grew up in another culture?"}, {"time": 6876, "text": "So yes, I think especially back then it's very different from now."}, {"time": 6880, "text": "So now they actually, I see these students coming from China, and even undergrads, actually they speak fluent English."}, {"time": 6891, "text": "It was just amazing."}, {"time": 6894, "text": "And they have already understood so much of the culture in the US and so on."}, {"time": 6900, "text": "It was to you, it was all foreign?"}, {"time": 6904, "text": "It was a very different time."}, {"time": 6906, "text": "At the time, actually, we didn't even have easy access to email, not to mention about the web."}, {"time": 6916, "text": "I remember I had to go to specific privileged server rooms to use email, and hence, at the time, at the time we had much less knowledge about the Western world."}, {"time": 6932, "text": "And actually at the time I didn't know, actually in the US, the West Coast weather is much better than the East Coast."}, {"time": 6940, "text": "Yeah, things like that, actually."}, {"time": 6948, "text": "But now it's so different."}, {"time": 6950, "text": "At the time, I would say there's also a bigger cultural difference, because there was so much less opportunity for shared information."}, {"time": 6959, "text": "So it's such a different time and world."}, {"time": 6962, "text": "So let me ask maybe a sensitive question."}, {"time": 6964, "text": "I'm not sure, but I think you and I are in similar positions."}, {"time": 6968, "text": "I've been here for already 20 years as well, and looking at Russia from my perspective, and you looking at China."}, {"time": 6976, "text": "In some ways, it's a very distant place, because it's changed a lot."}, {"time": 6981, "text": "But in some ways you still have echoes, you still have knowledge of that place."}, {"time": 6985, "text": "The question is, China's doing a lot of incredible work in AI."}, {"time": 6989, "text": "Do you see, please tell me there's an optimistic picture you see where the United States and China can collaborate and sort of grow together in the development of AI towards, there's different values in terms of the role of government and so on, of ethical, transparent, secure systems."}, {"time": 7008, "text": "We see it differently in the United States a little bit than China, but we're still trying to work it out."}, {"time": 7013, "text": "Do you see the two countries being able to successfully collaborate and work in a healthy way without sort of fighting and making it an AI arms race kind of situation?"}, {"time": 7026, "text": "Yeah, I believe so."}, {"time": 7028, "text": "I think science has no border, and the advancement of the technology helps everyone, helps the whole world."}, {"time": 7038, "text": "And so I certainly hope that the two countries will collaborate, and I certainly believe so."}, {"time": 7046, "text": "Do you have any reason to believe so except being an optimist?"}, {"time": 7052, "text": "So first, again, like I said, science has no borders."}, {"time": 7055, "text": "And especially in... Science doesn't know borders?"}, {"time": 7059, "text": "And you believe that will, in the former Soviet Union during the Cold War..."}, {"time": 7064, "text": "So that's, yeah."}, {"time": 7065, "text": "So that's the other point I was going to mention is that especially in academic research, everything is public."}, {"time": 7072, "text": "Like we write papers, we open source codes, and all this is in the public domain."}, {"time": 7079, "text": "It doesn't matter whether the person is in the US, in China, or some other parts of the world."}, {"time": 7084, "text": "They can go on archive and look at the latest research and results."}, {"time": 7089, "text": "So that openness gives you hope."}, {"time": 7092, "text": "And that's also how, as a world, we make progress the best."}, {"time": 7097, "text": "So, I apologize for the romanticized question, but looking back, what would you say was the most transformative moment in your life that maybe made you fall in love with computer science?"}, {"time": 7112, "text": "You said physics."}, {"time": 7113, "text": "You remember there was a moment where you thought you could derive the entirety of the universe."}, {"time": 7118, "text": "Was there a moment that you really fell in love with the work you do now, from security to machine learning, to program synthesis?"}, {"time": 7127, "text": "So maybe, as I mentioned, actually, in college, one summer I just taught myself programming in C. Yes."}, {"time": 7136, "text": "And you just read a book, and then you're like... Don't tell me you fell in love with computer science by programming in C. Remember I mentioned one of the draws for me to computer science is how easy it is to realize your ideas."}, {"time": 7150, "text": "So once I read a book, I taught myself how to program in C. Immediately, what did I do?"}, {"time": 7159, "text": "I programmed two games."}, {"time": 7162, "text": "One's just simple, like it's a Go game, like it's a board, you can move the stones and so on."}, {"time": 7168, "text": "And the other one, I actually programmed a game that's like a 3D Tetris."}, {"time": 7172, "text": "It turned out to be a super hard game to play."}, {"time": 7175, "text": "Because instead of just the standard 2D Tetris, it's actually a 3D thing."}, {"time": 7180, "text": "But I realized, wow, I just had these ideas to try it out, and then, yeah, you can just do it."}, {"time": 7188, "text": "And so that's when I realized, wow, this is amazing."}, {"time": 7193, "text": "Yeah, you can create yourself."}, {"time": 7195, "text": "Yes, yes, exactly."}, {"time": 7197, "text": "From nothing to something that's actually out in the real world."}, {"time": 7201, "text": "So let me ask..."}, {"time": 7202, "text": "Right, I think with your own hands."}, {"time": 7203, "text": "Let me ask a silly question, or maybe the ultimate question."}, {"time": 7207, "text": "What is to you the meaning of life?"}, {"time": 7211, "text": "What gives your life meaning, purpose, fulfillment, happiness, joy?"}, {"time": 7219, "text": "Okay, these are two different questions."}, {"time": 7221, "text": "Very different, yeah."}, {"time": 7222, "text": "It's usually that you ask this question."}, {"time": 7224, "text": "Maybe this question is probably the question that has followed me and followed my life the most."}, {"time": 7232, "text": "Have you discovered anything, any satisfactory answer for yourself?"}, {"time": 7238, "text": "Is there something you've arrived at?"}, {"time": 7241, "text": "You know, there's a moment..."}, {"time": 7244, "text": "I've talked to a few people who have faced, for example, a cancer diagnosis, or faced their own mortality, and that seems to change their view of them."}, {"time": 7253, "text": "It seems to be a catalyst for them removing most of the crap."}, {"time": 7259, "text": "Of seeing that most of what they've been doing is not that important, and really reducing it into saying, like, here's actually the few things that really give meaning."}, {"time": 7271, "text": "Mortality is a really powerful catalyst for that, it seems like."}, {"time": 7275, "text": "Facing mortality, whether it's your parents dying or somebody close to you dying, or facing your own death for whatever reason, or cancer and so on."}, {"time": 7283, "text": "So yeah, so in my own case, I didn't need to face mortality, too."}, {"time": 7288, "text": "So try to ask that question."}, {"time": 7295, "text": "And I think there are a couple things."}, {"time": 7298, "text": "So one is, like, who should be defining the meaning of your life, right?"}, {"time": 7304, "text": "Is there some kind of even greater things than you who should define the meaning of your life?"}, {"time": 7311, "text": "So for example, when people say that searching the meaning for your life, is there some outside voice, or is there something outside of you who actually tells you, you know..."}, {"time": 7326, "text": "So people talk about, oh, you know, this is what you have been born to do, right?"}, {"time": 7334, "text": "Like, this is your destiny."}, {"time": 7339, "text": "So who, right, so that's one question, like, who gets to define the meaning of your life?"}, {"time": 7344, "text": "Should you be finding some other things, some other factor to define this for you?"}, {"time": 7350, "text": "Or is something actually, it's just entirely what you define yourself, and it can be very arbitrary."}, {"time": 7357, "text": "Yeah, so an inner voice or an outer voice, whether it could be spiritual or religious, too, with God, or some other components of the environment outside of you, or just your own voice."}, {"time": 7370, "text": "Do you have an answer there?"}, {"time": 7372, "text": "So, okay, so for that, I have an answer."}, {"time": 7375, "text": "And through, you know, the long period of time of thinking and searching, even searching through outsides, right, you know, voices or factors outside of me."}, {"time": 7388, "text": "So that, I have an answer."}, {"time": 7389, "text": "I've come to the conclusion and realization that it's you yourself that defines the meaning of life."}, {"time": 7398, "text": "Yeah, that's a big burden, though, isn't it?"}, {"time": 7400, "text": "I mean, yes and no, right?"}, {"time": 7406, "text": "So then you have the freedom to define it."}, {"time": 7409, "text": "And another question is, like, what does it really mean by the meaning of life?"}, {"time": 7419, "text": "And also, whether the question even makes sense."}, {"time": 7425, "text": "Absolutely, and you said it somehow distinct from happiness."}, {"time": 7429, "text": "So meaning is something much deeper than just any kind of emotional, any kind of contentment or joy or whatever."}, {"time": 7437, "text": "It might be much deeper."}, {"time": 7438, "text": "And then you have to ask, what is deeper than that?"}, {"time": 7442, "text": "What is there at all?"}, {"time": 7444, "text": "And then the question starts being silly."}, {"time": 7447, "text": "Right, and also you can say it's deeper, but you can also say it's shallower, depending on how people want to define the meaning of their life."}, {"time": 7454, "text": "So for example, most people don't even think about this question."}, {"time": 7457, "text": "Then the meaning of life to them doesn't really matter that much."}, {"time": 7462, "text": "And also, whether knowing the meaning of life, whether it actually helps your life to be better or whether it helps your life to be happier, these actually are open questions."}, {"time": 7474, "text": "It's not, right?"}, {"time": 7476, "text": "Of course, most questions are open."}, {"time": 7477, "text": "I tend to think that just asking the question, as you mentioned, as you've done for a long time, is the only, that there is no answer."}, {"time": 7484, "text": "And asking the question is a really good exercise."}, {"time": 7487, "text": "I mean, I have this, for me personally, I've had a kind of feeling that creation is, like for me has been very fulfilling."}, {"time": 7498, "text": "And it seems like my meaning has been to create."}, {"time": 7500, "text": "And I'm not sure what that is."}, {"time": 7502, "text": "Like I don't have, I'm single and I don't have kids."}, {"time": 7505, "text": "I'd love to have kids, but I also, sounds creepy, but I also see sort of, you said see programs."}, {"time": 7513, "text": "I see programs as little creations."}, {"time": 7515, "text": "I see robots as little creations."}, {"time": 7519, "text": "I think those bring, and then ideas, theorems are creations."}, {"time": 7525, "text": "And those somehow intrinsically, like you said, bring me joy."}, {"time": 7529, "text": "I think they do to a lot of, at least scientists, but I think they do to a lot of people."}, {"time": 7534, "text": "So that, to me, if I had to force the answer to that, I would say creating new things yourself."}, {"time": 7543, "text": "For you."}, {"time": 7544, "text": "For me, for me, for me."}, {"time": 7545, "text": "I don't know, but like you said, it keeps changing."}, {"time": 7548, "text": "Is there some answer that?"}, {"time": 7549, "text": "And some people, they can, I think, they may say it's experience, right?"}, {"time": 7554, "text": "Like their meaning of life, they just want to experience to the richest and fullest they can."}, {"time": 7559, "text": "And a lot of people do take that path."}, {"time": 7562, "text": "Yes, seeing life as actually a collection of moments and then trying to make the richest possible sets, fill those moments with the richest possible experiences."}, {"time": 7574, "text": "And for me, I think it's certainly, we do share a lot of similarity here."}, {"time": 7578, "text": "So creation is also really important for me, even from the things I've already talked about, even like writing papers, and these are all creations as well."}, {"time": 7590, "text": "And I have not quite thought whether that is really the meaning of my life."}, {"time": 7594, "text": "Like in a sense, also then maybe like, what kind of things should you create?"}, {"time": 7598, "text": "There are so many different things that you could create."}, {"time": 7602, "text": "And also you can say, another view is maybe growth."}, {"time": 7606, "text": "It's related, but different from experience."}, {"time": 7610, "text": "Growth is also maybe type of meaning of life."}, {"time": 7613, "text": "It's just, you try to grow every day, try to be a better self every day."}, {"time": 7619, "text": "And also ultimately, we are here, it's part of the overall evolution."}, {"time": 7629, "text": "Right, the world is evolving and it's growing."}, {"time": 7631, "text": "Isn't it funny that the growth seems to be the more important thing than the thing you're growing towards."}, {"time": 7638, "text": "It's like, it's not the goal, it's the journey to it."}, {"time": 7641, "text": "It's almost when you submit a paper, there's a sort of depressing element to it, not to submit a paper, but when that whole project is over."}, {"time": 7652, "text": "I mean, there's the gratitude, there's the celebration and so on, but you're usually immediately looking for the next thing or the next step, right?"}]}, {"title": "Matt Botvinick: Neuroscience, Psychology, and AI at DeepMind | Lex Fridman Podcast #106", "id": "3t06ajvBtl0", "quotes": [{"time": 280, "text": "And at the other end of the spectrum, in the last few years, incredible progress has been made in terms of technologies that allow us to see, actually literally see, in some cases, what's going on at the single unit level, even the dendritic level."}, {"time": 302, "text": "And then there's this yawning gap in between."}, {"time": 305, "text": "Well, that's interesting."}, {"time": 306, "text": "So at the high level, so that's almost a cognitive science level."}, {"time": 309, "text": "And then at the neuronal level, that's neurobiology and neuroscience, just studying single neurons, the synaptic connections and all the dopamine, all the kind of neurotransmitters."}, {"time": 321, "text": "One blanket statement I should probably make is that as I've gotten older, I have become more and more reluctant to make a distinction between psychology and neuroscience."}, {"time": 333, "text": "To me, the point of neuroscience is to study what the brain is for."}, {"time": 341, "text": "If you're a nephrologist and you wanna learn about the kidney, you start by saying, what is this thing for?"}, {"time": 350, "text": "Well, it seems to be for taking blood on one side that has metabolites in it that shouldn't be there, sucking them out of the blood while leaving the good stuff behind, and then excreting that in the form of urine."}, {"time": 367, "text": "That's what the kidney is for."}, {"time": 368, "text": "It's like obvious."}, {"time": 370, "text": "So the rest of the work is deciding how it does that."}, {"time": 373, "text": "And this, it seems to me, is the right approach to take to the brain."}, {"time": 377, "text": "You say, well, what is the brain for?"}, {"time": 379, "text": "The brain, as far as I can tell, is for producing behavior."}, {"time": 382, "text": "It's for going from perceptual inputs to behavioral outputs, and the behavioral outputs should be adaptive."}, {"time": 391, "text": "So that's what psychology is about."}, {"time": 393, "text": "It's about understanding the structure of that function."}, {"time": 395, "text": "And then the rest of neuroscience is about figuring out how those operations are actually carried out at a mechanistic level."}, {"time": 404, "text": "That's really interesting, but so unlike the kidney, the brain, the gap between the electrical signal and behavior, so you truly see neuroscience as the science that touches behavior, how the brain generates behavior, or how the brain converts raw visual information into understanding."}, {"time": 428, "text": "Like, you basically see cognitive science, psychology, and neuroscience as all one science."}, {"time": 435, "text": "Yeah, it's a personal statement."}, {"time": 439, "text": "Is that a hopeful or a realistic statement?"}, {"time": 442, "text": "So certainly you will be correct in your feeling in some number of years, but that number of years could be 200, 300 years from now."}, {"time": 451, "text": "Oh, well, there's a... Is that aspirational or is that pragmatic engineering feeling that you have?"}, {"time": 459, "text": "It's both in the sense that this is what I hope and expect will bear fruit over the coming decades, but it's also pragmatic in the sense that I'm not sure what we're doing in either psychology or neuroscience if that's not the framing."}, {"time": 484, "text": "I don't know what it means to understand the brain if there's no, if part of the enterprise is not about understanding the behavior that's being produced."}, {"time": 500, "text": "I mean, yeah, but I would compare it to maybe astronomers looking at the movement of the planets and the stars without any interest of the underlying physics, right?"}, {"time": 512, "text": "And I would argue that at least in the early days, there is some value to just tracing the movement of the planets and the stars without thinking about the physics too much because it's such a big leap to start thinking about the physics before you even understand even the basic structural elements of... Oh, I agree with that."}, {"time": 531, "text": "But you're saying in the end, the goal should be to deeply understand."}, {"time": 534, "text": "Well, right, and I think..."}, {"time": 537, "text": "So I thought about this a lot when I was in grad school because a lot of what I studied in grad school was psychology and I found myself a little bit confused about what it meant to..."}, {"time": 548, "text": "It seems like what we were talking about a lot of the time were virtual causal mechanisms."}, {"time": 554, "text": "Like, oh, well, you know, attentional selection then selects some object in the environment and that is then passed on to the motor, you know, information about that is passed on to the motor system."}, {"time": 567, "text": "But these are virtual mechanisms."}, {"time": 569, "text": "These are, you know, they're metaphors."}, {"time": 571, "text": "They're, you know, there's no reduction going on in that conversation to some physical mechanism that, you know, which is really what it would take to fully understand, you know, how behavior is rising."}, {"time": 587, "text": "But the causal mechanisms are definitely neurons interacting."}, {"time": 590, "text": "I'm willing to say that at this point in history."}, {"time": 593, "text": "So in psychology, at least for me personally, there was this strange insecurity about trafficking in these metaphors, you know, which were supposed to explain the function of the mind."}, {"time": 607, "text": "If you can't ground them in physical mechanisms, then what is the explanatory validity of these explanations?"}, {"time": 616, "text": "And I managed to soothe my own nerves by thinking about the history of genetics research."}, {"time": 629, "text": "So I'm very far from being an expert on the history of this field."}, {"time": 634, "text": "But I know enough to say that, you know, Mendelian genetics preceded, you know, Watson and Crick."}, {"time": 642, "text": "And so there was a significant period of time during which people were, you know, productively investigating the structure of inheritance using what was essentially a metaphor, the notion of a gene, you know."}, {"time": 658, "text": "Oh, genes do this and genes do that."}, {"time": 660, "text": "But, you know, where are the genes?"}, {"time": 662, "text": "They're sort of an explanatory thing that we made up."}, {"time": 666, "text": "And we ascribed to them these causal properties."}, {"time": 668, "text": "Oh, there's a dominant, there's a recessive, and then they recombine it."}, {"time": 672, "text": "And then later, there was a kind of blank there that was filled in with a physical mechanism."}, {"time": 681, "text": "That connection was made."}, {"time": 684, "text": "But it was worth having that metaphor because that gave us a good sense of what kind of causal mechanism we were looking for."}, {"time": 694, "text": "And the fundamental metaphor of cognition, you said, is the interaction of neurons."}, {"time": 700, "text": "Is that, what is the metaphor?"}, {"time": 702, "text": "No, no, the metaphor, the metaphors we use in cognitive psychology are things like attention, the way that memory works."}, {"time": 716, "text": "I retrieve something from memory, right?"}, {"time": 719, "text": "A memory retrieval occurs."}, {"time": 722, "text": "You know, that's not a physical mechanism that I can examine in its own right."}, {"time": 728, "text": "But it's still worth having, that metaphorical level."}, {"time": 733, "text": "Yeah, so yeah, I misunderstood actually."}, {"time": 736, "text": "So the higher level of abstractions is the metaphor that's most useful."}, {"time": 740, "text": "But what about, so how does that connect to the idea that that arises from interaction of neurons?"}, {"time": 753, "text": "Well, even, is the interaction of neurons also not a metaphor to you?"}, {"time": 758, "text": "Or is it literally, like that's no longer a metaphor."}, {"time": 762, "text": "That's already the lowest level of abstractions that could actually be directly studied."}, {"time": 770, "text": "Well, I'm hesitating because I think what I want to say could end up being controversial."}, {"time": 777, "text": "So what I want to say is, yes, the interactions of neurons, that's not metaphorical."}, {"time": 783, "text": "That's a physical fact."}, {"time": 784, "text": "That's where the causal interactions actually occur."}, {"time": 788, "text": "Now, I suppose you could say, well, even that is metaphorical relative to the quantum events that underlie."}, {"time": 795, "text": "I don't want to go down that rabbit hole."}, {"time": 797, "text": "It's always turtles on top of turtles."}, {"time": 798, "text": "Yeah, there's turtles all the way down."}, {"time": 801, "text": "There's a reduction that you can do."}, {"time": 802, "text": "You can say these psychological phenomena can be explained through a very different kind of causal mechanism, which has to do with neurotransmitter release."}, {"time": 811, "text": "And so what we're really trying to do in neuroscience writ large, as I say, which for me includes psychology, is to take these psychological phenomena and map them onto neural events."}, {"time": 829, "text": "I think remaining forever at the level of description that is natural for psychology, for me personally, would be disappointing."}, {"time": 842, "text": "I want to understand how mental activity arises from neural activity."}, {"time": 850, "text": "But the converse is also true."}, {"time": 853, "text": "Studying neural activity without any sense of what you're trying to explain, to me feels like at best groping around at random."}, {"time": 867, "text": "Now, you've kind of talked about this bridging of the gap between psychology and neuroscience, but do you think it's possible, like my love is, like I fell in love with psychology and psychiatry in general with Freud and when I was really young, and I hoped to understand the mind."}, {"time": 883, "text": "And for me, understanding the mind, at least at that young age before I discovered AI and even neuroscience was to, is psychology."}, {"time": 892, "text": "And do you think it's possible to understand the mind without getting into all the messy details of neuroscience?"}, {"time": 899, "text": "Like you kind of mentioned to you it's appealing to try to understand the mechanisms at the lowest level, but do you think that's needed, that's required to understand how the mind works?"}, {"time": 911, "text": "That's an important part of the whole picture, but I would be the last person on earth to suggest that that reality renders psychology in its own right unproductive."}, {"time": 929, "text": "I trained as a psychologist."}, {"time": 931, "text": "I am fond of saying that I have learned much more from psychology than I have from neuroscience."}, {"time": 938, "text": "To me, psychology is a hugely important discipline."}, {"time": 943, "text": "And one thing that warms in my heart is that ways of investigating behavior that have been native to cognitive psychology since it's dawn in the 60s are starting to become, they're starting to become interesting to AI researchers for a variety of reasons."}, {"time": 969, "text": "And that's been exciting for me to see."}, {"time": 971, "text": "Can you maybe talk a little bit about what you see as beautiful aspects of psychology, maybe limiting aspects of psychology?"}, {"time": 981, "text": "I mean, maybe just start it off as a science, as a field."}, {"time": 985, "text": "To me, it was when I understood what psychology is, analytical psychology, like the way it's actually carried out, it was really disappointing to see two aspects."}, {"time": 996, "text": "One is how small the N is, how small the number of subject is in the studies."}, {"time": 1003, "text": "And two, it was disappointing to see how controlled the entire, how much it was in the lab."}, {"time": 1010, "text": "It wasn't studying humans in the wild."}, {"time": 1012, "text": "There was no mechanism for studying humans in the wild."}, {"time": 1015, "text": "So that's where I became a little bit disillusioned to psychology."}, {"time": 1019, "text": "And then the modern world of the internet is so exciting to me."}, {"time": 1022, "text": "The Twitter data or YouTube data, data of human behavior on the internet becomes exciting because the N grows and then in the wild grows."}, {"time": 1031, "text": "But that's just my narrow sense."}, {"time": 1033, "text": "Like, do you have a optimistic or pessimistic cynical view of psychology?"}, {"time": 1038, "text": "How do you see the field broadly?"}, {"time": 1041, "text": "When I was in graduate school, it was early enough that there was still a thrill in seeing that there were ways of doing, there were ways of doing experimental science that provided insight to the structure of the mind."}, {"time": 1060, "text": "One thing that impressed me most when I was at that stage in my education was neuropsychology, looking at, analyzing the behavior of populations who had brain damage of different kinds and trying to understand what the specific deficits were that arose from a lesion in a particular part of the brain."}, {"time": 1086, "text": "And the kind of experimentation that was done and that's still being done to get answers in that context was so creative and it was so deliberate."}, {"time": 1098, "text": "It was good science."}, {"time": 1101, "text": "An experiment answered one question but raised another and somebody would do an experiment that answered that question."}, {"time": 1106, "text": "And you really felt like you were narrowing in on some kind of approximate understanding of what this part of the brain was for."}, {"time": 1114, "text": "Do you have an example from memory of what kind of aspects of the mind could be studied in this kind of way?"}, {"time": 1122, "text": "I mean, the very detailed neuropsychological studies of language function, looking at production and reception and the relationship between visual function, reading and auditory and semantic."}, {"time": 1140, "text": "There were these, and still are, these beautiful models that came out of that kind of research that really made you feel like you understood something that you hadn't understood before about how language processing is organized in the brain."}, {"time": 1155, "text": "But having said all that, I think you are, I mean, I agree with you that the cost of doing highly controlled experiments is that you, by construction, miss out on the richness and complexity of the real world."}, {"time": 1179, "text": "One thing that, so I was drawn into science by what in those days was called connectionism, which is, of course, what we now call deep learning."}, {"time": 1189, "text": "And at that point in history, neural networks were primarily being used in order to model human cognition."}, {"time": 1196, "text": "They weren't yet really useful for industrial applications."}, {"time": 1200, "text": "So you always found neural networks in biological form beautiful."}, {"time": 1204, "text": "Oh, neural networks were very concretely the thing that drew me into science."}, {"time": 1209, "text": "I was handed, are you familiar with the PDP books from the 80s when I was in, I went to medical school before I went into science."}, {"time": 1218, "text": "And, yeah."}, {"time": 1219, "text": "Really, interesting."}, {"time": 1221, "text": "I also did a graduate degree in art history, so I'm kind of exploring."}, {"time": 1226, "text": "Well, art history, I understand."}, {"time": 1228, "text": "That's just a curious, creative mind."}, {"time": 1231, "text": "But medical school, with the dream of what, if we take that slight tangent?"}, {"time": 1236, "text": "What, did you want to be a surgeon?"}, {"time": 1239, "text": "I actually was quite interested in surgery."}, {"time": 1241, "text": "I was interested in surgery and psychiatry."}, {"time": 1244, "text": "And I thought, I must be the only person on the planet who was torn between those two fields."}, {"time": 1252, "text": "And I said exactly that to my advisor in medical school, who turned out, I found out later, to be a famous psychoanalyst."}, {"time": 1261, "text": "And he said to me, no, no, it's actually not so uncommon to be interested in surgery and psychiatry."}, {"time": 1267, "text": "And he conjectured that the reason that people develop these two interests is that both fields are about going beneath the surface and kind of getting into the kind of secret."}, {"time": 1279, "text": "I mean, maybe you understand this as someone who was interested in psychoanalysis."}, {"time": 1283, "text": "There's sort of a, there's a cliche phrase that people use now, like in NPR, the secret life of blankety blank, right?"}, {"time": 1291, "text": "And that was part of the thrill of surgery, was seeing the secret activity that's inside everybody's abdomen and thorax."}, {"time": 1300, "text": "That's a very poetic way to connect it to disciplines that are very, practically speaking, different from each other."}, {"time": 1306, "text": "That's for sure, that's for sure, yes."}, {"time": 1308, "text": "So how did we get onto medical school?"}, {"time": 1312, "text": "So I was in medical school and I was doing a psychiatry rotation and my kind of advisor in that rotation asked me what I was interested in."}, {"time": 1324, "text": "And I said, well, maybe psychiatry."}, {"time": 1327, "text": "He said, why?"}, {"time": 1329, "text": "And I said, well, I've always been interested in how the brain works."}, {"time": 1333, "text": "I'm pretty sure that nobody's doing scientific research that addresses my interests, which are, I didn't have a word for it then, but I would have said about cognition."}, {"time": 1345, "text": "And he said, well, you know, I'm not sure that's true."}, {"time": 1347, "text": "You might be interested in these books."}, {"time": 1349, "text": "And he pulled down the PDB books from his shelf and they were still shrink wrapped."}, {"time": 1353, "text": "He hadn't read them, but he handed them to me."}, {"time": 1356, "text": "He said, you feel free to borrow these."}, {"time": 1358, "text": "And that was, you know, I went back to my dorm room and I just, you know, read them cover to cover."}, {"time": 1363, "text": "And what's PDB?"}, {"time": 1364, "text": "Parallel distributed processing, which was one of the original names for deep learning."}, {"time": 1370, "text": "And so I apologize for the romanticized question, but what idea in the space of neuroscience and the space of the human brain is to you the most beautiful, mysterious, surprising?"}, {"time": 1383, "text": "What had always fascinated me, even when I was a pretty young kid, I think, was the paradox that lies in the fact that the brain is so mysterious and seems so distant."}, {"time": 1410, "text": "But at the same time, it's responsible for the full transparency of everyday life."}, {"time": 1419, "text": "The brain is literally what makes everything obvious and familiar."}, {"time": 1423, "text": "And there's always one in the room with you."}, {"time": 1428, "text": "I used to teach, when I taught at Princeton, I used to teach a cognitive neuroscience course."}, {"time": 1433, "text": "And the very last thing I would say to the students was, you know, people often, when people think of scientific inspiration, the metaphor is often, well, look to the stars."}, {"time": 1448, "text": "The stars will inspire you to wonder at the universe and think about your place in it and how things work."}, {"time": 1455, "text": "And I'm all for looking at the stars, but I've always been much more inspired."}, {"time": 1461, "text": "And my sense of wonder comes from the, not from the distant, mysterious stars, but from the extremely intimately close brain."}, {"time": 1475, "text": "There's something just endlessly fascinating to me about that."}, {"time": 1480, "text": "The, like, just like you said, the one that's close and yet distant in terms of our understanding of it."}, {"time": 1488, "text": "Do you, are you also captivated by the fact that this very conversation is happening because two brains are communicating so that?"}, {"time": 1499, "text": "The, I guess what I mean is the subjective nature of the experience, if it can take a small attention into the mystical of it, the consciousness, or when you were saying you're captivated by the idea of the brain, are you talking about specifically the mechanism of cognition?"}, {"time": 1518, "text": "Or are you also just, like, at least for me, it's almost like paralyzing the beauty and the mystery of the fact that it creates the entirety of the experience, not just the reasoning capability, but the experience."}, {"time": 1532, "text": "Well, I definitely resonate with that latter thought."}, {"time": 1538, "text": "And I often find discussions of artificial intelligence to be disappointingly narrow."}, {"time": 1550, "text": "Speaking as someone who has always had an interest in art."}, {"time": 1556, "text": "I was just gonna go there because it sounds like somebody who has an interest in art."}, {"time": 1560, "text": "Yeah, I mean, there are many layers to full bore human experience."}, {"time": 1568, "text": "And in some ways it's not enough to say, oh, well, don't worry, we're talking about cognition, but we'll add emotion, you know?"}, {"time": 1577, "text": "There's an incredible scope to what humans go through in every moment."}, {"time": 1585, "text": "And yes, so that's part of what fascinates me, is that our brains are producing that."}, {"time": 1600, "text": "But at the same time, it's so mysterious to us."}, {"time": 1606, "text": "Our brains are literally in our heads producing this experience."}, {"time": 1610, "text": "Producing the experience."}, {"time": 1612, "text": "And yet it's so mysterious to us."}, {"time": 1615, "text": "And so, and the scientific challenge of getting at the actual explanation for that is so overwhelming."}, {"time": 1623, "text": "That's just, I don't know."}, {"time": 1625, "text": "Certain people have fixations on particular questions and that's always, that's just always been mine."}, {"time": 1631, "text": "Yeah, I would say the poetry of that is fascinating."}, {"time": 1634, "text": "And I'm really interested in natural language as well."}, {"time": 1636, "text": "And when you look at artificial intelligence community, it always saddens me how much when you try to create a benchmark for the community to gather around, how much of the magic of language is lost when you create that benchmark."}, {"time": 1653, "text": "That there's something, we talk about experience, the music of the language, the wit, the something that makes a rich experience, something that would be required to pass the spirit of the Turing test is lost in these benchmarks."}, {"time": 1667, "text": "And I wonder how to get it back in because it's very difficult."}, {"time": 1671, "text": "The moment you try to do like real good rigorous science, you lose some of that magic."}, {"time": 1676, "text": "When you try to study cognition in a rigorous scientific way, it feels like you're losing some of the magic."}, {"time": 1683, "text": "The seeing cognition in a mechanistic way that AI folk at this stage in our history."}, {"time": 1690, "text": "Well, I agree with you, but at the same time, one thing that I found really exciting about that first wave of deep learning models in cognition was the fact that the people who were building these models were focused on the richness and complexity of human cognition."}, {"time": 1714, "text": "So an early debate in cognitive science, which I sort of witnessed as a grad student was about something that sounds very dry, which is the formation of the past tense."}, {"time": 1727, "text": "But there were these two camps."}, {"time": 1729, "text": "One said, well, the mind encodes certain rules and it also has a list of exceptions because of course, the rule is add ED, but that's not always what you do."}, {"time": 1741, "text": "So you have to have a list of exceptions."}, {"time": 1745, "text": "And then there were the connectionists who evolved into the deep learning people who said, well, if you look carefully at the data, if you actually look at corpora, like language corpora, it turns out to be very rich because yes, there are most verbs that you just tack on ED, and then there are exceptions, but there are rules that the exceptions aren't just random."}, {"time": 1776, "text": "There are certain clues to which verbs should be exceptional."}, {"time": 1781, "text": "And then there are exceptions to the exceptions."}, {"time": 1784, "text": "And there was a word that was kind of deployed in order to capture this, which was quasi regular."}, {"time": 1791, "text": "In other words, there are rules, but it's messy."}, {"time": 1794, "text": "And there's either structure even among the exceptions."}, {"time": 1798, "text": "And it would be, yeah, you could try to write down, we could try to write down the structure in some sort of closed form, but really the right way to understand how the brain is handling all this, and by the way, producing all of this, is to build a deep neural network and train it on this data and see how it ends up representing all of this richness."}, {"time": 1818, "text": "So the way that deep learning was deployed in cognitive psychology was that was the spirit of it."}, {"time": 1825, "text": "It was about that richness."}, {"time": 1829, "text": "And that's something that I always found very compelling, still do."}, {"time": 1833, "text": "Is there something especially interesting and profound to you in terms of our current deep learning neural network, artificial neural network approaches, and whatever we do understand about the biological neural networks in our brain?"}, {"time": 1849, "text": "Is there, there's quite a few differences."}, {"time": 1852, "text": "Are some of them to you, either interesting or perhaps profound in terms of the gap we might want to try to close in trying to create a human level intelligence?"}, {"time": 1867, "text": "What I would say here is something that a lot of people are saying, which is that one seeming limitation of the systems that we're building now is that they lack the kind of flexibility, the readiness to sort of turn on a dime when the context calls for it that is so characteristic of human behavior."}, {"time": 1892, "text": "So is that connected to you to the, like which aspect of the neural networks in our brain is that connected to?"}, {"time": 1899, "text": "Is that closer to the cognitive science level of, now again, see like my natural inclination is to separate into three disciplines of neuroscience, cognitive science and psychology."}, {"time": 1914, "text": "And you've already kind of shut that down by saying you're kind of see them as separate, but just to look at those layers, I guess where is there something about the lowest layer of the way the neural neurons interact that is profound to you in terms of this difference to the artificial neural networks, or is all the key differences at a higher level of abstraction?"}, {"time": 1940, "text": "One thing I often think about is that, if you take an introductory computer science course and they are introducing you to the notion of Turing machines, one way of articulating what the significance of a Turing machine is, is that it's a machine emulator."}, {"time": 1962, "text": "It can emulate any other machine."}, {"time": 1967, "text": "And that to me, that way of looking at a Turing machine really sticks with me."}, {"time": 1977, "text": "I think of humans as maybe sharing in some of that character."}, {"time": 1985, "text": "We're capacity limited, we're not Turing machines obviously, but we have the ability to adapt behaviors that are very much unlike anything we've done before, but there's some basic mechanism that's implemented in our brain that allows us to run software."}, {"time": 2002, "text": "But just on that point, you mentioned Turing machine, but nevertheless, it's fundamentally our brains are just computational devices in your view."}, {"time": 2009, "text": "Is that what you're getting at?"}, {"time": 2011, "text": "It was a little bit unclear to this line you drew."}, {"time": 2015, "text": "Is there any magic in there or is it just basic computation?"}, {"time": 2020, "text": "I'm happy to think of it as just basic computation, but mind you, I won't be satisfied until somebody explains to me what the basic computations are that are leading to the full richness of human cognition."}, {"time": 2034, "text": "It's not gonna be enough for me to understand what the computations are that allow people to do arithmetic or play chess."}, {"time": 2042, "text": "I want the whole thing."}, {"time": 2046, "text": "And a small tangent, because you kind of mentioned coronavirus, there's group behavior."}, {"time": 2053, "text": "Is there something interesting to your search of understanding the human mind where behavior of large groups or just behavior of groups is interesting, seeing that as a collective mind, as a collective intelligence, perhaps seeing the groups of people as a single intelligent organisms, especially looking at the reinforcement learning work you've done recently."}, {"time": 2075, "text": "Well, yeah, I can't."}, {"time": 2076, "text": "I mean, I have the honor of working with a lot of incredibly smart people and I wouldn't wanna take any credit for leading the way on the multiagent work that's come out of my group or DeepMind lately, but I do find it fascinating."}, {"time": 2093, "text": "And I mean, I think it can't be debated."}, {"time": 2100, "text": "You know, human behavior arises within communities."}, {"time": 2106, "text": "That just seems to me self evident."}, {"time": 2108, "text": "But to me, it is self evident, but that seems to be a profound aspects of something that created."}, {"time": 2116, "text": "That was like, if you look at like 2001 Space Odyssey when the monkeys touched the... Yeah."}, {"time": 2164, "text": "And that to me has always been a mystery that I think is somehow productive for also understanding AI systems."}, {"time": 2173, "text": "But I guess that's the next step."}, {"time": 2176, "text": "The first step is try to understand the mind."}, {"time": 2179, "text": "I mean, I think there's something to the argument that that kind of like strictly bottom up approach is wrongheaded."}, {"time": 2189, "text": "In other words, there are basic phenomena, basic aspects of human intelligence that can only be understood in the context of groups."}, {"time": 2203, "text": "I'm perfectly open to that."}, {"time": 2204, "text": "I've never been particularly convinced by the notion that we should consider intelligence to inhere at the level of communities."}, {"time": 2215, "text": "I don't know why, I'm sort of stuck on the notion that the basic unit that we want to understand is individual humans."}, {"time": 2222, "text": "And if we have to understand that in the context of other humans, fine."}, {"time": 2228, "text": "But for me, intelligence is just, I stubbornly define it as something that is an aspect of an individual human."}, {"time": 2238, "text": "That's just my, I don't know if that's a matter of taste."}, {"time": 2240, "text": "I'm with you, but that could be the reductionist dream of a scientist because you can understand a single human."}, {"time": 2246, "text": "It also is very possible that intelligence can only arise when there's multiple intelligences."}, {"time": 2253, "text": "When there's multiple sort of, it's a sad thing, if that's true, because it's very difficult to study."}, {"time": 2259, "text": "But if it's just one human, that one human would not be homosapien, would not become that intelligent."}, {"time": 2266, "text": "That's a possibility."}, {"time": 2268, "text": "I'm with you."}, {"time": 2270, "text": "One thing I will say along these lines is that I think a serious effort to understand human intelligence and maybe to build humanlike intelligence needs to pay just as much attention to the structure of the environment as to the structure of the cognizing system, whether it's a brain or an AI system."}, {"time": 2303, "text": "That's one thing I took away actually from my early studies with the pioneers of neural network research, people like Jay McClelland and John Cohen."}, {"time": 2314, "text": "The structure of cognition is really, it's only partly a function of the architecture of the brain and the learning algorithms that it implements."}, {"time": 2326, "text": "What really shapes it is the interaction of those things with the structure of the world in which those things are embedded."}, {"time": 2336, "text": "And that's especially important for, that's made most clear in reinforcement learning where the simulated environment is, you can only learn as much as you can simulate."}, {"time": 2345, "text": "And that's what DeepMind made very clear with the other aspect of the environment, which is the self play mechanism of the other agent, of the competitive behavior, which the other agent becomes the environment essentially."}, {"time": 2360, "text": "And that's, I mean, one of the most exciting ideas in AI is the self play mechanism that's able to learn successfully."}, {"time": 2367, "text": "So there you go."}, {"time": 2368, "text": "There's a thing where competition is essential for learning, at least in that context."}, {"time": 2375, "text": "So if we can step back into another sort of beautiful world, which is the actual mechanics, the dirty mess of it of the human brain, is there something for people who might not know?"}, {"time": 2389, "text": "Is there something you can comment on or describe the key parts of the brain that are important for intelligence or just in general, what are the different parts of the brain that you're curious about that you've studied and that are just good to know about when you're thinking about cognition?"}, {"time": 2406, "text": "Well, my area of expertise, if I have one, is prefrontal cortex."}, {"time": 2416, "text": "Where do we?"}, {"time": 2418, "text": "It depends on who you ask."}, {"time": 2421, "text": "The technical definition is anatomical."}, {"time": 2425, "text": "There are parts of your brain that are responsible for motor behavior and they're very easy to identify."}, {"time": 2435, "text": "And the region of your cerebral cortex, the sort of outer crust of your brain that lies in front of those is defined as the prefrontal cortex."}, {"time": 2449, "text": "And when you say anatomical, sorry to interrupt, so that's referring to sort of the geographic region as opposed to some kind of functional definition."}, {"time": 2460, "text": "Exactly, so this is kind of the coward's way out."}, {"time": 2464, "text": "I'm telling you what the prefrontal cortex is just in terms of what part of the real estate it occupies."}, {"time": 2469, "text": "It's the thing in the front of the brain."}, {"time": 2471, "text": "And in fact, the early history of neuroscientific investigation of what this front part of the brain does is sort of funny to read because it was really World War I that started people down this road of trying to figure out what different parts of the brain, the human brain do in the sense that there were a lot of people with brain damage who came back from the war with brain damage."}, {"time": 2504, "text": "And that provided, as tragic as that was, it provided an opportunity for scientists to try to identify the functions of different brain regions."}, {"time": 2513, "text": "And that was actually incredibly productive, but one of the frustrations that neuropsychologists faced was they couldn't really identify exactly what the deficit was that arose from damage to these most kind of frontal parts of the brain."}, {"time": 2528, "text": "It was just a very difficult thing to pin down."}, {"time": 2533, "text": "There were a couple of neuropsychologists who identified through a large amount of clinical experience and close observation, they started to put their finger on a syndrome that was associated with frontal damage."}, {"time": 2547, "text": "Actually, one of them was a Russian neuropsychologist named Luria, who students of cognitive psychology still read."}, {"time": 2556, "text": "And what he started to figure out was that the frontal cortex was somehow involved in flexibility, in guiding behaviors that required someone to override a habit, or to do something unusual, or to change what they were doing in a very flexible way from one moment to another."}, {"time": 2582, "text": "So focused on like new experiences."}, {"time": 2585, "text": "And so the way your brain processes and acts in new experiences."}, {"time": 2590, "text": "Yeah, what later helped bring this function into better focus was a distinction between controlled and automatic behavior, or in other literatures, this is referred to as habitual behavior versus goal directed behavior."}, {"time": 2608, "text": "So it's very, very clear that the human brain has pathways that are dedicated to habits, to things that you do all the time, and they need to be automatized so that they don't require you to concentrate too much."}, {"time": 2625, "text": "So that leaves your cognitive capacity free to do other things."}, {"time": 2629, "text": "Just think about the difference between driving when you're learning to drive versus driving after you're a fairly expert."}, {"time": 2639, "text": "There are brain pathways that slowly absorb those frequently performed behaviors so that they can be habits, so that they can be automatic."}, {"time": 2652, "text": "That's kind of like the purest form of learning."}, {"time": 2654, "text": "I guess it's happening there, which is why, I mean, this is kind of jumping ahead, which is why that perhaps is the most useful for us to focusing on and trying to see how artificial intelligence systems can learn."}, {"time": 2667, "text": "Is that the way you think?"}, {"time": 2669, "text": "I do think about this distinction between controlled and automatic, or goal directed and habitual behavior a lot in thinking about where we are in AI research."}, {"time": 2682, "text": "But just to finish the kind of dissertation here, the role of the prefrontal cortex is generally understood these days sort of in contradistinction to that habitual domain."}, {"time": 2700, "text": "In other words, the prefrontal cortex is what helps you override those habits."}, {"time": 2705, "text": "It's what allows you to say, well, what I usually do in this situation is X, but given the context, I probably should do Y. I mean, the elbow bump is a great example, right?"}, {"time": 2718, "text": "Reaching out and shaking hands is probably a habitual behavior, and it's the prefrontal cortex that allows us to bear in mind that there's something unusual going on right now, and in this situation, I need to not do the usual thing."}, {"time": 2734, "text": "The kind of behaviors that Luria reported, and he built tests for detecting these kinds of things, were exactly like this."}, {"time": 2743, "text": "So in other words, when I stick out my hand, I want you instead to present your elbow."}, {"time": 2749, "text": "A patient with frontal damage would have a great deal of trouble with that."}, {"time": 2753, "text": "Somebody proffering their hand would elicit a handshake."}, {"time": 2758, "text": "The prefrontal cortex is what allows us to say, hold on, hold on, that's the usual thing, but I have the ability to bear in mind even very unusual contexts and to reason about what behavior is appropriate there."}, {"time": 2773, "text": "Just to get a sense, are us humans special in the presence of the prefrontal cortex?"}, {"time": 2780, "text": "Do mice have a prefrontal cortex?"}, {"time": 2782, "text": "Do other mammals that we can study?"}, {"time": 2785, "text": "If no, then how do they integrate new experiences?"}, {"time": 2790, "text": "Yeah, that's a really tricky question and a very timely question because we have revolutionary new technologies for monitoring, measuring, and also causally influencing neural behavior in mice and fruit flies."}, {"time": 2817, "text": "And these techniques are not fully available even for studying brain function in monkeys, let alone humans."}, {"time": 2828, "text": "And so it's a very sort of, for me at least, a very urgent question whether the kinds of things that we wanna understand about human intelligence can be pursued in these other organisms."}, {"time": 2842, "text": "And to put it briefly, there's disagreement."}, {"time": 2846, "text": "People who study fruit flies will often tell you, hey, fruit flies are smarter than you think."}, {"time": 2855, "text": "And they'll point to experiments where fruit flies were able to learn new behaviors, were able to generalize from one stimulus to another in a way that suggests that they have abstractions that guide their generalization."}, {"time": 2871, "text": "I've had many conversations in which I will start by observing, recounting some observation about mouse behavior where it seemed like mice were taking an awfully long time to learn a task that for a human would be profoundly trivial."}, {"time": 2893, "text": "And I will conclude from that, that mice really don't have the cognitive flexibility that we want to explain."}, {"time": 2900, "text": "And then a mouse researcher will say to me, well, hold on, that experiment may not have worked because you asked a mouse to deal with stimuli and behaviors that were very unnatural for the mouse."}, {"time": 2914, "text": "If instead you kept the logic of the experiment the same, but presented the information in a way that aligns with what mice are used to dealing with in their natural habitats, you might find that a mouse actually has more intelligence than you think."}, {"time": 2932, "text": "And then they'll go on to show you videos of mice doing things in their natural habitat, which seem strikingly intelligent, dealing with physical problems."}, {"time": 2942, "text": "I have to drag this piece of food back to my lair, but there's something in my way and how do I get rid of that thing?"}, {"time": 2950, "text": "So I think these are open questions to put it, to sum that up."}, {"time": 2955, "text": "And then taking a small step back related to that is you kind of mentioned we're taking a little shortcut by saying it's a geographic part of the prefrontal cortex is a region of the brain."}, {"time": 2968, "text": "But if we, what's your sense in a bigger philosophical view, prefrontal cortex and the brain in general, do you have a sense that it's a set of subsystems in the way we've kind of implied that are pretty distinct or to what degree is it that or to what degree is it a giant interconnected mess where everything kind of does everything and it's impossible to disentangle them?"}, {"time": 2994, "text": "I think there's overwhelming evidence that there's functional differentiation, that it's clearly not the case that all parts of the brain are doing the same thing."}, {"time": 3007, "text": "This follows immediately from the kinds of studies of brain damage that we were chatting about before."}, {"time": 3014, "text": "It's obvious from what you see if you stick an electrode in the brain and measure what's going on at the level of neural activity."}, {"time": 3025, "text": "Having said that, there are two other things to add, which kind of, I don't know, maybe tug in the other direction."}, {"time": 3034, "text": "One is that it's when you look carefully at functional differentiation in the brain, what you usually end up concluding, at least this is my observation of the literature, is that the differences between regions are graded rather than being discreet."}, {"time": 3055, "text": "So it doesn't seem like it's easy to divide the brain up into true modules that have clear boundaries and that have you know, clear channels of communication between them."}, {"time": 3076, "text": "And this applies to the prefrontal cortex?"}, {"time": 3078, "text": "Yeah, oh yeah."}, {"time": 3078, "text": "The prefrontal cortex is made up of a bunch of different subregions, the functions of which are not clearly defined and the borders of which seem to be quite vague."}, {"time": 3092, "text": "And then there's another thing that's popping up in very recent research, which, you know, which, involves application of these new techniques, which there are a number of studies that suggest that parts of the brain that we would have previously thought were quite focused in their function are actually carrying signals that we wouldn't have thought would be there."}, {"time": 3121, "text": "For example, looking in the primary visual cortex, which is classically thought of as basically the first cortical way station for processing visual information."}, {"time": 3130, "text": "Basically what it should care about is, you know, where are the edges in this scene that I'm viewing?"}, {"time": 3137, "text": "It turns out that if you have enough data, you can recover information from primary visual cortex about all sorts of things."}, {"time": 3143, "text": "Like, you know, what behavior the animal is engaged in right now and how much reward is on offer in the task that it's pursuing."}, {"time": 3151, "text": "So it's clear that even regions whose function is pretty well defined at a core screen are nonetheless carrying some information about information from very different domains."}, {"time": 3167, "text": "So, you know, the history of neuroscience is sort of this oscillation between the two views that you articulated, you know, the kind of modular view and then the big, you know, mush view."}, {"time": 3177, "text": "And, you know, I think, I guess we're gonna end up somewhere in the middle."}, {"time": 3182, "text": "Which is unfortunate for our understanding because there's something about our, you know, conceptual system that finds it's easy to think about a modularized system and easy to think about a completely undifferentiated system."}, {"time": 3195, "text": "But something that kind of lies in between is confusing."}, {"time": 3199, "text": "But we're gonna have to get used to it, I think."}, {"time": 3201, "text": "Unless we can understand deeply the lower level mechanism of neuronal communication."}, {"time": 3206, "text": "But on that topic, you kind of mentioned information."}, {"time": 3209, "text": "Just to get a sense, I imagine something that there's still mystery and disagreement on is how does the brain carry information and signal?"}, {"time": 3218, "text": "Like what in your sense is the basic mechanism of communication in the brain?"}, {"time": 3226, "text": "Well, I guess I'm old fashioned in that I consider the networks that we use in deep learning research to be a reasonable approximation to, you know, the mechanisms that carry information in the brain."}, {"time": 3242, "text": "So the usual way of articulating that is to say, what really matters is a rate code."}, {"time": 3248, "text": "What matters is how quickly is an individual neuron spiking?"}, {"time": 3254, "text": "You know, what's the frequency at which it's spiking?"}, {"time": 3256, "text": "Is it right?"}, {"time": 3257, "text": "So the timing of the spike."}, {"time": 3258, "text": "Yeah, is it firing fast or slow?"}, {"time": 3260, "text": "Let's, you know, let's put a number on that."}, {"time": 3262, "text": "And that number is enough to capture what neurons are doing."}, {"time": 3266, "text": "There's, you know, there's still uncertainty about whether that's an adequate description of how information is transmitted within the brain."}, {"time": 3279, "text": "There, you know, there are studies that suggest that the precise timing of spikes matters."}, {"time": 3286, "text": "There are studies that suggest that there are computations that go on within the dendritic tree, within a neuron, that are quite rich and structured and that really don't equate to anything that we're doing in our artificial neural networks."}, {"time": 3302, "text": "Having said that, I feel like we can get, I feel like we're getting somewhere by sticking to this high level of abstraction."}, {"time": 3311, "text": "Just the rate, and by the way, we're talking about the electrical signal."}, {"time": 3316, "text": "I remember reading some vague paper somewhere recently where the mechanical signal, like the vibrations or something of the neurons, also communicates information."}, {"time": 3328, "text": "I haven't seen that, but."}, {"time": 3330, "text": "There's somebody who was arguing that the electrical signal, this is in a nature paper, something like that, where the electrical signal is actually a side effect of the mechanical signal."}, {"time": 3343, "text": "But I don't think that changes the story."}, {"time": 3346, "text": "But it's almost an interesting idea that there could be a deeper, it's always like in physics with quantum mechanics, there's always a deeper story that could be underlying the whole thing."}, {"time": 3357, "text": "But you think it's basically the rate of spiking that gets us, that's like the lowest hanging fruit that can get us really far."}, {"time": 3364, "text": "This is a classical view."}, {"time": 3366, "text": "I mean, this is not, the only way in which this stance would be controversial is in the sense that there are members of the neuroscience community who are interested in alternatives."}, {"time": 3378, "text": "But this is really a very mainstream view."}, {"time": 3381, "text": "The way that neurons communicate is that neurotransmitters arrive, they wash up on a neuron, the neuron has receptors for those transmitters, the meeting of the transmitter with these receptors changes the voltage of the neuron."}, {"time": 3402, "text": "And if enough voltage change occurs, then a spike occurs, one of these like discrete events."}, {"time": 3408, "text": "And it's that spike that is conducted down the axon and leads to neurotransmitter release."}, {"time": 3414, "text": "This is just like neuroscience 101."}, {"time": 3416, "text": "This is like the way the brain is supposed to work."}, {"time": 3419, "text": "Now, what we do when we build artificial neural networks of the kind that are now popular in the AI community is that we don't worry about those individual spikes."}, {"time": 3431, "text": "We just worry about the frequency at which those spikes are being generated."}, {"time": 3436, "text": "And people talk about that as the activity of a neuron."}, {"time": 3442, "text": "And so the activity of units in a deep learning system is broadly analogous to the spike rate of a neuron."}, {"time": 3452, "text": "There are people who believe that there are other forms of communication in the brain."}, {"time": 3459, "text": "In fact, I've been involved in some research recently that suggests that the voltage fluctuations that occur in populations of neurons that are sort of below the level of spike production may be important for communication."}, {"time": 3477, "text": "But I'm still pretty old school in the sense that I think that the things that we're building in AI research constitute reasonable models of how a brain would work."}, {"time": 3490, "text": "Let me ask just for fun a crazy question, because I can."}, {"time": 3494, "text": "Do you think it's possible we're completely wrong about the way this basic mechanism of neuronal communication, that the information is stored in some very different kind of way in the brain?"}, {"time": 3506, "text": "Oh, heck yes."}, {"time": 3507, "text": "I mean, look, I wouldn't be a scientist if I didn't think there was any chance we were wrong."}, {"time": 3512, "text": "But I mean, if you look at the history of deep learning research as it's been applied to neuroscience, of course the vast majority of deep learning research these days isn't about neuroscience."}, {"time": 3525, "text": "But if you go back to the 1980s, there's sort of an unbroken chain of research in which a particular strategy is taken, which is, hey, let's train a deep learning system."}, {"time": 3540, "text": "Let's train a multi layer neural network on this task that we trained our rat on, or our monkey on, or this human being on."}, {"time": 3552, "text": "And then let's look at what the units deep in the system are doing."}, {"time": 3557, "text": "And let's ask whether what they're doing resembles what we know about what neurons deep in the brain are doing."}, {"time": 3564, "text": "And over and over and over and over, that strategy works in the sense that the learning algorithms that we have access to, which typically center on back propagation, they give rise to patterns of activity, patterns of response, patterns of neuronal behavior in these artificial models that look hauntingly similar to what you see in the brain."}, {"time": 3593, "text": "And is that a coincidence?"}, {"time": 3597, "text": "At a certain point, it starts looking like such coincidence is unlikely to not be deeply meaningful, yeah."}, {"time": 3603, "text": "Yeah, the circumstantial evidence is overwhelming."}, {"time": 3607, "text": "But it could be."}, {"time": 3607, "text": "But you're always open to total flipping at the table."}, {"time": 3610, "text": "Hey, of course."}, {"time": 3611, "text": "So you have coauthored several recent papers that sort of weave beautifully between the world of neuroscience and artificial intelligence."}, {"time": 3620, "text": "And maybe if we could, can we just try to dance around and talk about some of them?"}, {"time": 3627, "text": "Maybe try to pick out interesting ideas that jump to your mind from memory."}, {"time": 3632, "text": "So maybe looking at, we were talking about the prefrontal cortex, the 2018, I believe, paper called the Prefrontal Cortex as a Meta Reinforcement Learning System."}, {"time": 3642, "text": "What, is there a key idea that you can speak to from that paper?"}, {"time": 3647, "text": "Yeah, I mean, the key idea is about meta learning."}, {"time": 3653, "text": "What is meta learning?"}, {"time": 3654, "text": "Meta learning is, by definition, a situation in which you have a learning algorithm and the learning algorithm operates in such a way that it gives rise to another learning algorithm."}, {"time": 3674, "text": "In the earliest applications of this idea, you had one learning algorithm sort of adjusting the parameters on another learning algorithm."}, {"time": 3683, "text": "But the case that we're interested in this paper is one where you start with just one learning algorithm and then another learning algorithm kind of emerges out of thin air."}, {"time": 3695, "text": "I can say more about what I mean by that."}, {"time": 3696, "text": "I don't mean to be scurrentist, but that's the idea of meta learning."}, {"time": 3704, "text": "It relates to the old idea in psychology of learning to learn."}, {"time": 3709, "text": "Situations where you have experiences that make you better at learning something new."}, {"time": 3717, "text": "A familiar example would be learning a foreign language."}, {"time": 3721, "text": "The first time you learn a foreign language, it may be quite laborious and disorienting and novel, but let's say you've learned two foreign languages."}, {"time": 3732, "text": "The third foreign language, obviously, is gonna be much easier to pick up."}, {"time": 3736, "text": "Because you've learned how to learn."}, {"time": 3738, "text": "You know how this goes."}, {"time": 3740, "text": "You know, okay, I'm gonna have to learn how to conjugate."}, {"time": 3742, "text": "I'm gonna have to... That's a simple form of meta learning in the sense that there's some slow learning mechanism that's helping you kind of update your fast learning mechanism."}, {"time": 3755, "text": "So how from our understanding from the psychology world, from neuroscience, our understanding how meta learning might work in the human brain, what lessons can we draw from that that we can bring into the artificial intelligence world?"}, {"time": 3773, "text": "Well, yeah, so the origin of that paper was in AI work that we were doing in my group."}, {"time": 3780, "text": "We were looking at what happens when you train a recurrent neural network using standard reinforcement learning algorithms."}, {"time": 3790, "text": "But you train that network, not just in one task, but you train it in a bunch of interrelated tasks."}, {"time": 3795, "text": "And then you ask what happens when you give it yet another task in that sort of line of interrelated tasks."}, {"time": 3803, "text": "And what we started to realize is that a form of meta learning spontaneously happens in recurrent neural networks."}, {"time": 3813, "text": "And the simplest way to explain it is to say a recurrent neural network has a kind of memory in its activation patterns."}, {"time": 3825, "text": "It's recurrent by definition in the sense that you have units that connect to other units, that connect to other units."}, {"time": 3831, "text": "So you have sort of loops of connectivity, which allows activity to stick around and be updated over time."}, {"time": 3837, "text": "In psychology we call, in neuroscience we call this working memory."}, {"time": 3840, "text": "It's like actively holding something in mind."}, {"time": 3844, "text": "And so that memory gives the recurrent neural network a dynamics, right?"}, {"time": 3853, "text": "The way that the activity pattern evolves over time is inherent to the connectivity of the recurrent neural network, okay?"}, {"time": 3861, "text": "So that's idea number one."}, {"time": 3863, "text": "Now, the dynamics of that network are shaped by the connectivity, by the synaptic weights."}, {"time": 3869, "text": "And those synaptic weights are being shaped by this reinforcement learning algorithm that you're training the network with."}, {"time": 3877, "text": "So the punchline is if you train a recurrent neural network with a reinforcement learning algorithm that's adjusting its weights, and you do that for long enough, the activation dynamics will become very interesting, right?"}, {"time": 3890, "text": "So imagine I give you a task where you have to press one button or another, left button or right button."}, {"time": 3897, "text": "And there's some probability that I'm gonna give you an M&M if you press the left button, and there's some probability I'll give you an M&M if you press the other button."}, {"time": 3907, "text": "And you have to figure out what those probabilities are just by trying things out."}, {"time": 3912, "text": "But as I said before, instead of just giving you one of these tasks, I give you a whole sequence."}, {"time": 3917, "text": "You know, I give you two buttons and you figure out which one's best."}, {"time": 3919, "text": "And I go, good job, here's a new box."}, {"time": 3922, "text": "Two new buttons, you have to figure out which one's best."}, {"time": 3924, "text": "Good job, here's a new box."}, {"time": 3925, "text": "And every box has its own probabilities and you have to figure it out."}, {"time": 3928, "text": "So if you train a recurrent neural network on that kind of sequence of tasks, what happens, it seemed almost magical to us when we first started kind of realizing what was going on."}, {"time": 3941, "text": "The slow learning algorithm that's adjusting the synaptic weights, those slow synaptic changes give rise to a network dynamics that themselves, that, you know, the dynamics themselves turn into a learning algorithm."}, {"time": 3956, "text": "So in other words, you can tell this is happening by just freezing the synaptic weights saying, okay, no more learning, you're done."}, {"time": 3963, "text": "Here's a new box, figure out which button is best."}, {"time": 3967, "text": "And the recurrent neural network will do this just fine."}, {"time": 3969, "text": "There's no, like it figures out which button is best."}, {"time": 3973, "text": "It kind of transitions from exploring the two buttons to just pressing the one that it likes best in a very rational way."}, {"time": 3980, "text": "How is that happening?"}, {"time": 3981, "text": "It's happening because the activity dynamics of the network have been shaped by the slow learning process that's occurred over many, many boxes."}, {"time": 3990, "text": "And so what's happened is that this slow learning algorithm that's slowly adjusting the weights is changing the dynamics of the network, the activity dynamics into its own learning algorithm."}, {"time": 4003, "text": "And as we were kind of realizing that this is a thing, it just so happened that the group that was working on this included a bunch of neuroscientists and it started kind of ringing a bell for us, which is to say that we thought this sounds a lot like the distinction between synaptic learning and activity, synaptic memory and activity based memory in the brain."}, {"time": 4031, "text": "And it also reminded us of recurrent connectivity that's very characteristic of prefrontal function."}, {"time": 4039, "text": "So this is kind of why it's good to have people working on AI that know a little bit about neuroscience and vice versa, because we started thinking about whether we could apply this principle to neuroscience."}, {"time": 4052, "text": "And that's where the paper came from."}, {"time": 4053, "text": "So the kind of principle of the recurrence they can see in the prefrontal cortex, then you start to realize that it's possible for something like an idea of a learning to learn emerging from this learning process as long as you keep varying the environment sufficiently."}, {"time": 4074, "text": "Exactly, so the kind of metaphorical transition we made to neuroscience was to think, okay, well, we know that the prefrontal cortex is highly recurrent."}, {"time": 4084, "text": "We know that it's an important locus for working memory for activation based memory."}, {"time": 4091, "text": "So maybe the prefrontal cortex supports reinforcement learning."}, {"time": 4095, "text": "In other words, what is reinforcement learning?"}, {"time": 4099, "text": "You take an action, you see how much reward you got, you update your policy of behavior."}, {"time": 4104, "text": "Maybe the prefrontal cortex is doing that sort of thing strictly in its activation patterns."}, {"time": 4108, "text": "It's keeping around a memory in its activity patterns of what you did, how much reward you got, and it's using that activity based memory as a basis for updating behavior."}, {"time": 4121, "text": "But then the question is, well, how did the prefrontal cortex get so smart?"}, {"time": 4124, "text": "In other words, where did these activity dynamics come from?"}, {"time": 4128, "text": "How did that program that's implemented in the recurrent dynamics of the prefrontal cortex arise?"}, {"time": 4134, "text": "And one answer that became evident in this work was, well, maybe the mechanisms that operate on the synaptic level, which we believe are mediated by dopamine, are responsible for shaping those dynamics."}, {"time": 4150, "text": "So this may be a silly question, but because this kind of several temporal sort of classes of learning are happening and the learning to learnism emerges, can you keep building stacks of learning to learn to learn, learning to learn to learn to learn to learn because it keeps, I mean, basically abstractions of more powerful abilities to generalize of learning complex rules."}, {"time": 4181, "text": "Yeah, that's overstretching this kind of mechanism."}, {"time": 4208, "text": "That's really what's gonna get us to true intelligence."}, {"time": 4213, "text": "Certainly there's a poetic aspect to it and it seems interesting and correct that that kind of levels of abstraction would be powerful, but is that something you see in the brain?"}, {"time": 4223, "text": "This kind of, is it useful to think of learning in these meta, meta, meta way or is it just meta learning?"}, {"time": 4232, "text": "Well, one thing that really fascinated me about this mechanism that we were starting to look at, and other groups started talking about very similar things at the same time."}, {"time": 4244, "text": "And then a kind of explosion of interest in meta learning happened in the AI community shortly after that."}, {"time": 4250, "text": "I don't know if we had anything to do with that, but I was gratified to see that a lot of people started talking about meta learning."}, {"time": 4257, "text": "One of the things that I liked about the kind of flavor of meta learning that we were studying was that it didn't require anything special."}, {"time": 4265, "text": "It was just, if you took a system that had some form of memory that the function of which could be shaped by pick URL algorithm, then this would just happen, right?"}, {"time": 4279, "text": "I mean, there are a lot of forms of, there are a lot of meta learning algorithms that have been proposed since then that are fascinating and effective in their domains of application."}, {"time": 4289, "text": "But they're engineered, they're things that somebody had to say, well, gee, if we wanted meta learning to happen, how would we do that?"}, {"time": 4295, "text": "Here's an algorithm that would, but there's something about the kind of meta learning that we were studying that seemed to me special in the sense that it wasn't an algorithm."}, {"time": 4304, "text": "It was just something that automatically happened if you had a system that had memory and it was trained with a reinforcement learning algorithm."}, {"time": 4314, "text": "And in that sense, it can be as meta as it wants to be."}, {"time": 4319, "text": "There's no limit on how abstract the meta learning can get because it's not reliant on a human engineering a particular meta learning algorithm to get there."}, {"time": 4331, "text": "And that's, I also, I don't know, I guess I hope that that's relevant in the brain."}, {"time": 4337, "text": "I think there's a kind of beauty in the ability of this emergent."}, {"time": 4343, "text": "The emergent aspect of it, as opposed to engineered."}, {"time": 4346, "text": "Exactly, it's something that just, it just happens in a sense, in a sense, you can't avoid this happening."}, {"time": 4353, "text": "If you have a system that has memory and the function of that memory is shaped by reinforcement learning, and this system is trained in a series of interrelated tasks, this is gonna happen."}, {"time": 4366, "text": "You can't stop it."}, {"time": 4368, "text": "As long as you have certain properties, maybe like a recurrent structure to."}, {"time": 4372, "text": "You have to have memory."}, {"time": 4373, "text": "It actually doesn't have to be a recurrent neural network."}, {"time": 4375, "text": "One of, a paper that I was honored to be involved with even earlier, used a kind of slot based memory."}, {"time": 4382, "text": "Do you remember the title?"}, {"time": 4383, "text": "Just for people to understand."}, {"time": 4385, "text": "It was Memory Augmented Neural Networks."}, {"time": 4388, "text": "I think it was, I think the title was Meta Learning in Memory Augmented Neural Networks."}, {"time": 4394, "text": "And it was the same exact story."}, {"time": 4397, "text": "If you have a system with memory, here it was a different kind of memory, but the function of that memory is shaped by reinforcement learning."}, {"time": 4409, "text": "Here it was the reads and writes that occurred on this slot based memory."}, {"time": 4416, "text": "This will just happen."}, {"time": 4419, "text": "But this brings us back to something I was saying earlier about the importance of the environment."}, {"time": 4426, "text": "This will happen if the system is being trained in a setting where there's like a sequence of tasks that all share some abstract structure."}, {"time": 4436, "text": "Sometimes we talk about task distributions."}, {"time": 4439, "text": "And that's something that's very obviously true of the world that humans inhabit."}, {"time": 4449, "text": "Like if you just kind of think about what you do every day, you never do exactly the same thing that you did the day before."}, {"time": 4457, "text": "But everything that you do sort of has a family resemblance."}, {"time": 4461, "text": "It shares a structure with something that you did before."}, {"time": 4463, "text": "And so the real world is sort of saturated with this kind of, this property."}, {"time": 4472, "text": "It's endless variety with endless redundancy."}, {"time": 4477, "text": "And that's the setting in which this kind of meta learning happens."}, {"time": 4480, "text": "And it does seem like we're just so good at finding, just like in this emergent phenomena you described, we're really good at finding that redundancy, finding those similarities, the family resemblance."}, {"time": 4493, "text": "Some people call it sort of, what is it?"}, {"time": 4496, "text": "Melanie Mitchell was talking about analogies."}, {"time": 4499, "text": "So we're able to connect concepts together in this kind of way, in this same kind of automated emergent way, which there's so many echoes here of psychology and neuroscience."}, {"time": 4510, "text": "And obviously now with reinforcement learning with recurrent neural networks at the core."}, {"time": 4518, "text": "If we could talk a little bit about dopamine, you have really, you're a part of coauthoring really exciting recent paper, very recent, in terms of release on dopamine and temporal difference learning."}, {"time": 4531, "text": "Can you describe the key ideas of that paper?"}, {"time": 4535, "text": "I mean, one thing I want to pause to do is acknowledge my coauthors on actually both of the papers we're talking about."}, {"time": 4541, "text": "So this dopamine paper."}, {"time": 4542, "text": "I'll just, I'll certainly post all their names."}, {"time": 4545, "text": "Okay, wonderful."}, {"time": 4546, "text": "Yeah, because I'm sort of abashed to be the spokesperson for these papers when I had such amazing collaborators on both."}, {"time": 4555, "text": "So it's a comfort to me to know that you'll acknowledge them."}, {"time": 4558, "text": "Yeah, there's an incredible team there, but yeah."}, {"time": 4560, "text": "Oh yeah, it's such a, it's so much fun."}, {"time": 4563, "text": "And in the case of the dopamine paper, we also collaborated with Naochit at Harvard, who, you know, obviously a paper simply wouldn't have happened without him."}, {"time": 4572, "text": "But so you were asking for like a thumbnail sketch of."}, {"time": 4577, "text": "Yeah, thumbnail sketch or key ideas or, you know, things, the insights that are, you know, continuing on our kind of discussion here between neuroscience and AI."}, {"time": 4586, "text": "Yeah, I mean, this was another, a lot of the work that we've done so far is taking ideas that have bubbled up in AI and, you know, asking the question of whether the brain might be doing something related, which I think on the surface sounds like something that's really mainly of use to neuroscience."}, {"time": 4609, "text": "We see it also as a way of validating what we're doing on the AI side."}, {"time": 4615, "text": "If we can gain some evidence that the brain is using some technique that we've been trying out in our AI work, that gives us confidence that, you know, it may be a good idea, that it'll, you know, scale to rich, complex tasks, that it'll interface well with other mechanisms."}, {"time": 4634, "text": "So you see it as a two way road."}, {"time": 4636, "text": "Just because a particular paper is a little bit focused on from one to the, from AI, from neural networks to neuroscience."}, {"time": 4645, "text": "Ultimately the discussion, the thinking, the productive longterm aspect of it is the two way road nature of the whole interaction."}, {"time": 4653, "text": "Yeah, I mean, we've talked about the notion of a virtuous circle between AI and neuroscience."}, {"time": 4659, "text": "And, you know, the way I see it, that's always been there since the two fields, you know, jointly existed."}, {"time": 4670, "text": "There have been some phases in that history when AI was sort of ahead."}, {"time": 4673, "text": "There are some phases when neuroscience was sort of ahead."}, {"time": 4676, "text": "I feel like given the burst of innovation that's happened recently on the AI side, AI is kind of ahead in the sense that there are all of these ideas that we, you know, for which it's exciting to consider that there might be neural analogs."}, {"time": 4696, "text": "And neuroscience, you know, in a sense has been focusing on approaches to studying behavior that come from, you know, that are kind of derived from this earlier era of cognitive psychology."}, {"time": 4709, "text": "And, you know, so in some ways fail to connect with some of the issues that we're grappling with in AI."}, {"time": 4716, "text": "Like how do we deal with, you know, large, you know, complex environments."}, {"time": 4721, "text": "But, you know, I think it's inevitable that this circle will keep turning and there will be a moment in the not too different distant future when neuroscience is pelting AI researchers with insights that may change the direction of our work."}, {"time": 4738, "text": "Just a quick human question."}, {"time": 4740, "text": "Is it, you have parts of your brain, this is very meta, but they're able to both think about neuroscience and AI."}, {"time": 4750, "text": "You know, I don't often meet people like that."}, {"time": 4754, "text": "So do you think, let me ask a meta plasticity question."}, {"time": 4759, "text": "Do you think a human being can be both good at AI and neuroscience?"}, {"time": 4763, "text": "It's like what, on the team at DeepMind, what kind of human can occupy these two realms?"}, {"time": 4770, "text": "And is that something you see everybody should be doing, can be doing, or is that a very special few can kind of jump?"}, {"time": 4777, "text": "Just like we talk about art history, I would think it's a special person that can major in art history and also consider being a surgeon."}, {"time": 4786, "text": "Otherwise known as a dilettante."}, {"time": 4788, "text": "A dilettante, yeah."}, {"time": 4790, "text": "Easily distracted."}, {"time": 4792, "text": "No, I think it does take a special kind of person to be truly world class at both AI and neuroscience."}, {"time": 4802, "text": "And I am not on that list."}, {"time": 4805, "text": "I happen to be someone whose interest in neuroscience and psychology involved using the kinds of modeling techniques that are now very central in AI."}, {"time": 4820, "text": "And that sort of, I guess, bought me a ticket to be involved in all of the amazing things that are going on in AI research right now."}, {"time": 4829, "text": "I do know a few people who I would consider pretty expert on both fronts, and I won't embarrass them by naming them, but there are exceptional people out there who are like this."}, {"time": 4841, "text": "The one thing that I find is a barrier to being truly world class on both fronts is just the complexity of the technology that's involved in both disciplines now."}, {"time": 4858, "text": "So the engineering expertise that it takes to do truly frontline, hands on AI research is really, really considerable."}, {"time": 4870, "text": "The learning curve of the tools, just like the specifics of just whether it's programming or the kind of tools necessary to collect the data, to manage the data, to distribute, to compute, all that kind of stuff."}, {"time": 4880, "text": "And on the neuroscience, I guess, side, there'll be all different sets of tools."}, {"time": 4884, "text": "Exactly, especially with the recent explosion in neuroscience methods."}, {"time": 4888, "text": "So having said all that, I think the best scenario for both neuroscience and AI is to have people interacting who live at every point on this spectrum from exclusively focused on neuroscience to exclusively focused on the engineering side of AI."}, {"time": 4915, "text": "But to have those people inhabiting a community where they're talking to people who live elsewhere on the spectrum."}, {"time": 4924, "text": "And I may be someone who's very close to the center in the sense that I have one foot in the neuroscience world and one foot in the AI world, and that central position, I will admit, prevents me, at least someone with my limited cognitive capacity, from having true technical expertise in either domain."}, {"time": 4946, "text": "But at the same time, I at least hope that it's worthwhile having people around who can kind of see the connections."}, {"time": 4954, "text": "Yeah, the community, the emergent intelligence of the community when it's nicely distributed is useful."}, {"time": 4964, "text": "So hopefully that, I mean, I've seen that work, I've seen that work out well at DeepMind."}, {"time": 4968, "text": "There are people who, I mean, even if you just focus on the AI work that happens at DeepMind, it's been a good thing to have some people around doing that kind of work whose PhDs are in neuroscience or psychology."}, {"time": 4984, "text": "Every academic discipline has its kind of blind spots and kind of unfortunate obsessions and its metaphors and its reference points, and having some intellectual diversity is really healthy."}, {"time": 5004, "text": "People get each other unstuck, I think."}, {"time": 5008, "text": "I see it all the time at DeepMind."}, {"time": 5010, "text": "And I like to think that the people who bring some neuroscience background to the table are helping with that."}, {"time": 5017, "text": "So one of my probably the deepest passion for me, what I would say, maybe we kind of spoke off mic a little bit about it, but that I think is a blind spot for at least robotics and AI folks is human robot interaction, human agent interaction."}, {"time": 5035, "text": "Maybe do you have thoughts about how we reduce the size of that blind spot?"}, {"time": 5042, "text": "Do you also share the feeling that not enough folks are studying this aspect of interaction?"}, {"time": 5050, "text": "Well, I'm actually pretty intensively interested in this issue now, and there are people in my group who've actually pivoted pretty hard over the last few years from doing more traditional cognitive psychology and cognitive neuroscience to doing experimental work on human agent interaction."}, {"time": 5070, "text": "And there are a couple of reasons that I'm pretty passionately interested in this."}, {"time": 5075, "text": "One is it's kind of the outcome of having thought for a few years now about what we're up to."}, {"time": 5086, "text": "Like what are we doing?"}, {"time": 5089, "text": "Like what is this AI research for?"}, {"time": 5093, "text": "So what does it mean to make the world a better place?"}, {"time": 5097, "text": "I think I'm pretty sure that means making life better for humans."}, {"time": 5102, "text": "And so how do you make life better for humans?"}, {"time": 5105, "text": "That's a proposition that when you look at it carefully and honestly is rather horrendously complicated, especially when the AI systems that you're building are learning systems."}, {"time": 5125, "text": "They're not, you're not programming something that you then introduce to the world and it just works as programmed, like Google Maps or something."}, {"time": 5136, "text": "We're building systems that learn from experience."}, {"time": 5139, "text": "So that typically leads to AI safety questions."}, {"time": 5143, "text": "How do we keep these things from getting out of control?"}, {"time": 5145, "text": "How do we keep them from doing things that harm humans?"}, {"time": 5149, "text": "And I mean, I hasten to say, I consider those hugely important issues."}, {"time": 5154, "text": "And there are large sectors of the research community at DeepMind and of course elsewhere who are dedicated to thinking hard all day, every day about that."}, {"time": 5164, "text": "But there's, I guess I would say a positive side to this too which is to say, well, what would it mean to make human life better?"}, {"time": 5175, "text": "And how can we imagine learning systems doing that?"}, {"time": 5181, "text": "And in talking to my colleagues about that, we reached the initial conclusion that it's not sufficient to philosophize about that."}, {"time": 5190, "text": "You actually have to take into account how humans actually work and what humans want and the difficulties of knowing what humans want and the difficulties that arise when humans want different things."}, {"time": 5207, "text": "And so human agent interaction has become, a quite intensive focus of my group lately."}, {"time": 5216, "text": "If for no other reason that, in order to really address that issue in an adequate way, you have to, I mean, psychology becomes part of the picture."}, {"time": 5227, "text": "Yeah, and so there's a few elements there."}, {"time": 5230, "text": "So if you focus on solving like the, if you focus on the robotics problem, let's say AGI without humans in the picture is you're missing fundamentally the final step."}, {"time": 5242, "text": "When you do want to help human civilization, you eventually have to interact with humans."}, {"time": 5247, "text": "And when you create a learning system, just as you said, that will eventually have to interact with humans, the interaction itself has to be become, has to become part of the learning process."}, {"time": 5260, "text": "So you can't just watch, well, my sense is, it sounds like your sense is you can't just watch humans to learn about humans."}, {"time": 5268, "text": "You have to also be part of the human world."}, {"time": 5270, "text": "You have to interact with humans."}, {"time": 5272, "text": "And I mean, then questions arise that start imperceptibly, but inevitably to slip beyond the realm of engineering."}, {"time": 5282, "text": "So questions like, if you have an agent that can do something that you can't do, under what conditions do you want that agent to do it?"}, {"time": 5293, "text": "So if I have a robot that can play Beethoven sonatas better than any human, in the sense that the sensitivity, the expression is just beyond what any human, do I want to listen to that?"}, {"time": 5316, "text": "Do I want to go to a concert and hear a robot play?"}, {"time": 5318, "text": "These aren't engineering questions."}, {"time": 5321, "text": "These are questions about human preference and human culture."}, {"time": 5325, "text": "Psychology bordering on philosophy."}, {"time": 5327, "text": "Yeah, and then you start asking, well, even if we knew the answer to that, is it our place as AI engineers to build that into these agents?"}, {"time": 5339, "text": "Probably the agents should interact with humans beyond the population of AI engineers and figure out what those humans want."}, {"time": 5348, "text": "And then when you start, I referred this the moment ago, but even that becomes complicated."}, {"time": 5354, "text": "Be quote, what if two humans want different things?"}, {"time": 5359, "text": "And you have only one agent that's able to interact with them and try to satisfy their preferences."}, {"time": 5364, "text": "Then you're into the realm of economics and social choice theory and even politics."}, {"time": 5373, "text": "So there's a sense in which, if you kind of follow what we're doing to its logical conclusion, then it goes beyond questions of engineering and technology and starts to shade imperceptibly into questions about what kind of society do you want?"}, {"time": 5391, "text": "And actually, once that dawned on me, I actually felt, I don't know what the right word is, quite refreshed in my involvement in AI research."}, {"time": 5403, "text": "It was almost like building this kind of stuff is gonna lead us back to asking really fundamental questions about what is this, what's the good life and who gets to decide and bringing in viewpoints from multiple sub communities to help us shape the way that we live."}, {"time": 5427, "text": "There's something, it started making me feel like doing AI research in a fully responsible way, would, could potentially lead to a kind of like cultural renewal."}, {"time": 5442, "text": "Yeah, it's the way to understand human beings at the individual, at the societal level."}, {"time": 5450, "text": "It may become a way to answer all the silly human questions of the meaning of life and all those kinds of things."}, {"time": 5457, "text": "Even if it doesn't give us a way of answering those questions, it may force us back to thinking about them."}, {"time": 5463, "text": "And it might bring, it might restore a certain, I don't know, a certain depth to, or even dare I say spirituality to the way that, to the world, I don't know."}, {"time": 5478, "text": "Maybe that's too grandiose."}, {"time": 5479, "text": "Well, I'm with you."}, {"time": 5481, "text": "I think it's AI will be the philosophy of the 21st century, the way which will open the door."}, {"time": 5489, "text": "I think a lot of AI researchers are afraid to open that door of exploring the beautiful richness of the human agent interaction, human AI interaction."}, {"time": 5499, "text": "I'm really happy that somebody like you have opened that door."}, {"time": 5503, "text": "And one thing I often think about is the usual schema for thinking about human agent interaction as this kind of dystopian, oh, our robot overlords."}, {"time": 5520, "text": "And again, I hasten to say AI safety is hugely important."}, {"time": 5523, "text": "And I'm not saying we shouldn't be thinking about those risks, totally on board for that."}, {"time": 5529, "text": "But there's, having said that, what often follows for me is the thought that there's another kind of narrative that might be relevant, which is, when we think of humans gaining more and more information about human life, the narrative there is usually that they gain more and more wisdom and they get closer to enlightenment and they become more benevolent."}, {"time": 5563, "text": "And the Buddha is like, that's a totally different narrative."}, {"time": 5567, "text": "And why isn't it the case that we imagine that the AI systems that we're creating are just gonna, like, they're gonna figure out more and more about the way the world works and the way that humans interact and they'll become beneficent."}, {"time": 5579, "text": "I'm not saying that will happen."}, {"time": 5580, "text": "I don't honestly expect that to happen without some careful, setting things up very carefully."}, {"time": 5588, "text": "But it's another way things could go, right?"}, {"time": 5591, "text": "And yeah, and I would even push back on that."}, {"time": 5593, "text": "I personally believe that the most trajectories, natural human trajectories will lead us towards progress."}, {"time": 5605, "text": "So for me, there is a kind of sense that most trajectories in AI development will lead us into trouble."}, {"time": 5612, "text": "To me, and we over focus on the worst case."}, {"time": 5617, "text": "It's like in computer science, theoretical computer science has been this focus on worst case analysis."}, {"time": 5622, "text": "There's something appealing to our human mind at some lowest level to be good."}, {"time": 5627, "text": "I mean, we don't wanna be eaten by the tiger, I guess."}, {"time": 5630, "text": "So we wanna do the worst case analysis."}, {"time": 5632, "text": "But the reality is that shouldn't stop us from actually building out all the other trajectories which are potentially leading to all the positive worlds, all the enlightenment."}, {"time": 5644, "text": "There's a book, Enlightenment Now, with Steven Pinker and so on."}, {"time": 5646, "text": "This is looking generally at human progress."}, {"time": 5649, "text": "And there's so many ways that human progress can happen with AI."}, {"time": 5653, "text": "And I think you have to do that research."}, {"time": 5656, "text": "You have to do that work."}, {"time": 5657, "text": "You have to do the, not just the AI safety work of the one worst case analysis."}, {"time": 5662, "text": "How do we prevent that?"}, {"time": 5663, "text": "But the actual tools and the glue and the mechanisms of human AI interaction that would lead to all the positive actions that can go."}, {"time": 5674, "text": "It's a super exciting area, right?"}, {"time": 5676, "text": "Yeah, we should be spending, we should be spending a lot of our time saying what can go wrong."}, {"time": 5682, "text": "I think it's harder to see that there's work to be done to bring into focus the question of what it would look like for things to go right."}, {"time": 5694, "text": "That's not obvious."}, {"time": 5697, "text": "And we wouldn't be doing this if we didn't have the sense there was huge potential, right?"}, {"time": 5701, "text": "We're not doing this for no reason."}, {"time": 5705, "text": "We have a sense that AGI would be a major boom to humanity."}, {"time": 5710, "text": "But I think it's worth starting now, even when our technology is quite primitive, asking exactly what would that mean?"}, {"time": 5719, "text": "We can start now with applications that are already gonna make the world a better place, like solving protein folding."}, {"time": 5725, "text": "I think DeepMind has gotten heavy into science applications lately, which I think is a wonderful, wonderful move for us to be making."}, {"time": 5736, "text": "But when we think about AGI, when we think about building fully intelligent agents that are gonna be able to, in a sense, do whatever they want, we should start thinking about what do we want them to want, right?"}, {"time": 5748, "text": "What kind of world do we wanna live in?"}, {"time": 5752, "text": "That's not an easy question."}, {"time": 5754, "text": "And I think we just need to start working on it."}, {"time": 5756, "text": "And even on the path to, it doesn't have to be AGI, but just intelligent agents that interact with us and help us enrich our own existence on social networks, for example, on recommender systems of various intelligence."}, {"time": 5768, "text": "And there's so much interesting interaction that's yet to be understood and studied."}, {"time": 5772, "text": "And how do you create, I mean, Twitter is struggling with this very idea, how do you create AI systems that increase the quality and the health of a conversation?"}, {"time": 5785, "text": "That's a beautiful human psychology question."}, {"time": 5788, "text": "And how do you do that without deception being involved, without manipulation being involved, maximizing human autonomy?"}, {"time": 5802, "text": "And how do you make these choices in a democratic way?"}, {"time": 5805, "text": "How do we face the, again, I'm speaking for myself here."}, {"time": 5812, "text": "How do we face the fact that it's a small group of people who have the skillset to build these kinds of systems, but what it means to make the world a better place is something that we all have to be talking about."}, {"time": 5829, "text": "Yeah, the world that we're trying to make a better place includes a huge variety of different kinds of people."}, {"time": 5838, "text": "Yeah, how do we cope with that?"}, {"time": 5839, "text": "This is a problem that has been discussed in gory, extensive detail in social choice theory."}, {"time": 5848, "text": "One thing I'm really interested in and one thing I'm really enjoying about the recent direction work has taken in some parts of my team is that, yeah, we're reading the AI literature, we're reading the neuroscience literature, but we've also started reading economics and, as I mentioned, social choice theory, even some political theory, because it turns out that it all becomes relevant."}, {"time": 5870, "text": "It all becomes relevant."}, {"time": 5873, "text": "But at the same time, we've been trying not to write philosophy papers, we've been trying not to write physician papers."}, {"time": 5881, "text": "We're trying to figure out ways of doing actual empirical research that kind of take the first small steps to thinking about what it really means for humans with all of their complexity and contradiction and paradox to be brought into contact with these AI systems in a way that really makes the world a better place."}, {"time": 5905, "text": "Often, reinforcement learning frameworks actually kind of allow you to do that, machine learning, and so that's the exciting thing about AI is it allows you to reduce the unsolvable problem, philosophical problem, into something more concrete that you can get ahold of."}, {"time": 5921, "text": "Yeah, and it allows you to kind of define the problem in some way that allows for growth in the system that's sort of, you know, you're not responsible for the details, right?"}, {"time": 5934, "text": "You say, this is generally what I want you to do, and then learning takes care of the rest."}, {"time": 5939, "text": "Of course, the safety issues arise in that context, but I think also some of these positive issues arise in that context."}, {"time": 5946, "text": "What would it mean for an AI system to really come to understand what humans want?"}, {"time": 5954, "text": "And with all of the subtleties of that, right?"}, {"time": 5958, "text": "You know, humans want help with certain things, but they don't want everything done for them, right?"}, {"time": 5967, "text": "There is, part of the satisfaction that humans get from life is in accomplishing things."}, {"time": 5972, "text": "So if there were devices around that did everything for, you know, I often think of the movie WALLI, right?"}, {"time": 5977, "text": "That's like dystopian in a totally different way."}, {"time": 5979, "text": "It's like, the machines are doing everything for us."}, {"time": 5981, "text": "That's not what we wanted."}, {"time": 5983, "text": "You know, anyway, I find this, you know, this opens up a whole landscape of research that feels affirmative and exciting."}, {"time": 5992, "text": "To me, it's one of the most exciting, and it's wide open."}, {"time": 5996, "text": "We have to, because it's a cool paper, talk about dopamine."}, {"time": 5999, "text": "Oh yeah, okay, so I can."}, {"time": 6001, "text": "We were gonna, I was gonna give you a quick summary."}, {"time": 6004, "text": "Yeah, a quick summary of, what's the title of the paper?"}, {"time": 6009, "text": "I think we called it a distributional code for value in dopamine based reinforcement learning, yes."}, {"time": 6019, "text": "So that's another project that grew out of pure AI research."}, {"time": 6025, "text": "A number of people at DeepMind and a few other places had started working on a new version of reinforcement learning, which was defined by taking something in traditional reinforcement learning and just tweaking it."}, {"time": 6041, "text": "So the thing that they took from traditional reinforcement learning was a value signal."}, {"time": 6046, "text": "So at the center of reinforcement learning, at least most algorithms, is some representation of how well things are going, your expected cumulative future reward."}, {"time": 6057, "text": "And that's usually represented as a single number."}, {"time": 6061, "text": "So if you imagine a gambler in a casino and the gambler's thinking, well, I have this probability of winning such and such an amount of money, and I have this probability of losing such and such an amount of money, that situation would be represented as a single number, which is like the expected, the weighted average of all those outcomes."}, {"time": 6080, "text": "And this new form of reinforcement learning said, well, what if we generalize that to a distributional representation?"}, {"time": 6088, "text": "So now we think of the gambler as literally thinking, well, there's this probability that I'll win this amount of money, and there's this probability that I'll lose that amount of money, and we don't reduce that to a single number."}, {"time": 6097, "text": "And it had been observed through experiments, through just trying this out, that that kind of distributional representation really accelerated reinforcement learning and led to better policies."}, {"time": 6112, "text": "What's your intuition about, so we're talking about rewards."}, {"time": 6116, "text": "So what's your intuition why that is, why does it do that?"}, {"time": 6118, "text": "Well, it's kind of a surprising historical note, at least surprised me when I learned it, that this had been proven to be true."}, {"time": 6127, "text": "This had been tried out in a kind of heuristic way."}, {"time": 6129, "text": "People thought, well, gee, what would happen if we tried?"}, {"time": 6132, "text": "And then it had this, empirically, it had this striking effect."}, {"time": 6137, "text": "And it was only then that people started thinking, well, gee, wait, why?"}, {"time": 6141, "text": "Wait, why?"}, {"time": 6142, "text": "Why is this working?"}, {"time": 6143, "text": "And that's led to a series of studies just trying to figure out why it works, which is ongoing."}, {"time": 6149, "text": "But one thing that's already clear from that research is that one reason that it helps is that it drives richer representation learning."}, {"time": 6159, "text": "So if you imagine two situations that have the same expected value, the same kind of weighted average value, standard deep reinforcement learning algorithms are going to take those two situations and kind of, in terms of the way they're represented internally, they're gonna squeeze them together because the thing that you're trying to represent, which is their expected value, is the same."}, {"time": 6184, "text": "So all the way through the system, things are gonna be mushed together."}, {"time": 6188, "text": "But what if those two situations actually have different value distributions?"}, {"time": 6193, "text": "They have the same average value, but they have different distributions of value."}, {"time": 6199, "text": "In that situation, distributional learning will maintain the distinction between these two things."}, {"time": 6205, "text": "So to make a long story short, distributional learning can keep things separate in the internal representation that might otherwise be conflated or squished together."}, {"time": 6215, "text": "And maintaining those distinctions can be useful when the system is now faced with some other task where the distinction is important."}, {"time": 6223, "text": "If we look at the optimistic and pessimistic dopamine neurons."}, {"time": 6226, "text": "So first of all, what is dopamine?"}, {"time": 6231, "text": "Why is this at all useful to think about in the artificial intelligence sense?"}, {"time": 6240, "text": "But what do we know about dopamine in the human brain?"}, {"time": 6245, "text": "Why is it useful?"}, {"time": 6246, "text": "Why is it interesting?"}, {"time": 6247, "text": "What does it have to do with the prefrontal cortex and learning in general?"}, {"time": 6250, "text": "Yeah, so, well, this is also a case where there's a huge amount of detail and debate."}, {"time": 6259, "text": "But one currently prevailing idea is that the function of this neurotransmitter dopamine resembles a particular component of standard reinforcement learning algorithms, which is called the reward prediction error."}, {"time": 6279, "text": "So I was talking a moment ago about these value representations."}, {"time": 6284, "text": "How do you learn them?"}, {"time": 6285, "text": "How do you update them based on experience?"}, {"time": 6286, "text": "Well, if you made some prediction about a future reward and then you get more reward than you were expecting, then probably retrospectively, you want to go back and increase the value representation that you attached to that earlier situation."}, {"time": 6303, "text": "If you got less reward than you were expecting, you should probably decrement that estimate."}, {"time": 6308, "text": "And that's the process of temporal difference."}, {"time": 6310, "text": "Exactly, this is the central mechanism of temporal difference learning, which is one of several sort of the backbone of our momentarium in NRL."}, {"time": 6320, "text": "And this connection between the reward prediction error and dopamine was made in the 1990s."}, {"time": 6331, "text": "And there's been a huge amount of research that seems to back it up."}, {"time": 6335, "text": "Dopamine may be doing other things, but this is clearly, at least roughly, one of the things that it's doing."}, {"time": 6342, "text": "But the usual idea was that dopamine was representing these reward prediction errors, again, in this like kind of single number way that representing your surprise with a single number."}, {"time": 6356, "text": "And in distributional reinforcement learning, this kind of new elaboration of the standard approach, it's not only the value function that's represented as a single number, it's also the reward prediction error."}, {"time": 6370, "text": "And so what happened was that Will Dabney, one of my collaborators who was one of the first people to work on distributional temporal difference learning, talked to a guy in my group, Zeb Kurt Nelson, who's a computational neuroscientist, and said, gee, you know, is it possible that dopamine might be doing something like this distributional coding thing?"}, {"time": 6393, "text": "And they started looking at what was in the literature, and then they brought me in, and we started talking to Nao Uchida, and we came up with some specific predictions about if the brain is using this kind of distributional coding, then in the tasks that Nao has studied, you should see this, this, this, and this, and that's where the paper came from."}, {"time": 6436, "text": "So yeah, so that's showing, suggesting possibly that dopamine has a really interesting representation scheme in the human brain for its reward signal."}, {"time": 6449, "text": "That's another beautiful example of AI revealing something nice about neuroscience, potentially suggesting possibilities."}, {"time": 6456, "text": "Well, you never know."}, {"time": 6457, "text": "So the minute you publish a paper like that, the next thing you think is, I hope that replicates."}, {"time": 6462, "text": "Like, I hope we see that same thing in other data sets, but of course, several labs now are doing the followup experiments, so we'll know soon."}, {"time": 6470, "text": "But it has been a lot of fun for us to take these ideas from AI and kind of bring them into neuroscience and see how far we can get."}, {"time": 6478, "text": "So we kind of talked about it a little bit, but where do you see the field of neuroscience and artificial intelligence heading broadly?"}, {"time": 6487, "text": "Like, what are the possible exciting areas that you can see breakthroughs in the next, let's get crazy, not just three or five years, but the next 10, 20, 30 years that would make you excited and perhaps you'd be part of?"}, {"time": 6509, "text": "On the neuroscience side, there's a great deal of interest now in what's going on in AI."}, {"time": 6516, "text": "And at the same time, I feel like, so neuroscience, especially the part of neuroscience that's focused on circuits and systems, kind of like really mechanism focused, there's been this explosion in new technology."}, {"time": 6541, "text": "And up until recently, the experiments that have exploited this technology have not involved a lot of interesting behavior."}, {"time": 6553, "text": "And this is for a variety of reasons, one of which is in order to employ some of these technologies, you actually have to, if you're studying a mouse, you have to head fix the mouse."}, {"time": 6563, "text": "In other words, you have to like immobilize the mouse."}, {"time": 6566, "text": "And so it's been tricky to come up with ways of eliciting interesting behavior from a mouse that's restrained in this way, but people have begun to create very interesting solutions to this, like virtual reality environments where the animal can kind of move a track ball."}, {"time": 6583, "text": "And as people have kind of begun to explore what you can do with these technologies, I feel like more and more people are asking, well, let's try to bring behavior into the picture."}, {"time": 6595, "text": "Let's try to like reintroduce behavior, which was supposed to be what this whole thing was about."}, {"time": 6636, "text": "If we can do that, then we might be taking a step closer to this utopian future that we were talking about earlier where there's really no distinction between psychology and neuroscience."}, {"time": 6646, "text": "Neuroscience is about studying the mechanisms that underlie whatever it is the brain is for, and what is the brain for?"}, {"time": 6656, "text": "What is the brain for?"}, {"time": 6656, "text": "It's for behavior."}, {"time": 6658, "text": "I feel like we could maybe take a step toward that now if people are motivated in the right way."}, {"time": 6666, "text": "You also asked about AI."}, {"time": 6668, "text": "So that was a neuroscience question."}, {"time": 6670, "text": "You said neuroscience, that's right."}, {"time": 6672, "text": "And especially places like DeepMind are interested in both branches."}, {"time": 6675, "text": "So what about the engineering of intelligence systems?"}, {"time": 6680, "text": "I think one of the key challenges that a lot of people are seeing now in AI is to build systems that have the kind of flexibility and the kind of flexibility that humans have in two senses."}, {"time": 6698, "text": "One is that humans can be good at many things."}, {"time": 6701, "text": "They're not just expert at one thing."}, {"time": 6704, "text": "And they're also flexible in the sense that they can switch between things very easily and they can pick up new things very quickly because they very ably see what a new task has in common with other things that they've done."}, {"time": 6721, "text": "And that's something that our AI systems just blatantly do not have."}, {"time": 6729, "text": "There are some people who like to argue that deep learning and deep RL are simply wrong for getting that kind of flexibility."}, {"time": 6737, "text": "I don't share that belief, but the simpler fact of the matter is we're not building things yet that do have that kind of flexibility."}, {"time": 6745, "text": "And I think the attention of a large part of the AI community is starting to pivot to that question."}, {"time": 6751, "text": "How do we get that?"}, {"time": 6753, "text": "That's gonna lead to a focus on abstraction."}, {"time": 6758, "text": "It's gonna lead to a focus on what in psychology we call cognitive control, which is the ability to switch between tasks, the ability to quickly put together a program of behavior that you've never executed before, but you know makes sense for a particular set of demands."}, {"time": 6775, "text": "It's very closely related to what the prefrontal cortex does on the neuroscience side."}, {"time": 6781, "text": "So I think it's gonna be an interesting new chapter."}, {"time": 6785, "text": "So that's the reasoning side and cognition side, but let me ask the over romanticized question."}, {"time": 6790, "text": "Do you think we'll ever engineer an AGI system that we humans would be able to love and that would love us back?"}, {"time": 6799, "text": "So have that level and depth of connection?"}, {"time": 6806, "text": "I love that question."}, {"time": 6807, "text": "And it relates closely to things that I've been thinking about a lot lately, in the context of this human AI research."}, {"time": 6816, "text": "There's social psychology research in particular by Susan Fisk at Princeton the department where I used to work, where she dissects human attitudes toward other humans into a sort of two dimensional scheme."}, {"time": 6839, "text": "And one dimension is about ability."}, {"time": 6843, "text": "How able, how capable is this other person?"}, {"time": 6850, "text": "But the other dimension is warmth."}, {"time": 6851, "text": "So you can imagine another person who's very skilled and capable, but is very cold."}, {"time": 6859, "text": "And you wouldn't really like highly, you might have some reservations about that other person."}, {"time": 6866, "text": "But there's also a kind of reservation that we might have about another person who elicits in us or displays a lot of human warmth, but is not good at getting things done."}, {"time": 6877, "text": "We reserve our greatest esteem really for people who are both highly capable and also quite warm."}, {"time": 6887, "text": "That's like the best of the best."}, {"time": 6889, "text": "This isn't a normative statement I'm making."}, {"time": 6893, "text": "This is just an empirical statement."}, {"time": 6895, "text": "This is what humans seem..."}, {"time": 6897, "text": "These are the two dimensions that people seem to kind of like along which people size other people up."}, {"time": 6902, "text": "And in AI research, there's a lot of people who think that humans are very capable, and in AI research, we really focus on this capability thing."}, {"time": 6911, "text": "We want our agents to be able to do stuff."}, {"time": 6913, "text": "This thing can play go at a superhuman level."}, {"time": 6916, "text": "But that's only one dimension."}, {"time": 6918, "text": "What about the other dimension?"}, {"time": 6920, "text": "What would it mean for an AI system to be warm?"}, {"time": 6925, "text": "And I don't know, maybe there are easy solutions here."}, {"time": 6927, "text": "Like we can put a face on our AI systems."}]}, {"title": "Richard Karp: Algorithms and Computational Complexity | Lex Fridman Podcast #111", "id": "KllCrlfLuzs", "quotes": [{"time": 383, "text": "It was much more fun than the earlier mathematics courses which were mostly about arithmetic operations and manipulating them."}, {"time": 392, "text": "Was there something about geometry itself, the slightly visual component of it?"}, {"time": 398, "text": "Oh, yes, absolutely, although I lacked three dimensional vision."}, {"time": 404, "text": "I wasn't very good at three dimensional vision."}, {"time": 407, "text": "You mean being able to visualize three dimensional objects?"}, {"time": 409, "text": "Three dimensional objects or surfaces, hyperplanes and so on."}, {"time": 417, "text": "So there I didn't have an intuition."}, {"time": 421, "text": "But for example, the fact that the sum of the angles of a triangle is 180 degrees is proved convincingly."}, {"time": 436, "text": "And it comes as a surprise that that can be done."}, {"time": 441, "text": "Why is that surprising?"}, {"time": 443, "text": "Well, it is a surprising idea, I suppose."}, {"time": 450, "text": "Why is that proved difficult?"}, {"time": 452, "text": "It's not, that's the point."}, {"time": 454, "text": "It's so easy and yet it's so convincing."}, {"time": 457, "text": "Do you remember what is the proof that it adds up to 180?"}, {"time": 462, "text": "You start at a corner and draw a line parallel to the opposite side."}, {"time": 476, "text": "And that line sort of trisects the angle between the other two sides."}, {"time": 485, "text": "And you get a half plane which has to add up to 180 degrees."}, {"time": 490, "text": "It has to add up to 180 degrees and it consists in the angles by the equality of alternate angles."}, {"time": 504, "text": "You get a correspondence between the angles created along the side of the triangle and the three angles of the triangle."}, {"time": 514, "text": "Has geometry had an impact on when you look into the future of your work with combinatorial algorithms?"}, {"time": 521, "text": "Has it had some kind of impact in terms of, yeah, being able, the puzzles, the visual aspects that were first so compelling to you?"}, {"time": 531, "text": "Not Euclidean geometry particularly."}, {"time": 534, "text": "I think I use tools like linear programming and integer programming a lot."}, {"time": 543, "text": "But those require high dimensional visualization and so I tend to go by the algebraic properties."}, {"time": 553, "text": "Right, you go by the linear algebra and not by the visualization."}, {"time": 559, "text": "Well, the interpretation in terms of, for example, finding the highest point on a polyhedron as in linear programming is motivating."}, {"time": 572, "text": "But again, I don't have the high dimensional intuition that would particularly inform me so I sort of lean on the algebra."}, {"time": 584, "text": "So to linger on that point, what kind of visualization do you do when you're trying to think about, we'll get to combinatorial algorithms, but just algorithms in general."}, {"time": 598, "text": "What's inside your mind when you're thinking about designing algorithms?"}, {"time": 602, "text": "Or even just tackling any mathematical problem?"}, {"time": 609, "text": "Well, I think that usually an algorithm involves a repetition of some inner loop and so I can sort of visualize the distance from the desired solution as iteratively reducing until you finally hit the exact solution."}, {"time": 633, "text": "And try to take steps that get you closer to the."}, {"time": 635, "text": "Try to take steps that get closer and having the certainty of converging."}, {"time": 641, "text": "So it's basically the mechanics of the algorithm is often very simple, but especially when you're trying something out on the computer."}, {"time": 653, "text": "So for example, I did some work on the traveling salesman problem and I could see there was a particular function that had to be minimized and it was fascinating to see the successive approaches to the minimum, to the optimum."}, {"time": 671, "text": "You mean, so first of all, traveling salesman problem is where you have to visit every city without ever, the only ones."}, {"time": 682, "text": "Find the shortest path through a set of cities."}, {"time": 685, "text": "Yeah, which is sort of a canonical standard, a really nice problem that's really hard."}, {"time": 690, "text": "Right, exactly, yes."}, {"time": 692, "text": "So can you say again what was nice about being able to think about the objective function there and maximizing it or minimizing it?"}, {"time": 701, "text": "Well, just that as the algorithm proceeded, you were making progress, continual progress, and eventually getting to the optimum point."}, {"time": 714, "text": "So there's two parts, maybe."}, {"time": 717, "text": "Maybe you can correct me."}, {"time": 718, "text": "First is like getting an intuition about what the solution would look like and or even maybe coming up with a solution and two is proving that this thing is actually going to be pretty good."}, {"time": 730, "text": "What part is harder for you?"}, {"time": 733, "text": "Where's the magic happen?"}, {"time": 734, "text": "Is it in the first sets of intuitions or is it in the messy details of actually showing that it is going to get to the exact solution and it's gonna run at a certain complexity?"}, {"time": 752, "text": "Well, the magic is just the fact that the gap from the optimum decreases monotonically and you can see it happening and various metrics of what's going on are improving all along until finally you hit the optimum."}, {"time": 773, "text": "Perhaps later we'll talk about the assignment problem and I can illustrate."}, {"time": 778, "text": "It illustrates a little better."}, {"time": 780, "text": "Now zooming out again, as you write, Don Knuth has called attention to a breed of people who derive great aesthetic pleasure from contemplating the structure of computational processes."}, {"time": 793, "text": "So Don calls these folks geeks and you write that you remember the moment you realized you were such a person, you were shown the Hungarian algorithm to solve the assignment problem."}, {"time": 805, "text": "So perhaps you can explain what the assignment problem is and what the Hungarian algorithm is."}, {"time": 813, "text": "So in the assignment problem, you have n boys and n girls and you are given the desirability of, or the cost of matching the ith boy with the jth girl for all i and j."}, {"time": 832, "text": "You're given a matrix of numbers and you want to find the one to one matching of the boys with the girls such that the sum of the associated costs will be minimized."}, {"time": 848, "text": "So the best way to match the boys with the girls or men with jobs or any two sets."}, {"time": 856, "text": "Any possible matching is possible or?"}, {"time": 861, "text": "Yeah, all one to one correspondences are permissible."}, {"time": 866, "text": "If there is a connection that is not allowed, then you can think of it as having an infinite cost."}, {"time": 872, "text": "I see, yeah."}, {"time": 874, "text": "So what you do is to depend on the observation that the identity of the optimal assignment or as we call it, the optimal permutation is not changed if you subtract a constant from any row or column of the matrix."}, {"time": 901, "text": "You can see that the comparison between the different assignments is not changed by that."}, {"time": 906, "text": "Because if you decrease a particular row, all the elements of a row by some constant, all solutions decrease by an amount equal to that constant."}, {"time": 921, "text": "So the idea of the algorithm is to start with a matrix of non negative numbers and keep subtracting from rows or from columns."}, {"time": 934, "text": "Subtracting from rows or entire columns in such a way that you subtract the same constant from all the elements of that row or column while maintaining the property that all the elements are non negative."}, {"time": 958, "text": "Simple."}, {"time": 959, "text": "Yeah, and so what you have to do is find small moves which will decrease the total cost while subtracting constants from rows or columns."}, {"time": 977, "text": "And there's a particular way of doing that by computing the kind of shortest path through the elements in the matrix."}, {"time": 984, "text": "And you just keep going in this way until you finally get a full permutation of zeros while the matrix is non negative and then you know that that has to be the cheapest."}, {"time": 998, "text": "Is that as simple as it sounds?"}, {"time": 1002, "text": "So the shortest path of the matrix part."}, {"time": 1005, "text": "Yeah, the simplicity lies in how you find, I oversimplified slightly what you, you will end up subtracting a constant from some rows or columns and adding the same constant back to other rows and columns."}, {"time": 1024, "text": "So as not to reduce any of the zero elements, you leave them unchanged."}, {"time": 1031, "text": "But each individual step modifies several rows and columns by the same amount but overall decreases the cost."}, {"time": 1046, "text": "So there's something about that elegance that made you go aha, this is a beautiful, like it's amazing that something like this, something so simple can solve a problem like this."}, {"time": 1058, "text": "Yeah, it's really cool."}, {"time": 1059, "text": "If I had mechanical ability, I would probably like to do woodworking or other activities where you sort of shape something into something beautiful and orderly and there's something about the orderly systematic nature of that iterative algorithm that is pleasing to me."}, {"time": 1085, "text": "So what do you think about this idea of geeks as Don Knuth calls them?"}, {"time": 1091, "text": "What do you think, is it something specific to a mindset that allows you to discover the elegance in computational processes or is this all of us, can all of us discover this beauty?"}, {"time": 1105, "text": "Were you born this way?"}, {"time": 1109, "text": "I always like to play with numbers."}, {"time": 1110, "text": "I used to amuse myself by multiplying by multiplying four digit decimal numbers in my head and putting myself to sleep by starting with one and doubling the number as long as I could go and testing my memory, my ability to retain the information."}, {"time": 1132, "text": "And I also read somewhere that you wrote that you enjoyed showing off to your friends by I believe multiplying four digit numbers."}, {"time": 1145, "text": "Four digit numbers."}, {"time": 1147, "text": "Yeah, I had a summer job at a beach resort outside of Boston and the other employee, I was the barker at a skee ball game."}, {"time": 1161, "text": "I used to sit at a microphone saying come one, come all, come in and play skee ball, five cents to play, a nickel to win and so on."}, {"time": 1171, "text": "That's what a barker, I wasn't sure if I should know but barker, that's, so you're the charming, outgoing person that's getting people to come in."}, {"time": 1181, "text": "Yeah, well I wasn't particularly charming but I could be very repetitious and loud."}, {"time": 1187, "text": "And the other employees were sort of juvenile delinquents who had no academic bent but somehow I found that I could impress them by performing this mental arithmetic."}, {"time": 1206, "text": "Yeah, there's something to that."}, {"time": 1210, "text": "Some of the most popular videos on the internet is there's a YouTube channel called Numberphile that shows off different mathematical ideas."}, {"time": 1221, "text": "There's still something really profoundly interesting to people about math, the beauty of it."}, {"time": 1227, "text": "Something, even if they don't understand the basic concept even being discussed, there's something compelling to it."}, {"time": 1237, "text": "Any lessons you drew from your early teen years when you were showing off to your friends with the numbers?"}, {"time": 1245, "text": "Like what is it that attracts us to the beauty of mathematics do you think?"}, {"time": 1251, "text": "The general population, not just the computer scientists and mathematicians."}, {"time": 1256, "text": "I think that you can do amazing things."}, {"time": 1259, "text": "You can test whether large numbers are prime."}, {"time": 1264, "text": "You can solve little puzzles about cannibals and missionaries."}, {"time": 1273, "text": "And that's a kind of achievement, it's puzzle solving."}, {"time": 1279, "text": "And at a higher level, the fact that you can do this reasoning that you can prove in an absolutely ironclad way that some of the angles of a triangle is 180 degrees."}, {"time": 1292, "text": "Yeah, it's a nice escape from the messiness of the real world where nothing can be proved."}, {"time": 1298, "text": "So, and we'll talk about it, but sometimes the ability to map the real world into such problems where you can't prove it is a powerful step."}, {"time": 1307, "text": "It's amazing that we can do it."}, {"time": 1308, "text": "Of course, another attribute of geeks is they're not necessarily endowed with emotional intelligence, so they can live in a world of abstractions without having to master the complexities of dealing with people."}, {"time": 1326, "text": "So just to link on the historical note, as a PhD student in 1955, you joined the computational lab at Harvard where Howard Aiken had built the Mark I and the Mark IV computers."}, {"time": 1339, "text": "Just to take a step back into that history, what were those computers like?"}, {"time": 1346, "text": "The Mark IV filled a large room, much bigger than this large office that we were talking in now."}, {"time": 1356, "text": "And you could walk around inside it."}, {"time": 1359, "text": "There were rows of relays."}, {"time": 1363, "text": "You could just walk around the interior and the machine would sometimes fail because of bugs, which literally meant flying creatures landing on the switches."}, {"time": 1379, "text": "So I never used that machine for any practical purpose."}, {"time": 1386, "text": "The lab eventually acquired one of the earlier commercial computers."}, {"time": 1394, "text": "And this was already in the 60s?"}, {"time": 1396, "text": "No, in the mid 50s, or late 50s."}, {"time": 1399, "text": "There was already commercial computers in the... Yeah, we had a Univac, a Univac with 2,000 words of storage."}, {"time": 1407, "text": "And so you had to work hard to allocate the memory properly to also the excess time from one word to another depended on the number of the particular words."}, {"time": 1421, "text": "And so there was an art to sort of arranging the storage allocation to make fetching data rapid."}, {"time": 1431, "text": "Were you attracted to this actual physical world implementation of mathematics?"}, {"time": 1438, "text": "So it's a mathematical machine that's actually doing the math physically?"}, {"time": 1443, "text": "No, not at all."}, {"time": 1444, "text": "I think I was attracted to the underlying algorithms."}, {"time": 1449, "text": "But did you draw any inspiration?"}, {"time": 1452, "text": "So could you have imagined, like what did you imagine was the future of these giant computers?"}, {"time": 1460, "text": "Could you have imagined that 60 years later we'd have billions of these computers all over the world?"}, {"time": 1465, "text": "I couldn't imagine that, but there was a sense in the laboratory that this was the wave of the future."}, {"time": 1476, "text": "In fact, my mother influenced me."}, {"time": 1478, "text": "She told me that data processing was gonna be really big and I should get into it."}, {"time": 1483, "text": "You're a smart woman."}, {"time": 1487, "text": "Yeah, she was a smart woman."}, {"time": 1489, "text": "And there was just a feeling that this was going to change the world, but I didn't think of it in terms of personal computing."}, {"time": 1497, "text": "I had no anticipation that we would be walking around with computers in our pockets or anything like that."}, {"time": 1506, "text": "Did you see computers as tools, as mathematical mechanisms to analyze sort of the theoretical computer science, or as the AI folks, which is an entire other community of dreamers, as something that could one day have human level intelligence?"}, {"time": 1526, "text": "Well, AI wasn't very much on my radar."}, {"time": 1529, "text": "I did read Turing's paper about the..."}, {"time": 1533, "text": "The Turing Test, Computing and Intelligence."}, {"time": 1538, "text": "Yeah, the Turing test."}, {"time": 1540, "text": "What'd you think about that paper?"}, {"time": 1541, "text": "Was that just like science fiction?"}, {"time": 1545, "text": "I thought that it wasn't a very good test because it was too subjective."}, {"time": 1550, "text": "So I didn't feel that the Turing test was really the right way to calibrate how intelligent an algorithm could be."}, {"time": 1561, "text": "But to linger on that, do you think it's, because you've come up with some incredible tests later on, tests on algorithms, right, that are like strong, reliable, robust across a bunch of different classes of algorithms, but returning to this emotional mess that is intelligence, do you think it's possible to come up with a test that's as ironclad as some of the computational complexity work?"}, {"time": 1591, "text": "Well, I think the greater question is whether it's possible to achieve human level intelligence."}, {"time": 1598, "text": "Right, so first of all, let me, at the philosophical level, do you think it's possible to create algorithms that reason and would seem to us to have the same kind of intelligence as human beings?"}, {"time": 1676, "text": "I don't think there's any computer program which surpasses a six month old child in terms of comprehension of the world."}, {"time": 1690, "text": "Do you think this complexity of human intelligence, all the cognitive abilities we have, all the emotion, do you think that could be reduced one day or just fundamentally can it be reduced to a set of algorithms or an algorithm?"}, {"time": 1707, "text": "So can a Turing machine achieve human level intelligence?"}, {"time": 1713, "text": "I am doubtful about that."}, {"time": 1715, "text": "I guess the argument in favor of it is that the human brain seems to achieve what we call intelligence cognitive abilities of different kinds."}, {"time": 1731, "text": "And if you buy the premise that the human brain is just an enormous interconnected set of switches, so to speak, then in principle, you should be able to diagnose what that interconnection structure is like, characterize the individual switches, and build a simulation outside."}, {"time": 1754, "text": "But while that may be true in principle, that cannot be the way we're eventually gonna tackle this problem."}, {"time": 1765, "text": "That does not seem like a feasible way to go about it."}, {"time": 1769, "text": "So there is, however, an existence proof that if you believe that the brain is just a network of neurons operating by rules, I guess you could say that that's an existence proof of the capabilities of a mechanism, but it would be almost impossible to acquire the information unless we got enough insight into the operation of the brain."}, {"time": 1802, "text": "But there's so much mystery there."}, {"time": 1804, "text": "Do you think, what do you make of consciousness, for example, as an example of something we completely have no clue about?"}, {"time": 1813, "text": "The fact that we have this subjective experience."}, {"time": 1815, "text": "Is it possible that this network of, this circuit of switches is able to create something like consciousness?"}, {"time": 1824, "text": "To know its own identity."}, {"time": 1826, "text": "Yeah, to know the algorithm, to know itself."}, {"time": 1830, "text": "To know itself."}, {"time": 1832, "text": "I think if you try to define that rigorously, you'd have a lot of trouble."}, {"time": 1836, "text": "Yeah, that seems to be."}, {"time": 1839, "text": "So I know that there are many who believe that general intelligence can be achieved, and there are even some who feel certain that the singularity will come and we will be surpassed by the machines which will then learn more and more about themselves and reduce humans to an inferior breed."}, {"time": 1868, "text": "I am doubtful that this will ever be achieved."}, {"time": 1872, "text": "Just for the fun of it, could you linger on why, what's your intuition, why you're doubtful?"}, {"time": 1879, "text": "So there are quite a few people that are extremely worried about this existential threat of artificial intelligence, of us being left behind by this super intelligent new species."}, {"time": 1892, "text": "What's your intuition why that's not quite likely?"}, {"time": 1897, "text": "Just because none of the achievements in speech or robotics or natural language processing or creation of flexible computer assistants or any of that comes anywhere near close to that level of cognition."}, {"time": 1920, "text": "What do you think about ideas of sort of, if we look at Moore's Law and exponential improvement to allow us, that would surprise us?"}, {"time": 1929, "text": "Sort of our intuition fall apart with exponential improvement because, I mean, we're not able to kind of, we kind of think in linear improvement."}, {"time": 1938, "text": "We're not able to imagine a world that goes from the Mark I computer to an iPhone X. Yeah."}, {"time": 1947, "text": "So do you think we could be really surprised by the exponential growth?"}, {"time": 1953, "text": "Or on the flip side, is it possible that also intelligence is actually way, way, way, way harder, even with exponential improvement to be able to crack?"}, {"time": 1967, "text": "I don't think any constant factor improvement could change things."}, {"time": 1973, "text": "I mean, given our current comprehension of what cognition requires, it seems to me that multiplying the speed of the switches by a factor of a thousand or a million will not be useful until we really understand the organizational principle behind the network of switches."}, {"time": 2003, "text": "Well, let's jump into the network of switches and talk about combinatorial algorithms if we could."}, {"time": 2009, "text": "Let's step back with the very basics."}, {"time": 2011, "text": "What are combinatorial algorithms?"}, {"time": 2013, "text": "And what are some major examples of problems they aim to solve?"}, {"time": 2018, "text": "A combinatorial algorithm is one which deals with a system of discrete objects that can occupy various states or take on various values from a discrete set of values and need to be arranged or selected in such a way as to achieve some, to minimize some cost function."}, {"time": 2053, "text": "Or to prove the existence of some combinatorial configuration."}, {"time": 2059, "text": "So an example would be coloring the vertices of a graph."}, {"time": 2065, "text": "What's a graph?"}, {"time": 2068, "text": "So it's fun to ask one of the greatest computer scientists of all time the most basic questions in the beginning of most books."}, {"time": 2079, "text": "But for people who might not know, but in general how you think about it, what is a graph?"}, {"time": 2084, "text": "A graph, that's simple."}, {"time": 2087, "text": "It's a set of points, certain pairs of which are joined by lines called edges."}, {"time": 2095, "text": "And they sort of represent the, in different applications represent the interconnections between discrete objects."}, {"time": 2105, "text": "So they could be the interactions, interconnections between switches in a digital circuit or interconnections indicating the communication patterns of a human community."}, {"time": 2119, "text": "And they could be directed or undirected and then as you've mentioned before, might have costs."}, {"time": 2125, "text": "Right, they can be directed or undirected."}, {"time": 2127, "text": "They can be, you can think of them as, if you think, if a graph were representing a communication network, then the edge could be undirected meaning that information could flow along it in both directions or it could be directed with only one way communication."}, {"time": 2146, "text": "A road system is another example of a graph with weights on the edges."}, {"time": 2152, "text": "And then a lot of problems of optimizing the efficiency of such networks or learning about the performance of such networks are the object of combinatorial algorithms."}, {"time": 2171, "text": "So it could be scheduling classes at a school where the vertices, the nodes of the network are the individual classes and the edges indicate the constraints which say that certain classes cannot take place at the same time or certain teachers are available only for certain classes, et cetera."}, {"time": 2196, "text": "Or I talked earlier about the assignment problem of matching the boys with the girls where you have there a graph with an edge from each boy to each girl with a weight indicating the cost."}, {"time": 2213, "text": "Or in logical design of computers, you might want to find a set of so called gates, switches that perform logical functions which can be interconnected to each other and perform logical functions which can be interconnected to realize some function."}, {"time": 2235, "text": "So you might ask how many gates do you need in order for a circuit to give a yes output if at least a given number of its inputs are ones and no if fewer are present."}, {"time": 2262, "text": "My favorite's probably all the work with network flow."}, {"time": 2266, "text": "So anytime you have, I don't know why it's so compelling but there's something just beautiful about it."}, {"time": 2272, "text": "It seems like there's so many applications and communication networks and traffic flow that you can map into these and then you could think of pipes and water going through pipes and you could optimize it in different ways."}, {"time": 2287, "text": "There's something always visually and intellectually compelling to me about it."}, {"time": 2292, "text": "And of course you've done work there."}, {"time": 2295, "text": "Yeah, so there the edges represent channels along which some commodity can flow."}, {"time": 2304, "text": "It might be gas, it might be water, it might be information."}, {"time": 2309, "text": "Maybe supply chain as well like products being."}, {"time": 2313, "text": "Products flowing from one operation to another."}, {"time": 2317, "text": "And the edges have a capacity which is the rate at which the commodity can flow."}, {"time": 2323, "text": "And a central problem is to determine given a network of these channels."}, {"time": 2331, "text": "In this case the edges are communication channels."}, {"time": 2336, "text": "The challenge is to find the maximum rate at which the information can flow along these channels to get from a source to a destination."}, {"time": 2349, "text": "And that's a fundamental combinatorial problem that I've worked on jointly with the scientist Jack Edmonds."}, {"time": 2359, "text": "I think we're the first to give a formal proof that this maximum flow problem through a network can be solved in polynomial time."}, {"time": 2370, "text": "Which I remember the first time I learned that."}, {"time": 2373, "text": "Just learning that in maybe even grad school."}, {"time": 2379, "text": "I don't think it was even undergrad."}, {"time": 2381, "text": "No, algorithm, yeah."}, {"time": 2383, "text": "Do network flows get taught in basic algorithms courses?"}, {"time": 2390, "text": "Yes, probably."}, {"time": 2391, "text": "Okay, so yeah, I remember being very surprised that max flow is a polynomial time algorithm."}, {"time": 2396, "text": "That there's a nice fast algorithm that solves max flow."}, {"time": 2399, "text": "So there is an algorithm named after you in Edmonds."}, {"time": 2406, "text": "The Edmond Carp algorithm for max flow."}, {"time": 2408, "text": "So what was it like tackling that problem and trying to arrive at a polynomial time solution?"}, {"time": 2415, "text": "And maybe you can describe the algorithm."}, {"time": 2417, "text": "Maybe you can describe what's the running time complexity that you showed."}, {"time": 2420, "text": "Yeah, well, first of all, what is a polynomial time algorithm?"}, {"time": 2425, "text": "Perhaps we could discuss that."}, {"time": 2428, "text": "So yeah, let's actually just even, yeah."}, {"time": 2431, "text": "What is algorithmic complexity?"}, {"time": 2434, "text": "What are the major classes of algorithm complexity?"}, {"time": 2438, "text": "So in a problem like the assignment problem or scheduling schools or any of these applications, you have a set of input data which might, for example, be a set of vertices connected by edges with you're given for each edge the capacity of the edge."}, {"time": 2467, "text": "And you have algorithms which are, think of them as computer programs with operations such as addition, subtraction, multiplication, division, comparison of numbers, and so on."}, {"time": 2482, "text": "And you're trying to construct an algorithm based on those operations, which will determine in a minimum number of computational steps the answer to the problem."}, {"time": 2498, "text": "In this case, the computational step is one of those operations."}, {"time": 2503, "text": "And the answer to the problem is let's say the configuration of the network that carries the maximum amount of flow."}, {"time": 2514, "text": "And an algorithm is said to run in polynomial time if as a function of the size of the input, the number of vertices, the number of edges, and so on, the number of basic computational steps grows only as some fixed power of that size."}, {"time": 2535, "text": "A linear algorithm would execute a number of steps linearly proportional to the size."}, {"time": 2544, "text": "Quadratic algorithm would be steps proportional to the square of the size, and so on."}, {"time": 2550, "text": "And algorithms whose running time is bounded by some fixed power of the size are called polynomial algorithms."}, {"time": 2560, "text": "And that's supposed to be relatively fast class of algorithms."}, {"time": 2565, "text": "Theoreticians take that to be the definition of an algorithm being efficient."}, {"time": 2574, "text": "And we're interested in which problems can be solved by such efficient algorithms."}, {"time": 2582, "text": "One can argue whether that's the right definition of efficient because you could have an algorithm whose running time is the 10,000th power of the size of the input, and that wouldn't be really efficient."}, {"time": 2595, "text": "And in practice, it's oftentimes reducing from an N squared algorithm to an N log N or a linear time is practically the jump that you wanna make to allow a real world system to solve a problem."}, {"time": 2611, "text": "Yeah, that's also true because especially as we get very large networks, the size can be in the millions, and then anything above N log N where N is the size would be too much for a practical solution."}, {"time": 2629, "text": "Okay, so that's polynomial time algorithms."}, {"time": 2632, "text": "What other classes of algorithms are there?"}, {"time": 2636, "text": "What's, so that usually they designate polynomials of the letter P. Yeah."}, {"time": 2643, "text": "There's also NP, NP complete and NP hard."}, {"time": 2647, "text": "So can you try to disentangle those by trying to define them simply?"}, {"time": 2654, "text": "Right, so a polynomial time algorithm is one whose running time is bounded by a polynomial in the size of the input."}, {"time": 2664, "text": "Then the class of such algorithms is called P. In the worst case, by the way, we should say, right?"}, {"time": 2672, "text": "So for every case of the problem."}, {"time": 2673, "text": "Yes, that's right, and that's very important that in this theory, when we measure the complexity of an algorithm, we really measure the number of steps, the growth of the number of steps in the worst case."}, {"time": 2688, "text": "So you may have an algorithm that runs very rapidly in most cases, but if there's any case where it gets into a very long computation, that would increase the computational complexity by this measure."}, {"time": 2705, "text": "And that's a very important issue because there are, as we may discuss later, there are some very important algorithms which don't have a good standing from the point of view of their worst case performance and yet are very effective."}, {"time": 2720, "text": "So theoreticians are interested in P, the class of problem solvable in polynomial time."}, {"time": 2727, "text": "Then there's NP, which is the class of problems which may be hard to solve, but when confronted with a solution, you can check it in polynomial time."}, {"time": 2746, "text": "Let me give you an example there."}, {"time": 2749, "text": "So if we look at the assignment problem, so you have N boys, you have N girls, the number of numbers that you need to write down to specify the problem instance is N squared."}, {"time": 2763, "text": "And the question is how many steps are needed to solve it?"}, {"time": 2771, "text": "And Jack Edmonds and I were the first to show that it could be done in time and cubed."}, {"time": 2780, "text": "Earlier algorithms required N to the fourth."}, {"time": 2783, "text": "So as a polynomial function of the size of the input, this is a fast algorithm."}, {"time": 2790, "text": "Now to illustrate the class NP, the question is how long would it take to verify that a solution is optimal?"}, {"time": 2802, "text": "So for example, if the input was a graph, we might want to find the largest clique in the graph or a clique is a set of vertices such that any vertex, each vertex in the set is adjacent to each of the others."}, {"time": 2823, "text": "So the clique is a complete subgraph."}, {"time": 2828, "text": "Yeah, so if it's a Facebook social network, everybody's friends with everybody else, close clique."}, {"time": 2835, "text": "No, that would be what's called a complete graph."}, {"time": 2837, "text": "It would be."}, {"time": 2838, "text": "No, I mean within that clique."}, {"time": 2840, "text": "Within that clique, yeah."}, {"time": 2841, "text": "Yeah, they're all friends."}, {"time": 2845, "text": "So a complete graph is when?"}, {"time": 2847, "text": "Everybody is friendly."}, {"time": 2848, "text": "As everybody is friends with everybody, yeah."}, {"time": 2851, "text": "So the problem might be to determine whether in a given graph there exists a clique of a certain size."}, {"time": 2863, "text": "Now that turns out to be a very hard problem, but if somebody hands you a clique and asks you to check whether it is, hands you a set of vertices and asks you to check whether it's a clique, you could do that simply by exhaustively looking at all of the edges between the vertices and the clique and verifying that they're all there."}, {"time": 2888, "text": "And that's a polynomial time algorithm."}, {"time": 2890, "text": "That's a polynomial."}, {"time": 2891, "text": "So the problem of finding the clique appears to be extremely hard, but the problem of verifying a clique to see if it reaches a target number of vertices is easy to verify."}, {"time": 2911, "text": "So finding the clique is hard, checking it is easy."}, {"time": 2915, "text": "Problems of that nature are called nondeterministic polynomial time algorithms, and that's the class NP."}, {"time": 2925, "text": "And what about NP complete and NP hard?"}, {"time": 2928, "text": "Okay, let's talk about problems where you're getting a yes or no answer rather than a numerical value."}, {"time": 2935, "text": "So either there is a perfect matching of the boys with the girls or there isn't."}, {"time": 2944, "text": "It's clear that every problem in P is also in NP."}, {"time": 2950, "text": "If you can solve the problem exactly, then you can certainly verify the solution."}, {"time": 2957, "text": "On the other hand, there are problems in the class NP."}, {"time": 2963, "text": "This is the class of problems that are easy to check, although they may be hard to solve."}, {"time": 2969, "text": "It's not at all clear that problems in NP lie in P. So for example, if we're looking at scheduling classes at a school, the fact that you can verify when handed a schedule for the school, whether it meets all the requirements, that doesn't mean that you can find the schedule rapidly."}, {"time": 2991, "text": "So intuitively, NP, nondeterministic polynomial checking rather than finding, is going to be harder than, is going to include, is easier."}, {"time": 3006, "text": "Checking is easier, and therefore the class of problems that can be checked appears to be much larger than the class of problems that can be solved."}, {"time": 3014, "text": "And then you keep adding appears to, and sort of these additional words that designate that we don't know for sure yet."}, {"time": 3025, "text": "So the theoretical question, which is considered to be the most central problem in theoretical computer science, or at least computational complexity theory, combinatorial algorithm theory, the question is whether P is equal to NP."}, {"time": 3043, "text": "If P were equal to NP, it would be amazing."}, {"time": 3046, "text": "It would mean that every problem where a solution can be rapidly checked can actually be solved in polynomial time."}, {"time": 3060, "text": "We don't really believe that's true."}, {"time": 3063, "text": "If you're scheduling classes at a school, we expect that if somebody hands you a satisfying schedule, you can verify that it works."}, {"time": 3075, "text": "That doesn't mean that you should be able to find such a schedule."}, {"time": 3078, "text": "So intuitively, NP encompasses a lot more problems than P. So can we take a small tangent and break apart that intuition?"}, {"time": 3090, "text": "So do you, first of all, think that the biggest sort of open problem in computer science, maybe mathematics, is whether P equals NP?"}, {"time": 3100, "text": "Do you think P equals NP, or do you think P is not equal to NP?"}, {"time": 3106, "text": "If you had to bet all your money on it."}, {"time": 3108, "text": "I would bet that P is unequal to NP, simply because there are problems that have been around for centuries and have been studied intensively in mathematics, and even more so in the last 50 years since the P versus NP was stated."}, {"time": 3125, "text": "And no polynomial time algorithms have been found for these easy to check problems."}, {"time": 3133, "text": "So one example is a problem that goes back to the mathematician Gauss, who was interested in factoring large numbers."}, {"time": 3144, "text": "So we know what a number is prime if it cannot be written as the product of two or more numbers unequal to one."}, {"time": 3156, "text": "So if we can factor a number like 91, it's seven times 13."}, {"time": 3163, "text": "But if I give you 20 digit or 30 digit numbers, you're probably gonna be at a loss to have any idea whether they can be factored."}, {"time": 3176, "text": "So the problem of factoring very large numbers does not appear to have an efficient solution."}, {"time": 3186, "text": "But once you have found the factors, expressed the number as a product of two smaller numbers, you can quickly verify that they are factors of the number."}, {"time": 3199, "text": "And your intuition is a lot of people finding, a lot of brilliant people have tried to find algorithms for this one particular problem."}, {"time": 3206, "text": "There's many others like it that are really well studied and it would be great to find an efficient algorithm for."}, {"time": 3213, "text": "Right, and in fact, we have some results that I was instrumental in obtaining following up on work by the mathematician Stephen Cook to show that within the class NP of easy to check problems, easy to check problems, there's a huge number that are equivalent in the sense that either all of them or none of them lie in P. And this happens only if P is equal to NP."}, {"time": 3246, "text": "So if P is unequal to NP, we would also know that virtually all the standard combinatorial problems, virtually all the standard combinatorial problems, if P is unequal to NP, none of them can be solved in polynomial time."}, {"time": 3265, "text": "Can you explain how that's possible to tie together so many problems in a nice bunch that if one is proven to be efficient, then all are?"}, {"time": 3276, "text": "The first and most important stage of progress was a result by Stephen Cook who showed that a certain problem called the satisfiability problem of propositional logic is as hard as any problem in the class P. So the propositional logic problem is expressed in terms of expressions involving the logical operations and, or, and not operating on variables that can be either true or false."}, {"time": 3319, "text": "So an instance of the problem would be some formula involving and, or, and not."}, {"time": 3328, "text": "And the question would be whether there is an assignment of truth values to the variables in the problem that would make the formula true."}, {"time": 3337, "text": "So for example, if I take the formula A or B and A or not B and not A or B and not A or not B and take the conjunction of all four of those so called expressions, you can determine that no assignment of truth values to the variables A and B will allow that conjunction of what are called clauses to be true."}, {"time": 3369, "text": "So that's an example of a formula in propositional logic involving expressions based on the operations and, or, and not."}, {"time": 3383, "text": "That's an example of a problem which is not satisfiable."}, {"time": 3387, "text": "There is no solution that satisfies all of those constraints."}, {"time": 3391, "text": "I mean that's like one of the cleanest and fundamental problems in computer science."}, {"time": 3395, "text": "It's like a nice statement of a really hard problem."}, {"time": 3397, "text": "It's a nice statement of a really hard problem and what Cook showed is that every problem in NP can be reexpressed as an instance of the satisfiability problem."}, {"time": 3416, "text": "So to do that, he used the observation that a very simple abstract machine called the Turing machine can be used to describe any algorithm."}, {"time": 3434, "text": "An algorithm for any realistic computer can be translated into an equivalent algorithm on one of these Turing machines which are extremely simple."}, {"time": 3447, "text": "So a Turing machine, there's a tape and you can Yeah, you have data on a tape and you have basic instructions, a finite list of instructions which say, if you're reading a particular symbol on the tape and you're in a particular state, then you can move to a different state and change the state of the number or the element that you were looking at, the cell of the tape that you were looking at."}, {"time": 3475, "text": "And that was like a metaphor and a mathematical construct that Turing put together to represent all possible computation."}, {"time": 3482, "text": "All possible computation."}, {"time": 3483, "text": "Now, one of these so called Turing machines is too simple to be useful in practice, but for theoretical purposes, we can depend on the fact that an algorithm for any computer can be translated into one that would run on a Turing machine."}, {"time": 3501, "text": "And then using that fact, he could sort of describe any possible non deterministic polynomial time algorithm."}, {"time": 3515, "text": "Any algorithm for a problem in NP could be expressed as a sequence of moves of the Turing machine described in terms of reading a symbol on the tape while you're in a given state and moving to a new state and leaving behind a new symbol."}, {"time": 3540, "text": "And given that fact that any non deterministic polynomial time algorithm can be described by a list of such instructions, you could translate the problem into the language of the satisfiability problem."}, {"time": 3559, "text": "Is that amazing to you, by the way, if you take yourself back when you were first thinking about the space of problems?"}, {"time": 3564, "text": "How amazing is that?"}, {"time": 3566, "text": "It's astonishing."}, {"time": 3567, "text": "When you look at Cook's proof, it's not too difficult to sort of figure out why this is so, but the implications are staggering."}, {"time": 3580, "text": "It tells us that this, of all the problems in NP, all the problems where solutions are easy to check, they can all be rewritten in terms of the satisfiability problem."}, {"time": 3599, "text": "Yeah, it's adding so much more weight to the P equals NP question because all it takes is to show that one algorithm in this class."}, {"time": 3611, "text": "So the P versus NP can be re expressed as simply asking whether the satisfiability problem of propositional logic is solvable in polynomial time."}, {"time": 3623, "text": "But there's more."}, {"time": 3628, "text": "I encountered Cook's paper when he published it in a conference in 1971."}, {"time": 3634, "text": "Yeah, so when I saw Cook's paper and saw this reduction of each of the problems in NP by a uniform method to the satisfiability problem of propositional logic, that meant that the satisfiability problem was a universal combinatorial problem."}, {"time": 3659, "text": "And it occurred to me through experience I had had in trying to solve other combinatorial problems that there were many other problems which seemed to have that universal structure."}, {"time": 3676, "text": "And so I began looking for reductions from the satisfiability to other problems."}, {"time": 3686, "text": "And one of the other problems would be the so called integer programming problem of determining whether there's a solution to a set of linear inequalities involving integer variables."}, {"time": 3708, "text": "Just like linear programming, but there's a constraint that the variables must remain integers."}, {"time": 3713, "text": "In fact, must be the zero or one could only take on those values."}, {"time": 3718, "text": "And that makes the problem much harder."}, {"time": 3720, "text": "Yes, that makes the problem much harder."}, {"time": 3723, "text": "And it was not difficult to show that the satisfiability problem can be restated as an integer programming problem."}, {"time": 3733, "text": "So can you pause on that?"}, {"time": 3735, "text": "Was that one of the first mappings that you tried to do?"}, {"time": 3739, "text": "And how hard is that mapping?"}, {"time": 3740, "text": "You said it wasn't hard to show, but that's a big leap."}, {"time": 3747, "text": "It is a big leap, yeah."}, {"time": 3749, "text": "Well, let me give you another example."}, {"time": 3752, "text": "Another problem in NP is whether a graph contains a clique of a given size."}, {"time": 3762, "text": "And now the question is, can we reduce the propositional logic problem to the problem of whether there's a clique of a certain size?"}, {"time": 3778, "text": "Well, if you look at the propositional logic problem, it can be expressed as a number of clauses, each of which is a, of the form A or B or C, where A is either one of the variables in the problem or the negation of one of the variables."}, {"time": 3802, "text": "And an instance of the propositional logic problem can be rewritten using operations of Boolean logic, can be rewritten as the conjunction of a set of clauses, the AND of a set of ORs, where each clause is a disjunction, an OR of variables or negated variables."}, {"time": 3833, "text": "So the question in the satisfiability problem is whether those clauses can be simultaneously satisfied."}, {"time": 3847, "text": "Now, to satisfy all those clauses, you have to find one of the terms in each clause, which is going to be true in your truth assignment, but you can't make the same variable both true and false."}, {"time": 3864, "text": "So if you have the variable A in one clause and you want to satisfy that clause by making A true, you can't also make the complement of A true in some other clause."}, {"time": 3879, "text": "And so the goal is to make every single clause true if it's possible to satisfy this, and the way you make it true is at least... One term in the clause must be true."}, {"time": 3893, "text": "So now we, to convert this problem to something called the independent set problem, where you're just sort of asking for a set of vertices in a graph such that no two of them are adjacent, sort of the opposite of the clique problem."}, {"time": 3914, "text": "So we've seen that we can now express that as finding a set of terms, one in each clause, without picking both the variable and the negation of that variable, because if the variable is assigned the truth value, the negated variable has to have the opposite truth value."}, {"time": 3989, "text": "And so you get a graph where you have all of these occurrences of variables, you have edges, which mean that you're not allowed to choose both ends of the edge, either because they're in the same clause or they're negations of one another."}, {"time": 4006, "text": "All right, and that's a, first of all, sort of to zoom out, that's a really powerful idea that you can take a graph and connect it to a logic equation somehow, and do that mapping for all possible formulations of a particular problem on a graph."}, {"time": 4027, "text": "I mean, that still is hard for me to believe."}, {"time": 4032, "text": "Yeah, it's hard for me to believe."}, {"time": 4034, "text": "It's hard for me to believe that that's possible."}, {"time": 4037, "text": "That they're, like, what do you make of that, that there's such a union of, there's such a friendship among all these problems across that somehow are akin to combinatorial algorithms, that they're all somehow related?"}, {"time": 4055, "text": "I know it can be proven, but what do you make of it, that that's true?"}, {"time": 4061, "text": "Well, that they just have the same expressive power."}, {"time": 4066, "text": "You can take any one of them and translate it into the terms of the other."}, {"time": 4073, "text": "The fact that they have the same expressive power also somehow means that they can be translatable."}, {"time": 4079, "text": "Right, and what I did in the 1971 paper was to take 21 fundamental problems, the commonly occurring problems of packing, covering, matching, and so forth, lying in the class NP, and show that the satisfiability problem can be reexpressed as any of those, that any of those have the same expressive power."}, {"time": 4110, "text": "And that was like throwing down the gauntlet of saying there's probably many more problems like this."}, {"time": 4116, "text": "Saying that, look, that they're all the same."}, {"time": 4119, "text": "They're all the same, but not exactly."}, {"time": 4123, "text": "They're all the same in terms of whether they are rich enough to express any of the others."}, {"time": 4133, "text": "But that doesn't mean that they have the same computational complexity."}, {"time": 4137, "text": "But what we can say is that either all of these problems or none of them are solvable in polynomial time."}, {"time": 4145, "text": "Yeah, so what is NP completeness and NP hard as classes?"}, {"time": 4151, "text": "Oh, that's just a small technicality."}, {"time": 4154, "text": "So when we're talking about decision problems, that means that the answer is just yes or no."}, {"time": 4161, "text": "There is a clique of size 15 or there's not a clique of size 15."}, {"time": 4166, "text": "On the other hand, an optimization problem would be asking find the largest clique."}, {"time": 4173, "text": "The answer would not be yes or no."}, {"time": 4175, "text": "It would be 15."}, {"time": 4179, "text": "So when you're asking for the, when you're putting a valuation on the different solutions and you're asking for the one with the highest valuation, that's an optimization problem."}, {"time": 4191, "text": "And there's a very close affinity between the two kinds of problems."}, {"time": 4195, "text": "But the counterpart of being the hardest decision problem, the hardest yes, no problem, the counterpart of that is to minimize or maximize an objective function."}, {"time": 4213, "text": "And so a problem that's hardest in the class when viewed in terms of optimization, those are called NP hard rather than NP complete."}, {"time": 4224, "text": "And NP complete is for decision problems."}, {"time": 4228, "text": "So if somebody shows that P equals NP, what do you think that proof will look like if you were to put on yourself, if it's possible to show that as a proof or to demonstrate an algorithm?"}, {"time": 4249, "text": "All I can say is that it will involve concepts that we do not now have and approaches that we don't have."}, {"time": 4256, "text": "Do you think those concepts are out there in terms of inside complexity theory, inside of computational analysis of algorithms?"}, {"time": 4264, "text": "Do you think there's concepts that are totally outside of the box that we haven't considered yet?"}, {"time": 4269, "text": "I think that if there is a proof that P is equal to NP or that P is unequal to NP, it'll depend on concepts that are now outside the box."}, {"time": 4282, "text": "Now, if that's shown either way, P equals NP or P not, well, actually P equals NP, what impact, you kind of mentioned a little bit, but can you linger on it?"}, {"time": 4294, "text": "What kind of impact would it have on theoretical computer science and perhaps software based systems in general?"}, {"time": 4302, "text": "Well, I think it would have enormous impact on the world in either way case."}, {"time": 4309, "text": "If P is unequal to NP, which is what we expect, then we know that for the great majority of the combinatorial problems that come up, since they're known to be NP complete, we're not going to be able to solve them by efficient algorithms."}, {"time": 4327, "text": "However, there's a little bit of hope in that it may be that we can solve most instances."}, {"time": 4336, "text": "All we know is that if a problem is not NP, then it can't be solved efficiently on all instances."}, {"time": 4342, "text": "But basically, if we find that P is unequal to NP, it will mean that we can't expect always to get the optimal solutions to these problems."}, {"time": 4358, "text": "And we have to depend on heuristics that perhaps work most of the time or give us good approximate solutions, but not."}, {"time": 4367, "text": "So we would turn our eye towards the heuristics with a little bit more acceptance and comfort on our hearts."}, {"time": 4377, "text": "Okay, so let me ask a romanticized question."}, {"time": 4382, "text": "What to you is one of the most or the most beautiful combinatorial algorithm in your own life or just in general in the field that you've ever come across or have developed yourself?"}, {"time": 4394, "text": "Oh, I like the stable matching problem or the stable marriage problem very much."}, {"time": 4402, "text": "What's the stable matching problem?"}, {"time": 4406, "text": "Imagine that you want to marry off N boys with N girls."}, {"time": 4417, "text": "And each boy has an ordered list of his preferences among the girls."}, {"time": 4422, "text": "His first choice, his second choice, through her, Nth choice."}, {"time": 4427, "text": "And each girl also has an ordering of the boys, his first choice, second choice, and so on."}, {"time": 4438, "text": "And we'll say that a matching, a one to one matching of the boys with the girls is stable if there are no two couples in the matching such that the boy in the first couple prefers the girl in the second couple to her mate and she prefers the boy to her current mate."}, {"time": 4467, "text": "In other words, if the matching is stable if there is no pair who want to run away with each other leaving their partners behind."}, {"time": 4478, "text": "Gosh, yeah."}, {"time": 4484, "text": "Actually, this is relevant to matching residents with hospitals and some other real life problems, although not quite in the form that I described."}, {"time": 4496, "text": "So it turns out that there is, for any set of preferences, a stable matching exists."}, {"time": 4506, "text": "And moreover, it can be computed by a simple algorithm in which each boy starts making proposals to girls."}, {"time": 4521, "text": "And if the girl receives the proposal, she accepts it tentatively, but she can drop it later if she gets a better proposal from her point of view."}, {"time": 4536, "text": "And the boys start going down their lists proposing to their first, second, third choices until stopping when a proposal is accepted."}, {"time": 4550, "text": "But the girls meanwhile are watching the proposals that are coming into them."}, {"time": 4555, "text": "And the girl will drop her current partner if she gets a better proposal."}, {"time": 4563, "text": "And the boys never go back through the list?"}, {"time": 4566, "text": "They never go back, yeah."}, {"time": 4567, "text": "So once they've been denied."}, {"time": 4571, "text": "They don't try again."}, {"time": 4572, "text": "They don't try again because the girls are always improving their status as they receive better and better proposals."}, {"time": 4582, "text": "The boys are going down their lists starting with their top preferences."}, {"time": 4588, "text": "And one can prove that the process will come to an end where everybody will get matched with somebody and you won't have any pair that want to abscond from each other."}, {"time": 4610, "text": "Do you find the proof or the algorithm itself beautiful?"}, {"time": 4614, "text": "Or is it the fact that with the simplicity of just the two marching, I mean the simplicity of the underlying rule of the algorithm, is that the beautiful part?"}, {"time": 4624, "text": "Both I would say."}, {"time": 4627, "text": "And you also have the observation that you might ask who is better off, the boys who are doing the proposing or the girls who are reacting to proposals."}, {"time": 4637, "text": "And it turns out that it's the boys who are doing the best."}, {"time": 4642, "text": "That is, each boy is doing at least as well as he could do in any other staple matching."}, {"time": 4650, "text": "So there's a sort of lesson for the boys that you should go out and be proactive and make those proposals."}, {"time": 4658, "text": "Go for broke."}, {"time": 4661, "text": "I don't know if this is directly mappable philosophically to our society, but certainly seems like a compelling notion."}, {"time": 4668, "text": "And like you said, there's probably a lot of actual real world problems that this could be mapped to."}, {"time": 4674, "text": "Yeah, well you get complications."}, {"time": 4678, "text": "For example, what happens when a husband and wife want to be assigned to the same hospital?"}, {"time": 4683, "text": "So you have to take those constraints into account."}, {"time": 4690, "text": "And then the problem becomes NP hard."}, {"time": 4695, "text": "Why is it a problem for the husband and wife to be assigned to the same hospital?"}, {"time": 4700, "text": "No, it's desirable."}, {"time": 4702, "text": "Or at least go to the same city."}, {"time": 4704, "text": "So you can't, if you're assigning residents to hospitals."}, {"time": 4709, "text": "And then you have some preferences for the husband and the wife or for the hospitals."}, {"time": 4714, "text": "The residents have their own preferences."}, {"time": 4719, "text": "Residents both male and female have their own preferences."}, {"time": 4724, "text": "The hospitals have their preferences."}, {"time": 4727, "text": "But if resident A, the boy, is going to Philadelphia, then you'd like his wife also to be assigned to a hospital in Philadelphia."}, {"time": 4744, "text": "Which step makes it a NP hard problem that you mentioned?"}, {"time": 4748, "text": "The fact that you have this additional constraint."}, {"time": 4751, "text": "That it's not just the preferences of individuals, but the fact that the two partners to a marriage have to be assigned to the same place."}, {"time": 4762, "text": "I'm being a little dense."}, {"time": 4769, "text": "The perfect matching, no, not the perfect, stable matching is what you referred to."}, {"time": 4773, "text": "That's when two partners are trying to."}, {"time": 4776, "text": "Okay, what's confusing you is that in the first interpretation of the problem, I had boys matching with girls."}, {"time": 4784, "text": "In the second interpretation, you have humans matching with institutions."}, {"time": 4789, "text": "With institutions."}, {"time": 4791, "text": "I, and there's a coupling between within the, gotcha, within the humans."}, {"time": 4796, "text": "Any added little constraint will make it an NP hard problem."}, {"time": 4805, "text": "By the way, the algorithm you mentioned wasn't one of yours or no?"}, {"time": 4807, "text": "No, no, that was due to Gale and Shapley and my friend David Gale passed away before he could get part of a Nobel Prize, but his partner Shapley shared in a Nobel Prize with somebody else for."}, {"time": 4824, "text": "Economics?"}, {"time": 4825, "text": "For economics."}, {"time": 4828, "text": "For ideas stemming from the stable matching idea."}, {"time": 4832, "text": "So you've also have developed yourself some elegant, beautiful algorithms."}, {"time": 4838, "text": "Again, picking your children, so the Robin Karp algorithm for string searching, pattern matching, Edmund Karp algorithm for max flows we mentioned, Hopcroft Karp algorithm for finding maximum cardinality matchings in bipartite graphs."}, {"time": 4852, "text": "Is there ones that stand out to you, ones you're most proud of or just whether it's beauty, elegance, or just being the right discovery development in your life that you're especially proud of?"}, {"time": 4870, "text": "I like the Rabin Karp algorithm because it illustrates the power of randomization."}, {"time": 4877, "text": "So the problem there is to decide whether a given long string of symbols is to decide whether a given long string of symbols from some alphabet contains a given word, whether a particular word occurs within some very much longer word."}, {"time": 4905, "text": "And so the idea of the algorithm is to associate with the word that we're looking for, a fingerprint, some number, or some combinatorial object that describes that word, and then to look for an occurrence of that same fingerprint as you slide along the longer word."}, {"time": 4938, "text": "And what we do is we associate with each word a number."}, {"time": 4943, "text": "So first of all, we think of the letters that occur in a word as the digits of, let's say, decimal or whatever base here, whatever number of different symbols there are."}, {"time": 4960, "text": "That's the base of the numbers, yeah."}, {"time": 4962, "text": "Right, so every word can then be thought of as a number with the letters being the digits of that number."}, {"time": 4970, "text": "And then we pick a random prime number in a certain range, and we take that word viewed as a number, and take the remainder on dividing that number by the prime."}, {"time": 4989, "text": "So coming up with a nice hash function."}, {"time": 4991, "text": "It's a kind of hash function."}, {"time": 4993, "text": "Yeah, it gives you a little shortcut for that particular word."}, {"time": 5002, "text": "Yeah, so that's the..."}, {"time": 5006, "text": "It's very different than other algorithms of its kind that we're trying to do search, string matching."}, {"time": 5015, "text": "Yeah, which usually are combinatorial and don't involve the idea of taking a random fingerprint."}, {"time": 5023, "text": "And doing the fingerprinting has two advantages."}, {"time": 5028, "text": "One is that as we slide along the long word, digit by digit, we keep a window of a certain size, the size of the word we're looking for, and we compute the fingerprint of every stretch of that length."}, {"time": 5047, "text": "And it turns out that just a couple of arithmetic operations will take you from the fingerprint of one part to what you get when you slide over by one position."}, {"time": 5059, "text": "So the computation of all the fingerprints is simple."}, {"time": 5066, "text": "And secondly, it's unlikely if the prime is chosen randomly from a certain range that you will get two of the segments in question having the same fingerprint."}, {"time": 5081, "text": "And so there's a small probability of error which can be checked after the fact, and also the ease of doing the computation because you're working with these fingerprints which are remainder's modulo some big prime."}, {"time": 5095, "text": "So that's the magical thing about randomized algorithms is that if you add a little bit of randomness, it somehow allows you to take a pretty naive approach, a simple looking approach, and allow it to run extremely well."}, {"time": 5110, "text": "So can you maybe take a step back and say what is a randomized algorithm, this category of algorithms?"}, {"time": 5118, "text": "Well, it's just the ability to draw a random number from such, from some range or to associate a random number with some object or to draw that random from some set."}, {"time": 5135, "text": "So another example is very simple if we're conducting a presidential election and we would like to pick the winner."}, {"time": 5152, "text": "In principle, we could draw a random sample of all of the voters in the country."}, {"time": 5159, "text": "And if it was of substantial size, say a few thousand, then the most popular candidate in that group would be very likely to be the correct choice that would come out of counting all the millions of votes."}, {"time": 5175, "text": "And of course we can't do this because first of all, everybody has to feel that his or her vote counted."}, {"time": 5181, "text": "And secondly, we can't really do a purely random sample from that population."}, {"time": 5188, "text": "And I guess thirdly, there could be a tie in which case we wouldn't have a significant difference between two candidates."}, {"time": 5196, "text": "But those things aside, if you didn't have all that messiness of human beings, you could prove that that kind of random picking would come up again."}, {"time": 5203, "text": "You just said random picking would solve the problem with a very low probability of error."}, {"time": 5211, "text": "Another example is testing whether a number is prime."}, {"time": 5215, "text": "So if I wanna test whether 17 is prime, I could pick any number between one and 17, raise it to the 16th power modulo 17, and you should get back the original number."}, {"time": 5235, "text": "That's a famous formula due to Fermat about, it's called Fermat's Little Theorem, that if you take any number a in the range zero through n minus one, and raise it to the n minus 1th power modulo n, you'll get back the number a if a is prime."}, {"time": 5263, "text": "So if you don't get back the number a, that's a proof that a number is not prime."}, {"time": 5268, "text": "And you can show that suitably defined the probability that you will get a value unequaled, you will get a violation of Fermat's result is very high."}, {"time": 5294, "text": "And so this gives you a way of rapidly proving that a number is not prime."}, {"time": 5301, "text": "It's a little more complicated than that because there are certain values of n where something a little more elaborate has to be done, but that's the basic idea."}, {"time": 5312, "text": "Taking an identity that holds for primes, and therefore, if it ever fails on any instance for a non prime, you know that the number is not prime."}, {"time": 5323, "text": "It's a quick choice, a fast choice, fast proof that a number is not prime."}, {"time": 5328, "text": "Can you maybe elaborate a little bit more what's your intuition why randomness works so well and results in such simple algorithms?"}, {"time": 5337, "text": "Well, the example of conducting an election where you could take, in theory, you could take a sample and depend on the validity of the sample to really represent the whole is just the basic fact of statistics, which gives a lot of opportunities."}, {"time": 5357, "text": "And I actually exploited that sort of random sampling idea in designing an algorithm for counting the number of solutions that satisfy a particular formula and propositional logic."}, {"time": 5377, "text": "A particular, so some version of the satisfiability problem?"}, {"time": 5384, "text": "A version of the satisfiability problem."}, {"time": 5387, "text": "Is there some interesting insight that you wanna elaborate on, like what some aspect of that algorithm that might be useful to describe?"}, {"time": 5397, "text": "So you have a collection of formulas and you want to count the number of solutions that satisfy at least one of the formulas."}, {"time": 5420, "text": "And you can count the number of solutions that satisfy any particular one of the formulas, but you have to account for the fact that that solution might be counted many times if it solves more than one of the formulas."}, {"time": 5440, "text": "And so what you do is you sample from the formulas according to the number of solutions that satisfy each individual one."}, {"time": 5453, "text": "In that way, you draw a random solution, but then you correct by looking at the number of formulas that satisfy that random solution and don't double count."}, {"time": 5468, "text": "So you can think of it this way."}, {"time": 5471, "text": "So you have a matrix of zeros and ones and you wanna know how many columns of that matrix contain at least one one."}, {"time": 5482, "text": "And you can count in each row how many ones there are."}, {"time": 5486, "text": "So what you can do is draw from the rows according to the number of ones."}, {"time": 5491, "text": "If a row has more ones, it gets drawn more frequently."}, {"time": 5495, "text": "But then if you draw from that row, you have to go up the column and looking at where that same one is repeated in different rows and only count it as a success or a hit if it's the earliest row that contains the one."}, {"time": 5514, "text": "And that gives you a robust statistical estimate of the total number of columns that contain at least one of the ones."}, {"time": 5524, "text": "So that is an example of the same principle that was used in studying random sampling."}, {"time": 5533, "text": "Another viewpoint is that if you have a phenomenon that occurs almost all the time, then if you sample one of the occasions where it occurs, you're most likely to, and you're looking for an occurrence, a random occurrence is likely to work."}, {"time": 5554, "text": "So that comes up in solving identities, solving algebraic identities."}, {"time": 5562, "text": "You get two formulas that may look very different."}, {"time": 5566, "text": "You wanna know if they're really identical."}, {"time": 5569, "text": "What you can do is just pick a random value and evaluate the formulas at that value and see if they agree."}, {"time": 5578, "text": "And you depend on the fact that if the formulas are distinct, then they're gonna disagree a lot."}, {"time": 5586, "text": "And so therefore, a random choice will exhibit the disagreement."}, {"time": 5592, "text": "If there are many ways for the two to disagree and you only need to find one disagreement, then random choice is likely to yield it."}, {"time": 5602, "text": "And in general, so we've just talked about randomized algorithms, but we can look at the probabilistic analysis of algorithms."}, {"time": 5609, "text": "And that gives us an opportunity to step back and as you said, everything we've been talking about is worst case analysis."}, {"time": 5618, "text": "Could you maybe comment on the usefulness and the power of worst case analysis versus best case analysis, average case, probabilistic?"}, {"time": 5631, "text": "How do we think about the future of theoretical computer science, computer science in the kind of analysis we do of algorithms?"}, {"time": 5639, "text": "Does worst case analysis still have a place, an important place?"}, {"time": 5642, "text": "Or do we want to try to move forward towards kind of average case analysis?"}, {"time": 5647, "text": "And what are the challenges there?"}, {"time": 5649, "text": "So if worst case analysis shows that an algorithm is always good, that's fine."}, {"time": 5657, "text": "If worst case analysis is used to show that the problem, that the solution is not always good, then you have to step back and do something else to ask how often will you get a good solution?"}, {"time": 5676, "text": "Just to pause on that for a second, that's so beautifully put because I think we tend to judge algorithms."}, {"time": 5683, "text": "We throw them in the trash the moment their worst case is shown to be bad."}, {"time": 5688, "text": "Right, and that's unfortunate."}, {"time": 5690, "text": "I think a good example is going back to the satisfiability problem."}, {"time": 5700, "text": "There are very powerful programs called SAT solvers which in practice fairly reliably solve instances with many millions of variables that arise in digital design or in proving programs correct in other applications."}, {"time": 5720, "text": "And so in many application areas, even though satisfiability as we've already discussed is NP complete, the SAT solvers will work so well that the people in that discipline tend to think of satisfiability as an easy problem."}, {"time": 5740, "text": "So in other words, just for some reason that we don't entirely understand, the instances that people formulate in designing digital circuits or other applications are such that satisfiability is not hard to check and even searching for a satisfying solution can be done efficiently in practice."}, {"time": 5771, "text": "And there are many examples."}, {"time": 5773, "text": "For example, we talked about the traveling salesman problem."}, {"time": 5778, "text": "So just to refresh our memories, the problem is you've got a set of cities, you have pairwise distances between cities and you want to find a tour through all the cities that minimizes the total cost of all the edges traversed, all the trips between cities."}, {"time": 5798, "text": "The problem is NP hard, but people using integer programming codes together with some other mathematical tricks can solve geometric instances of the problem where the cities are, let's say points in the plane and get optimal solutions to problems with tens of thousands of cities."}, {"time": 5825, "text": "Actually, it'll take a few computer months to solve a problem of that size, but for problems of size a thousand or two, it'll rapidly get optimal solutions, provably optimal solutions, even though again, we know that it's unlikely that the traveling salesman problem can be solved in polynomial time."}, {"time": 5848, "text": "Are there methodologies like rigorous systematic methodologies for, you said in practice."}, {"time": 5858, "text": "In practice, this algorithm's pretty good."}, {"time": 5860, "text": "Are there systematic ways of saying in practice, this algorithm's pretty good?"}, {"time": 5863, "text": "So in other words, average case analysis."}, {"time": 5866, "text": "Or you've also mentioned that average case kind of requires you to understand what the typical case is, typical instances, and that might be really difficult."}, {"time": 5875, "text": "That's very difficult."}, {"time": 5876, "text": "So after I did my original work on showing all these problems through NP complete, I looked around for a way to shed some positive light on combinatorial algorithms."}, {"time": 5893, "text": "And what I tried to do was to study problems, behavior on the average or with high probability."}, {"time": 5904, "text": "But I had to make some assumptions about what's the probability space?"}, {"time": 5909, "text": "What's the sample space?"}, {"time": 5910, "text": "What do we mean by typical problems?"}, {"time": 5913, "text": "That's very hard to say."}, {"time": 5915, "text": "So I took the easy way out and made some very simplistic assumptions."}, {"time": 5920, "text": "So I assumed, for example, that if we were generating a graph with a certain number of vertices and edges, then we would generate the graph by simply choosing one edge at a time at random until we got the right number of edges."}, {"time": 5936, "text": "That's a particular model of random graphs that has been studied mathematically a lot."}, {"time": 5942, "text": "And within that model, I could prove all kinds of wonderful things, I and others who also worked on this."}, {"time": 5950, "text": "So we could show that we know exactly how many edges there have to be in order for there be a so called Hamiltonian circuit."}, {"time": 5964, "text": "That's a cycle that visits each vertex exactly once."}, {"time": 5971, "text": "We know that if the number of edges is a little bit more than n log n, where n is the number of vertices, then such a cycle is very likely to exist."}, {"time": 5984, "text": "And we can give a heuristic that will find it with high probability."}, {"time": 5988, "text": "And the community in which I was working got a lot of results along these lines."}, {"time": 5998, "text": "But the field tended to be rather lukewarm about accepting these results as meaningful because we were making such a simplistic assumption about the kinds of graphs that we would be dealing with."}, {"time": 6013, "text": "So we could show all kinds of wonderful things, it was a great playground, I enjoyed doing it."}, {"time": 6018, "text": "But after a while, I concluded that it didn't have a lot of bite in terms of the practical application."}, {"time": 6031, "text": "Oh the, okay, so there's too much into the world of toy problems."}, {"time": 6036, "text": "That can, okay."}, {"time": 6036, "text": "But all right, is there a way to find nice representative real world impactful instances of a problem on which demonstrate that an algorithm is good?"}, {"time": 6048, "text": "So this is kind of like the machine learning world, that's kind of what they at his best tries to do is find a data set from like the real world and show the performance, all the conferences are all focused on beating the performance of on that real world data set."}, {"time": 6067, "text": "Is there an equivalent in complexity analysis?"}, {"time": 6071, "text": "Not really, Don Knuth started to collect examples of graphs coming from various places."}, {"time": 6081, "text": "So he would have a whole zoo of different graphs that he could choose from and he could study the performance of algorithms on different types of graphs."}, {"time": 6091, "text": "But there it's really important and compelling to be able to define a class of graphs."}, {"time": 6101, "text": "The actual act of defining a class of graphs that you're interested in, it seems to be a non trivial step if we're talking about instances that we should care about in the real world."}, {"time": 6111, "text": "Yeah, there's nothing available there that would be analogous to the training set for supervised learning where you sort of assume that the world has given you a bunch of examples to work with."}, {"time": 6130, "text": "We don't really have that for problems, for combinatorial problems on graphs and networks."}, {"time": 6138, "text": "You know, there's been a huge growth, a big growth of data sets available."}, {"time": 6143, "text": "Do you think some aspect of theoretical computer science might be contradicting my own question while saying it, but will there be some aspect, an empirical aspect of theoretical computer science which will allow the fact that these data sets are huge, we'll start using them for analysis."}, {"time": 6164, "text": "Sort of, you know, if you want to say something about a graph algorithm, you might take a social network like Facebook and looking at subgraphs of that and prove something about the Facebook graph and be respected, and at the same time, be respected in the theoretical computer science community."}, {"time": 6183, "text": "That hasn't been achieved yet, I'm afraid."}, {"time": 6186, "text": "Is that P equals NP, is that impossible?"}, {"time": 6190, "text": "Is it impossible to publish a successful paper in the theoretical computer science community that shows some performance on a real world data set?"}, {"time": 6202, "text": "Or is that really just those are two different worlds?"}, {"time": 6205, "text": "They haven't really come together."}, {"time": 6207, "text": "I would say that there is a field of experimental algorithmics where people, sometimes they're given some family of examples."}, {"time": 6219, "text": "Sometimes they just generate them at random and they report on performance, but there's no convincing evidence that the sample is representative of anything at all."}, {"time": 6237, "text": "So let me ask, in terms of breakthroughs and open problems, what are the most compelling open problems to you and what possible breakthroughs do you see in the near term in terms of theoretical computer science?"}, {"time": 6253, "text": "Well, there are all kinds of relationships among complexity classes that can be studied, just to mention one thing, I wrote a paper with Richard Lipton in 1979, where we asked the following question."}, {"time": 6316, "text": "And that would, in other words, briefly, what you would say in that case is that the problem has small circuits, polynomial size circuits."}, {"time": 6328, "text": "Now, we know that if P is equal to NP, then, in fact, these problems will have small circuits, but what about the converse?"}, {"time": 6337, "text": "Could a problem have small circuits, meaning that an algorithm tailored to any particular size could work well, and yet not be a polynomial time algorithm?"}, {"time": 6348, "text": "That is, you couldn't write it as a single, uniform algorithm, good for all sizes."}, {"time": 6352, "text": "Just to clarify, small circuits for a problem of particular size, by small circuits for a problem of particular size, or even further constraint, small circuit for a particular... No, for all the inputs of that size."}, {"time": 6370, "text": "Is that a trivial problem for a particular instance?"}, {"time": 6373, "text": "So, coming up, an automated way of coming up with a circuit."}, {"time": 6377, "text": "I guess that's just an answer."}, {"time": 6379, "text": "That would be hard, yeah."}, {"time": 6382, "text": "But there's the existential question."}, {"time": 6385, "text": "Everybody talks nowadays about existential questions."}, {"time": 6389, "text": "Existential challenges."}, {"time": 6395, "text": "You could ask the question, does the Hamiltonian circuit problem have a small circuit for every size, for each size, a different small circuit?"}, {"time": 6411, "text": "In other words, could you tailor solutions depending on the size, and get polynomial size?"}, {"time": 6420, "text": "Even if P is not equal to NP."}, {"time": 6426, "text": "That would be fascinating if that's true."}, {"time": 6428, "text": "Yeah, what we proved is that if that were possible, then something strange would happen in complexity theory."}, {"time": 6438, "text": "Some high level class which I could briefly describe, something strange would happen."}, {"time": 6448, "text": "So, I'll take a stab at describing what I mean."}, {"time": 6451, "text": "Sure, let's go there."}, {"time": 6453, "text": "So, we have to define this hierarchy in which the first level of the hierarchy is P, and the second level is NP."}, {"time": 6464, "text": "And what is NP?"}, {"time": 6465, "text": "NP involves statements of the form there exists a something such that something holds."}, {"time": 6473, "text": "So, for example, there exists the coloring such that a graph can be colored with only that number of colors."}, {"time": 6486, "text": "Or there exists a Hamiltonian circuit."}, {"time": 6489, "text": "There's a statement about this graph."}, {"time": 6490, "text": "Yeah, so the NP deals with statements of that kind, that there exists a solution."}, {"time": 6506, "text": "Now, you could imagine a more complicated expression which says for all x there exists a y such that some proposition holds involving both x and y."}, {"time": 6527, "text": "So, that would say, for example, in game theory, for all strategies for the first player, there exists a strategy for the second player such that the first player wins."}, {"time": 6539, "text": "That would be at the second level of the hierarchy."}, {"time": 6543, "text": "The third level would be there exists an A such that for all B there exists a C, that something holds."}, {"time": 6549, "text": "And you could imagine going higher and higher in the hierarchy."}, {"time": 6552, "text": "And you'd expect that the complexity classes that correspond to those different cases would get bigger and bigger."}, {"time": 6567, "text": "What do you mean by bigger and bigger?"}, {"time": 6569, "text": "They'd get harder and harder to solve."}, {"time": 6570, "text": "Harder and harder, right."}, {"time": 6572, "text": "Harder and harder to solve."}, {"time": 6575, "text": "And what Lipton and I showed was that if NP had small circuits, then this hierarchy would collapse down to the second level."}, {"time": 6586, "text": "In other words, you wouldn't get any more mileage by complicating your expressions with three quantifiers or four quantifiers or any number."}, {"time": 6595, "text": "I'm not sure what to make of that exactly."}, {"time": 6597, "text": "Well, I think it would be evidence that NP doesn't have small circuits because something so bizarre would happen."}, {"time": 6607, "text": "But again, it's only evidence, not proof."}, {"time": 6609, "text": "Well, yeah, that's not even evidence because you're saying P is not equal to NP because something bizarre has to happen."}, {"time": 6619, "text": "I mean, that's proof by the lack of bizarreness in our science."}, {"time": 6626, "text": "But it seems like just the very notion of P equals NP would be bizarre."}, {"time": 6633, "text": "So any way you arrive at, there's no way."}, {"time": 6636, "text": "You have to fight the dragon at some point."}, {"time": 6639, "text": "Well, anyway, for whatever it's worth, that's what we proved."}, {"time": 6645, "text": "So that's a potential space of interesting problems."}, {"time": 6650, "text": "Let me ask you about this other world that of machine learning, of deep learning."}, {"time": 6657, "text": "What's your thoughts on the history and the current progress of machine learning field that's often progressed sort of separately as a space of ideas and space of people than the theoretical computer science or just even computer science world?"}, {"time": 6672, "text": "Yeah, it's really very different from the theoretical computer science world because the results about it, algorithmic performance tend to be empirical."}, {"time": 6685, "text": "It's more akin to the world of SAT solvers where we observe that for formulas arising in practice, the solver does well."}, {"time": 6695, "text": "So it's of that type."}, {"time": 6698, "text": "We're moving into the empirical evaluation of algorithms."}, {"time": 6705, "text": "Now, it's clear that there've been huge successes in image processing, robotics, natural language processing, a little less so, but across the spectrum of game playing is another one."}, {"time": 6720, "text": "There've been great successes and one of those effects is that it's not too hard to become a millionaire if you can get a reputation in machine learning and there'll be all kinds of companies that will be willing to offer you the moon because they think that if they have AI at their disposal, then they can solve all kinds of problems."}, {"time": 6745, "text": "But there are limitations."}, {"time": 6750, "text": "One is that the solutions that you get to supervise learning problems through convolutional neural networks seem to perform amazingly well even for inputs that are outside the training set."}, {"time": 6783, "text": "But we don't have any theoretical understanding of why that's true."}, {"time": 6789, "text": "Secondly, the solutions, the networks that you get are very hard to understand and so very little insight comes out."}, {"time": 6799, "text": "So yeah, yeah, they may seem to work on your training set and you may be able to discover whether your photos occur in a different sample of inputs or not, but we don't really know what's going on."}, {"time": 6817, "text": "We don't know the features that distinguish the photographs or the objects are not easy to characterize."}, {"time": 6829, "text": "Well, it's interesting because you mentioned coming up with a small circuit to solve a particular size problem."}, {"time": 6836, "text": "It seems that neural networks are kind of small circuits."}, {"time": 6839, "text": "In a way, yeah."}, {"time": 6841, "text": "But they're not programs."}, {"time": 6842, "text": "Sort of like the things you've designed are algorithms, programs, algorithms."}, {"time": 6848, "text": "Neural networks aren't able to develop algorithms to solve a problem."}, {"time": 6854, "text": "Well, they are algorithms."}, {"time": 6856, "text": "It's just that they're..."}, {"time": 6858, "text": "But sort of, yeah, it could be a semantic question, but there's not a algorithmic style manipulation of the input."}, {"time": 6873, "text": "Perhaps you could argue there is."}, {"time": 6877, "text": "It feels a lot more like a function of the input."}, {"time": 6880, "text": "Yeah, it's a function."}, {"time": 6881, "text": "It's a computable function."}, {"time": 6883, "text": "Once you have the network, you can simulate it on a given input and figure out the output."}, {"time": 6891, "text": "But if you're trying to recognize images, then you don't know what features of the image are really being determinant of what the circuit is doing."}, {"time": 6909, "text": "The circuit is sort of very intricate and it's not clear that the simple characteristics that you're looking for, the edges of the objects or whatever they may be, they're not emerging from the structure of the circuit."}, {"time": 6929, "text": "Well, it's not clear to us humans, but it's clear to the circuit."}, {"time": 6934, "text": "I mean, it's not clear to sort of the elephant how the human brain works, but it's clear to us humans, we can explain to each other our reasoning and that's why the cognitive science and psychology field exists."}, {"time": 6952, "text": "Maybe the whole thing of being explainable to humans is a little bit overrated."}, {"time": 6957, "text": "Oh, maybe, yeah."}, {"time": 6959, "text": "I guess you can say the same thing about our brain that when we perform acts of cognition, we have no idea how we do it really."}, {"time": 6968, "text": "We do though, I mean, at least for the visual system, the auditory system and so on, we do get some understanding of the principles that they operate under, but for many deeper cognitive tasks, we don't have that."}, {"time": 6986, "text": "Let me ask, you've also been doing work on bioinformatics."}, {"time": 6993, "text": "Does it amaze you that the fundamental building blocks?"}, {"time": 6996, "text": "So if we take a step back and look at us humans, the building blocks used by evolution to build us intelligent human beings is all contained there in our DNA."}, {"time": 7008, "text": "It's amazing and what's really amazing is that we are beginning to learn how to edit DNA, which is very, very, very fascinating."}, {"time": 7025, "text": "This ability to take a sequence, find it in the genome and do something to it."}, {"time": 7038, "text": "I mean, that's really taking our biological systems towards the world of algorithms."}, {"time": 7044, "text": "Yeah, but it raises a lot of questions."}, {"time": 7050, "text": "You have to distinguish between doing it on an individual or doing it on somebody's germline, which means that all of their descendants will be affected."}, {"time": 7060, "text": "So that's like an ethical."}, {"time": 7062, "text": "Yeah, so it raises very severe ethical questions."}, {"time": 7070, "text": "And even doing it on individuals, there's a lot of hubris involved that you can assume that knocking out a particular gene is gonna be beneficial because you don't know what the side effects are going to be."}, {"time": 7088, "text": "So we have this wonderful new world of gene editing, which is very, very impressive and it could be used in agriculture, it could be used in medicine in various ways."}, {"time": 7112, "text": "But very serious ethical problems arise."}, {"time": 7117, "text": "What are to you the most interesting places where algorithms, sort of the ethical side is an exceptionally challenging thing that I think we're going to have to tackle with all of genetic engineering."}, {"time": 7131, "text": "But on the algorithmic side, there's a lot of benefit that's possible."}, {"time": 7135, "text": "So is there areas where you see exciting possibilities for algorithms to help model, optimize, study biological systems?"}, {"time": 7146, "text": "Yeah, I mean, we can certainly analyze genomic data to figure out which genes are operative in the cell and under what conditions and which proteins affect one another, which proteins physically interact."}, {"time": 7167, "text": "We can sequence proteins and modify them."}, {"time": 7172, "text": "Is there some aspect of that that's a computer science problem or is that still fundamentally a biology problem?"}, {"time": 7179, "text": "Well, it's a big data, it's a statistical big data problem for sure."}, {"time": 7237, "text": "You dedicate your 1985 Turing Award lecture to the memory of your father."}, {"time": 7242, "text": "What's your fondest memory of your dad?"}, {"time": 7253, "text": "Seeing him standing in front of a class at the blackboard, drawing perfect circles by hand and showing his ability to attract the interest of the motley collection of eighth grade students that he was teaching."}, {"time": 7279, "text": "When did you get a chance to see him draw the perfect circles?"}, {"time": 7284, "text": "On rare occasions, I would get a chance to sneak into his classroom and observe him."}, {"time": 7293, "text": "And I think he was at his best in the classroom."}, {"time": 7296, "text": "I think he really came to life and had fun, not only teaching, but engaging in chit chat with the students and ingratiating himself with the students."}, {"time": 7313, "text": "And what I inherited from that is the great desire to be a teacher."}, {"time": 7321, "text": "I retired recently and a lot of my former students came, students with whom I had done research or who had read my papers or who had been in my classes."}]}, {"title": "Lisa Feldman Barrett: Counterintuitive Ideas About How the Brain Works | Lex Fridman Podcast #129", "id": "NbdRIVCBqNI", "quotes": [{"time": 361, "text": "Well, I think that has to be true."}, {"time": 363, "text": "If you just look at the range of creatures who've gone extinct."}, {"time": 366, "text": "I mean, if you look at the range of creatures that are on the Earth now, it's incredible."}, {"time": 373, "text": "And it's sort of tried to say that, but it actually is really incredible."}, {"time": 378, "text": "Particularly, I don't know, I mean, animals, there are animals that seem really ordinary until you watch them closely and then they become miraculous, like certain types of birds, which do very miraculous things, build bowers and do dances and all these really funky things that are hard to explain with a standard evolutionary story, although people have them."}, {"time": 403, "text": "Yeah, the birds are weird."}, {"time": 404, "text": "They do a lot for mating purposes."}, {"time": 407, "text": "They have a concept of beauty that I haven't quite, maybe you know much better, but it doesn't seem to fit evolutionary arguments well."}, {"time": 415, "text": "It does fit."}, {"time": 416, "text": "Well, it depends, right?"}, {"time": 417, "text": "So I think you're talking about the evolution of beauty, the book that was written recently by, was it Frum, was that his name?"}, {"time": 426, "text": "Richard Frum, I think, at Yale."}, {"time": 427, "text": "Oh, I'm sorry, no, I didn't know."}, {"time": 429, "text": "Oh, it's a great book."}, {"time": 429, "text": "It's very controversial, though, because he's making the argument that the question about birds and some other animals is why would they engage in such metabolically costly displays when it doesn't improve their fitness at all?"}, {"time": 447, "text": "And the answer that he gives is the answer that Darwin gave, which is sexual selection, not natural selection."}, {"time": 455, "text": "But selection can occur for all kinds of reasons."}, {"time": 457, "text": "There could be artificial selection, which is when we breed animals, right?"}, {"time": 461, "text": "Which is actually how Darwin, that observation helped Darwin come to the idea of natural selection."}, {"time": 469, "text": "And then there's sexual selection, meaning, and the argument that, I think his name is Frum, makes is that it's the pleasure, the selection pressure is the pleasure of female birds."}, {"time": 483, "text": "Which, as a woman, and as someone who studies affect, that's a great answer."}, {"time": 489, "text": "I actually think there probably is natural, I think there is an aspect of natural selection to it, which he maybe hasn't considered."}, {"time": 495, "text": "But you were saying the reason we brought up birds is the life we've got now seems to be quite incredible."}, {"time": 500, "text": "Yeah, so he brought up birds, now seems to be quite incredible."}, {"time": 505, "text": "Yeah, so you peek into the ocean, peek into the sky, there are miraculous creatures."}, {"time": 509, "text": "Look at creatures who've gone extinct."}, {"time": 511, "text": "And in science fiction stories, you couldn't dream up something as interesting."}, {"time": 517, "text": "So my guess is that intelligent life evolves in many different ways, even on this planet."}, {"time": 527, "text": "There isn't one form of intelligence."}, {"time": 528, "text": "There's not one brain that gives you intelligence."}, {"time": 531, "text": "There are lots of different brain structures that can give you intelligence."}, {"time": 534, "text": "So my guess is that the menagerie might not look exactly the way that it looks now, but it would certainly be as interesting."}, {"time": 544, "text": "But if we look at the human brain versus the brains, or whatever you call them, the mechanisms of intelligence in our ancestors, even early ancestors, that you write about, for example, in your new book, what's the difference between the fanciest brain we got, which is the human brain, and the ancestor brains that it came from?"}, {"time": 571, "text": "Yeah, I think it depends on how far back you want to go."}, {"time": 574, "text": "You go all the way back, right, in your book."}, {"time": 578, "text": "So what's the interesting comparison, would you say?"}, {"time": 581, "text": "Well, first of all, I wouldn't say that the human brain is the fanciest brain we've got."}, {"time": 585, "text": "I mean, an octopus brain is pretty different and pretty fancy, and they can do some pretty amazing things that we cannot do."}, {"time": 592, "text": "You know, we can't grow back limbs, we can't change color and texture, we can't comport ourselves and squeeze ourselves into a little crevice."}, {"time": 601, "text": "I mean, these are things that we invent, these are like superhero abilities that we invent in stories, right?"}, {"time": 606, "text": "We can't do any of those things."}, {"time": 608, "text": "And so the human brain is certainly, we can certainly do some things that other animals can't do."}, {"time": 615, "text": "That seemed pretty impressive to us."}, {"time": 616, "text": "But I would say that there are a number of animal brains which seem pretty impressive to me that can do interesting things and really impressive things that we can't do."}, {"time": 628, "text": "I mean, with your work on how emotions are made and so on, you kind of repaint the view of the brain as less glamorous, I suppose, than you would otherwise think."}, {"time": 641, "text": "Or like, I guess you draw a thread that connects all brains together in terms of homeostasis and all that kind of stuff."}, {"time": 650, "text": "Yeah, I wouldn't say that the human brain is any less miraculous than anybody else would say."}, {"time": 657, "text": "I just think that there are other brain structures which are also miraculous."}, {"time": 662, "text": "And I also think that there are a number of things about the human brain which we share with other vertebrates, other animals with backbones."}, {"time": 671, "text": "But that we share these miraculous things."}, {"time": 676, "text": "But we can do some things in abundance."}, {"time": 679, "text": "And we can also do some things with our brains together, working together that other animals can't do."}, {"time": 687, "text": "Or at least we haven't discovered their ability to do it."}, {"time": 691, "text": "Yeah, this social thing."}, {"time": 693, "text": "That's one of the things you write about."}, {"time": 697, "text": "How do you make sense of the fact, like the book Sapiens, and the fact that we're able to kind of connect, like network our brains together like you write about?"}, {"time": 708, "text": "I'll try to stop saying that."}, {"time": 713, "text": "Is that like some kind of feature that's built into there?"}, {"time": 718, "text": "Is that unique to our human brains?"}, {"time": 720, "text": "Like how do you make sense of that?"}, {"time": 722, "text": "What I would say is that our ability to coordinate with each other is not unique to humans."}, {"time": 729, "text": "There are lots of animals who can do that."}, {"time": 734, "text": "But what we do with that coordination is unique because of some of the structural features in our brains."}, {"time": 745, "text": "And it's not that other animals don't have those structural features."}, {"time": 750, "text": "It's we have them in abundance."}, {"time": 753, "text": "So the human brain is not larger than you would expect it to be for a primate of our size."}, {"time": 762, "text": "If you took a chimpanzee and you grew it to the size of a human, that chimpanzee would have a brain that was the size of a human brain."}, {"time": 773, "text": "So there's nothing special about our brain in terms of its size."}, {"time": 777, "text": "There's nothing special about our brain in terms of the basic blueprint that builds our brain from an embryo is the basic blueprint that builds all mammalian brains and maybe even all vertebrate brains."}, {"time": 794, "text": "It's just that because of its size and particularly because of the size of the cerebral cortex, which is a part that people mistakenly attribute to rationality."}, {"time": 807, "text": "Why mistakenly?"}, {"time": 809, "text": "Is that where all the clever stuff happens?"}, {"time": 811, "text": "Well, no, it really isn't."}, {"time": 813, "text": "And I will also say that lots of clever stuff happens in animals who don't have a cerebral cortex."}, {"time": 818, "text": "But because of the size of the cerebral cortex and because of some of the features that are enhanced by that size, that gives us the capacity to do things like build civilizations and coordinate with each other, not just to manipulate the physical world, but to add to it in very profound ways."}, {"time": 845, "text": "Like, other animals can cooperate with each other and use tools."}, {"time": 851, "text": "We draw a line in the sand and we make countries and then we create citizens and immigrants."}, {"time": 860, "text": "But also ideas."}, {"time": 861, "text": "I mean, the countries are centered around the concept of like ideas."}, {"time": 865, "text": "Well, what do you think a citizen is and an immigrant?"}, {"time": 868, "text": "Those are ideas."}, {"time": 870, "text": "Those are ideas that we impose on reality and make them real."}, {"time": 874, "text": "And then they have very, very serious and real effects, physical effects on people."}, {"time": 880, "text": "What do you think about the idea that a bunch of people have written about, Dawkins with memes, which is like ideas are breeding."}, {"time": 888, "text": "Like, we're just like the canvas for ideas to breed in our brains."}, {"time": 894, "text": "So this kind of network that you talk about of brains is just a little canvas for ideas to then compete against each other and so on."}, {"time": 902, "text": "I think as a rhetorical tool, it's cool to think that way."}, {"time": 908, "text": "So I think it was Michael Pollan."}, {"time": 910, "text": "I don't remember if it was in the Botany of Desire, but it was in one of his early books on botany and gardening where he wrote about plants and he wrote about plants utilizing humans for their own evolutionary purposes."}, {"time": 932, "text": "Which is kind of interesting."}, {"time": 933, "text": "You can think about a human gut in a sense as a propagation device for the seeds of tomatoes and what have you."}, {"time": 943, "text": "So it's kind of cool."}, {"time": 945, "text": "So I think rhetorically it's an interesting device, but ideas are, as far as I know, invented by humans, propagated by humans."}, {"time": 958, "text": "So I don't think they're separate from human brains in any way, although it is interesting to think about it that way."}, {"time": 966, "text": "Well, of course, the ideas that are using your brain to communicate and write excellent books."}, {"time": 973, "text": "And they basically picked you, Lisa, as an effective communicator and thereby are winning."}, {"time": 981, "text": "So that's an interesting worldview to think that there's particular aspects of your brain that are conducive to certain sets of ideas and maybe those ideas will win out."}, {"time": 993, "text": "Yeah, I think the way that I would say it really though is that there are many species of animals that influence each other's nervous systems, that regulate each other's nervous systems, and they mainly do it by physical means."}, {"time": 1004, "text": "They do it by chemicals, scent."}, {"time": 1007, "text": "They do it by, so termites and ants and bees, for example, use chemical scents."}, {"time": 1015, "text": "Mammals like rodents use scent and they also use hearing, audition, and that little bit of vision."}, {"time": 1025, "text": "Primates, nonhuman primates add vision, right?"}, {"time": 1029, "text": "And I think everybody uses touch."}, {"time": 1033, "text": "Humans, as far as I know, are the only species that use ideas and words to regulate each other, right?"}, {"time": 1040, "text": "I can text something to someone halfway around the world."}, {"time": 1044, "text": "They don't have to hear my voice."}, {"time": 1046, "text": "They don't have to see my face and I can have an effect on their nervous system."}, {"time": 1050, "text": "And ideas, the ideas that we communicate with words, I mean, words are in a sense a way for us to do mental telepathy with each other, right?"}, {"time": 1059, "text": "I mean, I'm not the first person to say that obviously, but how do I control your heart rate?"}, {"time": 1065, "text": "How do I control your breathing?"}, {"time": 1066, "text": "How do I control your actions with words?"}, {"time": 1069, "text": "It's because those words are communicating ideas."}, {"time": 1074, "text": "So you also write, I think, let's go back to the brain."}, {"time": 1077, "text": "You write that Plato gave us the idea that the human brain has three brains in it, three forces, which is kind of a compelling notion."}, {"time": 1088, "text": "You disagree."}, {"time": 1089, "text": "First of all, what are the three parts of the brain and why do you disagree?"}, {"time": 1096, "text": "So Plato's description of the psyche, which for the moment we'll just assume is the same as a mind."}, {"time": 1104, "text": "There are some scholars who would say a soul, a psyche, a mind, those aren't actually all the same thing in ancient Greece, but we'll just for now gloss over that."}, {"time": 1114, "text": "So Plato's idea was that, and it was a description of really about moral behavior and moral responsibility in humans."}, {"time": 1124, "text": "So the idea was that the human psyche can be described with a metaphor of two horses and a charioteer."}, {"time": 1133, "text": "So one horse for instincts, like feeding and fighting and fleeing and reproduction."}, {"time": 1142, "text": "I'm trying to control my salty language, which apparently they print in England."}, {"time": 1151, "text": "Like I actually tossed off a fairly."}, {"time": 1154, "text": "F, S?"}, {"time": 1155, "text": "Yeah, F, F, yeah."}, {"time": 1157, "text": "I was like, you printed that?"}, {"time": 1159, "text": "I couldn't believe you printed that."}, {"time": 1160, "text": "Without like the stars or whatever?"}, {"time": 1162, "text": "No, no, no, it was full print."}, {"time": 1163, "text": "They also printed a B word and it was really, yeah."}, {"time": 1168, "text": "Well, we should learn something from England."}, {"time": 1172, "text": "Indeed, anyways, but instincts."}, {"time": 1174, "text": "And then the other horse represents emotions."}, {"time": 1177, "text": "And then the charioteer represents rationality, which controls the two beasts, right?"}, {"time": 1183, "text": "And fast forward a couple of centuries and in the middle of the 20th century, there was a very popular view of brain evolution, which suggested that you have this reptilian core, like an inner lizard brain for instincts."}, {"time": 1208, "text": "And then wrapped around that evolved, layer on top of that evolved a limbic system in mammals."}, {"time": 1216, "text": "So the novelty was in a mammalian brain, which bestowed mammals with, gave them emotions, the capacity for emotions."}, {"time": 1224, "text": "And then on top of that evolved a cerebral cortex, which in largely in primates, but very large in humans."}, {"time": 1241, "text": "And it's not that I personally disagree."}, {"time": 1246, "text": "It's that as far back as the 1960s, but really by the 1970s, it was shown pretty clearly with evidence from molecular genetics."}, {"time": 1255, "text": "So peering into cells in the brain to look at the molecular makeup of genes that the brain did not evolve that way."}, {"time": 1265, "text": "And the irony is that the idea of the three layered brain with an inner lizard that hijacks your behavior and causes you to do and say things that you would otherwise not, or maybe that you will regret later."}, {"time": 1287, "text": "That idea became very popular, was popularized by Carl Sagan in The Dragons of Eden, which won a Pulitzer Prize in 1977, when it was already known pretty much in evolutionary neuroscience that the whole narrative was a myth."}, {"time": 1307, "text": "So what the narrative is on the way it evolved, but do you, I mean, again, it's that problem of it being a useful tool of conversation to say like there's a lizard brain and there's a, like if I get overly emotional on Twitter, that was the lizard brain and so on."}, {"time": 1329, "text": "But do you?"}, {"time": 1330, "text": "No, I don't think it's useful."}, {"time": 1331, "text": "I think it's, I think that."}, {"time": 1333, "text": "Is it useful, is it accurate?"}, {"time": 1336, "text": "I don't think it's accurate, and therefore I don't think it's useful."}, {"time": 1340, "text": "So here's what I would say."}, {"time": 1342, "text": "I think that the way I think about philosophy and science is that they are useful tools for living."}, {"time": 1354, "text": "And in order to be useful tools for living, they have to help you make good decisions."}, {"time": 1364, "text": "The triune brain, as it's called, this three layer brain, the idea that your brain is like an already baked cake and the cortex, cerebral cortex, just layered on top like icing."}, {"time": 1374, "text": "The idea, that idea is the foundation of the law in most Western countries."}, {"time": 1383, "text": "It's the foundation of economic theory and it's a great narrative."}, {"time": 1391, "text": "It sort of fits in with what I've been saying fits our intuitions about how we work."}, {"time": 1397, "text": "But it also, in addition to being wrong, it lets people off the hook for nasty behavior."}, {"time": 1409, "text": "And it also suggests that emotions can't be a source of wisdom, which they often are."}, {"time": 1416, "text": "In fact, you would not wanna be around someone who didn't have emotions."}, {"time": 1420, "text": "That would be, that's a psychopath."}, {"time": 1423, "text": "I mean, that's not someone you wanna really have that person deciding your outcome."}, {"time": 1430, "text": "So I guess my, and I could sort of go on and on and on, but my point is that I don't think, I don't think it's a useful narrative in the end."}, {"time": 1443, "text": "What's the more accurate view of the brain that we should use when we're thinking about it?"}, {"time": 1448, "text": "I'll answer that in a second, but I'll say that even our notion of what an instinct is or what a reflex is, it's not quite right, right?"}, {"time": 1456, "text": "So if you look at evidence from ecology, for example, and you look at animals in their ecological context, what you can see is that even things which are reflexes are very context sensitive."}, {"time": 1473, "text": "The brains of those animals are executing so called instinctual actions in a very, very context sensitive way."}, {"time": 1482, "text": "And so even when a physician takes the, it's like the idea of your patellar reflex where they hit your patellar tendon on your knee and you kick, the force with which you kick and so on is influenced by all kinds of things."}, {"time": 1500, "text": "A reflex isn't like a robotic response."}, {"time": 1505, "text": "And so I think a better way is a way that, to think about how brains work, is the way that matches our best understanding, our best scientific understanding, which I think is really cool because it's really counterintuitive."}, {"time": 1524, "text": "So how I came to this view, and I'm certainly not the only one who holds this view."}, {"time": 1528, "text": "I was reading work on neuroanatomy and the view that I'm about to tell you was strongly suggested by that."}, {"time": 1536, "text": "And then I was reading work in signal processing, like by electrical engineering."}, {"time": 1541, "text": "And similarly, the work suggested that, the research suggested that the brain worked this way."}, {"time": 1548, "text": "And I'll just say that I was reading across multiple literatures and they were who don't speak to each other and they were all pointing in this direction."}, {"time": 1556, "text": "And so far, although some of the details are still up for grabs, the general gist I think is I've not come across anything yet which really violates, and I'm looking."}, {"time": 1571, "text": "And so the idea is something like this."}, {"time": 1573, "text": "It's very counterintuitive."}, {"time": 1575, "text": "So the way to describe it is to say that your brain doesn't react to things in the world."}, {"time": 1582, "text": "It's not, to us it feels like our eyes are windows on the world."}, {"time": 1587, "text": "We see things, we hear things, we react to them."}, {"time": 1592, "text": "In psychology, we call this stimulus response."}, {"time": 1594, "text": "So your face, your voice is a stimulus to me."}, {"time": 1599, "text": "I receive input and then I react to it."}, {"time": 1604, "text": "And I might react very automatically, system one."}, {"time": 1610, "text": "But I also might execute some control where I maybe stop myself from saying something or doing something and in a more reflective way execute a different action, right?"}, {"time": 1624, "text": "That's system two."}, {"time": 1626, "text": "The way the brain works though, is it's predicting all the time."}, {"time": 1630, "text": "It's constantly talking to itself, constantly talking to your body, and it's constantly predicting what's going on in the body and what's going on in the world and making predictions and the information from your body and from the world really confirm or correct those predictions."}, {"time": 1652, "text": "So fundamentally the thing that the brain does most of the time is just like talking to itself and predicting stuff about the world, not like this dumb thing that just senses and responds, senses and responds."}, {"time": 1666, "text": "Yeah, so the way to think about it is like this."}, {"time": 1668, "text": "You know, your brain is trapped in a dark silent box."}, {"time": 1672, "text": "Yeah, that's very romantic of you."}, {"time": 1676, "text": "Which is your skull."}, {"time": 1677, "text": "And the only information that it receives from your body and from the world, right, is through the senses, through the sense organs, your eyes, your ears, and you have sensory data that comes from your body that you're largely unaware of to your brain, which we call interoceptive, as opposed to exteroceptive, which is the world around you."}, {"time": 1703, "text": "But your brain is receiving sense data continuously, which are the effect of some set of causes."}, {"time": 1717, "text": "Your brain doesn't know the cause of these sense data."}, {"time": 1721, "text": "It's only receiving the effects of those causes, which are the data themselves."}, {"time": 1726, "text": "And so your brain has to solve what philosophers call an inverse inference problem."}, {"time": 1731, "text": "How do you know, when you only receive the effects of something, how do you know what caused those effects?"}, {"time": 1736, "text": "So when there's a flash of light or a change in air pressure or a tug somewhere in your body, how does your brain know what caused those events so that it knows what to do next to keep you alive and well?"}, {"time": 1755, "text": "And the answer is that your brain has one other source of information available to it, which is your past experience."}, {"time": 1763, "text": "It can reconstitute in its wiring past experiences, and it can combine those past experiences in novel ways."}, {"time": 1774, "text": "And so we have lots of names for this in psychology."}, {"time": 1779, "text": "We call it memory."}, {"time": 1780, "text": "We call it perceptual inference."}, {"time": 1782, "text": "We call it simulation."}, {"time": 1785, "text": "It's also, we call it concepts or conceptual knowledge."}, {"time": 1789, "text": "We call it prediction."}, {"time": 1790, "text": "Basically, if we were to stop the world right now, stop time, your brain is in a state, and it's representing what it believes is going on in your body and in the world."}, {"time": 1808, "text": "And it's predicting what will happen next based on past experience, right?"}, {"time": 1813, "text": "Probabilistically, what's most likely to happen."}, {"time": 1815, "text": "And it begins to prepare your action, and it begins to prepare your experience based, so it's anticipating the sense data it's going to receive."}, {"time": 1835, "text": "And then when those data come in, they either confirm that prediction and your action executes because the plan's already been made, or there's some sense data that your brain didn't predict that's unexpected, and your brain takes it in."}, {"time": 1854, "text": "We say encodes it."}, {"time": 1855, "text": "We have a fancy name for that."}, {"time": 1857, "text": "We call it learning."}, {"time": 1858, "text": "Your brain learns, and it updates its storehouse of knowledge, which we call an internal model so that you can predict better next time."}, {"time": 1868, "text": "And it turns out that predicting and correcting, predicting and correcting is a much more metabolically efficient way to run a system than constantly reacting all the time."}, {"time": 1878, "text": "Because if you're constantly reacting, it means you can't anticipate in any way what's going to happen."}, {"time": 1884, "text": "And so the amount of uncertainty that you have to deal with is overwhelming to a nervous system."}, {"time": 1890, "text": "Metabolically costly."}, {"time": 1893, "text": "And so what is a reflex?"}, {"time": 1894, "text": "A reflex is when your brain doesn't check against the sense data."}, {"time": 1900, "text": "That the potential cost to you is so great, maybe because your life is threatened, that your brain makes the prediction and executes the action without checking."}, {"time": 1915, "text": "Yeah, so but prediction is still at the core."}, {"time": 1917, "text": "That's a beautiful vision of the brain."}, {"time": 1918, "text": "I wonder, from almost an AI perspective, but just computationally, is the brain just mostly a prediction machine then?"}, {"time": 1927, "text": "Like is the perception just the nice little feature added on top?"}, {"time": 1932, "text": "Like the, both the integration of new perceptual information."}, {"time": 1937, "text": "I wonder how big of an impressive system is that relative to just the big predictor, model constructor."}, {"time": 1945, "text": "Well, I think that we can look to evolution for that, for one answer, which is that when you go back, you know, 550 million years, give or take, we, you know, the world was populated by creatures, really ruled by creatures without brains."}, {"time": 1963, "text": "And, you know, that's a biological statement, not a political statement."}, {"time": 1968, "text": "Really ruled with creatures with a."}, {"time": 1969, "text": "You calling dinosaurs dumb?"}, {"time": 1970, "text": "You're talking about like."}, {"time": 1971, "text": "Oh no, I'm not talking about dinosaurs, honey."}, {"time": 1973, "text": "I'm talking way back, further back than that."}, {"time": 1976, "text": "Really these, there are these little, little creatures called amphioxus, which is the modern, it's a, or a lancet."}, {"time": 1984, "text": "That's the modern animal, but it's an animal that scientists believe is very similar to our common, the common ancestor that we share with invertebrates because, basically because of the tracing back, the molecular genetics and cells."}, {"time": 2003, "text": "And that animal had no brain."}, {"time": 2007, "text": "It had some cells that would later turn into a brain, but in that animal, there's no brain, but that animal also had no head, and it had no eyes, and it had no ears, and it had really, really no senses for the most part."}, {"time": 2020, "text": "It had very, very limited sense of touch."}, {"time": 2023, "text": "It had an eye spot for, not for seeing, but just for entraining to circadian rhythm, to light and dark."}, {"time": 2032, "text": "And it had no hearing."}, {"time": 2034, "text": "It had a vestibular cell so that it could keep upright in the water."}, {"time": 2038, "text": "So at the time, we're talking evolutionary scale here, so give or take some 100 million years or something, but at the time, what are the vertebrate, like when a backbone evolved and a brain evolved, a full brain, that was when a head evolved with sense organs and when that's when your viscera, like internal systems involved."}, {"time": 2063, "text": "So the answer I would say is that senses, motor neuroscientists, people who study the control of motor behavior believe that senses evolved in the service of motor action."}, {"time": 2081, "text": "So the idea is that, like what triggered, what was the big evolutionary change?"}, {"time": 2089, "text": "What was the big pressure that made it useful to have eyes and ears and a visual system and an auditory system and a brain basically?"}, {"time": 2099, "text": "And the answer that is commonly entertained right now is that it was predation, that when at some point an animal evolved that deliberately ate another animal and this launched an arms race between predators and prey and it became very useful to have senses, right?"}, {"time": 2124, "text": "So these little amphioxies don't really have, they're not aware of their environment very much, really."}, {"time": 2136, "text": "And so being able to look up ahead and ask yourself, should I eat that or will it eat me is a very useful thing."}, {"time": 2153, "text": "So the idea is that sense data is not there for consciousness."}, {"time": 2161, "text": "It didn't evolve for the purposes of consciousness."}, {"time": 2163, "text": "It didn't evolve for the purposes of experiencing anything."}, {"time": 2168, "text": "It evolved to be in the service of motor control."}, {"time": 2173, "text": "However, maybe it's useful."}, {"time": 2178, "text": "This is why scientists sometimes avoid questions about why things evolved."}, {"time": 2185, "text": "This is what philosophers call this teleology."}, {"time": 2188, "text": "You might be able to say something about how things evolve, but not necessarily why."}, {"time": 2195, "text": "We don't really know the why."}, {"time": 2198, "text": "That's all speculation."}, {"time": 2200, "text": "But the why is kind of nice here."}, {"time": 2202, "text": "The interesting thing is, that was the first element of social interaction is, am I gonna eat you or are you gonna eat me?"}, {"time": 2210, "text": "And for that, it's useful to be able to see each other, sense each other."}, {"time": 2217, "text": "That's kind of fascinating that there was a time when life didn't eat each other."}, {"time": 2223, "text": "Or they did by accident."}, {"time": 2224, "text": "So an amphioxus, for example, it kind of like gyrates in the water, and then it plants itself in the sand like a living blade of grass, and then it just filters whatever comes into its mouth."}, {"time": 2241, "text": "So it is eating, but it's not actively hunting."}, {"time": 2245, "text": "And when the concentration of food decreases, the amphioxus can sense this."}, {"time": 2255, "text": "And so it basically wriggles itself randomly to some other spot, which probabilistically will have more food than wherever it is."}, {"time": 2266, "text": "So it's not guiding its actions on the basis of, we would say there's no real intentional action in the traditional sense."}, {"time": 2278, "text": "Speaking of intentional action, and if the brain is, if prediction is indeed a core component of the brain, let me ask you a question that scientists also hate is about free will."}, {"time": 2291, "text": "So how does, do you think about free will much?"}, {"time": 2295, "text": "How does that fit into this, into your view of the brain?"}, {"time": 2299, "text": "Why does it feel like we make decisions in this world?"}, {"time": 2304, "text": "This is a hard, we scientists hate this, this is a hard question we don't have the answer to."}, {"time": 2308, "text": "Have you taken a side?"}, {"time": 2310, "text": "I think I have."}, {"time": 2310, "text": "Do you have free will?"}, {"time": 2311, "text": "I think I have taken a side, but I don't put a lot of stock in my own intuitions or anybody's intuitions about the cause of things."}, {"time": 2321, "text": "One thing we know about the brain for sure is that the brain creates experiences for us."}, {"time": 2326, "text": "My brain creates experiences for me, your brain creates experiences for you in a way that lures you to believe that those experiences actually reveals the way that it works, but it doesn't."}, {"time": 2339, "text": "So you don't trust your own intuition about free will?"}, {"time": 2341, "text": "Not really, not really."}, {"time": 2343, "text": "No, I mean, no, but I am also somewhat persuaded by, I think Dan Dennett wrote at one point, the philosopher Dan Dennett wrote at one point that it's, I can't say it as eloquently as him, but people obviously have free will, they are obviously making choices."}, {"time": 2362, "text": "So there is this observation that we're not robots and we can do some things like a little more sophisticated than an amphioxus."}, {"time": 2375, "text": "I would say that your predictions, your internal model that's running right now, your ability to understand the sounds that I'm making and attach them to ideas is based on the fact that you have years of experience knowing what these sounds mean in a particular statistical pattern, right?"}, {"time": 2401, "text": "I mean, that's how you can understand the words that are coming out of my mouth."}, {"time": 2406, "text": "Right, I think we did this once before too, didn't we?"}, {"time": 2409, "text": "When we were."}, {"time": 2410, "text": "I don't know, I would have to access my memory module."}, {"time": 2412, "text": "I think when I was in your, when I."}, {"time": 2414, "text": "The class thing?"}, {"time": 2415, "text": "Yeah, I think we did it just like that actually, so bravo."}, {"time": 2418, "text": "Wow, I have to go look back to the tape."}, {"time": 2421, "text": "Yeah, anyways, the idea though is that your brain is using past experience and it can use past experience in, so it's remembering, but you're not consciously remembering."}, {"time": 2436, "text": "It's basically re implementing prior experiences as a way of predicting what's gonna happen next."}, {"time": 2442, "text": "And it can do something called conceptual combination, which is it can take bits and pieces of the past and combine it in new ways."}, {"time": 2450, "text": "So you can experience and make sense of things that you've never encountered before because you've encountered something similar to them."}, {"time": 2464, "text": "And so a brain in a sense is not just, doesn't just contain information."}, {"time": 2473, "text": "It is information gaining, meaning it can create new information by this generative process."}, {"time": 2479, "text": "So in a sense, you could say, well, that maybe that's a source of free will."}, {"time": 2483, "text": "But I think really where free will comes from or the kind of free will that I think is worth having a conversation about involves cultivating experiences for yourself that change your internal model."}, {"time": 2500, "text": "When you were born and you were raised in a particular context, your brain wired itself to your surroundings, to your physical surroundings and also to your social surroundings."}, {"time": 2513, "text": "So you were handed an internal model basically."}, {"time": 2518, "text": "But when you grow up, the more control you have over where you are and what you do, you can cultivate new experiences for yourself."}, {"time": 2531, "text": "And those new experiences can change your internal model."}, {"time": 2536, "text": "And you can actually practice those experiences in a way that makes them automatic, meaning it makes it easier for the brain, your brain to make them again."}, {"time": 2548, "text": "And I think that that is something like what you would call free will."}, {"time": 2555, "text": "You aren't responsible for the model that you were handed, that someone, your caregivers cultivated a model in your brain."}, {"time": 2567, "text": "You're not responsible for that model, but you are responsible for the one you have now."}, {"time": 2572, "text": "You can choose, you choose what you expose yourself to."}, {"time": 2576, "text": "You choose how you spend your time."}, {"time": 2579, "text": "Not everybody has choice over everything, but everybody has a little bit of choice."}, {"time": 2584, "text": "And so I think that is something that I think is arguably called free will."}, {"time": 2593, "text": "Yeah, the ripple effects of the billions of decisions you make early on in life are so great that even if it's not, even if it's like all deterministic, just the amount of possibilities that are created and then the focusing on those possibilities into a single trajectory, that somewhere within that, that's free will."}, {"time": 2625, "text": "Even if it's all deterministic, that might as well be just the number of choices that are possible and the fact that you just make one trajectory to those set of choices seems to be like something like they'll be called free will."}, {"time": 2639, "text": "But it's still kind of sad to think like there doesn't seem to be a place where there's magic in there, where it is all just the computer."}, {"time": 2648, "text": "Well, there's lots of magic, I would say, so far, because we don't really understand how all of this is exactly played out at a, I mean, scientists are working hard and disagree about some of the details under the hood of what I just described, but I think there's quite a bit of magic actually."}, {"time": 2671, "text": "And also there's also stochastic firing of, neurons don't, they're not purely digital in the sense that there is, there's also analog communication between neurons, not just digital."}, {"time": 2688, "text": "So it's not just with firing of axons."}, {"time": 2691, "text": "And some of that, there are other ways to communicate."}, {"time": 2695, "text": "And also there's noise in the system and the noise is there for a really good reason."}, {"time": 2704, "text": "And that is the more variability there is, the more potential there is for your brain to be able to be information bearing."}, {"time": 2715, "text": "So basically, there are some animals that have clusters of cells."}, {"time": 2722, "text": "The only job is to inject noise."}, {"time": 2725, "text": "You know, into their neural patterns."}, {"time": 2727, "text": "So maybe noise is the source of free will."}, {"time": 2730, "text": "So you can think about stochasticity or noise as a source of free will, or you can think of conceptual combination as a source of free will."}, {"time": 2742, "text": "You can certainly think about cultivating, you know, you can't reach back into your past and change your past."}, {"time": 2751, "text": "You know, people try by psychotherapy and so on, but what you can do is change your present, which becomes your past."}, {"time": 2763, "text": "So one way to think about it is that you're continuously, this is a colleague of mine, a friend of mine said, so what you're saying is that people are continually cultivating their past."}, {"time": 2775, "text": "And I was like, that's very poetic."}, {"time": 2777, "text": "Yes, you are continually cultivating your past as a means of controlling your future."}, {"time": 2786, "text": "So you think, yeah, I guess the construction of the mental model that you use for prediction ultimately contains within it your perception of the past, like the way you interpret the past, or even just the entirety of your narrative about the past."}, {"time": 2801, "text": "So you're constantly rewriting the story of your past."}, {"time": 2808, "text": "That's one poetic and also just awe inspiring."}, {"time": 2811, "text": "What about the other thing you talk about?"}, {"time": 2815, "text": "You've mentioned about sensory perception as a thing that like is just, you have to infer about the sources of the thing that you have perceived through your senses."}, {"time": 2827, "text": "So let me ask another ridiculous question."}, {"time": 2832, "text": "Is anything real at all?"}, {"time": 2834, "text": "Like, how do we know it's real?"}, {"time": 2835, "text": "How do we make sense of the fact that just like you said, there's this brain sitting alone in the darkness trying to perceive the world."}, {"time": 2843, "text": "How do we know that the world is out there to be perceived?"}, {"time": 2847, "text": "Yeah, so I don't think that you should be asking questions like that without passing a joint."}, {"time": 2852, "text": "Right, no, for sure."}, {"time": 2853, "text": "I actually did before this, so I apologize."}, {"time": 2856, "text": "Okay, no, well, that's okay."}, {"time": 2857, "text": "You apologize for not sharing."}, {"time": 2859, "text": "So, I mean, here's what I would say."}, {"time": 2861, "text": "What I would say is that the reason why we can be pretty sure that there's a there there is that the structure of the information in the world, what we call statistical regularities in sights and sounds and so on, and the structure of the information that comes from your body, it's not random stuff."}, {"time": 2880, "text": "There's a structure to it."}, {"time": 2882, "text": "There's a spatial structure and a temporal structure."}, {"time": 2885, "text": "And that spatial and temporal structure wires your brain."}, {"time": 2888, "text": "So an infant brain is not a miniature adult brain."}, {"time": 2893, "text": "It's a brain that is waiting for wiring instructions from the world."}, {"time": 2898, "text": "And it must receive those wiring instructions to develop in a typical way."}, {"time": 2903, "text": "So, for example, when a newborn is born, when a newborn is born, when a baby is born, the baby can't see very well because the visual system in that baby's brain is not complete."}, {"time": 2922, "text": "The retina of your eye, which actually is part of your brain, has to be stimulated with photons of light."}, {"time": 2929, "text": "If it's not, the baby won't develop normally to be able to see in a neurotypical way."}, {"time": 2936, "text": "Same thing is true for hearing."}, {"time": 2937, "text": "The same thing is true really for all your senses."}, {"time": 2940, "text": "So the point is that the physical world the physical world, the sense data from the physical world wires your brain so that you have an internal model of that world so that your brain can predict well to keep you alive and well and allow you to thrive."}, {"time": 2959, "text": "That's fascinating that the brain is waiting for a very specific kind of set of instructions from the world."}, {"time": 2967, "text": "Like not the specific, but a very specific kind of instructions."}, {"time": 2971, "text": "So scientists call it expectable input."}, {"time": 2975, "text": "The brain needs some input in order to develop normally."}, {"time": 2979, "text": "And we are genetically, as I say in the book, we have the kind of nature that requires nurture."}, {"time": 2988, "text": "We can't develop normally without sensory input from the world and from the body."}, {"time": 2995, "text": "And what's really interesting about humans and some other animals too, but really seriously in humans, is the input that we need is not just physical."}, {"time": 3008, "text": "It's also social."}, {"time": 3010, "text": "We, in order for an infant, a human infant to develop normally, that infant needs eye contact, touch."}, {"time": 3019, "text": "It needs certain types of smells."}, {"time": 3022, "text": "It needs to be cuddled."}, {"time": 3024, "text": "It needs, right?"}, {"time": 3025, "text": "So without social input, that infant's brain will not wire itself in a neurotypical way."}, {"time": 3038, "text": "And again, I would say there are lots of cultural patterns of caring for an infant."}, {"time": 3046, "text": "It's not like the infant has to be cared for in one way."}, {"time": 3050, "text": "Whatever the social environment is for an infant, that will be reflected in that infant's internal model."}, {"time": 3059, "text": "So we have lots of different cultures, lots of different ways of rearing children."}, {"time": 3062, "text": "And that's an advantage for our species, although we don't always experience it that way."}, {"time": 3067, "text": "That is an advantage for our species."}, {"time": 3070, "text": "But if you just feed and water a baby without all the extra social doodads, what you get is a profoundly impaired human."}, {"time": 3085, "text": "Yeah, but nevertheless, you're kind of saying that the physical reality has a consistent thing throughout that keeps feeding these set of sensory information that our brains are constructed for."}, {"time": 3103, "text": "Yeah, the cool thing though, is that if you change the consistency, if you change the statistical regularities, so prediction error, your brain can learn it."}, {"time": 3112, "text": "It's expensive for your brain to learn it."}, {"time": 3113, "text": "And it takes a while for the brain to get really automated with it."}, {"time": 3117, "text": "But you had a wonderful conversation with David Edelman, who just published a book about this and gave lots and lots of really very, very cool examples."}, {"time": 3127, "text": "Some of which I actually discussed in How Emotions Were Made, but not obviously to the extent that he did in his book."}, {"time": 3134, "text": "It's a fascinating book, but it speaks to the point that your internal model is always under construction."}, {"time": 3143, "text": "And therefore, you always can modify your experience."}, {"time": 3150, "text": "I wonder what the limits are."}, {"time": 3151, "text": "Like if we put it on Mars or if we put it in virtual reality or if we sit at home during a pandemic and we spend most of our day on Twitter and TikTok, like I wonder where the breaking point, like the limitations of the brain's capacity to properly continue wiring itself."}, {"time": 3174, "text": "Well, I think what I would say is that there are different ways to specify your question, right?"}, {"time": 3180, "text": "Like one way to specify it would be the way that David phrases it, which is can we create a new sense?"}, {"time": 3189, "text": "Like can we create a new sensory modality?"}, {"time": 3194, "text": "How hard would that be?"}, {"time": 3195, "text": "What are the limits in doing that?"}, {"time": 3199, "text": "But another way to say it is what happens to a brain when you remove some of those statistical regularities, right?"}, {"time": 3208, "text": "Like what happens to an adult brain when you remove some of the statistical patterns that were there and they're not there anymore?"}, {"time": 3217, "text": "Are you talking about in the environment or in the actual like you remove eyesight, for example?"}, {"time": 3223, "text": "Well, either way."}, {"time": 3224, "text": "I mean, basically one way to limit the inputs to your brain are to stay home and protect yourself."}, {"time": 3233, "text": "Another way is to put someone in solitary confinement."}, {"time": 3237, "text": "Another way is to stick them in a nursing home."}, {"time": 3242, "text": "Well, not all nursing homes, but there are some, right?"}, {"time": 3246, "text": "Which really are where people are somewhat impoverished in the interactions and the variety of sensory stimulation that they get."}, {"time": 3257, "text": "Another way is that you lose a sense, right?"}, {"time": 3260, "text": "But the point is I think that the human brain really likes variety, to say it in a sort of Cartesian way."}, {"time": 3276, "text": "Variety is a good thing for a brain."}, {"time": 3279, "text": "And there are risks that you take when you restrict what you expose yourself to."}, {"time": 3294, "text": "Yeah, you know, there's all this talk of diversity."}, {"time": 3296, "text": "The brain loves it to the fullest definition and degree of diversity."}, {"time": 3301, "text": "Yeah, I mean, I would say the only thing, basically human brains thrive on diversity."}, {"time": 3307, "text": "The only place where we seem to have difficulty with diversity is with each other, right?"}, {"time": 3313, "text": "But who wants to eat the same food every day?"}, {"time": 3316, "text": "You never would."}, {"time": 3317, "text": "Who wants to wear the same clothes every day?"}, {"time": 3319, "text": "I mean, my husband, if you ask him to close his eyes, he won't be able to tell you what he's wearing, right?"}, {"time": 3324, "text": "He'll buy seven shirts of exactly the same style in different colors, but they are in different colors, right?"}, {"time": 3330, "text": "It's not like he's wearing."}, {"time": 3331, "text": "How would you then explain my brain, which is terrified of choice and therefore wear the same thing every time?"}, {"time": 3339, "text": "Well, you must be getting your diversity."}, {"time": 3341, "text": "Well, first of all, you are a fairly sharp dresser, so there is that, but you're getting some reinforcement for dressing the way you do."}, {"time": 3348, "text": "But no, your brain must get diversity in other places."}, {"time": 3352, "text": "But I think we, you know, so the two most expensive things your brain can do, metabolically speaking, is move your body and learn."}, {"time": 3364, "text": "And learn something new."}, {"time": 3368, "text": "So novelty, that is diversity, right, comes at a cost, a metabolic cost, but it's a cost, it's an investment that gives returns."}, {"time": 3379, "text": "And in general, people vary in how much they like novelty, unexpected things."}, {"time": 3384, "text": "Some people really like it."}, {"time": 3386, "text": "Some people really don't like it, and there's everybody in between."}, {"time": 3389, "text": "But in general, we don't eat the same thing every day."}, {"time": 3392, "text": "We don't usually do exactly the same thing in exactly the same order, in exactly the same place every day."}, {"time": 3401, "text": "The only place we have difficulty with diversity is in each other."}, {"time": 3408, "text": "And then we have considerable problems there, I would say, as a species."}, {"time": 3412, "text": "Let me ask, I don't know if you're familiar with Donald Hoffman's work about questions of reality."}, {"time": 3420, "text": "What are your thoughts of the possibility that the very thing we've been talking about, of the brain wiring itself from birth to a particular set of inputs, is just a little slice of reality, that there is something much bigger out there that we humans, with our cognition, cognitive capabilities, is just not even perceiving."}, {"time": 3443, "text": "The thing we're perceiving is just a crappy, like Windows 95 interface onto a much bigger, richer set of complex physics that we're not even in touch with."}, {"time": 3458, "text": "Well, without getting too metaphysical about it, I think we know for sure."}, {"time": 3462, "text": "It doesn't have to be the crappy version of anything, but we definitely have a limited, we have a set of senses that are limited in very physical ways, and we're clearly not perceiving everything there is to perceive."}, {"time": 3479, "text": "I mean, it's just, it's not that hard."}, {"time": 3481, "text": "We can't, without special, why do we invent scientific tools?"}, {"time": 3484, "text": "It's so that we can overcome our senses and experience things that we couldn't otherwise, whether they are different parts of the visual spectrum, the light spectrum, or things that are too microscopically small for us to see or too far away for us to see."}, {"time": 3502, "text": "So clearly, we're only getting a slice, and that slice, the interesting or potentially sad thing about humans is that we, whatever we experience, we think there's a natural reason for experiencing it, and we think it's obvious and natural and it must be this way, and that all the other stuff isn't important."}, {"time": 3530, "text": "And that's clearly not true."}, {"time": 3533, "text": "Many of the things that we think of as natural are anything but, they're certainly real, but we've created them."}, {"time": 3540, "text": "They certainly have very real impacts, but we've created those impacts."}, {"time": 3544, "text": "And we also know that there are many things outside of our awareness that have tremendous influence on what we experience and what we do."}, {"time": 3553, "text": "So there's no question that that's true."}, {"time": 3556, "text": "I mean, just, it's, but the extent is how, really the question is, how fantastical is it?"}, {"time": 3563, "text": "Yeah, like what, you know, a lot of people ask me, am I allowed to say this?"}, {"time": 3567, "text": "I think I'm allowed to say this."}, {"time": 3568, "text": "I've eaten shrooms a couple of times, but I haven't gone the full, I'm talking to a few researchers in psychedelics."}, {"time": 3575, "text": "It's an interesting scientifically place."}, {"time": 3577, "text": "Like what is the portal you're entering when you take psychedelics?"}, {"time": 3581, "text": "Or another way to ask is like dreams."}, {"time": 3585, "text": "So let me tell you what I think, which is based on nothing."}, {"time": 3588, "text": "Like this is based on my, right, so I don't."}, {"time": 3591, "text": "Your intuition."}, {"time": 3592, "text": "It's based on my, I'm guessing now, based on what I do know, I would say."}, {"time": 3599, "text": "But I think that, well, think about what happens."}, {"time": 3602, "text": "So you're running, your brain's running this internal model and it's all outside of your awareness."}, {"time": 3606, "text": "You see the, you feel the products, but you don't sense the, you have no awareness of the mechanics of it, right?"}, {"time": 3613, "text": "It's going on all the time."}, {"time": 3617, "text": "And so one thing that's going on all the time that you're completely unaware of is that when your brain, your brain is basically asking itself, figuratively speaking, not literally, right?"}, {"time": 3627, "text": "Like how is, the last time I was in this sensory array with this stuff going on in my body and this chain of events which just occurred, what did I do next?"}, {"time": 3639, "text": "What did I feel next?"}, {"time": 3640, "text": "What did I see next?"}, {"time": 3642, "text": "It doesn't come up with one answer."}, {"time": 3643, "text": "It comes up with a distribution of it, possible answers."}, {"time": 3647, "text": "And then there has to be some selection process."}, {"time": 3650, "text": "And so you have a network in your brain, a sub network in your brain, a population of neurons that helps to choose."}, {"time": 3660, "text": "It's not, I'm not talking about a homunculus in your brain or anything silly like that."}, {"time": 3667, "text": "This is not the soul."}, {"time": 3668, "text": "It's not the center of yourself or anything like that."}, {"time": 3671, "text": "But there is a set of neurons that weighs the probabilities and helps to select or narrow the field, okay?"}, {"time": 3686, "text": "And that network is working all the time."}, {"time": 3690, "text": "It's actually called the control network, the executive control network, or you can call it a frontoparietal because the regions of the brain that make it up are in the frontal lobe and the parietal lobe."}, {"time": 3701, "text": "There are also parts that belong to the subcortical parts of your brain."}, {"time": 3705, "text": "The point is that there is this network and it is working all the time."}, {"time": 3709, "text": "Whether or not you feel in control, whether or not you feel like you're expending effort doesn't really matter."}, {"time": 3713, "text": "It's on all the time, except when you sleep."}, {"time": 3717, "text": "When you sleep, it's a little bit relaxed."}, {"time": 3723, "text": "And so think about what's happening when you sleep."}, {"time": 3725, "text": "When you sleep, the external world recedes, the sense data from, so basically your model becomes a little bit, the tethers from the world are loosened."}, {"time": 3739, "text": "And this network, which is involved in, you know, maybe weeding out unrealistic things is a little bit quiet."}, {"time": 3749, "text": "So use your dreams are really your internal model that's unconstrained by the immediate world."}, {"time": 3760, "text": "Except, so you can do things that you can't do in real life, in your dreams, right?"}, {"time": 3765, "text": "You can fly."}, {"time": 3766, "text": "Like I, for example, when I fly on my back in a dream, I'm much faster than when I fly on my front."}, {"time": 3771, "text": "Don't ask me why, I don't know."}, {"time": 3773, "text": "Or when you're laying on your back in your dream."}, {"time": 3775, "text": "No, when I'm in my dream and flying in a dream, I am much faster flyer in the air."}, {"time": 3780, "text": "You fly often?"}, {"time": 3782, "text": "Not often, but I, You talk about it like you, I don't think I've flown for many years."}, {"time": 3786, "text": "Well, you must try it."}, {"time": 3788, "text": "I've flown, I've fallen."}, {"time": 3791, "text": "That's scary."}, {"time": 3792, "text": "Yeah, but you're talking about like airplane."}, {"time": 3794, "text": "Yeah, I fly in my dreams."}, {"time": 3796, "text": "And I'm way faster, right?"}, {"time": 3796, "text": "On your back."}, {"time": 3798, "text": "On my back, way faster."}, {"time": 3801, "text": "Now you can say, well, you know, you never flew in your life."}, {"time": 3804, "text": "Right, it's conceptual combination."}, {"time": 3805, "text": "I mean, I've flown in an airplane and I've seen birds fly and I've watched movies of people flying and I know Superman probably flies, I don't know if he flies faster on his back, but."}, {"time": 3816, "text": "He's, I've never seen Superman."}, {"time": 3817, "text": "He's always flying on his front, right, but yeah."}, {"time": 3820, "text": "But anyways, my point is that, you know, all of this stuff really, all of these experiences really become part of your internal model."}, {"time": 3828, "text": "The thing is that when you're asleep, your internal model is still being constrained by your body."}, {"time": 3836, "text": "Your brain's always attached to your body."}, {"time": 3838, "text": "It's always receiving sense data from your body."}, {"time": 3841, "text": "You're mostly never aware of it unless you run up the stairs or, you know, maybe you are ill in some way."}, {"time": 3851, "text": "But you're mostly not aware of it, which is a really good thing."}, {"time": 3853, "text": "Because if you were, you know, you'd never pay attention to anything outside your own skin ever again."}, {"time": 3859, "text": "Like right now, you seem like you're sitting there very calmly, but you have a virtual drama, right?"}, {"time": 3865, "text": "It's like an opera going on inside your body."}, {"time": 3870, "text": "And so I think that one of the things that happens when people take psilocybin or take, you know, ketamine, for example, is that the tethers are completely removed."}, {"time": 3890, "text": "And that's why it's helpful to have a guide, right?"}, {"time": 3893, "text": "Because the guide is giving you sense data to steer that internal model so that it doesn't go completely off the rails."}, {"time": 3903, "text": "Again, that wiring to the other brain, that's the guide, is at least a tiny little tether."}, {"time": 3911, "text": "Let's talk about emotion a little bit, if we could."}, {"time": 3914, "text": "Emotion comes up often."}, {"time": 3916, "text": "And I have never spoken with anybody who has a clarity about emotion from a biological and neuroscience perspective that you do."}, {"time": 3929, "text": "And I'm not sure I fully know how to, as a, I mentioned this way too much, but as somebody who was born in the Soviet Union and romanticizes basically everything, talks about love nonstop, you know, emotion is a, I don't know what to make of it."}, {"time": 3948, "text": "I don't know what to, so maybe let's just try to talk about it."}, {"time": 3953, "text": "I mean, from a neuroscience perspective, we talked about it a little bit last time, your book covers it, how emotions are made, but what are some misconceptions we writers of poetry, we romanticizing humans have about emotion that we should move away from before to think about emotion from both a scientific and an engineering perspective?"}, {"time": 3980, "text": "Yeah, so there is a common view of emotion in the West."}, {"time": 3985, "text": "The caricature of that view is that, you know, we have an inner beast, right?"}, {"time": 3993, "text": "Your limbic system, your inner lizard, we have an inner beast and that comes baked in to the brain at birth."}, {"time": 4001, "text": "So you've got circuits for anger, sadness, fear."}, {"time": 4004, "text": "It's interesting that they all have English names, these circuits."}, {"time": 4007, "text": "But, and they're there and they're triggered by things in the world."}, {"time": 4012, "text": "And then they cause you to do and say, and so when your fear circuit is triggered, you widen your eyes, you gasp, your heart rate goes up, you prepare to flee or to freeze."}, {"time": 4032, "text": "And these are modal responses."}, {"time": 4035, "text": "They're not the only responses that you give, but on average, they're the prototypical responses."}, {"time": 4040, "text": "That's the view."}, {"time": 4042, "text": "And that's the view of emotion in the law."}, {"time": 4045, "text": "That's the view, you know, that emotions are these profoundly unhelpful things that are obligatory kind of like reflexes."}, {"time": 4057, "text": "The problem with that view is that it doesn't comport to the evidence."}, {"time": 4064, "text": "And it doesn't really matter."}, {"time": 4066, "text": "The evidence actually lines up beautifully with each other."}, {"time": 4069, "text": "It just doesn't line up with that view."}, {"time": 4070, "text": "And it doesn't matter whether you're measuring people's faces, facial movements, or you're measuring their body movements, or you're measuring their peripheral physiology, or you're measuring their brains or their voices or whatever."}, {"time": 4080, "text": "Pick any output that you wanna measure and any system you wanna measure, and you don't really find strong evidence for this."}, {"time": 4089, "text": "And I say this as somebody who not only has reviewed really thousands of articles and run big meta analyses, which are statistical summaries of published papers, but also as someone who has sent teams of researchers to small scale cultures, you know, remote cultures, which are very different from urban, large scale cultures like ours."}, {"time": 4120, "text": "And one culture that we visited, and I say we euphemistically because I myself didn't go because I only had two research permits, and I gave them to my students because I felt like it was better for them to have that experience and more formative for them to have that experience."}, {"time": 4139, "text": "But I was in contact with them every day by satellite phone."}, {"time": 4143, "text": "And this was to visit the Hadza hunter gatherers in Tanzania who are not an ancient people, they're a modern culture, but they live in circumstances, hunting and foraging, circumstances that are very similar, in similar conditions to our ancestors, hunting gathering ancestors, when expressions of emotion were supposed to have evolved, at least by one view of, okay."}, {"time": 4177, "text": "So, you know, for many years, I was sort of struggling with this set of observations, which is that I feel emotion, and I perceive emotion in other people, but scientists can't find a single marker, a single biomarker, not a single individual measure or pattern of measures that can predict what kind of emotional state they're in."}, {"time": 4206, "text": "How could that possibly be?"}, {"time": 4208, "text": "How can you possibly make sense of those two things?"}, {"time": 4212, "text": "And through a lot of reading and a lot of an immersing myself in different literatures, I came to the hypothesis that the brain is constructing these instances out of more basic ingredients."}, {"time": 4229, "text": "So when I tell you that the brain, when I suggest to you that what your brain is doing is making a prediction, and it's asking itself, figuratively speaking, the last time I was in this situation and this, you know, physical state, what did I do next?"}, {"time": 4248, "text": "What did I hear next?"}, {"time": 4250, "text": "It's basically asking what in my past is similar to the present?"}, {"time": 4259, "text": "Things which are similar to one another are called a category."}, {"time": 4263, "text": "A group of things which are similar to one another is a category."}, {"time": 4267, "text": "And a mental representation of a category is a concept."}, {"time": 4272, "text": "So your brain is constructing categories or concepts on the fly continuously."}, {"time": 4277, "text": "So you really want to understand what a brain is doing."}, {"time": 4279, "text": "You don't, using machine learning like classification models is not going to help you because the brain doesn't classify."}, {"time": 4285, "text": "It's doing category construction."}, {"time": 4289, "text": "And the categories change, or you could say it's doing concept construction."}, {"time": 4294, "text": "It's using past experience to conjure a concept, which is a prediction."}, {"time": 4301, "text": "And if it's using past experiences of emotion, then it's constructing an emotion concept."}, {"time": 4310, "text": "Your concept will be, the content of it changes depending on the situation that you're in."}, {"time": 4323, "text": "So for example, if your brain uses past experiences of anger that you have learned, either because somebody labeled them for you, taught them to you, you observed them in movies and so on, in one situation could be very different from your concept of for anger than another situation."}, {"time": 4344, "text": "And this is how anger, instances of anger are, we call a population of variable instances."}, {"time": 4352, "text": "Sometimes when you're angry, you scowl."}, {"time": 4354, "text": "Sometimes when you're angry, you might smile."}, {"time": 4358, "text": "Sometimes when you're angry, you might cry."}, {"time": 4362, "text": "Sometimes your heart rate will go up, it will go down, it will stay the same."}, {"time": 4366, "text": "It depends on what action you're about to take because the way prediction, and I should say, the idea that physiology is yoked to action is a very old idea in the study of the peripheral nervous system that's been known for really decades."}, {"time": 4384, "text": "And so if you look at what the brain is doing, if you just look at the anatomy and you, here's the hypothesis that you would come up with."}, {"time": 4392, "text": "And I can go into the details."}, {"time": 4394, "text": "I've published these details in scientific papers and they also appear somewhat in How Emotions Were Made, my first book."}, {"time": 4402, "text": "They are not in the seven and a half lessons because that book is really not pitched at that level of explanation."}, {"time": 4411, "text": "It's just giving, it's really just a set of little essays."}, {"time": 4416, "text": "But the evidence, but what I'm about to say is actually based on scientific evidence."}, {"time": 4421, "text": "When your brain begins to form a prediction, the first thing it's doing is it's making a prediction of how to change the internal systems of your body, your heart, your cardiovascular system, the control of your heart, control of your lungs, a flush of cortisol, which is not a stress hormone."}, {"time": 4443, "text": "It's a hormone that gets glucose into your bloodstream very fast because your brain is predicting you need to do this."}, {"time": 4450, "text": "Predicting you need to do something metabolically expensive."}, {"time": 4458, "text": "And so either that means either move or learn, okay?"}, {"time": 4464, "text": "And so your brain is preparing your body, the internal systems of your body to execute some actions, to move in some way."}, {"time": 4474, "text": "And then it infers based on those motor predictions and what we call viscera motor predictions, meaning the changes in the viscera that your brain is preparing to execute, your brain makes an inference about what you will sense based on those motor movements."}, {"time": 4501, "text": "So your experience of the world and your experience of your own body are a consequence of those predictions, those concepts."}, {"time": 4513, "text": "When your brain makes a concept for emotion, it's constructing an instance of that emotion."}, {"time": 4521, "text": "And that is how emotions are made."}, {"time": 4524, "text": "And those concepts load in, the predictions that are made include contents inside the body, contents outside the body."}, {"time": 4536, "text": "I mean, it includes other humans."}, {"time": 4538, "text": "So just this construction of a concept includes the variables that are much richer than just some sort of simple notion."}, {"time": 4551, "text": "Yeah, so our colloquial notion of a concept where I say, well, what's a concept of a bird?"}, {"time": 4560, "text": "And then you list a set of features off to me."}, {"time": 4562, "text": "That's people's understanding, typically of what a concept is."}, {"time": 4565, "text": "But if you go into the literature in cognitive science, what you'll see is that the way that scientists have understood what a concept is has really changed over the years."}, {"time": 4577, "text": "So people used to think about a concept as philosophers and scientists used to think about a concept as a dictionary definition for a category."}, {"time": 4587, "text": "So there's a set of things which are similar out in the world."}, {"time": 4591, "text": "And your concept for that category is a dictionary definition of the features, the necessary insufficient features of those instances."}, {"time": 4603, "text": "So for a bird, it would be."}, {"time": 4607, "text": "Wings, feathers."}, {"time": 4607, "text": "Right, a beak."}, {"time": 4610, "text": "It flies, whatever, okay."}, {"time": 4613, "text": "That's called the classical category."}, {"time": 4615, "text": "And scientists discovered, observed that actually not all instances of birds have feathers and not all instances of birds fly."}, {"time": 4625, "text": "And so the idea was that you don't have a single representation of necessary insufficient features stored in your brain somewhere."}, {"time": 4633, "text": "Instead, what you have is a prototype, a prototype meaning you still have a single representation for the category, one, but the features are like of the most typical instance of the category or maybe the most frequent instance, but not all instances of the category have all the features, right?"}, {"time": 4653, "text": "They have some graded similarity to the prototype."}, {"time": 4658, "text": "And then, you know, what I'm gonna like incredibly simplify now, a lot of work to say that then a series of experiments were done to show that in fact, what your brain seems to be doing is coming up with a single exemplar or instance of the category and reading off the features when I ask you for the concept."}, {"time": 4691, "text": "So if we were in a pet store and I asked you what are the features of a bird, tell me the concept of bird, you would be more likely to give me features of a good pet."}, {"time": 4706, "text": "And if we were in a restaurant, you would be more likely, you know, like a budgie, right?"}, {"time": 4711, "text": "Or a canary."}, {"time": 4712, "text": "If we were in a restaurant, you would be more likely to give me the features of a bird that you would eat, like a chicken."}, {"time": 4719, "text": "And if we were in a park, you'd be more likely to give me in this country, you know, the features of a sparrow or a robin."}, {"time": 4729, "text": "Whereas if we were in South America, you would probably give me the features of a peacock because that's more common or it is more common there than here that you would see a peacock in such circumstances."}, {"time": 4741, "text": "So the idea was that really what your brain was doing was conjuring a concept on the fly that meets the function that the category is being put to."}, {"time": 4761, "text": "Then people started studying ad hoc concepts, meaning concepts where the instances don't share any physical features, but the function of the instances are the same."}, {"time": 4780, "text": "So for example, think about all the things that can protect you from the rain."}, {"time": 4786, "text": "What are all the things that can protect you from the rain?"}, {"time": 4789, "text": "Umbrella, like this apartment."}, {"time": 4796, "text": "Your car."}, {"time": 4797, "text": "Not giving a damn."}, {"time": 4799, "text": "Like a mindset."}, {"time": 4803, "text": "Yeah, right, right."}, {"time": 4805, "text": "So the idea is that the function of the instances is the same in a given situation."}, {"time": 4811, "text": "Even if they look different, sound different, smell different, this is called an abstract concept or a conceptual concept."}, {"time": 4822, "text": "Now the really cool thing about conceptual categories or conceptual category is a category of things that are held together by a function, which is called an abstract concept or a conceptual category, because the things don't share physical features, they share functional features."}, {"time": 4844, "text": "There are two really cool things about this."}, {"time": 4846, "text": "One is that's what Darwin said a species was."}, {"time": 4850, "text": "So Darwin is known for discovering natural selection."}, {"time": 4859, "text": "But the other thing he really did, which was really profound, which he's less celebrated for, is understanding that all biological categories have inherent variation, inherent variation."}, {"time": 4875, "text": "Darwin wrote in The Origin of Species about before Darwin's book, a species was thought to be a classical category where all the instances of dogs were the same, had the exactly same features, and any variation from that perfect platonic instance was considered to be error."}, {"time": 4901, "text": "And Darwin said, no, it's not error, it's meaningful."}, {"time": 4904, "text": "So nature selects on the basis of that variation."}, {"time": 4912, "text": "The reason why natural selection is powerful and can exist is because there is variation in a species."}, {"time": 4921, "text": "And in dogs, we talk about that variation in terms of the size of the dog and the amount of fur the dog has and the color and how long is the tail and how long is the snout."}, {"time": 4932, "text": "In humans, we talk about that variation in all kinds of ways, right, including in cultural ways."}, {"time": 4943, "text": "So that's one thing that's really interesting about conceptual categories is that Darwin is basically saying a species is a conceptual category."}, {"time": 4951, "text": "And in fact, if you look at modern debates about what is a species, you can't find anybody agreeing on what the criteria are for a species, because they don't all share the same genome."}, {"time": 4966, "text": "We don't all share, we don't, there isn't a single human genome."}, {"time": 4969, "text": "There's a population of genomes, but they're variable."}, {"time": 4976, "text": "It's not unbounded variation, but they are variable, right?"}, {"time": 4980, "text": "And the other thing that's really cool about conceptual categories is that they are the categories that we use to make civilization."}, {"time": 4995, "text": "So think about money, for example."}, {"time": 4999, "text": "What are all the physical things that make something a currency?"}, {"time": 5005, "text": "Is there any physical feature that all the currencies in all the worlds that's ever been used by humans share?"}, {"time": 5013, "text": "Well, certainly, right, but what is it?"}, {"time": 5016, "text": "Is it definable?"}, {"time": 5018, "text": "So it's getting to the point that you make this function."}, {"time": 5023, "text": "It's the function, right."}, {"time": 5024, "text": "It's that we trade it for material goods."}, {"time": 5027, "text": "And we have to agree, right?"}, {"time": 5029, "text": "We all impose on whatever it is, salt, barley, little shells, big rocks in the ocean that can't move, Bitcoin, pieces of plastic, mortgages, which are basically a promise of something in the future, nothing more, right?"}, {"time": 5042, "text": "All of these things, we impose value on them."}, {"time": 5046, "text": "And we all agree that we can exchange them for material goods."}, {"time": 5051, "text": "Yeah, and yes, that's brilliant."}, {"time": 5053, "text": "By the way, you're attributing some of that to Darwin, that he thought."}, {"time": 5056, "text": "No, no, I'm saying that what Darwin."}, {"time": 5058, "text": "Because it's a brilliant view of what a species is, is the function."}, {"time": 5061, "text": "Yeah, what I'm saying is that what Darwin, Darwin really talked about variation in, so if you read, for example, the biologist Ernst Mayr, who was an evolutionary biologist, and then when he retired, became a historian and philosopher of biology."}, {"time": 5078, "text": "And his suggestion is that Darwin, Darwin did talk about variation."}, {"time": 5085, "text": "He vanquished what's called essentialism, the idea that there's a single set of features that define any species."}, {"time": 5096, "text": "And out of that grew really discussions of some of the functional features that species have, like they can reproduce, they can have offspring, the individuals of a species can have offspring."}, {"time": 5112, "text": "It turns out that's not a perfect criterion to use, but it's a functional criterion, right?"}, {"time": 5120, "text": "So what I'm saying is that in cognitive science, people came up with the idea, they discovered the idea of conceptual categories or ad hoc concepts, these concepts that can change based on the function they're serving, right?"}, {"time": 5133, "text": "And that it's there, it's in Darwin, and it's also in the philosophy of social reality."}, {"time": 5142, "text": "The way that philosophers talk about social reality, just look around you."}, {"time": 5146, "text": "I mean, we impose, we're treating a bunch of things as similar, which are physically different."}, {"time": 5152, "text": "And sometimes we take things that are physically the same and we treat them as separate categories."}, {"time": 5158, "text": "But it feels like the number of variables involved in that kind of categorization is nearly infinite."}, {"time": 5164, "text": "No, I don't think so, because there is a physical constraint, right?"}, {"time": 5168, "text": "Like you and I could agree that we can fly in real life, but we can't."}, {"time": 5174, "text": "That's a physical constraint that we can't break, right?"}, {"time": 5178, "text": "You and I could agree that we could walk through the walls, but we can't."}, {"time": 5182, "text": "We could agree that we could eat glass, but we can't."}, {"time": 5185, "text": "Oh, there's a lot of constraints, but I just."}, {"time": 5185, "text": "Yeah, we could agree that the virus doesn't exist and we don't have to wear masks."}, {"time": 5193, "text": "But physical reality still holds the Trump card, right?"}, {"time": 5197, "text": "But still there's a lot of."}, {"time": 5198, "text": "The Trump card, well, pun unintended."}, {"time": 5201, "text": "Pun completely unintended, but there you go, that's a predicting brain for you."}, {"time": 5204, "text": "But there is a tremendous amount of leeway."}, {"time": 5210, "text": "Yeah, that's the point."}, {"time": 5211, "text": "So what I'm saying is that emotions are like money."}, {"time": 5215, "text": "Basically, they're like money, they're like countries, they're like kings and queens and presidents."}, {"time": 5222, "text": "They're like everything that we construct that we impose meaning on."}, {"time": 5227, "text": "We take these physical signals and we give them meanings that they don't otherwise have by their physical nature."}, {"time": 5233, "text": "And because we agree, they have that function."}, {"time": 5239, "text": "But the beautiful thing, so maybe unlike money, I love this similarity is it's not obvious to me that this kind of emergent agreement should happen with emotion, because our experiences are so different for each of us humans, and yet we kind of converge."}, {"time": 5256, "text": "Well, in a culture we converge, but not across cultures."}, {"time": 5259, "text": "There are huge, huge differences."}, {"time": 5261, "text": "There are huge differences in what concepts exist, what they look like."}, {"time": 5268, "text": "So what I would say is that what we're doing with our young children as their brains become wired to their physical and their social environment is that we are curating for them."}, {"time": 5285, "text": "We are bootstrapping into their brains a set of emotion concepts."}, {"time": 5291, "text": "That's partly what they're learning."}, {"time": 5293, "text": "And we curate those for infants just the way we curate for them what is a dog, what is a cat, what is a truck."}, {"time": 5299, "text": "We sometimes explicitly label and we sometimes just use mental words."}, {"time": 5306, "text": "When your kid is throwing Cheerios on the floor instead of eating them, or your kid is crying when she won't put herself to sleep or whatever."}, {"time": 5317, "text": "We use mental words."}, {"time": 5319, "text": "And a word is this, words for infants, words are these really special things that they help infants learn abstract categories."}, {"time": 5329, "text": "There's a huge literature showing that children can take things that don't look infants, like infants, really young infants, preverbal infants can take, if you label, if I say to you, and you're an infant, okay?"}, {"time": 5347, "text": "So I say, Lexi, this is a bling."}, {"time": 5353, "text": "And I put it down and the bling makes a squeaky noise."}, {"time": 5357, "text": "And then I say, Lexi, this is a bling."}, {"time": 5362, "text": "And I put it down and it makes a squeaky noise."}, {"time": 5370, "text": "You, as young as four months old, will expect this to make a noise, a squeaky noise."}, {"time": 5379, "text": "And if you don't, if it doesn't, you'll be surprised because it violated your expectation, right?"}, {"time": 5384, "text": "I'm building for you an internal model of a bling."}, {"time": 5389, "text": "Okay, infants can do this really, really at a young age."}, {"time": 5393, "text": "And so there's no reason to believe that they couldn't learn emotion categories and concepts in the same way."}, {"time": 5399, "text": "And what happens when you go to a new culture?"}, {"time": 5404, "text": "When you go to a new culture, you have to do what's called emotion acculturation."}, {"time": 5411, "text": "So my colleague Bacha Mesquita in Belgium studies emotion acculturation."}, {"time": 5415, "text": "She studies how, when people move from one culture to another, how do they learn the emotion concepts of that culture?"}, {"time": 5421, "text": "How do they learn to make sense of their own internal sensations and also the movements, the raise of an eyebrow, the tilt of a head?"}, {"time": 5430, "text": "How do they learn to make sense of cues from other people using concepts they don't have, but have to make on the fly?"}, {"time": 5440, "text": "So that's the difference between cultures."}, {"time": 5443, "text": "Let me open another door."}, {"time": 5445, "text": "I'm not sure I wanna open, but the difference between men and women."}, {"time": 5449, "text": "Is there a difference between the emotional lives of those two categories of biological systems?"}, {"time": 5460, "text": "We did a series of studies in the 1990s where we asked men and women to tell us about their emotional lives."}, {"time": 5470, "text": "And women described themselves as much more emotional than men."}, {"time": 5473, "text": "They believed that they were more emotional than men and men agreed."}, {"time": 5477, "text": "Women are much more emotional than men."}, {"time": 5479, "text": "And then we gave them little handheld computers."}, {"time": 5484, "text": "These were little Hewlett Packard computers."}, {"time": 5486, "text": "They fit in the palm of your hand."}, {"time": 5488, "text": "They weighed a couple of pounds."}, {"time": 5489, "text": "So this was like pre palm pilot even, like this was 1990s and like early."}, {"time": 5496, "text": "And we asked them, we would ping them like 10 times a day and just ask them to report how they were feeling, which is called experience sampling."}, {"time": 5511, "text": "So we experienced sampled."}, {"time": 5513, "text": "And then at the end, and then we looked at their reports and what we found is that men and women basically didn't differ."}, {"time": 5522, "text": "And there were some people who were really, had many more instances of emotion."}, {"time": 5527, "text": "So they were treading water in a tumultuous sea of emotion."}, {"time": 5535, "text": "And then there were other people who were like floating tranquilly in a lake."}, {"time": 5541, "text": "It was really not perturbed very often."}, {"time": 5543, "text": "And everyone in between, but there were no difference between men and women."}, {"time": 5548, "text": "And the really interesting thing is at the end of the sampling period, we asked people, so reflect over the past two weeks and tell it."}, {"time": 5556, "text": "So we've been now pinging people like again and again and again, right?"}, {"time": 5561, "text": "So tell us how emotional do you think you are?"}, {"time": 5564, "text": "No change from the beginning."}, {"time": 5565, "text": "So men and women believe that they are different."}, {"time": 5570, "text": "And when they are looking at other people, they make different inferences about emotion."}, {"time": 5576, "text": "If a man is scowling, like if you and I were together and so somebody is watching this, okay?"}, {"time": 5584, "text": "And yeah, hey, who are you saying?"}, {"time": 5587, "text": "Hey, hi."}, {"time": 5588, "text": "Yeah, hi."}, {"time": 5589, "text": "By the way, people love it when you look at the camera."}, {"time": 5595, "text": "If you and I make exactly the same set of facial movements, when people look at you, both men and women look at you, they are more likely to think, oh, he's reacting to the situation."}, {"time": 5610, "text": "And when they look at me, they'll say, oh, she's having an emotion."}, {"time": 5614, "text": "She's, you know, yeah."}, {"time": 5616, "text": "And I wrote about this actually right before the 2016 election."}, {"time": 5626, "text": "You know what, maybe I could confess."}, {"time": 5629, "text": "Let me try to carefully confess."}, {"time": 5631, "text": "But you are really gonna."}, {"time": 5633, "text": "Yeah, that when I, that there is an element when I see Hillary Clinton that there was something annoying about her to me."}, {"time": 5646, "text": "And I, just that feeling, and then I tried to reduce that to what is that?"}, {"time": 5653, "text": "Because I think the same attributes that are annoying about her when I see in other people wouldn't be annoying."}, {"time": 5662, "text": "So I was trying to understand what is it?"}, {"time": 5665, "text": "Because it certainly does feel like that concept that I've constructed in my mind."}, {"time": 5670, "text": "Well, I'll tell you that I think, well, let me just say that what you would predict about, for example, the performance of the two of them in the debates, and I wrote an op ed for the New York Times actually before the second debate."}, {"time": 5686, "text": "And it played out really pretty much as I thought that it would based on research."}, {"time": 5691, "text": "It's not like I'm like a great fortune teller or anything."}, {"time": 5693, "text": "It's just, I was just applying the research, which was that when a woman, a woman's, people make internal attributions, it's called."}, {"time": 5703, "text": "They infer that the facial movements and body posture and vocalizations of a woman reflect her interstate."}, {"time": 5710, "text": "But for a man, they're more likely to assume that they reflect his response to the situation."}, {"time": 5715, "text": "It doesn't say anything about him."}, {"time": 5716, "text": "It says something about the situation he's in."}, {"time": 5719, "text": "Now, for the thing that you were describing about Hillary Clinton, I think a lot of people experienced, but it's also in line with research, which shows, and particularly research actually about teaching evaluations is one place that you really see it, where the expectation is that a woman will be nurturant and that a man, there's just no expectation for him to be nurturant."}, {"time": 5747, "text": "So if he is nurturant, he gets points."}, {"time": 5751, "text": "If he's not, he gets points."}, {"time": 5754, "text": "They're just different points, right?"}, {"time": 5756, "text": "Whereas for a woman, especially a woman who's an authority figure, she's really in a catch 22."}, {"time": 5762, "text": "Because if she's serious, she's a bitch."}, {"time": 5765, "text": "And if she's empathic, then she's weak."}, {"time": 5769, "text": "Right, that's brilliant."}, {"time": 5769, "text": "I mean, one of the bigger questions to ask here, so that's one example where our construction of concepts gets in trouble."}, {"time": 5780, "text": "So, but remember I said science and philosophy are like tools for living."}, {"time": 5786, "text": "So I learned recently that if you ask me what is my intuition about what regulates my eating, I will say carbohydrates."}, {"time": 5796, "text": "I love carbohydrates."}, {"time": 5797, "text": "I love pasta."}, {"time": 5798, "text": "I love bread."}, {"time": 5799, "text": "I love, I just love carbohydrates."}, {"time": 5802, "text": "But actually research shows, and it's beautiful research."}, {"time": 5805, "text": "I love this research because it so violates my own like deeply, deeply held beliefs about myself that most animals on this planet who have been studied and there are many actually eat to regulate their protein intake."}, {"time": 5824, "text": "So you will overeat carbohydrates if you, in order to get enough protein."}, {"time": 5830, "text": "And this research has been done with human, very beautiful research with humans, with crickets, with like, you know, bonobos."}, {"time": 5837, "text": "I mean, just like all these different animals, not bonobos, but I think like baboons."}, {"time": 5841, "text": "Now that I have no intuition about that."}, {"time": 5844, "text": "And I, even now as I regulate my eating, I still, I just have no intuition."}, {"time": 5850, "text": "It just, I can't feel it."}, {"time": 5852, "text": "What I feel is only about the carbohydrates."}, {"time": 5855, "text": "It feels like you're regulating around carbohydrates, not the protein."}, {"time": 5858, "text": "Yeah, but in fact, actually what I am doing, if I am like most animals on the planet, I am regulating around protein."}, {"time": 5865, "text": "So knowing this, what do I do?"}, {"time": 5868, "text": "I correct my behavior to eat, to actually deliberately try to focus on the protein."}, {"time": 5876, "text": "This is the idea behind bias training, right?"}, {"time": 5880, "text": "Like if you, I also did not experience Hillary Clinton as the warmest candidate."}, {"time": 5892, "text": "However, you can use consistent science, since the consistent scientific findings to organize your behavior."}, {"time": 5904, "text": "That doesn't mean that rationality is the absence of emotion, because sometimes emotion or any feelings in general, not the same thing as emotion, that's another topic, but are a source of information and their wisdom and helpful."}, {"time": 5922, "text": "So I'm not saying that, but what I am saying is that if you have a deeply held belief and the evidence shows that you're wrong, then you're wrong."}, {"time": 5930, "text": "It doesn't really matter how confident you feel."}, {"time": 5933, "text": "That confidence could be also explained by science, right?"}, {"time": 5936, "text": "So it would be the same thing as if I, regardless of whether someone is like Charlie Baker, regardless of whether somebody is a Republican or a Democrat, if that person has a record that you can see is consistent with what you believe, then that is information that you can act on."}, {"time": 5955, "text": "Yeah, and then try to, I mean, this is kind of what empathy is in open mindedness, is try to consider that the set of concepts that your brain has constructed through which you are now perceiving the world is not painting the full picture."}, {"time": 5972, "text": "I mean, this is now true for basically every, it doesn't have to be men and women, it could be basically the prism through which we perceive actually the political discourse, right?"}, {"time": 5981, "text": "Absolutely, so here's what I would say."}, {"time": 5989, "text": "There are people who, scientists who will talk to you about cognitive empathy and emotional empathy and I prefer to think of it, I think the evidence is more consistent with what I'm about to say, which is that your brain is always making predictions using your own past experience and what you've learned from books and movies and other people telling you about their experiences and so on."}, {"time": 6017, "text": "And if your brain cannot make a concept to make sense of those, anticipate what those sense data are and make sense of them, you will be experientially blind."}, {"time": 6031, "text": "So, when I'm giving lectures to people, I'll show them like a blobby black and white image and they're experientially blind to the image, they can't see anything in it."}, {"time": 6044, "text": "And then I show them a photograph and then I show them the image again, the blobby image and then they see actually an object in it."}, {"time": 6051, "text": "But the image is the same."}, {"time": 6053, "text": "It's they're actually adding, their predictions now are adding, right?"}, {"time": 6057, "text": "Or anybody who's learned a language, a second language after their first language also has this experience of things that initially sound like sounds that they can't quite make sense of, eventually come to make sense of them."}, {"time": 6078, "text": "And in fact, there are really cool examples of people who were like born blind because they have cataracts or they have corneal damage so that no light is reaching the brain."}, {"time": 6093, "text": "And then they have an operation and then light reaches the brain and they can't see."}, {"time": 6101, "text": "For days and weeks and sometimes years, they are experientially blind to certain things."}, {"time": 6107, "text": "So what happens with empathy, right?"}, {"time": 6111, "text": "Is that your brain is making a prediction."}, {"time": 6114, "text": "And if it doesn't have the capacity to make, if you don't share, if you're not similar, remember categories are instances which are similar in some way."}, {"time": 6132, "text": "If you are not similar enough to that person, you will have a hard time making a prediction about what they feel."}, {"time": 6139, "text": "You will be experientially blind to what they feel."}, {"time": 6144, "text": "In the United States, children of color are under prescribed medicine by their physicians."}, {"time": 6154, "text": "This is been documented."}, {"time": 6158, "text": "It's not that the physicians are racist necessarily but they might be experientially blind."}, {"time": 6172, "text": "The same thing is true of male physicians with female patients."}, {"time": 6176, "text": "I could tell you some hair raising stories really that where people die as a consequence of a physician making the wrong inference, the wrong prediction because of being experientially blind."}, {"time": 6191, "text": "So we are, empathy is not, it's not magic."}, {"time": 6201, "text": "We make inferences about each other, about what each other's feeling and thinking."}, {"time": 6206, "text": "In this culture more than, there are some cultures where people have what's called opacity of mind where they will make a prediction about someone else's actions but they're not inferring anything about the internal state of that person."}, {"time": 6219, "text": "But in our culture, we're constantly making inferences."}, {"time": 6223, "text": "What is this person thinking?"}, {"time": 6224, "text": "And we're not doing it necessarily consciously but we're just doing it really automatically using our predictions, what we know."}, {"time": 6231, "text": "And if you expose yourself to information which is very different from somebody else, I mean, really what we have is we have different cultures in this country right now that are, there are a number of reasons for this."}, {"time": 6248, "text": "I mean, part of it is, I don't know if you saw the Social Dilemma, the Netflix."}, {"time": 6254, "text": "Heard about it."}, {"time": 6255, "text": "Yeah, it's a great, it's really great documentary and... About what social networks are doing to our society?"}, {"time": 6264, "text": "But nothing, no phenomenon has a simple single cause."}, {"time": 6271, "text": "There are multiple small causes which all add up to a perfect storm."}, {"time": 6277, "text": "That's just how most things work."}, {"time": 6281, "text": "And so the fact that machine learning algorithms are serving people up information on social media that is consistent with what they've already viewed and making, is part of the reason that you have these silos but it's not the only reason why you have these silos."}, {"time": 6300, "text": "I think there are other things afoot that enhance people's inability to even have a decent conversation."}, {"time": 6313, "text": "Yeah, I mean, okay, so many things you said are just brilliant, so the experiential blindness but also from my perspective, like I preach and I try to practice empathy a lot and something about the way you've explained it makes me almost see it as a kind of exercise that we should all do, like to train, like to add experiences to the brain to expand this capacity to predict more effectively."}, {"time": 6343, "text": "So like what I do is kind of like a method acting thing which is I imagine what the life of a person is like."}, {"time": 6352, "text": "Just think, I mean, this is something you see with Black Lives Matter and police officers."}, {"time": 6358, "text": "It feels like they're both, not both, but I have, because martial arts and so on, I have a lot of friends who are cops."}, {"time": 6366, "text": "They don't necessarily have empathy or visualize the experience of the other."}, {"time": 6374, "text": "Certainly, currently, unfortunately, people aren't doing that with police officers."}, {"time": 6379, "text": "They're not imagining, they're not empathizing or putting themselves in the shoes of a police officer to realize how difficult that job is, how dangerous it is, how difficult it is to maintain calm and under so much uncertainty, all those kinds of things."}, {"time": 6395, "text": "But there's more, there's even, that's all that's true, but I think that there's even more, there's even more to be said there."}, {"time": 6401, "text": "I mean, like from a predicting brain standpoint, there's even more that can be said there."}, {"time": 6407, "text": "So I don't know if you wanna go down that path or you wanna stick on empathy, but I will also say that one of the things that I was most gratified by, I still am receiving, it's been more than three and a half years since How Motions Are Made came out and I'm still receiving daily emails from people, right?"}, {"time": 6424, "text": "So that's gratifying."}, {"time": 6425, "text": "But one of the most gratifying emails I received was from a police officer in Texas who told me that he thought that How Motions Are Made contained information that would be really helpful to resolving some of these difficulties."}, {"time": 6448, "text": "And he hadn't even read my op ed piece about when is a gun not a gun?"}, {"time": 6455, "text": "And like using what we know about the science of perception from a prediction standpoint, like the brain is a predictor, to understand a little differently what might be happening in these circumstances."}, {"time": 6469, "text": "So there's a real, what's hard about, it's hard to talk about because everyone gets mad at you when you talk about this, like, you know."}, {"time": 6479, "text": "And there is a way to understand this which has profound empathy for the suffering of people of color and that definitely is in line with Black Lives Matter at the same time as understanding the really difficult situation that police officers find themselves in."}, {"time": 6503, "text": "And I'm not talking about this bad apple or that bad apple."}, {"time": 6506, "text": "I'm not talking about police officers who are necessarily shooting people in the back as they run away."}, {"time": 6511, "text": "I'm talking about the cases of really good, well meaning cops who have the kind of predicting brain that everybody else has."}, {"time": 6522, "text": "They're in a really difficult situation that I think both they and the people who are harmed don't realize, like the way that these situations are constructed, I think it's just, there's a lot to be said there I guess is what I want to say."}, {"time": 6542, "text": "Yeah, is there something we can try to say in a sense, like what I'm, from the perspective of the predictive brain which is a fascinating perspective to take on this, you know, all the protests that are going on, there seems to be a concept of a police officer being built."}, {"time": 6562, "text": "No, I think that concept is there."}, {"time": 6565, "text": "But it's gaining strength, so it's being re, I mean."}, {"time": 6571, "text": "Sure, it is there."}, {"time": 6572, "text": "But I think, yeah, for sure, I think that that's right."}, {"time": 6575, "text": "I think that there's a shift in the stereotype of what I would say is a stereotype."}, {"time": 6584, "text": "There's a stereotype of a black man in this country that's always in movies and television, not always, but like largely, that many people watch."}, {"time": 6596, "text": "I mean, you think you're watching a 10 o clock drama and all you're doing is like kicking back and relaxing, but actually you're having certain predictions reinforced and others not."}, {"time": 6607, "text": "And what's happening now with police is the same thing, that there are certain stereotypes of a police officer that are being abandoned and other stereotypes that are being reinforced by what you see happening."}, {"time": 6623, "text": "All I'll say is that if you remember, I mean, there's a lot to say about this, really, that regardless of whether it makes people mad or not, I mean, I just, the science is what it is."}, {"time": 6637, "text": "Just remember what I said."}, {"time": 6639, "text": "The brain makes predictions about internal changes in the body first and then it starts to prepare motor action and then it makes a prediction about what you will see and hear and feel based on those actions, okay?"}, {"time": 6657, "text": "So it's also the case that we didn't talk about is that sensory sampling, like your brain's ability to sample what's out there is yoked to your heart rate, it's yoked to your heartbeats."}, {"time": 6672, "text": "There are certain phases of the heartbeat where it's easier for you to see what's happening in the world than in others."}, {"time": 6680, "text": "And so if your heart rate goes through the roof, you will be less likely, you will be more likely to just go with your prediction and not correct based on what's out there because you're actually literally not seeing as well."}, {"time": 6699, "text": "Or you will see things that aren't there, basically."}, {"time": 6703, "text": "Is there something that we could say by way of advice for when this episode is released in the chaos of emotion?"}, {"time": 6717, "text": "Sorry, I don't know about a term that's just flying around on social media."}, {"time": 6722, "text": "Well, I actually think it is emotion in the following sense."}, {"time": 6727, "text": "And it sounds a little bit like, it sounds a little bit like artificial in the way that I'm about to say it, but I really think that this is what's happening."}, {"time": 6738, "text": "One thing we haven't talked about is brains evolved, didn't evolve for you to see, they didn't evolve for you to hear, they didn't evolve for you to feel, they evolved to control your body."}, {"time": 6750, "text": "That's why you have a brain."}, {"time": 6751, "text": "You have a brain so that it can control your body."}, {"time": 6754, "text": "And the metaphor, the scientific term for predictively controlling your body is allostasis."}, {"time": 6760, "text": "Your brain is attempting to anticipate the needs of your body and meet those needs before they arise so that you can act as you need to act."}, {"time": 6771, "text": "And the metaphor that I use is a body budget."}, {"time": 6775, "text": "You know, your brain is running a budget for your body."}, {"time": 6777, "text": "It's not budgeting money, it's budgeting glucose and salt and water."}, {"time": 6781, "text": "And instead of having, you know, one or two bank accounts, it has gazillions."}, {"time": 6786, "text": "There are all these systems in your body that have to be kept in balance."}, {"time": 6790, "text": "And it's monitoring very closely, it's making predictions about like, when is it good to spend and when is it good to save and what would be a good investment and am I gonna get a return on my investment?"}, {"time": 6803, "text": "Whenever people talk about reward or reward prediction error or anything to do with reward or punishment, they're talking about the body budget."}, {"time": 6812, "text": "They're talking about your brain's predictions about whether or not there will be a deposit or withdrawal."}, {"time": 6819, "text": "So when your brain is running a deficit in your body budgets, you have some kind of metabolic imbalance, you experience that as discomfort."}, {"time": 6835, "text": "You experience that as distress."}, {"time": 6838, "text": "When your brain, when things are chaotic, you can't predict what's going to happen next."}, {"time": 6845, "text": "So I have this absolutely brilliant scientist working in my lab, his name is Jordan Theriot and he's published this really terrific paper on a sense of should, like why do we have social rules?"}, {"time": 6862, "text": "Why do we adhere to social norms?"}, {"time": 6867, "text": "It's because if I make myself predictable to you, then you are predictable to me."}, {"time": 6873, "text": "And if you're predictable to me, that's good because that is less metabolically expensive for me."}, {"time": 6881, "text": "Novelty or unpredictability at the extreme is expensive."}, {"time": 6886, "text": "And if it goes on for long enough, what happens is first of all, you will feel really jittery and antsy, which we describe as anxiety."}, {"time": 6896, "text": "It isn't necessarily anxiety."}, {"time": 6898, "text": "It could be just something is not predictable and you are experiencing arousal because the chemicals that help you learn increase your feeling of arousal basically."}, {"time": 6913, "text": "But if it goes on for long enough, you will become depleted and you will start to feel really, really, really distressed."}, {"time": 6922, "text": "So what we have is a culture full of people right now who their body budgets are just decimated and there's a tremendous amount of uncertainty."}, {"time": 6936, "text": "When you talk about it as depression and anxiety, it makes you think that it's not about your metabolism, that it's not about your body budgeting, that it's not about getting enough sleep or about eating well or about making sure that you have social connections."}, {"time": 6955, "text": "You think that it's something separate from that."}, {"time": 6957, "text": "But depression and anxiety are just a way of being in the world."}, {"time": 6961, "text": "They're a way of being in the world when things aren't quite right with your predictions."}, {"time": 6968, "text": "That's such a deep way of thinking."}, {"time": 6970, "text": "Like the brain is maintaining homeostasis."}, {"time": 6976, "text": "It's actually allostasis."}, {"time": 6979, "text": "And it's constantly making predictions and metabolically speaking, it's very costly to make novel, like constantly be learning to making adjustments."}, {"time": 6989, "text": "And then over time, there's a cost to be paid if you're just in a place of chaos where there's constant need for adjusting and learning and experience novel things."}, {"time": 7006, "text": "And so part of the problem here, there are a couple of things."}, {"time": 7010, "text": "Like I said, it's a perfect storm."}, {"time": 7012, "text": "There isn't a single cause."}, {"time": 7014, "text": "There are multiple cause, multiple things that combine together."}, {"time": 7017, "text": "It's a complex system, multiple things."}, {"time": 7021, "text": "Part of it is that they're metabolically encumbered and they're distressed."}, {"time": 7030, "text": "And in order to try to have empathy for someone who is very much unlike you, you have to forage for information."}, {"time": 7039, "text": "You have to explore information that is novel to you and unexpected."}, {"time": 7045, "text": "And that's expensive."}, {"time": 7047, "text": "And at a time when people feel, what do you do when you are running a deficit in your bank account?"}, {"time": 7054, "text": "You stop spending."}, {"time": 7057, "text": "What does it mean for a brain to stop spending?"}, {"time": 7060, "text": "A brain stops moving very much, stops moving the body and it stops learning."}, {"time": 7066, "text": "It just goes with its internal model."}, {"time": 7068, "text": "Brilliantly put, yeah."}, {"time": 7070, "text": "So empathy requires, to have empathy for someone who is unlike you requires learning and practice, foraging for information."}, {"time": 7084, "text": "I mean, it is something I talk about in the book in seven and a half lessons about the brain."}, {"time": 7090, "text": "It's hard, but it's hard."}, {"time": 7093, "text": "I think it's hard for people to have, to be curious about views that are unlike their own when they feel so encumbered."}, {"time": 7106, "text": "And I'll just tell you, I had this epiphany really."}, {"time": 7110, "text": "I was listening to Robert Reich's The System."}, {"time": 7114, "text": "He was talking about oligarchy versus democracy."}, {"time": 7119, "text": "And so oligarchy is where very wealthy people, like extremely wealthy people, shift power so that they become even more wealthy and even more insulated and from the pressures of the common person."}, {"time": 7138, "text": "It's actually the kind of system that leads to the collapse of civilizations if you believe Jared Diamond."}, {"time": 7145, "text": "Just say that."}, {"time": 7146, "text": "But anyways, I'm listening to this and I'm listening to him describe in fairly decent detail how the CEOs of these companies, there's been a shift in what it means to be a CEO and no longer being a steward of the community and so on, but like in the 1980s, it sort of shifted to this other model of being like an oligarch."}, {"time": 7170, "text": "And he's talking about how it used to be the case that CEOs made like 20 times what their employees made and now they make about 300 times on average what their employees made."}, {"time": 7189, "text": "So where did that money come from?"}, {"time": 7191, "text": "It came from the pockets of the employees."}, {"time": 7195, "text": "And they don't know about it, right?"}, {"time": 7197, "text": "No one knows about it."}, {"time": 7198, "text": "They just know they can't feed their children, they can't pay for healthcare, they can't take care of their family and they worry about what's gonna happen to their, they're living like months a month basically."}, {"time": 7211, "text": "Any one big bill could completely put them out on the street."}, {"time": 7215, "text": "So there are a huge number of people living like this."}, {"time": 7217, "text": "So all they, what they're experiencing, they don't know why they're experiencing it."}, {"time": 7222, "text": "And then someone comes along and gives them a narrative."}, {"time": 7226, "text": "Well, somebody else butted in line in front of you and that's why you're this way."}, {"time": 7232, "text": "That's why you experience what you're experiencing."}, {"time": 7235, "text": "And just for a minute, I was thinking, I had deep empathy for people who have beliefs that are really, really, really different from mine."}, {"time": 7250, "text": "But I was trying really hard to see it through their eyes."}, {"time": 7255, "text": "And did it cost me something metabolically?"}, {"time": 7259, "text": "I'm sure, I'm sure."}, {"time": 7262, "text": "But you had something in the gas tank."}, {"time": 7264, "text": "Well, I."}, {"time": 7264, "text": "In order to allocate that."}, {"time": 7267, "text": "I mean, that's the question is like, where did you, what resources did your brain draw on in order to actually make that effort?"}, {"time": 7274, "text": "Well, I'll tell you something, honestly, Lex."}, {"time": 7277, "text": "I don't have that much in the gas tank right now."}, {"time": 7279, "text": "Right, so I am surfing the stress that, stress is just, what is stress?"}, {"time": 7288, "text": "Stress is your brain is preparing for a big metabolic outlay and it just keeps preparing and preparing and preparing and preparing."}, {"time": 7295, "text": "You as a professor, you as a human."}, {"time": 7299, "text": "For me, this is a moment of existential crisis as much as anybody else, democracy, all of these things."}, {"time": 7305, "text": "So in many of my roles, so I guess what I'm trying to say is that I get up every morning and I exercise."}, {"time": 7315, "text": "I run, I row, I lift weights, right?"}, {"time": 7318, "text": "You exercise in the middle of the day."}, {"time": 7320, "text": "I saw your like, you know, daily thing."}, {"time": 7323, "text": "Yeah, I hate it actually."}, {"time": 7326, "text": "You love it, right?"}, {"time": 7327, "text": "You get a... No, I hate it."}, {"time": 7328, "text": "I hate it, but I do it religiously."}, {"time": 7334, "text": "Because it's a really good investment."}, {"time": 7336, "text": "It's an expenditure that is a really good investment."}, {"time": 7340, "text": "And so when I was exercising, I was listening to the book and when I realized the insights that I was sort of like playing around with, like, is this, does this make sense?"}, {"time": 7352, "text": "I didn't immediately plunge into it."}, {"time": 7354, "text": "I basically wrote some stuff down, I set it aside and then I did what I prepared myself to make an expenditure."}, {"time": 7362, "text": "I don't know what you do before you exercise."}, {"time": 7364, "text": "I always have a protein shake, always have a protein shake because I need to fuel up before I make this really big expenditure."}, {"time": 7372, "text": "And so I did the same thing."}, {"time": 7375, "text": "I didn't have a protein drink, but I did the same thing."}, {"time": 7378, "text": "And fueling up can mean lots of different things."}, {"time": 7381, "text": "It can mean talking to a friend about it."}, {"time": 7383, "text": "It can mean, you know, it can mean making sure you get a good night's sleep before you do it."}, {"time": 7388, "text": "It can mean lots of different things, but I guess I think we have to do these things."}, {"time": 7400, "text": "Yeah, I'm gonna re listen to this conversation several times, this is brilliant."}, {"time": 7406, "text": "But I do think about, you know, I've encountered so many people that can't possibly imagine that a good human being can vote for Donald Trump."}, {"time": 7418, "text": "And I've also encountered people that can't imagine that an intelligent person can possibly vote for Democrat."}, {"time": 7427, "text": "And I look at both these people, many of whom are friends, and let's just say, after this conversation, I can see as they're predicting brains not willing to invest the resources to empathize with the other side."}, {"time": 7446, "text": "And I think you have to in order to be able to, like, to see the obvious common humanity in us."}, {"time": 7454, "text": "I don't know what the system is that's creating this division."}, {"time": 7457, "text": "We can put it, like you said, it's a perfect storm."}, {"time": 7460, "text": "It might be the social media, I don't know what the hell it is."}, {"time": 7463, "text": "I think it's a bunch of things."}, {"time": 7464, "text": "I think it's, there's an economic system, which is disadvantaging large numbers of people."}, {"time": 7470, "text": "There's a use of social media."}, {"time": 7474, "text": "Like if you, you know, if I had to orchestrate or architect a system that would screw up a human body budget, it would be the one that we live in."}, {"time": 7484, "text": "You know, we don't sleep enough."}, {"time": 7485, "text": "We eat pseudo food, basically."}, {"time": 7488, "text": "We are on social media too much, which is full of ambiguity, which is really hard for a human nervous system, right?"}, {"time": 7495, "text": "Really, really hard."}, {"time": 7497, "text": "Like ambiguity with no context to predict in."}, {"time": 7499, "text": "I mean, it's like, really?"}, {"time": 7501, "text": "And then, you know, there are the economic concerns that affect large swaths of people in this country."}, {"time": 7506, "text": "I mean, it's really, I'm not saying everything is reducible to metabolism."}, {"time": 7511, "text": "Not everything is reducible to metabolism, but there, if you combine all these things together."}, {"time": 7518, "text": "It's helpful to think of it that way."}, {"time": 7520, "text": "Then somehow it's also, somehow it reduces the entirety of the human experience, the same kind of obvious logic."}, {"time": 7528, "text": "Like we should exercise every day in the same kind of way."}, {"time": 7531, "text": "We should empathize every day."}, {"time": 7535, "text": "You know, there are these really wonderful, wonderful programs for teens and sometimes also for parents of people who've lost children in wars and in conflicts, in political conflicts, where they go to a bucolic setting and they talk to each other about their experiences."}, {"time": 7554, "text": "And miraculous things happen, you know?"}, {"time": 7559, "text": "So, you know, it's easy to sort of shrug this stuff off It's easy to sort of shrug this stuff off as kind of Pollyanna ish."}, {"time": 7572, "text": "You know, like, what's this really gonna do?"}, {"time": 7573, "text": "But you have to think about, when my daughter went to college, I gave her advice."}, {"time": 7583, "text": "I said, try to be around people who let you be the kind of person you wanna be."}, {"time": 7592, "text": "We're back to free will."}, {"time": 7595, "text": "You have a choice, you have a choice."}, {"time": 7600, "text": "It might seem like a really hard choice."}, {"time": 7601, "text": "It might seem like an unimaginably difficult choice."}, {"time": 7606, "text": "You have a choice."}, {"time": 7607, "text": "Do you wanna be somebody who is wrapped in fury and agony?"}, {"time": 7614, "text": "Or do you wanna be somebody who extends a little empathy to somebody else?"}, {"time": 7620, "text": "And in the process, maybe learn something."}, {"time": 7622, "text": "Curiosity is the thing that protects you."}, {"time": 7627, "text": "Curiosity is the thing, it's curative curiosity."}, {"time": 7632, "text": "On social media, the thing I recommend to people, at least that's the way I've been approaching social media."}, {"time": 7640, "text": "It doesn't seem to be the common approach, but I basically give love to people who seem to also give love to others."}, {"time": 7650, "text": "So it's the same similar concept of surrounding yourself by the people you wanna become."}, {"time": 7656, "text": "And I ignore, sometimes block, but just ignore."}, {"time": 7660, "text": "I don't add aggression to people who are just constantly full of aggression and negativity and toxicity."}, {"time": 7668, "text": "There's a certain desire when somebody says something mean to say something, to say why, or try to alleviate the meanness and so on."}, {"time": 7681, "text": "But what you're doing essentially is you're now surrounding yourself by that group of folks that have that negativity."}, {"time": 7689, "text": "So even just the conversation."}, {"time": 7691, "text": "So I think it's just so powerful to put yourself amongst people whose basic mode of interaction is kindness."}, {"time": 7703, "text": "Because I don't know what it is, but maybe it's the way I'm built, is that to me is energizing for the gas tank that then I can pull to when I start reading The Rise and Fall of the Third Reich and start thinking about Nazi Germany."}, {"time": 7720, "text": "I can empathize with everybody involved."}, {"time": 7723, "text": "I can start to make these difficult thinking that's required to understand our little planet Earth."}, {"time": 7732, "text": "Well, there is research to back up what you said."}, {"time": 7734, "text": "There's research that's consistent with your intuition there, that there's research that shows that being kind to other people, doing something nice for someone else is like making a deposit to some extent."}, {"time": 7751, "text": "Because I think making a deposit not only in their body budgets, but also in yours."}, {"time": 7758, "text": "Like people feel good when they do good things for other people."}, {"time": 7764, "text": "We are social animals."}, {"time": 7766, "text": "We regulate each other's nervous systems for better and for worse, right?"}, {"time": 7770, "text": "The best thing for a human nervous system is another human."}, {"time": 7776, "text": "And the worst thing for a human nervous system is another human."}, {"time": 7781, "text": "So you decide, do you wanna be somebody who makes people feel better or do you wanna be somebody who causes people pain?"}, {"time": 7793, "text": "And we are more responsible for one another than we might like or than we might want."}, {"time": 7802, "text": "But remember what we said about social reality."}, {"time": 7805, "text": "Social reality, there are lots of different cultural norms about independence or collective nature of people."}, {"time": 7820, "text": "But the fact is we have socially dependent nervous systems."}, {"time": 7824, "text": "We evolved that way as a species."}, {"time": 7827, "text": "And in this country, we prize individual rights and freedoms."}, {"time": 7832, "text": "And that is a dilemma that we have to grapple with."}, {"time": 7838, "text": "And we have to do it in a way if we're gonna be productive about it."}, {"time": 7841, "text": "We have to do it in a way that requires engaging with each other, and which is what I understand the founding members of this country intended."}, {"time": 7858, "text": "Let me ask a few final silly questions."}, {"time": 7861, "text": "So one, talked a bit about love, but it's fun to ask somebody like you who can effectively, from at least neuroscience perspective, disassemble some of these romantic notions."}, {"time": 7875, "text": "But what do you make of romantic love?"}, {"time": 7878, "text": "Why do human beings seem to fall in love?"}, {"time": 7882, "text": "At least a bunch of 80s hair bands have written about it."}, {"time": 7887, "text": "Is that a nice feature to have?"}, {"time": 7889, "text": "Is that a bug?"}, {"time": 7891, "text": "Well, I'm really happy that I fell in love."}, {"time": 7895, "text": "I wouldn't want it any other way."}, {"time": 7897, "text": "But I would say."}, {"time": 7898, "text": "Is that you the person speaking or the neuroscientist?"}, {"time": 7901, "text": "Well, that's me the person speaking."}, {"time": 7904, "text": "But I would say as a neuroscientist, babies are born not able to regulate their own body budgets because their brains aren't fully wired yet."}, {"time": 7914, "text": "When you feed a baby, when you cuddle a baby, everything you do with a baby impacts that baby's body budget and helps to wire that baby's brain to manage eventually her own body budget to some extent."}, {"time": 7933, "text": "That's the basis biologically of attachment."}, {"time": 7940, "text": "Humans evolved as a species to be socially dependent, meaning you cannot manage your body budget on your own without a tax that eventually you pay many years later in terms of some metabolic illness."}, {"time": 7963, "text": "Loneliness, when you break up with someone that you love or you lose them, you feel like it's gonna kill you, but it doesn't."}, {"time": 7973, "text": "But loneliness will kill you."}, {"time": 7975, "text": "It will kill you approximately, what is it, seven years earlier?"}, {"time": 7979, "text": "I can't remember exactly the exact number."}, {"time": 7981, "text": "It's actually in the web notes to seven and a half lessons."}, {"time": 7985, "text": "But social isolation and loneliness will kill you earlier than you would otherwise die."}, {"time": 7991, "text": "And the reason why is that you didn't evolve to manage your nervous system on your own."}, {"time": 7998, "text": "And when you do, you pay a little tax and that tax accrues very slightly over time, over a long period of time so that by the time you're in middle age or a little older, you are more likely to die sooner from some metabolic illness, from heart disease, from diabetes, from depression."}, {"time": 8018, "text": "You're more likely to develop Alzheimer's disease."}, {"time": 8020, "text": "I mean, it takes a long time for that tax to accrue, but it does."}, {"time": 8027, "text": "So yes, I think it's a good thing for people to fall in love."}, {"time": 8033, "text": "But I think the funny view of it is that it's clear that humans need the social attachment to, what is it, manage their nervous system as you're describing."}, {"time": 8048, "text": "And the reason you wanna stay with somebody for a long time is so you don't have, is the novelty is very costly for."}, {"time": 8056, "text": "Well, now you're mixing thing."}, {"time": 8058, "text": "Now you're, you know, you have to decide whether."}, {"time": 8061, "text": "But what I would say is when you lose someone you love, it feels like you've lost a part of you."}, {"time": 8069, "text": "And that's because you have."}, {"time": 8072, "text": "You've lost someone who was contributing to your body budget."}, {"time": 8077, "text": "We are the caretakers of one another's nervous systems, like it or not."}, {"time": 8081, "text": "And out of that comes very deep feelings of attachment, some of which are romantic love."}, {"time": 8090, "text": "Are you afraid of your own mortality?"}, {"time": 8095, "text": "We're two humans sitting here."}, {"time": 8097, "text": "Do you think, do you ponder your own mortality?"}, {"time": 8101, "text": "I mean, somebody thinks about your brain a lot."}, {"time": 8105, "text": "It seems one of the more terrifying or, I don't know."}, {"time": 8112, "text": "I don't know how to feel about it, but it seems to be one of the most definitive aspects of life is that it ends."}, {"time": 8118, "text": "It's a complicated answer, but I think the best I can do in a short snippet would be to say, for a very long time, I did not fear my own mortality."}]}, {"title": "Dmitry Korkin: Evolution of Proteins, Viruses, Life, and AI | Lex Fridman Podcast #153", "id": "I51DuprOb0o", "quotes": [{"time": 400, "text": "So the spike protein."}, {"time": 401, "text": "And so it was solved very quickly."}, {"time": 406, "text": "And the reason for that is the advancement of this technology is pretty spectacular."}, {"time": 413, "text": "How many domains does the, is it more than one domain?"}, {"time": 418, "text": "Oh yes, I mean, so it's a very complex structure."}, {"time": 421, "text": "And we, you know, on top of the complexity of a single protein, right?"}, {"time": 428, "text": "So this structure is actually is a complex, is a trimer."}, {"time": 433, "text": "So it needs to form a trimer in order to function properly."}, {"time": 437, "text": "What's a complex?"}, {"time": 438, "text": "So a complex is a glomeration of multiple proteins."}, {"time": 442, "text": "And so we can have the same protein copied in multiple, you know, made up in multiple copies and forming something that we called a homo oligomer."}, {"time": 456, "text": "Homo means the same, right?"}, {"time": 458, "text": "So in this case, so the spike protein is the, is an example of a homo tetram, homo trimer, sorry."}, {"time": 466, "text": "So you need three copies of it?"}, {"time": 468, "text": "Three copies."}, {"time": 468, "text": "In order to."}, {"time": 470, "text": "We have these three chains, the three molecular chains coupled together and performing the function."}, {"time": 478, "text": "That's what, when you look at this protein from the top, you see a perfect triangle."}, {"time": 484, "text": "So, but other, you know, so other complexes are made up of, you know, different proteins."}, {"time": 492, "text": "Some of them are completely different."}, {"time": 495, "text": "Some of them are similar."}, {"time": 496, "text": "The hemoglobin molecule, right?"}, {"time": 498, "text": "So it's actually, it's a protein complex."}, {"time": 501, "text": "It's made of four basic subunits."}, {"time": 505, "text": "Two of them are identical to each other."}, {"time": 509, "text": "Two other identical to each other, but they are also similar to each other, which sort of gives us some ideas about the evolution of this, you know, of this molecule."}, {"time": 520, "text": "And perhaps, so one of the hypothesis is that, you know, in the past, it was just a homo tetramer, right?"}, {"time": 528, "text": "So four identical copies, and then it became, you know, sort of modified, it became mutated over the time and became more specialized."}, {"time": 540, "text": "Can we linger on the spike protein for a little bit?"}, {"time": 542, "text": "Is there something interesting or like beautiful you find about it?"}, {"time": 546, "text": "I mean, first of all, it's an incredibly challenging protein."}, {"time": 550, "text": "And so we, as a part of our sort of research to understand the structural basis of this virus, to sort of decode, structurally decode, every single protein in its proteome, which, you know, we've been working on this spike protein."}, {"time": 571, "text": "And one of the main challenges was that the cryoEM data allows us to reconstruct or to obtain the 3D coordinates of roughly two thirds of the protein."}, {"time": 588, "text": "The rest of the one third of this protein, it's a part that is buried into the membrane of the virus and of the viral envelope."}, {"time": 601, "text": "And it also has a lot of unstable structures around it."}, {"time": 606, "text": "So it's chemically interacting somehow with whatever the hex is connecting to."}, {"time": 610, "text": "Yeah, so people are still trying to understand."}, {"time": 612, "text": "So the nature of, and the role of this one third, because the top part, you know, the primary function is to get attached to the ACE2 receptor, human receptor."}, {"time": 628, "text": "There is also beautiful mechanics of how this thing happens, right?"}, {"time": 634, "text": "So because there are three different copies of this chains, you know, there are three different domains, right?"}, {"time": 643, "text": "So we're talking about domains."}, {"time": 644, "text": "So this is the receptor binding domains, RBDs, that gets untangled and get ready to get attached to the receptor."}, {"time": 655, "text": "And now they are not necessarily going in a sync mode."}, {"time": 662, "text": "As a matter of fact."}, {"time": 664, "text": "It's asynchronous."}, {"time": 665, "text": "So yes, and this is where another level of complexity comes into play because right now what we see is, we typically see just one of the arms going out and getting ready to be attached to the ACE2 receptors."}, {"time": 687, "text": "However, there was a recent mutation that people studied in that spike protein."}, {"time": 695, "text": "And very recently, a group from UMass Medical School will happen to collaborate with groups."}, {"time": 705, "text": "So this is a group of Jeremy Lubin and a number of other faculty."}, {"time": 711, "text": "They actually solve the mutated structure of the spike."}, {"time": 719, "text": "And they showed that actually, because of these mutations, you have more than one arms opening up."}, {"time": 728, "text": "And so now, so the frequency of two arms going up increase quite drastically."}, {"time": 738, "text": "Does that change the dynamics somehow?"}, {"time": 740, "text": "It potentially can change the dynamics because now you have two possible opportunities to get attached to the ACE2 receptor."}, {"time": 750, "text": "It's a very complex molecular process, mechanistic process."}, {"time": 754, "text": "But the first step of this process is the attachment of this spike protein, of the spike trimer to the human ACE2 receptor."}, {"time": 766, "text": "So this is a molecule that sits on the surface of the human cell."}, {"time": 771, "text": "And that's essentially what initiates, what triggers the whole process of encapsulation."}, {"time": 778, "text": "If this was dating, this would be the first date."}, {"time": 781, "text": "So this is the..."}, {"time": 783, "text": "In a way."}, {"time": 785, "text": "So is it possible to have the spike protein just like floating about on its own?"}, {"time": 790, "text": "Or does it need that interactability with the membrane?"}, {"time": 794, "text": "Yeah, so it needs to be attached, at least as far as I know."}, {"time": 799, "text": "But when you get this thing attached on the surface, there is also a lot of dynamics on how it sits on the surface."}, {"time": 808, "text": "So for example, there was a recent work in, again, where people use the cryolectron microscopy to get the first glimpse of the overall structure."}, {"time": 818, "text": "It's a very low res, but you still get some interesting details about the surface, about what is happening inside, because we have literally no clue until recent work about how the capsid is organized."}, {"time": 834, "text": "What's a capsid?"}, {"time": 835, "text": "So a capsid is essentially, it's the inner core of the viral particle where there is the RNA of the virus, and it's protected by another protein, N protein, that essentially acts as a shield."}, {"time": 853, "text": "But now we are learning more and more, so it's actually, it's not just this shield, it potentially is used for the stability of the outer shell of the virus."}, {"time": 865, "text": "So it's pretty complicated."}, {"time": 867, "text": "And I mean, understanding all of this is really useful for trying to figure out like developing a vaccine or some kind of drug to attack, any aspects of this, right?"}, {"time": 876, "text": "So, I mean, there are many different implications to that."}, {"time": 879, "text": "First of all, it's important to understand the virus itself, right?"}, {"time": 884, "text": "So in order to understand how it acts, what is the overall mechanistic process of this virus replication, of this virus proliferation to the cell, right?"}, {"time": 900, "text": "So that's one aspect."}, {"time": 903, "text": "The other aspect is designing new treatments."}, {"time": 906, "text": "So one of the possible treatments is designing nanoparticles."}, {"time": 912, "text": "And so some nanoparticles that will resemble the viral shape that would have the spike integrated, and essentially would act as a competitor to the real virus by blocking the ACE2 receptors, and thus preventing the real virus entering the cell."}, {"time": 930, "text": "Now, there are also, you know, there is a very interesting direction in looking at the membrane, at the envelope portion of the protein and attacking its M protein."}, {"time": 944, "text": "So there are, you know, to give you a, you know, sort of a brief overview, there are four structural proteins."}, {"time": 952, "text": "These are the proteins that made up a structure of the virus."}, {"time": 958, "text": "So SPIKE, S protein that acts as a trimer, so it needs three copies."}, {"time": 966, "text": "E, envelope protein that acts as a pantomime, so it needs five copies to act properly."}, {"time": 973, "text": "M is a membrane protein, it forms dimers, and actually it forms beautiful lattice."}, {"time": 980, "text": "And this is something that we've been studying and we are seeing it in simulations."}, {"time": 984, "text": "It actually forms a very nice grid or, you know, threads, you know, of different dimers attached next to each other."}, {"time": 993, "text": "Just a bunch of copies of each other, and they naturally, when you have a bunch of copies of each other, they form an interesting lattice."}, {"time": 999, "text": "And, you know, if you think about this, right?"}, {"time": 1002, "text": "So this complex, you know, the viral shape needs to be organized somehow, self organized somehow, right?"}, {"time": 1012, "text": "So it, you know, if it was a completely random process, you know, you probably wouldn't have the envelope shell of the ellipsoid shape, you know, you would have something, you know, pretty random, right, shape."}, {"time": 1027, "text": "So there is some, you know, regularity in how this, you know, how this M dimers get to attach to each other in a very specific directed way."}, {"time": 1040, "text": "Is that understood at all?"}, {"time": 1043, "text": "It's not understood."}, {"time": 1044, "text": "We are now, we've been working in the past six months since, you know, we met, actually, this is where we started working on trying to understand the overall structure of the envelope and the key components that made up this, you know, structure."}, {"time": 1061, "text": "Wait, does the envelope also have the lattice structure or no?"}, {"time": 1064, "text": "So the envelope is essentially is the outer shell of the viral particle."}, {"time": 1068, "text": "The N, the nucleocapsid protein, is something that is inside."}, {"time": 1074, "text": "But get that, the N is likely to interact with M. Does it go M and E?"}, {"time": 1081, "text": "Like, where's the E and the M?"}, {"time": 1082, "text": "So E, those different proteins, they occur in different copies on the viral particle."}, {"time": 1090, "text": "So E, this pentamer complex, we only have two or three, maybe, per each particle, okay?"}, {"time": 1098, "text": "We have thousand or so of M dimers that essentially made up, that makes up the entire, you know, outer shell."}, {"time": 1110, "text": "So most of the outer shell is the M. M dimer."}, {"time": 1114, "text": "And the M protein."}, {"time": 1115, "text": "When you say particle, that's the virion, the virus, the individual virus."}, {"time": 1120, "text": "It's a single, yes."}, {"time": 1120, "text": "Single element of the virus, it's a single virus."}, {"time": 1123, "text": "Single virus, right."}, {"time": 1125, "text": "And we have about, you know, roughly 50 to 90 spike trimmers."}, {"time": 1131, "text": "So when you, you know, when you show a..."}, {"time": 1134, "text": "Per virus particle."}, {"time": 1136, "text": "Sorry, what did you say, 50 to 90?"}, {"time": 1138, "text": "50 to 90, right?"}, {"time": 1140, "text": "So this is how this thing is organized."}, {"time": 1144, "text": "And so now, typically, right, so you see these, the antibodies that target, you know, spike protein, certain parts of the spike protein, but there could be some, also some treatments, right?"}, {"time": 1157, "text": "So these are, you know, these are small molecules that bind strategic parts of these proteins, disrupting its function."}, {"time": 1169, "text": "So one of the promising directions, it's one of the newest directions, is actually targeting the M dimer of the protein."}, {"time": 1180, "text": "Targeting the proteins that make up this outer shell."}, {"time": 1184, "text": "Because if you're able to destroy the outer shell, you're essentially destroying the viral particle itself."}, {"time": 1192, "text": "So preventing it from, you know, functioning at all."}, {"time": 1196, "text": "So that's, you think is, from a sort of cyber security perspective, virus security perspective, that's the best attack vector?"}, {"time": 1205, "text": "Is, or like, that's a promising attack vector?"}, {"time": 1208, "text": "I would say, yeah."}, {"time": 1209, "text": "So, I mean, there's still tons of research needs to be, you know, to be done."}, {"time": 1214, "text": "But yes, I think, you know, so."}, {"time": 1216, "text": "There's more attack surface, I guess."}, {"time": 1218, "text": "More attack surface."}, {"time": 1219, "text": "But, you know, from our analysis, from other evolutionary analysis, this protein is evolutionarily more stable compared to the, say, to the spike protein."}, {"time": 1231, "text": "Oh, and stable means a more static target?"}, {"time": 1235, "text": "Well, yeah, so it doesn't change."}, {"time": 1238, "text": "It doesn't evolve from the evolutionary perspective so drastically as, for example, the spike protein."}, {"time": 1246, "text": "There's a bunch of stuff in the news about mutations of the virus in the United Kingdom."}, {"time": 1251, "text": "I also saw in South Africa something."}, {"time": 1254, "text": "Maybe that was yesterday."}, {"time": 1256, "text": "You just kind of mentioned about stability and so on."}, {"time": 1260, "text": "Which aspects of this are mutatable and which aspects, if mutated, become more dangerous?"}, {"time": 1267, "text": "And maybe even zooming out, what are your thoughts and knowledge and ideas about the way it's mutated, all the news that we've been hearing?"}, {"time": 1275, "text": "Are you worried about it from a biological perspective?"}, {"time": 1278, "text": "Are you worried about it from a human perspective?"}, {"time": 1281, "text": "So, I mean, you know, mutations are sort of a general way for these viruses to evolve, right?"}, {"time": 1288, "text": "So, it's, you know, it's essentially, this is the way they evolve."}, {"time": 1294, "text": "This is the way they were able to jump from one species to another."}, {"time": 1302, "text": "We also see some recent jumps."}, {"time": 1306, "text": "There were some incidents of this virus jumping from human to dogs."}, {"time": 1311, "text": "So, you know, there is some danger in those jumps because every time it jumps, it also mutates, right?"}, {"time": 1319, "text": "So, when it jumps to the species and jumps back, right?"}, {"time": 1326, "text": "So, it acquires some mutations that are sort of driven by the environment of a new host, right?"}, {"time": 1336, "text": "And it's different from the human environment."}, {"time": 1339, "text": "And so, we don't know whether the mutations that are acquired in the new species are neutral with respect to the human host or maybe, you know, maybe damaging."}, {"time": 1352, "text": "Yeah, change is always scary, but so are you worried about, I mean, it seems like because the spread is, during winter now, seems to be exceptionally high and especially with a vaccine just around the corner already being actually deployed, is there some worry that this puts evolutionary pressure, selective pressure on the virus for it to mutate?"}, {"time": 1379, "text": "Is that a source of worry?"}, {"time": 1380, "text": "Well, I mean, there is always this thought in the scientist's mind, you know, what will happen, right?"}, {"time": 1388, "text": "So, I know there've been discussions about sort of the arms race between the ability of the humanity to get vaccinated faster than the virus, you know, essentially, you know, it becomes, you know, resistant to the vaccine."}, {"time": 1414, "text": "I mean, I don't worry that much simply because, you know, there is not that much evidence to that."}, {"time": 1424, "text": "To aggressive mutation around the vaccine."}, {"time": 1427, "text": "Exactly, you know, obviously there are mutations around the vaccine, so the reason we get vaccinated every year against the seasonal mutations, right?"}, {"time": 1441, "text": "But, you know, I think it's important to study it."}, {"time": 1446, "text": "No doubts, right?"}, {"time": 1484, "text": "And hopefully that knowledge will enable us to sort of forecast the evolutionary traces, the future evolutionary traces of this virus."}, {"time": 1495, "text": "I mean, what, from a biological perspective, this might be a dumb question, but is there parts of the virus that if souped up, like through mutation, could make it more effective at doing its job?"}, {"time": 1509, "text": "We're talking about this specific coronavirus because we were talking about the different, like, the membrane, the M protein, the E protein, the N and the S, the spike, is there some?"}, {"time": 1524, "text": "And there are 20 or so more in addition to that."}, {"time": 1527, "text": "But is that a dumb way to look at it?"}, {"time": 1529, "text": "Like, which of these, if mutated, could have the greatest impact, potentially damaging impact, on the effectiveness of the virus?"}, {"time": 1541, "text": "So it's actually, it's a very good question because, and the short answer is, we don't know yet."}, {"time": 1548, "text": "But of course there is capacity of this virus to become more efficient."}, {"time": 1553, "text": "The reason for that is, you know, so if you look at the virus, I mean, it's a machine, right?"}, {"time": 1559, "text": "So it's a machine that does a lot of different functions, and many of these functions are sort of nearly perfect, but they're not perfect."}, {"time": 1567, "text": "And those mutations can have the greatest impact and make those functions more perfect."}, {"time": 1574, "text": "For example, the attachment to ACE2 receptor, right, of the spike, right?"}, {"time": 1579, "text": "So, you know, has this virus reached the efficiency in which the attachment is carried out?"}, {"time": 1591, "text": "Or there are some mutations that still to be discovered, right, that will make this attachment sort of stronger, or, you know, something more, in a way more efficient from the point of view of this virus functioning."}, {"time": 1611, "text": "That's sort of the obvious example."}, {"time": 1614, "text": "But if you look at each of these proteins, I mean, it's there for a reason, it performs certain function."}, {"time": 1620, "text": "And it could be that certain mutations will, you know, enhance this function."}, {"time": 1628, "text": "It could be that some mutations will make this function much less efficient, right?"}, {"time": 1633, "text": "So that's also the case."}, {"time": 1636, "text": "Let's, since we're talking about the evolutionary history of a virus, let's zoom back out and look at the evolution of proteins."}, {"time": 1645, "text": "I glanced at this 2010 Nature paper on the quote, ongoing expansion of the protein universe."}, {"time": 1654, "text": "And then, you know, it kind of implies and talks about that proteins started with a common ancestor, which is, you know, kind of interesting."}, {"time": 1664, "text": "It's interesting to think about like, even just like the first organic thing that started life on Earth."}, {"time": 1671, "text": "And from that, there's now, you know, what is it?"}, {"time": 1676, "text": "3.5 billion years later, there's now millions of proteins."}, {"time": 1679, "text": "And they're still evolving."}, {"time": 1681, "text": "And that's, you know, in part, one of the things that you're researching."}, {"time": 1685, "text": "Is there something interesting to you about the evolution of proteins from this initial ancestor to today?"}, {"time": 1694, "text": "Is there something beautiful and insightful about this long story?"}, {"time": 1698, "text": "So I think, you know, if I were to pick a single keyword about protein evolution, I would pick modularity, something that we talked about in the beginning."}, {"time": 1712, "text": "And that's the fact that the proteins are no longer considered as, you know, as a sequence of letters."}, {"time": 1721, "text": "There are hierarchical complexities in the way these proteins are organized."}, {"time": 1728, "text": "And these complexities are actually going beyond the protein sequence."}, {"time": 1733, "text": "It's actually going all the way back to the gene, to the nucleotide sequence."}, {"time": 1740, "text": "And so, you know, again, these protein domains, they are not only functional building blocks, they are also evolutionary building blocks."}, {"time": 1749, "text": "And so what we see in the sort of, in the later stages of evolution, I mean, once this stable structurally and functionally building blocks were discovered, they essentially, they stay, those domains stay as such."}, {"time": 1768, "text": "So that's why if you start comparing different proteins, you will see that many of them will have similar fragments."}, {"time": 1777, "text": "And those fragments will correspond to something that we call protein domain families."}, {"time": 1782, "text": "And so they are still different because you still have mutations and, you know, the, you know, different mutations are attributed to, to, you know, diversification of the function of this, you know, protein domains."}, {"time": 1798, "text": "However, you don't, you very rarely see, you know, the evolutionary events that would split this domain into fragments because, and it's, you know, once you have the domain split, you actually, you, you know, you can completely cancel out its function or at the very least you can reduce it."}, {"time": 1826, "text": "And that's not, you know, efficient from the point of view of the, you know, of the cell functioning."}, {"time": 1832, "text": "So, so the, the, the protein domain level is a very important one."}, {"time": 1839, "text": "Now, on top of that, right?"}, {"time": 1842, "text": "So if you look at the proteins, right, so you have this structural units and they carry out the function, but then much less is known about things that connect this protein domains, something that we call linkers."}, {"time": 1856, "text": "And those linkers are completely flexible, you know, parts of the protein that nevertheless carry out a lot of function."}, {"time": 1866, "text": "So it's like little tails, little heads."}, {"time": 1868, "text": "So, so, so we do have tails."}, {"time": 1869, "text": "So they're called termini, C and N termini."}, {"time": 1872, "text": "So these are things right on the, on, on, on one and another ends of the protein sequence."}, {"time": 1880, "text": "So they are also very important."}, {"time": 1882, "text": "So they, they attributed to very specific interactions between the proteins."}, {"time": 1888, "text": "But you're referring to the links between domains."}, {"time": 1890, "text": "That connect the domains."}, {"time": 1892, "text": "And, you know, apart from the, just the, the simple perspective, if you have, you know, a very short domain, you have, sorry, a very short linker, you have two domains next to each other."}, {"time": 1905, "text": "They are forced to be next to each other."}, {"time": 1907, "text": "If you have a very long one, you have the domains that are extremely flexible and they carry out a lot of sort of spatial reorganization, right?"}, {"time": 1918, "text": "But on top of that, right, just this linker itself, because it's so flexible, it actually can adapt to a lot of different shapes."}, {"time": 1927, "text": "And therefore it's a, it's a very good interactor when it comes to interaction between this protein and other protein, right?"}, {"time": 1935, "text": "So these things also evolve, you know, and they in a way have different sort of laws of the driving laws that underlie the evolution because they no longer need to, to preserve certain structure, right?"}, {"time": 1957, "text": "Unlike protein domains."}, {"time": 1958, "text": "And so on top of that, you have something that is even less studied."}, {"time": 1965, "text": "And this is something that attribute to, to the concept of alternative splicing."}, {"time": 1973, "text": "So alternative splicing."}, {"time": 1974, "text": "So it's a, it's a very cool concept."}, {"time": 1976, "text": "It's something that we've been fascinated about for, you know, over a decade in my lab and trying to do research with that."}, {"time": 1985, "text": "But so, you know, so typically, you know, a simplistic perspective is that one gene is equal one protein product, right?"}, {"time": 1996, "text": "So you have a gene, you know, you transcribe it and translate it and it becomes a protein."}, {"time": 2004, "text": "In reality, when we talk about eukaryotes, especially sort of more recent eukaryotes that are very complex, the gene is no longer equal to one protein."}, {"time": 2020, "text": "It actually can produce multiple functionally, you know, active protein products."}, {"time": 2030, "text": "And each of them is, you know, is called an alternatively spliced product."}, {"time": 2037, "text": "The reason it happens is that if you look at the gene, it actually has, it has also blocks."}, {"time": 2045, "text": "And the blocks, some of which, and it's essentially, it goes like this."}, {"time": 2050, "text": "So we have a block that will later be translated."}, {"time": 2053, "text": "We call it exon."}, {"time": 2055, "text": "Then we'll have a block that is not translated, cut out."}, {"time": 2059, "text": "We call it intron."}, {"time": 2060, "text": "So we have exon, intron, exon, intron, et cetera, et cetera, et cetera, right?"}, {"time": 2064, "text": "So sometimes you can have, you know, dozens of these exons and introns."}, {"time": 2069, "text": "So what happens is during the process when the gene is converted to RNA, we have things that are cut out, the introns that are cut out, and exons that now get assembled together."}, {"time": 2087, "text": "And sometimes we will throw out some of the exons and the remaining protein product will become still be the same."}, {"time": 2096, "text": "Oh, different."}, {"time": 2097, "text": "So now you have fragments of the protein that no longer there."}, {"time": 2101, "text": "They were cut out with the introns."}, {"time": 2103, "text": "Sometimes you will essentially take one exon and replace it with another one, right?"}, {"time": 2109, "text": "So there's some flexibility in this process."}, {"time": 2112, "text": "So that creates a whole new level of complexity."}, {"time": 2117, "text": "Cause now."}, {"time": 2118, "text": "Is this random though?"}, {"time": 2118, "text": "Is it random?"}, {"time": 2119, "text": "It's not random."}, {"time": 2120, "text": "We, and this is where I think now the appearance of this modern single cell and before that tissue level sequencing, next generation sequencing techniques such as RNA seed allows us to see that these are the events that often happen in response."}, {"time": 2141, "text": "It's a dynamic event that happens in response to disease or in response to certain developmental stage of a cell."}, {"time": 2151, "text": "And this is an incredibly complex layer that also undergoes, I mean, because it's at the gene level, right?"}, {"time": 2161, "text": "So it undergoes certain evolution, right?"}, {"time": 2165, "text": "And now we have this interplay between what is happening in the protein world and what is happening in the gene and RNA world."}, {"time": 2177, "text": "And for example, it's often that we see that the boundaries of this exons coincide with the boundaries of the protein domains, right?"}, {"time": 2192, "text": "So there is this close interplay to that."}, {"time": 2196, "text": "It's not always, I mean, otherwise it would be too simple, right?"}, {"time": 2200, "text": "But we do see the connection between those sort of machineries."}, {"time": 2205, "text": "And obviously the evolution will pick up this complexity and, you know."}, {"time": 2211, "text": "Select for whatever is successful, whatever is interesting function."}, {"time": 2215, "text": "We see that complexity in play and makes this question more complex, but more exciting."}, {"time": 2222, "text": "Small detour, I don't know if you think about this into the world of computer science."}, {"time": 2227, "text": "There's a Douglas Hostetter, I think, came up with the name of Quine, which are, I don't know if you're familiar with these things, but it's computer programs that have, I guess, exon and intron, and they copy, the whole purpose of the program is to copy itself."}, {"time": 2246, "text": "So it prints copies of itself, but can also carry information inside of it."}, {"time": 2250, "text": "So it's a very kind of crude, fun exercise of, can we sort of replicate these ideas from cells?"}, {"time": 2260, "text": "Can we have a computer program that when you run it, just print itself, the entirety of itself, and does it in different programming languages and so on."}, {"time": 2270, "text": "I've been playing around and writing them."}, {"time": 2271, "text": "It's a kind of fun little exercise."}, {"time": 2273, "text": "You know, when I was a kid, so you know, it was essentially one of the sort of main stages in informatics Olympiads that you have to reach in order to be any so good, is you should be able to write a program that replicates itself."}, {"time": 2296, "text": "And so the task then becomes even sort of more complicated."}, {"time": 2300, "text": "So what is the shortest program?"}, {"time": 2304, "text": "And of course, it's a function of a programming language, but yeah, I remember a long, long, long time ago when we tried to make it short and short and find the shortcut."}, {"time": 2316, "text": "There's actually on a stack exchange, there's a entire site called CodeGolf, I think, where the entirety is just the competition."}, {"time": 2326, "text": "People just come up with whatever task, I don't know, like write code that reports the weather today."}, {"time": 2334, "text": "And the competition is about whatever programming language, what is the shortest program?"}, {"time": 2340, "text": "And it makes you actually, people should check it out because it makes you realize there's some weird programming languages out there."}, {"time": 2347, "text": "But just to dig on that a little deeper, do you think, in computer science, we don't often think about programs, just like the machine learning world now, that's still kind of basic programs."}, {"time": 2366, "text": "And then there's humans that replicate themselves, right?"}, {"time": 2369, "text": "And there's these mutations and so on."}, {"time": 2371, "text": "Do you think we'll ever have a world where there's programs that kind of have an evolutionary process?"}, {"time": 2380, "text": "So I'm not talking about evolutionary algorithms, but I'm talking about programs that kind of mate with each other and evolve and like on their own replicate themselves."}, {"time": 2389, "text": "So this is kind of the idea here is, that's how you can have a runaway thing."}, {"time": 2397, "text": "So we think about machine learning as a system that gets smarter and smarter and smarter and smarter."}, {"time": 2401, "text": "At least the machine learning systems of today are like, it's a program that you can like turn off, as opposed to throwing a bunch of little programs out there and letting them like multiply and mate and evolve and replicate."}, {"time": 2417, "text": "Do you ever think about that kind of world, when we jump from the biological systems that you're looking at to artificial ones?"}, {"time": 2427, "text": "I mean, it's almost like you take the sort of the area of intelligent agents, right?"}, {"time": 2434, "text": "Which are essentially the independent sort of codes that run and interact and exchange the information, right?"}, {"time": 2442, "text": "So I don't see why not."}, {"time": 2445, "text": "I mean, it could be sort of a natural evolution in this area of computer science."}, {"time": 2452, "text": "I think it's kind of an interesting possibility."}, {"time": 2454, "text": "It's terrifying too, but I think it's a really powerful tool."}, {"time": 2458, "text": "Like to have like agents that, you know, we have social networks with millions of people and they interact."}, {"time": 2463, "text": "I think it's interesting to inject into that, was already injected into that bots, right?"}, {"time": 2468, "text": "But those bots are pretty dumb."}, {"time": 2471, "text": "You know, they're probably pretty dumb algorithms."}, {"time": 2475, "text": "You know, it's interesting to think that there might be bots that evolve together with humans."}, {"time": 2480, "text": "And there's the sea of humans and robots that are operating first in the digital space."}, {"time": 2486, "text": "And then you can also think, I love the idea."}, {"time": 2489, "text": "Some people worked, I think at Harvard, at Penn, there's robotics labs that, you know, take as a fundamental task to build a robot that given extra resources can build another copy of itself, like in the physical space, which is super difficult to do, but super interesting."}, {"time": 2510, "text": "I remember there's like research on robots that can build a bridge."}, {"time": 2515, "text": "So they make a copy of themselves and they connect themselves and the sort of like self building bridge based on building blocks."}, {"time": 2522, "text": "You can imagine like a building that self assembles."}, {"time": 2525, "text": "So it's basically self assembling structures from robotic parts."}, {"time": 2530, "text": "But it's interesting to, within that robot, add the ability to mutate and do all the interesting like little things that you're referring to in evolution to go from a single origin protein building block to like this weird complex."}, {"time": 2548, "text": "And if you think about this, I mean, you know, the bits and pieces are there, you know."}, {"time": 2554, "text": "So you mentioned the evolution algorithm, right?"}, {"time": 2557, "text": "You know, so this is sort of, and maybe sort of the goal is in a way different, right?"}, {"time": 2563, "text": "So the goal is to, you know, to essentially, to optimize your search, right?"}, {"time": 2570, "text": "So, but sort of the ideas are there."}, {"time": 2573, "text": "So people recognize that, you know, that the recombination events lead to global changes in the search trajectories, the mutations event is a more refined, you know, step in the search."}, {"time": 2589, "text": "Then you have, you know, other sort of nature inspired algorithm, right?"}, {"time": 2596, "text": "So one of the reasons that, you know, I think it's one of the funnest one is the slime based algorithm, right?"}, {"time": 2604, "text": "So it's, I think the first was introduced by the Japanese group, where it was able to solve some pre complex problems."}, {"time": 2615, "text": "So that's, and then I think there are still a lot of things we've yet to, you know, borrow from the nature, right?"}, {"time": 2628, "text": "So there are a lot of sort of ideas that nature, you know, gets to offer us that, you know, it's up to us to grab it and to, you know, get the best use of it."}, {"time": 2642, "text": "Including neural networks, you know, we have a very crude inspiration from nature on neural networks."}, {"time": 2648, "text": "Maybe there's other inspirations to be discovered in the brain or other aspects of the various systems, even like the immune system, the way it interplays."}, {"time": 2660, "text": "I recently started to understand that the, like the immune system has something to do with the way the brain operates."}, {"time": 2666, "text": "Like there's multiple things going on in there, which all of which are not modeled in artificial neural networks."}, {"time": 2672, "text": "And maybe if you throw a little bit of that biological spice in there, you'll come up with something, something cool."}, {"time": 2679, "text": "I'm not sure if you're familiar with the Drake equation that estimate, I just did a video on it yesterday because I wanted to give my own estimate of it."}, {"time": 2689, "text": "It's an equation that combines a bunch of factors to estimate how many alien civilizations are in the galaxy."}, {"time": 2696, "text": "I've heard about it, yes."}, {"time": 2698, "text": "So one of the interesting parameters, you know, it's like how many stars are born every year, how many planets are on average per star for this, how many habitable planets are there."}, {"time": 2714, "text": "And then the one that starts being really interesting is the probability that life emerges on a habitable planet."}, {"time": 2724, "text": "So like, I don't know if you think about, you certainly think a lot about evolution, but do you think about the thing which evolution doesn't describe, which is like the beginning of evolution, the origin of life."}, {"time": 2736, "text": "I think I put the probability of life developing in a habitable planet at 1%."}, {"time": 2741, "text": "This is very scientifically rigorous."}, {"time": 2744, "text": "Okay, well, first at a high level for the Drake equation, what would you put that percent at on earth?"}, {"time": 2751, "text": "And in general, do you have something, do you have thoughts about how life might've started, you know, like the proteins being the first kind of, one of the early jumping points?"}, {"time": 2762, "text": "Yeah, so I think back in 2018, there was a very exciting paper published in Nature where they found one of the simplest amino acids, glycine, in a comet dust."}, {"time": 2783, "text": "So this is, and I apologize if I don't pronounce, it's a Russian named comet, it's I think Chugryumov Gerasimenko."}, {"time": 2794, "text": "This is the comet where, and there was this mission to get close to this comet and get the stardust from its tail."}, {"time": 2808, "text": "And when scientists analyzed it, they actually found traces of, you know, of glycine, which, you know, makes up, you know, it's one of the basic, one of the 20 basic amino acids that makes up proteins, right?"}, {"time": 2826, "text": "So that was kind of very exciting, right?"}, {"time": 2830, "text": "But, you know, the question is very interesting, right?"}, {"time": 2834, "text": "So what, you know, if there is some alien life, is it gonna be made of proteins, right?"}, {"time": 2842, "text": "Or maybe RNAs, right?"}, {"time": 2844, "text": "So we see that, you know, the RNA viruses are certainly, you know, very well established sort of, you know, group of molecular machines, right?"}, {"time": 2857, "text": "So, yeah, it's a very interesting question."}, {"time": 2862, "text": "What probability would you put?"}, {"time": 2863, "text": "Like, how hard is this job?"}, {"time": 2865, "text": "Like, how unlikely just on Earth do you think this whole thing is that we got going?"}, {"time": 2871, "text": "Like, are we really lucky or is it inevitable?"}, {"time": 2874, "text": "Like, what's your sense when you sit back and think about life on Earth?"}, {"time": 2878, "text": "Is it higher or lower than 1%?"}, {"time": 2880, "text": "Well, because 1% is pretty low, but it still is like, damn, that's a pretty good chance."}, {"time": 2885, "text": "Yes, it's a pretty good chance."}, {"time": 2886, "text": "I mean, I would, personally, but again, you know, I'm, you know, probably not the best person to do such estimations, but I would, you know, intuitively, I would probably put it lower."}, {"time": 2903, "text": "But still, I mean, you know, given."}, {"time": 2904, "text": "So we're really lucky here on Earth."}, {"time": 2908, "text": "Or the conditions are really good."}, {"time": 2910, "text": "It's, you know, I think that there was, everything was right in a way, right?"}, {"time": 2915, "text": "So we still, it's not, the conditions were not like ideal if you try to look at, you know, what was, you know, several billions years ago when the life emerged."}, {"time": 2928, "text": "So there is something called the Rare Earth Hypothesis that, you know, in counter to the Drake Equation says that the, you know, the conditions of Earth, if you actually were to describe Earth, it's quite a special place."}, {"time": 2945, "text": "So special it might be unique in our galaxy and potentially, you know, close to unique in the entire universe."}, {"time": 2952, "text": "Like it's very difficult to reconstruct those same conditions."}, {"time": 2956, "text": "And what the Rare Earth Hypothesis argues is all those different conditions are essential for life."}, {"time": 2963, "text": "And so that's sort of the counter, you know, like all the things we, you know, thinking that Earth is pretty average."}, {"time": 2971, "text": "I mean, I can't really, I'm trying to remember to go through all of them, but just the fact that it is shielded from a lot of asteroids, the, obviously the distance to the sun, but also the fact that it's like a perfect balance between the amount of water and land and all those kinds of things."}, {"time": 2993, "text": "I don't know, there's a bunch of different factors that I don't remember, there's a long list."}, {"time": 2997, "text": "But it's fascinating to think about if in order for something like proteins and then DNA and RNA to emerge, you need, and basic living organisms, you need to be very close to an Earth like planet, which will be sad or exciting, I don't know which."}, {"time": 3019, "text": "If you ask me, I, you know, in a way I put a parallel between, you know, between our own research."}, {"time": 3028, "text": "And I mean, from the intuitive perspective, you know, you have those two extremes and the reality is never very rarely falls into the extremes."}, {"time": 3041, "text": "It's always the optimus always reached somewhere in between."}, {"time": 3046, "text": "So, and that's what I tend to think."}, {"time": 3050, "text": "I think that, you know, we're probably somewhere in between."}, {"time": 3054, "text": "So they were not unique, unique, but again, the chances are, you know, reasonably small."}, {"time": 3061, "text": "The problem is we don't know the other extreme is like, I tend to think that we don't actually understand the basic mechanisms of like what this is all originated from, like, it seems like we think of life as this distinct thing, maybe intelligence is a distinct thing, maybe the physics that, from which planets and suns are born is a distinct thing."}, {"time": 3084, "text": "But that could be a very, it's like the Stephen Wolfram thing, it's like the, from simple rules emerges greater and greater complexity."}, {"time": 3091, "text": "So, you know, I tend to believe that just life finds a way."}, {"time": 3096, "text": "Like, we don't know the extreme of how common life is because it could be life is like everywhere."}, {"time": 3104, "text": "Like, so everywhere that it's almost like laughable, like that we're such idiots to think who are you?"}, {"time": 3112, "text": "Like, it's like ridiculous to even like think, it's like ants thinking that their little colony is the unique thing and everything else doesn't exist."}, {"time": 3123, "text": "I mean, it's also very possible that that's the extreme and we're just not able to maybe comprehend the nature of that life."}, {"time": 3132, "text": "Just to stick on alien life for just a brief moment more, there is some signs of life on Venus in gaseous form."}, {"time": 3142, "text": "There's hope for life on Mars, probably extinct."}, {"time": 3147, "text": "We're not talking about intelligent life."}, {"time": 3149, "text": "Although that has been in the news recently."}, {"time": 3152, "text": "We're talking about basic like, you know, bacteria."}, {"time": 3156, "text": "Yeah, and then also, I guess, there's a couple moons."}, {"time": 3160, "text": "Europe."}, {"time": 3161, "text": "Yeah, Europa, which is Jupiter's moon."}, {"time": 3165, "text": "I think there's another one."}, {"time": 3166, "text": "Are you, is that exciting or is it terrifying to you that we might find life?"}, {"time": 3172, "text": "Do you hope we find life?"}, {"time": 3173, "text": "I certainly do hope that we find life."}, {"time": 3176, "text": "I mean, it was very exciting to hear about this news about the possible life on Venus."}, {"time": 3189, "text": "It'd be nice to have hard evidence of something with, which is what the hope is for Mars and Europa."}, {"time": 3197, "text": "But do you think those organisms will be similar biologically or would they even be sort of carbon based if we do find them?"}, {"time": 3205, "text": "I would say they would be carbon based."}, {"time": 3208, "text": "How similar, it's a big question, right?"}, {"time": 3211, "text": "So it's the moment we discover things outside Earth, right?"}, {"time": 3219, "text": "Even if it's a tiny little single cell."}, {"time": 3223, "text": "I mean, there is so much."}, {"time": 3225, "text": "Just imagine that, that would be so."}, {"time": 3227, "text": "I think that that would be another turning point for the science, you know?"}, {"time": 3232, "text": "Especially if it's different in some very new way."}, {"time": 3237, "text": "Because that says, that's a definitive statement, not a definitive, but a pretty strong statement that life is everywhere in the universe."}, {"time": 3245, "text": "To me at least, that's really exciting."}, {"time": 3248, "text": "You brought up Joshua Lederberg in an offline conversation."}, {"time": 3253, "text": "I think I'd love to talk to you about Alpha Fold and this might be an interesting way to enter that conversation because, so he won the 1958 Nobel Prize in Physiology and Medicine for discovering that bacteria can mate and exchange genes."}, {"time": 3269, "text": "But he also did a ton of other stuff, like we mentioned, helping NASA find life on Mars and the... Dendro."}, {"time": 3280, "text": "Dendro."}, {"time": 3282, "text": "The chemical expert system."}, {"time": 3285, "text": "Expert systems, remember those?"}, {"time": 3286, "text": "What do you find interesting about this guy and his ideas about artificial intelligence in general?"}, {"time": 3294, "text": "So I have a kind of personal story to share."}, {"time": 3300, "text": "So I started my PhD in Canada back in 2000."}, {"time": 3305, "text": "And so essentially my PhD was, so we were developing sort of a new language for symbolic machine learning."}, {"time": 3312, "text": "So it's different from the feature based machine learning."}, {"time": 3315, "text": "And one of the sort of cleanest applications of this approach, of this formalism was to cheminformatics and computer aided drug design."}, {"time": 3328, "text": "So essentially we were, as a part of my research, I developed a system that essentially looked at chemical compounds of say the same therapeutic category, you know, male hormones, right?"}, {"time": 3345, "text": "And try to figure out the structural fragments that are the structural building blocks that are important that define this class versus structural building blocks that are there just because, you know, to complete the structure."}, {"time": 3364, "text": "But they are not essentially the ones that make up the chemical, the key chemical properties of this therapeutic category."}, {"time": 3372, "text": "And, you know, for me, it was something new."}, {"time": 3376, "text": "I was trained as an applied mathematicians, you know, as with some machine learning background, but, you know, computer aided drug design was a completely new territory."}, {"time": 3387, "text": "So because of that, I often find myself asking lots of questions on one of these sort of central forums."}, {"time": 3396, "text": "Back then, there were no Facebooks or stuff like that."}, {"time": 3400, "text": "There was a forum, you know, it's a forum."}, {"time": 3403, "text": "It's essentially, it's like a bulletin board."}, {"time": 3406, "text": "On the internet."}, {"time": 3407, "text": "Yeah, so you essentially, you have a bunch of people and you post a question and you get, you know, an answer from, you know, different people."}, {"time": 3415, "text": "And back then, just like one of the most popular forums was CCL, I think Computational Chemistry Library, not library, but something like that, but CCL, that was the forum."}, {"time": 3429, "text": "And there, I, you know, I..."}, {"time": 3432, "text": "Asked a lot of dumb questions."}, {"time": 3434, "text": "Yes, I asked questions."}, {"time": 3435, "text": "Also shared some, you know, some information about how formal it is and how we do and whether whatever we do makes sense."}, {"time": 3445, "text": "And so, you know, and I remember that one of these posts, I mean, I still remember, you know, I would call it desperately looking for a chemist advice, something like that, right?"}, {"time": 3460, "text": "And so I post my question, I explained, you know, how formalism is, what it does and what kind of applications I'm planning to do."}, {"time": 3473, "text": "And, you know, and it was, you know, in the middle of the night and I went back to bed."}, {"time": 3479, "text": "And next morning, have a phone call from my advisor who also looked at this forum."}, {"time": 3486, "text": "It's like, you won't believe who replied to you."}, {"time": 3491, "text": "And it's like, who?"}, {"time": 3493, "text": "And he said, well, you know, there is a message to you from Joshua Lederberg."}, {"time": 3499, "text": "And my reaction was like, who is Joshua Lederberg?"}, {"time": 3502, "text": "Your advisor hung up."}, {"time": 3502, "text": "So, and essentially, you know, Joshua wrote me that we had conceptually similar ideas in the dendrial project."}, {"time": 3516, "text": "You may wanna look it up."}, {"time": 3519, "text": "And we should also, sorry, and it's a side comment, say that even though he won the Nobel Prize at a really young age, in 58, but so he was, I think he was what, 33."}, {"time": 3532, "text": "It's just crazy."}, {"time": 3533, "text": "So anyway, so that's, so hence in the 90s, responding to young whippersnappers on the CCL forum."}, {"time": 3542, "text": "And so back then he was already very senior."}, {"time": 3545, "text": "I mean, he unfortunately passed away back in 2008, but, you know, back in 2001, he was, I mean, he was a professor emeritus at Rockefeller University."}, {"time": 3555, "text": "And, you know, that was actually, believe it or not, one of the reasons I decided to join, you know, as a postdoc, the group of Andre Salle, who was at Rockefeller University, with the hope that, you know, that I could actually, you know, have a chance to meet Joshua in person."}, {"time": 3578, "text": "And I met him very briefly, right?"}, {"time": 3582, "text": "Just because he was walking, you know, there's a little bridge that connects the, sort of the research campus with the, with the sort of skyscraper that Rockefeller owns, the where, you know, postdocs and faculty and graduate students live."}, {"time": 3600, "text": "And so I met him, you know, and had a very short conversation, you know."}, {"time": 3606, "text": "But so I started, you know, reading about Dendral and I was amazed, you know, it's, we're talking about 1960, right?"}, {"time": 3616, "text": "The ideas were so profound."}, {"time": 3619, "text": "Well, what's the fun about the ideas of it?"}, {"time": 3621, "text": "The reason to make this is even crazier."}, {"time": 3625, "text": "So, Lederberg wanted to make a system that would help him study the extraterrestrial molecules, right?"}, {"time": 3639, "text": "So, the idea was that, you know, the way you study the extraterrestrial molecules is you do the mass spec analysis, right?"}, {"time": 3646, "text": "And so the mass spec gives you sort of bits, numbers about essentially gives you the ideas about the possible fragments or, you know, atoms, you know, and maybe a little fragments, pieces of this molecule that make up the molecule, right?"}, {"time": 3663, "text": "So now you need to sort of, to decompose this information and to figure out what was the hole before it became fragments, bits and pieces, right?"}, {"time": 3732, "text": "But the original idea, I suppose, is to solve the entirety of this problem automatically."}, {"time": 3737, "text": "So he, you know, so he, back then he approached."}, {"time": 3741, "text": "60s."}, {"time": 3745, "text": "Yes, believe that, it's amazing."}, {"time": 3748, "text": "I mean, it still blows my mind, you know, that it's, that's, and this was essentially the origin of the modern bioinformatics, cheminformatics, you know, back in 60s."}, {"time": 3762, "text": "So that's, you know, every time you deal with projects like this, with the, you know, research like this, you just, you know, so the power of the, you know, intelligence of this people is just, you know, overwhelming."}, {"time": 3781, "text": "Do you think about expert systems, is there, and why they kind of didn't become successful, especially in the space of bioinformatics, where it does seem like there is a lot of expertise in humans, and, you know, it's possible to see that a system like this could be made very useful."}, {"time": 3804, "text": "And be built up."}, {"time": 3805, "text": "So it's actually, it's a great question, and this is something, so, you know, so, you know, at my university, I teach artificial intelligence, and, you know, we start, my first two lectures are on the history of AI."}, {"time": 3820, "text": "And there we, you know, we try to, you know, go through the main stages of AI."}, {"time": 3828, "text": "And so, you know, the question of why expert systems failed or became obsolete, it's actually a very interesting one."}, {"time": 3838, "text": "And there are, you know, if you try to read the, you know, the historical perspectives, there are actually two lines of thoughts."}, {"time": 3845, "text": "One is that they were essentially not up to the expectations."}, {"time": 3854, "text": "And so therefore they were replaced, you know, by other things, right?"}, {"time": 3861, "text": "The other one was that completely opposite one, that they were too good."}, {"time": 3868, "text": "And as a result, they essentially became sort of a household name, and then essentially they got transformed."}, {"time": 3877, "text": "I mean, in both cases, sort of the outcome was the same."}, {"time": 3880, "text": "They evolved into something, right?"}, {"time": 3883, "text": "And that's what I, you know, if I look at this, right?"}, {"time": 3887, "text": "So the modern machine learning, right?"}, {"time": 3891, "text": "So there's echoes in the modern machine learning."}, {"time": 3893, "text": "I think so, I think so, because, you know, if you think about this, you know, and how we design, you know, the most successful algorithms, including AlphaFold, right?"}, {"time": 3904, "text": "You built in the knowledge about the domain that you study, right?"}, {"time": 3909, "text": "So you built in your expertise."}, {"time": 3912, "text": "So speaking of AlphaFold, so DeepMind's AlphaFold 2 recently was announced to have, quote unquote, solved protein folding."}, {"time": 3921, "text": "But how exciting is this to you?"}, {"time": 3924, "text": "It seems to be one of the, one of the exciting things that have happened in 2020."}, {"time": 3929, "text": "It's an incredible accomplishment from the looks of it."}, {"time": 3932, "text": "What part of it is amazing to you?"}, {"time": 3933, "text": "What part would you say is over hype or maybe misunderstood?"}, {"time": 3939, "text": "It's definitely a very exciting achievement."}, {"time": 3941, "text": "To give you a little bit of perspective, right?"}, {"time": 3943, "text": "So in bioinformatics, we have several competitions."}, {"time": 3950, "text": "And so the way, you know, you often hear how those competitions have been explained to sort of to non bioinformaticians is that, you know, they call it bioinformatics Olympic games."}, {"time": 3961, "text": "And there are several disciplines, right?"}, {"time": 3963, "text": "So the historically one of the first one was the discipline in predicting the protein structure, predicting the 3D coordinates of the protein."}, {"time": 3972, "text": "But there are some others."}, {"time": 3973, "text": "So the predicting protein functions, predicting effects of mutations on protein functions, then predicting protein, protein interactions."}, {"time": 3984, "text": "So the original one was CASP or a critical assessment of a protein structure."}, {"time": 3992, "text": "And the, you know, typically what happens during this competitions is, you know, scientists, experimental scientists solve the structures, but don't put them into the protein data bank, which is the centralized database that contains all the 3D coordinates."}, {"time": 4017, "text": "Instead, they hold it and release protein sequences."}, {"time": 4022, "text": "And now the challenge of the community is to predict the 3D structures of this proteins and then use the experimental results structures to assess which one is the closest one, right?"}, {"time": 4036, "text": "And this competition, by the way, just a bunch of different tangents."}, {"time": 4039, "text": "And maybe you can also say, what is protein folding?"}, {"time": 4042, "text": "Then this competition, CASP competition has become the gold standard."}, {"time": 4047, "text": "And that's what was used to say that protein folding was solved."}, {"time": 4052, "text": "So just to add a little, just a bunch."}, {"time": 4055, "text": "So if you could, whenever you say stuff, maybe throw in some of the basics for the folks that might be outside of the field."}, {"time": 4062, "text": "So, yeah, so, you know, so the reason it's, you know, it's relevant to our understanding of protein folding is because, you know, we've yet to learn how the folding mechanistically works, right?"}, {"time": 4078, "text": "So there are different hypothesis, what happens to this fold?"}, {"time": 4082, "text": "For example, there is a hypothesis that the folding happens by, you know, also in the modular fashion, right?"}, {"time": 4092, "text": "So that, you know, we have protein domains that get folded independently because their structure is stable."}, {"time": 4099, "text": "And then the whole protein structure gets formed."}, {"time": 4103, "text": "But, you know, within those domains, we also have a so called secondary structure, the small alpha helices, beta schists."}, {"time": 4109, "text": "So these are, you know, elements that are structurally stable."}, {"time": 4114, "text": "And so, and the question is, you know, when do they get formed?"}, {"time": 4120, "text": "Because some of the secondary structure elements, you have to have, you know, a fragment in the beginning and say the fragment in the middle, right?"}, {"time": 4129, "text": "So you cannot potentially start having the full fold from the get go, right?"}, {"time": 4137, "text": "So it's still, you know, it's still a big enigma, what happens."}, {"time": 4141, "text": "We know that it's an extremely efficient and stable process, right?"}, {"time": 4145, "text": "So there's this long sequence and the fold happens really quickly."}, {"time": 4150, "text": "So that's really weird, right?"}, {"time": 4151, "text": "And it happens like the same way almost every time."}, {"time": 4156, "text": "That's really weird."}, {"time": 4157, "text": "That's freaking weird."}, {"time": 4159, "text": "It's, yeah, that's why it's such an amazing thing."}, {"time": 4162, "text": "But most importantly, right?"}, {"time": 4164, "text": "So it's, you know, so when you see the, you know, the translation process, right?"}, {"time": 4169, "text": "So when you don't have the whole protein translated, right, it's still being translated, you know, getting out from the ribosome, you already see some structural, you know, fragmentation."}, {"time": 4185, "text": "So folding starts happening before the whole protein gets produced, right?"}, {"time": 4192, "text": "And so this is obviously, you know, one of the biggest questions in, you know, in modern molecular biologists."}, {"time": 4200, "text": "Not like maybe what happens, like that's not as bigger than the question of folding."}, {"time": 4207, "text": "That's the question of like, something like deeper fundamental idea of folding."}, {"time": 4212, "text": "Behind folding."}, {"time": 4214, "text": "So, you know, so obviously if we are able to predict the end product of protein folding, we are one step closer to understanding sort of the mechanisms of the protein folding."}, {"time": 4230, "text": "Because we can then potentially look and start probing what are the critical parts of this process and what are not so critical parts of this process."}, {"time": 4241, "text": "So we can start decomposing this, you know, so in a way this protein structure prediction algorithm can be used as a tool, right?"}, {"time": 4253, "text": "So you change the, you know, you modify the protein, you get back to this tool, it predicts, okay, it's completely unstable."}, {"time": 4264, "text": "Yeah, which aspects of the input will have a big impact on the output?"}, {"time": 4271, "text": "So what happens is, you know, we typically have some sort of incremental advancement, you know, each stage of this CASP competition, you have groups with incremental advancement and, you know, historically the top performing groups were, you know, they were not using machine learning."}, {"time": 4345, "text": "But what happens when we don't have these relatives?"}, {"time": 4347, "text": "This is when it becomes really, really hard, right?"}, {"time": 4351, "text": "So that's so called de novo, you know, de novo protein structure prediction."}, {"time": 4357, "text": "And in this case, those methods were traditionally very good."}, {"time": 4363, "text": "But what happened in the last year, the original alpha fold came into and all of a sudden it's much better than everyone else."}, {"time": 4376, "text": "This is 2018."}, {"time": 4378, "text": "Oh, and the competition is only every two years, I think."}, {"time": 4382, "text": "And then, so, you know, it was sort of kind of over shockwave to the bioinformatics community that, you know, we have like a state of the art machine learning system that does, you know, structure prediction."}, {"time": 4398, "text": "And essentially what it does, you know, so if you look at this, it actually predicts the context."}, {"time": 4406, "text": "So, you know, so the process of reconstructing the 3D structure starts by predicting the context between the different parts of the protein."}, {"time": 4418, "text": "And the context essentially is the parts of the proteins that are in a close proximity to each other."}, {"time": 4423, "text": "Right, so actually the machine learning part seems to be estimating, you can correct me if I'm wrong here, but it seems to be estimating the distance matrix, which is like the distance between the different parts."}, {"time": 4435, "text": "Yeah, so we call the contact map."}, {"time": 4438, "text": "Contact map."}, {"time": 4438, "text": "So once you have the contact map, the reconstruction is becoming more straightforward, right?"}, {"time": 4444, "text": "But so the contact map is the key."}, {"time": 4446, "text": "And so, you know, so that what happened."}, {"time": 4451, "text": "And now we started seeing in this current stage, right?"}, {"time": 4455, "text": "Well, in the most recent one, we started seeing the emergence of these ideas in other people works, right?"}, {"time": 4465, "text": "But yet here's, you know, AlphaFold2 that again outperforms everyone else."}, {"time": 4473, "text": "And also by introducing yet another wave of the machine learning ideas."}, {"time": 4478, "text": "Yeah, there don't seem to be also an incorporation."}, {"time": 4481, "text": "First of all, the paper is not out yet, but there's a bunch of ideas already out."}, {"time": 4484, "text": "There does seem to be an incorporation of this other thing."}, {"time": 4488, "text": "I don't know if it's something that you could speak to, which is like the incorporation of like other structures, like evolutionary similar structures that are used to kind of give you hints."}, {"time": 4503, "text": "Yes, so evolutionary similarity is something that we can detect at different levels, right?"}, {"time": 4510, "text": "So we know, for example, that the structure of proteins is more conserved than the sequence."}, {"time": 4520, "text": "The sequence could be very different, but the structural shape is actually still very conserved."}, {"time": 4526, "text": "So that's sort of the intrinsic property that, you know, in a way related to protein folds, you know, to the evolution of the, you know, of the proteins and protein domains, et cetera."}, {"time": 4537, "text": "But we know that, I mean, there've been multiple studies."}, {"time": 4541, "text": "And, you know, ideally, if you have structures, you know, you should use that information."}, {"time": 4548, "text": "However, sometimes we don't have this information."}, {"time": 4551, "text": "Instead, we have a bunch of sequences."}, {"time": 4553, "text": "Sequences, we have a lot, right?"}, {"time": 4554, "text": "So we have, you know, hundreds, thousands of, you know, different organisms sequenced, right?"}, {"time": 4564, "text": "And by taking the same protein, but in different organisms and aligning it, so making it, you know, making the corresponding positions aligned, we can actually say a lot about sort of what is conserved in this protein and therefore, you know, structurally more stable, what is diverse in this protein."}, {"time": 4588, "text": "So on top of that, we could provide sort of the information about the sort of the secondary structure of this protein, et cetera, et cetera."}, {"time": 4596, "text": "So this information is extremely useful and it's already there."}, {"time": 4601, "text": "So while it's tempting to, you know, to do a complete ab initio, so you just have a protein sequence and nothing else, the reality is such that we are overwhelmed with this data."}, {"time": 4614, "text": "So why not use it?"}, {"time": 4616, "text": "And so, yeah, so I'm looking forward to reading this paper."}, {"time": 4621, "text": "It does seem to, like they've, in the previous version of Alpha Fold, they didn't, for this evolutionary similarity thing, they didn't use machine learning for that."}, {"time": 4632, "text": "Or rather, they used it as like the input to the entirety of the neural net, like the features derived from the similarity."}, {"time": 4642, "text": "It seems like there's some kind of quote, unquote, iterative thing where it seems to be part of the learning process is the incorporation of this evolutionary similarity."}, {"time": 4654, "text": "Yeah, I don't think there is a bioarchive paper, right?"}, {"time": 4657, "text": "No, there's nothing."}, {"time": 4658, "text": "There's a blog post that's written by a marketing team, essentially, which, you know, it has some scientific similarity, probably, to the actual methodology used, but it could be, it's like interpreting scripture."}, {"time": 4675, "text": "It could be just poetic interpretations of the actual work as opposed to direct connection to the work."}, {"time": 4681, "text": "So now, speaking about protein folding, right?"}, {"time": 4684, "text": "So, you know, in order to answer the question whether or not we have solved this, right?"}, {"time": 4689, "text": "So we need to go back to the beginning of our conversation with the realization that an average protein is that typically what the CASP has been focusing on is this competition has been focusing on the single, maybe two domain proteins that are still very compact."}, {"time": 4711, "text": "And even those ones are extremely challenging to solve."}, {"time": 4715, "text": "But now we talk about, you know, an average protein that has two, three protein domains."}, {"time": 4722, "text": "If you look at the proteins that are in charge of the, you know, of the process with the neural system, right, perhaps one of the most recently evolved sort of systems in an organism, right?"}, {"time": 4743, "text": "All of them, well, the majority of them are highly multi domain proteins."}, {"time": 4749, "text": "So they are, you know, some of them have five, six, seven, you know, and more domains, right?"}, {"time": 4756, "text": "And, you know, we are very far away from understanding how these proteins are folded."}, {"time": 4762, "text": "So the complexity of the protein matters here."}, {"time": 4764, "text": "The complexity of the protein modules or the protein domains."}, {"time": 4770, "text": "So you're saying solved, so the definition of solved here is particularly the CASP competition achieving human level, not human level, achieving experimental level performance on these particular sets of proteins that have been used in these competitions."}, {"time": 4790, "text": "Well, I mean, you know, I do think that, you know, especially with regards to the alpha fold, you know, it is able to, you know, to solve, you know, at the near experimental level, pre big majority of the more compact proteins like, or protein domains."}, {"time": 4816, "text": "Because again, in order to understand how the overall protein, you know, multi domain protein fold, we do need to understand the structure of its individual domains."}, {"time": 4828, "text": "I mean, unlike if you look at alpha zero or like even mu zero, if you look at that work, you know, it's nice reinforcement learning self playing mechanisms are nice cause it's all in simulation."}, {"time": 4842, "text": "So you can learn from just huge amounts."}, {"time": 4845, "text": "Like you don't need data."}, {"time": 4847, "text": "It was like the problem with proteins, like the size, I forget how many 3D structures have been mapped, but the training data is very small."}, {"time": 4856, "text": "No matter what, it's like millions, maybe a one or two million or something like that, but it's some very small number, but like, it doesn't seem like that's scalable."}, {"time": 4866, "text": "There has to be, I don't know, it feels like you want to somehow 10 X the data or a hundred X the data somehow."}, {"time": 4875, "text": "Yes, but we also can take advantage of homology models, right, so the models that are of very good quality because they are essentially obtained based on the evolutionary information, right?"}, {"time": 4893, "text": "So you can, there is a potential to enhance this information and, you know, use it again to empower the training set."}, {"time": 4903, "text": "And it's, I think, I am actually very optimistic."}, {"time": 4909, "text": "I think it's been one of this sort of, you know, churning events where you have a system that is, you know, a machine learning system that is truly better than the machine learning system."}, {"time": 4932, "text": "Better than the sort of the more conventional biophysics based methods."}, {"time": 4937, "text": "That's a huge leap."}, {"time": 4939, "text": "This is one of those fun questions, but where would you put it in the ranking of the greatest breakthroughs in artificial intelligence history?"}, {"time": 4951, "text": "So like, okay, so let's see who's in the running."}, {"time": 4955, "text": "So you got like AlphaZero and AlphaGo beating the world champion at the game of Go."}, {"time": 4964, "text": "Thought to be impossible like 20 years ago."}, {"time": 4968, "text": "Or at least the AI community was highly skeptical."}, {"time": 4971, "text": "Then you got like also Deep Blue original Kasparov."}, {"time": 4975, "text": "You have deep learning itself, like the maybe, what would you say, the AlexNet, ImageNet moment."}, {"time": 4980, "text": "So the first neural network achieving human level performance."}, {"time": 4984, "text": "Super, that's not true."}, {"time": 4987, "text": "Achieving like a big leap in performance on the computer vision problem."}, {"time": 4994, "text": "There is OpenAI, the whole like GPT3, that whole space of transformers and language models just achieving this incredible performance of application of neural networks to language models."}, {"time": 5011, "text": "Boston Dynamics, pretty cool."}, {"time": 5013, "text": "Like robotics."}, {"time": 5015, "text": "People are like, there's no AI."}, {"time": 5018, "text": "No, no, there's no machine learning currently."}, {"time": 5021, "text": "But AI is much bigger than machine learning."}, {"time": 5024, "text": "So that just the engineering aspect, I would say it's one of the greatest accomplishments in engineering side."}, {"time": 5032, "text": "Engineering meaning like mechanical engineering of robotics ever."}, {"time": 5037, "text": "Then of course, autonomous vehicles."}, {"time": 5039, "text": "You can argue for Waymo, which is like the Google self driving car."}, {"time": 5043, "text": "Or you can argue for Tesla, which is like actually being used by hundreds of thousands of people on the road today, machine learning system."}, {"time": 5053, "text": "And I don't know if you can, what else is there?"}, {"time": 5057, "text": "But I think that's it."}, {"time": 5058, "text": "And then AlphaFold, many people are saying is up there, potentially number one."}, {"time": 5063, "text": "Would you put them at number one?"}, {"time": 5064, "text": "Well, in terms of the impact on the science and on the society beyond, it's definitely, to me would be one of the... Top three?"}, {"time": 5079, "text": "What you want?"}, {"time": 5079, "text": "Maybe, I mean, I'm probably not the best person to answer that."}, {"time": 5085, "text": "But I do have, I remember my, back in, I think 1997, when Deep Blue, that Kasparov, it was, I mean, it was a shock."}, {"time": 5101, "text": "I mean, it was, and I think for the, for the pre substantial part of the world, that especially people who have some experience with chess, and realizing how incredibly human this game, how much of a brain power you need to reach those levels of grandmasters, right, level."}, {"time": 5136, "text": "And it's probably one of the first time, and how good Kasparov was."}, {"time": 5139, "text": "And again, yeah, so Kasparov's arguably one of the best ever, right?"}, {"time": 5145, "text": "And you get a machine that beats him."}, {"time": 5147, "text": "All right, so it's... First time a machine probably beat a human at that scale of a thing, of anything."}, {"time": 5154, "text": "So that was, to me, that was like, you know, one of the groundbreaking events in the history of AI."}, {"time": 5160, "text": "Yeah, that's probably number one."}, {"time": 5162, "text": "Probably, like we don't, it's hard to remember."}, {"time": 5165, "text": "It's like Muhammad Ali versus, I don't know, any of the Mike Tyson, something like that."}, {"time": 5169, "text": "It's like, nah, you gotta put Muhammad Ali at number one."}, {"time": 5173, "text": "Same with Deep Blue, even though it's not machine learning based."}, {"time": 5179, "text": "Still, it uses advanced search, and search is the integral part of AI, right?"}, {"time": 5184, "text": "It's not, people don't think of it that way at this moment."}, {"time": 5187, "text": "In vogue currently, search is not seen as a fundamental aspect of intelligence, but it very well, I mean, it very likely is."}, {"time": 5197, "text": "In fact, I mean, that's what neural networks are, is they're just performing search on the space of parameters, and it's all search."}, {"time": 5205, "text": "All of intelligence is some form of search, and you just have to become cleverer and clever at that search problem."}, {"time": 5210, "text": "And I also have another one that you didn't mention that's one of my favorite ones is, so you've probably heard of this, it's, I think it's called Deep Rembrandt."}, {"time": 5223, "text": "It's the project where they trained, I think there was a collaboration between the sort of the experts in Rembrandt painting in Netherlands, and a group, an artificial intelligence group, where they train an algorithm to replicate the style of the Rembrandt, and they actually printed a portrait that never existed before in the style of Rembrandt."}, {"time": 5252, "text": "I think they printed it on a sort of, on the canvas that, you know, using pretty much same types of paints and stuff."}, {"time": 5262, "text": "To me, it was mind blowing."}, {"time": 5264, "text": "Yeah, and the space of art, that's interesting."}, {"time": 5266, "text": "There hasn't been, maybe that's it, but I think there hasn't been an image in that moment yet in the space of art."}, {"time": 5276, "text": "You haven't been able to achieve superhuman level performance in the space of art, even though there's this big famous thing where a piece of art was purchased, I guess for a lot of money."}, {"time": 5289, "text": "Yeah, but it's still, you know, people are like in the space of music at least, that's, you know, it's clear that human created pieces are much more popular."}, {"time": 5301, "text": "So there hasn't been a moment where it's like, oh, this is, we're now, I would say in the space of music, what makes a lot of money, we're talking about serious money, it's music and movies, or like shows and so on, and entertainment."}, {"time": 5316, "text": "There hasn't been a moment where AI created, AI was able to create a piece of music or a piece of cinema, like Netflix show, that is, you know, that's sufficiently popular to make a ton of money."}, {"time": 5336, "text": "And that moment would be very, very powerful, because that's like, that's an AI system being used to make a lot of money."}, {"time": 5343, "text": "And like direct, of course, AI tools, like even Premiere, audio editing, all the editing, everything I do, to edit this podcast, there's a lot of AI involved."}, {"time": 5351, "text": "Actually, this is a program, I wanna talk to those folks, just cause I wanna nerd out, it's called iZotope, I don't know if you're familiar with it."}, {"time": 5358, "text": "They have a bunch of tools of audio processing, and they have, I think they're Boston based, just, it's so exciting to me to use it, like on the audio here, cause it's all machine learning."}, {"time": 5370, "text": "It's not, cause most audio production stuff is like any kind of processing you do, it's very basic signal processing, and you're tuning knobs and so on."}, {"time": 5381, "text": "They have all of that, of course, but they also have all of this machine learning stuff, like where you actually give it training data, you select parts of the audio you train on, you train on it, and it figures stuff out."}, {"time": 5396, "text": "It's great, it's able to detect, like the ability of it to be able to separate voice and music, for example, or voice and anything, is incredible."}, {"time": 5407, "text": "Like it just, it's clearly exceptionally good at applying these different neural networks models to just separate the different kinds of signals from the audio."}, {"time": 5419, "text": "That, okay, so that's really exciting."}, {"time": 5422, "text": "Photoshop, Adobe people also use it, but to generate a piece of music that will sell millions, a piece of art, yeah."}, {"time": 5431, "text": "No, I agree, and you know, it's, that's, you know, as I mentioned, I offer my AI class, and you know, an integral part of this is the project, right?"}, {"time": 5444, "text": "So it's my favorite, ultimate favorite part, because it typically, we have these project presentations the last two weeks of the classes, right before, you know, the Christmas break, and it's sort of, it adds this cool excitement, and every time, I mean, I'm amazed, you know, with some projects that people, you know, come up with."}, {"time": 5467, "text": "And so, and quite a few of them are actually, you know, they have some link to arts."}, {"time": 5477, "text": "I mean, you know, I think last year we had a group who designed an AI producing hokus, Japanese poems."}, {"time": 5489, "text": "So, and some of them, so, you know, it got trained on the English based, haikus, haikus, right?"}, {"time": 5496, "text": "So, and some of them, you know, they get to present, like, the top selection."}, {"time": 5503, "text": "They were pretty good."}, {"time": 5504, "text": "I mean, you know, I mean, of course, I'm not a specialist, but you read them, and you see this is real."}, {"time": 5509, "text": "It seems profound."}, {"time": 5510, "text": "Yes, yeah, it seems real."}, {"time": 5515, "text": "We also had a couple of projects where people tried to teach AI how to play, like, rock music, classical music."}, {"time": 5522, "text": "I think, and popular music."}, {"time": 5527, "text": "Interestingly enough, you know, classical music was among the most difficult ones."}, {"time": 5535, "text": "And, you know, of course, if you, if, you know, you know, if you look at the, you know, the, like, grandmasters of music, like Bach, right?"}, {"time": 5548, "text": "So there is a lot of, there is a lot of, there is a lot of almost math."}, {"time": 5554, "text": "Yeah, well, he's very mathematical."}, {"time": 5557, "text": "So this is, I would imagine that at least some style of this music could be picked up, but then you have this completely different spectrum of classical composers."}, {"time": 5569, "text": "And so, you know, it's almost like, you know, you don't have to sort of look at the data."}, {"time": 5576, "text": "You just listen to it and say, nah, that's not it, not yet."}, {"time": 5581, "text": "That's not it, yeah."}, {"time": 5583, "text": "There's OpenAI has, I think, OpenMuse or something like that, the system."}, {"time": 5587, "text": "It's cool, but it's like, eh, it's not compelling for some reason."}, {"time": 5592, "text": "It could be a psychological reason too."}, {"time": 5594, "text": "Maybe we need to have a human being, a tortured soul behind the music."}, {"time": 5602, "text": "I completely agree."}, {"time": 5603, "text": "But yeah, whether or not we'll have, one day we'll have, you know, a song written by an AI engine to be like in top charts, musical charts, I wouldn't be surprised."}, {"time": 5620, "text": "I wouldn't be surprised."}, {"time": 5623, "text": "I wonder if we already have one and it just hasn't been announced."}, {"time": 5628, "text": "We wouldn't know."}, {"time": 5629, "text": "How hard is the multi protein folding problem?"}, {"time": 5633, "text": "Is that kind of something you've already mentioned which is baked into this idea of greater and greater complexity of proteins?"}, {"time": 5641, "text": "Like multi domain proteins, is that basically become multi protein complexes?"}, {"time": 5648, "text": "Yes, you got it right."}, {"time": 5650, "text": "So it's sort of, it has the components of both of protein folding and protein, protein interactions."}, {"time": 5661, "text": "Because in order for these domains, many of these proteins actually, they never form a stable structure."}, {"time": 5671, "text": "One of my favorite proteins, and pretty much everyone who works in the, I know, whom I know, who works with proteins, they always have their favorite proteins."}, {"time": 5684, "text": "Right, so one of my favorite proteins, probably my favorite protein, the one that I worked when I was a postdoc is so called post synaptic density 95, PSD 95 protein."}, {"time": 5696, "text": "So it's one of the key actors in the majority of neurological processes at the molecular level."}, {"time": 5704, "text": "So it's a, and essentially it's a key player in the post synaptic density."}, {"time": 5713, "text": "So this is the crucial part of this synapse where a lot of these chemical processes are happening."}, {"time": 5722, "text": "So it has five domains, right?"}, {"time": 5726, "text": "So five protein domains."}, {"time": 5727, "text": "So pretty large proteins, I think 600 something assets."}, {"time": 5735, "text": "But the way it's organized itself, it's flexible, right?"}, {"time": 5741, "text": "So it acts as a scaffold."}, {"time": 5743, "text": "So it is used to bring in other proteins."}, {"time": 5749, "text": "So they start acting in the orchestrated manner, right?"}, {"time": 5754, "text": "So, and the type of the shape of this protein, it's in a way, there are some stable parts of this protein, but there are some flexible."}, {"time": 5764, "text": "And this flexibility is built in into the protein in order to become sort of this multifunctional machine."}, {"time": 5773, "text": "So do you think that kind of thing is also learnable through the alpha fold two kind of approach?"}, {"time": 5779, "text": "I mean, the time will tell."}, {"time": 5782, "text": "Is it another level of complexity?"}, {"time": 5784, "text": "Is it like how big of a jump in complexity is that whole thing?"}, {"time": 5788, "text": "To me, it's yet another level of complexity because when we talk about protein, protein interactions, and there is actually a different challenge for this called Capri, and so this, that is focused specifically on macromolecular interactions, protein, protein, protein, DNA, et cetera."}, {"time": 5808, "text": "So, but it's, there are different mechanisms that govern molecular interactions and that need to be picked up, say by a machine learning algorithm."}, {"time": 5823, "text": "Interestingly enough, we actually, we participated for a few years in this competition."}, {"time": 5831, "text": "We typically don't participate in competitions, I don't know, don't have enough time, because it's very intensive, it's a very intensive process."}, {"time": 5843, "text": "But we participated back in about 10 years ago or so."}, {"time": 5850, "text": "And the way we entered this competition, so we design a scoring function, right?"}, {"time": 5855, "text": "So the function that evaluates whether or not your protein, protein interaction is supposed to look like experimentally solved, right?"}, {"time": 5863, "text": "So the scoring function is very critical part of the model prediction."}, {"time": 5869, "text": "So we designed it to be a machine learning one."}, {"time": 5872, "text": "And so it was one of the first machine learning based scoring function used in Capri."}, {"time": 5880, "text": "And we essentially learned what should contribute, what are the critical components contributing into the protein, protein interaction."}, {"time": 5890, "text": "So this could be converted into a learning problem and thereby it could be learned?"}, {"time": 5895, "text": "I believe so, yes."}, {"time": 5897, "text": "Do you think AlphaFold2 or something similar to it from DeepMind or somebody else will be, will result in a Nobel Prize or multiple Nobel Prizes?"}, {"time": 5908, "text": "So like, you know, obviously, maybe not so obviously, you can't give a Nobel Prize to a computer program."}, {"time": 5918, "text": "At least for now, give it to the designers of that program."}, {"time": 5922, "text": "But do you see one or multiple Nobel Prizes where AlphaFold2 is like a large percentage of what that prize is given for?"}, {"time": 5934, "text": "Would it lead to discoveries at the level of Nobel Prizes?"}, {"time": 5940, "text": "I mean, I think we are definitely destined to see the Nobel Prize becoming sort of, to be evolving with the evolution of science and the evolution of science as such that it now becomes like really multi facets, right?"}, {"time": 5957, "text": "So where you don't really have like a unique discipline, you have sort of the, a lot of cross disciplinary talks in order to achieve sort of, you know, really big advancements, you know."}, {"time": 5972, "text": "So I think, you know, the computational methods will be acknowledged in one way or another."}, {"time": 5982, "text": "And as a matter of fact, you know, they were first acknowledged back in 2013, right?"}, {"time": 5990, "text": "Where, you know, the first three people were, you know, awarded the Nobel Prize for study the protein folding, right, the principle."}, {"time": 6001, "text": "And, you know, I think all three of them are computational biophysicists, right?"}, {"time": 6006, "text": "So, you know, that I think is unavoidable."}, {"time": 6013, "text": "You know, it will come with the time."}, {"time": 6016, "text": "The fact that, you know, alpha fold and, you know, similar approaches, because again, it's a matter of time that people will embrace this, you know, principle and we'll see more and more such, you know, such tools coming into play."}, {"time": 6036, "text": "But, you know, these methods will be critical in a scientific discovery, no doubts about it."}, {"time": 6047, "text": "On the engineering side, maybe a dark question, but do you think it's possible to use these machine learning methods to start to engineer proteins?"}, {"time": 6059, "text": "And the next question is something quite a few biologists are against, some are for, for study purposes, is to engineer viruses."}, {"time": 6069, "text": "Do you think machine learning, like something like alpha fold could be used to engineer viruses?"}, {"time": 6074, "text": "So to answer the first question, you know, it has been, you know, a part of the research in the protein science, the protein design is, you know, is a very prominent areas of research."}, {"time": 6089, "text": "Of course, you know, one of the pioneers is David Baker and Rosetta algorithm that, you know, essentially was doing the de novo design and was used to design new proteins, you know."}, {"time": 6101, "text": "And design of proteins means design of function."}, {"time": 6104, "text": "So like when you design a protein, you can control, I mean, the whole point of a protein with the protein structure comes a function, like it's doing something."}, {"time": 6114, "text": "So you can design different things."}, {"time": 6116, "text": "So you can, yeah, so you can, well, you can look at the proteins from the functional perspective."}, {"time": 6120, "text": "You can also look at the proteins from the structural perspective, right?"}, {"time": 6124, "text": "So the structural building blocks."}, {"time": 6125, "text": "So if you want to have a building block of a certain shape, you can try to achieve it by, you know, introducing a new protein sequence and predicting, you know, how it will fold."}, {"time": 6137, "text": "So with that, I mean, it's a natural, one of the, you know, natural applications of these algorithms."}, {"time": 6148, "text": "Now, talking about engineering a virus."}, {"time": 6154, "text": "With machine learning."}, {"time": 6155, "text": "With machine learning, right?"}, {"time": 6156, "text": "So, well, you know, so luckily for us, I mean, we don't have that much data, right?"}, {"time": 6167, "text": "We actually, right now, one of the projects that we are carrying on in the lab is we're trying to develop a machine learning algorithm that determines the, whether or not the current strain is pathogenic."}, {"time": 6182, "text": "And the current strain of the coronavirus."}, {"time": 6184, "text": "Of the virus."}, {"time": 6186, "text": "I mean, so there are applications to coronaviruses because we have strains of SARS COVID 2, also SARS COVID, MERS that are pathogenic, but we also have strains of other coronaviruses that are, you know, not pathogenic."}, {"time": 6200, "text": "I mean, the common cold viruses and, you know, some other ones, right?"}, {"time": 6205, "text": "So, so pathogenic meaning spreading."}, {"time": 6208, "text": "Pathogenic means actually inflicting damage."}, {"time": 6215, "text": "There are also some, you know, seasonal versus pandemic strains of influenza, right?"}, {"time": 6221, "text": "And determining the, what are the molecular determinant, right?"}, {"time": 6226, "text": "So that are built in, into the protein sequence, into the gene sequence, right?"}, {"time": 6230, "text": "So, and whether or not the machine learning can determine those, those components, right?"}, {"time": 6239, "text": "So like using machine learning to do, that's really interesting to, to, to given, give the input is like what the entire, the protein sequence and then determine if this thing is going to be able to do damage to a biological system."}, {"time": 6255, "text": "So, so I mean, It's a good machine learning, you're saying we don't have enough data for that?"}, {"time": 6259, "text": "We, I mean, for, for this specific one, we do."}, {"time": 6262, "text": "We might actually, I have, you know, have to back up on this because we're still in the process."}, {"time": 6267, "text": "There was one work that appeared in bioarchive by Eugene Kunin, who is one of these, you know, pioneers in, in, in evolutionary genomics."}, {"time": 6279, "text": "And they tried to look at this, but, you know, the methods were sort of standard, you know, supervised learning methods."}, {"time": 6288, "text": "And now the question is, you know, can you advance it further by, by using, you know, not so standard methods, you know?"}, {"time": 6298, "text": "So there's obviously a lot of hope in, in transfer learning where you can actually try to transfer the information that the machine learning learns about the proper protein sequences, right?"}, {"time": 6311, "text": "And, you know, so, so there is some promise in going this direction, but if we have this, it would be extremely useful because then we could essentially forecast the potential mutations that would make the current strain more or less pathogenic."}, {"time": 6327, "text": "Anticipate, anticipate them from a vaccine development, for the treatment, antiviral drug development."}, {"time": 6334, "text": "That, that would be a very crucial task."}, {"time": 6336, "text": "But you could also use that system to then say, how would we potentially modify this virus to make it more pathogenic?"}, {"time": 6347, "text": "This, that's true."}, {"time": 6350, "text": "And then, you know, the, again, the hope is, well, several things, right?"}, {"time": 6359, "text": "So one is that, you know, it's, even if you design a, you know, a sequence, right?"}, {"time": 6366, "text": "So to carry out the actual experimental biology, to ensure that all the components working, you know, is a completely different matter."}, {"time": 6379, "text": "Difficult process."}, {"time": 6380, "text": "Then the, you know, we've seen in the past, there could be some regulation of the moment the scientific community recognizes that it's now becoming no longer a sort of a fun puzzle to, you know, for machine learning."}, {"time": 6396, "text": "Could be open."}, {"time": 6397, "text": "Yeah, so then there might be some regulation."}, {"time": 6400, "text": "So I think back in, what, 2015, there was, you know, there was an issue on regulating the research on influenza strains, right?"}, {"time": 6412, "text": "There were several groups, you know, used sort of the mutation analysis to determine whether or not this strain will jump from one species to another."}, {"time": 6423, "text": "And I think there was like a half a year moratorium on the research on the paper published until, you know, scientists, you know, analyzed it and decided that it's actually safe."}, {"time": 6436, "text": "I forgot what that's called."}, {"time": 6437, "text": "Something of function, test of function."}, {"time": 6440, "text": "Gain of function."}, {"time": 6440, "text": "Gain of function, yeah."}, {"time": 6442, "text": "Gain of function, loss of function, that's right."}, {"time": 6446, "text": "It's like, let's watch this thing mutate for a while to see like, to see what kind of things we can observe."}, {"time": 6453, "text": "I guess I'm not so much worried about that kind of research if there's a lot of regulation and if it's done very well and with competence and seriously."}, {"time": 6462, "text": "I am more worried about kind of this, you know, the underlying aspect of this question is more like 50 years from now."}, {"time": 6472, "text": "Speaking to the Drake equation, one of the parameters in the Drake equation is how long civilizations last."}, {"time": 6479, "text": "And that seems to be the most important value actually for calculating if there's other alien intelligent civilizations out there."}, {"time": 6488, "text": "That's where there's most variability."}, {"time": 6490, "text": "Assuming like if life, if that percentage that life can emerge is like not zero, like if we're a super unique, then it's the how long we last is basically the most important thing."}, {"time": 6506, "text": "So from a selfish perspective, but also from a Drake equation perspective, I'm worried about our civilization lasting."}, {"time": 6515, "text": "And you kind of think about all the ways in which machine learning can be used to design greater weapons of destruction, right?"}, {"time": 6525, "text": "And I mean, one way to ask that if you look sort of 50 years from now, a hundred years from now, would you be more worried about natural pandemics or engineered pandemics?"}, {"time": 6539, "text": "Like who's the better designer of viruses, nature or humans if we look down the line?"}, {"time": 6545, "text": "I think in my view, I would still be worried about the natural pandemics simply because I mean, the capacity of the nature producing this."}, {"time": 6560, "text": "It does pretty good job, right?"}, {"time": 6563, "text": "And the motivation for using virus, engineering viruses as a weapon is a weird one because maybe you can correct me on this, but it seems very difficult to target a virus, right?"}, {"time": 6575, "text": "The whole point of a weapon, the way a rocket works, if a starting point, you have an end point and you're trying to hit a target, to hit a target with a virus is very difficult."}, {"time": 6584, "text": "It's basically just, right?"}, {"time": 6587, "text": "The target would be the human species."}, {"time": 6592, "text": "Yeah, I have a hope in us."}, {"time": 6594, "text": "I'm forever optimistic that we will not, there's insufficient evil in the world to lead to that kind of destruction."}, {"time": 6604, "text": "Well, I also hope that, I mean, that's what we see."}, {"time": 6607, "text": "I mean, with the way we are getting connected, the world is getting connected."}, {"time": 6614, "text": "I think it helps for the world to become more transparent."}, {"time": 6622, "text": "So the information spread is, I think it's one of the key things for the society to become more balanced one way or another."}, {"time": 6636, "text": "This is something that people disagree with me on, but I do think that the kind of secrecy that governments have."}, {"time": 6643, "text": "So you're kind of speaking more to the other aspects, like a research community being more open, companies are being more open."}, {"time": 6652, "text": "Government is still like, we're talking about like military secrets."}, {"time": 6657, "text": "I think military secrets of the kind that could destroy the world will become also a thing of the 20th century."}, {"time": 6667, "text": "It'll become more and more open."}, {"time": 6670, "text": "I think nations will lose power in the 21st century, like lose sufficient power towards secrecies."}, {"time": 6675, "text": "Transparency is more beneficial than secrecy, but of course it's not obvious."}, {"time": 6681, "text": "Let's hope so."}, {"time": 6682, "text": "Let's hope so that the governments will become more transparent."}, {"time": 6691, "text": "What, so we last talked, I think in March or April, what have you learned?"}, {"time": 6696, "text": "How has your philosophical, psychological, biological worldview changed since then?"}, {"time": 6703, "text": "Or you've been studying it nonstop from a computational biology perspective."}, {"time": 6708, "text": "How has your understanding and thoughts about this virus changed over those months from the beginning to today?"}, {"time": 6714, "text": "One thing that I was really amazed at how efficient the scientific community was."}, {"time": 6723, "text": "I mean, and even just judging on this very narrow domain of protein structure and understanding the structural characterization of this virus from the components point of view, whole virus point of view."}, {"time": 6741, "text": "If you look at SARS, something that happened less than 20, but close enough, 20 years ago, and you see what, when it happened, what was sort of the response by the scientific community, you see that the structure characterizations did a cure, but it took several years, right?"}, {"time": 6771, "text": "Now the things that took several years, it's a matter of months, right?"}, {"time": 6776, "text": "So we see that the research pop up."}, {"time": 6781, "text": "We are at the unprecedented level in terms of the sequencing, right?"}, {"time": 6835, "text": "It'd be cool if we also had a lot more data about, so that the spread of this virus, not maybe, well, it'd be nice if we had it for like contact tracing purposes for this virus, but it'd be also nice if we had it for the study for future viruses to be able to respond and so on, but it's already nice that we have geographical data and the basic data from individual humans, yeah."}, {"time": 6858, "text": "Exactly, no, I think contact tracing is obviously a key component in understanding the spread of this virus."}, {"time": 6869, "text": "There is also, there is a number of challenges, right?"}, {"time": 6871, "text": "So XPRIZE is one of them, we just recently took a part of this competition, it's the prediction of the number of infections in different regions."}, {"time": 6888, "text": "So, you know, obviously the AI is the main topic in those predictions."}, {"time": 6895, "text": "Yeah, but it's still, the data, I mean, that's a competition, but the data is weak on the training."}, {"time": 6903, "text": "Like, it's great, it's much more than probably before, but like, it'd be nice if it was like really rich."}, {"time": 6911, "text": "I talked to Michael Mina from Harvard, I mean, he dreams that the community comes together with like a weather map to where viruses, right, like really high resolution sensors on like how from person to person the viruses that travel, all the different kinds of viruses, right?"}, {"time": 6931, "text": "Because there's a ton of them, and then you'd be able to tell the story that you've spoken about of the evolution of these viruses, like day to day mutations that are occurring."}, {"time": 6943, "text": "I mean, that'd be fascinating just from a perspective of study and from the perspective of being able to respond to future pandemics."}, {"time": 6951, "text": "That's ultimately what I'm worried about."}, {"time": 6951, "text": "People love books."}, {"time": 6955, "text": "Is there some three or whatever number of books, technical, fiction, philosophical, that brought you joy in life, had an impact on your life, and maybe some that you would recommend others?"}, {"time": 6971, "text": "I'll give you three very different books, and I also have a special runner up."}, {"time": 6975, "text": "Honorable mention."}, {"time": 6979, "text": "I mean, it's an audiobook, and that's some specific reason behind it."}, {"time": 6983, "text": "So the first book is something that sort of impacted my earlier stage of life, and I'm probably not going to be very original here."}, {"time": 6995, "text": "It's Bulgakov's Master and Margarita."}, {"time": 6999, "text": "For a Russian, maybe it's not super original, but it's a really powerful book, even in English."}, {"time": 7007, "text": "It is incredibly powerful, and I mean, the way it ends."}, {"time": 7015, "text": "I still have goosebumps when I read the very last sort of, it's called prologue, where it's just so powerful."}, {"time": 7023, "text": "What impact did it have on you?"}, {"time": 7023, "text": "What ideas?"}, {"time": 7027, "text": "What insights did you get from it?"}, {"time": 7027, "text": "I was just taken by the fact that you have those parallel lives apart from many centuries, and somehow they got sort of intertwined into one story, and that to me was fascinating."}, {"time": 7051, "text": "And of course the romantic part of this book is like it's not just romance, it's like the romance empowered by sort of magic, right?"}, {"time": 7067, "text": "And maybe on top of that, you have some irony, which is unavoidable, right?"}, {"time": 7071, "text": "Because it was that Soviet time."}, {"time": 7075, "text": "But it's very deeply Russian, so that's the wit, the humor, the pain, the love, all of that is one of the books that kind of captures something about Russian culture that people outside of Russia should probably read."}, {"time": 7091, "text": "What's the second one?"}, {"time": 7091, "text": "So the second one is again another one that it happened I read it later in my life."}, {"time": 7099, "text": "I think I read it first time when I was a graduate student."}, {"time": 7107, "text": "And that's the Solzhenitsyn's Cancer Word."}, {"time": 7111, "text": "That is amazingly powerful book."}, {"time": 7115, "text": "What is it about?"}, {"time": 7115, "text": "It's about, I mean, essentially based on Solzhenitsyn was diagnosed with cancer when he was reasonably young, and he made a full recovery."}, {"time": 7127, "text": "So this is about a person who was sentenced for life in one of these camps."}, {"time": 7139, "text": "And he had some cancer, so he was transported back to one of these Soviet republics, I think it was South Asian republics."}, {"time": 7151, "text": "And the book is about his experience being a prisoner, being a patient in the cancer clinic, in the cancer ward, surrounded by people, many of which die."}, {"time": 7175, "text": "But in the way it reads, first of all, later on I read the accounts of the doctors who describe the experiences in the book by the patient as incredibly accurate."}, {"time": 7199, "text": "So I read that there was some doctor saying that every single doctor should read this book to understand what the patient feels."}, {"time": 7207, "text": "But again, as many of the Solzhenitsyn's books, it has multiple levels of complexity."}, {"time": 7219, "text": "And obviously if you look above the cancer and the patient, the tumor that was growing and then disappeared in his body with some consequences, this is allegorically the Soviet, and he actually when he was asked, he said that this is what made him think about this, how to combine these experiences."}, {"time": 7255, "text": "Him being a part of the Soviet regime, also being a part of the someone sent to Gulag camp, and also someone who experienced cancer in his life."}, {"time": 7271, "text": "The Gulag Archipelago and this book, these are the works that actually made him receive a Nobel Prize."}, {"time": 7279, "text": "But to me I've read other books by Solzhenitsyn."}, {"time": 7291, "text": "This one to me is the most powerful one."}, {"time": 7295, "text": "And by the way, both this one and the previous one you read in Russian?"}, {"time": 7299, "text": "So now there is the third book is an English book and it's completely different."}, {"time": 7303, "text": "So we're switching the gears completely."}, {"time": 7307, "text": "So this is the book which, it's not even a book, it's an essay by Jonathan Neumann called The Computer and the Brain."}, {"time": 7319, "text": "And that was the book he was writing knowing that he was dying of cancer."}, {"time": 7327, "text": "So the book was released back, it's a very thin book."}, {"time": 7331, "text": "But the power, the intellectual power in this book, in this essay is incredible."}, {"time": 7339, "text": "I mean you probably know that von Neumann is considered to be one of the biggest thinkers."}, {"time": 7347, "text": "So his intellectual power was incredible."}, {"time": 7351, "text": "And you can actually feel this power in this book where the person is writing knowing that he will be, he will die."}, {"time": 7359, "text": "The book actually got published only after his death back in 1958."}, {"time": 7363, "text": "He died in 1957."}, {"time": 7367, "text": "So he tried to put as many ideas that he still hadn't realized."}, {"time": 7379, "text": "So this book is very difficult to read because every single paragraph is just compact, is filled with these ideas."}, {"time": 7391, "text": "And the ideas are incredible."}, {"time": 7395, "text": "Even nowadays, so he tried to put the parallels between the brain computing power, the neural system, and the computers as they were understood."}, {"time": 7407, "text": "Do you remember what year he was working on this?"}, {"time": 7411, "text": "57."}, {"time": 7411, "text": "So that was right during his, when he was diagnosed with cancer and he was essentially... Yeah, he's one of those, there's a few folks people mention, I think Ed Witten is another that like everyone that meets them, they say he's just an intellectual powerhouse."}, {"time": 7431, "text": "Okay, so who's the honorable mention?"}, {"time": 7435, "text": "And this is, I mean, the reason I put it sort of in a separate section because this is a book that I recently listened to."}, {"time": 7443, "text": "So it's an audio book."}, {"time": 7447, "text": "And this is a book called Lab Girl by Hope Jarron."}, {"time": 7451, "text": "So Hope Jarron, she is a scientist, she's a geochemist that essentially studies the fossil plants."}, {"time": 7463, "text": "And so she uses this fossil plant, the chemical analysis to understand what was the climate back in a thousand years, hundreds of thousands of years ago."}, {"time": 7479, "text": "And so something that incredibly touched me by this book, it was narrated by the author."}, {"time": 7487, "text": "And it's an incredibly personal story, incredibly."}, {"time": 7491, "text": "So certain parts of the book, you could actually hear the author crying."}, {"time": 7499, "text": "And that to me, I mean, I never experienced anything like this, reading the book, but it was like the connection between you and the author."}, {"time": 7511, "text": "And I think this is really a must read, but even better, a must listen to audio book for anyone who wants to learn about sort of academia, science, research in general, because it's a very personal account about her becoming a scientist."}, {"time": 7535, "text": "So we're just before New Year's."}, {"time": 7543, "text": "We talked a lot about some difficult topics of viruses and so on."}, {"time": 7547, "text": "Do you have some exciting things you're looking forward to in 2021?"}, {"time": 7551, "text": "Some New Year's resolutions, maybe silly or fun, or something very important and fundamental to the world of science or something completely unimportant?"}, {"time": 7567, "text": "Well, I'm definitely looking forward to towards things becoming normal."}, {"time": 7575, "text": "So yes, I really miss traveling."}, {"time": 7579, "text": "Every summer I go to an international summer school."}, {"time": 7583, "text": "It's called the School for Molecular and Theoretical Biology."}, {"time": 7587, "text": "It's held in Europe."}, {"time": 7591, "text": "It's organized by very good friends of mine."}]}, {"title": "Cal Newport: Deep Work, Focus, Productivity, Email, and Social Media | Lex Fridman Podcast #166", "id": "y3Umo_jd5AA", "quotes": [{"time": 256, "text": "Like I often feel for many reasons, like a fraud, but I definitely feel like a fraud when I hang out with like either mathematicians or physicists."}, {"time": 265, "text": "It's like, it feels like they're doing the legit work because when you talk closer in computer science, you get to programming or like machine learning, like the experimental machine learning or like just the engineering version of it."}, {"time": 281, "text": "It feels like you're gone so far away from what's required to solve something fundamental about this universe."}, {"time": 289, "text": "It feels like you're just like cheating your way into like some kind of trick to figure out how to solve a problem in this one particular case."}, {"time": 299, "text": "I'd be interested to hear what you think about that because programming doesn't always feel like you need to think deeply to work deeply, but sometimes it does."}, {"time": 312, "text": "So it's a weird dance."}, {"time": 314, "text": "For sure code does, right?"}, {"time": 315, "text": "I mean, especially if you're coming up with original algorithmic designs, I think it's a great example of deep work."}, {"time": 322, "text": "I mean, yeah, the hardcore theoreticians, they push it to an extreme."}, {"time": 326, "text": "I mean, I think it's like knowing that athletic endeavor is good and then hanging out with a Olympic athlete, you're like, oh, I see that's what it is."}, {"time": 335, "text": "Now for the grad students like me, we're not anywhere near that level, but the faculty in that group, these were the cognitive Olympic athletes."}, {"time": 344, "text": "But coding I think is a classic example of deep work because I got this problem I wanna solve, I have all of these tools and I have to combine them somehow creatively and on the fly."}, {"time": 356, "text": "But so basically I had been exposed to that."}, {"time": 359, "text": "So I was used to this notion when I was in grad school and I was writing my blog, I'd write about hard focus."}, {"time": 363, "text": "That was the term I used."}, {"time": 365, "text": "Then I published this book, So Good They Can't Ignore You, which came out in 2012."}, {"time": 369, "text": "So like right as I began as a professor."}, {"time": 372, "text": "And that book had this notion of skill being really important for career satisfaction, that it's not just following your passion."}, {"time": 379, "text": "You have to actually really get good at something and then you use that skills as leverage."}, {"time": 382, "text": "And there was this big followup question to that book of, okay, well, how do I get really good at things?"}, {"time": 387, "text": "And then I look back to my grad school experience, I was like, huh, there was this focus thing that we used to do."}, {"time": 392, "text": "And I wonder how generally applicable that is into the knowledge sector."}, {"time": 396, "text": "And so as I started thinking about it, it became clear, there's this interesting storyline that emerged that, okay, actually undistracted concentration is not just important for esoteric theoreticians, it's important here, it's important here, it's important here."}, {"time": 408, "text": "And that involved into the deep work hypothesis, which is across the whole knowledge work sector."}, {"time": 415, "text": "Focus is very important and we've accidentally created circumstances where we just don't do a lot of it."}, {"time": 420, "text": "So focus is the sort of prerequisite for basically, you say knowledge work, but basically any kind of skill acquisition, any kind of major effort in this world."}, {"time": 429, "text": "Can we break that apart a little bit?"}, {"time": 431, "text": "Yeah, so a key aspect of focus is not just that you're concentrating hard on something, but you do it without distraction."}, {"time": 440, "text": "So a big theme of my work is that context shifting kills the human capacity to think."}, {"time": 447, "text": "So if I change what I'm paying attention to to something different, really, even if it's brief and then try to bring it back to the main thing I'm doing, that causes a huge cognitive pile up that makes it very hard to think clearly."}, {"time": 458, "text": "So even if you think, okay, look, I'm writing this code or I'm writing this essay and I'm not multitasking and all my windows are closed and I have no notifications on, but every five or six minutes you quickly check like an inbox or your phone, that initiates a context shift in your brain, right?"}, {"time": 474, "text": "We're gonna start to suppress some neural networks, we're gonna try to amplify some others."}, {"time": 477, "text": "It's a pretty complicated process actually."}, {"time": 479, "text": "There's a sort of neurological cascade that happens."}, {"time": 482, "text": "You rip yourself away from that halfway through and go back to what you're doing and now it's trying to switch back to the original thing even though it's also your brain's in the process of switching to these emails and trying to understand those contexts."}, {"time": 491, "text": "And as a result, your ability to think clearly just goes really down."}, {"time": 496, "text": "And it's fatiguing too."}, {"time": 497, "text": "I mean, you do this long enough and you get midday and you're like, okay, I can't think anymore."}, {"time": 502, "text": "You've exhausted yourself."}, {"time": 503, "text": "Is there some kind of perfect number of minutes, would you say?"}, {"time": 508, "text": "So we're talking about focusing on a particular task for one minute, five minutes, 10 minutes, 30 minutes."}, {"time": 517, "text": "Is it possible to kind of context switch while maintaining deep focus every 20 minutes or so?"}, {"time": 524, "text": "So if you're thinking of like this, again, maybe it's a selfish kind of perspective, but if you think about programming, you're focused on a particular design of a little bit, maybe a small scale on a particular function or large scale on a system."}, {"time": 539, "text": "And then the shift of focus happens like this, which is like, wait a minute, is there a library that can achieve this little task or something like that?"}, {"time": 548, "text": "And then you have to look it up."}, {"time": 550, "text": "This is the danger zone."}, {"time": 551, "text": "You go to the internets."}, {"time": 553, "text": "And so you have to, now it is a kind of context switch because as opposed to thinking about the particular problem, you now have switch thinking about like consuming and integrating knowledge that's out there that can plug into your solution to a particular problem."}, {"time": 571, "text": "It definitely feels like a context switch, but is that a really bad thing to do?"}, {"time": 575, "text": "So should you be setting it aside always and really trying to as much as possible go deep and stay there for like a really long period of time?"}, {"time": 585, "text": "Well, I mean, I think if you're looking up a library that's relevant to what you're doing, that's probably okay."}, {"time": 591, "text": "And I don't know that I would count that as a full context shift because the semantic networks involved are relatively similar, right?"}, {"time": 598, "text": "You're thinking about this type of solution."}, {"time": 600, "text": "You're thinking about coding."}, {"time": 601, "text": "You're thinking about this type of functions."}, {"time": 603, "text": "Where you're really gonna get hit is if you switch your context to something that's different."}, {"time": 608, "text": "And if there's unresolved obligations."}, {"time": 609, "text": "So really the worst possible thing you could do would be to look at like an email inbox, right?"}, {"time": 614, "text": "Cause here's 20 emails."}, {"time": 616, "text": "I can't answer most of these right now."}, {"time": 618, "text": "They're completely different."}, {"time": 619, "text": "Like the context of these emails, like, okay, there's a grant funding issue or something like this."}, {"time": 623, "text": "It's very different than the coding I'm doing."}, {"time": 625, "text": "And I'm leaving it unresolved."}, {"time": 627, "text": "So like someone needs something from me and I'm gonna try to pull my attention back."}, {"time": 630, "text": "The second worst would be something that's emotionally arousing."}, {"time": 633, "text": "So if you're like, let me just glance over at Twitter."}, {"time": 635, "text": "I'm sure it's nice and calm and peaceful over there, right?"}, {"time": 637, "text": "That could be devastating because you're gonna expose yourself to something that's emotionally arousing."}, {"time": 641, "text": "That's gonna completely mess up the cognitive plateau there."}, {"time": 643, "text": "And then when you come back to, okay, let me try to code again."}, {"time": 646, "text": "It's really difficult."}, {"time": 647, "text": "So it's both the information and the emotion."}, {"time": 650, "text": "Yeah, both can be killers if what you're trying to do."}, {"time": 653, "text": "So I would recommend at least an hour at a time because it could take up to 20 minutes to completely clear out the residue from whatever it was you were thinking about before."}, {"time": 662, "text": "So if you're coding for 30 minutes, you might only be getting 10 or 15 minutes of actual sort of peak lacks going on there, right?"}, {"time": 668, "text": "So an hour at least you get a good 40, 45 minutes plus."}, {"time": 671, "text": "I'm partial to 90 minutes as a really good chunk."}, {"time": 675, "text": "We can get a lot done."}, {"time": 676, "text": "But just before you get exhausted, you can sort of pull back a little bit."}, {"time": 681, "text": "Yeah, and one of the beautiful, people can read about it in your book, Deep Work."}, {"time": 687, "text": "And I know this has been out for a long time and people are probably familiar with many of the concepts, but it's still pretty profound and it has stayed with me for a long time."}, {"time": 696, "text": "There's something about adding the terms to it that actually solidifies the concepts."}, {"time": 702, "text": "Like words matter, it's pretty cool."}, {"time": 704, "text": "And just for me, sort of as a comment, there's, it's a struggle and it's very difficult to maintain focus for a prolonged period of time."}, {"time": 716, "text": "But the days on which I'm able to accomplish several hours of that kind of work, I'm happy."}, {"time": 723, "text": "So forget being productive and all that."}, {"time": 725, "text": "I'm just satisfied with my life."}, {"time": 727, "text": "I feel fulfilled, it's like joyful."}, {"time": 731, "text": "And then I can be, I'm less of a dick to other people in my life afterwards."}, {"time": 739, "text": "And I find the opposite when I don't do that kind of thing, I'm much more irritable."}, {"time": 745, "text": "Like I feel like I didn't accomplish anything and there's this stress that then the negative emotion builds up to where you're no longer able to sort of enjoy the hell out of this amazing life."}, {"time": 755, "text": "So in that sense, Deep Work has been a source of a lot of happiness."}, {"time": 759, "text": "I'd love to ask you, how do you, again, you cover this in the book, but how do you integrate Deep Work into your life?"}, {"time": 766, "text": "What are different scheduling strategies that you would recommend just at a high level?"}, {"time": 771, "text": "What are different ideas there?"}, {"time": 772, "text": "Well, I mean, I'm a big fan of time blocking, right?"}, {"time": 775, "text": "So if you're facing your workday, don't allow like your inbox or a to do list to sort of drive you."}, {"time": 782, "text": "Don't just come into your day and think, what do I wanna do next?"}, {"time": 785, "text": "I mean, I'm a big planner saying, here's the time available, let me make a plan for it."}, {"time": 791, "text": "So I have a meeting here, I have an appointment here, here's what's left, what do I actually wanna do with it?"}, {"time": 795, "text": "So in this half hour, I'm gonna work on this."}, {"time": 797, "text": "For this 90 minute block, I'm gonna work on that."}, {"time": 799, "text": "And during this hour, I'm gonna try to fit this in."}, {"time": 801, "text": "And then actually I have this half hour gap between two meetings."}, {"time": 803, "text": "So why don't I take advantage of that to go run five errands, I can kind of batch those together."}, {"time": 807, "text": "But blocking out in advance, this is what I wanna do with the time available."}, {"time": 812, "text": "I mean, I find that's much more effective."}, {"time": 813, "text": "Now, once you're doing this, once you're in a discipline of time blocking, it's much easier to actually see, this is where I want, for example, the Deep Work."}, {"time": 820, "text": "And I can get a handle on the other things that need to happen and find better places to fit them so I can prioritize this."}, {"time": 826, "text": "And you're gonna get a lot more of that done than if it's just going through your day and saying, what's next?"}, {"time": 831, "text": "I schedule every single day kind of thing."}, {"time": 833, "text": "So as I could try to do in the morning to try to have a plan."}, {"time": 837, "text": "Yeah, so I do a quarterly, weekly, daily planning."}, {"time": 840, "text": "So at the semester or quarterly level, I have a big picture vision for what I'm trying to get done during the fall, let's say, or during the winter."}, {"time": 848, "text": "Like there's a deadline coming up for academic papers at the end of the season, here's what I'm working on."}, {"time": 853, "text": "I wanna have this many chapters done of a book, something like this."}, {"time": 856, "text": "Like you have the big picture vision of what you wanna get done."}, {"time": 860, "text": "Then weekly, you look at that, and then you look at your week and you put together a plan for like, okay, what's my week gonna look like?"}, {"time": 867, "text": "What do I need to do?"}, {"time": 868, "text": "How am I gonna make progress on these things?"}, {"time": 869, "text": "Maybe I need to do an hour every morning or I see that Monday is my only really empty day."}, {"time": 874, "text": "So that's gonna be the day that I really need to nail on writing or something like this."}, {"time": 878, "text": "And then every day, you look at your weekly plan and say, let me block off the actual hours."}, {"time": 882, "text": "So you do that three scales, the quarterly, down to weekly, down to daily."}, {"time": 887, "text": "And we're talking about actual times of day versus, so the alternative is what I end up doing a lot, and I'm not sure it's the best way to do it, is scheduling the duration of time."}, {"time": 901, "text": "This is called the luxury when you don't have any meetings."}, {"time": 904, "text": "I'm like, religiously don't do meetings."}, {"time": 907, "text": "All other academics are jealous of you, by the way."}, {"time": 911, "text": "No Zoom meetings."}, {"time": 913, "text": "I find those are, that's one of the worst tragedies of the pandemic, is both the opportunity to, the positive thing is to have more time with your family, sort of reconnect in many ways."}, {"time": 929, "text": "Be able to remotely sort of not waste time on travel and all those kinds of things."}, {"time": 935, "text": "The negative is, actually both those things are also sourced from the negative."}, {"time": 940, "text": "But the negative is like, it seems like people have multiplied the number of meetings because they're so easy to schedule."}, {"time": 946, "text": "And there's nothing more draining to me intellectually, philosophically, just my spirit is destroyed by even a 10 minute Zoom meeting."}, {"time": 957, "text": "Like, what are we doing here?"}, {"time": 961, "text": "Yeah, I have, every Zoom meeting is, I have an existential crisis, so."}, {"time": 965, "text": "Kierkegaard with the internet connection."}, {"time": 968, "text": "So, what the hell are we talking about?"}, {"time": 973, "text": "Oh, so when you don't have meetings, there's a luxury to really allow for certain things if they need to, like the important things, like deep work sessions to last way longer than you maybe planned for."}, {"time": 990, "text": "I mean, that's my goal is to try to schedule, the goal is to schedule, to sit and focus for a particular task for an hour and hope I can keep going and hope I can get lost in it."}, {"time": 1001, "text": "And do you find that this is at all an okay way to go and the time blocking is just something you have to do to actually be an adult and operate in this real world?"}, {"time": 1014, "text": "Or is there some magic to the time blocking?"}, {"time": 1017, "text": "Well, I mean, there's magic to the intention."}, {"time": 1021, "text": "There's magic to it if you have varied responsibilities."}, {"time": 1025, "text": "So I'm often juggling multiple jobs, essentially."}, {"time": 1028, "text": "There's academic stuff, there's teaching stuff, there's book stuff, there's the business surrounding my book stuff."}, {"time": 1036, "text": "But I'm of your same mindset."}, {"time": 1038, "text": "If a deep work session is going well, you just rock and roll and let it go on."}, {"time": 1044, "text": "So like one of the big keys of time block, at least the way I do it, so I even sell this planner to help people time block, it has many columns because the discipline is, oh, if your initial schedule changes, you just move over one."}, {"time": 1056, "text": "Next time you get a chance, you move over one column and then you just fix it for the time that's remaining."}, {"time": 1061, "text": "So in other words, there's no bonus for I made a schedule and I stuck with it."}, {"time": 1066, "text": "Like there's actually, it's not like you get a prize for it, right?"}, {"time": 1068, "text": "Like for me, the prize is I have an intentional plan for my time and if I have to change that plan, that's fine."}, {"time": 1074, "text": "Like the state I wanna be is basically at any point in the day, I've thought about what time remains and gave it some thought for what to do because I'll do the same thing, even though I have a lot more meetings and other types of things I have to do in my various jobs and I basically prioritize the deep work and they get yelled at a lot."}, {"time": 1091, "text": "So that's kind of my strategy is like, just be okay, just be okay getting yelled at a lot because I feel you, if you're rolling, yeah."}, {"time": 1122, "text": "So I'm willing to get yelled at by almost everyone."}, {"time": 1125, "text": "Of course, there is also a positive effect to pulling yourself out of it when things are going great because then you're kind of excited to resume."}, {"time": 1136, "text": "Like stopping on a dead end."}, {"time": 1143, "text": "There's an extra force of procrastination that comes with if you stop on a dead end to return to the task."}, {"time": 1148, "text": "Yeah, or a cold start."}, {"time": 1151, "text": "Whenever I feel like I'm in a stage now, I submitted a few papers recently."}, {"time": 1155, "text": "So now we're sort of starting something up from cold and it takes way too long to get going because it's very hard to get the motivation to schedule a time when it's not, yeah, we're in it."}, {"time": 1165, "text": "Like here's where we are."}, {"time": 1166, "text": "We feel like something's about to give here."}, {"time": 1168, "text": "We need the very early stages where it's just, I don't know, I'm gonna read hard papers and it's gonna be hard to understand them and I'm gonna have no idea how to make progress."}, {"time": 1175, "text": "It's not motivating."}, {"time": 1179, "text": "Can we, okay, so this is like a therapy session."}, {"time": 1186, "text": "It seems like I only get stuff done that has deadlines."}, {"time": 1190, "text": "And so one of the implied powerful things about time blocking is there's a kind of deadline or there's a artificial or real sense of urgency."}, {"time": 1199, "text": "Do you think it's possible to get anything done in this world without deadlines?"}, {"time": 1204, "text": "Why do deadlines work so well?"}, {"time": 1206, "text": "Well, I mean, it's a clear motivational signal, but in the short term, you do get an effect like that in time blocking."}, {"time": 1212, "text": "I think the strong effect you get by saying, this is the exact time I'm gonna work on this, is that you don't have the debate with yourself every three minutes about, should I take a break now?"}, {"time": 1223, "text": "This is the big issue with just saying, I'm gonna go write."}, {"time": 1226, "text": "I'm gonna write for a while and that's it because your mind is saying, well, obviously we're gonna take some breaks."}, {"time": 1230, "text": "We're not just gonna write forever."}, {"time": 1232, "text": "And so why not right now?"}, {"time": 1234, "text": "You have to be like, well, not right now."}, {"time": 1235, "text": "Let's go a little bit longer, five minutes."}, {"time": 1236, "text": "So why don't we just take a break now?"}, {"time": 1237, "text": "We should probably look at the internet."}, {"time": 1238, "text": "Now you have to constantly have this battle."}, {"time": 1240, "text": "On the other hand, if you're in a time block schedule, I've got these two hours put aside for writing."}, {"time": 1244, "text": "That's what I'm supposed to be doing."}, {"time": 1246, "text": "I have a break scheduled over here."}, {"time": 1248, "text": "I don't have to fight with myself, right?"}, {"time": 1250, "text": "And maybe at a larger scale, deadlines give you a similar sort of effect."}, {"time": 1253, "text": "I know this is what I'm supposed to be working on because it's due."}, {"time": 1257, "text": "Perhaps, but will you describe it as much healthier sort of giving yourself over, and you talk about this in the new email book, the process, I mean, in general, you talk about it all over, is creating a process and then giving yourself over to the process."}, {"time": 1275, "text": "But then you have to be strict with yourself."}, {"time": 1277, "text": "Yeah, but what are the deadlines you're talking about?"}, {"time": 1279, "text": "It's like with papers, like what's the main type of deadline work?"}, {"time": 1284, "text": "Well, so papers, definitely, but publications, like say this podcast, I have to publish this podcast early next week, one, because your book is coming out."}, {"time": 1296, "text": "I'd love to sort of support this amazing book, but the other is I have to fly to Vegas on Thursday to run 40 miles with David Goggins."}, {"time": 1307, "text": "And so I want this podcast, this conversation we're doing now to be out of my life."}, {"time": 1314, "text": "Like I don't wanna be in a hotel in Vegas, like freaking out while David Goggins is yelling."}, {"time": 1320, "text": "On hour 43 of your Tarathon thing."}, {"time": 1325, "text": "But actually it's possible that I still will be doing that because that's not a hard, that's a softer deadline, right?"}, {"time": 1331, "text": "But those are sort of, life imposes these kinds of deadlines."}, {"time": 1336, "text": "I'm not, so yeah, papers are nice because there's an actual deadline."}, {"time": 1340, "text": "But I am almost referring to like the pressure that people put on you."}, {"time": 1345, "text": "Hey man, you said you're gonna get this done two months ago."}, {"time": 1348, "text": "Why haven't you gotten it done?"}, {"time": 1350, "text": "I don't see, I don't like that pressure."}, {"time": 1352, "text": "First of all, I think we can all."}, {"time": 1353, "text": "I hate it too."}, {"time": 1354, "text": "We can agree, by the way, having David Goggins yell at you is probably the top productivity technique."}, {"time": 1359, "text": "I think we'd all get a lot more done if he was yelling, but see, I don't like that."}, {"time": 1365, "text": "So I will try to get things done early."}, {"time": 1367, "text": "I like having flex."}, {"time": 1369, "text": "I also don't like the idea of this has to get done today."}, {"time": 1373, "text": "Like it's due at midnight and we've got a lot to do as the night before, because then I get in my head about what if I get sick?"}, {"time": 1379, "text": "Or like, what if, you know, what if I don't get a bad night's sleep and I can't think clearly?"}, {"time": 1384, "text": "So I like to have the flex."}, {"time": 1385, "text": "So I'm all process."}, {"time": 1387, "text": "And that's like the philosophical aspect of that book, Deep Work, is that there's something very human and deep about just wrangling with the world of ideas."}, {"time": 1395, "text": "I mean, Aristotle talked about this."}, {"time": 1396, "text": "If you go back and read the ethics, he's trying to understand the meaning of life and he eventually ends up ultimately at the human capacity to contemplate deeply."}, {"time": 1406, "text": "It's kind of like a teleological argument."}, {"time": 1407, "text": "It's the things that only humans can do and therefore it must be somehow connected to our ends."}, {"time": 1411, "text": "And he said, ultimately that's where he found his meaning, but, you know, he's touching on some sort of intimation there that's correct."}, {"time": 1417, "text": "And so what I try to build my life around is regularly thinking hard about stuff that's interesting."}, {"time": 1424, "text": "Just like if you get a fitness habit going, you feel off when you don't do it."}, {"time": 1430, "text": "I try to get that cognitive habit."}, {"time": 1431, "text": "So it's like, I got it."}, {"time": 1432, "text": "I mean, look, I have my bag here somewhere, I have my notebook in it because I was thinking on the Uber ride over, I was like, you know, I could get some, I'm working on this new proof and it just, so you train yourself."}, {"time": 1442, "text": "You train yourself to appreciate certain things."}, {"time": 1444, "text": "And then over time, the hope is that it accretes."}, {"time": 1448, "text": "Well, let's talk about some demons because I wonder there's like deep work, which and the world without email books that to me symbolize the life I want to live."}, {"time": 1464, "text": "And then there is, I'm like, despite appearances and adult at this point, and this is the life I actually live."}, {"time": 1473, "text": "And I'm in constant chaos."}, {"time": 1476, "text": "You said you don't like that anxiety."}, {"time": 1478, "text": "But it seems like I'm always in it."}, {"time": 1481, "text": "It's a giant mess."}, {"time": 1482, "text": "It's like, it's almost like whenever I establish, whenever I have successful processes for doing deep work, I'll add stuff on top of it just to introduce the chaos."}, {"time": 1492, "text": "And like, I don't want to."}, {"time": 1494, "text": "But you have to look in the mirror at a certain point and you have to say like, who the hell am I?"}, {"time": 1500, "text": "Like, I keep doing this."}, {"time": 1502, "text": "Is this something that's fundamental to who I am or do I really need to fix this?"}, {"time": 1506, "text": "What's the chaos right now?"}, {"time": 1507, "text": "Like, I've seen your video about like your routine."}, {"time": 1509, "text": "It seemed very structured and deep."}, {"time": 1512, "text": "In fact, I was really envious of it."}, {"time": 1513, "text": "So like, what's the chaos now that's not in that video?"}, {"time": 1517, "text": "Many of those sessions go way longer."}, {"time": 1519, "text": "I don't get enough sleep."}, {"time": 1521, "text": "And then I, the main introduction of chaos is, it's taking on too many things on the to do list."}, {"time": 1527, "text": "It's, I mean, I suppose it's a problem that everybody deals with, which is saying, not saying no."}, {"time": 1533, "text": "But it's not like I have trouble saying no."}, {"time": 1536, "text": "It's that there's so much cool shit in my life."}, {"time": 1539, "text": "Okay, listen, there's nothing I love more in this world than the Boston Dynamics robots."}, {"time": 1545, "text": "Spot and the other, yeah."}, {"time": 1546, "text": "And they're giving me spot."}, {"time": 1548, "text": "So there's a to do, what am I gonna say?"}, {"time": 1552, "text": "So they're getting me spot and I wanna do some computer vision stuff for the hell of it."}, {"time": 1555, "text": "Okay, so that's now a to do item."}, {"time": 1557, "text": "And then you go to Texas for a while."}, {"time": 1559, "text": "There's Texas."}, {"time": 1560, "text": "Everything's happening."}, {"time": 1560, "text": "There's all the interesting people down there."}, {"time": 1562, "text": "And then there's surprises, right?"}, {"time": 1563, "text": "There are power outages in Texas."}, {"time": 1565, "text": "There's constant changes to plans and all those kinds of things."}, {"time": 1568, "text": "And you sleep less."}, {"time": 1569, "text": "And then there's personal stuff, like just people in your life, sources of stress, all those kinds of things."}, {"time": 1576, "text": "But it does feel like if I'm just being introspective, that I bring it onto myself."}, {"time": 1582, "text": "I suppose a lot of people do this kind of thing."}, {"time": 1585, "text": "Is they flourish under pressure."}, {"time": 1590, "text": "And I wonder if that's just a hack I've developed as a habit early on in life that you need to let go of, you need to fix."}, {"time": 1602, "text": "But it's all interesting things."}, {"time": 1605, "text": "Yeah, because these are all interesting things."}, {"time": 1607, "text": "Well, one of the things you talked about in Deep Work, which is really important, is having an end to the day."}, {"time": 1614, "text": "Like putting it down."}, {"time": 1616, "text": "Like that, I don't think I've ever done that in my life."}, {"time": 1619, "text": "Well, see, I started doing that early because I got married early."}, {"time": 1624, "text": "So I didn't have a real job."}, {"time": 1625, "text": "I was a grad student, but my wife had a real job."}, {"time": 1627, "text": "And so I just figured I should do my work when she's at work."}, {"time": 1632, "text": "Because hey, when work's over, she'll be home, and I don't wanna be on campus or whatever."}, {"time": 1637, "text": "And so real early on, I just got in that habit of this is when you end work."}, {"time": 1642, "text": "And then when I was a postdoc, which is kind of an easy job, right?"}, {"time": 1646, "text": "I put artificial, I was like, I wanna train."}, {"time": 1649, "text": "I was like, when I'm a professor, it's gonna be busier because there's demands that professors have beyond research."}, {"time": 1654, "text": "And so as a postdoc, I added artificial large time consuming things into the middle of my day."}, {"time": 1658, "text": "I basically exercise for two hours in the middle of the day and do all this productive meditation and stuff like this, while still maintaining the nine to five."}, {"time": 1666, "text": "So it's like, okay, I wanna get really good at putting artificial constraints on so that I stay, I didn't wanna get flabby when my job was easy."}, {"time": 1674, "text": "So that when I became a professor, and now all of that's paying off because I have a ton of kids."}, {"time": 1679, "text": "So now I don't really have a choice."}, {"time": 1681, "text": "That's what's probably keeping me away from cool things is I just don't have time to do them."}, {"time": 1686, "text": "And then after a while people stop bothering."}, {"time": 1689, "text": "Well, but that's how you have a successful life."}, {"time": 1693, "text": "Otherwise you're going to, it's too easy to then go into the full Hunter S. Thompson."}, {"time": 1697, "text": "Like to where nobody wants, nobody functional wants to be in your vicinity."}, {"time": 1705, "text": "Like you're driving, you attract the people that have a similar behavior pattern as you."}, {"time": 1713, "text": "So if you live in chaos, you're going to attract chaotic people."}, {"time": 1717, "text": "And then it becomes like this self fulfilling prophecy."}, {"time": 1722, "text": "And it feels like I'm not bothered by it, but I guess this is all coming around to exactly what you're saying, which is like, I think one of the big hacks for productive people that I've met is to get married and have kids, honestly."}, {"time": 1737, "text": "It's very perhaps counterintuitive, but it gets, it's like the ultimate timetable enforcer."}, {"time": 1745, "text": "Yeah, it enforces a lot of timetables, though it has a huge, kids have a huge productivity hit those, you gotta weigh it."}, {"time": 1753, "text": "But okay, here's the complicated thing though."}, {"time": 1755, "text": "Like you could think about in your own life, starting the podcast as one of these just cool opportunities that you put on yourself, right?"}, {"time": 1762, "text": "Like I could have been talking to you at MIT four years ago and be like, don't do that."}, {"time": 1765, "text": "Like your research is going well, right?"}, {"time": 1768, "text": "But then everyone who watches you is like, okay, this podcast is, the direction that's taking you is like a couple of years from now, it's gonna, it'll be something really monumental that you're probably, that's gonna probably lead to, right?"}, {"time": 1778, "text": "There'll be some really, it just feels like your life is going somewhere."}, {"time": 1781, "text": "It's going somewhere."}, {"time": 1783, "text": "Unexpected, yeah."}, {"time": 1784, "text": "Yeah, so how do you balance those two things?"}, {"time": 1786, "text": "And so what I try to throw at it is this motto of do less, do better, know why, right?"}, {"time": 1790, "text": "So do less, do better, know why."}, {"time": 1795, "text": "It used to be the motto of my website years ago."}, {"time": 1798, "text": "So do a few things, but like an interesting array, right?"}, {"time": 1801, "text": "So I was doing MIT stuff, but I was also writing, you know?"}, {"time": 1806, "text": "So a couple of things are, you know, they were interesting."}, {"time": 1808, "text": "Like I have a couple bets placed on a couple of different numbers on the roulette table, but not too many things."}, {"time": 1814, "text": "And then really try to do those things really well and see where it goes."}, {"time": 1816, "text": "Like with my writing, I just spent years and years and years just training."}, {"time": 1819, "text": "I was like, I wanna be a better writer, I wanna be a better writer."}, {"time": 1821, "text": "I started writing student books when I was a student."}, {"time": 1824, "text": "I really wanted to write hardcover idea books."}, {"time": 1825, "text": "I started training."}, {"time": 1826, "text": "I would use like New Yorker articles to train myself."}, {"time": 1830, "text": "I'd break them down and then I'd get commissions with much smaller magazines and practice the skills."}, {"time": 1834, "text": "And it took forever until, you know, but now today, like I actually get to write for the New Yorker, but it took like a decade."}, {"time": 1840, "text": "So a small number of things, try to do them really well."}, {"time": 1842, "text": "And then the know why is have a connection to some sort of value."}, {"time": 1845, "text": "Like in general, I think this is worth doing and then seeing where it leads."}, {"time": 1850, "text": "And so the choice of the few things is grounded in what?"}, {"time": 1855, "text": "Like a little flame of passion, like a love for the thing, like a sense that you say you wanted to write, get good at writing."}, {"time": 1864, "text": "You had that kind of introspective moment of thinking, this actually brings me a lot of joy and fulfillment."}, {"time": 1870, "text": "Yeah, I mean, it gets complicated because I wrote a whole book about following your passion being bad advice, which is like the first thing I kind of got infamous for."}, {"time": 1878, "text": "I wrote that back in 2012."}, {"time": 1880, "text": "But the argument there is like passion cultivates, right?"}, {"time": 1883, "text": "So what I was pushing back on was the myth that the passion for what you do exists full intensity before you start, and then that's what propels you."}, {"time": 1892, "text": "Or actually the reality is as you get better at something, as you gain more autonomy, more skill and more impact, the passion grows along with it."}, {"time": 1898, "text": "So that when people look back later and say, oh, follow your passion, what they really mean is I'm very passionate about what I do, and that's a worthy goal."}, {"time": 1907, "text": "But how you actually cultivate that is much more complicated than just introspection is gonna identify, like for sure you should be a writer or something like this."}, {"time": 1914, "text": "So I was actually quoting you."}, {"time": 1915, "text": "I was on a social network last night in a clubhouse."}, {"time": 1920, "text": "I don't know if you've heard of it."}, {"time": 1921, "text": "Wait, I have to ask you about this because I'm invited to do a clubhouse."}, {"time": 1927, "text": "A tech reporter has invited me to do a clubhouse about my new book."}, {"time": 1932, "text": "Well, let me know when, because I'll show up."}, {"time": 1934, "text": "But what is it?"}, {"time": 1935, "text": "Okay, so first of all, let me just mention that I was in a clubhouse room last night, and I kept plugging exactly what you said about passion."}, {"time": 1944, "text": "So we'll talk about it."}, {"time": 1945, "text": "It was a room that was focused on burnout."}, {"time": 1949, "text": "But first, clubhouse is a kind of fascinating place in terms of your mind would be very interesting to analyze this place because we talk about email, talk about social networks, but clubhouse is something very different."}, {"time": 1965, "text": "And I've encountered it in other places, Discord and so on, that's voice only communication."}, {"time": 1972, "text": "So it's a bunch of people in a room."}, {"time": 1973, "text": "They're just, their eyes closed."}, {"time": 1976, "text": "All you hear is their voices."}, {"time": 1977, "text": "In real time."}, {"time": 1978, "text": "Real time, live."}, {"time": 1979, "text": "It only happens live."}, {"time": 1981, "text": "You're technically not allowed to record, but some people still do, and especially when it's big conversations."}, {"time": 1987, "text": "But the whole point is it's there live."}, {"time": 1989, "text": "And there's different structures."}, {"time": 1990, "text": "Like on Discord, it was so fascinating."}, {"time": 1993, "text": "I have this Discord server that would have hundreds of people in a room together, right?"}, {"time": 1999, "text": "We're all just little icons that can mute and unmute our mics."}, {"time": 2003, "text": "And so you're sitting there, so it's just voices, and you're able with hundreds of people to not interrupt each other."}, {"time": 2013, "text": "Well, first of all, like as a dynamic system, like."}, {"time": 2017, "text": "You see icons just like mics muted or not muted basically."}, {"time": 2020, "text": "Yeah, well, so everyone's muted and they unmute and it starts flashing."}, {"time": 2024, "text": "Oh, so you're like, okay, let me get precedence."}, {"time": 2028, "text": "So it's the digital equivalent of when you're in a conversation, like at a faculty meeting, and you sort of like kind of make some noises, like while the other person's finishing."}, {"time": 2036, "text": "And so people realize like, okay, this person wants to talk next, but now it's purely digital."}, {"time": 2040, "text": "You see a flashing."}, {"time": 2041, "text": "But in a faculty meeting, which is very interesting, like even as we're talking now, there's a visual element that seems to increase the probability of interruption."}, {"time": 2052, "text": "It's just darkness."}, {"time": 2053, "text": "You actually listen better and you don't interrupt."}, {"time": 2057, "text": "So like if you create a culture, there's always gonna be assholes, but they're actually exceptions."}, {"time": 2063, "text": "Everybody adjusts."}, {"time": 2064, "text": "They kind of evolve to the beat of the room."}, {"time": 2068, "text": "Okay, that's one fascinating aspect."}, {"time": 2070, "text": "It's like, okay, that's weird."}, {"time": 2072, "text": "Cause it's different than like a Zoom call where there's video."}, {"time": 2076, "text": "It's just audio."}, {"time": 2078, "text": "You think video adds, but actually seems like it subtracts."}, {"time": 2082, "text": "The second aspect of it that's fascinating is when it's no video, just audio, there's an intimacy."}, {"time": 2091, "text": "Because with strangers, you connect in a much more real way."}, {"time": 2097, "text": "It's similar to podcasts."}, {"time": 2099, "text": "But with a lot of people."}, {"time": 2101, "text": "With a lot of people and new people."}, {"time": 2103, "text": "And they bring, okay, first of all, different voices, like low voices and like high voices."}, {"time": 2110, "text": "And it's more difficult to judge."}, {"time": 2114, "text": "In Discord, you couldn't even see the people."}, {"time": 2118, "text": "It was a culture where you do funny profile pictures as opposed to your actual face."}, {"time": 2123, "text": "In clubhouse, it's your actual face."}, {"time": 2124, "text": "So you can tell like as an older person, younger person."}, {"time": 2127, "text": "In Discord, you couldn't."}, {"time": 2128, "text": "You just have to judge based on the voice."}, {"time": 2131, "text": "But there's something about the listening and the intimacy of being surprised by different strangers that feels almost like a party with friends."}, {"time": 2143, "text": "And friends of friends you haven't met yet, but you really like."}, {"time": 2147, "text": "Now clubhouse also has an interesting innovation where there's a large crowd that just listens and there's a stage."}, {"time": 2154, "text": "And you can bring people up onto stage."}, {"time": 2156, "text": "So only people on stage are talking."}, {"time": 2159, "text": "And you can have like five, six, seven, eight, sometimes 20, 30 people on stage."}, {"time": 2163, "text": "And then you can also have thousands of people just listening."}, {"time": 2166, "text": "So there's a, I don't know, a lot of people are being surprised by this."}, {"time": 2170, "text": "Why is it called a social network?"}, {"time": 2172, "text": "It seems like it doesn't have, there's not social links."}, {"time": 2174, "text": "There's not a feed that's trying to harvest attention."}, {"time": 2177, "text": "It feels like a communication."}, {"time": 2180, "text": "So the social network aspect is you follow people."}, {"time": 2184, "text": "And the people you follow, now this is like the first social network that is actually correct use of follow, I think."}, {"time": 2190, "text": "You're more likely to see the rooms they're in."}, {"time": 2195, "text": "So there's a, your feed is a bunch of rooms that are going on right now."}, {"time": 2199, "text": "And the people you follow are the ones that will increase the likelihood that you'll see the room they're in."}, {"time": 2206, "text": "And so the final result is like, there's a list of really interesting rooms."}, {"time": 2210, "text": "Like I have all these, I've been speaking Russian quite a bit, there's practicing, but also just like talking politics and philosophy in Russian."}, {"time": 2220, "text": "I've never done that before, but it allows me to connect with that community."}, {"time": 2223, "text": "And then there's a community of people, like it's funny, but like I'll go in a community of all African American people talking about race and I'll be welcomed."}, {"time": 2233, "text": "I've never had, like I've literally never been in a difficult conversation about race, like with people from all over the place."}, {"time": 2242, "text": "It's like fascinating."}, {"time": 2243, "text": "And then musicians, jazz musicians, I don't know."}, {"time": 2246, "text": "You could say that a lot of other places could have created that culture, I suppose."}, {"time": 2251, "text": "Twitter and Facebook a lot for that culture, but there's something about this network as it stands now, cause no Android users."}, {"time": 2260, "text": "It's probably just because it's iPhone people."}, {"time": 2264, "text": "Less conspiratorial or something."}, {"time": 2265, "text": "Well, like less, listen, I'm an Android person."}, {"time": 2267, "text": "So I got an iPhone just for this network, which is funny."}, {"time": 2272, "text": "For now it's all like, there's very few trolls."}, {"time": 2275, "text": "There's very few people that are trying to manipulate the system and so on."}, {"time": 2279, "text": "So I don't know, it's interesting."}, {"time": 2280, "text": "Now the downside, the reason you're going to hate it is because it's so intimate, because it pulls you in and pulls in very successful people like you, just like really successful, productive, very busy people."}, {"time": 2300, "text": "It's a huge time sink."}, {"time": 2301, "text": "It's very difficult to pull yourself out."}, {"time": 2303, "text": "Interesting, you mean once you're in a room?"}, {"time": 2305, "text": "Well, no, leaving the room is actually easy."}, {"time": 2307, "text": "The beautiful thing about a stage with multiple people, there's a little button that says leave quietly."}, {"time": 2313, "text": "So culture, no etiquette wise, it's okay to just leave."}, {"time": 2318, "text": "So you and I in a room, when it's just you and I, it's a little awkward to leave."}, {"time": 2322, "text": "If you're asking questions, I'm just gone."}, {"time": 2324, "text": "But, and actually if you're being interviewed for the book, that's weird because you're now in the event and you're supposed to, but usually the person interviewing would be like, okay, it's time for you to go."}, {"time": 2363, "text": "And there's the addicting aspect to it."}, {"time": 2366, "text": "The reason it's a time sink is you don't wanna leave."}, {"time": 2370, "text": "What I've noticed about exceptionally busy people that they love this."}, {"time": 2375, "text": "I think it might have to do with the pandemic."}, {"time": 2377, "text": "It might be a little bit, yeah."}, {"time": 2378, "text": "There's a loneliness."}, {"time": 2379, "text": "They're all starved, yeah."}, {"time": 2380, "text": "But also it's really cool people."}, {"time": 2383, "text": "Like when was the last time you talked to Sam Harris or whoever, like think of anybody, Tyler Copeland, like any faculty."}, {"time": 2392, "text": "This is like what universities strive to create, but it's taken hundreds of years of cultural evolution to try to get a lot of interesting, smart people together that run into each other."}, {"time": 2400, "text": "We have really strong faculty in a room together with no scheduling."}, {"time": 2405, "text": "This is the power of it."}, {"time": 2407, "text": "It's like you just show up, there's none of that baggage of scheduling and so on and there's no pressure to leave, sorry, no pressure to stay."}, {"time": 2415, "text": "It's very easy for you to leave."}, {"time": 2416, "text": "You realize that there's a lot of constraints on meetings and like faculty, like even stopping by before the pandemic, a friend or faculty or colleague and so on, there's a weirdness about leaving."}, {"time": 2431, "text": "But here there's not a weirdness about leaving."}, {"time": 2433, "text": "So they've discovered something interesting."}, {"time": 2436, "text": "But the final result when you observe it is it's very fulfilling."}, {"time": 2441, "text": "I think it's very beneficial, but it's very addicting."}, {"time": 2444, "text": "So you have to make sure you moderate."}, {"time": 2450, "text": "Okay, well, so maybe I'll try it."}, {"time": 2452, "text": "I mean, look, there's no, the things that make me suspicious about other platforms aren't here."}, {"time": 2456, "text": "So the feed is not full of user generated content that is going through some sort of algorithmic rating process with all the weird incentives and nudging that does."}, {"time": 2465, "text": "And you're not producing content that's being harvested to be monetized by another company."}, {"time": 2471, "text": "I mean, it seems like it's more ephemeral, right?"}, {"time": 2474, "text": "You're here, you're talking."}, {"time": 2475, "text": "The feed is just actually just showing you here's interesting things happening, right?"}, {"time": 2479, "text": "You're not jockeying in the feed for, look, I'm being clever or something and I'm gonna get a light count that goes up and that's gonna influence."}, {"time": 2486, "text": "And there's more friction."}, {"time": 2487, "text": "There's more cognitive friction, I guess, involved in listening to smart people versus scrolling through."}, {"time": 2493, "text": "Yeah, there's something there."}, {"time": 2494, "text": "So there's no."}, {"time": 2495, "text": "Why are people so, I see all, there's all these articles that seem, I haven't really read them."}, {"time": 2500, "text": "Why are reporters negative about this?"}, {"time": 2502, "text": "Competition."}, {"time": 2503, "text": "The New York Times wrote this article called Unfettered Conversations Happening on Clubhouse is."}, {"time": 2509, "text": "So I'm right in picking up a tone even from the headlines that there's some like negative vibes from the press."}, {"time": 2515, "text": "No, so I can say, let's say, well, I'll tell you what the article was saying, which is they're having cancellable conversations, like the biggest people in the world almost trolling the press."}, {"time": 2529, "text": "And the press is desperately."}, {"time": 2530, "text": "Like foreshanning the press."}, {"time": 2531, "text": "Yeah, foreshanning the press."}, {"time": 2533, "text": "By saying that you guys are looking for click bait from our genuine human conversations."}, {"time": 2539, "text": "And so I think the, honestly, the press is just like, what do we do with this?"}, {"time": 2545, "text": "We can't, first of all, it's a lot of work for them."}, {"time": 2549, "text": "It's what Naval says, which is like, this is skipping the journalist."}, {"time": 2554, "text": "Like the interview you, if you go on Clubhouse, the interview you might do for the book will be with somebody who's like a journalist and interviewing you."}, {"time": 2563, "text": "That's more traditional."}, {"time": 2565, "text": "It'd be a good introduction for you to try it."}, {"time": 2567, "text": "But like the way to use Clubhouse is you just show up and it's like, again, like me, I'm sorry, I'm like, boy, I keep mentioning Sam Harris as if it's like the only person I know, but like a lot of these major faculty, I don't know, Max Tegmark."}, {"time": 2584, "text": "Like just major faculty just sitting there and then you show up and then I'll ask like, oh, don't you have a book coming out or something?"}, {"time": 2592, "text": "And then you'll talk about the book and then you'll leave five minutes later because you have to go get coffee included."}, {"time": 2598, "text": "So like that's the, it's not the journalistic, you're not gonna actually enjoy the interview as much because it'll be like the normal thing."}, {"time": 2606, "text": "Like you're there 40 minutes or an hour and there'll be questions from the audience."}, {"time": 2611, "text": "Like I'm doing an event next week for the book launch where it's like Jason Fried and I are talking about email, but it's using some more like a thousand people who are there to watch virtually, but it's using some sort of traditional webinar."}, {"time": 2624, "text": "Clubhouse would be a situation where that could just happen informally."}, {"time": 2627, "text": "Like I jump in like Jason's there and then someone else jumps in and yeah, that's interesting."}, {"time": 2631, "text": "But for now it's still closed."}, {"time": 2633, "text": "So even though there's a lot of excitement and there'll be quite famous people just sitting there listening to you."}, {"time": 2641, "text": "But the numbers aren't exactly high."}, {"time": 2644, "text": "So you're talking about rooms, like even the huge rooms are like just a few thousand."}, {"time": 2650, "text": "And this is probably like Soho in the 50s or something too."}, {"time": 2652, "text": "Just because of the exponential growth, give it seven more months."}, {"time": 2657, "text": "And if you let one invite be, it gets two invites, it gets four invites, because pretty soon it'll be everyone."}, {"time": 2662, "text": "And then the rooms in your feed are gonna be whatever, marketing, performance enhancing drugs or something like that."}, {"time": 2669, "text": "But then in a bunch of competitors, there's already like 30 plus competitors sprung up, Twitter spaces."}, {"time": 2674, "text": "So Twitter is creating a competitor that's going to likely destroy Clubhouse because they just have a much larger user base and they already have a social network."}, {"time": 2682, "text": "So I would be very cautious, of course, with the addictive element, but it doesn't just like you said, this particular implementation in its early stages doesn't have the like, it doesn't have the context switching problem."}, {"time": 2698, "text": "You'll just switch to it and you'll be stuck."}, {"time": 2701, "text": "Yeah, to keep a context is great."}, {"time": 2704, "text": "But then I think the best way I've found to use it is to acknowledge that these things pull you in."}, {"time": 2713, "text": "So I've used it in the past, like almost, I'll go get a coffee and I'll tune into a conversation as if that's how I use podcasts sometimes."}, {"time": 2724, "text": "I'll just like play a little bit of a podcast and then I can just turn it off."}, {"time": 2729, "text": "The problem with these is it pulls you in, it's really interesting."}, {"time": 2732, "text": "And then the other problem that you'll experience is like somebody will recognize you."}, {"time": 2738, "text": "And then they'll be like, oh, Lex."}, {"time": 2740, "text": "Come on up."}, {"time": 2742, "text": "Oh, hey, I had a question for you."}, {"time": 2743, "text": "And then it takes a lot for you to go like, to ignore that."}, {"time": 2749, "text": "And then you pulled in and it's fascinating and it's really cool people."}, {"time": 2752, "text": "So it's like a source of a lot of joy, but you have to be very, very careful."}, {"time": 2758, "text": "The reason I brought it up is we, there's a room, there's an entire club actually on burnout."}, {"time": 2764, "text": "And I brought you up and I brought David Goggins as the process I go through, which is, my passion goes up and down, it dips."}, {"time": 2774, "text": "And I don't think I trust my own mind to tell me whether I'm getting close to burnout or exhaustion or not."}, {"time": 2784, "text": "I kind of go with the David Goggins model of, I mean, he's probably more applying it to running, but when it feels like your mind can't take any more, that you're just 40% at your capacity."}, {"time": 2798, "text": "I mean, it's just like an arbitrary level."}, {"time": 2801, "text": "It's the Navy SEAL thing, right?"}, {"time": 2801, "text": "The Navy SEAL thing."}, {"time": 2803, "text": "I mean, you could put that at any percent, but it is remarkable that if you just take it one step at a time, just keep going, it's similar to this idea of a process."}, {"time": 2813, "text": "If you just trust the process and you just keep following, even if the passion goes up and down and so on, then ultimately, if you look in aggregate, the passion will increase."}, {"time": 2824, "text": "Your self satisfaction will increase."}, {"time": 2826, "text": "And if you have two things, this has been a big strategy of mine, so that what you hope for is off phase, off phase alignment."}, {"time": 2834, "text": "Sometimes it's in phase and that's a problem, but off phase alignment's good."}, {"time": 2838, "text": "So, okay, my research, I'm struggling, but my book stuff is going well, right?"}, {"time": 2842, "text": "And so when you add those two waves together, like, oh, we're doing pretty well."}, {"time": 2845, "text": "And then in other periods, like on my writing, I feel like I'm just not getting anywhere, but I've had some good papers, I'm feeling good over there."}, {"time": 2852, "text": "So having two things that can counteract each other."}, {"time": 2855, "text": "Now, sometimes they fall into sync and then it gets rough."}, {"time": 2858, "text": "Then when, you know, when everything, because everything for me is cyclical, good periods, bad periods with all this stuff."}, {"time": 2863, "text": "So typically they don't coincide, so it helps compensate."}, {"time": 2867, "text": "When they do coincide, you get really high highs, like where everything's clicking, and then you get these really low lows where like your research is not working, your program's not clicking, you feel like you're nowhere with your writing, and then it's a little rougher."}, {"time": 2880, "text": "Is, do you think about the concept of burnout?"}, {"time": 2884, "text": "Because I personally have never experienced burnout in the way that folks talk about, which is like, it's not just the up and down."}, {"time": 2891, "text": "It's like, you don't want to do anything ever again."}, {"time": 2895, "text": "It's like, for some people it's like physical, like to the hospital kind of thing."}, {"time": 2899, "text": "Yeah, so I do worry about it."}, {"time": 2902, "text": "So when I used to do student writing, like writing about students and student advice, it came up a lot with students at elite schools, and I used to call it deep procrastination, but it was a real, really vivid, very replicatable syndrome where they stop being able to do schoolwork."}, {"time": 2920, "text": "Like this is due, and the professor gives you an extension, and the professor gives you an incomplete, and says, you got it, you were gonna fail the course, you have to hand this in, and they can't do it, right?"}, {"time": 2928, "text": "It's like a complete stop on the ability to actually do work."}, {"time": 2932, "text": "And so I used to counsel students who had that issue, and often it was a combination of, this is my best analysis, is you have just the physical and cognitive difficulties of they're usually under a very hard load, right?"}, {"time": 2943, "text": "They're doing too many majors, too many extracurriculars, just really pushing themselves, and the motivation is not sufficiently intrinsic."}, {"time": 2952, "text": "So if you have a motivational center that's not completely on board, so a lot of these kids, like when I'm dealing with MIT kids, they would be, their whole town was shooting off fireworks that they got in."}, {"time": 2961, "text": "Everyone's hoped that they were going there, and that they're in three majors, they don't wanna let people down, but they're not really interested in being a doctor or whatever."}, {"time": 2968, "text": "So your motivation's not in the right place."}, {"time": 2970, "text": "The motivational psychologist would say the locus of control was more towards the extrinsic end of the spectrum, and you have hardship."}, {"time": 2976, "text": "And you could just fritz out the whole system."}, {"time": 2978, "text": "And so I would always be very worried about that."}, {"time": 2980, "text": "So I think about that a lot."}, {"time": 2981, "text": "I do a lot of multi phase or multi scale seasonality."}, {"time": 2985, "text": "So I'll go hard on something for a while, and then for a few weeks, go easy."}, {"time": 2990, "text": "I'll have semesters that are hard, and semesters that are easy."}, {"time": 2993, "text": "Or I'll take the summer really low."}, {"time": 2994, "text": "So on multiple scales, and in the day I'll go really hard on something, but then have a hard cut off at five."}, {"time": 2997, "text": "So like every scale, it's all about rest and recovery."}, {"time": 3001, "text": "Because I really wanna avoid that."}, {"time": 3002, "text": "And I do burn out."}, {"time": 3003, "text": "I burnt out, pretty recently I get minor burnt outs."}, {"time": 3006, "text": "I got a couple papers that I was trying to work through for a deadline a few weeks ago, and I wasn't sleeping well, and there's some other things going on."}, {"time": 3017, "text": "And it just knocks out and I get sick usually, is how I know I've pushed myself too far."}, {"time": 3022, "text": "And so I kind of pulled it back."}, {"time": 3023, "text": "Now I'm doing this book launch."}, {"time": 3024, "text": "Then after this book launch, I'm pulling it back again."}, {"time": 3026, "text": "So I like seasonality for rest and recovery, I think it's crucial."}, {"time": 3030, "text": "And at every scale, daily, monthly, and then at the annual scale."}, {"time": 3034, "text": "An easy summer, for example, I think is like a great idea if that's possible."}, {"time": 3038, "text": "Okay, you just made me realize that that's exactly what I do."}, {"time": 3043, "text": "Because I feel like I'm not even close to burnout or anything."}, {"time": 3046, "text": "Even though I'm in chaos, I feel the right exact way is the seasonality, is the, not even the seasonality, but like you always have multiple seasons operating."}, {"time": 3059, "text": "It's like you said, because when you have a lot of cool shit going on, there's always at least one thing that's a source of joy, that there's always a reason."}, {"time": 3068, "text": "I suppose the fundamental thing, and I've known people that suffer from depression too, the fundamental problem with the experience of depression and burnout is why do, life is meaningless."}, {"time": 3081, "text": "And I always have an answer of why today could be cool."}, {"time": 3088, "text": "And you have to contrive it, right?"}, {"time": 3089, "text": "If you don't have it, you have to contrive it."}, {"time": 3093, "text": "Like, okay, well, this is going bad, so now is the time to start thinking about, I mean, look, I started a podcast during the pandemic."}, {"time": 3099, "text": "It's like, this is going pretty bad, but you know what?"}, {"time": 3103, "text": "This could be something really interesting."}, {"time": 3106, "text": "Deep questions with Kyle Newport."}, {"time": 3109, "text": "I do it all in that voice."}, {"time": 3110, "text": "I love the podcast, by the way."}, {"time": 3113, "text": "But yeah, I think David Foster Wallace said, the key to life is to be unboreable."}, {"time": 3119, "text": "I've always kind of taken that to heart, which is like, you should be able to maybe artificially generate anything."}, {"time": 3128, "text": "Like, find something in your environment, in your surroundings, that's a source of joy."}, {"time": 3136, "text": "Like, everything is fun."}, {"time": 3138, "text": "Did you read The Pale King?"}, {"time": 3140, "text": "It goes deep on boredom."}, {"time": 3141, "text": "It's like uncomfortable."}, {"time": 3142, "text": "It's like an uncomfortable meditation on boredom."}, {"time": 3145, "text": "Like, the characters in that are just driven to the extremes of, I just bought three books on boredom the other day, so now I'm really interested in this topic."}, {"time": 3155, "text": "Because I was anxious about my book launch happening this week."}, {"time": 3158, "text": "So I was like, okay, I need something else."}, {"time": 3159, "text": "So I have this idea for, I might do it as an article first, but as a book."}, {"time": 3163, "text": "Like, okay, I need something cool to be thinking about."}, {"time": 3166, "text": "Because I was worried about, like, I don't know if the launch's gonna work, the pandemic, what's gonna happen, I don't know if it's gonna get there."}, {"time": 3172, "text": "So this is exactly what we're talking about."}, {"time": 3174, "text": "So I went out and I bought a bunch of books, and I'm beginning like a whole intellectual exploration."}, {"time": 3180, "text": "Well, I think that's one of the profound ideas in deep work that you don't expand on too much is boredom."}, {"time": 3188, "text": "Yeah, well, so deep work had a superficial idea about boredom, which was, I had this chapter called Embrace Boredom, and a very functionalist idea was basically, you have to have some boredom in your regular schedule, or your mind is gonna form a Pavlovian connection between as soon as I feel boredom, I get stimuli."}, {"time": 3208, "text": "And once it forms that connection, it's never gonna tolerate deep work."}, {"time": 3210, "text": "So there's this very pragmatic treatment of boredom of your mind better be used to the idea that sometimes you don't get stimuli because otherwise you can't write for three hours, like it's just not gonna tolerate it."}, {"time": 3221, "text": "But more recently, what I'm really interested in boredom is it as a fundamental human drive, right?"}, {"time": 3227, "text": "Because it's incredibly uncomfortable."}, {"time": 3229, "text": "And think about the other things that are incredibly uncomfortable, like hunger or thirst, they serve a really important purpose for a species, right?"}, {"time": 3236, "text": "Like if something is really distressing, there's a reason."}, {"time": 3238, "text": "Pain is really uncomfortable because we need to worry about getting injured."}, {"time": 3242, "text": "Thirst is really uncomfortable because we need water to survive."}, {"time": 3245, "text": "So what's boredom?"}, {"time": 3247, "text": "Why is that uncomfortable?"}, {"time": 3248, "text": "And I've been interested in this notion that boredom is about driving us towards productive action."}, {"time": 3257, "text": "Like as a species, I mean, think about it, like what got us to actually take advantage of these brains?"}, {"time": 3262, "text": "What got us to actually work with fire?"}, {"time": 3264, "text": "What got us to start shaping stones and the hand axes and figuring out if we could actually sharpen a stick sharp enough that we could throw it as a melee weapon or a distance weapon for hunting mammoth, right?"}, {"time": 3275, "text": "Boredom drives us towards action."}, {"time": 3277, "text": "So now I'm fascinated by this fundamental action instinct because I have this theory that I'm working on that we're out of sync with it."}, {"time": 3285, "text": "Just like we have this drive for hunger, but then we introduced junk food and got out of sync with hunger and it makes us really unhealthy."}, {"time": 3292, "text": "We have this drive towards action, but then we overload ourselves and we have all of these distractions."}, {"time": 3296, "text": "And then that causes, it's like a cognitive action obesity type things because it short circuits this system that wants us to do things, but we put more things on our plate than we can possibly do and then we're really frustrated we can't do them and we're short circuiting all of our wires."}, {"time": 3309, "text": "So it all comes back to this question, well, what would be the ideal sort of amount of stuff to do and type of things to do?"}, {"time": 3318, "text": "Like if we wanted to look back at our ancestral environment and say, if I could just build from scratch, how much work I do and what I work on to be as in touch with that as like paleo people are trying to get their diets in touch with that."}, {"time": 3330, "text": "And so now I'm just, well, see, this is, it's something I made up, but now I'm going deep on it."}, {"time": 3336, "text": "And one of my podcast listeners I was talking about on the show and I was like, well, I get trying to learn about animals and boredom."}, {"time": 3341, "text": "And she sent me this cool article from an animal behaviorist journal about what we know about human boredom versus animal boredom."}, {"time": 3348, "text": "So trying to figure out that puzzle is the wave that's high."}, {"time": 3352, "text": "So I can get through the wave that's low of like, I don't know about this pandemic book launch."}, {"time": 3355, "text": "And my research is stumbling a little bit because of the pandemic."}, {"time": 3360, "text": "And so I needed a nice, you know, high."}, {"time": 3363, "text": "So there we go, there's a case study."}, {"time": 3365, "text": "Well, it's both a case study and a very interesting set of concepts because I didn't even realize that it's so simple."}, {"time": 3372, "text": "I'm one of the people that has a interesting push and pull dynamic with hunger, trying to understand the hunger with myself."}, {"time": 3381, "text": "Like I probably have an unhealthy relationship with food."}, {"time": 3384, "text": "I don't know, but there's probably a perfect, that's a nice way to think about diet as action."}, {"time": 3392, "text": "There's probably an optimal diet response to the experience that our body's telling us, the signal that our body's sending, which is hunger."}, {"time": 3403, "text": "And in that same way, boredom is sending a signal."}, {"time": 3406, "text": "And most of our intellectual activities in this world, our creative activities, are essentially a response to that signal."}, {"time": 3416, "text": "Yeah, and think about this analogy that we have this hunger instinct that junk food short circuits, right?"}, {"time": 3423, "text": "It's like, oh, we'll satisfy that hyper palatably and it doesn't end up well."}, {"time": 3428, "text": "Now think about modern attention engineered, digitally mediated entertainment."}, {"time": 3434, "text": "We have this boredom instinct."}, {"time": 3436, "text": "Oh, we can take care of that with a hyper palatable alternative."}, {"time": 3440, "text": "Is that gonna lead to a similar problem?"}, {"time": 3442, "text": "So I've been fasting a lot lately, like I'm doing eating once a day."}, {"time": 3447, "text": "I've been doing that for over a month, just eating one meal a day and primarily meat."}, {"time": 3453, "text": "But it's very, fasting has been incredible for me, for focus, for wellbeing, for, I don't know, just for feeling good, okay?"}, {"time": 3463, "text": "We'll put on a chart what makes me feel good."}, {"time": 3465, "text": "And that fasting and eating primarily a meat based diet makes me feel really good."}, {"time": 3472, "text": "And so, but that ultimately what fasting did, I haven't fasted super long yet, like a seven day diet, which I really like to do."}, {"time": 3482, "text": "But even just fasting for a day for 24 hours gets you in touch with your, with the signal."}, {"time": 3490, "text": "Like you get to listen to your, learn to listen to your body that like, it's okay to be hungry."}, {"time": 3497, "text": "It's like a little signal that sends you stuff."}, {"time": 3499, "text": "And then I get to listen to how it responds when I put food in my body."}, {"time": 3507, "text": "Like, and I get to like, okay, cool."}, {"time": 3510, "text": "So like food is a thing that pacifies the signal."}, {"time": 3513, "text": "Like it sounds ridiculous, okay?"}, {"time": 3515, "text": "And you could do that with."}, {"time": 3516, "text": "And do different types of food."}, {"time": 3518, "text": "It feels different."}, {"time": 3519, "text": "So you learn about what your body wants."}, {"time": 3521, "text": "For some reason fasting, it's similar to the deep work, embrace boredom."}, {"time": 3527, "text": "Fasting allowed me to go into mode of listening, of trying to understand the signal that I could say, I have an unhealthy appreciation of fruit, okay?"}, {"time": 3537, "text": "I love apples and cherries."}, {"time": 3539, "text": "Like, I don't know how to moderate them."}, {"time": 3541, "text": "So if you take just same amount of calories, I don't know calories matter, but they say calories."}, {"time": 3545, "text": "2000 calories of cherries versus 2000 calories of steak."}, {"time": 3551, "text": "If I eat 2000 calories of steak, maybe just a little bit of like green beans or cauliflower, I'm going to feel really good, fulfilled, focused and happy."}, {"time": 3562, "text": "If I eat cherries, I'm going to be, I'm going to wake up behind a dumpster crying with like naked and like, it's just."}, {"time": 3569, "text": "Pits all around."}, {"time": 3570, "text": "Yeah, with everything."}, {"time": 3571, "text": "Over your face, yeah."}, {"time": 3572, "text": "And it's just like bloated, just not and unhappy."}, {"time": 3576, "text": "And also the mood swings up and down."}, {"time": 3581, "text": "And I'll be much hungrier the next day."}, {"time": 3584, "text": "Sometimes it takes a couple of days."}, {"time": 3586, "text": "But when I introduce carbs into the system, too many carbs, it starts, it's just unhealthy."}, {"time": 3593, "text": "I go into this roller coaster as opposed to a calm boat ride along the river in the Amazon or something like that."}, {"time": 3598, "text": "And so fasting was the mechanism for me to start listening to the body."}, {"time": 3603, "text": "I wonder if you can do that same kind of, I guess that's what meditation a little bit is."}, {"time": 3607, "text": "A little bit, but yeah, listen to boredom."}, {"time": 3610, "text": "But so two years ago, I had a book out called Digital Minimalism."}, {"time": 3613, "text": "And one of the things I was recommending that people do is basically a 30 day fast."}, {"time": 3618, "text": "But from digital personal entertainment, social media, online videos, anything that captures your attention and dispels boredom."}, {"time": 3626, "text": "And people were thinking like, oh, this is a detox."}, {"time": 3629, "text": "Like, I just wanna teach your body not to need the distraction, this or that."}, {"time": 3632, "text": "But it really wasn't what I was interested in."}, {"time": 3634, "text": "I wanted there to be space that you could listen to your boredom."}, {"time": 3639, "text": "Like, okay, I can't just dispel it."}, {"time": 3641, "text": "I can't just look at the screen and revel in it a little bit and start to listen to it and say, what is this really pushing me towards?"}, {"time": 3648, "text": "And you take the new stuff, the new technology off the table and sort of ask, what is this?"}, {"time": 3652, "text": "What am I craving?"}, {"time": 3653, "text": "Like, what's the activity equivalent of 2000 calories of meat with a little bit of green beans on the side?"}, {"time": 3659, "text": "And I had 1700 people go through this experiment, like spend 30 days doing this."}, {"time": 3663, "text": "And it's hard at first, but then they get used to listening to themselves and sort of seeking out, what is this really pushing me towards?"}, {"time": 3669, "text": "And it was pushing people towards connection."}, {"time": 3672, "text": "It was pushing people towards, I just wanna go be around other people."}, {"time": 3675, "text": "It was pushing people towards high quality leisure activities."}, {"time": 3679, "text": "Like I wanna go do something that's complicated."}, {"time": 3681, "text": "And it took weeks sometimes for them to get in touch with their boredom, but then it completely rewired how they thought about, what do I wanna do with my time outside of work?"}, {"time": 3690, "text": "And then the idea is when you're done with that, then it was much easier to go back and completely change your digital life because you have alternatives, right?"}, {"time": 3697, "text": "You're not just trying to abstain from things you don't like, but that's basically a listening to boredom experiment."}, {"time": 3702, "text": "Like just be there with the boredom and see where it drives you when you don't have the digital Cheez Its."}, {"time": 3708, "text": "Okay, so if I can't do that, where is it gonna drive me?"}, {"time": 3711, "text": "Well, I guess I kinda wanna go to the library, which came up a lot, by the way, a lot of people rediscovered the library."}, {"time": 3717, "text": "With physical books."}, {"time": 3718, "text": "Physical books, so like you can just go borrow them."}, {"time": 3720, "text": "And there's like low pressure and you can explore and you bring them home and then you read them and you can like sit by the window and read them and it's nice weather outside."}, {"time": 3727, "text": "And I used to do that 20 years ago, they're listening to boredom."}, {"time": 3730, "text": "So can you maybe elaborate a little bit on the different experiences that people had when they quit social media for 30 days?"}, {"time": 3737, "text": "Like if you were to recommend that process, what is ultimately the goal?"}, {"time": 3742, "text": "Yeah, digital minimalism, that's my philosophy for all this tech."}, {"time": 3747, "text": "And it's working backwards from what's important."}, {"time": 3750, "text": "So it's you figure out what you're actually all about, like what you wanna do, what you wanna spend your time doing."}, {"time": 3755, "text": "And then you can ask, okay, is there a place that tech could amplify or support some of these things?"}, {"time": 3760, "text": "And that's how you decide what tech to use."}, {"time": 3762, "text": "And so the process is, let's actually get away from everything, let's be bored for a while, let's really spend a month getting really figuring out what do I actually wanna do?"}, {"time": 3770, "text": "What do I wanna spend my time doing?"}, {"time": 3772, "text": "What's important to me?"}, {"time": 3773, "text": "What makes me feel good?"}, {"time": 3774, "text": "And then when you're done, you can bring back in tech very strategically to help those things, right?"}, {"time": 3778, "text": "And that was the goal."}, {"time": 3779, "text": "That turns out to be much more successful than when people take a abstention only approach."}, {"time": 3785, "text": "So if you come out your tech life and say, you know, whatever, I look at Instagram too much."}, {"time": 3790, "text": "Like I don't like how much I'm on Instagram, that's a bad thing."}, {"time": 3793, "text": "I wanna reduce this bad thing."}, {"time": 3795, "text": "So here's my new thing, I'm gonna spend less time looking at Instagram, much less likely to succeed in the longterm."}, {"time": 3800, "text": "So we're much less likely at trying to reduce this sort of amorphous negative because in the moment you're like, yeah, but it's not that bad and it would be kind of interesting to look at it now."}, {"time": 3809, "text": "When you're instead controlling behavior because you have a positive that you're aiming towards, it's very powerful for people."}, {"time": 3813, "text": "Like I want my life to be like this, here's the role that tech plays in that life."}, {"time": 3819, "text": "The connection to wanting your life to be like that is very, very strong."}, {"time": 3822, "text": "And then it's much, much easier to say, yeah, like using Instagram is not part of my plan for how I have that life."}, {"time": 3826, "text": "And I really wanna have that life, so of course I'm not gonna use Instagram."}, {"time": 3829, "text": "So it turns out to be a much more sustainable way to tame what's going on."}, {"time": 3833, "text": "So if you quit social media for 30 days, you kinda have to do the work."}, {"time": 3838, "text": "You have to do the work."}, {"time": 3839, "text": "Of thinking like, what am I actually, what makes me happy in terms of these tools that I've previously used and when you try to integrate them back, how can I integrate them to maximize the thing that actually makes me happy?"}, {"time": 3851, "text": "Yeah, or what makes me happy unrelated to technology?"}, {"time": 3854, "text": "Like what do I actually, what do I want my life to be like?"}, {"time": 3856, "text": "Well, maybe what I wanna do is be like outside of nature two hours a day and spend a lot more time like helping my community and sacrificing on behalf of my connections and then have some sort of intellectually engaging leisure activity like I'm reading or trying to read the great books and having more calm and seeing the sunset."}, {"time": 3871, "text": "Like you create this picture and then you go back and say, well, I still need my Facebook group because that's how I keep up with my cycling group."}, {"time": 3879, "text": "But Twitter is just, you know, toxic, it's not helping any of these things."}, {"time": 3882, "text": "And well, I'm an artist, so I kinda need Instagram to get inspiration."}, {"time": 3886, "text": "But if I know that's why I'm using Instagram, I don't need it on my phone, it's just on my computer and I just follow 10 artists and check it once a week."}, {"time": 3891, "text": "Like you really can start deploying."}, {"time": 3894, "text": "It was the number one thing that differentiated in that experiment, the people who ended up sustainably making changes and getting through the 30 days and those who didn't, was the people who did the experimentation and the reflection."}, {"time": 3904, "text": "Like let me try to figure out what's positive."}, {"time": 3907, "text": "They were much more successful than the people that just said, I'm sick of using my phone so much."}, {"time": 3911, "text": "So I'm just gonna white knuckle it."}, {"time": 3912, "text": "Just 30 days will be good for me."}, {"time": 3914, "text": "I just gotta get away from it or something."}, {"time": 3916, "text": "It doesn't last."}, {"time": 3917, "text": "So you don't use social media currently."}, {"time": 3921, "text": "Do you find that a lot of people going through this process will seek to basically arrive at a similar place to not use social media primarily?"}, {"time": 3930, "text": "About half."}, {"time": 3932, "text": "Right, so about half when they went through this exercise, and these aren't quantified numbers."}, {"time": 3936, "text": "This is just, they sent me reports and yeah."}, {"time": 3940, "text": "That's pretty good though, 1700?"}, {"time": 3942, "text": "So roughly half probably got rid of social media altogether."}, {"time": 3947, "text": "Once they did this exercise, they realized these things I care about, I don't, social media's not the tools that's really helping."}, {"time": 3953, "text": "The other half kept some, there were some things in their life where some social media was useful."}, {"time": 3959, "text": "But the key thing is if they knew why they were deploying social media, they could put fences around it."}, {"time": 3964, "text": "So for example, of those half that kept some social media, almost none of them kept it on their phone."}, {"time": 3970, "text": "Yeah, you can't optimize if you don't know what the function you're trying to optimize."}, {"time": 3973, "text": "So it's like this huge hack."}, {"time": 3974, "text": "Like once you know this is why I'm using Twitter, then you can have a lot of rules about how you use Twitter."}, {"time": 3979, "text": "And suddenly you take this cost benefit ratio and it goes like way from the company's advantage and then way over towards your advantage."}, {"time": 3985, "text": "It's kind of fascinating because I've been torn with social media, but I did this kind of process."}, {"time": 3990, "text": "I haven't actually done it for 30 days, which I probably should."}, {"time": 3993, "text": "I'll do it for like a week at a time and regularly and thinking what kind of approach to Twitter works for me."}, {"time": 4003, "text": "I'm distinctly aware of the fact that I really enjoy posting once or twice a day."}, {"time": 4011, "text": "And at that time checking from the previous post, it makes me feel even when there's like negative comments, they go right past me."}, {"time": 4021, "text": "And when there's positive comments, it makes you smile."}, {"time": 4023, "text": "I feel like love and connection with people, especially with people I know, but even just in general, it's like, it makes me feel like the world is full of awesome people."}, {"time": 4032, "text": "Okay, when you increase that from checking from two to like, I don't know what the threshold is for me, but probably like five or six per day, it starts going to anxiety world."}, {"time": 4041, "text": "Like where negative comments will actually stick to me mentally and positive comments will feel more shallow."}, {"time": 4054, "text": "So I've been trying to, there's been long stretches of time, I think December and January where I did just post and check, post and check."}, {"time": 4066, "text": "That makes me really happy."}, {"time": 4069, "text": "Most of 2020 I did that, it made me really happy."}, {"time": 4072, "text": "Recently I started like, I'll go, you go right back in like a drug addict, where you check it like, I don't know what that number is, but that number is high."}, {"time": 4081, "text": "Not good, you don't come out happy."}, {"time": 4083, "text": "No one comes out of a day full of Twitter celebrating humanity."}, {"time": 4087, "text": "And it's not even, cause I'm very fortunate to have a lot of just positivity in the Twitter, but there's just a general anxiety."}, {"time": 4096, "text": "I wouldn't even say it's, it's probably the thing that you're talking about with the contact switching."}, {"time": 4102, "text": "It's almost like an exhaustion."}, {"time": 4105, "text": "I wouldn't even say it's like a negative feeling."}, {"time": 4107, "text": "It's almost just an exhaustion to where I'm not creating anything beautiful in my life, just exhausted."}, {"time": 4113, "text": "Like an existential exhaustion."}, {"time": 4115, "text": "Existential exhaustion."}, {"time": 4116, "text": "But I wonder, do you think it's possible to use from the people you've seen from yourself to use social media in the way I'm describing moderation?"}, {"time": 4125, "text": "Or is it always going to become?"}, {"time": 4128, "text": "When people do this exercise, you get lots of configurations."}, {"time": 4132, "text": "So for people that have a public presence, for example, like what you're doing is not that unusual."}, {"time": 4138, "text": "Okay, I post one thing a day and my audience likes it and that's kind of it."}, {"time": 4144, "text": "But you've thought through like, okay, this supports something I value, which is like having a sort of informal connection with my audience and being exposed to some sort of positive randomness."}, {"time": 4155, "text": "Okay, then you could say if that's my goal, what's the right way to do it?"}, {"time": 4159, "text": "Well, I don't need to be on Twitter on my phone all day."}, {"time": 4160, "text": "Maybe what I do is every day at five, I do my post and check on the day."}, {"time": 4165, "text": "So I have a writer friend, Ryan Holiday, who writes about the Stoics a lot."}, {"time": 4170, "text": "And he has this similar strategy."}, {"time": 4172, "text": "He posts one quote every day usually from a famous Stoic and sometimes from a contemporary figure."}, {"time": 4177, "text": "And that's just what he does."}, {"time": 4178, "text": "He just posts it and it's a very positive thing."}, {"time": 4181, "text": "Like his readers really love it because it's just like a dose of inspiration."}, {"time": 4184, "text": "He doesn't spend time."}, {"time": 4186, "text": "He's never interacting with anyone on social media, right?"}, {"time": 4188, "text": "But that's an example of I figured out what's important to me, what's the best way to use tools to amplify it."}, {"time": 4194, "text": "And then you get advantages out of the tools."}, {"time": 4196, "text": "So I like what you're doing."}, {"time": 4197, "text": "I looked you up, I looked up your Twitter feed before I came over here."}, {"time": 4200, "text": "I was curious, you're not on there a lot."}, {"time": 4202, "text": "I don't see you yelling at people."}, {"time": 4204, "text": "Now, do you think social media as a medium changed the cultural standards?"}, {"time": 4209, "text": "And I mean it in a, have you read Neil Postman at all?"}, {"time": 4211, "text": "Have you read like a Amusing Ourselves to Death?"}, {"time": 4214, "text": "He was a social critic, technology critic and wrote a lot about sort of technological determinism."}, {"time": 4219, "text": "So the ways, which is a really influential idea to a lot of my work, which is actually a little out of fashion right now in academia."}, {"time": 4225, "text": "But the ways that the properties and presence of technologies change things about humans in a way that's not really intended or planned by the humans themselves."}, {"time": 4233, "text": "And that book is all about how different communication medium, like fundamentally just changed the way the human brain understands and operates."}, {"time": 4242, "text": "And so he sort of gets into the, what happened when the printed word was widespread and how television changed it."}, {"time": 4247, "text": "And this was all pre social media."}, {"time": 4249, "text": "But this is one of these ideas I'm having is like what's the degree to which, and I get into it sometimes on my show, I get into a little bit, like the degree to which like Twitter in particular just changed the way that people conceptualized what for example, debate and discussion was."}, {"time": 4263, "text": "Like it introduced a rhetorical dunk culture where it's sort of more about tribes not giving ground to other tribes."}, {"time": 4270, "text": "And it's like, it's a complete, there's different places and times when that type of discussion was thought of differently."}, {"time": 4277, "text": "Well, yeah, absolutely."}, {"time": 4279, "text": "But I tend to believe, I don't know what you think, that there's the technological solutions."}, {"time": 4283, "text": "Like there's literally different features in Twitter that could completely reverse that."}, {"time": 4289, "text": "There's so much power in the different choices that are made."}, {"time": 4293, "text": "And it could still be highly engaging and have very different effects."}, {"time": 4297, "text": "Perhaps more negative or hopefully more positive."}, {"time": 4300, "text": "Yeah, so I'm trying to pull these two things apart."}, {"time": 4302, "text": "So there's these two ways social media, let's say could change the experience of reading a major newspaper today."}, {"time": 4309, "text": "One could be a little bit more economic, right?"}, {"time": 4310, "text": "So the internet made it cheaper to get news."}, {"time": 4313, "text": "The newspapers had to retreat to a paywall model because it was the only way they were gonna survive."}, {"time": 4316, "text": "But once you're in a paywall model, then what you really wanna do is make your tribe, which is within the paywall, very, very happy with you."}, {"time": 4323, "text": "So you wanna work to them."}, {"time": 4324, "text": "But then there's the sort of determinist point of view, which is the properties of Twitter, which were arbitrary."}, {"time": 4330, "text": "Jack and Evan just, whatever, let's just do it this way."}, {"time": 4333, "text": "Influenced the very way that people now understand and think about the world."}, {"time": 4336, "text": "So the one influenced the other, I think."}, {"time": 4339, "text": "They kind of started adjusting together."}, {"time": 4341, "text": "I did this thing, I mean, I'm trying to understand this."}, {"time": 4345, "text": "Part of the, I've been playing with the entrepreneurial idea."}, {"time": 4350, "text": "That's a very particular dream I've had of a startup."}, {"time": 4354, "text": "That this is a longer term thing, it has to do with artificial intelligence."}, {"time": 4359, "text": "But more and more, it seems like there's some trajectory through creating social media type of technologies."}, {"time": 4367, "text": "Very different than what people are thinking I'm doing."}, {"time": 4369, "text": "But it's a kind of challenge to the way the Twitter is done."}, {"time": 4375, "text": "But it's not obvious what the best mechanisms are to still make an exceptionally engaging platform."}, {"time": 4381, "text": "My clubhouse is very engaging."}, {"time": 4383, "text": "And not have any other negative effects."}, {"time": 4386, "text": "For example, there's Chrome extensions that allow you to turn off all likes and dislikes and all of that from Twitter."}, {"time": 4394, "text": "So all you're seeing is just the content."}, {"time": 4398, "text": "On Twitter, that to me creates, that's not a compelling experience at all."}, {"time": 4403, "text": "Because I still need, I would argue, I still need the likes to know what's a tweet worth reading."}, {"time": 4410, "text": "Because I don't only have a limited amount of time, so I need to know what's valuable."}, {"time": 4414, "text": "It's like great Yelp reviews on tweets or something."}, {"time": 4416, "text": "But I've turned off on, for example, on my account on YouTube, I wrote a Chrome extension that turns off all likes and dislikes and just views."}, {"time": 4430, "text": "I don't know how many views the video gets and so on."}, {"time": 4433, "text": "Unless it's on my phone."}, {"time": 4433, "text": "Did you take off the recommendations?"}, {"time": 4438, "text": "On YouTube, some people, distraction for YouTube is a big one for people."}, {"time": 4442, "text": "No, I'm not worried about the distraction because I'm able to control myself on YouTube."}, {"time": 4446, "text": "You don't rabbit hole."}, {"time": 4447, "text": "No, I don't rabbit hole."}, {"time": 4449, "text": "So you have to know your demons or your addictions or whatever."}, {"time": 4452, "text": "On YouTube, I'm okay."}, {"time": 4453, "text": "I don't keep clicking."}, {"time": 4454, "text": "The negative feelings come from seeing the views on stuff you've created."}, {"time": 4462, "text": "Oh, so you don't want to see your views."}, {"time": 4464, "text": "So I'm just speaking to the things that I'm aware of of myself that are helpful and things that are not helpful emotionally."}, {"time": 4471, "text": "And I feel like there should be, we need to create actually tooling for ourselves."}, {"time": 4477, "text": "That's not me with JavaScript, but anybody is able to create, sort of control the experience that they have."}, {"time": 4485, "text": "Well, so my big unified theory on social media is I'm very bearish on the big platforms having a long future."}, {"time": 4494, "text": "I think the moment of three or four major platforms is not gonna last, right?"}, {"time": 4503, "text": "This is just perspective, right?"}, {"time": 4503, "text": "So you can start shorting these stocks on my, don't tell."}, {"time": 4507, "text": "It's not financial advice."}, {"time": 4510, "text": "Don't do it Robinhood."}, {"time": 4511, "text": "So here's, I think the big mistake the major platforms made as when they took out the network effect advantage, right?"}, {"time": 4519, "text": "So the original pitch, especially if something like Facebook or Instagram was the people you know are on here, right?"}, {"time": 4526, "text": "So like what you use this for is you can connect to people that you already know."}, {"time": 4529, "text": "This is what makes the network useful."}, {"time": 4531, "text": "So therefore the value of our network grows quadratically with the number of users."}, {"time": 4535, "text": "And therefore it's such a headstart that there's no way that someone else can catch up."}, {"time": 4540, "text": "But when they shifted and when Facebook took the lead of say we're gonna shift towards a newsfeed model, they basically said we're going to try to in the moment get more data and get more likes."}, {"time": 4550, "text": "Like what we're gonna go towards is actually just seeing interesting stuff."}, {"time": 4554, "text": "Like seeing different information."}, {"time": 4555, "text": "So people took this social internet impulse to connect to people digitally, to other tools like group text messages and WhatsApp and stuff like this, right?"}, {"time": 4563, "text": "So you don't think about these tools as oh, this is where I connect with people."}, {"time": 4566, "text": "Once it's just a feed that's kind of interesting, now you're competing with everything else that can produce interesting content that's diverting."}, {"time": 4573, "text": "And I think that is a much fiercer competition because now for example, you're going up against podcasts, right?"}, {"time": 4579, "text": "I mean like, okay, I guess the Twitter feed is interesting right now, but also a podcast is interesting or something else could be interesting too."}, {"time": 4585, "text": "I think it's a much fiercer competition when there's no more network effects, right?"}, {"time": 4589, "text": "And so my sense is we're gonna see a fragmentation into what I call long tail social media, where if I don't need everyone I know to be on a platform, then why not have three or four bespoke platforms I use where it's a thousand people and we're all interested in whatever, AI or comedy."}, {"time": 4607, "text": "And we've perfected this interface and maybe it's like Clubhouse, it's audio or something."}, {"time": 4612, "text": "And we all pay $2 so that we don't have to worry about attention harvesting."}, {"time": 4615, "text": "And that's gonna be wildly more entertaining."}, {"time": 4617, "text": "Like, I mean, I'm thinking about comedians on Twitter."}, {"time": 4620, "text": "It's not the best internet possible format for them expressing themselves and being interesting."}, {"time": 4626, "text": "That you have all these comedians that are trying to like, well, I can do like little clips and little whatever."}, {"time": 4630, "text": "Like, I don't know if there was a long tail social media."}, {"time": 4633, "text": "I mean, it's really, this is where the comedians are and there's podcasts and the comedians are on podcasts now."}, {"time": 4636, "text": "So this is my thought is that there's really no, there's really no strong advantage to having one large platform that everyone is on."}, {"time": 4645, "text": "If all you're getting from it is, I now have different options for diversion and like uplifting aspirational or whatever types of entertainment, that whole thing could fragment."}, {"time": 4654, "text": "And I think the glue that was holding together was network effects."}, {"time": 4656, "text": "I don't think they realized that when network effects have been destabilized, they don't have the centrifugal force anymore and they're spinning faster and faster."}, {"time": 4663, "text": "But is a Twitter feed really that much more interesting than all of these streaming services?"}, {"time": 4668, "text": "Is it really that much more interesting than Clubhouse, is it that much more interesting than podcast?"}, {"time": 4674, "text": "I feel like they don't realize how unstable their ground actually is."}, {"time": 4678, "text": "But the thing that makes Twitter and Facebook work, I mean, the newsfeed, you're exactly right."}, {"time": 4687, "text": "Like you can just duplicate the news."}, {"time": 4688, "text": "Like if it's not the social network and it's the newsfeed, then why not have multiple different feeds that are more, that are better at satisfying."}, {"time": 4697, "text": "There's a dopamine gamification that they've figured out."}, {"time": 4701, "text": "And so you have to, whatever you create, you have to at least provide some pleasure in that same gamification kind of way."}, {"time": 4709, "text": "It doesn't have to have to do with scale of large social networks."}, {"time": 4713, "text": "But I mean, I guess you're implying that you should be able to design that kind of mechanism in other forms."}, {"time": 4720, "text": "Or people are turning on that gamification."}, {"time": 4722, "text": "I mean, so people are getting wise to it and are getting uncomfortable about it, right?"}, {"time": 4726, "text": "So if I'm offering something, these exist out here."}, {"time": 4729, "text": "Like sugar."}, {"time": 4729, "text": "People realize sugar's bad for you."}, {"time": 4730, "text": "Yeah, sugar's great."}, {"time": 4731, "text": "They're gonna stop eating it."}, {"time": 4732, "text": "Yeah, drinking a lot's great too, but also after a while you realize there's problems."}, {"time": 4736, "text": "So some of the long tail social media networks that are out there that I've looked at, they offer usually like a deeper sense of connection."}, {"time": 4742, "text": "Like it's usually interesting people that you share some affinity and you have these carefully cultivated."}, {"time": 4748, "text": "I wrote this New Yorker piece a couple of years ago about the indie social media movement that really got into some of these different technologies."}, {"time": 4754, "text": "But I think the technologies are a distraction."}, {"time": 4757, "text": "We focus too much on Macedon versus whatever."}, {"time": 4760, "text": "Like forget, or Discord."}, {"time": 4761, "text": "Like actually let's forget the protocols right now."}, {"time": 4763, "text": "It's the idea of, okay."}, {"time": 4766, "text": "And there's a lot of these long tail social media groups, what people are getting out of it, which I think can outweigh the dopamine gamification is strong connection and motivation."}, {"time": 4775, "text": "Like you're in a group with other guys that are all trying to be better dads or something like this."}, {"time": 4780, "text": "And you talk to them on a regular basis and you're sharing your stories and there's interesting talks."}, {"time": 4785, "text": "And that's a powerful thing too."}, {"time": 4787, "text": "One interesting thing about scale of Twitter is you have these viral spread of information."}, {"time": 4793, "text": "So sort of Twitter has become a newsmaker in itself."}, {"time": 4797, "text": "Yeah, I think it's a problem."}, {"time": 4798, "text": "Well, yes, but I wonder what replaces that because then you immediately."}, {"time": 4803, "text": "Reporting?"}, {"time": 4805, "text": "Reporters have to do some work again, I don't know."}, {"time": 4807, "text": "The problem with reporters and journalism is that they're intermediary."}, {"time": 4812, "text": "They have control."}, {"time": 4814, "text": "I mean, this is the problem in Russia currently is that it creates a shield between the people and the news."}, {"time": 4822, "text": "The interesting thing and the powerful thing about Twitter is that the news originates from the individual that's creating the news."}, {"time": 4829, "text": "Like you have the former president of the United States on Twitter creating news."}, {"time": 4834, "text": "You have Elon Musk creating news."}, {"time": 4836, "text": "You have people announcing stuff on Twitter as opposed to talking to a journalist."}, {"time": 4841, "text": "And that feels much more genuine and it feels very powerful, but actually coming to realize it doesn't need the social network."}, {"time": 4853, "text": "You can just put that announcement on a YouTube type thing."}, {"time": 4856, "text": "This is what I'm thinking."}, {"time": 4856, "text": "Right, so this is my point about that because that's right."}, {"time": 4859, "text": "The democratizing power of the internet is fantastic."}, {"time": 4861, "text": "I mean, I'm an old school internet nerd, a guy that was telemeting in the servers and gophering before the World Wide Web was around, right?"}, {"time": 4868, "text": "So I'm a huge internet booster."}, {"time": 4870, "text": "And that's one of its big power."}, {"time": 4872, "text": "But when you put everything on Twitter, I think the fact that you've taken, you homogenized everything, right?"}, {"time": 4878, "text": "So everything looks the same, moves with the same low friction is very difficult."}, {"time": 4882, "text": "You have no what I call distributed curation, right?"}, {"time": 4885, "text": "The only curation that really happens, there's a little bit with likes and also the algorithm."}, {"time": 4916, "text": "So if you think like the 2004 presidential election, most of the information people are getting from the internet was one of the first big internet news driven elections was from, you had like the daily costs and drudge, but there was like blogs that were out there and this was back, Ezra Klein was just running a blog out of his dorm room at this point, right?"}, {"time": 4975, "text": "So everything you've said up until the very last statement, I would agree with."}, {"time": 4981, "text": "This is a topic I don't know a ton about, I guess, QAnon."}, {"time": 4983, "text": "There's, I think, I'll forget QAnon."}, {"time": 4987, "text": "Yeah, no, we can."}, {"time": 4988, "text": "But QAnon is, QAnon could be that, I also don't know, I should know more, I apologize, I don't know more."}, {"time": 4993, "text": "I mean, that's a power and the downside, you can have, I mean, Hitler could have a blog today and you would have potentially a very large following if he's charismatic, if he's as good with words, is able to express the ideas, whatever maybe he's able to channel, the frustration, the anger that people have about a certain thing."}, {"time": 5014, "text": "And so I think that's the power of blogs, but it's also the limitation, but that doesn't, we're not trying to solve that."}, {"time": 5020, "text": "You can't solve that, yeah."}, {"time": 5021, "text": "The fundamental problem you're saying is not the problem."}, {"time": 5025, "text": "Your thesis is that there's nothing special about large scale social networks that guarantees that they will keep existing."}, {"time": 5033, "text": "And it's important to remember for a lot of the older generation of internet activists or the people who are very pro internet in the early days, they were completely flabbergasted by the rise of these platforms."}, {"time": 5045, "text": "Say, why would you take the internet and then build your own version of the internet where you own all the servers?"}, {"time": 5052, "text": "And we built this whole distributed, the whole thing, we had open protocols."}, {"time": 5056, "text": "Everyone anywhere in the world could use the same protocols."}, {"time": 5058, "text": "Your machine can talk to any other machine."}, {"time": 5060, "text": "It's the most democratic communication system that's ever been built."}, {"time": 5064, "text": "And then these companies came along and said, we're gonna build our own, we'll just own all the servers and put them in buildings that we own."}, {"time": 5069, "text": "And the internet will just be the first mile that gets you into our private internet where we owned the whole thing."}, {"time": 5073, "text": "It went completely against the entire motivation of the internet was like, yes, it's not gonna be one person owns all the servers and you pay to access them."}, {"time": 5082, "text": "It's any one server that they own could talk to anyone else's server because we all agree on a standard set of protocols."}, {"time": 5088, "text": "And so the old guard of pro internet people never understood this move towards let's build private versions of the internet."}, {"time": 5097, "text": "We'll build three or four private internets and that's what we'll all use."}, {"time": 5100, "text": "It was the opposite basically."}, {"time": 5101, "text": "Well, it's funny enough, I don't know if you follow, but Jack Dorsey is also as a proponent and is helping to fund, create fully distributed versions of Twitter, essentially, I think that would potentially destroy Twitter."}, {"time": 5115, "text": "But I think there might be financial, like business cases to be made there, I'm not sure."}, {"time": 5121, "text": "But that seems to be another alternative as opposed to creating a bunch of like the long tail, creating like the ultimate long tail of like fully distributed."}, {"time": 5133, "text": "Yeah, which is what the internet is."}, {"time": 5135, "text": "But that's sort of my long, when I'm thinking about long tail social media, I'm thinking it's like the tech's not so important."}, {"time": 5140, "text": "Like there's groups out there, right?"}, {"time": 5142, "text": "I know where the tech they use to actually implement their digital only social group, whatever, they might use Slack, they might use some combination of Zoom or it doesn't matter."}, {"time": 5151, "text": "I think in the tech world, we wanna build the beautiful protocol that okay, everyone's gonna use as just a federated server protocol in which we've worked out X, Y, and Z, and no one understands it because then the engineers need it all to make, I get it because I'm a nerd like this, like, okay, every standard has to fit with everything else and no one understands what's going on."}, {"time": 5167, "text": "Meanwhile, you have this group of bike enthusiasts that are like, yeah, we'll just jump on to Zoom and have some Slack and put up a blog."}, {"time": 5174, "text": "The tech doesn't really matter."}, {"time": 5175, "text": "Like we built a world with our own curation, our own rules, our own sort of social ecosystem that's generating a lot of value."}, {"time": 5183, "text": "I mean, I don't know if it'll happen."}, {"time": 5184, "text": "There's a lot of money at stake with obviously these large, but I just think they're more, they're so, I mean, look how quickly Americans left Facebook, right?"}, {"time": 5193, "text": "I mean, Facebook was savvy to buy other properties and to diversify, right?"}, {"time": 5196, "text": "But how quick did that take for just standard Facebook news feed?"}, {"time": 5200, "text": "Everyone under the age of something were using it and no one under a certain age is using it now."}, {"time": 5204, "text": "It took like four years."}, {"time": 5205, "text": "I mean, this stuff is really."}, {"time": 5207, "text": "I believe people can leave Facebook overnight."}, {"time": 5211, "text": "Like I think Facebook hasn't actually messed up like enough to, there's two things."}, {"time": 5217, "text": "They haven't messed up enough for people to really leave aggressively and there's no good alternative for them to leave."}, {"time": 5223, "text": "I think if good alternatives pop up, it would just immediately happen."}, {"time": 5227, "text": "The stuff is a lot more culturally fragile, I think."}, {"time": 5230, "text": "I mean, Twitter's having a moment because it was feeding a certain type of, I mean, there's a lot of anxieties that was in the sort of political sphere anyways that Twitter was working with, but its moment could go to as well."}, {"time": 5241, "text": "I mean, it's a really arbitrary thing."}, {"time": 5243, "text": "Short little things."}, {"time": 5244, "text": "I read a Wired article about this earlier in the pandemic."}, {"time": 5247, "text": "This is crazy that the way that we're trying to communicate information about the pandemic is all these weird arbitrary rules where people are screenshotting pictures of articles that are part of a tweet thread where you say one slash in under it."}, {"time": 5260, "text": "We have the technology guys to really clearly convey long form information to people."}, {"time": 5267, "text": "Why do we have these?"}, {"time": 5268, "text": "And I know this because it's the gamified dopamine hits, but what a weird medium."}, {"time": 5272, "text": "There's no reason for us to have to have these threads that you have to find and pin with your screenshot."}, {"time": 5277, "text": "I mean, we have technology to communicate better using the internet."}, {"time": 5280, "text": "I mean, why are epidemiologists having to do tweet threads?"}, {"time": 5285, "text": "Because there's mechanisms of publishing that make it easier on Twitter."}, {"time": 5288, "text": "I mean, we're evolving as a species and the internet is a very fresh thing."}, {"time": 5292, "text": "And so it's kind of interesting to think that as opposed to Twitter, this is what Jack also complains about is Twitter's not innovating fast enough."}, {"time": 5303, "text": "And so it's almost like the people are innovating and thinking about their productive life faster than the platforms on which they operate can catch up."}, {"time": 5313, "text": "And so at the point the gap grows sufficiently, they'll jump."}, {"time": 5318, "text": "A few people, a few innovative folks will just create an alternative and perhaps distributed perhaps just many little silos and then people will jump and then we'll just continue this kind of way."}, {"time": 5330, "text": "Yeah, but see, I think like Substack, for example, what they're gonna pull out of Twitter, among other things, is the audience that was, let's say, like slightly left of center, but slightly left of center, don't like Trump, uncomfortable with like postmodern critical theories made into political action, right?"}, {"time": 5347, "text": "And they're like, yeah, Twitter, there was people on there talking about this and it made me feel sort of hurt because I was feeling a little bit like a nerd about it."}, {"time": 5354, "text": "But honestly, I'd probably rather subscribe to the four subs, you know, I'm gonna have like Barry's and Andrew Sullivan's, I'll have like a Jesse Signals, like I'll have a few substacks I can subscribe to and honestly, I'm a knowledge worker who's 32 anyways, probably that's an email all day."}, {"time": 5368, "text": "And so like, there's an innovation that's gonna, that group, you know, it's gonna suck them off."}, {"time": 5372, "text": "Which is actually a very large group."}, {"time": 5374, "text": "Yeah, that's a lot of energy."}, {"time": 5376, "text": "And then once Trump's gone, I guess that's probably gonna drive, that drove a lot of more like Trump people off Twitter."}, {"time": 5382, "text": "Like this stuff is fragile, I think."}, {"time": 5384, "text": "I, but the fascinating thing to me, because I've hung out on Parler for a short amount enough to know that the interface matters."}, {"time": 5392, "text": "It's so fascinating like that, that it's not just about ideas."}, {"time": 5397, "text": "It's about creating like Substack 2, creating a pleasant experience, a dicting experience."}, {"time": 5404, "text": "No, you're right, you're right about that."}, {"time": 5406, "text": "And it's why the, this is one of the conclusions from that indie social media article is it's just the ugliness matters."}, {"time": 5412, "text": "And I don't mean even just aesthetically, it's just the clunkiness of the interfaces."}, {"time": 5417, "text": "And I don't know, it's, to some degree, the social media companies have spent a lot of money on this."}, {"time": 5421, "text": "And to some degree, it's a survivorship bias, right?"}, {"time": 5424, "text": "I think Twitter, every time I hear Jack talks about this, it seems like he's as surprised as anyone else, the way Twitter is being used."}, {"time": 5431, "text": "I mean, it's basically the way, you know, they had it years ago."}, {"time": 5436, "text": "And then, you know, it was like, great, there'll be statuses, right?"}, {"time": 5439, "text": "This is what I'm doing, you know?"}, {"time": 5441, "text": "And my friends can follow me and see it."}, {"time": 5442, "text": "Without really changing anything, it just happened to hit everything right to support this other type of interaction."}, {"time": 5447, "text": "Well, there's also the JavaScript model, which Brendan Eich talked about."}, {"time": 5451, "text": "He just implemented JavaScript, like the crappy version of JavaScript in 10 days, threw it out there and just changed it really quickly, evolved it really quickly."}, {"time": 5461, "text": "And now it's become, according to Stack Exchange, the most popular programming language in the world that drives like most of the internet and even the backend and now mobile."}, {"time": 5470, "text": "And so that's an argument for the kind of thing you're talking about where like the bike club people could literally create the thing that would, you know, run most of the internet in 10 years from now."}, {"time": 5485, "text": "So there's something to that, like as opposed to trying to get lucky or trying to think through stuff is just to solve a particular problem."}, {"time": 5493, "text": "Do stuff, yeah."}, {"time": 5494, "text": "And then do stuff."}, {"time": 5495, "text": "Do stuff, keep tinkering until you love it."}, {"time": 5497, "text": "And then, and of course the sad thing is timing and luck matter and that you can't really control."}, {"time": 5505, "text": "But you can't go back to 2007."}, {"time": 5508, "text": "That's like the number one thing you could do to have a lot of success with a new platform is go back in time 14 years."}, {"time": 5513, "text": "So the thing you have to kind of think about is what is the like, what's the totally new thing that 10 years from now would seem obvious."}, {"time": 5523, "text": "I mean, some people saying clubhouses that, there's been a lot of stuff like clubhouse before, but it hit the right kind of thing."}, {"time": 5532, "text": "Similar to Tesla actually, what clubhouse did is it got a lot of relatively famous people on there quickly."}, {"time": 5539, "text": "And then the other effect is like, it's invite only."}, {"time": 5544, "text": "So like, oh, all the smart, like famous people are on there."}, {"time": 5547, "text": "I wonder what's, it's the FOMO, like fear that you're missing something really profound as exciting happening there."}, {"time": 5554, "text": "So those social effects."}, {"time": 5556, "text": "And then once they actually show up, I'm a huge fan of this."}, {"time": 5560, "text": "It's the JavaScript model is like, clubhouse is so dumb, like so simple in its interface."}, {"time": 5566, "text": "Like you literally can't do anything except mute, unmute."}, {"time": 5570, "text": "There's a mute button."}, {"time": 5572, "text": "And there's a leave quietly button."}, {"time": 5575, "text": "And it's kinda."}, {"time": 5576, "text": "I love single use technology that sense, yeah."}, {"time": 5579, "text": "There's no like, there's no, it's just like trivial."}, {"time": 5584, "text": "And Twitter kinda started like that."}, {"time": 5588, "text": "Facebook started like that."}, {"time": 5590, "text": "But they've evolved quickly to add all these features and so on."}, {"time": 5593, "text": "And I do hope clubhouse stays that way."}, {"time": 5597, "text": "Or there's alternatives."}, {"time": 5598, "text": "I mean, even with clubhouse though, so one of the issues with a lot of these platforms I think is bits are cheap enough now that we don't really need a unicorn investor model."}, {"time": 5610, "text": "I mean, the investors need that model."}, {"time": 5612, "text": "There's really not really an imperative of we need something that can scale to a hundred million plus a year revenue."}, {"time": 5622, "text": "So, because it was gonna require this much seed and angel investment, and you're not gonna get this much seed angel investment unless you can have a potential exit this wide because you have to be part of a portfolio that depends on one out of 10 exiting here."}, {"time": 5635, "text": "If you don't actually need that and you don't need to satisfy that investor model, which I think is basically the case."}, {"time": 5641, "text": "I mean, bits are so cheap."}, {"time": 5642, "text": "Everything is so cheap."}, {"time": 5644, "text": "So even like with clubhouse, it's investor backed, right?"}, {"time": 5647, "text": "This notion of like, this needs to be a major platform, but the bike club doesn't necessarily need a major platform."}, {"time": 5654, "text": "That's where I'm interested."}, {"time": 5655, "text": "There's so much money."}, {"time": 5656, "text": "That's the only problem that bets against me is that you can concentrate a lot of capital if you do these things, right?"}, {"time": 5662, "text": "I mean, so Facebook was like a fantastic capital concentration machine."}, {"time": 5666, "text": "It's crazy how much, where it even found that capital in the world that it could concentrate and ossify in the stock price that a very small number of people have access to, right?"}, {"time": 5675, "text": "That's incredibly powerful."}, {"time": 5677, "text": "So when there is a possibility to consolidate and gather a huge amount of capital, that's a huge imperative that's very hard for the bike club to go up against, so."}, {"time": 5685, "text": "But there's a lot of money in the bike club."}, {"time": 5687, "text": "If you see what the Wall Street bets on that when a bunch of people get together, I mean, it doesn't have to be a bike."}, {"time": 5694, "text": "It could be a bunch of different bike clubs just kind of team up to overtake."}, {"time": 5699, "text": "That's what we're doing now, yeah."}, {"time": 5700, "text": "Or we're gonna repurpose off the shelf stuff."}, {"time": 5703, "text": "That's not, yeah, we're gonna repurpose whatever it was for office productivity or something, and like the clubs using Slack just to build out these, you know."}, {"time": 5712, "text": "Let's talk about email."}, {"time": 5715, "text": "I wrote a book."}, {"time": 5716, "text": "You wrote yet another amazing book, A World Without Email."}, {"time": 5722, "text": "Maybe one way to enter this discussion is to ask what is the hyperactive hive mind, which is the concept you opened the book with?"}, {"time": 5729, "text": "Yeah, and the devil."}, {"time": 5731, "text": "And the devil."}, {"time": 5732, "text": "It's the scourge of hundreds of millions."}, {"time": 5735, "text": "So I think, so I called this book A World Without Email."}, {"time": 5740, "text": "The real title should be A World Without the Hyperactive Hive Mind Workflow, but my publisher didn't like that, right?"}, {"time": 5745, "text": "So we had to get a little bit more pithy."}, {"time": 5747, "text": "I was trying to answer the question after deep work, why is it so hard to do this?"}, {"time": 5752, "text": "Like, if this is so valuable, if we can produce much higher, if people are much happier, why do we check email a day?"}, {"time": 5758, "text": "Why are we on Slack all day?"}, {"time": 5760, "text": "And so I started working on this book immediately after deep work."}, {"time": 5764, "text": "And so my initial interviews were done in 2016."}, {"time": 5766, "text": "So it took five years to pull the threads together."}, {"time": 5768, "text": "I was trying to understand why is it so hard for most people to actually find any time to do the stuff that actually moves the needle?"}, {"time": 5776, "text": "And the story was, and I thought this was, I hadn't heard this reported anywhere else."}, {"time": 5780, "text": "That's why it took me so long to pull it together, is email arrives on the scene, email spreads, I trace it, it really picks up steam in the early 1990s, between like 1990 and 1995, it makes its move, right?"}, {"time": 5792, "text": "And it does so for very pragmatic reasons."}, {"time": 5794, "text": "It was replacing existing communication technologies that it was better than."}, {"time": 5797, "text": "It was mainly the fax machine, voicemail, and memos, right?"}, {"time": 5799, "text": "So this was just better, right?"}, {"time": 5801, "text": "So it was a killer app because it was useful."}, {"time": 5804, "text": "In its wake came a new way of collaborating, and that's the Hyperactive Hive Mind."}, {"time": 5809, "text": "So it's like the virus that follows the rats that went through Western Europe for the Black Pig."}, {"time": 5815, "text": "As email spread through organizations, in its wake came the Hyperactive Hive Mind workflow, which says, okay, guys, here's the way we're gonna collaborate."}, {"time": 5823, "text": "We'll just work things out on the fly with unscheduled back and forth messages."}, {"time": 5827, "text": "Just boom, boom, boom, let's go back and forth."}, {"time": 5829, "text": "Hey, what about this?"}, {"time": 5829, "text": "Did you see this?"}, {"time": 5830, "text": "What about that client?"}, {"time": 5831, "text": "What's going on over here?"}, {"time": 5833, "text": "That followed email."}, {"time": 5834, "text": "It completely took over office work."}, {"time": 5838, "text": "And the need to keep up with all of these asynchronous back and forth unscheduled messages, as those got more and more and more, and we had more of those to service, the need to service those required us to check more and more and more and more, right?"}, {"time": 5850, "text": "And so by the time, and I go through the numbers, but by the time you get to today, now the average knowledge worker has to check one of these channels once every six minutes."}, {"time": 5857, "text": "Because every single thing you do in your organization, how you talk to your colleagues, how you talk to your vendors, how you talk to your clients, how you talk to the HR department, it's all this asynchronous unscheduled back and forth messaging."}, {"time": 5867, "text": "And you have to service the conversations."}, {"time": 5869, "text": "And it spiraled out of control, and it has sort of devolved a lot of work in the office now to all I do is constantly tend communication channels."}, {"time": 5878, "text": "So it's fascinating what you're describing is nobody ever paused in this whole evolution to try to create a system that actually works."}, {"time": 5888, "text": "That it was kind of like a huge fan of cellular automata."}, {"time": 5893, "text": "So it's just kind of started a very simple mechanism, just like cellular automata."}, {"time": 5898, "text": "It just kind of grew to overtake all the fundamental communication of how we do business and also personal life."}, {"time": 5905, "text": "Yeah, and that's one of the big ideas is that the unintentionality, right?"}, {"time": 5909, "text": "So this goes back to technological determinism."}, {"time": 5911, "text": "I mean, this is a weird business book because I go deep on philosophy."}, {"time": 5915, "text": "I go deep on, for some reason, we get into paleoanthropology for a while."}, {"time": 5919, "text": "We do a lot of neuroscience."}, {"time": 5920, "text": "It's kind of a weird book."}, {"time": 5922, "text": "But I got real into this technological determinism, right?"}, {"time": 5924, "text": "This notion that just the presence of a technology can change how people act."}, {"time": 5928, "text": "That's my big argument about what happened with the hive mind."}, {"time": 5931, "text": "And I can document specific examples, right?"}, {"time": 5934, "text": "So I document this example in IBM, 1987, maybe 85, but it's in like the mid to late eighties, IBM, R. Monk headquarters."}, {"time": 5943, "text": "We're gonna put an internal email, right?"}, {"time": 5945, "text": "Because it's convenient."}, {"time": 5947, "text": "And so they ran a whole study."}, {"time": 5949, "text": "And so I talked to the engineer who ran the study, Adrian Stone, like we're gonna run this study to figure out how much do we communicate because it was still an era where it's expensive, right?"}, {"time": 5957, "text": "So you have to provision a mainframe."}, {"time": 5959, "text": "So you can't over provision."}, {"time": 5960, "text": "Like we wanna know how much communication actually happened."}, {"time": 5962, "text": "So they went and figured it out."}, {"time": 5964, "text": "How many memos, how many calls, how many notes, great."}, {"time": 5966, "text": "We'll provision a mainframe to handle email that can handle all of that."}, {"time": 5969, "text": "So if all of our communication moves to email, the mainframe will still be fine."}, {"time": 5974, "text": "In three days, they had melted it down."}, {"time": 5976, "text": "People were communicating six times more than that estimate."}, {"time": 5979, "text": "So just in three days, the presence of a low friction digital communication tool drastically changed how everyone collaborated."}, {"time": 5986, "text": "So that's not enough time for an all hands meeting."}, {"time": 5989, "text": "Guys, we figured it out."}, {"time": 5991, "text": "This is what we need to communicate a lot more is what's gonna make us more productive."}, {"time": 5994, "text": "We need more emails."}, {"time": 5995, "text": "It's emergent."}, {"time": 5997, "text": "Isn't that just on the positive end, amazing to you?"}, {"time": 6000, "text": "Like, isn't email amazing?"}, {"time": 6003, "text": "Like in those early days, like just the frictionless communication."}, {"time": 6007, "text": "I mean, email is awesome."}, {"time": 6009, "text": "Like people say that there's a lot of problems with emails, just like people say a lot of problems with Twitter and so on."}, {"time": 6015, "text": "It's kind of cool that you can just send a little note."}, {"time": 6018, "text": "It was a miracle, right?"}, {"time": 6020, "text": "So I wrote a, there's originally was a New Yorker piece from a year or two ago called, was email a mistake?"}, {"time": 6026, "text": "And then it's in the book too."}, {"time": 6028, "text": "But I go into the history of email, like why did it come along?"}, {"time": 6032, "text": "And it solved a huge problem."}, {"time": 6034, "text": "It was the problem of fast asynchronous communication."}, {"time": 6037, "text": "And it was a problem that did not exist until we got large offices."}, {"time": 6041, "text": "We got large offices, synchronous communication, like let's get on the phone at the same time."}, {"time": 6044, "text": "There's too much overhead to it."}, {"time": 6045, "text": "There's too many people you might have to talk to."}, {"time": 6048, "text": "Asynchronous communication, like let me send you a memo when I'm ready and you can read it when you're ready, took too long."}, {"time": 6053, "text": "And so it was like a huge problem."}, {"time": 6055, "text": "So one of the things I talked about is the way that when they built the CIA headquarters, there was such a need for fast asynchronous communication that they built a pneumatic powered email system."}, {"time": 6065, "text": "They had these pneumatic tubes all throughout the headquarters with electromagnetic routers."}, {"time": 6069, "text": "So you would put your message in a plexiglass tube and you would turn these brass dials about the location."}, {"time": 6075, "text": "You would stick it in these things and pneumatic tubes and it would shoot and sort and work its way through these tubes to show up in just a minute or something at the floor and at the general office suite where you wanted to go."}, {"time": 6086, "text": "And my point is the fact that they spent so much money to make that work, to show how important fast asynchronous communication was to large offices."}, {"time": 6093, "text": "So when email came along, it was a productivity silver bullet."}, {"time": 6097, "text": "It was a miracle."}, {"time": 6097, "text": "I talked to the researchers who were working on computer supported collaboration in the late 80s, trying to figure out how are we gonna use computer networks to be more productive?"}, {"time": 6105, "text": "And they were building all these systems and tools."}, {"time": 6107, "text": "Email showed up, it just wiped all that research off the map."}, {"time": 6110, "text": "There was no need to build these custom intranet applications."}, {"time": 6113, "text": "There was no need to build these communication platforms."}, {"time": 6116, "text": "Email could just do everything."}, {"time": 6118, "text": "So it was a miracle application, which is why it spread everywhere."}, {"time": 6122, "text": "That's one of these things where, okay, on into the consequences, right?"}, {"time": 6125, "text": "You had this miracle productivity silver bullet."}, {"time": 6127, "text": "It spread everywhere, but it was so effective."}, {"time": 6130, "text": "It just, I don't know, like a drug."}, {"time": 6132, "text": "I'm sure there's some pandemic metaphor here, analogy here of a drug that like it's so effective at treating this that it also blows up your whole immune system and then everyone gets sick."}, {"time": 6141, "text": "Well, ultimately it probably significantly increased the productivity of the world, but there's a kind of hump that it now has plateaued."}, {"time": 6148, "text": "And then the fundamental question you're asking is like, okay, how do we take the next, how do we keep increasing the productivity?"}, {"time": 6155, "text": "Now, I think it brought it down."}, {"time": 6156, "text": "So my contention, and so again, there's a little bit in the book, but I have a more recent Wired article that puts some newer numbers to this."}, {"time": 6167, "text": "I subscribed to the hypothesis that the hyperactive hive mind was so detrimental."}, {"time": 6171, "text": "So yeah, it helped productivity at first, right?"}, {"time": 6173, "text": "When you could do fast asynchronous communication, but very quickly there was a sort of exponential rise in communication amounts."}, {"time": 6181, "text": "Once we got to the point where the hive mind meant you had to constantly check your email, I think that made us so unproductive that it actually was pulling down non industrial productivity."}, {"time": 6189, "text": "And I think the only reason why, so it certainly has not been going up."}, {"time": 6192, "text": "That metric has been stagnating for a long time now while all of this was going on."}, {"time": 6196, "text": "I think the only reason why it hasn't fallen is that we added these extra shifts off the books."}, {"time": 6202, "text": "I'm gonna work for three hours in the morning, I'm gonna work for three hours at night."}, {"time": 6205, "text": "And only that I think has allowed us to basically maintain a stagnated non industrial growth."}, {"time": 6211, "text": "We should have been shooting up the charts."}, {"time": 6213, "text": "I mean, this is miraculous innovations, the computer networks."}, {"time": 6216, "text": "And then we built out these hundred billion dollar ubiquitous worldwide high speed wireless internet infrastructure with supercomputers in our pockets where we could talk to anyone at any time."}, {"time": 6224, "text": "Like why did our productivity not shoot off the charts?"}, {"time": 6227, "text": "Because our brain can't context switch once every six minutes."}, {"time": 6229, "text": "So it's fundamentally back to the context switching."}, {"time": 6231, "text": "Context switching is poison."}, {"time": 6234, "text": "What is it about email that forces context switching?"}, {"time": 6238, "text": "Is it both our psychology that drags us in?"}, {"time": 6240, "text": "Or is it the expectation?"}, {"time": 6243, "text": "Because it's not, I think we've seen this through a personal will or failure lens recently."}, {"time": 6248, "text": "Like, oh, am I addicted to email?"}, {"time": 6251, "text": "I have bad etiquette about my email."}, {"time": 6254, "text": "No, it's the underlying workflow."}, {"time": 6256, "text": "So the tool itself I will exonerate."}, {"time": 6259, "text": "I think I would rather use POP3 than a fax protocol."}, {"time": 6263, "text": "I think it's easier."}, {"time": 6264, "text": "The issue is the hyperactive hive mind workflow."}, {"time": 6267, "text": "So if I am now collaborating with 20 or 30 different people with back and forth unscheduled messaging, I have to tend those conversations, right?"}, {"time": 6275, "text": "It's like you have 30 metaphorical ping pong tables."}, {"time": 6278, "text": "And when the balls come back across, you have to pretty soon hit it back or stuff actually grinds to a halt."}, {"time": 6283, "text": "So it's the workflow that's the problem."}, {"time": 6285, "text": "It's not the tools, the fact that we use it to do all of our collaboration."}, {"time": 6288, "text": "Let's just send messages back and forth, which means you can't be far from checking that."}, {"time": 6292, "text": "Cause if you take a break, if you batch, if you try to have better habits, it's gonna slow things down."}, {"time": 6298, "text": "So my whole villain is this hyperactive hive mind workflow."}, {"time": 6302, "text": "The tool is fine."}, {"time": 6303, "text": "I don't want the tool to go away, but I wanna replace the hyperactive hive mind workflow."}, {"time": 6307, "text": "I think this is gonna be one of the biggest value generating productivity revolutions of the 21st century."}, {"time": 6314, "text": "I quote an anonymous CEO who's pretty well known who says this is gonna be the moonshot of the 21st century."}, {"time": 6319, "text": "It's gonna be of that importance."}, {"time": 6320, "text": "There's so much latent productivity that's being suppressed because we just figure things out on the fly in email that as we figure that out, I think it's gonna be hundreds of billions of dollars."}, {"time": 6332, "text": "You're so absolutely right."}, {"time": 6335, "text": "The question is, what is a world without email look like?"}, {"time": 6339, "text": "How do we fix email?"}, {"time": 6340, "text": "So what happens is, at least in my vision, you identify, well, actually there's these different processes that make up my workday."}, {"time": 6349, "text": "Like these are things that I do repeatedly, often in collaboration with other people that do useful things for my company or whatever."}, {"time": 6356, "text": "Right now, most of these processes are implicitly implemented with the hyperactive hive mind."}, {"time": 6360, "text": "How do we do this thing?"}, {"time": 6361, "text": "Like answering client questions to shoot messages back and forth."}, {"time": 6365, "text": "Posting podcast episodes, we'll just figure it out on the fly."}, {"time": 6367, "text": "My main argument is we actually have to do like they did in the industrial sector, take each of these processes and say, is there a better way to do this?"}, {"time": 6374, "text": "And by better, I mean a way that's gonna minimize the need to have unscheduled back and forth messaging."}, {"time": 6379, "text": "So we actually have to do process engineering."}, {"time": 6382, "text": "This created a massive growth and productivity in the industrial sector during the 20th century."}, {"time": 6385, "text": "We have to do it in knowledge work."}, {"time": 6386, "text": "We can't just rock and roll an inbox as we actually have to say, how do we deal with client questions?"}, {"time": 6391, "text": "Well, let's put in place a process that doesn't require us to send messages back and forth."}, {"time": 6395, "text": "How do we post podcast episodes?"}, {"time": 6396, "text": "Let's automate this to a degree where I don't have to just send you a message on the fly."}, {"time": 6400, "text": "And you do this process by process and the pressure on that inbox is released."}, {"time": 6405, "text": "And now you don't have to check it every six minutes."}, {"time": 6406, "text": "So you still have email."}, {"time": 6407, "text": "I mean, like I need to send you a file."}, {"time": 6409, "text": "Sure, I'll use email, but we're not coordinating or collaborating over email or Slack, which is just a faster way of doing the hive mind."}, {"time": 6415, "text": "I mean, Slack doesn't solve anything there."}, {"time": 6417, "text": "You have better structured bespoke processes."}, {"time": 6420, "text": "I think that's what's gonna unleash this massive productivity."}, {"time": 6423, "text": "Bespoke, so the interesting thing is like, for example, you and I exchange some emails."}, {"time": 6427, "text": "So obviously I, let's just say in my particular case, I schedule podcasts."}, {"time": 6431, "text": "There's a bunch of different tasks, fascinatingly enough, that I do that can be converted into processes."}, {"time": 6439, "text": "Is it up to me to create that process?"}, {"time": 6441, "text": "Or do you think we also need to build tools just like email was a protocol for helping us create processes for the different tasks?"}, {"time": 6451, "text": "I mean, I think ultimately the whole organization, the whole team has to be involved."}, {"time": 6455, "text": "I think ultimately there's certainly a lot of investor money being spent right now to try to figure out those tools, right?"}, {"time": 6460, "text": "So I think Silicon Valley has figured this out in the past couple of years."}, {"time": 6463, "text": "This is the difference between when I was talking to people after Deep Work and now five years later is this scent is in the air, right?"}, {"time": 6471, "text": "Because there's so much latent productivity."}, {"time": 6473, "text": "So yes, there are gonna be new tools, which I think could help."}, {"time": 6475, "text": "There are already tools that exist."}, {"time": 6477, "text": "I mean, in the different groups I profiled use things like Trello or Basecamp or Asana or Flow and our schedule wants and acuity, like there's a lot of tools out there."}, {"time": 6488, "text": "The key is not to think about it in terms of what tool do I replace email with?"}, {"time": 6492, "text": "Instead, you think about it with, we're trying to come up with a process that reduces back and forth messages."}, {"time": 6497, "text": "Oh, what tool might help us do that?"}, {"time": 6501, "text": "Yeah, and I would push, it's not about necessarily efficiency."}, {"time": 6504, "text": "In fact, some of these things are gonna take more time."}, {"time": 6506, "text": "So writing a letter to someone is like a high value activity it's probably worth doing."}, {"time": 6511, "text": "The thing that's killer is the back and forth because now I have to keep checking, right?"}, {"time": 6515, "text": "So we scheduled this together because I knew you from before, but like most of the interviews I was scheduling for this actually I have a process with my publicist where we use a shared document and she puts stuffs in there and then I check it twice a week and there's scheduling options."}, {"time": 6530, "text": "I say, here's when I wanna do this one or this will work for this one or whatever."}, {"time": 6532, "text": "And it takes more time in the moment than just, but it means that we have almost no back and forth messaging for podcast scheduling, which without this, so like with my UK publisher, I didn't put this process in the place because we're not doing as many interviews, but it's all the time."}, {"time": 6547, "text": "And I'm like, oh, I could really feel the difference, right?"}, {"time": 6550, "text": "It's the back and forth that's killer."}, {"time": 6551, "text": "I suppose it is up to the individual people involved, like you said, knowledge workers, like they have to carry the responsibility of creating processes."}, {"time": 6563, "text": "Like how always asking the first principles question, how can this be converted into a process?"}, {"time": 6568, "text": "Yeah, so you can start by doing this yourself, like just with what you can control."}, {"time": 6572, "text": "I think ultimately once the teams are doing that, I think that's probably the right scale."}, {"time": 6576, "text": "If you try to do this at the organizational scale, you're gonna get bureaucracy, right?"}, {"time": 6579, "text": "So if it's, if Elon Musk is gonna dictate down to everyone at Tesla or something like this, that's too much remove and you get bureaucracy."}, {"time": 6588, "text": "But if it's, we're a team of six that's working together on whatever powertrain software, then we can figure out on our own, what are our processes?"}, {"time": 6597, "text": "How do we wanna do this?"}, {"time": 6598, "text": "So it's ultimately also creating a culture where saying like an email, sending an email just for the hell of it, it should be taboo."}, {"time": 6605, "text": "So you are being, you're being destructive to the productivity of the team by sending this email."}, {"time": 6612, "text": "As opposed to helping develop a process and so on that will ultimately automate this."}, {"time": 6620, "text": "That's why I'm trying to spread this message of the context switches as poison."}, {"time": 6624, "text": "I get so much into the science of it."}, {"time": 6625, "text": "I think we underestimate how much it kills us to have to wrench away our context, look at a message and come back."}, {"time": 6630, "text": "And so once you have the mindset of, it's a huge thing to ask of someone to have to take their attention off something and look back at this."}, {"time": 6638, "text": "And if they have to do that for three or four times, like we're just gonna figure this out on the fly and every message is gonna require five checks of the inbox while you wait for it."}, {"time": 6645, "text": "Now you've created whatever it is at this point, 25 or 30 context shifts."}, {"time": 6650, "text": "Like you've just done a huge disservice to someone's day."}, {"time": 6652, "text": "This would be like, if I had a professional athlete, like, hey, do me a favor."}, {"time": 6655, "text": "I need you to go do this press interview, but to get there, you're gonna have to carry this sandbag and sprint up this hill, like completely exhaust your muscles and then you have to go play a game."}, {"time": 6663, "text": "Like, of course I'm not gonna ask an athlete to do like an incredibly physically demanding thing right before a game, but something as easy as thoughts, question mark, or like, hey, do you wanna jump on a call and it's gonna be six back and forth messages to figure it out."}, {"time": 6675, "text": "It's kind of the cognitive equivalent, right?"}, {"time": 6677, "text": "You're taking the wind out of someone."}, {"time": 6679, "text": "Yeah, and by the way, for people who are listening, because I recently posted a few job openings for us so I wanted to help with this thing."}, {"time": 6686, "text": "And one of the things that people are surprised when they work with me is how many spreadsheets and processes are involved."}, {"time": 6692, "text": "Yeah, it's like Claude Shannon, right?"}, {"time": 6693, "text": "I talked about communication theory or information theory."}, {"time": 6696, "text": "It takes time to come up with a clever code upfront."}, {"time": 6698, "text": "So you spend more time upfront figuring out those spreadsheets and trying to get people on board with it."}, {"time": 6702, "text": "But then your communication going forward is all much more efficient."}, {"time": 6706, "text": "So over time, you're using much less bandwidth, right?"}, {"time": 6709, "text": "So you do pain upfront."}, {"time": 6712, "text": "It's quicker just right now to send an email."}, {"time": 6714, "text": "But if I spend a half day to do this over the next six months, I've saved myself 600 emails."}, {"time": 6720, "text": "Now, here's a tough question for, you know, from the computer science perspective, we often over optimize."}, {"time": 6727, "text": "So you've create processes and you, okay, just like you're saying, it's so pleasurable to increase in the longterm productivity that sometimes you just enjoy that process in itself by just creating processes and you actually never, like it has a negative effect on productivity longterm because you're too obsessed with the processes."}, {"time": 6753, "text": "Is that a nice problem to have essentially?"}, {"time": 6757, "text": "I mean, it's a problem."}, {"time": 6758, "text": "I mean, because let's look at the one sector that does do this, which is developers, right?"}, {"time": 6764, "text": "So agile methodologies like Scrum or Kanban are basically workflow methodologies that are much better than the hyperactive hive mind."}, {"time": 6772, "text": "But man, some of those programmers get pretty obsessive."}, {"time": 6775, "text": "I don't know if you've ever talked to a whatever level three Scrum master."}, {"time": 6779, "text": "They get really obsessive about like, it has to happen exactly this way and it's probably seven times more complex than it needs to be."}, {"time": 6787, "text": "I'm hoping that's just because nerds like me, you know, like to do that, but it's a broadly probably an issue, right?"}, {"time": 6794, "text": "We have to be careful because you can just go down that fiddling path."}, {"time": 6798, "text": "Like, so it needs to be, here's how we do it."}, {"time": 6799, "text": "Let's reduce the messages and let's roll, you know?"}, {"time": 6802, "text": "You can't save yourself through, if you can get the process just right, right?"}, {"time": 6808, "text": "So I wrote this article kind of recently called The Rise and Fall of Getting Things Done."}, {"time": 6812, "text": "And I profiled this productivity guru named Merlin Mann."}, {"time": 6844, "text": "So you have to have this sort of balance between, context switches are poison."}, {"time": 6850, "text": "So we got to get rid of the context switches."}, {"time": 6852, "text": "Once like something's working good enough to get rid of the context switches, then get after it."}, {"time": 6857, "text": "Yeah, there's a psychological process there for me."}, {"time": 6859, "text": "The OCD nature, like I've literally, embarrassing enough, have lost my shit before when, so in many of the processes that involve Python scripts, the rule is to not use spaces."}, {"time": 6874, "text": "Underscores, there's like rules for like how you format stuff, okay?"}, {"time": 6879, "text": "And like, I should not lose my shit when somebody had a space and maybe capital letters, like it's okay to have a space because there's this feeling like something's not perfect."}, {"time": 6891, "text": "And as opposed to in the Python script, allowing some flexibility around that, you create this programmatic way that's flawless and when everything's working perfectly, it's perfect."}, {"time": 6901, "text": "But actually, if you strive for perfection, it has the same stress, like has a lot of the stress that you were seeking to escape with the context switching because you're almost stressing about errors."}, {"time": 6918, "text": "Like when the process is functioning, there's always this anxiety of like, I wonder if it's gonna succeed."}, {"time": 6925, "text": "I wonder if it's gonna succeed."}, {"time": 6926, "text": "Yeah, no, no, I think some of that's just you and I probably."}, {"time": 6929, "text": "I mean, it's just our mindset, right?"}, {"time": 6930, "text": "We're in, we do computer science, right?"}, {"time": 6932, "text": "So chicken and egg, I guess."}, {"time": 6934, "text": "And a lot of the processes end up working here much rougher."}, {"time": 6937, "text": "It's like, okay, instead of letting clients just email me all the time, we have a weekly call and then we send them a breakdown of everything we committed to, right?"}, {"time": 6947, "text": "That's a process that works."}, {"time": 6948, "text": "Okay, I get asked a lot of questions because I'm the JavaScript guy in the company."}, {"time": 6951, "text": "Instead of doing it by email, I have office hours."}, {"time": 6953, "text": "This is what Basecamp does."}, {"time": 6954, "text": "All right, so you come to my office hours, that cuts down a lot of back and forth."}, {"time": 6957, "text": "All right, we're gonna, instead of emailing about this project, we'll have a Trello board and we'll do a weekly really structured status meeting real quick, what's going on, who needs what, let's go."}, {"time": 6967, "text": "And now everything's on there and on our inboxes, we don't have to send as many messages."}, {"time": 6970, "text": "So like that rough level of granularity, that gets you most of the way there."}, {"time": 6974, "text": "So the parts that you can't automate and turn into a process."}, {"time": 6978, "text": "So how many parts like that do you think should remain in a perfect world?"}, {"time": 6984, "text": "And for those parts where email is still useful, what do you recommend those emails look like?"}, {"time": 6992, "text": "How should you write emails?"}, {"time": 6994, "text": "When should you send them?"}, {"time": 6995, "text": "Yeah, I think email is good for delivering information."}, {"time": 7000, "text": "Right, so I think of it like a fax machine or something."}, {"time": 7003, "text": "It's a really good fax machine."}, {"time": 7004, "text": "So if I need to send you something and you just send you a file, I need to broadcast a new policy or something, like email is a great way to do it."}, {"time": 7011, "text": "It's bad for collaboration."}, {"time": 7013, "text": "So if you're having a conversation, like we're trying to reach a decision on something, I'm trying to learn about something, I'm trying to clarify what this is, that's more than just like a one answer type question, then I think that you shouldn't be doing an email."}, {"time": 7027, "text": "But see, here's the thing."}, {"time": 7028, "text": "Like you and I don't talk often and so we have a kind of new interaction."}, {"time": 7033, "text": "It's not, so sure, yeah, you have a book coming out, so there's a process and so on, but say there, don't you think there's a lot of novel interactive experiences?"}, {"time": 7044, "text": "Yeah, I think it's fine."}, {"time": 7045, "text": "So you could, just for every novel experience, it's okay to have a little bit of exchange."}, {"time": 7050, "text": "Like I think it's fine if stuff comes in over the transom or you hear from someone you haven't heard from in a while."}, {"time": 7056, "text": "I think all that's fine."}, {"time": 7057, "text": "I mean, that's email at its best."}, {"time": 7059, "text": "Where it starts to kill us is where all of our collaboration is happening with the back and forth."}, {"time": 7063, "text": "So when you've moved the bulk of that out of your inbox, now you're back in that Meg Ryan movie, like You Got Mail, where it's like, all right, load this up and you wait for the boat and be like, oh, we got a message."}, {"time": 7073, "text": "Yeah, Lex sent me a message."}, {"time": 7074, "text": "This is interesting, right?"}, {"time": 7075, "text": "You're back to the AOL days."}, {"time": 7076, "text": "So you're talking about the bulk of the business world where email has replaced the actual communication, all of the communication protocols required to accomplish anything."}, {"time": 7086, "text": "Everything is just happening with messages."}, {"time": 7088, "text": "So if you now get most stuff done, repeatable collaborations with other processes that don't require you to check these inboxes, then the inbox can serve like an inbox, which includes hearing from interesting people, right?"}, {"time": 7100, "text": "Or sending something, hey, I don't know if you saw this, I thought you might like it."}, {"time": 7103, "text": "I think it's great for that."}, {"time": 7104, "text": "So there's probably a bunch of people listening to this."}, {"time": 7107, "text": "They're like, yeah, but I work on a team and all they use is email."}, {"time": 7113, "text": "How do you start the revolution from the ground up?"}, {"time": 7115, "text": "Yeah, well, do asymmetric optimization first."}, {"time": 7119, "text": "So identify all your processes and then change what you can change and be socially very careful about it."}, {"time": 7124, "text": "So don't necessarily say like, okay, this is a new process we all have to do."}, {"time": 7128, "text": "You're just, hey, we gotta get this report ready."}, {"time": 7131, "text": "Here's what I think we should do."}, {"time": 7132, "text": "I'll get a draft into our Dropbox folder by noon on Monday, grab it."}, {"time": 7137, "text": "I won't touch it again until Tuesday morning and then I'll look at your changes."}, {"time": 7141, "text": "I have this office hours always scheduled Tuesday afternoon."}, {"time": 7143, "text": "So if there's anything that catches your attention, grab me then."}, {"time": 7147, "text": "But I've told the designer who CC'd on this that by COB Tuesday, the final version will be ready for them to take and polish or whatever."}, {"time": 7154, "text": "Like the person on the other end is like, great, I'm glad Cal has a plan."}, {"time": 7158, "text": "So what do I need to do?"}, {"time": 7159, "text": "I need to edit this tomorrow, whatever, right?"}, {"time": 7161, "text": "But you've actually pulled them into a process."}, {"time": 7162, "text": "That means we're gonna get this report together without having to just go back and forth."}, {"time": 7165, "text": "So you just asymmetrically optimize these things and then you can begin the conversation."}, {"time": 7171, "text": "And maybe that's where my book comes in place."}, {"time": 7172, "text": "You just sort of slide it across the desk."}, {"time": 7176, "text": "Buy the book and just leave it, give it to everybody on your team."}, {"time": 7180, "text": "Okay, so we solved the bulk of the email problem with this."}, {"time": 7182, "text": "Is there a case to be made that even for communication between you and I, we should move away from email?"}, {"time": 7190, "text": "And for example, there's a guy, I recently, I don't know if you know comedians, but there's a guy named Joey Diaz that I've had an interaction with recently."}, {"time": 7197, "text": "And that guy, first of all, the sweetest human, despite what his comedy sounds like, is the sweetest human being."}, {"time": 7204, "text": "And he's a big proponent of just pick up the phone and call."}, {"time": 7208, "text": "And it makes me so uncomfortable when people call me."}, {"time": 7211, "text": "It's like, I don't know what to do with this thing."}, {"time": 7214, "text": "But it kind of gets everything done quicker, I think, if I remove the anxiety from that."}, {"time": 7219, "text": "Is there a case to be made for that?"}, {"time": 7221, "text": "Or is email could still be the most efficient way to do this?"}, {"time": 7225, "text": "No, look, if you have to interact with someone, there's a lot of efficiency and synchrony, right?"}, {"time": 7230, "text": "And this is something from distributed system theory where you know if you go from synchronous to asynchronous networks, there's a huge amount of overhead to the asynchrony."}, {"time": 7236, "text": "So actually the protocols required to solve things in asynchronous networks are significantly more complicated and fragile than synchronous protocols."}, {"time": 7244, "text": "So if we can just do real time, it's usually better."}, {"time": 7246, "text": "And also from an interaction, like social connection standpoint, there's a lot more information in the human voice and the back and forth."}, {"time": 7253, "text": "Yeah, if you just call, so very generational, right?"}, {"time": 7256, "text": "Our generation will be comfortable talking on the phone in a way that a younger generation isn't, but an older generation is more comfortable with, well, you just call people."}, {"time": 7265, "text": "Whereas we, so there's a happy medium, but most of my good friends, we just talk, we have regular phone calls."}, {"time": 7271, "text": "Yeah, it's not, I don't just call them, we schedule it, we schedule it, yeah."}, {"time": 7274, "text": "Just on text, like, yeah, you wanna talk sometime soon."}, {"time": 7277, "text": "Do you ever have a process around friends?"}, {"time": 7280, "text": "Not really, no."}, {"time": 7282, "text": "I feel like I should, I feel like."}, {"time": 7284, "text": "Well, you have like a lot of interesting friend possibilities."}, {"time": 7287, "text": "You have like an interesting problem, right?"}, {"time": 7289, "text": "Like really interesting people you can talk to."}, {"time": 7292, "text": "Well, that's one problem."}, {"time": 7293, "text": "The other one is the introversion where I'm just afraid of people and get really stressed."}, {"time": 7297, "text": "Like I freak out."}, {"time": 7299, "text": "You picked a good line of work."}, {"time": 7301, "text": "Yeah, now perhaps it's the Goggins thing."}, {"time": 7303, "text": "It's like facing your fears or whatever, but it's almost like there's, it has to do with the timetables thing and the deep work that the nice thing about the processes is it not only automates sort of, automates away the context switching, it ensures you do the important things too."}, {"time": 7326, "text": "It's like prioritize."}, {"time": 7327, "text": "So the thing is with email, because everything is done over email, you can be lazy in the same way with like social networks and do the easy things first that are not that important."}, {"time": 7340, "text": "So the process also enforces that you do the important things."}, {"time": 7344, "text": "And for me, the important things is like, okay, that sounds weird, but like social connection."}, {"time": 7350, "text": "No, that's one of the most important things in all of human existence."}, {"time": 7354, "text": "And doing it, the paradoxical thing, I got into this for digital minimalism, the more you sacrifice on behalf of the connection, the stronger the connection feels, right?"}, {"time": 7364, "text": "So sacrificing non trivial time and attention on behalf of someone is what tells your brain that this is a serious relationship, which is why social media had this paradoxical effect making people feel less social because it took the friction out of it."}, {"time": 7378, "text": "And so the brain just doesn't like, like, yeah, you've been commenting on this person's, whatever, you've been retweeting them or sending them some text."}, {"time": 7385, "text": "You haven't, it's not hard enough."}, {"time": 7387, "text": "And then the perceived strength of that social connection diminishes where if you talk to them or go spend time with them or whatever, you're gonna feel better about it."}, {"time": 7396, "text": "So the friction is good."}, {"time": 7397, "text": "I have a thing with some of my friends where at the end of each call, we take a couple minutes to schedule the next."}, {"time": 7403, "text": "Then you never have to, it's like I do with haircuts or something, right?"}, {"time": 7405, "text": "Like if I don't schedule it then, I'm never gonna get my haircut, right?"}, {"time": 7409, "text": "And so it's like, okay, when do you wanna talk next?"}, {"time": 7412, "text": "Yeah, that's a really good idea."}, {"time": 7414, "text": "I just don't call friends."}, {"time": 7416, "text": "And like every 10 years I do something dramatic for them so that we maintain the friendship."}, {"time": 7420, "text": "We're like, I'd murder somebody that they really don't like."}, {"time": 7424, "text": "Careful, man, Joey might ask you to do that."}, {"time": 7426, "text": "Yeah, that's why, that's one of my favorite things."}, {"time": 7429, "text": "Lex, I need you to come down to New Jersey."}, {"time": 7431, "text": "That's exactly what we're gonna do."}, {"time": 7432, "text": "With that robot dog of yours."}, {"time": 7435, "text": "We're gonna go down to New Jersey."}, {"time": 7436, "text": "There's a special human."}, {"time": 7437, "text": "I love the comedian world."}, {"time": 7440, "text": "They've been shaking up."}, {"time": 7441, "text": "I don't know if you listen to Joe Rogan, all those folks."}, {"time": 7444, "text": "They kind of are doing something interesting for MIT and academia."}, {"time": 7450, "text": "They're shaking up this world a little bit."}, {"time": 7453, "text": "Like podcasting, because comedians are paving the way for podcasting."}, {"time": 7457, "text": "And so you have like Andrew Huberman, who's a neuroscientist at Stanford, friend of mine now."}, {"time": 7463, "text": "He's like into podcasting now and you're into podcasting."}, {"time": 7467, "text": "Of course, you're not necessarily podcasting about computer science currently, right?"}, {"time": 7470, "text": "But that, it feels like you could have a lot of the free spirit of the comedians implemented by the people who are academically trained."}, {"time": 7483, "text": "Who actually have a niche specialty."}, {"time": 7486, "text": "Yeah, and then that results, I mean, who knows what the experiment looks like, but that results me being able to talk about robotics with Joey Diaz when he says, you know, drops F bombs every other sentence."}, {"time": 7498, "text": "And I, the world is like, I've seen actually a shift within colleagues and friends within MIT where they're becoming much more accepting of that kind of thing."}, {"time": 7511, "text": "So you're seeing, okay."}, {"time": 7512, "text": "Because they're seeing how popular it is."}, {"time": 7514, "text": "They're like, wait a minute."}, {"time": 7515, "text": "Well, you're really popular."}, {"time": 7516, "text": "I don't know how they think about it at Georgetown, for example."}, {"time": 7519, "text": "It's interesting, but I think what happens is the popularity of it combined with just good conversations with people they respect."}, {"time": 7529, "text": "It's like, oh, wait, this is the thing."}, {"time": 7533, "text": "And this is more fun to listen to than a shitty Zoom lecture about their work."}, {"time": 7540, "text": "It's like, there's something here."}, {"time": 7540, "text": "There's something interesting."}, {"time": 7541, "text": "And we don't, nobody actually knows what that is."}, {"time": 7544, "text": "Just like with like Clubhouse or something, nobody's figured out like, where does this medium take?"}, {"time": 7549, "text": "Is this a legitimate medium of education?"}, {"time": 7552, "text": "Or is this just like a fun?"}, {"time": 7554, "text": "Well, that's your innovation, I think, was we can bring on professors."}, {"time": 7558, "text": "And I know Joe Rogan did some of that too, but your professors in your field."}, {"time": 7565, "text": "You bring on all these MIT guys who I remember."}, {"time": 7568, "text": "Well, that's been the big challenge for me is, I don't, is I feel, I would ask big like philosophical questions of people like yourself."}, {"time": 7580, "text": "They're like really well public."}, {"time": 7583, "text": "Like, so for example, you have a lot of excellent papers on, you know, that has a lot of theory in it, right?"}, {"time": 7591, "text": "And there's some temptation to just go through papers."}, {"time": 7595, "text": "And I think it's possible to actually do that."}, {"time": 7597, "text": "I haven't done that much, but I think it's possible."}, {"time": 7599, "text": "It just requires a lot of preparation."}, {"time": 7601, "text": "And I can probably only do that with things that I'm actually like in the field I'm aware of."}, {"time": 7608, "text": "But there's a dance that I would love to be able to try to hit right where it's actually getting to the core of some interesting ideas as opposed to just talking about philosophy."}, {"time": 7616, "text": "At the same time, there's a large audience of people that just want to be inspired by disciplines where they don't necessarily know the details."}, {"time": 7627, "text": "But there's a lot of people that are like, hmm, I'm really curious."}, {"time": 7630, "text": "I've been thinking about pivoting careers into software engineering."}, {"time": 7634, "text": "They would love to hear from people like you about computer science."}, {"time": 7637, "text": "Even if it's like theory."}, {"time": 7639, "text": "Yeah, but just like the idea that you can have big ideas, you push them through and it's interesting, you fight for it, yeah."}, {"time": 7645, "text": "Well, there's some, there's what is it?"}, {"time": 7647, "text": "Computerphile and Numberphile, these YouTube channels."}, {"time": 7653, "text": "There's channels I watch on like chess, exceptionally popular where I don't understand maybe 80% of the time what the hell they're talking about because they're talking about like why this move is better than this move."}, {"time": 7665, "text": "But I love the passion and the genius of those people and just overhearing it."}, {"time": 7670, "text": "I don't know why that's so exciting."}, {"time": 7672, "text": "Do you look at like Scott Aaronson's blog at all?"}, {"time": 7673, "text": "The Settled, Optimized?"}, {"time": 7675, "text": "Yeah, it's like hardcore complexity theory."}, {"time": 7677, "text": "But it's just an enthusiasm or like Terry Tao's blog."}, {"time": 7681, "text": "A little bit of humor about it."}, {"time": 7682, "text": "Terry Tao has a blog?"}, {"time": 7683, "text": "He used to, yeah."}, {"time": 7685, "text": "And it would just be, I'm going all in on, here's a new affine group with which you can do whatever."}, {"time": 7691, "text": "Whatever, it was just equations."}, {"time": 7692, "text": "Well, in the case of Scott Aaronson, he's good, he's able to turn on like the inner troll and comedian and so on."}, {"time": 7701, "text": "He keeps the fun, which is the best of kinds of books."}, {"time": 7702, "text": "And he's a philosophical guy."}, {"time": 7704, "text": "He wrote that."}, {"time": 7704, "text": "He turns on the philosophy."}, {"time": 7707, "text": "Yeah, so we're exploring these different ways of communicating science and exciting the world."}, {"time": 7713, "text": "Speaking of which, I gotta ask you about computer science."}, {"time": 7716, "text": "Yeah, that's right, I do some of that."}, {"time": 7719, "text": "So, I mean, a lot of your work is what inspired this deep thinking about productivity from all the different angles, because some of the most rigorous work is mathematical work."}, {"time": 7732, "text": "And in computer science, the theoretical computer science, let me ask the Scott Aaronson question of like, is there something to you that stands out in particular that's beautiful or inspiring, or just really insightful about computer science or maybe mathematics?"}, {"time": 7748, "text": "I mean, I like theory."}, {"time": 7751, "text": "And in particular, what I've always liked in theory is the notion of impossibilities."}, {"time": 7754, "text": "That's kind of my specialty."}, {"time": 7756, "text": "So within the context of distributed algorithms, my specialty is impossibility results."}, {"time": 7761, "text": "So the idea that you can argue nothing exists that solves this, or nothing exists that can solve this faster than this."}, {"time": 7770, "text": "And I think that's really interesting."}, {"time": 7772, "text": "And that goes all the way back to Turing."}, {"time": 7774, "text": "His original paper on computable numbers with their connection to the German Eichsturzungen problem, but basically the German name that Hilbert called the decision problem."}, {"time": 7783, "text": "This was precomputers, but he's English, so it's written in English."}, {"time": 7787, "text": "So it's a very accessible paper."}, {"time": 7788, "text": "And it lays the foundation for all of theoretical computer science."}, {"time": 7791, "text": "He just has this insight."}, {"time": 7793, "text": "He's like, well, if we think about like an algorithm, I mean, he figures out like all effective procedures or Turing machines are basically algorithms."}, {"time": 7799, "text": "We could really describe a Turing machine with a number, which we can now imagine with like computer code, you could just take a source file and just treat the binary version of the file as like a really long number, right?"}, {"time": 7809, "text": "But he's like, every program is just a finite number."}, {"time": 7812, "text": "It's a natural number."}, {"time": 7814, "text": "And then he realized like one way to think about a problem is you have, and this is like kind of the Mike Sipser approach, but you have a sort of, it's a language."}, {"time": 7821, "text": "So of an infinite number of strings, some of them are in the language and some of them aren't, but basically you can imagine a problem is represented as an infinite binary string, where in every position, like a one means that string is in the language and a zero means it isn't."}, {"time": 7833, "text": "And then he applied Cantor from the 19th century and said, okay, the natural numbers are countable."}, {"time": 7839, "text": "So it's countably infinite and infinite binary strings, you can use a diagonalization argument and show they're uncountable."}, {"time": 7847, "text": "So there's just vastly more problems than there are algorithms."}, {"time": 7851, "text": "So basically anything you can come up with for the most part almost certainly is not solvable by a computer."}, {"time": 7856, "text": "And then he was like, let me give a particular example."}, {"time": 7858, "text": "And he figured out the very first computability proof."}, {"time": 7861, "text": "Let's just walk through with a little bit of simple logic to halting problem can't be solved by an algorithm."}, {"time": 7865, "text": "And that kicked off the whole enterprise of some things can't be solved by algorithms, some things can't be solved by computers."}, {"time": 7874, "text": "And we've just been doing theory on that since that was the 30s he wrote that."}, {"time": 7878, "text": "So proving that something is impossible is sort of a stricter version of that."}, {"time": 7883, "text": "Is it like proving bounds on the performance of different algorithms?"}, {"time": 7887, "text": "Yeah, so bounds are upper bounds, right?"}, {"time": 7889, "text": "So you say, this algorithm does at least this well and no worse than this, but you're looking at a particular algorithm and possibility proof say no algorithm ever could ever solve this problem."}, {"time": 7900, "text": "So no algorithm could ever solve the halting problem."}, {"time": 7902, "text": "So it's problem centric."}, {"time": 7903, "text": "It's making something different, making a conclusive statement about the problem."}, {"time": 7909, "text": "And that's somehow satisfying because it's..."}, {"time": 7911, "text": "It's just philosophically interesting."}, {"time": 7914, "text": "I mean, it all goes back to, you get back to Plato, it's all reductio ad absurdum."}, {"time": 7918, "text": "So all these arguments have to start."}, {"time": 7919, "text": "The only way to do it is because there's an infinite number of solutions you can't go through them."}, {"time": 7922, "text": "You say, let's assume for the sake of contradiction that there existed something that solves this problem."}, {"time": 7929, "text": "And then you turn to crank a logic until you blow up the universe."}, {"time": 7931, "text": "And then you go back and say, okay, our original assumption that this solution exists can't be true."}, {"time": 7936, "text": "I just think philosophically, it's like a really exciting kind of beautiful thing."}, {"time": 7939, "text": "It's what I specialize in within distributed algorithms is more like time bound and possibility results."}, {"time": 7944, "text": "Like no algorithm can solve this problem faster than this in this setting."}, {"time": 7949, "text": "Of all the infinite number of ways you might ever do it."}, {"time": 7952, "text": "So you have many papers, but the one that caught my eye is Smooth Analysis of Dynamic Networks, in which you write, a problem with the worst case perspective is that it often leads to extremely strong lower bounds."}, {"time": 7965, "text": "These strong results motivate a key question."}, {"time": 7968, "text": "Is this bond robust in the sense that it captures the fundamental difficulty introduced by dynamism?"}, {"time": 7973, "text": "Or is the bond fragile in the sense that the poor performance it describes depends on an exact sequence of adversarial changes."}, {"time": 7982, "text": "Fragile lower bounds leave open the possibility of algorithms that might still perform well in practice."}, {"time": 7988, "text": "That's in the sense of the impossible and the bounds discussion presents the interesting question."}, {"time": 7995, "text": "I just like the idea of robust and fragile bounds, but what do you make about this kind of tension between what's provably, like what bounds you can prove that are like robust and something that's a bit more fragile."}, {"time": 8012, "text": "And also by way of answering that for this particular paper, can you say what the hell are dynamic networks?"}, {"time": 8021, "text": "What are distributed algorithms?"}, {"time": 8022, "text": "You don't know this?"}, {"time": 8023, "text": "Come on now."}, {"time": 8023, "text": "And I have no idea."}, {"time": 8024, "text": "And what is Smooth Analysis?"}, {"time": 8026, "text": "Yeah, well, okay."}, {"time": 8027, "text": "So Smooth Analysis, so it wasn't my idea."}, {"time": 8029, "text": "So Spielman and Tang came up with this in the context of sequential algorithms."}, {"time": 8034, "text": "So just like the normal world of an algorithm that runs on a computer."}, {"time": 8038, "text": "And they were looking at, there's a well known algorithm called the simplex algorithm, but basically you're trying to find a hole around a group of points."}, {"time": 8047, "text": "And there was an algorithm that worked really well in practice."}, {"time": 8050, "text": "But when you analyze it, you would say, I can't guarantee it's gonna work well in practice because if you have just the right inputs, this thing could run really long."}, {"time": 8058, "text": "But in practice, it seemed to be really fast."}, {"time": 8060, "text": "So Smooth Analysis is they came in and they said, let's assume that a bad guy chooses the inputs."}, {"time": 8065, "text": "It could be anything like really bad ones."}, {"time": 8067, "text": "And all we're gonna do, because in simplex they're numbers, we're gonna just randomly put a little bit of noise on each of the numbers."}, {"time": 8074, "text": "And they said, if you put a little bit of noise on the numbers, suddenly simplex algorithm goes really fast."}, {"time": 8079, "text": "Like, oh, that explains this lower bound, this idea that it could sometimes run really long was a fragile bound because it could only run a really long time if you had exactly the worst pathological input."}, {"time": 8089, "text": "So then my collaborators and I brought this over to the world of distributed algorithms."}, {"time": 8093, "text": "We brought them over the general lower bounds, right?"}, {"time": 8095, "text": "So in the world of dynamic networks, so distributed algorithm is a bunch of algorithms on different machines talking to each other, trying to solve a problem."}, {"time": 8103, "text": "And sometimes they're in a network."}, {"time": 8105, "text": "So you imagine them connected with network links and a dynamic network, those can change, right?"}, {"time": 8110, "text": "So I was talking to you, but now I can't talk to you anymore."}, {"time": 8112, "text": "Now I'm connected to a person over here."}, {"time": 8114, "text": "It's a really hard environment mathematically speaking."}, {"time": 8116, "text": "And there's a lot of really strong lower bounds, which you could imagine if the network can change all the time and a bad guy is doing it, it's like hard to do things well."}, {"time": 8124, "text": "So there's an algorithm running on every single node in the network."}, {"time": 8128, "text": "And then you're trying to say something of any kind that makes any kind of definitive sense about the performance of that algorithm."}, {"time": 8134, "text": "Yeah, so I just submitted a new paper on this a couple of weeks ago."}, {"time": 8138, "text": "And we were looking at a very simple problem."}, {"time": 8139, "text": "There's some messages in the network."}, {"time": 8142, "text": "We want everyone to get them."}, {"time": 8144, "text": "If the network doesn't change, you can do this pretty well."}, {"time": 8147, "text": "You can pipeline them."}, {"time": 8148, "text": "There's some basic algorithms that work really well."}, {"time": 8152, "text": "If the network can change every round, there's these lower bounds that says, it takes a really long time."}, {"time": 8158, "text": "There's a way that no matter what algorithm you come up with, there's a way the network can change in such a way that just really slows down your progress basically, right?"}, {"time": 8165, "text": "So smooth analysis there says, yeah, but that seems like you'd have really bad luck if your network was changing exactly in the right way that you needed to screw your algorithm."}, {"time": 8175, "text": "So we said, what if we randomly just add or remove a couple of edges in every round?"}, {"time": 8180, "text": "So the adversary is trying to choose the worst possible network."}, {"time": 8182, "text": "And we're just tweaking it a little bit."}, {"time": 8184, "text": "And in that case, this is a new paper."}, {"time": 8185, "text": "I mean, it's a blinded submission, so maybe I shouldn't, it's not, whatever."}, {"time": 8190, "text": "We basically showed."}, {"time": 8191, "text": "An anonymous friend of yours submitted a paper."}, {"time": 8193, "text": "An anonymous friend of mine, yeah, whose paper should be accepted."}, {"time": 8197, "text": "Showed that even just adding like one random edge per round, and here's the cool thing about it, the simplest possible solution to this problem blows away that lower bound and does really well."}, {"time": 8207, "text": "So that's like a very fragile lower bound because we're like, it's almost impossible to actually keep things slow."}, {"time": 8215, "text": "I wonder how many lower bounds you can smash open with this kind of analysis and show that they're fragile."}, {"time": 8222, "text": "It's my interest, yeah."}, {"time": 8223, "text": "Because in distributed algorithms, there's a ton of really famous strong lower bounds, but things have to go wrong, really, really wrong for these lower bound arguments to work."}, {"time": 8234, "text": "And so I like this approach."}, {"time": 8235, "text": "So this whole notion of fragile versus robust, I was like, well, let's go in and just throw a little noise in there."}, {"time": 8241, "text": "And if it becomes solvable, then maybe that lower bound wasn't really something we should worry about."}, {"time": 8245, "text": "You know, that's gonna embarrass, that's really uncomfortable."}, {"time": 8248, "text": "That's really embarrassing to a lot of people."}, {"time": 8251, "text": "Because, okay, this is the OCD thing with the spaces, is it feels really good when you can prove a nice bound."}, {"time": 8259, "text": "And if you say that that bound is fragile, that's like, there's gonna be a sad kid that walks with their lunchbox back home, like, my lower bound doesn't matter."}, {"time": 8272, "text": "No, I don't think they care."}, {"time": 8273, "text": "It's all, I don't know, it feels like to me, a lot of this theory is just math machismo."}, {"time": 8277, "text": "It's like, whatever, this was a hard bound to prove."}, {"time": 8282, "text": "So if you show that something is fragile, that's really important in practice, right?"}, {"time": 8288, "text": "So do you think kind of theoretical computer science is living its own world, just like mathematics, and their main effort, which I think is very valuable, is to develop ideas that's not necessarily interesting, whether it's applicable in the real world."}, {"time": 8301, "text": "Yeah, we don't care about the applicability."}, {"time": 8302, "text": "Yeah, we kind of do, but not really."}, {"time": 8304, "text": "And we're terrible with computers, and can't do anything useful with computers, and we don't know how to code."}, {"time": 8308, "text": "And, you know, we're not productive members of like technological society, but I do think things percolate."}, {"time": 8317, "text": "You percolate from the world of theory into the world of algorithm design, where it will pull on the theory, and now suddenly it's useful, and then the algorithm design gets pulled into the world of practice, where they say, well, actually, we can make this algorithm a lot better, because in practice, really, these servers do X, Y, Z, and now we can make this super efficient."}, {"time": 8331, "text": "And so I do think, I mean, I teach theory to the PhD students at Georgetown."}, {"time": 8336, "text": "I show them the sort of funnel of like, okay, we're over here doing theory, but it eventually, some of this stuff will percolate down in effect at the very end, you know, a phone, but it's a long tunnel."}, {"time": 8348, "text": "But the very question you're asking, at the highest philosophical level, is fascinating."}, {"time": 8352, "text": "Like, if you take a system, a distributed system, or a network, and introduce a little bit of noise into it, like, how many problems of that nature are fundamentally changed by that little introduction of noise?"}, {"time": 8367, "text": "Yeah, because it's all, especially in distributed algorithms, the model is everything."}, {"time": 8371, "text": "Like, the way we work is we're incredibly precise about, here's exactly, it's mathematical, here's exactly how the network works, and it's a state machine, algorithms are state machines, there's rounds and schedulers, we're super precise so we can prove lower bounds."}, {"time": 8384, "text": "But yeah, often those lower, those impossibility results really get at the hard edges of exactly how that model works."}, {"time": 8390, "text": "So we'll see if this, so we published a paper on this, that paper you mentioned, that kind of introduced the idea to the distributed algorithms world."}, {"time": 8398, "text": "And I think that's got some traction and there's been some followup."}, {"time": 8402, "text": "So we've just submitted our next."}, {"time": 8405, "text": "I mean, honestly, the issue with the next that like the result fell out so easily, and this shows the mathematical machismo problem in these fields is there's a good chance the paper won't be accepted because there wasn't enough mathematical self flagellation."}, {"time": 8418, "text": "That's such a nice finding."}, {"time": 8420, "text": "So even showing that very few, just very little bit of noise, can have a dramatic, make a dramatic statement about the."}, {"time": 8428, "text": "It was a big surprise to us, but once we figured out how to show it, it's not too hard."}, {"time": 8434, "text": "And these are venues for theoretical work."}, {"time": 8438, "text": "Okay, so the fascinating tension that exists in other disciplines, like one of them is machine learning, which despite the power of machine learning and deep learning and all like the impact of it, in the real world, the main conferences on machine learning are still resistant to application papers."}, {"time": 8461, "text": "And application papers broadly defined, meaning like finding almost like you would, like Darwin did by like going around, collecting some information, saying, huh, isn't this interesting?"}, {"time": 8476, "text": "Like those are some of the most popular blogs, and yet as a paper, it's not really accepted."}, {"time": 8481, "text": "I wonder what you think about this whole world of deep learning from a perspective of theory."}, {"time": 8489, "text": "What do you make of this whole discipline of the success of Neon Networks, of how to do science on them?"}, {"time": 8494, "text": "Are you excited by the possibilities of what we might discover about Neon Networks?"}, {"time": 8500, "text": "Do you think it's fundamental in engineering discipline, or is there something theoretical that we might crack open one of these days in understanding something deep about how system optimization and how systems learn?"}, {"time": 8512, "text": "I am convinced by, is it Tegmark at MIT?"}, {"time": 8516, "text": "Tegmark?"}, {"time": 8516, "text": "Yeah, Tegmark, right."}, {"time": 8543, "text": "Yeah, and tweaking constants and hoping that the classifier fitness, for God's sakes, before the submission deadline actually gets above some, it feels like it's linear algebra and tedium, right?"}, {"time": 8557, "text": "But anyways, I'm really convinced with his idea that once we understand better and better what's going on from a theory perspective, it's gonna make it into an engineering discipline."}, {"time": 8564, "text": "So in my mind, where we're gonna end up is, okay, forget these metaphors of neurons, and these things are gonna be put down into these mathematical kind of elegant equations, differentiable equations that just kind of work well, and then it's gonna be when I need a little bit of AI in this thing, plumbing."}, {"time": 8582, "text": "Like, let's get a little bit of a pattern recognizer with a noise module and let's connect."}, {"time": 8586, "text": "I mean, you know this feel better than me, so I don't know if this is like a reasonable prediction, but it's gonna become less inscrutable, and then it's gonna become more engineerable, and then we're gonna have AI in more things because we're gonna have a little bit more control over how we piece together these different classification black boxes."}, {"time": 8605, "text": "So one of the problems, and there might be some interesting parallels that you might provide intuition on is, you know, neural networks are very large, and they have a lot of, you know, we were talking about, you know, dynamic networks and distributed algorithms."}, {"time": 8621, "text": "One of the problems with the analysis of neural networks is, you know, you have a lot of nodes, and you have a lot of edges."}, {"time": 8630, "text": "To be able to interpret and to control different things is very difficult."}, {"time": 8633, "text": "There's fields in trying to figure out like mathematically how you form clean representations that are like, like one node contains all the information about a particular thing, and no other nodes is correlated to it."}, {"time": 8650, "text": "So like it has unique knowledge and like, but that ultimately boils down to trying to simplify this thing into, that goes against this very nature, which is like deeply connected, and like dynamic and just, you know, hundreds of millions, billions of nodes."}, {"time": 8670, "text": "And in a distributed sense, like when you zoom out, the thing has a representation and understanding of something, but the individual nodes are just doing their little exchanging thing."}, {"time": 8680, "text": "And it's the same thing with Stephen Wolfram when you talk about cellular automata, it's very difficult to do math when you have a huge collection of distributed things, each acting on their own."}, {"time": 8690, "text": "And it's almost like, it feels like it's almost impossible to do any kind of theoretical work in the traditional sense."}, {"time": 8698, "text": "It almost becomes completely like a biology, you become a biologist as opposed to a theoretician."}, {"time": 8706, "text": "You just study it experimentally."}, {"time": 8707, "text": "Yeah, I think that's the big question, I guess, right?"}, {"time": 8710, "text": "Yeah, so is the large size and interconnectedness of the like a deep learning network fundamental to that task, or are we just not very good at it yet because we're using the wrong metaphor?"}, {"time": 8723, "text": "I mean, the human brain learns with much fewer examples and with much less tuning of the whatever, whatever, whatever probably that requires to get those like deep mind networks up and running."}, {"time": 8734, "text": "But yeah, so I don't really know, but the one thing I have observed is that the, yeah, there's the mundane nature of some of the working with these models tends to lead people to think that, to do it like, it could be Skynet or it could be like a lot of pain to get the thermostat to do what we want it to do."}, {"time": 8754, "text": "And there's a lot of open questions in between there."}, {"time": 8756, "text": "And then of course, the distributed network of humans that use these systems."}, {"time": 8764, "text": "So like you can have the system itself, then your network, but you can also have like little algorithms controlling the behavior of humans, which is what you have with social networks."}, {"time": 8774, "text": "It's possible that a very, what is it, a toaster or whatever, the opposite of Skynet when taken at scale while used by individual humans and controlling their behavior can actually have the Skynet effect."}, {"time": 8785, "text": "So the scale there."}, {"time": 8787, "text": "We might have that now."}, {"time": 8789, "text": "We might have that now, we just don't know."}, {"time": 8791, "text": "As it's happening."}, {"time": 8792, "text": "Is Twitter creating a little mini Skynet?"}, {"time": 8793, "text": "I mean, because of what happens, it twirls out ramifications in the world."}, {"time": 8798, "text": "And is it really that much different if it's a robot with tentacles or a bunch of servers that."}, {"time": 8804, "text": "Yeah, and the destructive effects could be, I mean, it could be political, but it could also be like, you could probably make an interesting case that the virus, the coronavirus spread on Twitter too, in the minds of people."}, {"time": 8820, "text": "Like the fear and the misinformation in some very interesting ways mixed up."}, {"time": 8826, "text": "And maybe this pandemic wasn't sufficiently dangerous to where that could have created a weird like an instability, but maybe other things might create instability."}, {"time": 8835, "text": "Like somebody, God forbid, detonates a nuclear weapon somewhere."}, {"time": 8839, "text": "And then maybe the destructive aspect of that would not as much be the military actions, but the way those news are spread on Twitter and the panic that creates."}, {"time": 8850, "text": "I mean, I think that's a great case study, right?"}, {"time": 8852, "text": "Like what happened, not, but I'm not suggesting that Lexi go let off a nuclear bomb."}, {"time": 8856, "text": "I meant the coronavirus, but yeah, I think that's a really interesting case study."}, {"time": 8863, "text": "I'm interested in the counterfactual of 1995, like do the same virus in 1995."}, {"time": 8868, "text": "So first of all, it would have been, I get to hear whatever the nightly news, we'll talk about it."}, {"time": 8874, "text": "And then there'll be my local health board, we'll talk about it."}, {"time": 8878, "text": "That mitigation decisions would probably necessarily be very sort of localized."}, {"time": 8884, "text": "Okay, our community is trying to figure out what are we gonna do?"}, {"time": 8887, "text": "Like we see this with schools, like where I grew up in New Jersey, there's very localized school districts."}, {"time": 8892, "text": "So even though they had sort of really bad viral numbers there, my school I grew up in has been open since the fall because it's very localized."}, {"time": 8900, "text": "It's like these teachers and these parents, what do we wanna do?"}, {"time": 8902, "text": "What are we comfortable with?"}, {"time": 8903, "text": "I live in a school district right now in Montgomery County that's a billion dollar a year budget, 150,000 kid school district."}, {"time": 8909, "text": "It just can't, it's closed because it's too."}, {"time": 8912, "text": "So I'm interested in that counterfactual."}, {"time": 8913, "text": "Yeah, so you have all this information moving around and then you have the effects on discourse that we were talking about earlier, that the Neil Postman style effects of Twitter, which shifts people into a sort of a dunk culture mindset of don't give an inch to the other team."}, {"time": 8929, "text": "And we're used to this and was fired up by politics and the unique attributes of Twitter."}, {"time": 8956, "text": "That's like very Twittery in a way that in 1995 is probably not the way public health officials would be thinking."}, {"time": 8963, "text": "Where now it's like, well, this is, if we said this about masks, but the other team said that about masks, we can't give an inch to this."}, {"time": 8969, "text": "So we gotta be careful."}, {"time": 8970, "text": "And like, we can't tell people it's okay after they're vaccinated because that might, we're giving them an inch on this and that's very Twittery in my mind, right?"}, {"time": 8976, "text": "That is the impact of Twitter on the way we think about discourse, which is a dunking culture of don't give any inch to the other team and it's all about slam dunks where you're completely right and they're completely wrong."}, {"time": 8986, "text": "It's as a rhetorical strategy, it's incredibly simplistic, but it's also the way that we think right now about how we do debate."}, {"time": 8992, "text": "It combined terribly with election year pandemic."}, {"time": 8996, "text": "Yeah, election year pandemic."}, {"time": 8998, "text": "I wonder if we could do some smooth analysis."}, {"time": 9000, "text": "Let's run the simulation over a few times."}, {"time": 9001, "text": "A little bit of noise, yeah."}, {"time": 9003, "text": "See if it can dramatically change the behavior of the system."}, {"time": 9007, "text": "Okay, we talked about your love for proving that something is impossible."}, {"time": 9011, "text": "So there's quite a few still open problems and complexity of algorithms."}, {"time": 9017, "text": "So let me ask, does P equal NP?"}, {"time": 9023, "text": "If P equals NP, what kind of, and you'd be really surprised somebody proves it."}, {"time": 9032, "text": "What would that proof look like and why would that even be?"}, {"time": 9035, "text": "What would that mean?"}, {"time": 9036, "text": "What would that proof look like?"}, {"time": 9038, "text": "And what possible universe could P equals NP?"}, {"time": 9040, "text": "Is there something in size that you could say there?"}, {"time": 9043, "text": "It could be true."}, {"time": 9045, "text": "I mean, I'm not a complexity theorist, but every complexity theorist I know is convinced they're not equal and are basically not working on it anymore."}, {"time": 9053, "text": "I mean, there is a million dollars at stake if you can solve the proof."}, {"time": 9055, "text": "It's one of the millennium prizes."}, {"time": 9057, "text": "Okay, so here's how I think the P not equals NP proof is gonna eventually happen."}, {"time": 9062, "text": "I think it's gonna fall out and it's gonna be not super simple, but not as hard as people think, because my theory about a lot of theoretical computer science based on just some results I've done, so this is a huge extrapolation, is that a lot of what we're doing is just obfuscating deeper mathematics."}, {"time": 9103, "text": "So this has happened to me."}, {"time": 9104, "text": "I had this paper I was quite fond of a while ago."}, {"time": 9107, "text": "It was looking at this problem called contention resolution where you put an unknown set of people on a shared channel and they're trying to break symmetry."}, {"time": 9115, "text": "So it's like an ethernet, whatever."}, {"time": 9117, "text": "Only one person can use it at a time."}, {"time": 9118, "text": "You try to break symmetry."}, {"time": 9119, "text": "There's all these bounds people have proven over the years about how long it takes to do this, right?"}, {"time": 9125, "text": "And like I discovered at some point, there's this one combinatorial result from the early 1990s."}, {"time": 9132, "text": "All of these lower bound proofs all come from this and in fact, it improved a lot of them and simplified a lot."}, {"time": 9137, "text": "You could put it all in one paper."}, {"time": 9139, "text": "It's like, are we really?"}, {"time": 9140, "text": "And then, okay, so this new paper that I submitted a couple of weeks ago, I found you could take some of these same lower bound proofs for this contention resolution problem."}, {"time": 9148, "text": "You could reprove them."}, {"time": 9149, "text": "Using Shannon's source code theorem that actually when you're breaking contention, what you're really doing is building a code over, if you have a distribution on the network sizes, it's a code over that source."}, {"time": 9161, "text": "And if you plug in a high entropy information source and plug in from 1948, the source code theorem that says on a noiseless channel, you can't send things at a faster rate than the entropy allows, the exact same lower bounds fall back out again, right?"}, {"time": 9174, "text": "So like this type of thing happens."}, {"time": 9175, "text": "There's some famous lower bounds and distributed algorithms that turned out to all be algebraic topology underneath the covers."}, {"time": 9182, "text": "And they won the Girdle Prize for working on that."}, {"time": 9185, "text": "So my sense is what's gonna happen is at some point, someone really smart to be very exciting is gonna realize there's some sort of other representation of what's going on with these Turing machines trying to sort of efficiently compute."}, {"time": 9198, "text": "And there'll be an existing mathematical result that apply."}, {"time": 9203, "text": "Someone or something, I guess."}, {"time": 9205, "text": "It could be AI theorem provers kind of thing."}, {"time": 9208, "text": "It could be, yeah."}, {"time": 9208, "text": "I mean, not a, well, yeah."}, {"time": 9210, "text": "I mean, there's theorem provers, like what that means now, which is not fun."}, {"time": 9215, "text": "It's just a bunch of..."}, {"time": 9217, "text": "Very carefully formulated postulates that, but I take your point, yeah."}, {"time": 9224, "text": "On a small tangent on that, then you're kind of implying that mathematics, it almost feels like a kind of weird evolutionary tree that ultimately leads back to some kind of ancestral, few fundamental ideas that all are just like, they're all somehow connected."}, {"time": 9241, "text": "In that sense, do you think math is fundamental to our universe and we're just like slowly trying to understand these patterns or is it discovered?"}, {"time": 9255, "text": "Or is it just a little game that we play amongst ourselves to try to fit little patterns to the world?"}, {"time": 9263, "text": "Yeah, that's the question, right?"}, {"time": 9264, "text": "That's the physicist question."}, {"time": 9266, "text": "I mean, I'm probably, I'm in the discovered camp, but I don't do theoretical physics."}, {"time": 9270, "text": "So I know they have a, they feel like they have a stronger claim to answering that question."}, {"time": 9277, "text": "But everything comes back to it."}, {"time": 9278, "text": "Everything comes back to it."}, {"time": 9279, "text": "I mean, all the physics, the fact that the universe is, well, okay."}, {"time": 9285, "text": "It's a complicated question."}, {"time": 9287, "text": "So how often do you think, how deeply does this result describe the fundamental reality of nature?"}, {"time": 9297, "text": "So the reason I hesitated, because it's something I'm, I taught this seminar and did a little work on what are called biological algorithms."}, {"time": 9305, "text": "So there's this notion of, so physicists use mathematics to explain the universe, right?"}, {"time": 9314, "text": "And it was unreasonable that mathematics works so well."}, {"time": 9318, "text": "All these differential equations, why does that explain all we need to know about thermodynamics and gravity and all these types of things?"}, {"time": 9324, "text": "Well, there's this movement within the intersection of computer science and biology, just kind of Wolframium, I guess, really, that algorithms can be very explanatory, right?"}, {"time": 9335, "text": "Like if you're trying to explain parsimoniously something about like an ant colony or something like this, you're not going to, ultimately it's not gonna be explained as a equation, like a physics equation."}, {"time": 9346, "text": "It's gonna be explained by an algorithm."}, {"time": 9348, "text": "So like this algorithm run distributedly is going to explain the behavior."}, {"time": 9353, "text": "So that's mathematical, but not quite mathematical, but it is if you think about an algorithm like a Lambda calculus, which brings you back to the world of mathematics."}, {"time": 9361, "text": "So I'm thinking out loud here, but basically abstract math is sort of like unreasonably effective at explaining a lot of things."}, {"time": 9370, "text": "And that's just what I feel like I glimpse."}, {"time": 9371, "text": "I'm not like a super well known theoretician."}, {"time": 9374, "text": "I don't have really famous results."}, {"time": 9376, "text": "So even as a sort of middling career theoretician, I keep encountering this where we think we're solving some problem about computers and algorithms, and it's some much deeper underlying math."}, {"time": 9391, "text": "It's Shannon, but Shannon is entropy, but entropy was really goes all the way back to whatever it was, Boyle or all the way back to looking at the early physics."}, {"time": 9400, "text": "And it's, anyways, to me, I think it's amazing."}, {"time": 9404, "text": "Yeah, but it could be the flip side of that could be just our brains draw so much pleasure from the deriving generalized theories and simplifying the universe that we just naturally see that kind of simplicity in everything."}, {"time": 9418, "text": "Yeah, so that's the whole Newton to Einstein, right?"}, {"time": 9421, "text": "So you can say this must be right because it's so predictive."}, {"time": 9424, "text": "Well, it's not quite predictive because Mercury wobbles a little bit, but I think we have it set and then you turn out, no, Einstein."}, {"time": 9430, "text": "And then you get Bohr like, no, not Einstein."}, {"time": 9433, "text": "It's actually statistical."}, {"time": 9435, "text": "And yeah, so that would be interesting."}, {"time": 9436, "text": "It's hard to also know where a smooth analysis fits into all that or a little bit of noise."}, {"time": 9441, "text": "Like you can say something very clean about a system and then a little bit of noise, like the average case is actually very different."}, {"time": 9449, "text": "And so, I mean, that's where the quantum mechanics comes in."}, {"time": 9452, "text": "It's like, ugh, why does it have to be randomness in this?"}, {"time": 9456, "text": "Yeah, I would have to do this complex statistics."}, {"time": 9461, "text": "So to be determined."}, {"time": 9462, "text": "Yeah, that'll be my next book."}, {"time": 9464, "text": "That'd be ambitious."}, {"time": 9465, "text": "The fundamental core of reality, comma, and some advice for being more productive at work."}, {"time": 9473, "text": "Can I ask you just, if it's possible to do an overview and just some brief comments of wisdom on the process of publishing a book, what's that process entail?"}, {"time": 9484, "text": "What are the different options and what's your recommendation for somebody that wants to write a book like yours, a nonfiction book that discovers something interesting about this world?"}, {"time": 9497, "text": "So what I usually advise is follow the process as is."}, {"time": 9505, "text": "Don't try to reinvent."}, {"time": 9507, "text": "I think that happens a lot where you'll try to reinvent the way the publishing industry should work."}, {"time": 9513, "text": "Like this is kind of not like in a business model ways, but just like, this is what I want to do."}, {"time": 9518, "text": "I want to write a thousand words a day and I want to do this and I'm gonna put it on the internet and the publishing industry is very specific about how it works."}, {"time": 9526, "text": "And so like when I got started writing books, which at a very young age, so I sold my first book at the age of 21."}, {"time": 9532, "text": "The way I did that is I found a family friend that was an agent and I said, I'm not trying to make you be my agent."}, {"time": 9540, "text": "Just explain to me how this works."}, {"time": 9542, "text": "Not just how the world works, but give me the hard truth about how would a 21 year old, under what conditions could a 21 year old sell a book and what would that look like?"}, {"time": 9549, "text": "And she just explained it to me."}, {"time": 9550, "text": "You know, you have to do this and have to be a subject that it made sense for you to write."}, {"time": 9554, "text": "And you would have to do this type of writing for the publications to validate it and blah, blah, blah."}, {"time": 9557, "text": "And you have to get the agent first."}, {"time": 9558, "text": "And I learned the whole game plan and then I executed."}, {"time": 9562, "text": "And so the rough game plan is with nonfiction, you get the agent first and the agent's gonna sell it to the publishers."}, {"time": 9568, "text": "So like you're never sending something directly to the publishers."}, {"time": 9571, "text": "In nonfiction, you're not writing the book first, right?"}, {"time": 9574, "text": "You're gonna get an advance from the publisher once sold and then you're gonna do the primary writing of the book."}, {"time": 9580, "text": "In fact, it will, in most circumstances, hurt you if you've already written it."}, {"time": 9583, "text": "If you've already written it."}, {"time": 9585, "text": "So you're trying to sell, well, I guess the agent, first you sell it to the agent and then the agent sells it to the publishers."}, {"time": 9590, "text": "It's much easier to get an agent than a book deal."}, {"time": 9592, "text": "So the thought is, if you can't get an agent, then why would you?"}, {"time": 9595, "text": "So you start with, and also the way this works with a good agent is they know all the editors and they have lunch with the editors and they're always just like, okay, what projects do you have coming?"}, {"time": 9604, "text": "Here's one of my authors."}, {"time": 9604, "text": "That's the way all these deals happen."}, {"time": 9606, "text": "It's not, you're not emailing a manuscript to a slush pile."}, {"time": 9609, "text": "Yeah, and so first of all, the agent takes a percentage and then the publishers, this is where the process comes in."}, {"time": 9614, "text": "They take also a cut that's probably ridiculous."}, {"time": 9617, "text": "So if you try to reinvent the system, you'll probably be frustrated by the percentage that everyone takes relative to how much bureaucracy and efficiency ridiculousness there is in the system."}, {"time": 9628, "text": "Your recommendation is like, you're just one ant."}, {"time": 9631, "text": "Stop trying to build your own ant colony."}, {"time": 9634, "text": "Well, or if you create your own process for how it should work, the book's not gonna get published."}, {"time": 9639, "text": "So there's the separate question, the economic question of like, should I create my own, like self publish it or do something like that?"}, {"time": 9645, "text": "But putting that aside, there's a lot of people I encounter that wanna publish a book with a main publisher, but they invent their own rules for how it works, right?"}, {"time": 9654, "text": "So then the alternative though is self publishing and the downside, there's a lot of downsides."}, {"time": 9660, "text": "It's almost like publishing an opinion piece in the New York Times versus writing on a blog."}, {"time": 9665, "text": "There's no reason why writing a blog post on Medium can't get way more attention and legitimacy and long lasting prestige than a New York Times article."}, {"time": 9676, "text": "But nevertheless, for most people, writing in a prestigious newspaper, quote unquote prestigious, is just easier."}, {"time": 9686, "text": "And well, and depends on your goal."}, {"time": 9689, "text": "So, you know, like I push you towards a big publisher because I think your goal, it's huge ideas, you want impact."}, {"time": 9696, "text": "You're gonna have more impact."}, {"time": 9697, "text": "Even though, like actually, so there's different ways to measure impact, right?"}, {"time": 9701, "text": "In the world of ideas."}, {"time": 9704, "text": "And also, yeah, in the world of ideas, it's kind of like the clubhouse thing now, even if the audience is not large, the people in the audience are very interesting."}, {"time": 9714, "text": "It's like the conversation feels like that has long lasting impact among the people in different and disparate industries that are also then starting their own conversations and all that kind of stuff."}, {"time": 9727, "text": "Yeah, because you have other, so like self publishing a book, the goals that would solve, you have much better ways of getting to those goals, might be part of it, right?"}, {"time": 9736, "text": "So if there's the financial aspect of well, you get to keep more of it, I mean, the podcast is probably gonna crush what the book's gonna do anyways, right?"}, {"time": 9743, "text": "Yeah, if it's, I wanna get directly to certain audiences or crowds, it might be harder through a traditional publisher."}, {"time": 9750, "text": "There's better ways to talk to those crowds."}, {"time": 9752, "text": "It could be on clubhouse with all these new technologies, self published books not gonna be the most effective way to find your way to a new crowd."}, {"time": 9759, "text": "But if the idea is like, I wanna have a, leave a dent in the world of ideas, then to have a vulnerable old publisher, put out your book in a nice hardcover and do the things they do, that goes a long way."}, {"time": 9772, "text": "And they do do a lot."}, {"time": 9773, "text": "I mean, it's very difficult actually."}, {"time": 9775, "text": "There's so much involved in putting together a book."}, {"time": 9777, "text": "They get books into bookstores and all that kind of stuff."}, {"time": 9779, "text": "And from an efficiency standpoint, I mean, just the time involved in trying to do this yourself is."}, {"time": 9785, "text": "They have a process, right?"}, {"time": 9786, "text": "Like you said, they have a process."}, {"time": 9788, "text": "They've got a process."}, {"time": 9789, "text": "I mean, I know like Jocko did this recently, he started his own imprint and I have a couple other."}, {"time": 9793, "text": "But it's a huge overhead."}, {"time": 9795, "text": "I mean, if you run a business and you, so like Jocko is a good case study, right?"}, {"time": 9799, "text": "So he got fed up with Simon and Schuster dragging their feet and said, I'm gonna start my own imprint then, if you're not gonna publish my kid's book."}, {"time": 9808, "text": "But he, what does he do, he runs businesses, right?"}, {"time": 9810, "text": "So I think in his world, like I already run, I'm a partner in whatever, in Origin, and I have this and that."}, {"time": 9815, "text": "And so it's like, yeah, we can run businesses."}, {"time": 9817, "text": "That's what we know how to do."}, {"time": 9818, "text": "That's what I do."}, {"time": 9819, "text": "I run businesses, I have people."}, {"time": 9820, "text": "But for like you or I, we don't run businesses."}, {"time": 9823, "text": "It'd be terrible."}, {"time": 9824, "text": "Yeah, well, especially these kinds of businesses, right?"}, {"time": 9827, "text": "So I do wanna launch a business with very different technology business."}, {"time": 9831, "text": "Yeah, it's very, very different, yeah."}, {"time": 9833, "text": "I mean, this is like, okay, I need copy editors and graphic book binders, and I need to contract with the printer, but oh, the printer doesn't have slots."}, {"time": 9840, "text": "And so now I have to try to, I mean, it's."}, {"time": 9842, "text": "I get so, I need to shut this off in my room, but I get so frustrated when the system could clearly be improved."}, {"time": 9848, "text": "It's the thing that you're mentioning."}, {"time": 9850, "text": "It's like, this is so inefficient."}, {"time": 9852, "text": "Every time I go to the DMV or something like that, you think like, ah, this could be done so much better."}, {"time": 9858, "text": "But, and the same thing as the worry with an editor, which I guess would come from the publisher, like who would, how much supervision on your book did you receive like, hey, do you think this is too long?"}, {"time": 9874, "text": "Or do you think the title, like title, how much choice do you have in the title, in the cover, in the presentation and the branding and all that kind of stuff?"}, {"time": 9882, "text": "Yeah, I mean, all of it depends, right?"}, {"time": 9883, "text": "So when it comes on the relationship with the editor on the writing, it depends on the editor and it depends on you."}, {"time": 9891, "text": "So like at this point, I'm on my seventh book and I write for a lot of major publications."}, {"time": 9896, "text": "And at this point I have what I feel like is a voice and a level of craft that I'm very comfortable with, right?"}, {"time": 9903, "text": "So my editor is not gonna be, she kind of is gonna trust me and it's gonna be more big picture."}, {"time": 9908, "text": "Like I'm losing the thread here or this seems like it could be longer."}, {"time": 9912, "text": "Whereas the first book I wrote when I was 21, I had notes such as you start a lot of sentences with so, you don't use any contractions because I've been doing scientific writing, we don't use contractions."}, {"time": 9923, "text": "Like you should probably use contractions."}, {"time": 9925, "text": "It was way more, I had to go back and rewrite the whole thing, yeah."}, {"time": 9929, "text": "But ultimately the recommendation, I mean, we talked offline and sort of, I was thinking loosely, not really sure, but I was thinking of writing a book and there's a kind of desire to go self publishing, not for financial reasons."}, {"time": 9942, "text": "And the money can be good by the way, right?"}, {"time": 9943, "text": "I mean, it's very power law type distributed, right?"}, {"time": 9948, "text": "So the money on a hardcover is somewhere between one or $2 a book."}, {"time": 9952, "text": "So the thing is, I personally don't."}, {"time": 9953, "text": "But then you give up 15% to the agent, so."}, {"time": 9956, "text": "I personally don't care about money as I've mentioned before, but I for some reason really don't like spending money on things that are not worth it."}, {"time": 9965, "text": "Like I don't care if I get money, I just don't like spending money on like feeding a system that's inefficient."}, {"time": 9972, "text": "It's like I'm contributing to the problem."}, {"time": 9974, "text": "That's my biggest problem."}, {"time": 9976, "text": "Right, so you're worried about the inefficiencies of the opportunity."}, {"time": 9979, "text": "Yeah, the fact that."}, {"time": 9981, "text": "Like the overheads, the number of people involved."}, {"time": 9983, "text": "Or the overheads."}, {"time": 9984, "text": "The emails again."}, {"time": 9986, "text": "The fact that they have this way of speaking, which I'm allergic to many people, like that's very marketing speak."}, {"time": 9994, "text": "Like you could tell they've been having Zoom meetings all day."}, {"time": 9997, "text": "It's like as opposed to a sort of creative collaborators that are like also a little bit crazy."}, {"time": 10006, "text": "I suppose some of that is finding the right people."}, {"time": 10008, "text": "Finding the right people."}, {"time": 10008, "text": "That's what I would say."}, {"time": 10009, "text": "I'd say there's definitely, and maybe it's just good fortune."}, {"time": 10013, "text": "Good fortune in terms of like my agents and editors I've worked with."}, {"time": 10016, "text": "There's really good people who see the vision are smart or incredibly literary."}, {"time": 10022, "text": "And they actually help you."}, {"time": 10024, "text": "Like psychologically."}, {"time": 10025, "text": "Yeah, I had a great editor when I was first moving into hardcover books, for example."}, {"time": 10028, "text": "It was my first big book advance and my first sort of big deal and he was like a senior editor and it was very useful, you know?"}, {"time": 10039, "text": "He was like, we had a lot of long talks, right?"}, {"time": 10041, "text": "I was, so this was my fourth book, So Good They Can't Ignore You was my first, my big hardcover idea book."}, {"time": 10048, "text": "And we had a lot of talks, like even before I started writing it, just let's talk about books and his philosophy."}, {"time": 10054, "text": "He'd been in the business for a long time."}, {"time": 10055, "text": "He was the head of the imprint."}, {"time": 10057, "text": "It was useful."}, {"time": 10058, "text": "Yeah, but I mean, the other frustrating thing is how long the whole thing takes."}, {"time": 10062, "text": "Makes a long time."}, {"time": 10065, "text": "But I suppose that's, you just have to accept that."}, {"time": 10066, "text": "Well, yeah, I handed in this manuscript for the book that comes out now, like when this, I handed it in, I mean, over the summer, like during the pandemic."}, {"time": 10074, "text": "So it's not, it's not terrible, right?"}, {"time": 10076, "text": "And we were editing during the pandemic and I finished it in the spring."}, {"time": 10080, "text": "We've talked most of the day, except for a little bit computer science, most of the day about a productive life."}, {"time": 10087, "text": "How does love, friendship and family fit into that?"}, {"time": 10091, "text": "Is there, do you find that there's a tension?"}, {"time": 10097, "text": "Is it possible for relationships to energize the whole process, to benefit?"}, {"time": 10102, "text": "Or is it ultimately a trade off?"}, {"time": 10105, "text": "But because life is short and ultimately we seek happiness, not productivity, that we have to accept that tension."}, {"time": 10116, "text": "I mean, I think relationships is the, that's the whole deal."}, {"time": 10121, "text": "Like I thought about this the other day, I don't know what the context was."}, {"time": 10124, "text": "I was thinking about if I was gonna give like an advice speech, like a commencement address or like giving advice to young people."}, {"time": 10131, "text": "And like the big question I have for young people is if they haven't already, bad things are gonna happen that you don't control, so what's the plan, right?"}, {"time": 10141, "text": "Like, let's start figuring that out now because it's not all, you know, some people get off better than others, but eventually stuff happens, right?"}, {"time": 10149, "text": "You get sick, something falls apart, the economy craters, someone you know dies, like all sorts of bad stuff is gonna happen, right?"}, {"time": 10159, "text": "So how are we gonna do this?"}, {"time": 10160, "text": "Like, how do we like live life when life is hard?"}, {"time": 10163, "text": "And in ways that is unfair and unpredictable, then relationships is the, that's the buffer for all of that."}, {"time": 10170, "text": "Cause we're wired for it, right?"}, {"time": 10171, "text": "I went down this rabbit hole with digital minimalism."}, {"time": 10174, "text": "I went down this huge rabbit hole about the human brain and sociality."}, {"time": 10178, "text": "It's all we're wired to do."}, {"time": 10179, "text": "It's like all of our brain is for this."}, {"time": 10181, "text": "Like everything, all of our mechanisms, everything is made to service the social connections because it's what kept you alive, you know?"}, {"time": 10187, "text": "I mean, you had the, your tribal connections is how you didn't starve during a famine, people would share food, et cetera."}, {"time": 10194, "text": "And so you can't neglect that."}, {"time": 10196, "text": "And it's like everything and people feel it, right?"}, {"time": 10198, "text": "Like there's no, our social networks are hooked up to the pain center."}, {"time": 10201, "text": "That's why it feels so terrible when you miss someone or like someone dies or something, right?"}, {"time": 10205, "text": "That's like how seriously we take it."}, {"time": 10207, "text": "There's a pretty accepted theory that the default mode network, like a lot of what the default mode network is doing."}, {"time": 10212, "text": "So that's sort of the default state our brain goes into when we're not doing something in particular is practicing sociality, practicing interactions thing, because it's so crucial to what we do."}, {"time": 10222, "text": "It's like at the core of human thriving."}, {"time": 10225, "text": "So I've more recently, the way I think about it is like relationships first."}, {"time": 10230, "text": "Given that foundation of putting like, and I don't think we put nearly enough time into it."}, {"time": 10233, "text": "I worry that social media is reducing relationships, strong relationships."}, {"time": 10237, "text": "Strong relationships where you're sacrificing non trivial time and attention and resources, whatever on behalf of other people."}, {"time": 10244, "text": "That's the net that is gonna allow you to get through anything."}, {"time": 10248, "text": "Then, all right."}, {"time": 10250, "text": "Now what do we wanna do with the surplus that remains?"}, {"time": 10253, "text": "Maybe I wanna build some fire, build some tools."}, {"time": 10255, "text": "So put relationships first."}, {"time": 10257, "text": "I like the worst case analysis from the computer science perspective."}, {"time": 10261, "text": "Put relationships first."}, {"time": 10263, "text": "Yeah, because everything else is just assuming average case, assuming things kind of keep going as they were going."}, {"time": 10270, "text": "And you're neglecting the fundamental human drive."}, {"time": 10273, "text": "Like we have this, we talked about the boredom instinct."}, {"time": 10275, "text": "We wanna build things, we wanna have impact, we wanna do productivity."}, {"time": 10277, "text": "That's not nearly as clear cut of a drive of we need people."}, {"time": 10281, "text": "But if we look at the real worst case analysis here is one day you're pretty young now, but that's not gonna last very long."}, {"time": 10291, "text": "You're gonna die one day."}, {"time": 10295, "text": "Little bit."}, {"time": 10297, "text": "Well, I'm of the mindset of, let's make that a productivity hack."}, {"time": 10301, "text": "I'm of the mindset of we need to confront that soon."}, {"time": 10307, "text": "So let's do what we can now so that when we really confront and think about it, we're more likely to feel better about it."}, {"time": 10312, "text": "So in other words, let's focus now on living and doing things in such a way that we're proud of so that when it really comes time to confront that, we're more likely to say, like, okay, I feel kind of good about the situation."}, {"time": 10325, "text": "So what, when you're laying on your deathbed, would you, in looking back, what would make you think like, oh, I did okay, I'm proud of that."}, {"time": 10333, "text": "I optimized the hell out of that."}, {"time": 10335, "text": "That's a good, I mean, it's a good question to go backwards on."}, {"time": 10339, "text": "I mean, this is like David Brooks's eulogy virtues versus resume virtues."}, {"time": 10346, "text": "Right, so his argument is that, and that's another interesting DC area person."}, {"time": 10350, "text": "I keep thinking of interesting DC area people."}, {"time": 10352, "text": "All right, David Brooks is here too."}, {"time": 10356, "text": "His argument, he thinks eulogy virtues is, so what we eulogize is different than what we promote on the resume."}, {"time": 10363, "text": "That's his whole thing now, right?"}, {"time": 10364, "text": "His Suckin Mountain wrote the character."}, {"time": 10366, "text": "Both these books are, he has this whole premise of there's like this professional phase and there's a phase of giving of yourself and sacrificing on behalf of other people."}, {"time": 10375, "text": "I don't know, maybe it's all mixed together, right?"}, {"time": 10377, "text": "You wanna, I think living by a code is important, right?"}, {"time": 10380, "text": "I mean, this is something that's not emphasized enough."}, {"time": 10383, "text": "I always think of advice that my undergrad should be given that they're not given, especially at a place like Georgetown that has this like deep history of trying to promote human flourishing because of the Jesuit connection."}, {"time": 10394, "text": "There's such resiliency and pride that comes out of living well, even when it's hard, like living according to a code, living accord to, which I think religion used to structure this for people."}, {"time": 10408, "text": "But in its absence, you need some sort of replacement."}, {"time": 10410, "text": "But even when things were, soldiers get this a lot, right?"}, {"time": 10413, "text": "They experienced this a lot."}, {"time": 10414, "text": "Even when things were tough, I was able to persist in living this way that I knew was right, even though it wasn't the easiest thing to do in the moment."}, {"time": 10419, "text": "Fewer things give humans more resiliency."}, {"time": 10422, "text": "It's like having done that, your relationships were strong, right?"}, {"time": 10425, "text": "Many people coming to your funeral is a standard."}, {"time": 10427, "text": "A lot of people are gonna come to your funeral."}, {"time": 10429, "text": "I mean, you matter to a lot of people."}, {"time": 10431, "text": "And then maybe having done, to the extent of whatever capabilities you happen to be granted, and they're different for different people, and some people can sprint real fast, and some people can do math problems, try to actually do something of impact."}, {"time": 10446, "text": "I'll just promise to give gift cards to anybody who shows up to the funeral."}, {"time": 10450, "text": "You're gonna hack it."}, {"time": 10451, "text": "I'm gonna hack even the funeral."}, {"time": 10452, "text": "There's gonna be a lottery wheel you spin when you come in and someone goes away with $10,000."}, {"time": 10457, "text": "See, the problem is, with all this living by principles, living a principled life, focusing on relationships, and kind of thinking of this life as this perfect thing kind of forgets the notion that none of it makes any sense, right?"}, {"time": 10476, "text": "It kind of implies that this is like a video game and you wanna get a high score, as opposed to none of this even makes sense."}, {"time": 10485, "text": "Like, why would he, like, what that?"}, {"time": 10487, "text": "Like, what does it even mean to die?"}, {"time": 10492, "text": "It's gonna be over."}, {"time": 10493, "text": "It's like everything I do, all these productivity hacks, all this life, all these efforts, all this creative efforts, kind of assume it's gonna go on forever."}, {"time": 10502, "text": "There's a kind of a sense of immortality, and I don't even know how to intellectually make sense that it ends."}, {"time": 10508, "text": "Of course, gotta ask you in that context, what do you think is the meaning of it all, especially for a computer scientist?"}, {"time": 10514, "text": "I mean, there's gotta be some mathematical."}, {"time": 10517, "text": "Yeah, 27, or what's the, what's the Douglas Adams?"}, {"time": 10521, "text": "Yeah, or 42, okay."}, {"time": 10523, "text": "27 is a better number."}, {"time": 10524, "text": "I should read more sci fi."}, {"time": 10526, "text": "Maybe you're onto something with a 27."}, {"time": 10528, "text": "I don't wanna give away too much, but just trust me, 27."}, {"time": 10531, "text": "It's visible, yeah."}, {"time": 10534, "text": "So, I mean, I don't know, obviously, right?"}, {"time": 10537, "text": "I mean, I'm a..."}, {"time": 10538, "text": "I was hoping you would."}, {"time": 10538, "text": "Yeah, I don't know, but going back to what you were saying about the sort of the existentialist, or sort of the more nihilist style approach, the one thing that there is are intimations, right?"}, {"time": 10550, "text": "So that there's these intimations that human halves of somehow this feels right, and this feels wrong, this feels good, this feels like I'm doing, I'm aligned with something, you know, when I'm acting with courage to save, whatever, right?"}, {"time": 10563, "text": "It's not, these intimations are a grounding against arbitrariness."}, {"time": 10567, "text": "Like, one of the ideas I'm really interested in is that when you look at religion, right?"}, {"time": 10573, "text": "So I'm interested in world religions."}, {"time": 10575, "text": "My grandfather was like a theologian that studied and wrote all these books, and I'm very interested in this type of stuff."}, {"time": 10581, "text": "And there's this great book that's, it's not specific to a particular religion, but it's Karen Armstrong wrote this great book called The Case for God."}, {"time": 10590, "text": "She's very interesting."}, {"time": 10591, "text": "She was a Catholic nun who sort of left that religion, but one of the smartest thinkers in terms of like accessible theological thinking that's not tied to any particular religion."}, {"time": 10602, "text": "Her whole argument is that the way to understand religion, first of all, you have to go way back pre enlightenment where all this was formed."}, {"time": 10608, "text": "We got messed up thinking about religion post enlightenment, right?"}, {"time": 10611, "text": "And these were operating systems for making sense of intimations."}, {"time": 10617, "text": "The one thing we had were these different intimations of this field, like awe and mystical experience."}, {"time": 10623, "text": "And this feels, there's something you feel when you act in a certain way and don't act in this other way."}, {"time": 10628, "text": "And it was like the scientists who were trying to study and understand the model of the atom by just looking at experiments and trying to understand what's going on."}, {"time": 10636, "text": "Like the great religions of the world were basically figuring out how do we make sense of these intimations and live in alignment with them and build a life of meaning around that."}, {"time": 10644, "text": "What were the tools they were using?"}, {"time": 10646, "text": "They were using ritual."}]}, {"title": "Saagar Enjeti: Politics, History, and Power | Lex Fridman Podcast #167", "id": "grceJbuPUXI", "quotes": [{"time": 317, "text": "I think he worked at it."}, {"time": 319, "text": "But also, there is an innate quality."}, {"time": 321, "text": "I'm forgetting his name, his lifelong, Rudolf, the one who flew to Berlin in like 1940."}, {"time": 327, "text": "I forget his name, anyway."}, {"time": 329, "text": "So he helped Hitler write Mein Kampf."}, {"time": 331, "text": "And he was like slavishly devoted to him in prison."}, {"time": 335, "text": "This is 1925 or something like that."}, {"time": 338, "text": "And so you read that and you're like, well, how does he get this like crank wacko to basically believe he's like the second coming, help him write this book?"}, {"time": 346, "text": "I mean, literally, they live together in the prison cell and they wake up every day."}, {"time": 350, "text": "And as he was composing Mein Kampf and because of the Beer Hall Putsch and all that, had this like absolute ability to gather people around him."}, {"time": 359, "text": "I think his greatest skill was, is he was just a very good politician, truly."}, {"time": 363, "text": "I mean, if you look at his ability in order to read coalitional politics and then convince exactly the right people in order to follow him."}, {"time": 372, "text": "I think I heard you ask this once and I've thought about it a lot, which is like, who could have stopped Hitler in Germany?"}, {"time": 377, "text": "It's always like the ever present question."}, {"time": 379, "text": "Of course, like the whole baby Hitler thing."}, {"time": 381, "text": "Really the answer is Hindenburg."}, {"time": 382, "text": "Like Hindenburg was the person who could have stopped and had the immense standing within the German public."}, {"time": 387, "text": "The only real like war hero definitely was personally skeptical of fascism and Nazism."}, {"time": 394, "text": "And didn't like Hitler."}, {"time": 395, "text": "And didn't like him and he knew he was full of shit."}, {"time": 398, "text": "He was like, yeah, I think this guy is dangerous."}, {"time": 400, "text": "I think this guy could do a lot of damage to the Republic."}, {"time": 403, "text": "But he acceded basically to Hitler at the time."}, {"time": 406, "text": "And I think that he was one of the main people who could have done something about it."}, {"time": 410, "text": "And also he was able to convince the generals, the military."}, {"time": 413, "text": "I mean, that was very interesting."}, {"time": 416, "text": "And to convince Chamberlain and the other political leaders."}, {"time": 421, "text": "That's something I often think about because we're just reading books about these people."}, {"time": 426, "text": "I think about what like Jeffrey Epstein, for example."}, {"time": 429, "text": "Like evil people, not evil, but people have done evil things."}, {"time": 434, "text": "Let's not go to the Dan Carlin thing of what is evil."}, {"time": 439, "text": "People that do evil things, I wonder what they are like in a room because I know quite a lot of intelligent people that did not see the evil in Jeffrey Epstein and spend time with them."}, {"time": 455, "text": "And were not bothered by it."}, {"time": 457, "text": "In the same sense, Hitler, it seems like he was able to get, just even before he had power, because people get intoxicated by power and so on."}, {"time": 468, "text": "They want to be close to power."}, {"time": 469, "text": "But even before he had power, he was able to convince people."}, {"time": 473, "text": "And it's unclear, like is there something that's more than words?"}, {"time": 478, "text": "It's like the way you, I mean, people talk, tell stories about like this piercing look and whatever, all that kind of stuff."}, {"time": 486, "text": "I wonder if that's somehow a part of it."}, {"time": 490, "text": "Like that has to be the base floor of any of these charismatic leaders."}, {"time": 494, "text": "You have to be able to, in a room alone, be able to convince anybody of anything."}, {"time": 500, "text": "So I can tell you from my personal experience, one of the best educated lessons I got was when I got to meet Trump."}, {"time": 509, "text": "So I interviewed Trump four different times as a journalist, spent like two and a half hours with him in the Oval Office, not alone, but like me and one person and like the press secretary, and that was it."}, {"time": 520, "text": "So I actually got to observe him."}, {"time": 522, "text": "And as a guy who reads these types of books, and you think of Trump, obviously most people, what they see on television, in articles and more, but being able to observe it like one on one, I was closer to him than I am right now from you."}, {"time": 537, "text": "That was one of the most educational experiences I got because it's like you just said, the look, the leaning forward, the way he talks, the way he is a master at taking the question and answering exactly which party wants."}, {"time": 554, "text": "And then if you try and follow up, he's like, excuse me, you know, like he knows."}, {"time": 558, "text": "And then whenever you're talking, it's not that he's annoyed about getting interrupted."}, {"time": 562, "text": "If he realizes he's been mirandering and then you interrupt him, all good."}, {"time": 566, "text": "But if he's driving home a point, which he has to make sure appears in your transcript or whatever, it really was fascinating for me to look at."}, {"time": 576, "text": "And what was also crazy with Trump is I realized how much he was living in the moment."}, {"time": 581, "text": "So when I went to the Oval, I've read all these biographies and I walk in, I'm like, holy shit, you're like, I'm in the Oval Office."}, {"time": 590, "text": "Were you interviewing him in the Oval Office?"}, {"time": 592, "text": "In the Oval, every time, I was in the Oval Office."}, {"time": 593, "text": "You scared shitless?"}, {"time": 594, "text": "Well, I wasn't scared."}, {"time": 596, "text": "I was just, look, it's the Oval Office, right?"}, {"time": 599, "text": "I mean, I'm this nerd."}, {"time": 601, "text": "He was like this kid, I'm so, I will admit this here."}, {"time": 605, "text": "I printed out on my dad's label maker when I was like seven and I wrote the Oval Office on my bedroom."}, {"time": 610, "text": "So I was a huge nerd, obviously egomaniacal, even from seven."}, {"time": 614, "text": "But so for this, I mean, it was huge, right?"}, {"time": 616, "text": "I'm like this 25 year old kid."}, {"time": 618, "text": "And I walk in there and I see the couch, right?"}, {"time": 622, "text": "And I'm like, oh man, that's Kissinger."}, {"time": 625, "text": "That's where Kissinger and Nixon got on their knees."}, {"time": 628, "text": "And then you see over by the door and you're like, are the scuff marks still there from when Eisenhower used to play golf?"}, {"time": 633, "text": "You know, this is all running through my mind."}, {"time": 634, "text": "With Trump, none of it was there, none of it, right?"}, {"time": 636, "text": "So like, even the desk, I put my phone on the desk to record and I'm like, this is the fucking Resolute desk."}, {"time": 643, "text": "Like, I shouldn't put my phone on this thing, right?"}, {"time": 646, "text": "And I'm like HMS Resolute, you know, all the international."}, {"time": 649, "text": "And even for him, he doesn't think about any of it."}, {"time": 651, "text": "It was like amazing to me."}, {"time": 653, "text": "Like he had this portrait of Andrew Jackson right next to his, to the, I think from on the fireplace, like right here on the right."}, {"time": 659, "text": "And the most revealing question was when I was like, Mr. President, what are people gonna remember you for in a hundred years?"}, {"time": 665, "text": "And he was like, I don't know, like veteran's choice."}, {"time": 669, "text": "He like has a list in front of him of like his accomplishments, which is staff."}, {"time": 674, "text": "Yeah, well, I mean, that's what I wanted to know."}, {"time": 677, "text": "And he's like, veteran's choice."}, {"time": 678, "text": "And I remember looking at him being like, it's not gonna be veteran's choice."}, {"time": 682, "text": "I'd be like, I'm like, I'm looking at you, Donald Trump, the harbinger of something new."}, {"time": 687, "text": "We still don't know what the hell it is."}, {"time": 689, "text": "And so I realized with these guys and their charisma and more is that they don't think about themselves the way that we think about them."}, {"time": 697, "text": "And that was actually important to understand because a lot of people are like, Trump is playing all this chess."}, {"time": 701, "text": "I'm like, I assure you he's not."}, {"time": 703, "text": "Like he's truly, one time I was interviewing him and he had like a certificate that he had to sign or something on his desk."}, {"time": 709, "text": "He's like, it was like child almost."}, {"time": 711, "text": "Like he got distracted by, he's like, oh, what's this?"}, {"time": 713, "text": "You know, he's just like picking up and I was like, wow, like this, this is the guy."}, {"time": 717, "text": "Like this is what he is."}, {"time": 719, "text": "Well, I wonder if there was a different person because you were recording then offline at a party."}, {"time": 725, "text": "I can tell you."}, {"time": 726, "text": "Well, here's the thing though, because that's another part of it."}, {"time": 729, "text": "Because that two hours, I would say like half of that was not on the record."}, {"time": 733, "text": "So like, whenever he's off the record, he changes completely, right?"}, {"time": 737, "text": "I don't wanna like go into too much of it or whatever, but like he, I mean, he is so mindful of when that camera is on and when the mic is hot in terms of the language that he uses, what he's willing to admit, what he's willing to talk about, how he's willing to even appear in front of his staff."}, {"time": 757, "text": "I think the most revealing thing Trump ever did was there was this press conference, like right after he lost the, right after the midterm elections in 2018."}, {"time": 766, "text": "And one of the journalists was like, Mr. President, thank you for doing this press conference."}, {"time": 770, "text": "And he looks at him and he goes, it's called earned media, it's worth billions."}, {"time": 774, "text": "And he just like had so much disdain for him because he's like, I'm not doing this for you."}, {"time": 779, "text": "He's like, I'm doing this for me."}, {"time": 780, "text": "So he's really aware of the narrative of the story."}, {"time": 783, "text": "I mean, that the people have talked about that all comes from the tabloid media of the, from New York and so on."}, {"time": 789, "text": "He's a master of that."}, {"time": 790, "text": "But I've also heard stories of just in private, he's a really, I don't wanna overuse the word charismatic, but just like, he is a really interesting, almost like friendly, like a good person."}, {"time": 805, "text": "Like, that's what I heard."}, {"time": 808, "text": "I've heard actually surprising the same thing about Hillary Clinton."}, {"time": 812, "text": "And like."}, {"time": 813, "text": "That I can't tell you anything about."}, {"time": 815, "text": "But like the way they present themselves is perhaps very different than they are as human beings and one on one."}, {"time": 822, "text": "That's something, maybe that's just like a skill thing."}, {"time": 826, "text": "Maybe the way they present themselves in public is actually their, I mean, almost their real self."}, {"time": 835, "text": "And they're just really good in private, one on one to go into this mode of just being really intimate in some kind of human way."}, {"time": 843, "text": "I think that's part of it."}, {"time": 844, "text": "Because I noticed that with Trump, you know, he's like, it's almost like a tour guide."}, {"time": 848, "text": "It was very like, it's very crazy, right?"}, {"time": 851, "text": "Cause you're like, you're in the Oval."}, {"time": 852, "text": "I mean, it's his office."}, {"time": 853, "text": "And he's like, do you guys want anything?"}, {"time": 855, "text": "And he's like, you want a Diet Coke?"}, {"time": 856, "text": "Cause he drinks like all this Diet Coke."}, {"time": 860, "text": "And he's just like, you guys want a Diet Coke, right?"}, {"time": 863, "text": "And you're sitting there and you're like, the way he's able to like, like the last time I interviewed him, he wanted to do it outside."}, {"time": 873, "text": "Because he like, he's studied himself from all angles."}, {"time": 876, "text": "And he knows exactly how he looks on a camera and with which lighting."}, {"time": 879, "text": "And so we were supposed to interview him on camera in the Oval Office, which is actually rare."}, {"time": 883, "text": "Like you don't usually get that."}, {"time": 885, "text": "And they ended up moving it outside at the last minute."}, {"time": 888, "text": "And he came out and he's like, I picked this spot for you."}, {"time": 890, "text": "He's like, great lighting."}, {"time": 892, "text": "I was like, you are your own like lighting director."}, {"time": 896, "text": "The president, right?"}, {"time": 897, "text": "It's so funny."}, {"time": 898, "text": "But it's like you said, he's very charismatic and friendly."}, {"time": 904, "text": "I mean, you wouldn't know."}, {"time": 905, "text": "I mean, look, this is what I mean in terms of the dynamism of these people that gets lost."}, {"time": 910, "text": "And I think even he knows that."}, {"time": 912, "text": "Like, I don't think he would want that side of him."}, {"time": 914, "text": "That I see, you know, that you see in those off the record moments and more in order to come out because he's very keen about how exactly he presents to the public."}, {"time": 923, "text": "It's like, you know, even his presidential portrait, everybody usually smiles and he refused to smile."}, {"time": 927, "text": "He was like, I want to look like Winston Churchill."}, {"time": 929, "text": "You know, like even he knew that."}, {"time": 931, "text": "Do you think he believes that he, what he kind of implies that he is one of, if not the greatest president in American history?"}, {"time": 941, "text": "Like people kind of laugh at this, but there's quite, I mean, there's quite a lot of people, first of all, that make the argument that he's the greatest president in history."}, {"time": 950, "text": "Like I've heard this argument being made."}, {"time": 953, "text": "And I mean, I don't know what the, first of all, I don't care."}, {"time": 957, "text": "Like, you can't make an argument that anyone is the greatest."}, {"time": 962, "text": "That's just, that just, I come from a school of like being humble and modest and so on."}, {"time": 968, "text": "It's like, even Michael, you can't have that conversation."}, {"time": 971, "text": "Okay, so I like that he's humble enough to say like Abraham Lincoln or whatever."}, {"time": 977, "text": "Like, I don't know."}, {"time": 978, "text": "He says maybe Lincoln."}, {"time": 979, "text": "Remember that."}, {"time": 982, "text": "Do you think he actually believes that?"}, {"time": 984, "text": "Or is that something he understands will create news and also perhaps more importantly, piss off a large number of people?"}, {"time": 995, "text": "Is he almost like a musician masterfully playing the emotions of the public?"}, {"time": 1001, "text": "Or does he, or, and does he believe when he looks in the mirror, I'm one of the greatest men in history?"}, {"time": 1009, "text": "Combination of all three."}, {"time": 1011, "text": "I do think he believes it."}, {"time": 1012, "text": "And for the reason why is I don't think he knows that much about US history."}, {"time": 1015, "text": "I really mean that."}, {"time": 1016, "text": "Like, and that's what I meant whenever I was in there and I realized he was just living in the moment."}, {"time": 1021, "text": "I don't think he knew all that much about why."}, {"time": 1023, "text": "I mean, this is why he was elected in many ways, right?"}, {"time": 1026, "text": "So I'm not saying this is an orbit, like I'm not making a judgment on this."}, {"time": 1030, "text": "I'm just saying, I do think in his mind, he does think he was one of the best presidents in American history largely because, and I encountered this with a lot of people who work for him, which is that they didn't really know all that much kind of about what came before and all that."}, {"time": 1045, "text": "And it's not necessarily to hold it against them because for in many ways, that's what they were elected to do or elected to be in many ways."}, {"time": 1052, "text": "It's an interesting question whether knowing history, being a student of history is productive or counterproductive."}, {"time": 1060, "text": "I tend to assume I really respect people who are deeply like well read in history, like presidents that are almost like history nerds."}, {"time": 1071, "text": "I admire that."}, {"time": 1073, "text": "But maybe that gets in the way of governance."}, {"time": 1077, "text": "It's not, I'm just sort of playing devil's advocate to my own beliefs, but it's possible that focusing on the moment and the issues and letting history, it's like first principles thinking, forget the lessons of the past and just focus on common sense reasoning through the problems of today."}, {"time": 1096, "text": "Yeah, it's really hard question."}, {"time": 1098, "text": "In terms of the modern era, I mean, Obama was a student of history."}, {"time": 1123, "text": "So in that way, I was a little pissed off because I'd be like, no, that actually like, you're comparing apples to oranges and all that."}, {"time": 1130, "text": "But if you look at Roosevelt, Teddy Roosevelt in particular, this was, I mean, a voracious reader, not of just American history, all history."}, {"time": 1139, "text": "That guy's just such a badass."}, {"time": 1143, "text": "The only president who willed himself to greatness."}, {"time": 1147, "text": "That's like the amazing thing about him."}, {"time": 1148, "text": "He wasn't tested by a crisis, right?"}, {"time": 1150, "text": "Like it wasn't, no, he didn't have a civil war."}, {"time": 1152, "text": "He didn't have World War II."}, {"time": 1153, "text": "He didn't have to found the country, literally, or like, didn't have to stave off that, or he didn't buy Louisiana Purchase, like all that."}, {"time": 1160, "text": "He literally came into a pretty static country and he could have just governed with, I mean, he was, the person who came before him was assassinated, like he easily could have coasted, but he literally willed the country into something more."}, {"time": 1177, "text": "And that's always why I've focused a lot on him too, because I'm like, that, in many ways, I wouldn't say it's easy to be great during crisis."}, {"time": 1184, "text": "I mean, like look at Trump, right?"}, {"time": 1186, "text": "But it can bring out the best within you, but it's a whole other level to bring out the best within yourself just for the sake of doing it."}, {"time": 1194, "text": "That's, I think is really interesting."}, {"time": 1196, "text": "The speeches were amazing."}, {"time": 1198, "text": "I'm also a sucker for great speeches because I tend to see the role of the president as in part like inspirer in chief, sort of to be able to, I mean, that's what great leaders do, like CEOs of companies and so on, establish a vision, a clear vision, and like hit that hard."}, {"time": 1219, "text": "But the way you establish the vision isn't just like, not to dig at Joe Biden, but like sleepy, boring statements."}, {"time": 1229, "text": "You have to sell those statements and you have to do it in a way where everybody's paying attention."}, {"time": 1235, "text": "Everybody's excited."}, {"time": 1236, "text": "And that, Teddy Roosevelt was definitely one of them."}, {"time": 1240, "text": "Obama was, I think, at least early on, I don't know, was incredible at that."}, {"time": 1247, "text": "It does feel that the modern political landscape makes it more difficult to be inspirational in a sense because everything becomes bickering and division."}, {"time": 1255, "text": "I do want to ask you about Trump."}, {"time": 1260, "text": "So you're now a successful podcaster."}, {"time": 1263, "text": "I've talked to Joe about Trump, Joe Rogan, and Joe's not interested in talking to Trump."}, {"time": 1271, "text": "It's just fascinating."}, {"time": 1272, "text": "I try to dig into like why."}, {"time": 1276, "text": "What would you interview Trump on like realignment, for example, and do you think it's possible to do a two, three hour conversation with him where you will get at something like human or you get at something, like when we're talking about the facade he puts forward, do you think you could get past that?"}, {"time": 1299, "text": "I look, I was a White House correspondent."}, {"time": 1301, "text": "I observed this man very closely."}, {"time": 1305, "text": "I interviewed him."}, {"time": 1306, "text": "I think if that mic is hot, he knows what he's doing."}, {"time": 1309, "text": "He just, he's done this too long, Lex."}, {"time": 1312, "text": "He just knows."}, {"time": 1312, "text": "But do you think he's a different human now after the election?"}, {"time": 1316, "text": "Yeah, not at all."}, {"time": 1319, "text": "I think he's been the same person since 1976."}, {"time": 1323, "text": "Like basically, 1976, I studied Trump a lot and I think he's basically been the core of who he is and elements of that."}, {"time": 1332, "text": "Ever since he built that, you know, the ice rink in Central Park and got that media attention, that was it."}, {"time": 1339, "text": "Yeah, he's a fascinating study."}, {"time": 1340, "text": "Still, I feel there's a hope in me that there would be a podcast like a Joe Rogan, like a long form podcast where it's something could be, you know, and you're actually a really good person to do that, where you can have a real conversation that looks back at the election and reveal something on us."}, {"time": 1360, "text": "But perhaps he's thinking about running again and so maybe he'll never let down that guard."}, {"time": 1366, "text": "But like, you know, I just love it when there's this switch in people where you start looking back at your life and wanting to tell stories."}, {"time": 1377, "text": "Like, you know, trying to extract wisdom and like realizing you're in this new phase of life where like the battles have all been fought, now you're this old, like former warrior and now you can tell the stories of that time."}, {"time": 1392, "text": "And it seems like Trump is still at it, like the young warrior he is, he's not in the mode of telling stories."}, {"time": 1398, "text": "You know what I got from Rogan?"}, {"time": 1399, "text": "He's the only president who didn't age well in office."}, {"time": 1403, "text": "Like, and this is what I mean, because he lives in the moment, like the job actually aged Obama, I mean, Bush, same thing, even Clinton."}, {"time": 1412, "text": "Clinton was like fat, it looked miserable by like 2000."}, {"time": 1416, "text": "HW, like, I mean, Reagan, famous, actually, yeah, pretty much everybody I think about, including John F. Kennedy, who got much sicker while in office."}, {"time": 1425, "text": "The job like weighs on you and makes you physically ill. Trump was, he's the only person who just didn't happen to."}, {"time": 1433, "text": "He almost gotten stronger and he was one of the most, like the climate, there's so many people attacking him, so much hatred, so much love and hatred."}, {"time": 1443, "text": "And it was just, I mean, it was whatever it was, it was quite masterful and a fascinating study."}, {"time": 1450, "text": "If we stick on Hitler for just a minute, what lessons do you take from that time?"}, {"time": 1460, "text": "Do you think it's a unique moment in human history, that World War II, I mean, both Stalin and Hitler, you know, is it something that's just an outlier in all of human history in terms of the atrocities, or is there lessons to be learned?"}, {"time": 1480, "text": "You mentioned offline that you're not just a student of the entirety of the history, but you also are fascinated by just different like policies and stuff."}, {"time": 1490, "text": "Like, what's the immigration policy?"}, {"time": 1492, "text": "What's the policy on science?"}, {"time": 1493, "text": "And... Third Reich in power, let me plug it, by Richard Evans, I think is what it was."}, {"time": 1498, "text": "Cause that actually will tell you, like what was it like to live under the Nazi regime without the war?"}, {"time": 1505, "text": "Yeah, it's a hard question in terms of the lessons that we can learn."}, {"time": 1508, "text": "Cause there's a lot, and it's actually been over, it's been over indexed almost."}, {"time": 1513, "text": "Everything comes back to Hitler in a conversation."}, {"time": 1515, "text": "So I kind of think of it within Mao, Stalin, and Hitler as, I don't wanna say payments for, but like the end point payment for the sins and the problems of the monarchical system that evolve within Europe."}, {"time": 1535, "text": "Basically like 1400 and more."}, {"time": 1538, "text": "I basically think that 1400, the wars between France, England, the balance of power, eventually World War I, and then serfdom within Russia, the Russian revolution that birthed Stalin."}, {"time": 1552, "text": "Same thing, the Kaiser and Imperial Germany and this like incredibly crazy system of balance of power in World War I."}, {"time": 1559, "text": "And then same thing within China in terms of the warring states and then the disintegration, the European, you know, this is how they think of it."}, {"time": 1568, "text": "Which is like the century of humiliation and they had to have something like this."}, {"time": 1572, "text": "I think of it, I try to think of it within the context of that."}, {"time": 1575, "text": "I don't wanna sound like an inevitablist, but I think of it as, I like to think about systems, especially here in DC, that's where I got into politics, which is that you have to understand systems of power and the incentives within systems and the disincentives, the downside risk of what you're creating because that is what leads and creates the behavior within that system."}, {"time": 1603, "text": "I was just talking to my girlfriend about this yesterday."}, {"time": 1605, "text": "It's kind of funny, like I read these, I'm obsessed with these books by Robert Caro, the biographies of Lyndon Johnson."}, {"time": 1612, "text": "He's written like 5,000 pages so far and it's still not done."}, {"time": 1615, "text": "Okay, so like these are like books I base my life on."}, {"time": 1619, "text": "And look, these are Washington and the story of the post New Deal era and forward."}, {"time": 1625, "text": "Not much has changed."}, {"time": 1626, "text": "Like the Senate is still the Senate."}, {"time": 1629, "text": "So many of the same problems with the Senate are still there in some cases."}, {"time": 1633, "text": "No, not anymore."}, {"time": 1634, "text": "But for a while, some of the people who were there with Johnson are actually still, one of them is the president of the United States, just a joke."}, {"time": 1641, "text": "And you think about also, same with the media relationship, right?"}, {"time": 1646, "text": "Like there's this media really, they may have come and gone."}, {"time": 1649, "text": "Like the people who were in the media and who were cozy with the administration officials, I mean, they just recreated themselves."}, {"time": 1657, "text": "It's like an ecosystem which doesn't change."}, {"time": 1661, "text": "And that's why I'm like, oh, it's not that was a specific time."}, {"time": 1666, "text": "That's just DC."}, {"time": 1667, "text": "Like that is DC because of the way the system is architected."}, {"time": 1673, "text": "It's pretty much been that way since like 1908, whenever like Teddy Roosevelt was dining with these journalists and he would yell at them."}, {"time": 1679, "text": "And then he would go over to the society house."}, {"time": 1682, "text": "And like in many ways, that's now instead of going to Henry Adams's house, like the people are congregating in Calorama, which is the richest neighborhood here at somebody else's house."}, {"time": 1693, "text": "Like it's the same thing."}, {"time": 1694, "text": "So you have to think about the system and then the incentives within that system about what the outcomes that they're producing."}, {"time": 1700, "text": "If you actually wanna think about how can I change this from the outside?"}, {"time": 1703, "text": "That's also why it's very difficult to change because the system is designed in order to produce actually pretty specific outcomes that can only be changed in extraordinary times."}, {"time": 1713, "text": "Yeah, and sometimes it's hard to predict what kind of outcomes will result from the incentive, the system that you create, right?"}, {"time": 1722, "text": "In the case, because especially when it's novel kind of situations."}, {"time": 1726, "text": "With Trump, he actually created a pretty novel situation."}, {"time": 1729, "text": "And a lot of the things that we've seen in the 20th century were very novel systems where people were very optimistic about the outcomes, right?"}, {"time": 1739, "text": "And then it turned out to not have the results that they predicted."}, {"time": 1744, "text": "In terms of things being unchanged for the past 100 years and so on, can you like Wikipedia style or maybe like in a musical form, like I'm only a bill, describe to me."}, {"time": 1757, "text": "I still sing that to my head sometimes."}, {"time": 1760, "text": "I'm just a bill."}, {"time": 1765, "text": "I don't know what the rest of the song is, but let's leave that to people's imagination."}, {"time": 1770, "text": "How does this whole thing work?"}, {"time": 1773, "text": "How does the US political system work?"}, {"time": 1775, "text": "The three branches is how do you think about the system we have now?"}, {"time": 1780, "text": "If you were to try to describe, if aliens showed up and asked you like, they didn't have time, so this is an elevator thing."}, {"time": 1789, "text": "Should we destroy you as you plead to avoid destruction?"}, {"time": 1795, "text": "Well, how would you describe how this thing works?"}, {"time": 1798, "text": "I would say we come together and we pick the people who make our laws."}, {"time": 1803, "text": "Then we pick the guy who executes those laws and they together pick the people who determine whether they or the president is breaking the law at the most basic level."}, {"time": 1816, "text": "That's how I would describe it."}, {"time": 1820, "text": "So the people who make the laws are Congress."}, {"time": 1822, "text": "The executive is charged with executing the laws as passed by Congress, the system, the branches of government, and the Supreme Court is picked by the president, confirmed by the Senate, which then decides whether you or other people are breaking the law in terms of interpretation of that law."}, {"time": 1841, "text": "That's basically it."}, {"time": 1842, "text": "Oh, and they decide whether those laws are in, they fall within the restrictions and the want of the founders as expressed by the Constitution of the United States, which is a set of principles that we came together in 1787."}, {"time": 1866, "text": "I want to make sure I get this right, 1787, and decided that we were going to live the rest of our lives barring a revolution and more."}, {"time": 1874, "text": "And we've made it 200 and something years in order on under that system."}, {"time": 1878, "text": "So there's a balance of power that's because it's multiple branches."}, {"time": 1882, "text": "There's a tension and a balance to it as designed by those original documents."}, {"time": 1888, "text": "What, which is the most dysfunctional, the branches, which is your favorite?"}, {"time": 1892, "text": "Like in terms of talking about systems and like what's the greatest of concern and what is the greatest source of benefit in your view?"}, {"time": 1901, "text": "The presidency, obviously, well, the presidency is my favorite to study, obviously, because it is the one where there's the most subjective variable change in terms of the personality involved because of so much power imbued within the executive."}, {"time": 1916, "text": "The Senate is actually pretty much the same."}, {"time": 1919, "text": "That's one of the things I love about reading about the Senate and histories of the Senate is you're like, oh yeah, there were always like assholes in the Senate who were doing their thing and filibustering constantly based upon this or that."}, {"time": 1935, "text": "And then the personalities involved with the Senate haven't mattered as much since like pre civil war, right?"}, {"time": 1943, "text": "Like pre civil war, you had like Henry Clay and then Daniel Webster and John C. Calhoun, who even in their own way, they represented like larger constituencies and they crafted these like compromises up until the outbreak of the civil war, et cetera."}, {"time": 1957, "text": "But like post since then, you don't think about like the Titans within the Senate."}, {"time": 1962, "text": "Most of that is because a lot of the stuff that they had power over has transferred over to the executive."}, {"time": 1967, "text": "So I'm most interested in really in like power, like where it lies."}, {"time": 1972, "text": "It's actually pretty, you know, throughout American history, much more used to lie with Congress."}, {"time": 1976, "text": "Now it's obviously just so imbued within the executive that understanding executive power is I think the thing I'm probably most interested in here."}, {"time": 1984, "text": "Do you think at this point, the amount of power that the president has is corrupting to their ability to lead well?"}, {"time": 1992, "text": "Is this, you know, power corrupts, absolute power corrupts, absolutely."}, {"time": 1997, "text": "Are we, is there too much power in the presidency?"}, {"time": 2001, "text": "There definitely is."}, {"time": 2002, "text": "And part of the problem, one of the things I try to make come across to people is if you're the president, unless you have a hyper intentional view of how something must be different in government, your view doesn't matter."}, {"time": 2017, "text": "So for example, like if you were Trump, let's take Trump even, and even in with a pretty intentional view, he was like, I'm gonna end the war in Afghanistan and Iraq, right?"}, {"time": 2027, "text": "And he came in and he gets these generals in."}, {"time": 2029, "text": "He's like, I wanna end the war in Afghanistan and Iraq."}, {"time": 2032, "text": "Oh, and I wanna withdraw these troops from Syria."}, {"time": 2034, "text": "And they're like, okay, we'll give you, give us like six months."}, {"time": 2037, "text": "He's like, okay."}, {"time": 2038, "text": "And this is the thing about Trump."}, {"time": 2038, "text": "He doesn't realize that it's bullshit."}, {"time": 2040, "text": "So they're like, he's like, oh, six months seems fun, right?"}, {"time": 2043, "text": "So then six months comes and he's like, he's like, so, and then he'll announce it."}, {"time": 2047, "text": "He'll be like, and we're getting out of Syria."}, {"time": 2050, "text": "And then the generals freak out."}, {"time": 2051, "text": "They're like, whoa, whoa, whoa."}, {"time": 2052, "text": "We don't have a plan for that."}, {"time": 2053, "text": "He's like, but you guys told me six months."}, {"time": 2055, "text": "He's like, I don't know, now we need another six months in order to figure this thing out."}, {"time": 2058, "text": "And by that time, now you're midterms."}, {"time": 2059, "text": "So now what?"}, {"time": 2060, "text": "Now you gotta run for reelection."}, {"time": 2062, "text": "So more what I mean by that is, if you don't have a hyperintentional view about how to change foreign policy, if you don't have a hyperintentional view about how the Department of Commerce should do its job, they are just gonna go on autopilot."}, {"time": 2073, "text": "So this is part of the problem."}, {"time": 2075, "text": "When you asked me about the presidency, it's not the presidency itself, like the president himself, which has become too powerful."}, {"time": 2083, "text": "It's that we have less democratic checks on the people and the systems that are on autopilot."}, {"time": 2091, "text": "And I would say that basically since 2008, we have voted every single time to disrupt that system, except in the case of 2020 with Joe Biden, and there are a lot of different reasons around why that happened."}, {"time": 2106, "text": "And in every single one of those cases, Obama and Trump, they all failed in order to radically disrupt that."}, {"time": 2114, "text": "And that just shows you how titanic the task is."}, {"time": 2117, "text": "And I'm using my language precisely because I don't wanna be like deep state, but obviously there's deep state."}, {"time": 2122, "text": "Deep state, I guess, has conspiratorial intentions to it."}, {"time": 2126, "text": "But so what you're saying is the true power currently lies with the autopilot, AKA deep state."}, {"time": 2132, "text": "Well, but see, this is the thing too I wanna make clear, because I think people think conspiratorially that they're all coming together to intentionally do something."}, {"time": 2143, "text": "They are doing what they know, believe they are right, and don't have real democratic checks within that."}, {"time": 2150, "text": "And so now they have entire generations of cultures within each of these bureaucracies where they say, this is the way that we do things around here."}, {"time": 2159, "text": "And that's the problem, which is that we have a culture of within many of these agencies and more."}, {"time": 2166, "text": "I think the best example for this would be during the Ukraine gate with Trump and all that, with the impeachment."}, {"time": 2175, "text": "I'm not talking about the politics here, but the most revealing thing that happened was when the whistleblower guy, Alexander Vindman, was like, here you have the president departing from the policy of the United States."}, {"time": 2187, "text": "And I was like, well, let me educate you, Lieutenant Colonel."}, {"time": 2192, "text": "The president of the United States makes American foreign policy."}, {"time": 2196, "text": "But it was a very revealing comment because he and all the people within national security bureaucracy do think that."}, {"time": 2204, "text": "They're like, this is the policy of the United States."}, {"time": 2206, "text": "We have to do this."}, {"time": 2208, "text": "That's where things get screwy."}, {"time": 2209, "text": "Well, listen, for me personally, but also from an engineering perspective, I just talked to Jim Keller."}, {"time": 2214, "text": "It's just, this is the kind of bullshit that we all hate when you're trying to innovate and design new products."}, {"time": 2222, "text": "So that's what first principles thinking requires."}, {"time": 2225, "text": "It's like, we don't give a shit what was done before."}, {"time": 2229, "text": "The point is, what is the best way to do it?"}, {"time": 2231, "text": "And it seems like the current government, government in general, probably, bureaucracies in general, are just really good at being lazy without never having those conversations."}, {"time": 2243, "text": "And just, it becomes this momentum thing that nobody has the difficult conversations."}, {"time": 2249, "text": "It's become a game within a certain set of constraints and they never kind of do revolutionary tasks."}, {"time": 2254, "text": "But you did say that the presidency is power, but you're saying that more power than the others, but that power has to be coupled with focused intentionality."}, {"time": 2266, "text": "You have to keep hammering the thing."}, {"time": 2268, "text": "If you want it done, it has to be done."}, {"time": 2271, "text": "I mean, and you gotta, this is the other part too, which is that it's not just that you have to get it done."}, {"time": 2277, "text": "You have to pick the 100 people who you can trust to pick 10 people each to actually do what you want."}, {"time": 2286, "text": "One of the most revealing quotes is from a guy named Tommy Corcoran."}, {"time": 2290, "text": "He was the top aide to FDR."}, {"time": 2292, "text": "This I'm getting from the Kara books too."}, {"time": 2294, "text": "And he said, what is a government?"}, {"time": 2297, "text": "It's not just one guy or even 10 guys."}, {"time": 2300, "text": "Hell, it's a thousand guys."}, {"time": 2303, "text": "And what FDR did is he masterfully picked the right people to execute his will through the federal agencies."}, {"time": 2311, "text": "Johnson was the same way."}, {"time": 2312, "text": "He played these people like a fiddle."}, {"time": 2314, "text": "He knew exactly who to pick."}, {"time": 2316, "text": "He knew the system and more."}, {"time": 2318, "text": "Part of the reason that outsiders who don't have a lot of experience in Washington almost always fail is they don't know who to pick or they pick people who say one thing to their face."}, {"time": 2329, "text": "And then when it comes time to carry out the president's policy in terms of the government, they just don't do it."}, {"time": 2335, "text": "And the president's too, think about this."}, {"time": 2337, "text": "I think some Rahm Emanuel said this."}, {"time": 2338, "text": "He was like, by the time it gets to the president's desk, nobody else can solve it."}, {"time": 2342, "text": "It's not easy."}, {"time": 2343, "text": "It's not like a yes or no question."}, {"time": 2345, "text": "It's every single thing that hits the president's desk is incredibly hard to do."}, {"time": 2350, "text": "And Obama actually even said, and this was a very revealing quote about how he thinks about the presidency, which is he's like, look, the presidency is like one of those super tankers."}, {"time": 2361, "text": "He's like, I can come in and I can take it two degrees left and two degrees right."}, {"time": 2367, "text": "In a hundred years, two degrees left, that's a whole different trajectory."}, {"time": 2371, "text": "Same thing on the right."}, {"time": 2372, "text": "And he's like, that ultimately is really all you can do."}, {"time": 2376, "text": "I quibble and disagree with that in terms of how he could have changed things in 2008, but there's a lot of truth to that statement."}, {"time": 2383, "text": "Okay, that's really fascinating."}, {"time": 2384, "text": "You make me realize that actually both Obama and Trump are probably playing victim here to the system."}, {"time": 2392, "text": "You're making me think that maybe you can correct me that, cause I'm thinking of like Elon Musk, whose major success despite everything is hiring the right people."}, {"time": 2404, "text": "And like creating those thousands, that structure of a thousand people."}, {"time": 2408, "text": "So maybe a president has power in that if they were exceptionally good at hiring the right people."}, {"time": 2413, "text": "Personnel is policy, man."}, {"time": 2415, "text": "That's what it comes down to."}, {"time": 2416, "text": "But wouldn't you be able to steer the ship way more than two degrees if you hire the right people?"}, {"time": 2421, "text": "So like, it's almost like Obama was not good at hiring the right people."}, {"time": 2425, "text": "Well, he hired all the Clinton people."}, {"time": 2426, "text": "That's what happened."}, {"time": 2427, "text": "What happened with Trump?"}, {"time": 2428, "text": "He hired all the Bush people."}, {"time": 2429, "text": "And then you just sit back and say, oh, president can't, but that means you're just suck at hiring."}, {"time": 2437, "text": "Yeah, I mean, look, I know it's funny."}, {"time": 2438, "text": "I'm giving you simultaneously the nationalist case against Trump and the progressive case against Obama."}, {"time": 2445, "text": "The progressive people are like, why the fuck are you hiring all these Clinton people in order to run the government and just recreate, like why are you hiring Larry Summers, who was one of the people who worked at all these banks and didn't believe that bailouts were gonna be big enough, and then to come in in the worst economic crisis in modern American history."}, {"time": 2462, "text": "That was 2008."}, {"time": 2463, "text": "And Summers actively lobbied against larger bailouts, which had huge implications for working class people and pretty much hollowed out America since."}, {"time": 2472, "text": "Okay, from Trump, same thing."}, {"time": 2474, "text": "You're like, I'm gonna drain the swamp."}, {"time": 2475, "text": "And by doing that, I'm gonna hire Goldman Sachs's Gary Cohn and Steve Mnuchin and all these other absolute bush clowns in order to run my White House."}, {"time": 2487, "text": "Well, yeah, no shit."}, {"time": 2489, "text": "The only thing that you accomplished in your four years in office is passing a massive tax cut for the rich and for corporations."}, {"time": 2497, "text": "I wonder how that happened."}, {"time": 2498, "text": "What role does money play in all of this?"}, {"time": 2501, "text": "Is money a huge influence in politics, super PACs, all that kind of stuff?"}, {"time": 2506, "text": "Or is this more just kind of a narrative that we play with because from the outsider's perspective, it seems to have, that seems to be one of the fundamental problems with modern politics."}, {"time": 2516, "text": "So I was just having this conversation, Marshall and I, Marshall Kosloff, my cohost on The Realignment."}, {"time": 2521, "text": "And it's funny because if you do enough research, we actually live in the least corrupt age in American campaign finance, as in it's never been more transparent."}, {"time": 2533, "text": "It's never been more up to the FEC and all of that."}, {"time": 2538, "text": "If you go back and read not even 50 years ago, we're talking about Lyndon B. Johnson, handing people like literally as he came up in his youth, paying people for votes, like the boss of the person who like had all the Mexican votes, like the person who had, and he was like giving out briefcases."}, {"time": 2555, "text": "This is like within people's lifetimes who are alive in America."}, {"time": 2558, "text": "So that doesn't happen anymore."}, {"time": 2560, "text": "But I don't like to blame everything on money."}, {"time": 2564, "text": "Although I do think money is obviously a huge part of the problem."}, {"time": 2567, "text": "I actually look at it in terms of distribution, which is that how is money distributed within our society?"}, {"time": 2575, "text": "Because I firmly believe that politics, this is gonna get complicated, but I think politics is mostly downstream from culture."}, {"time": 2584, "text": "And culture, obviously I'm using economics because there's obviously a huge interplay there, but like in terms of the equitable or lack of equitable distribution of money within our politics, what we're really pissed off about is we're like, our politics only seems to work for the people who have money."}, {"time": 2600, "text": "I think that's largely true."}, {"time": 2601, "text": "I think that the reason why things worked differently in the past is because our economy was structured in different ways."}, {"time": 2608, "text": "And there's a reason that our politics today are very analogous to the last Gilded Age because we had very similar levels of economic distribution and cultural problems too at the same time."}, {"time": 2621, "text": "I don't wanna erase that."}, {"time": 2622, "text": "Cause I actually think that's what's driving all of our politics right now."}, {"time": 2627, "text": "So in that sense, the representative government is doing a pretty good job of representing the state of culture and the people and so on."}, {"time": 2634, "text": "Can I ask you in terms of the deep state and conspiracy theories, there's a lot of talk about, again, from an outsider's perspective, if I were just looking at Twitter, it seems that at least 90% of people in government are pedophiles."}, {"time": 2650, "text": "90 to 95%, I'm not sure what that number is."}, {"time": 2655, "text": "If I were to just look at Twitter, honestly, or YouTube, I would think most of the world is a pedophile."}, {"time": 2660, "text": "I would almost feel like."}, {"time": 2662, "text": "And if you don't fully believe that, you're a pedophile."}, {"time": 2666, "text": "I would start to wonder like, wait, like what, am I a pedophile too?"}, {"time": 2671, "text": "I'm either a communist or a pedophile or both, I guess."}, {"time": 2675, "text": "Yeah, that's gonna be clipped out."}, {"time": 2676, "text": "Thank you, internet."}, {"time": 2679, "text": "I look forward to your emails."}, {"time": 2682, "text": "But is there any kind of shadow conspiracy theories that give you pause or, so the flip side, the response to a lot of conspiracy theories is like, no, the reason this happened is because it's a combination of just incompetence."}, {"time": 2701, "text": "So where do you land on some of these conspiracy theories?"}, {"time": 2706, "text": "I think most conspiracy theories are wrong."}, {"time": 2709, "text": "Some are true and those are spectacularly true."}, {"time": 2712, "text": "And if that makes sense."}, {"time": 2715, "text": "And we don't know which ones."}, {"time": 2716, "text": "I don't know which ones."}, {"time": 2718, "text": "I think, well, I mean, look, man, I listened to your podcast."}, {"time": 2721, "text": "I think I was a huge nonbeliever in UFOs and now I've probably never believed more in UFOs."}, {"time": 2728, "text": "Like I believe in UFOs."}, {"time": 2730, "text": "Like I'm very comfortable being like, not only do I believe in UFOs, like I think we're probably being visited by an alien civilization."}, {"time": 2737, "text": "And if you asked me that three years ago, I would have been like, you're out of your fucking mind."}, {"time": 2740, "text": "Like, what are you talking about?"}, {"time": 2742, "text": "Well, listen to David Fravor."}, {"time": 2743, "text": "That's all I have to say."}, {"time": 2745, "text": "I have the sense that the government has information that hasn't revealed, but it's not like they're, I don't think they're holding, there's like a green guy sitting there in a room."}, {"time": 2756, "text": "They have seen things they don't know what to do with."}, {"time": 2759, "text": "So it's like, they're confused."}, {"time": 2761, "text": "They're afraid of revealing that they don't know."}, {"time": 2764, "text": "That's what I think it is, right?"}, {"time": 2765, "text": "It's revealing, yeah, exactly, that they don't know."}, {"time": 2769, "text": "And then in the process, there's a lot of fears tied up in that."}, {"time": 2772, "text": "First, looking incompetent in the public eye."}, {"time": 2775, "text": "Nobody wants to be looked that way."}, {"time": 2777, "text": "And the other is like, in revealing it, even though they don't know, maybe China will figure it out."}, {"time": 2784, "text": "So like, we don't want China to figure it out first."}, {"time": 2786, "text": "And so all those kinds of things result in basically secrecy."}, {"time": 2790, "text": "Then that damages the trust in institutions on one of the most fascinating aspects, like one of the most fascinating mysteries of humankind of is there life, intelligent life, out there in the universe?"}, {"time": 2804, "text": "So that's one of them."}, {"time": 2805, "text": "But there's other ones, like for me, when I first came across actually Alex Jones was 9 11."}, {"time": 2813, "text": "I remember like, cause I was in Chicago."}, {"time": 2817, "text": "I was thinking like, oh shit, are they gonna hit Chicago too?"}, {"time": 2821, "text": "That's what everybody was thinking."}, {"time": 2822, "text": "Yeah, everybody."}, {"time": 2823, "text": "Everybody was thinking like, what does this mean?"}, {"time": 2825, "text": "What scale?"}, {"time": 2825, "text": "What, I mean, trying to interpret it."}, {"time": 2827, "text": "And I remember like looking for information desperately, like what happened?"}, {"time": 2832, "text": "And I remember not being satisfied with the quality of reporting and figuring out like rigorous, like here's exactly what happened."}, {"time": 2841, "text": "And so people like Alex Jones stepped up and others that said like, there's some shady shit going on."}, {"time": 2847, "text": "And it sure as hell looked like there's shady shit going on."}, {"time": 2851, "text": "So like, and I still stand behind the fact that it seems like there's not, there's not enough, like it wasn't a good job of being honest and transparent and all those kinds of things."}, {"time": 2862, "text": "Cause it would implicate the Saudis."}, {"time": 2864, "text": "And see, that's my conspiracy theories."}, {"time": 2866, "text": "I'm like, yeah, I think they covered up a lot of stuff because they wanted to cover up for the kingdom of Saudi Arabia."}, {"time": 2870, "text": "Like, I mean, that was a conspiracy theory not that long ago."}, {"time": 2874, "text": "I think it's true."}, {"time": 2875, "text": "I mean, I think it's a hundred percent true."}, {"time": 2877, "text": "Yeah, so those kinds of conspiracy theories are interesting."}, {"time": 2879, "text": "I mean, there's other ones for me personally that touched the institution that means a lot to me is the MIT and, you know, Jeffrey Epstein."}, {"time": 2889, "text": "Yeah, I wanna hear a lot more."}, {"time": 2890, "text": "I wanna hear about, I talk about Epstein a lot."}, {"time": 2892, "text": "So I'm like."}, {"time": 2892, "text": "Oh, you do?"}, {"time": 2893, "text": "Yeah, and he, I was gonna say, in terms of conspiracy theory, that one changed my outlook."}, {"time": 2898, "text": "Cause I was like, I was like, whoa, like you have this dude who convinced some of the most successful people on earth that he was like some money manager."}, {"time": 2909, "text": "And it looks like it was totally fake."}, {"time": 2911, "text": "Like Leon Black."}, {"time": 2912, "text": "I mean, this is one of the richest men on wall street, $9 billion net worth."}, {"time": 2916, "text": "Why is he giving him over a hundred million dollars between 2015 and 2019?"}, {"time": 2922, "text": "What's going on here?"}, {"time": 2923, "text": "Lex Wexner, same thing."}, {"time": 2925, "text": "So yeah, I wanna hear, because you know people who met him."}, {"time": 2928, "text": "And the only person I know who met him was Eric Weinstein."}, {"time": 2930, "text": "I've heard his, right."}, {"time": 2933, "text": "So I, listen, I'm still in and Eric is fascinating and like Eric is full on saying that."}, {"time": 2939, "text": "He was a Mossad or whatever."}, {"time": 2941, "text": "Yeah, there's a front for something, something much, much bigger."}, {"time": 2946, "text": "And there's a, whatever his name, Robert Maxwell, all the, all those stories, like you could dig deeper and deeper that Jeffrey's just like the tip of the iceberg."}, {"time": 2957, "text": "I just think he's an exceptionally charismatic, listen, this isn't speaking from confidence or like deep understanding of the situation, but from my speaking with people, he just seems like, at least from the side of his influence and interaction with researchers, he just seems like somebody that was exceptionally charismatic and actually took interest."}, {"time": 2984, "text": "He was unable to speak about interesting scientific things, but he took interest in them."}, {"time": 2991, "text": "So he knew how to stroke the egos of a lot of powerful people, like well, like in different kinds of ways, I suppose I don't know about this because I don't have, like if a really, okay, this is weird to say, but I have an ability, okay, I think women are beautiful, I like women, but like if like a supermodel came to me or something, like I'm able to reason."}, {"time": 3019, "text": "It seems like some people are not able to think clearly when there's like an attractive woman in the room."}, {"time": 3025, "text": "And I think that was one of the tools he used to manipulate people."}, {"time": 3030, "text": "I don't know, listen, it's like the pedophile thing."}, {"time": 3033, "text": "I don't know how many people are complete sex addicts, but like, it seems like looking out into the world, like the Me Too movement have revealed that there's a lot of like weird, like creepy people out there."}, {"time": 3047, "text": "I don't know, but I think it was just one of the many tools that he used to convince people and manipulate people, but not in some like evil way, but more just really good at the art of conversation and just winning people over on the side."}, {"time": 3070, "text": "And then by building through that process, building a network of other really powerful people and not explicitly, but implicitly having done shady shit with powerful people, like building up a kind of implied power of like, like we did some shady shit together."}, {"time": 3094, "text": "So we're not like, you're gonna help me out on this extra thing I need to do now."}, {"time": 3099, "text": "And that builds and builds and builds to where you're able to actually control, like have quite a lot of power without explicitly having like a strategy meeting."}, {"time": 3110, "text": "And I think a single person or yeah, I think a single person can do that, can start that ball rolling."}, {"time": 3118, "text": "And over time it becomes a group thing, like I don't know if Jillian Maxwell was involved or others and yeah, over time that becomes almost like a really powerful organization that wasn't, that's not a front for something much deeper and bigger, but it's almost like maybe it's cause I love cellular automata, man."}, {"time": 3139, "text": "A system that starts out as a simple thing with simple rules can create incredible complexity."}, {"time": 3172, "text": "So the final result is, I mean, listen, I have a pretty optimistic, I tend to see the good in people and so it's been heartbreaking to me in general just to see people I look up to not have the level of integrity I thought they would or like the strength of character, all those kinds of things."}, {"time": 3195, "text": "And it seems like you should be able to see the bullshit that is Jeffrey Epstein, like when you meet him."}, {"time": 3203, "text": "We're not talking about like Eric Weinstein, like one or two or three or five interactions, but like there's people that had like years of relationship with him."}, {"time": 3213, "text": "And I don't know, I'm not sure."}, {"time": 3215, "text": "Even after he was convicted."}, {"time": 3216, "text": "After he was convicted."}, {"time": 3218, "text": "That guy always gets me."}, {"time": 3219, "text": "Yeah, there's stories, I mean, I don't need to sort of, I honestly believe, okay, here's the open question I have."}, {"time": 3232, "text": "I don't know how many creepy sexual people that are out there."}, {"time": 3237, "text": "Like, I don't know if there is like, like the people I know, the faculty and so on, I don't know if they have like a kink that I'm just not aware of that was being leveraged because to me, it seems like if not everybody's a pedophile, then it's just the art of conversation."}, {"time": 3258, "text": "That is just like the art of just like manipulating people by making them feel good about like the exciting stuff they're doing."}, {"time": 3265, "text": "Listen, man, academics, people talk about money."}, {"time": 3268, "text": "I don't think academics care about money as much as people think."}, {"time": 3271, "text": "What they care about is like somebody, they want to be, it's the same thing that Instagram models posting their butt pictures, is they want to be loved."}, {"time": 3282, "text": "They want attention."}, {"time": 3283, "text": "My parents are professors."}, {"time": 3287, "text": "They, and Jeff Epstein, like the money is another way to show attention."}, {"time": 3292, "text": "Right, it's a proxy."}, {"time": 3294, "text": "My work matters."}, {"time": 3295, "text": "And he did that for some of the weirdest, most brilliant people."}, {"time": 3302, "text": "I don't want to sort of drop names, but everybody knows them."}, {"time": 3306, "text": "It's like people that are the most interesting academics is the one he cared about."}, {"time": 3311, "text": "Like people are thinking about the most difficult questions in all of science and all of engineering."}, {"time": 3316, "text": "So those people are, were kind of outcasts in academia a little bit because they're doing the weird shit."}, {"time": 3323, "text": "They're the weirdos."}, {"time": 3324, "text": "And he cared about the weirdos and he gave them money."}, {"time": 3326, "text": "And that, you know, that's, I don't know if there's something more nefarious than that."}, {"time": 3333, "text": "I hope not, but maybe I'm surprised."}, {"time": 3336, "text": "And in fact, half the population of the world is pedophiles."}, {"time": 3339, "text": "No, I think it's what you were talking about, which is that it's the, it's the implication after the initial, right?"}, {"time": 3346, "text": "Like you do some shady things together or you do something that you want out of the public eye and you're a public person."}, {"time": 3352, "text": "And look, we probably even experienced this to a limited extent, right?"}, {"time": 3355, "text": "You're like, ah, you know, like, I don't want to, I don't know, I almost lost my temper, you know, one time whenever a car hit me and I'm like, I can't freak out in public anymore."}, {"time": 3362, "text": "Like, you know, like what if somebody takes a photo or something?"}, {"time": 3365, "text": "And so I think that there's an extent to that times a billion, literally, when you have a billion dollars or more."}, {"time": 3372, "text": "And you take that all together and you stack it up on itself."}, {"time": 3375, "text": "I saw a story about like Bill Clinton."}, {"time": 3376, "text": "Like Bill Clinton was with Epstein or with Ghislaine Maxwell in a private air terminal or something."}, {"time": 3383, "text": "And she had one of their like sex, you know, one of those girls who was underage, had her dressed up in a literal like pilot uniform."}, {"time": 3391, "text": "And she was underage in order to, you know, and she was being disguised for being older."}, {"time": 3397, "text": "And she was a masseuse, right?"}, {"time": 3399, "text": "Because that was one of the guises which they got in order to sexually traffic these women."}, {"time": 3403, "text": "And she was like, Bill was like complaining about his neck."}, {"time": 3405, "text": "And she's like, give Bill Clinton a massage, right?"}, {"time": 3407, "text": "So now there's a photo of an underage girl giving a massage to the former president of the United States."}, {"time": 3412, "text": "I don't think he knew, right?"}, {"time": 3414, "text": "But like, that looks bad."}, {"time": 3416, "text": "And so this is kind of what we're getting at, which is that you're setting it all up and creating those preconditions or like Prince Andrew."}, {"time": 3424, "text": "Do I think Prince Andrew knew that Virginia Gouffre was underage?"}, {"time": 3430, "text": "Probably knew she was pretty young, which I think is, you know, skeevy enough where you're a fucking Prince, you probably know better."}, {"time": 3435, "text": "But I don't think he knew she was underage or maybe he did."}, {"time": 3439, "text": "And if he did, then he's even more of a piece of shit than I thought."}, {"time": 3442, "text": "But when we look at these things, the stuff I'm more interested in is like what you were talking about."}, {"time": 3448, "text": "I'm like, Bill Gates, how do you get the richest man in the world in your house?"}, {"time": 3453, "text": "Like under what, and Gates is like, he was talking about financing and all this."}, {"time": 3457, "text": "I'm like, you don't have access to money or bankers?"}, {"time": 3460, "text": "Like you're the richest man in the world."}, {"time": 3462, "text": "You can call Goldman Sachs anytime you want on a hotline."}, {"time": 3466, "text": "Like, why do you need, that's where I start again to get more conspiratorial because I'm like, Bill, dude, you have the gold credit, right?"}, {"time": 3474, "text": "Like you don't need Epstein to create some complicated financing structure."}, {"time": 3479, "text": "Or Leon Black, like what is 2015, 2009?"}, {"time": 3484, "text": "I mean, this is very recent stuff."}, {"time": 3486, "text": "Or, and this is the part that really got me as I read the department, I think it's called the Department of Financial Service report around Deutsche Bank with Epstein."}, {"time": 3495, "text": "They knew he was a criminal."}, {"time": 3496, "text": "They solicited his business, explicitly knew that his business meant access to other high net worth individuals, consistently doled money out from his account for hush payments to women in Europe and prostitution rings."}, {"time": 3511, "text": "They knew all of this within the bank."}, {"time": 3513, "text": "It was elevated multiple times."}, {"time": 3515, "text": "Here was the other one."}, {"time": 3516, "text": "One of Epstein's associates was like, hey, how much money can we take out before we hit the automatic sensor before you have to tell the IRS?"}, {"time": 3524, "text": "And that question by their own standards is supposed to result in a notification to the feds and they never did it."}, {"time": 3532, "text": "And he was withdrawing like $2 million of cash in five years for tips to, I'm like, okay, like something's going on here."}, {"time": 3540, "text": "Like, you see what I'm saying?"}, {"time": 3541, "text": "There's a lot of signs that make you think that there's a bigger thing at play than just the man, that there's some, it does look like a larger organization is using this front, right?"}, {"time": 3555, "text": "Again, I don't know."}, {"time": 3556, "text": "I truly don't know."}, {"time": 3557, "text": "And I'm not willing to use the certainty, which I think a lot of people online are, to say like, it wants 100%."}, {"time": 3562, "text": "The certainty is always the problem because that's probably why I hesitate to touch conspiracy theories is because I'm allergic to certainty in all forms."}, {"time": 3571, "text": "In politics, any kind of discourse."}, {"time": 3573, "text": "And people are so sure, in both directions, actually, it's kind of hilarious."}, {"time": 3579, "text": "Either they're sure that the conspiracy theory, particularly whatever the conspiracy theory is, is false."}, {"time": 3585, "text": "Like they almost dismiss it like, like they don't even want to talk about it."}, {"time": 3590, "text": "It's like the people, like the way they dismiss that the earth is flat."}, {"time": 3594, "text": "Most scientists are like, they don't even want to like hear what the flat earthers are saying."}, {"time": 3602, "text": "They don't have like zero patience for it, which is like, maybe in that case is deserved."}, {"time": 3609, "text": "But everything else, you really like have empathy."}, {"time": 3614, "text": "Like consider the fact, you have, okay, this is weird to say, but I feel like you have to consider that the earth may be flat for like one minute."}, {"time": 3626, "text": "Like you have to be empathetic."}, {"time": 3627, "text": "You have to be open minded."}, {"time": 3629, "text": "I don't see a lot of that through our cultural taste makers and more."}, {"time": 3632, "text": "And that really is what concerns me the most."}, {"time": 3635, "text": "Cause it's just another manifestation of all of our problems."}, {"time": 3638, "text": "Is that we have this completely bifurcating economy, bifurcating culture, literally, in terms of we have the middle of the country and then we have the coast."}, {"time": 3647, "text": "And in terms of the population, it's almost 50, 50."}, {"time": 3651, "text": "And with increasing mega cities and urban culture, like urban monoculture of LA, New York and Chicago and DC and Boston and Austin, relative to how an entire other group of Americans live their lives, or even the people within them who aren't rich and upwardly mobile, how they live their lives is just completely separating."}, {"time": 3672, "text": "And all of our language and communication in mass media and more is to the top."}, {"time": 3676, "text": "And then everybody else is forgotten."}, {"time": 3678, "text": "Do you think when you dig to the core, there is a big gap between left and right?"}, {"time": 3685, "text": "Is that division that's perceived currently real or are most people center left and center right?"}, {"time": 3693, "text": "It's so interesting because that's such a loaded term, center left."}, {"time": 3699, "text": "Like to you, I think the way you're thinking of it is, I'm not like a, well, even this, like I'm not a radical socialist, but I'm marginally left on cultural issues and economic issues."}, {"time": 3716, "text": "This is how we've traditionally understood things."}, {"time": 3719, "text": "And then in popular discourse, like center right, like what does it mean to be center right?"}, {"time": 3723, "text": "Like I am marginally right on social issues and marginally right on economic issues."}, {"time": 3730, "text": "But that's just not, like if you look at survey data, for example, like stimulus checks, people who are against stimulus checks are conservative."}, {"time": 3740, "text": "Well, 80% of the population is for a stimulus check."}, {"time": 3743, "text": "So that means a sizable number of Republicans are for stimulus checks."}, {"time": 3747, "text": "Same thing happens on like a wealth tax."}, {"time": 3750, "text": "The same thing happens on, okay, Florida voted for Trump, 3.1%, more than Barack Obama, 2008, on the same day passes a $15 minimum wage at 67%."}, {"time": 3765, "text": "So that's why I."}, {"time": 3767, "text": "Oh, that's my entire career."}, {"time": 3770, "text": "But it seems like, so that's fascinating."}, {"time": 3773, "text": "Conversation is different than the policies."}, {"time": 3777, "text": "Well, it's different than reality."}, {"time": 3779, "text": "That's what I would say, which is that the way we have to understand American politics today, it didn't always used to be this way, is it's almost entirely long."}, {"time": 3789, "text": "Basic, I would say the main divider is, because even when you talk about class, this misses it in terms of socioeconomics, it's around culture, which is that it's basically, if you went to a four year degree granting institution, you are part of one culture."}, {"time": 3805, "text": "If you didn't, you're part of another."}, {"time": 3807, "text": "I don't wanna erase the 20% or whatever of people who did go to a college degree who are Republicans or vice versa, et cetera, but I'm saying on average, in terms of the median way that you feel, we're basically bifurcating along those lines."}, {"time": 3823, "text": "And because people get upset, be like, oh, well, there are rich people who vote for Trump."}, {"time": 3827, "text": "And I'm like, yeah, but you know who they are?"}, {"time": 3830, "text": "They're like plumbers or something."}, {"time": 3832, "text": "They're people who make $100,000 a year, but they didn't go to a four year college degree and they might live who are in a place which is not an urban metro area."}, {"time": 3842, "text": "And then at the same time, you have like a Vox writer who makes like 30 grand, but they have a lot more cultural power than like the plumber."}, {"time": 3851, "text": "So you have to think about where exactly that line is."}, {"time": 3855, "text": "And I think in general, that's the way that we're trending."}, {"time": 3858, "text": "So that's why when I say like, what's going on, are we divided?"}, {"time": 3862, "text": "Yeah, like, but it's not left and right."}, {"time": 3864, "text": "I mean, like, and that's why I hate these labels."}, {"time": 3866, "text": "So it's more just red and blue like teams."}, {"time": 3869, "text": "They're arbitrary teams."}, {"time": 3871, "text": "So how arbitrary are these teams, I guess is another."}, {"time": 3874, "text": "Completely arbitrary."}, {"time": 3875, "text": "So, well, you kind of imply that there's, I don't know if you're sort of in post analyzing the patterns because it seems like there's a network effects of like, you just pick the team red or blue and it might have to do with college."}, {"time": 3890, "text": "You might have to do all of those things, but like, it seems like it's more about just the people around you."}, {"time": 3899, "text": "So less than whether you went to college or not."}, {"time": 3901, "text": "I mean, it's almost like, seems like, it's almost like a weird, like network effects that are hard."}, {"time": 3908, "text": "There's certain strong patterns you're identifying, but I don't know."}, {"time": 3913, "text": "It's sad to think that it might be just teams that have nothing to do with what you actually believe."}, {"time": 3918, "text": "Well, it is, Lex."}, {"time": 3920, "text": "Look, I mean, I don't want to believe that, but the data points me to this, which especially 2020, I'm one of the people chief among them."}, {"time": 3928, "text": "I will own up to it here."}, {"time": 3929, "text": "I was totally wrong about why Trump was elected in 2016."}, {"time": 3933, "text": "I believed and based a lot of my public commentary beliefs on this, Trump was elected because of a rejection of Hillary Clinton neoliberalism on the back of a pro worker message, which was anti immigration."}, {"time": 3948, "text": "It was its pillar, but alongside of it was a rejection of free trade with China and generally of the political correctness and globalism, which has been come in through the uniparty and same thing here with the military industrial complex and endless war, he rejected all of that."}, {"time": 3968, "text": "Wait, what's wrong with that prediction?"}, {"time": 3970, "text": "It's wrong, man."}, {"time": 3971, "text": "And the reason I know this is that it sounds right."}, {"time": 3974, "text": "I wish it, I honestly wish it was true, but here's the truth."}, {"time": 3977, "text": "Trump actually governed largely as a neoliberal Republican who was meaner online and who departed from orthodoxy in some very important ways."}, {"time": 3987, "text": "Don't get me wrong."}, {"time": 3988, "text": "I will always support the trade war with China."}, {"time": 3991, "text": "I will always support not expanding the wars in Afghanistan and in Iraq."}, {"time": 3995, "text": "I will support him moving the Overton window on a million different things and revealing once and for all that GOP voters don't care about economic orthodoxy necessarily."}, {"time": 4005, "text": "But here's what they do care about."}, {"time": 4007, "text": "Trump got more votes in 2020 than he did in 2016, despite not delivering largely for all the Trump people out there on that agenda."}, {"time": 4016, "text": "He wasn't more pro union, but he won more union votes."}, {"time": 4019, "text": "He wasn't necessarily more pro worker, but he actually won more votes in Ohio than he did in 2016."}, {"time": 4027, "text": "And he won more Hispanic votes than despite being all the immigration rhetoric, et cetera."}, {"time": 4033, "text": "Here's why, it's about the culture, which is that the culture war is so hot that negative partisanship is at such high levels."}, {"time": 4042, "text": "All of the vote is geared upon what the other guy might do in office."}, {"time": 4046, "text": "And there's a poll actually just came out by Echelon Insights."}, {"time": 4049, "text": "Crystal and I were talking about it on Rising, that number one concern amongst Democratic voters is Trump voters, number one concern."}, {"time": 4057, "text": "Not issues like Trump voters."}, {"time": 4061, "text": "And number two is white supremacy."}, {"time": 4063, "text": "And so like, which is basically code for Trump voters."}, {"time": 4067, "text": "And is the same true for the other side?"}, {"time": 4068, "text": "Also on the right, the number one concern is illegal immigration."}, {"time": 4072, "text": "And number, I think, three or four or whatever is Antifa, which is code for Democrats."}, {"time": 4078, "text": "At least on the right is a policy kind of thing."}, {"time": 4080, "text": "Well, yeah, it's funny."}, {"time": 4081, "text": "I saw Ben Shapiro was talking about this."}, {"time": 4083, "text": "But the reason why I would functionally say it's the same is because, I mean, you can believe whether it's true or not."}, {"time": 4090, "text": "I think it actually largely is true."}, {"time": 4091, "text": "But a lot of GOP voters feel like a lot of illegal immigration is code for people who are coming in, who are gonna be legalized and are gonna go vote Democrat."}, {"time": 4099, "text": "Like, I can just explain it from their point of view."}, {"time": 4102, "text": "So like, what does that actually mean?"}, {"time": 4105, "text": "Each other, like each other, which is that the number one concern is the other person."}, {"time": 4110, "text": "So negative partisanship has never been higher."}, {"time": 4113, "text": "And I think people who had my thesis in terms of why Trump was elected in 2016, you have to grapple with this."}, {"time": 4119, "text": "Like, how did he win 10 million more votes?"}, {"time": 4123, "text": "He came 44,000 votes away from winning the presidency across three states."}, {"time": 4126, "text": "Like, I don't, none of our popular discourse reflects that very stark reality."}, {"time": 4131, "text": "And I think so much of it is people really hate liberals."}, {"time": 4137, "text": "Like, they just really hate them."}, {"time": 4139, "text": "And I was driving through rural Nevada before the election."}, {"time": 4144, "text": "And I was like, literally in the middle of nowhere."}, {"time": 4146, "text": "And there was this massive sign this guy had out in front of his house."}, {"time": 4150, "text": "And it just said, Trump, colon, fuck your feelings."}, {"time": 4154, "text": "And I was like, that's it."}, {"time": 4156, "text": "That is why people voted for Trump."}, {"time": 4158, "text": "And I don't want to denigrate it because they truly feel they have no cultural power in America, except to raise the middle finger to the elite class by pressing the button for Trump."}, {"time": 4170, "text": "I get that."}, {"time": 4171, "text": "That's actually a totally rational way to vote."}, {"time": 4175, "text": "It's not the way I wish we did vote, but like, you know, that's not my place to say."}, {"time": 4180, "text": "So this is interesting."}, {"time": 4181, "text": "If you could just psychoanalyze, I'm again, probably naive about this, but I'm really bothered by the hatred of liberals."}, {"time": 4192, "text": "It's this amorphous monster that's mocked."}, {"time": 4197, "text": "It's like the Shapiro liberal tears."}, {"time": 4200, "text": "And I'm also really bothered by probably more of my colleagues and friends, the hatred of Trump."}, {"time": 4209, "text": "Yeah, the Trump and white supremacists."}, {"time": 4215, "text": "So apparently there's 70 million white supremacists, 75 million, sorry."}, {"time": 4221, "text": "There's millions of white supremacists."}, {"time": 4225, "text": "And apparently whatever liberal is, I mean, literally liberal has become equivalent to white supremacists in the power of negativity it arouses."}, {"time": 4236, "text": "I don't even know what those, I mean, honestly, they've become swears essentially."}, {"time": 4242, "text": "Is that, I mean, how do we get out of this?"}, {"time": 4246, "text": "Because that's why I just don't even say anything about politics online."}, {"time": 4250, "text": "Cause it's like, really?"}, {"time": 4253, "text": "Like you can't, here's what happens."}, {"time": 4258, "text": "Anything you say that's like thoughtful, like, hmm, I wonder, immigration, something."}, {"time": 4265, "text": "I wonder like why we have these many, we allow these many immigrants in or some version of the like thinking through these difficult policies and so on."}, {"time": 4278, "text": "They immediately tried to find like a single word in something you say that can put you in a bin of liberal or white supremacists and then hammer you to death by saying you're one of the two."}, {"time": 4292, "text": "And then everybody just piles on happily that we finally nailed this white supremacist or liberal."}, {"time": 4299, "text": "And that, is this some kind of weird like feature of online communication that we've just stumbled upon?"}, {"time": 4305, "text": "Is there a way or is it possible to argue that this is like a feature, not a bug?"}, {"time": 4311, "text": "Like, this is a good thing?"}, {"time": 4313, "text": "Yeah, well, look, I just think it's a reflection of who we are."}, {"time": 4316, "text": "People like to blame social media."}, {"time": 4317, "text": "I think we're just incredibly divided right now."}, {"time": 4319, "text": "I think we've been divided like this for the last 20 years."}, {"time": 4322, "text": "And I think that, the reason I focus almost 99% of my public commentary on economics is because you asked an important question at the top."}, {"time": 4330, "text": "How do we fix this?"}, {"time": 4332, "text": "What did I say about the stimulus checks?"}, {"time": 4334, "text": "Stimulus checks have 80% approval rating."}, {"time": 4336, "text": "So that's the type of thing."}, {"time": 4338, "text": "If I was Joe Biden and I wanted to actually heal this country, that's the very first thing I would have done when I came into office."}, {"time": 4343, "text": "Same thing on when you look at anything that's gonna increase wages."}, {"time": 4348, "text": "I said on the show, I was like, look, I think Joe Biden will have an 80% approval rating if he does two things."}, {"time": 4354, "text": "If he gives every American a $2,000 stimulus check and gives everybody who wants a vaccine a vaccine."}, {"time": 4360, "text": "It's pretty simple."}, {"time": 4361, "text": "Cause here's the thing."}, {"time": 4363, "text": "I don't really like Greg Abbott that much."}, {"time": 4365, "text": "We have like very different politics."}, {"time": 4366, "text": "I'm from Texas, but my parents got vaccinated really quickly."}, {"time": 4370, "text": "That means something to me."}, {"time": 4371, "text": "I'm like, listen, I don't really care about a lot of the other stuff."}, {"time": 4375, "text": "He got my family vaccinated."}, {"time": 4378, "text": "Like that, well, I will forever remember that."}, {"time": 4382, "text": "And that's how we will remember the checks."}, {"time": 4384, "text": "This is a part of a reason why Trump almost won the election and why, if the Republicans had been smart enough to give him another round of checks, 100% would have won."}, {"time": 4394, "text": "Which is that people were like, look, I don't really like Trump, but I got a check with his name on it."}, {"time": 4400, "text": "And that meant something to me and my family."}, {"time": 4404, "text": "I'm not saying for all the libertarians out there that they should go and like endlessly spend money and buy votes."}, {"time": 4411, "text": "What I am saying is lean into the majoritarian positions without adding your culture war bullshit on top of it."}, {"time": 4420, "text": "So for example, what's the number one concern that AOC says after the first round of checks got out?"}, {"time": 4425, "text": "Oh, the checks didn't go to illegal immigrants."}, {"time": 4427, "text": "I'm like, are you out of your fucking mind?"}, {"time": 4429, "text": "Like this is the most popular policy America has probably done in 50 years, since like Medicare and you're ruining it."}, {"time": 4440, "text": "And then on the right is the same thing, which is that they'll be like, these checks are going to like, you know, low level blah, blah, you know, people who are lazy and don't work."}, {"time": 4450, "text": "I'm like, oh, there you go, you know, like you're just playing a caricature of what you are."}, {"time": 4454, "text": "Like if you lean into those issues and you got to do it clean, this is what everybody hates about DC, which is that Biden right now is doing the $1,400 checks, but he's looping it in with his COVID relief bill and all that."}, {"time": 4466, "text": "That's his prerogative, that's the Democrats prerogative."}, {"time": 4468, "text": "They won the election, that's fine."}, {"time": 4470, "text": "But I'll tell you what I would have done if I was him, I would have come in and I would have said, there's five United States senators who are on the record, Republicans, who said they'll vote for a $2,000 check."}, {"time": 4479, "text": "And I would put that on the floor of the United States Senate on my, you know, first or the first day possible."}, {"time": 4486, "text": "And I would have passed it and I would have forced those Republican senators to live up to that, vote for this bill, come to the Oval Office for a signing so that the very first thing of my presidency was to say, I'm giving you all this relief check, this long national nightmare is over."}, {"time": 4503, "text": "Take this money, do with it what you need."}, {"time": 4505, "text": "We've all suffered together."}, {"time": 4507, "text": "The thing about Biden is he has a portrait of FDR and is in the Oval, which kind of bothers me because he thinks of himself as an FDR like figure."}, {"time": 4516, "text": "But this is, you have to understand the majesty of FDR."}, {"time": 4520, "text": "We're talking about a person who passed a piece of legislation five days after he became president."}, {"time": 4525, "text": "And he passed 15 transformative pieces of legislation in the first 100 days."}, {"time": 4530, "text": "We're on day like 34, 35, and nothing has passed."}, {"time": 4535, "text": "The reconciliation bill will eventually become law, but it will become law with no Republican votes."}, {"time": 4540, "text": "And again, that's fine."}, {"time": 4542, "text": "But it's not fulfilling that legacy and the urgency of the action."}, {"time": 4547, "text": "And the mandate, which I believe that history has handed, it handed it to Trump and he fucked it up, right?"}, {"time": 4552, "text": "He totally screwed it up."}, {"time": 4554, "text": "He could have remade America and made us into the greatest country ever coming out on the other side of this."}, {"time": 4558, "text": "He decided not to do that."}, {"time": 4561, "text": "I think Biden was again handed that like a scepter almost."}, {"time": 4564, "text": "It's like all you have to do, all America wants is for you to raise it up high, but he's keeping it within the realm of traditional politics."}, {"time": 4570, "text": "I think it's a huge mistake."}, {"time": 4571, "text": "Why, so this is, everything he's saying is makes perfect sense, like take, okay."}, {"time": 4576, "text": "It's like, it's like, again, if the aliens showed up, it's like the obvious thing to do is like, what's the popular thing?"}, {"time": 4585, "text": "Like 80% of Americans support this."}, {"time": 4588, "text": "Like do that clean."}, {"time": 4591, "text": "Also do it like with like grace, where you're able to bring people together, not like in a political way, but like obvious common sense way."}, {"time": 4604, "text": "Like just people, the Republicans and Democrats just bring them together on a policy and like bold, just hammer it without the dirt, without the mess, whatever, try to compromise."}, {"time": 4616, "text": "Just the yellow have a good Twitter account, like loud, very clear."}, {"time": 4623, "text": "We're gonna give a $2,000 or a stimulus check."}, {"time": 4626, "text": "Anyone who wants a vaccine gets a vaccine at scale."}, {"time": 4631, "text": "What make America, let's make America great again by manufacturing."}, {"time": 4636, "text": "Like we are manufacturing most of the world's vaccine because we're bad motherfuckers."}, {"time": 4642, "text": "And without maybe with more eloquence than that and just do that."}, {"time": 4647, "text": "Why haven't we seen that for many, for several presidencies?"}, {"time": 4652, "text": "Because of coalitional politics and they owe something to somebody else."}, {"time": 4656, "text": "For example, Biden has got a lot of the Democratic constituency has to satisfy within this bill."}, {"time": 4664, "text": "So there's gonna be a lot of shit that goes in there, state and local aid, all this stuff."}, {"time": 4669, "text": "Again, I'm not even saying this is bad, but he's like, his theory is, and this isn't wrong, is like we're gonna take the really popular stuff and use it as cover for the more downwardly less popular."}, {"time": 4680, "text": "And so the Dems could face the accusation, the people who are on this side, this is their pushback to me."}, {"time": 4686, "text": "They're like, why would we give away the most popular thing in the bill and then we would never be able to pass state and local aid, right?"}, {"time": 4693, "text": "Why would we do, and the Republicans do the same thing, right, like Mitch McConnell, because he's a fucking idiot, decided to say, we're gonna pair these $2,000 stimulus checks with like section 230 repeal."}, {"time": 4704, "text": "And it was like, oh, it's obviously dead, right?"}, {"time": 4706, "text": "Like it's not gonna happen together."}, {"time": 4708, "text": "That's largely why I believe Trump lost the election and why those races down in Georgia went the way that they did."}, {"time": 4714, "text": "Obviously Trump had something to do with it, but the reason why is they have longstanding things that they've wanted to get done."}, {"time": 4721, "text": "And in the words of Rahm Emanuel, never let a good crisis go to waste and try and get as much as you possibly can done within a single bill."}, {"time": 4728, "text": "My counter would be this, things have worked this way for too long, which is that the reconciliation bill is almost certainly going to be the only large signature legislative accomplishment of the Biden presidency."}, {"time": 4743, "text": "That's just how American politics works."}, {"time": 4745, "text": "Maybe he gets one more, maybe one."}, {"time": 4747, "text": "He has a second reconciliation bill, then you're running for midterms, it's over."}, {"time": 4752, "text": "I believe that by trying to change the paradigm of our politics, leaning into exactly what I'm talking here, you could possibly transcend that to a new one."}, {"time": 4763, "text": "And I'm not naive."}, {"time": 4764, "text": "I think people respond to political pressures."}, {"time": 4767, "text": "And the way that we found this out was David Perdue, who was just a total corporate dollar general CEO guy."}, {"time": 4775, "text": "He was against the original $1,200 stimulus checks."}, {"time": 4779, "text": "But then Trump came out, who's the single most popular figure in the Republican party."}, {"time": 4783, "text": "He's like, I want $2,000 stimulus checks."}, {"time": 4785, "text": "And all of a sudden, Perdue running in Georgia is like, yeah, I'm with President Trump, I want a $2,000 stimulus check."}, {"time": 4793, "text": "That was, if you're an astute observer of politics, to say, you can see there that you can force people to do the right thing because it's the popular thing."}, {"time": 4802, "text": "And that if it's clean, if you don't give them any other excuse, they have to do it."}, {"time": 4807, "text": "So this is what we've been gaslit into our culture war framework of politics."}, {"time": 4813, "text": "And the reason it feels so broken and awful is because it is, but there is a way out."}, {"time": 4820, "text": "It's just that nobody wants to be, it's a game of chicken, because maybe it is true."}, {"time": 4824, "text": "Maybe we would never be able to get your other democratic priorities, your Republican priorities."}, {"time": 4829, "text": "But I think that the country understands that this is fucking terrible and would be willing to support somebody who does it differently."}, {"time": 4837, "text": "There's just a lot of disincentives to not stay without, there's a lot of incentives to not stray from the traditional path."}, {"time": 4844, "text": "Yeah, is it also possible that the A students are not participating?"}, {"time": 4851, "text": "Like we drove all of the superstars away from politics."}, {"time": 4856, "text": "So like you just had this argument before."}, {"time": 4858, "text": "I mean, everything you're saying sort of rings true."}, {"time": 4866, "text": "Like this is the obvious thing to do."}, {"time": 4868, "text": "As a student of history, you can almost like tell, like, if you look at great people in history, this is what great leaders in history, this is what they did."}, {"time": 4877, "text": "It's like clean, bold action, sometimes facing crisis, but we're facing a crisis right now."}, {"time": 4884, "text": "No, we're in a crisis."}, {"time": 4885, "text": "We've been, exactly."}, {"time": 4887, "text": "So why don't we see those leaders step up?"}, {"time": 4893, "text": "I mean, you say that's kind of like, it makes sense."}, {"time": 4896, "text": "There's a lot of different interests at play."}, {"time": 4899, "text": "You don't wanna risk too many things, so on and so forth."}, {"time": 4901, "text": "But that sounds like the C students."}, {"time": 4905, "text": "I don't think it's that."}, {"time": 4907, "text": "I think it's that the pipeline of politician creation is just totally broken from beginning to end."}, {"time": 4914, "text": "So it's not that A students don't wanna be politicians."}, {"time": 4919, "text": "It's basically the way that our current primary system is constructed, is what is the greatest threat to you as a member of Congress?"}, {"time": 4927, "text": "It's not losing your reelection."}, {"time": 4930, "text": "It's losing your primary, right?"}, {"time": 4933, "text": "So that means, especially in a safe district, you're most concerned about being hit if you're a Republican from the right, and if you're a Democrat from the left for not being a good enough one."}, {"time": 4942, "text": "That's actually what stops people, heterodox people in particular, from winning primaries because the people who vote in our primaries are the party faithful."}, {"time": 4952, "text": "That's how you get the production."}, {"time": 4955, "text": "It's important to understand the production pipeline, which is that, all right, I'm from Texas, so that's what I know best."}, {"time": 4960, "text": "So it's like, if you think in Texas, if you're a more heterodox like state legislature or something who works with the left on this and does that, you're gonna get your ass beat in a Republican primary because they're gonna be like, he worked with the left to do this, blah, blah, take it out of context, and you're screwed."}, {"time": 4978, "text": "And then that means you never ascend up the next level of the ladder, and then so on and so forth all the way."}, {"time": 4985, "text": "But I do think Trump changed everything."}, {"time": 4988, "text": "This is why I have some hope, which is that he showed me that all the people I listened to were totally wrong about politics, and that's the most valuable lesson you could ever teach me, which was, I was like, wait, I don't really have to listen to these people."}, {"time": 5002, "text": "I'm like, they don't know anything, actually."}, {"time": 5004, "text": "That's powerful, man."}, {"time": 5006, "text": "I'm like, he did it."}, {"time": 5007, "text": "This guy."}, {"time": 5008, "text": "Even if he didn't do anything with it."}, {"time": 5013, "text": "He showed that it's possible."}, {"time": 5015, "text": "And that means a lot."}, {"time": 5020, "text": "There's young people right now that kind of look, turn around and like, huh."}, {"time": 5024, "text": "You're like, wait, I don't have to comb my hair a certain way and go to law school and be an asshole who everybody knows is an asshole."}, {"time": 5032, "text": "And then get elected to state legislature."}, {"time": 5035, "text": "I mean, look, who's the number one person in the New York City primary right now?"}, {"time": 5041, "text": "Andrew Yang."}, {"time": 5042, "text": "He's polling higher than everybody else in the race."}, {"time": 5045, "text": "Look, maybe the polls are totally fucked and maybe he'll lose because of ranked choice voting and all of that."}, {"time": 5050, "text": "But I consider Andrew, I mean, I know him a little bit and I've followed his candidacy from the very beginning."}, {"time": 5055, "text": "I consider him an inspiration."}, {"time": 5056, "text": "He's the new generation of politics."}, {"time": 5059, "text": "Like if I see who's gonna be president 20 years from now, it's gonna be, I'm not saying it's gonna be Andrew Yang."}, {"time": 5064, "text": "I think it's gonna be somebody like Andrew Yang outside the political system who talks in a totally different way, right?"}, {"time": 5071, "text": "Just a completely, one of my favorite things that he said on the debate stage, he's like, look at us, we're all wearing makeup."}, {"time": 5077, "text": "It's crazy, you know?"}, {"time": 5078, "text": "And he like, he like brought that, that he brought that."}, {"time": 5082, "text": "And he's writing like, yeah, why are they all wearing makeup?"}, {"time": 5084, "text": "He probably arguably hasn't gone far enough almost."}, {"time": 5088, "text": "But he showed that it's possible."}, {"time": 5090, "text": "And then you see other, like AOC is a good example of somebody, at least in my opinion, is doing the same kind of thing, but going too far in like, well, I don't know, she's doing the Trump thing, but on the other side."}, {"time": 5102, "text": "So I don't know, what's too far?"}, {"time": 5105, "text": "Don't take a normative judgment of it."}, {"time": 5106, "text": "I will tell you the future of politics looks like AOC."}, {"time": 5107, "text": "Appreciate the art of it."}, {"time": 5108, "text": "Right, no, I do."}, {"time": 5109, "text": "Look, I don't, I'm not a big AOC fan, but she's a genius, media genius, once in a generation talent."}, {"time": 5116, "text": "The way that she uses social media, Instagram, and everybody on the right is like trying to copy her."}, {"time": 5121, "text": "Like Matt Gaetz is like, I want to be the conservative AOC."}, {"time": 5124, "text": "I'm like, it's just not going to happen, dude."}, {"time": 5125, "text": "Like you just don't have it."}, {"time": 5127, "text": "Like what she has, it's like, it's electric."}, {"time": 5129, "text": "And Trump had that."}, {"time": 5131, "text": "Like I've been to a Trump rally, like to cover as a journalist, and there's nothing like it in America."}, {"time": 5137, "text": "And Yang is similar."}, {"time": 5139, "text": "It's the same way where you're like, there is something going on here, which is just like, I've been doing Obama rally."}, {"time": 5145, "text": "I've been to a Clinton rally."}, {"time": 5147, "text": "I've been to several normal politics."}, {"time": 5150, "text": "It's fine, you know, with Trump and with Yang, it was, it's another world."}, {"time": 5156, "text": "It's another world."}, {"time": 5157, "text": "Yeah, Yang gang."}, {"time": 5157, "text": "There's probably thousands of people listening right now, who are just like doing a slow clap."}, {"time": 5166, "text": "Okay, but yeah, I mean, my worst fear, I prefer Andrew Yang kind of free improvisational idea, exchange, all that versus AOC, who I think no matter what she stands for is a drama machine, creates dramas just like Trump does."}, {"time": 5189, "text": "I would say my worst fear would be in 2024, is AOC old enough?"}, {"time": 5194, "text": "It'd be AOC versus Trump."}, {"time": 5196, "text": "I don't think she's old enough."}, {"time": 5197, "text": "I think you'd have to be, I don't know."}, {"time": 5198, "text": "I think she's 30."}, {"time": 5199, "text": "So she needs five more years."}, {"time": 5200, "text": "So probably not."}, {"time": 5202, "text": "Okay, but that kind of, that's, or Trump Jr. Well, AOC probably wouldn't win a Democratic primary."}, {"time": 5207, "text": "So, I mean, look, Joe Biden is, you know, he's pretty much showed that."}, {"time": 5210, "text": "That's exactly what you're saying."}, {"time": 5212, "text": "This process grooms you over time."}, {"time": 5215, "text": "You see the same thing in academia actually, which is very interesting, is the process of getting tenure."}, {"time": 5222, "text": "There's this, it's like you're being taught without explicitly being taught to behave in the way that everybody's behaved before."}, {"time": 5234, "text": "I've heard this, it was funny."}, {"time": 5235, "text": "I've had a few conversations that were deeply disappointing, which involved statements like, this is what's good for your career."}, {"time": 5248, "text": "This kind of conversation, almost like mentor to mentee conversation, or it's like, there's a grooming process in the same way."}, {"time": 5256, "text": "I guess you're saying the primary process does the same kind of thing."}, {"time": 5260, "text": "So, I mean, that's what people have talked about with Andrew Yang."}, {"time": 5263, "text": "He was being suppressed by a bunch of different forces, the mainstream media and all."}, {"time": 5268, "text": "Just the Democratic, just that whole process didn't like the honesty that he was showing, right?"}, {"time": 5275, "text": "For now, but here's my question to you."}, {"time": 5277, "text": "People gotta see, look, Jordan Peterson is one of the most famous people in America, right?"}, {"time": 5281, "text": "Like you have a massive podcast."}, {"time": 5283, "text": "You're more famous than half, 99% of the people at MIT."}, {"time": 5287, "text": "So like, from that perspective, everything has changed."}, {"time": 5290, "text": "And somewhere out there, there's a student who's taking notice."}, {"time": 5294, "text": "And I've noticed that with my own career, everybody thought I was crazy for doing this show with Crystal, The Hill."}, {"time": 5299, "text": "They thought I was nuts."}, {"time": 5299, "text": "They're like, what are you doing?"}, {"time": 5301, "text": "You're a White House correspondent."}, {"time": 5302, "text": "You've got a job forever."}, {"time": 5304, "text": "The other job offer I had was being a White House correspondent."}, {"time": 5307, "text": "And people thought I was nuts for not just sticking there and aging out within Washington, pining for appearances on Fox News and CNN and MSNBC."}, {"time": 5319, "text": "But I hated it."}, {"time": 5320, "text": "I just hated doing it."}, {"time": 5321, "text": "I did not wanna be a company man, like a Washington man, who's one of those guys who like brags to his friends about how many times he's been on Fox or whatever, mostly because I just have a rebellious streak and I hate being at the subject of other people."}, {"time": 5335, "text": "I created something new, which a lot of people watch to get their news."}, {"time": 5338, "text": "And I noticed that younger people who are almost all my audience, they don't really look up to any of the people in traditional, right?"}, {"time": 5346, "text": "They don't go and they're not coming up and being like, how do I be like Jim Acosta?"}, {"time": 5350, "text": "You know, they're like, hey, how did you do what you do?"}, {"time": 5353, "text": "And the way you did it is by bucking the system."}, {"time": 5356, "text": "So I think that we are at a total split point."}, {"time": 5360, "text": "And look, there will always be a path for people."}, {"time": 5363, "text": "Cause like, I don't want people to over learn this lesson."}, {"time": 5366, "text": "I have people who are like, I'm not gonna go to college."}, {"time": 5367, "text": "And I'm like, well, just wait."}, {"time": 5369, "text": "Yeah, like, I'm like, just like stop, just like, just hold on a second."}, {"time": 5374, "text": "But there will always be a path for the institutional that will always be there for you."}, {"time": 5379, "text": "But now there's something else."}, {"time": 5380, "text": "Now there's another game in town."}, {"time": 5382, "text": "And that's more appealing to millions and millions and millions and millions of people who feel unserved by the corporate media, CNN and these people, possibly who feel unserved in the, you know, the faculty."}, {"time": 5396, "text": "Like if you are an up and comer who wants to teach as many young people as possible, I think you should be on YouTube, right?"}, {"time": 5404, "text": "Like look at the Khan Academy guy, that guy created a huge business."}, {"time": 5407, "text": "So I just think we can be cynical and like upset about what that system is, but we should also have hope."}, {"time": 5414, "text": "Like I have a lot of hope for what can be in the future."}, {"time": 5416, "text": "Yeah, there's a guy people should check out."}, {"time": 5418, "text": "So my story is a little bit different because I basically stepped aside with the dream of being an entrepreneur earlier in the pipeline than like a legitimate, like senior faculty would."}, {"time": 5434, "text": "There's an example of somebody people should check out, Andrew Huberman from Stanford, who's a neuroscientist, who's as world class as it gets in terms of like 10 year faculty, just a really world class researcher."}, {"time": 5448, "text": "And now he's doing YouTube."}, {"time": 5450, "text": "Yeah, I see him on Instagram."}, {"time": 5452, "text": "And he's great."}, {"time": 5453, "text": "So he not just does Instagram, he now has a podcast and he's changing the nature of like, I believe that Andrew might be the future of Stanford."}, {"time": 5464, "text": "And for a lot, it's funny, like he's basically, Joe Rogan is an inspiration to Andrew and to me as well."}, {"time": 5473, "text": "And those ripple effects and Andrew is an inspiration probably just like you're saying to these young, like 25 year olds who are soon to become faculty, if we're just talking about academia."}, {"time": 5483, "text": "And the same is probably happening with government is, funny enough, Trump probably is inspiring a huge number of people who are saying, wait a minute, I don't have to play by the rules."}, {"time": 5496, "text": "And I can think outside the box here and you're right."}, {"time": 5500, "text": "And the institutions we're seeing are just probably lagging behind."}, {"time": 5504, "text": "So the optimistic view is the future is going to be full of exciting new ideas."}, {"time": 5510, "text": "So Andrew Young is just kind of the beginning of this whole thing."}, {"time": 5512, "text": "He's the tip of the iceberg."}, {"time": 5514, "text": "And I hope that iceberg doesn't, it's not this influencer."}, {"time": 5517, "text": "One of the things that really bothers me, I've gotten the chance, I should be careful here."}, {"time": 5523, "text": "I don't wanna, I love everybody, but these people who talk about like, how to make your first million or how to succeed."}, {"time": 5533, "text": "And they're so, I mean, yeah, that makes me a little bit cynical about, I'm worried that the people that win the game of politics will be ones that want to win the game of politics."}, {"time": 5549, "text": "They are, they are, man."}, {"time": 5551, "text": "And like we mentioned, AOC, I hope they optimize for the 80% populist thing, right?"}, {"time": 5559, "text": "Like they optimize for that bad thing, that history will remember you as the great man or woman that did this thing, versus how do I maximize engagement today and keep growing those numbers?"}, {"time": 5571, "text": "The influencers are so, I'm so allergic to this, man."}, {"time": 5576, "text": "They keep saying how many followers they have on the different accounts."}, {"time": 5580, "text": "And it's like, I don't think they understand."}, {"time": 5584, "text": "Maybe I don't understand."}, {"time": 5587, "text": "I think it has destructive psychological effects."}, {"time": 5593, "text": "One, like thinking about the number, like getting excited, your number went from 100 to 101 and being like, and today went out to 105."}, {"time": 5603, "text": "Whoa, that's a big jump."}, {"time": 5604, "text": "Then maybe like thinking this way, like I wonder what I did, I'll do that again."}, {"time": 5608, "text": "In this way, one, it creates anxiety and those psychological effects, whatever."}, {"time": 5614, "text": "The more important thing is it prevents you from truly thinking boldly in the long arc of history and creatively, thinking outside the box, doing huge actions."}, {"time": 5628, "text": "And I actually, my optimism is in the sense that that kind of action will beat out all the influencers."}, {"time": 5634, "text": "Well, I don't know, Lex, this is where my cynicism comes in."}, {"time": 5638, "text": "So there's a guy, Madison Cawthorn, the youngest member of Congress."}, {"time": 5642, "text": "And he, I don't want to say got caught, but there was like an email where he was like, my staff is only oriented around comms."}, {"time": 5651, "text": "Like he was basically saying, he got basically caught saying like, my staff is only centered on communications."}, {"time": 5659, "text": "And that's the right play."}, {"time": 5661, "text": "If you do want to get the benefits of our current electoral political and engagement system, which is that what's the best way to be known within the right as a right wing politician."}, {"time": 5672, "text": "It's to be a culture warrior, go on Ben Shapiro's podcast, be one of the people on Fox News, go on Sean Hannity's show, go on Tucker's show and all of that, because you become a mini celebrity within that world."}, {"time": 5686, "text": "Left unsaid is that that world is increasingly shrinking portion of the American population."}, {"time": 5692, "text": "And they barely, they can't even win a popular vote election, let alone barely win, eke out an electoral college victory in 2016."}, {"time": 5701, "text": "Well, but the incentives are all aligned within that."}, {"time": 5704, "text": "And it's the same thing really on the left, but you're right, which is that, ultimately, and look, this is why geniuses are geniuses because they buck the short term incentives."}, {"time": 5715, "text": "They focus on the long term, they bet big and they usually fail."}, {"time": 5719, "text": "But then when they get big, they succeed spectacularly."}, {"time": 5724, "text": "The people I know who have done this the best are like a lot of the crypto folks that I've spoken to."}, {"time": 5730, "text": "Like some of the stuff they say, I'm like, I don't know if that's gonna happen, but look, they're like billionaires, right?"}, {"time": 5736, "text": "And you're like, so they were right."}, {"time": 5738, "text": "The way I've heard it expressed is you can be wrong a lot, but when you're right, you get right big."}, {"time": 5745, "text": "And I mean, I've seen this in Elon Musk's career."}, {"time": 5747, "text": "I mean, he took spectacular risk, like spectacular risk and just doubled down, doubled down, doubled down, doubled down, doubled down."}, {"time": 5756, "text": "And you can kind of tell to him, I mean, you know him better than I do, but like from my observation, I don't think the money matters, right?"}, {"time": 5763, "text": "I just, like when I see him, I'm like, I don't, nobody works as hard as you do and builds the way that you build if it's just about the money."}, {"time": 5772, "text": "It just doesn't happen."}, {"time": 5773, "text": "Like nobody wills SpaceX into existence just for the money."}, {"time": 5778, "text": "Like it's not worth it, frankly, right?"}, {"time": 5779, "text": "Like he probably destroyed years of his life and like mental sanity."}, {"time": 5783, "text": "Money or attention or fame, none of that."}, {"time": 5786, "text": "It's not the primary priority."}, {"time": 5786, "text": "Well, that's what's so appealing to me, to me in particular about him, just like in how he built."}, {"time": 5791, "text": "Like I read a biography of him and just like the way that he constructed his life and like we're able to hyperfocus in meeting after meeting and drill down and also hire all the right people who execute each one of his tasks discreetly to his perfection is amazing."}, {"time": 5805, "text": "Like that's actually the mark of a good leader."}, {"time": 5808, "text": "But I mean, if you think about his career, the reason he's a renegade is cause probably he was told to like put it in an index fund or whatever."}, {"time": 5815, "text": "Like whenever he made his like 29 million and from PayPal, I don't know how much he made."}, {"time": 5819, "text": "And then just go along that road and he's like, no."}, {"time": 5821, "text": "So he succeeds spectacularly."}, {"time": 5824, "text": "So you have to have somebody who's willing to come in and buck that system."}, {"time": 5828, "text": "So for now, I think our politics are generally frozen."}, {"time": 5832, "text": "I think that that model is gonna be most generally appealing to the mean person, but somebody will come along and we'll change everything."}, {"time": 5840, "text": "Yeah, I'm just surprised there's not more of them."}, {"time": 5843, "text": "On that topic, it's now 20, what is it, 21?"}, {"time": 5848, "text": "Let's make some predictions that you can be wrong about."}, {"time": 5853, "text": "What major political people are you thinking will run in 2024, including Trump, junior, senior, or Ivanka?"}, {"time": 5866, "text": "Any Trump."}, {"time": 5867, "text": "Trump."}, {"time": 5869, "text": "And who do you think wins?"}, {"time": 5872, "text": "I think Joe Biden will run again in 2024."}, {"time": 5876, "text": "And I think he will run against someone with the last name Trump."}, {"time": 5879, "text": "I do not know whether that is Trump or Trump junior, but I think one of those people will probably be the GOP nominee in 2024. Who is it?"}, {"time": 5889, "text": "Some prominent political figure, was it Romney?"}, {"time": 5891, "text": "Somebody like that said that Trump will win the primary if he runs again."}, {"time": 5895, "text": "Of course, that's not even a question."}, {"time": 5896, "text": "Trump is the single most popular figure in the Republican party by orders of magnitude."}, {"time": 5903, "text": "Oh, I mean, probably more, honestly."}, {"time": 5905, "text": "There was a, actually, I can tell you because I saw the data, which is that pre January 6th, it was like 54% of Republicans wanted him to run again."}, {"time": 5913, "text": "Then it went down eight points after January 6th, two days later."}, {"time": 5918, "text": "And then after impeachment, it went right back up to 54%."}, {"time": 5922, "text": "So the exact same number is in February, post impeachment vote, as it was after November."}, {"time": 5930, "text": "Now look, yeah, again, surveys, bullshit, et cetera."}, {"time": 5932, "text": "But like, that's all the data we have."}, {"time": 5934, "text": "That's what I can point you to."}, {"time": 5935, "text": "If Trump runs, he will be the nominee and he will be the 2024 nominee."}, {"time": 5940, "text": "I just don't know if he wants to."}, {"time": 5942, "text": "It really depends."}, {"time": 5944, "text": "Do you think he wins?"}, {"time": 5945, "text": "After the Trump vaccine heals all of us, do you think Trump wins?"}, {"time": 5950, "text": "It depends on how popular culture functions over the next four years."}, {"time": 5953, "text": "And I can tell you that they are, because I don't think Biden has that much to do with it."}, {"time": 5957, "text": "Because again, Trump is not a manifestation of an affirmative policy action."}, {"time": 5962, "text": "It is a defensive bulwark wall against cultural liberalism."}, {"time": 5969, "text": "So it's like, this is why it doesn't matter what Biden does."}, {"time": 5973, "text": "If there are more riots, if there is a more sense of persecution amongst people who are more lean towards conservative or like, hey, I don't know about that, that's crazy, then he very well could win."}, {"time": 5988, "text": "Okay, let's say Joe Biden doesn't run and they put up like Kamala Harris, I think he would beat her."}, {"time": 5993, "text": "I don't think there's a question that Trump would beat Kamala Harris in 2024."}, {"time": 5997, "text": "And you don't think anybody else, I don't know how the process works, you don't think anybody else on the Democratic side can take the... Well, how could you run against the sitting vice president?"}, {"time": 6007, "text": "It's like, Joe Biden has a 98% approval rating in the Democratic Party."}, {"time": 6012, "text": "If he says, she is my heir, I think enough people will listen to him in a competitive primary or a noncompetitive primary."}, {"time": 6019, "text": "And then there's all these things about how primary systems themselves are rigged, the DNC could make it known that they'll blacklist anybody who does try and primary Kamala Harris."}, {"time": 6029, "text": "And look, I mean, progressives aren't necessarily all that popular amongst actual Democrats, like we found that out during the election."}, {"time": 6037, "text": "There's an entire constituency which loves Joe Biden and Joe Biden level politics."}, {"time": 6042, "text": "And so if he tells them to vote for Kamala, I think she would probably get it."}, {"time": 6047, "text": "But again, there's a lot of game theory obviously happening."}, {"time": 6049, "text": "Well, see, I think you're talking about everything you're saying is correct about mediocre candidates."}, {"time": 6055, "text": "It feels like if there's somebody like a really strong, I don't wanna use this term incorrectly, but populist, somebody that speaks to the 80% that is able to provide bold, eloquently described solutions that are popular."}, {"time": 6075, "text": "I think that breaks through all of this nonsense."}, {"time": 6078, "text": "How do they break through the primary system?"}, {"time": 6079, "text": "Cause the problem is the primary system is not populism."}, {"time": 6082, "text": "It's primary."}, {"time": 6084, "text": "But you don't think they can tweet their way to."}, {"time": 6087, "text": "Well, you have to be willing to win a GOP primary."}, {"time": 6090, "text": "You basically have to be at, whoever wins the GOP primary, in my opinion, will be the person most hated by the left."}, {"time": 6097, "text": "One of the people, things that people forget is, you know who came in second to Trump?"}, {"time": 6101, "text": "Ted Cruz."}, {"time": 6102, "text": "And the reason why is because Ted Cruz was the second most hated guy by liberals in America."}, {"time": 6108, "text": "A second to Trump."}, {"time": 6109, "text": "They have nothing in policy in common."}, {"time": 6111, "text": "But don't you think this kind of brilliantly described system of hate being the main mechanism of our electoral choices, don't you think that just has to do with mediocre candidates?"}, {"time": 6128, "text": "Basically the field of candidates, including Trump, including everybody was just like, didn't make anyone feel great."}, {"time": 6136, "text": "It's like, really?"}, {"time": 6137, "text": "This is what we have to choose from?"}, {"time": 6139, "text": "Maybe a Mark Cuban, or like a Mark Cuban is a Democrat, or it would have to be somebody like that."}, {"time": 6149, "text": "Somebody who, because here's the thing about Trump."}, {"time": 6150, "text": "It's not just that it was Trump."}, {"time": 6152, "text": "He was so fucking famous."}, {"time": 6154, "text": "Like people don't realize he was so famous."}, {"time": 6156, "text": "Like I, even when I first met Trump, I met a couple of other presidents, but when I met Trump, even I felt like kind of starstruck."}, {"time": 6164, "text": "Cause I was like, yo, this is the guy from The Apprentice."}, {"time": 6167, "text": "I'm like, this is the dude."}, {"time": 6169, "text": "From The Apprentice?"}, {"time": 6170, "text": "Cause I'm like, my dad and I used to sit and watch The Apprentice when I was in high school."}, {"time": 6175, "text": "And then one of the guys was from College Station where I grew up and we're like, oh my God, like that guy's on The Apprentice."}, {"time": 6180, "text": "Like it was a phenomenon."}, {"time": 6182, "text": "There's like that level."}, {"time": 6183, "text": "It's kind of like when I met Joe Rogan, I'm like, holy shit, that's Joe Rogan."}, {"time": 6186, "text": "I don't feel that way when I meet Mitt Romney, or Tom Cotton, or Josh Hawley, I met all of them."}, {"time": 6191, "text": "But there's a lot of celebrities, right?"}, {"time": 6192, "text": "Do you think there's some celebrities you were not even thinking about that could step in?"}, {"time": 6195, "text": "The Rock?"}, {"time": 6196, "text": "So I was about to say, I think The Rock could do it, but does he wanna do it?"}, {"time": 6200, "text": "I mean, it's terrible."}, {"time": 6201, "text": "Like it's terrible gig."}, {"time": 6203, "text": "It's very hard to do."}, {"time": 6205, "text": "I don't know if The Rock necessarily has like the formed policy agenda."}, {"time": 6209, "text": "Cause then here's the other problem."}, {"time": 6211, "text": "What if we set ourselves up for a system where like these people keep winning, but like with Trump, they have no idea how to run a government."}, {"time": 6217, "text": "It's actually really hard, right?"}, {"time": 6218, "text": "And you have to have the knowhow and the trust to find the right people."}, {"time": 6222, "text": "This is where the genius element comes in is, you have to understand that front and you have to understand how to execute discrete tasks."}, {"time": 6232, "text": "Like this is the FDR."}, {"time": 6234, "text": "This is why it's so hard, like FDR, Lincoln, TR."}, {"time": 6238, "text": "They were who they were and they live in history and their name rings like for a reason."}, {"time": 6244, "text": "And yeah, I mean, one of the most depressing lessons I got from 2020 is at almost, it seems like in my opinion, that we over learn the lesson of our success and not of our failures."}, {"time": 6256, "text": "For example, like we have this narrative in our head that we always have the right person at the right time during crisis."}, {"time": 6263, "text": "And in some cases it was true."}, {"time": 6265, "text": "We didn't deserve Lincoln."}, {"time": 6266, "text": "We didn't deserve FDR."}, {"time": 6268, "text": "We didn't deserve a lot of presidents at times of crisis."}, {"time": 6273, "text": "But then you're like, okay, George W. Bush, 9 11, that was terrible."}, {"time": 6278, "text": "Reconstruction, Andrew Johnson, awful, right?"}, {"time": 6281, "text": "Like we had several periods in our history where the crisis was there, they were called and they did not show up."}, {"time": 6290, "text": "And I really, it hadn't happened in my lifetime except for 9 11."}, {"time": 6295, "text": "And even then you could kind of see that as an opportunity for somebody like Obama to come in and fix it."}, {"time": 6301, "text": "But then he didn't do it."}, {"time": 6302, "text": "And then Trump didn't do it."}, {"time": 6304, "text": "And you realize, I feel like our politics are most analogous to like the 1910s, like all in terms of the Gilded Age, in terms of that, remember there's that long period of presidents between like Lincoln and Teddy Roosevelt."}, {"time": 6322, "text": "We were like, wait, like who was president?"}, {"time": 6324, "text": "Like, or even TR was like an exception where you'll have like Calvin Coolidge who like, silent cow, Grover Cleveland."}, {"time": 6333, "text": "That's kind of how, if I think of us within history, I feel like we're in one of those times."}, {"time": 6338, "text": "We're just waiting."}, {"time": 6339, "text": "It feels really important to us right now."}, {"time": 6341, "text": "Like this is the most important moment in history, but it might be."}, {"time": 6344, "text": "It could just be a blip, right?"}, {"time": 6345, "text": "20, 30 year blip."}, {"time": 6346, "text": "Like when you think about who was president between 1890 and 19 before, I mean, yeah, between like 1888 and 1910."}, {"time": 6356, "text": "Like nobody really thinks about that period of America, but like that was an entire lifetime for people, right?"}, {"time": 6361, "text": "Like what did they, how did they feel about the country that they were in?"}, {"time": 6365, "text": "That's how I kind of think about where we are right now."}, {"time": 6367, "text": "It's funny to think."}, {"time": 6368, "text": "I mean, I don't want to minimize it, but like we haven't really gone through a World War II style crisis."}, {"time": 6373, "text": "So like, say that there is a crisis in like several decades of that level, right?"}, {"time": 6381, "text": "Existential risks to a large portion of the world."}, {"time": 6386, "text": "Then what will be remembered is World War II, maybe a little bit about Vietnam and then whatever that crisis is."}, {"time": 6394, "text": "And this whole period that we see as dramatic, even coronavirus."}, {"time": 6397, "text": "Even 9 11."}, {"time": 6398, "text": "Even 9 11, it's like, cause you can look at how many people died and all those kinds of things, all the drama around the war on terror and all those kinds of things."}, {"time": 6407, "text": "Maybe Obama will be remembered for being the first African American president, but then like that's, yeah, that's fascinating to think about, oh man, even Trump will be like, oh, okay, cool."}, {"time": 6420, "text": "That guy."}, {"time": 6421, "text": "Yeah, like maybe he'd be remembered as the first celebrity."}, {"time": 6428, "text": "I mean, Reagan was already a governor, right?"}, {"time": 6430, "text": "Yeah, so like the first apolitical celebrity that was, so maybe if there's more celebrities in the future, they'll say that Trump was the first person to pave the way for celebrities to win."}, {"time": 6443, "text": "Oh man, yeah."}, {"time": 6445, "text": "And yeah, I still hold that this era will probably be remembered."}, {"time": 6450, "text": "You know, people say I talk about Elon way too much, but the reality is like, there's not many people that are doing the kind of things he's doing is why I talk about it."}, {"time": 6461, "text": "I think this era, it's not necessarily Elon and SpaceX, but this era will be remembered by the new, the like of the space exploration, of the commercial of companies getting into space exploration of space travel."}, {"time": 6477, "text": "And perhaps like artificial intelligence around social media, all those kinds of things, this might be remembered for that."}, {"time": 6486, "text": "But every, all the political bickering, all that nonsense, that might be very well forgotten."}, {"time": 6491, "text": "One way to think about it is that the internet is so young."}, {"time": 6496, "text": "I think about it, so Jeff Jarvis, he's a media scholar I respect."}, {"time": 6500, "text": "He's not the only person to say this, but many others have, which is that, look, this is kind of like the printing press."}, {"time": 6505, "text": "There was a whole 30 years war because of the printing press."}, {"time": 6509, "text": "It took a long time for shit to sort out."}, {"time": 6511, "text": "I think that's where we're at with the internet."}, {"time": 6513, "text": "Like at a certain level, it disrupts everything."}, {"time": 6517, "text": "It can be very tumultuous."}, {"time": 6519, "text": "I never felt like I was living through history until coronavirus."}, {"time": 6523, "text": "Like, you know, like until we were all locked down, I was like, I'm living through history."}, {"time": 6526, "text": "Like this, there's this very overused cliche in DC where every comm staffer wants you to think that what their boss just did is history."}, {"time": 6534, "text": "And I've always been like, this isn't history."}, {"time": 6536, "text": "This is some like stupid fucking bill, you know, whatever."}, {"time": 6538, "text": "But like, that was the first time I was like, this is history, like this right here."}, {"time": 6543, "text": "Well, I was hoping, tragedy aside, that this, I wish the primaries happened during coronavirus so that we, because like, then we can see the, so, okay, here's a bunch of people facing crisis."}, {"time": 6557, "text": "It's an opportunity for a leader to step up."}, {"time": 6560, "text": "Like, I still believe the optimistic view is the game theory of like influencers will always be defeated by actual great leaders."}, {"time": 6571, "text": "So like, maybe the great leaders are rare, but I think they're sufficiently out there that they will step up, especially in moments of crisis."}, {"time": 6579, "text": "And coronavirus is obviously a crisis where like, you know, mass manufacture of tests, all kinds of infrastructure building that you could have done in 2020, there's so many possibilities for just like bold action."}, {"time": 6596, "text": "And none of that, even just, forget actually doing the action, advocating for it."}, {"time": 6604, "text": "Just saying like this, we need to do this."}, {"time": 6607, "text": "And none of that, like the speeches that Biden made, I don't even remember a single speech that Biden made because there's zero bold, I mean, their strategy was to be quiet and let Donald Trump."}, {"time": 6621, "text": "Polarize the electorate."}, {"time": 6623, "text": "Polarize the electorate and hope that results in them winning because of the high unemployment numbers and all those kinds of things, as opposed to like, let's go big, let's go with a big speech."}, {"time": 6636, "text": "Like, you know, that, yeah, it's a lost opportunity in some sense."}, {"time": 6642, "text": "So we talked a bunch about politics, but one of the other interesting things is that you're involved with is, or involved with defining the future of as journalism."}, {"time": 6653, "text": "I suppose you can think of podcasts as a kind of journalism, but also just writing in general, just whatever the hell the future of this thing looks like is up to be defined by people like you."}, {"time": 6665, "text": "So what do you think is broken about journalism and what do you think is the future of journalism?"}, {"time": 6671, "text": "I think the future of journalism looks much more like what we, you and I are doing here right now."}, {"time": 6677, "text": "And journalism is gonna be downstream from a culture that can be a good and a bad thing depending on how you look at it."}, {"time": 6683, "text": "We are gonna look at our media, our media is gonna look much more like it did pre mass media."}, {"time": 6691, "text": "And the way that I mean that is that back in the 18, in the 1800s in particular, especially after the invention of the telegraph when information itself was known."}, {"time": 6703, "text": "So for example, like you and I don't need to, let's say you and I are competing journalists."}, {"time": 6707, "text": "You and I are no longer competing quote unquote to tell the public X event happened."}, {"time": 6714, "text": "All journalism today is largely explaining why did X happen."}, {"time": 6721, "text": "And part of the problem with that is that that means that it's all up for partisan interpretation."}, {"time": 6728, "text": "Now you can say that that's a bad thing."}, {"time": 6729, "text": "I think it's a great thing because the highest level of literacy and news viewership in America was during the time of yellow journalism, was during the time of partisan journalism."}, {"time": 6742, "text": "Not a surprise."}, {"time": 6743, "text": "People like to read the news from people that they agree with."}, {"time": 6746, "text": "You could say that's bad, echo chambers, et cetera."}, {"time": 6749, "text": "That's the downside of it."}, {"time": 6751, "text": "The upside is more people are more educated."}, {"time": 6753, "text": "More people are interested in the news."}, {"time": 6756, "text": "So I think the proliferation of mass media, I mean, sorry, of this format of niching, of not just long form."}, {"time": 6765, "text": "Dude, I do updates on Instagram, which are five minutes."}, {"time": 6768, "text": "Are you considered like Instagram, almost even Twitter?"}, {"time": 6771, "text": "Oh, of course, Twitter."}, {"time": 6773, "text": "Twitter is where I get my news from."}, {"time": 6774, "text": "I don't read the paper."}, {"time": 6775, "text": "I have literally, Twitter is my news aggregator."}, {"time": 6777, "text": "It's called my wire where I find out about hard events."}, {"time": 6781, "text": "Like the president has departed the White House."}, {"time": 6783, "text": "But not only that, I don't know about you, but I also looked at Twitter to the exact thing you're saying, which is the response to the news, like the thoughtful sounds ridiculous, but you can be pretty thoughtful in a single tweet."}, {"time": 6795, "text": "If you follow the right people, you can get that."}, {"time": 6798, "text": "And so that is the future of media, which is that the future of media is it will be much larger amounts of people, which are famous to smaller groups."}, {"time": 6809, "text": "So Walter Cronkite's never gonna happen again, at least probably within our lifetimes, where everybody in America knows who this guy is."}, {"time": 6817, "text": "That age is over."}, {"time": 6819, "text": "I think that's a good thing because now people are gonna get the news from the people that they trust."}, {"time": 6824, "text": "Yes, some of it will be opinionated."}, {"time": 6826, "text": "I'm in my program."}, {"time": 6829, "text": "Crystal and I are like, she's coming from this view."}, {"time": 6833, "text": "I'm coming from this view."}, {"time": 6835, "text": "That's our bias when we talk about information and we're gonna talk about the information that we think is important."}, {"time": 6840, "text": "And it has garnered a large audience."}, {"time": 6842, "text": "I think that's very much where the future is gonna be."}, {"time": 6877, "text": "This will cause a total dispersion of all of that."}, {"time": 6880, "text": "The battle of our age is gonna be the guild versus the non guild."}, {"time": 6886, "text": "So like what we see right now with the New York Times and Clubhouse, this is a very, very, very, very, very intentional thing that is happening, which is that the Times talking about unfettered conversations, that's happening on Clubhouse for people who aren't aware."}, {"time": 6903, "text": "This is important because they need to be the fetters of conversation."}, {"time": 6908, "text": "They need to be the inter agent."}, {"time": 6911, "text": "That's where they get their power."}, {"time": 6912, "text": "They get their power from convincing Facebook that they are the ones who can fact check stuff."}, {"time": 6918, "text": "They are the ones who can tell you whether something is right or wrong."}, {"time": 6923, "text": "That battle over unimpeded conversation and the explosion of a format that you and I are doing really well in, and then this more consolidated one, which holds cultural power and elite power and more importantly, money, right?"}, {"time": 6937, "text": "Over you and I, that's the battle that we're all gonna play out."}, {"time": 6940, "text": "Do you think unfettered conversations have a chance to win this battle?"}, {"time": 6943, "text": "Yes, I do in the long run."}, {"time": 6945, "text": "In the long run, the internet is simply too powerful."}, {"time": 6948, "text": "But here's the mistake everybody makes."}, {"time": 6950, "text": "The New York Times will never lose."}, {"time": 6952, "text": "It will just become one of us."}, {"time": 6953, "text": "See."}, {"time": 6955, "text": "They already are."}, {"time": 6956, "text": "They are the largest."}, {"time": 6957, "text": "The daily?"}, {"time": 6957, "text": "The daily, look at the daily."}, {"time": 6958, "text": "Not even that."}, {"time": 6959, "text": "Think about it not in podcasting."}, {"time": 6961, "text": "The Times is not a mass media product."}, {"time": 6964, "text": "It is a subscription product for upper middle class largely white liberals who live the same circumstances across the United States and in Europe."}, {"time": 6975, "text": "There's nothing wrong with that."}, {"time": 6977, "text": "You can't be the paper of record when you're actually the paper of upper middle class white America."}, {"time": 6983, "text": "Your job is to report on the news from that angle and deliver them the product that they want."}, {"time": 6990, "text": "Their stock price is higher than ever."}, {"time": 6992, "text": "They're making 10 times more money than they did 10 years ago, but it comes at the cost of not having a mass application audience."}, {"time": 7001, "text": "So like when people, I think people in our space are always like, the New York Times is gonna be destroyed."}, {"time": 7006, "text": "No, it's actually even better."}, {"time": 7008, "text": "They will just become one of us."}, {"time": 7011, "text": "They're a subscription platform."}, {"time": 7013, "text": "Well, yes, in terms of the actual mechanism."}, {"time": 7014, "text": "But you know, New York Times is still, and I don't think I'm speaking about a particular sector."}, {"time": 7020, "text": "I think it, as a brand, it does have the level of credibility assigned to it still."}, {"time": 7028, "text": "There's politicization of it."}, {"time": 7031, "text": "But there's a credibility."}, {"time": 7033, "text": "Like it has much more credibility than, forgive me, than I think you and I have."}, {"time": 7039, "text": "In terms of your podcast, like people are not going to be like, they're gonna say at the New York Times versus what you said on the podcast for an opinion."}, {"time": 7053, "text": "I wonder in the sense of battles, whether on Federated Conversations, whether Joe Rogan, whether your podcast can become the, have the same level of legitimacy or the flip side, New York Times loses legitimacy to be at the same level of in terms of how we talk about it."}, {"time": 7072, "text": "It's a long battle, right?"}, {"time": 7074, "text": "It's gonna take a long time."}, {"time": 7075, "text": "And I'm saying, this is where I think the end state is going and look at what the Times is doing."}, {"time": 7079, "text": "They're leaning into podcasting for a reason, but not just podcasting as in NPR level, like here's what's happening."}, {"time": 7087, "text": "Michael Barbaro is a fucking celebrity, right?"}, {"time": 7090, "text": "The guy who does the daily."}, {"time": 7091, "text": "That guy's famous amongst these people because they're like, oh my God, I love Michael."}, {"time": 7096, "text": "Like, I love the way he does this stuff."}, {"time": 7098, "text": "Again, that's fine."}, {"time": 7099, "text": "More people are listening to the news."}, {"time": 7100, "text": "I think that's a good thing."}, {"time": 7102, "text": "And then who else do they hire?"}, {"time": 7103, "text": "Ezra Klein from Vox, Kara Swisher, also from Vox, who does Pivot, which is an amazing podcast."}, {"time": 7110, "text": "Or Jane Coaston, same thing."}, {"time": 7112, "text": "It's personalities who are becoming bundled together within this brand, right?"}, {"time": 7118, "text": "Here's, okay, maybe I'm just a hater."}, {"time": 7122, "text": "Cause I love podcasting from the beginning."}, {"time": 7125, "text": "I love Green Day before the recall, man."}, {"time": 7128, "text": "But I am bothered by it."}, {"time": 7130, "text": "Like why doesn't Kara Swisher, she's done successfully."}, {"time": 7133, "text": "I think in her own, no, she was always a part of some kind of institution."}, {"time": 7137, "text": "But she started her own thing, I think."}, {"time": 7140, "text": "It would."}, {"time": 7140, "text": "Recode, right, yeah."}, {"time": 7141, "text": "Recode, I don't know if that's her own thing."}, {"time": 7144, "text": "So she was very successful there."}, {"time": 7146, "text": "Why the hell did she join the New York Times with the new podcast?"}, {"time": 7149, "text": "Why is Michael Barbaro not do his own thing?"}, {"time": 7178, "text": "That's sad to me because it propagates old thinking, like it propagates old institutions."}, {"time": 7186, "text": "And you could say that New York Times is going to evolve quickly and so on, but I would love it if there was a mechanism for reestablishing, like for building new New York Times in terms of public legitimacy."}, {"time": 7199, "text": "And I suppose that's a wishful thinking cause it takes time to build trust in institutions and it takes time to build new institutions."}, {"time": 7208, "text": "My main thing I would say is public legitimacy as a concept is not gonna be there in mass media anymore because of the balkanization of audiences."}, {"time": 7215, "text": "I mean, think about it, right?"}, {"time": 7216, "text": "Like this is like Lesion, the classic stuff around a thousand true fans, or no, sorry, like a hundred true fans even now."}, {"time": 7224, "text": "Like you can make a living on the internet just talking to a hundred people."}, {"time": 7227, "text": "If as long as they're all high frequency traders, some of the highest paid people on substack, they don't have that many subs."}, {"time": 7234, "text": "It's just that they're Wall Street guys, right?"}, {"time": 7236, "text": "So people pay a lot of money."}, {"time": 7237, "text": "Again, that's great."}, {"time": 7238, "text": "So what you will have is an increasing balkanization of the internet, of audiences and of niches."}, {"time": 7246, "text": "People will become increasingly famous within us."}, {"time": 7248, "text": "You will become astoundingly famous."}, {"time": 7251, "text": "I'm sure you've noticed this with your fan base."}, {"time": 7252, "text": "I certainly have with mine."}, {"time": 7253, "text": "Like 99% of people have no idea who I am, but when somebody meets, they're like, oh my God, I watch your show every day, right?"}, {"time": 7261, "text": "Like it's the only thing I watch for news, right?"}, {"time": 7264, "text": "Like instead of casually famous, if that makes sense, but like, oh yeah, it's like Alec Baldwin, you know?"}, {"time": 7269, "text": "Whoa, shit, that's Alec Baldwin."}, {"time": 7270, "text": "But you're not like, oh shit, I love you Alec Baldwin."}, {"time": 7274, "text": "This is a Ben Smith of the New York Times, actually he wrote this column."}, {"time": 7277, "text": "He's like, the future is everybody will be famous, but only to a small group of people."}, {"time": 7282, "text": "And I think that is true."}, {"time": 7284, "text": "But again, I don't decry it."}, {"time": 7286, "text": "I think it's great because I think that the more that that happens, the more engaged people will be and it empowers different voices to be able to come in and then possibly, I wouldn't say destroy, but compete against."}, {"time": 7297, "text": "I mean, look at Joe."}, {"time": 7299, "text": "Joe is more powerful than CNN and MSNBC and Fox all put together."}, {"time": 7305, "text": "That gives me like immense inspiration."}, {"time": 7307, "text": "Like he created the space for me to succeed."}, {"time": 7310, "text": "And I told him that when I met him, I was like, dude, like I listened to his podcast when I was like young."}, {"time": 7315, "text": "And like, and I remember like when I got to meet him and all that, and I told him this on this pod, I was like, I didn't know people were millions were willing to listen to a guy talk about chimps for three straight hours, including me."}, {"time": 7328, "text": "I didn't know that I could be one of those people."}, {"time": 7330, "text": "I learned something about myself from his show, yeah."}, {"time": 7332, "text": "And so by creating that space, I'd be like, wait, there's a hunger here."}, {"time": 7337, "text": "Like he showed us all the way and none of us will ever again be as famous as Rogan because he was the first and that's fine because he created the umbrella ecosystem for us all to thrive."}, {"time": 7349, "text": "That is where I see like a great amount of hope within that story."}, {"time": 7353, "text": "Yeah, and the cool thing, he also supports that ecosystem."}, {"time": 7355, "text": "He's such a."}, {"time": 7355, "text": "He's so generous."}, {"time": 7358, "text": "One of the things he paved the way out for me is to show that you can just be honest, publicly honest, and not jealous of other people's success, but instead be supportive and all those kinds of things, just like loving towards others."}, {"time": 7376, "text": "He's been an inspiration."}, {"time": 7377, "text": "I mean, to the comics community, I think there are a bunch of, before that, I think there were all a bunch of competitive haters towards each other."}, {"time": 7387, "text": "Yeah, and now he's like just injected love."}, {"time": 7391, "text": "They're like, they're still like many are still resistant, but they're like, they can't help it because he's such a huge voice."}, {"time": 7397, "text": "He like forces them to be like loving towards each other."}, {"time": 7400, "text": "And the same, I tried to, one of the reasons I wanted to start this podcast was to try to, I wanted to be like do what Joe Rogan did, but for the scientific community, like my little circle of scientific community of like, like let's support each other."}, {"time": 7418, "text": "Yeah, well, like Avi Loeb, I would have no idea who he was if it wasn't for you."}, {"time": 7422, "text": "I mean, I assume you put him in touch with Joe."}, {"time": 7424, "text": "He went on Joe's show."}, {"time": 7425, "text": "I had him on my show."}, {"time": 7426, "text": "Like millions of people would have no idea who he was if it wasn't for you."}, {"time": 7430, "text": "Just by the way, in terms of deep state and shadow government, Avi Loeb has to do with aliens."}, {"time": 7434, "text": "You better believe Joe."}, {"time": 7436, "text": "Dude, the last thing I sent to him was the American Airlines audio."}, {"time": 7440, "text": "Did you see that?"}, {"time": 7442, "text": "The pilots who were, oh my God, dude, this is amazing."}, {"time": 7444, "text": "So like, this American Airlines flight crew was over New Mexico, this happened five or six days ago."}, {"time": 7452, "text": "And the guy comes and he goes, hey, do you have any targets up here?"}, {"time": 7456, "text": "A large cylindrical object just flew over me."}, {"time": 7460, "text": "Okay, so this happens, so this happens."}, {"time": 7463, "text": "Then a guy or like a radio catcher records this and posts it online."}, {"time": 7468, "text": "American Airlines confirms that this is authentic audio."}, {"time": 7473, "text": "And they go, all further questions should be referred to the FBI."}, {"time": 7477, "text": "So then, okay, American Airlines just confirmed it's a legitimate transmission."}, {"time": 7481, "text": "FBI, then the FAA comes out and says, we were tracking no objects in the vicinity of this plane at the time of the transmission."}, {"time": 7492, "text": "So the only plausible explanation that online sleuths have been able to say is maybe he saw a Learjet, which was, you know, using like open source data."}, {"time": 7502, "text": "FAA rules that out."}, {"time": 7503, "text": "So what was it?"}, {"time": 7505, "text": "He saw a large cylindrical object."}, {"time": 7507, "text": "While he was mid flight, American Airlines, but you can go online, listen to the audio yourself."}, {"time": 7512, "text": "This is a 100% no shit transmission confirmed by American Airlines of a commercial pilot over New Mexico, seeing a quote unquote, large cylindrical object in the air."}, {"time": 7526, "text": "Like I said, when we first started talking, I've never believed more in UFOs and aliens."}, {"time": 7531, "text": "Yeah, this is awesome."}, {"time": 7533, "text": "I just wish both American Airlines, FBI, and government would be more transparent."}, {"time": 7540, "text": "Like there would be voices, and I know it sounds ridiculous, but the kind of transparency that you see, maybe not Joe Rogan, he's like overly transparent."}, {"time": 7548, "text": "He's just a comic really, but just the, I don't know, like a podcast from the FBI, just like being honest, like excited, confused."}, {"time": 7558, "text": "I'm sure that they're being overly cautious about their release information."}, {"time": 7564, "text": "I'm sure there's a lot of information that would inspire the public, that would inspire trust in institutions that will not damage national security."}, {"time": 7572, "text": "Like it seems to me obvious, and the reason they're not sharing it is because of this momentum of bureaucracy, of caution and so on."}, {"time": 7579, "text": "But there's probably so much cool information that the government has."}, {"time": 7582, "text": "The way I almost, I wouldn't say it confirmed it's real, but Trump didn't declassify it."}, {"time": 7588, "text": "Like you know that if there was ever a president that actually wanted to get to the bottom of it, it was him."}, {"time": 7594, "text": "I mean, he didn't declassify it, man."}, {"time": 7597, "text": "And people begged him to."}, {"time": 7598, "text": "I know for a fact, because I pushed to try and make this happen, that some people did speak to him about it."}, {"time": 7604, "text": "And he was like, no, I'm not gonna do it."}, {"time": 7607, "text": "He might be afraid."}, {"time": 7608, "text": "That's what I mean, though."}, {"time": 7609, "text": "They were probably all telling him, they're like, sir, you can't do this, you know, all this, like, wow, and I get that."}, {"time": 7613, "text": "And there's this legislation written at COVID that like they have six months to release it, man."}, {"time": 7618, "text": "Is that real?"}, {"time": 7620, "text": "Is that a bunch of bullshit?"}, {"time": 7621, "text": "I think it's bullshit."}, {"time": 7621, "text": "There's so many different levels of classification that people need to understand."}, {"time": 7625, "text": "I mean, look, I read John Podesta."}, {"time": 7627, "text": "He was the chief of staff to Bill Clinton."}, {"time": 7630, "text": "He's a big UFO guy."}, {"time": 7631, "text": "He tried."}, {"time": 7632, "text": "Like him and Clinton tried to get some of this information and they could not get any of it."}, {"time": 7637, "text": "And we're talking about the president and the White House chief of staff."}, {"time": 7641, "text": "Well, there's a whole bureaucracy, but just like you were saying, with intent."}, {"time": 7644, "text": "You have to be like, that has to be your focus because there's a whole bureaucracy built around secrecy for probably for a good reason."}, {"time": 7651, "text": "So to get through to the information, there's a whole like paperwork process, all that kind of stuff."}, {"time": 7656, "text": "You can't just walk in and get the, unless again, with intention, that becomes your thing."}, {"time": 7660, "text": "Like let's revolutionize this thing."}, {"time": 7663, "text": "And then you get only so many things."}, {"time": 7665, "text": "It's sad that the bureaucracy has gotten so bulky, but I think the hopeful messages from earlier in our conversation, it seems like a single person can't fix it, but if you hire the right team, it feels like you can."}, {"time": 7681, "text": "Can't fix everything."}, {"time": 7683, "text": "I don't wanna give people unrealistic expectations."}, {"time": 7685, "text": "You can fix a lot, especially in crisis, you can remake America."}, {"time": 7690, "text": "And the reason I know that is because it's already happened twice."}, {"time": 7692, "text": "FDR, or in modern history, FDR and JFK."}, {"time": 7697, "text": "Sorry, FDR and JFK's assassination, LBJ."}, {"time": 7700, "text": "Two hyper competent men who understood government, who understood personnel, and coincidentally were friends."}, {"time": 7709, "text": "I don't think actually people understand this."}, {"time": 7711, "text": "FDR met Johnson three days after he won his election to Congress, special election."}, {"time": 7718, "text": "He was only 29 years old."}, {"time": 7720, "text": "And he left that meeting and called somebody and said, this young man is gonna be president of the United States someday."}, {"time": 7726, "text": "Like even then, like what was within him to understand and to recognize that."}, {"time": 7731, "text": "And sometimes Johnson, as a young member of Congress, would come and have breakfast with FDR, like just to the great political minds of the 20th century, just sitting there talking."}, {"time": 7741, "text": "Like I would give anything to know what was happening."}, {"time": 7744, "text": "Yeah, I hope they were real with each other."}, {"time": 7746, "text": "And there was like a genuine human connection, right?"}, {"time": 7748, "text": "That seems to be the... Well, Johnson wasn't a genuine guy, so probably certainly not."}, {"time": 7753, "text": "Well, I need to read those thousands of pages."}, {"time": 7756, "text": "I've been way too focused on Hitler."}, {"time": 7760, "text": "I was gonna say, one of my goals in coming to this is I was like, I gotta get Lex into two things, because I know he'll love it."}, {"time": 7765, "text": "I know he'll love LBJ, if he takes the time to read the books."}, {"time": 7771, "text": "He's the most... Of all the presidents..."}, {"time": 7772, "text": "I didn't say you'll love him, but you'll love the books about him."}, {"time": 7774, "text": "Because the books are a story of America, the story of politics, the story of power."}, {"time": 7779, "text": "This is the guy who wrote the Power Broker."}, {"time": 7781, "text": "These books are up there with Decline and Follow the Roman Empire by Edward Gibbon, in terms of how power works."}, {"time": 7788, "text": "Study of power."}, {"time": 7790, "text": "No, that's why Carroll wrote the books."}, {"time": 7814, "text": "But he's overlooked for so many of the incredible things that he did with civil rights."}, {"time": 7819, "text": "Nobody else could have done it."}, {"time": 7821, "text": "No one else could have gotten it done."}, {"time": 7823, "text": "And the second thing is, we gotta get you into World War I."}, {"time": 7827, "text": "We gotta get you more into World War I, because I think that's a rabbit hole, which I know you're a Dan Carlin fan."}, {"time": 7833, "text": "So blueprint for Armageddon."}, {"time": 7835, "text": "Yeah, it's good."}, {"time": 7837, "text": "But there's fewer evil people there."}, {"time": 7839, "text": "Yes, but..."}, {"time": 7841, "text": "But that's what actually..."}, {"time": 7843, "text": "There's a banality of that evil, of the Kaiser and of the Austro Hungarians."}, {"time": 7850, "text": "And of... See, I like World War I more because it was unresolved."}, {"time": 7854, "text": "It's one of those periods I was talking to you about, about sometimes you're called and you fail."}, {"time": 7859, "text": "I mean, 50 million people were killed in the most horrific way."}, {"time": 7863, "text": "People literally drowned in the mud, like an entire generation."}, {"time": 7869, "text": "One stat I love is that, Britain didn't need a draft till 1916."}, {"time": 7874, "text": "Like they went two years of throwing people into barbed wire voluntarily."}, {"time": 7880, "text": "And because people love their country and they love the king, and they thought they were going against the Kaiser."}, {"time": 7886, "text": "It's just like that conflict to me, I just can't read enough about it."}, {"time": 7890, "text": "Also just like births Russian Revolution, you know."}, {"time": 7893, "text": "Yeah, I mean... Hitler."}, {"time": 7895, "text": "You can't talk about World War II without World War I."}, {"time": 7897, "text": "And I'm obsessed with the conflict."}, {"time": 7899, "text": "I've read way too many books about it."}, {"time": 7900, "text": "For this reason is, it's unresolved."}, {"time": 7902, "text": "And like the roots of so much of even our current problems are happened in Versailles, right?"}, {"time": 7907, "text": "Like Vietnam is because of the Treaty of Versailles."}, {"time": 7911, "text": "Many ways the Middle Eastern problems and the division of the states there."}, {"time": 7915, "text": "The Treaty of Versailles in terms of the penalties against Germany."}, {"time": 7918, "text": "But also they fall out from those wars on the French and the German population, or the French and the British populations and their reluctance for war in 1939 or 1938."}, {"time": 7930, "text": "When Neville Chamberlain goes, right?"}, {"time": 7932, "text": "Like that's one of the things people don't understand is the actual appetite of the British public at that time."}, {"time": 7936, "text": "They didn't want to go to war."}, {"time": 7937, "text": "Only Churchill, he was the only one in the gathering storm, right?"}, {"time": 7941, "text": "Like being like, hey, this is really bad and all of that."}, {"time": 7944, "text": "And then even in the United States, our streak of isolationism, which sweat."}, {"time": 7948, "text": "I mean, things were because of that conflict."}, {"time": 7952, "text": "We were convinced as a country that we wanted nothing to do with Europe and its problems."}, {"time": 7957, "text": "And in many ways that contributed to the proliferation of Hitler and more."}, {"time": 7961, "text": "So like I'm obsessed with World War I for this reason, which is that it's just like the root."}, {"time": 7966, "text": "It's like the culmination of the monarchies, then the fall, and then just all the shit spills out from there for like a hundred years."}, {"time": 7973, "text": "So World War I is like the most important shift in human history versus World War II is like a consequence of that."}, {"time": 7980, "text": "Yeah, so I have a degree in security studies from Georgetown."}, {"time": 7983, "text": "And one of the thing is that we would focus a lot on that is like war and, but also like the complexity around war."}, {"time": 7991, "text": "And it's funny."}, {"time": 7992, "text": "We never spent that much time on World War II because it was actually quite of a clean war."}, {"time": 7997, "text": "It's a very atypical war as in the war object, which we learned from World War I is we must inflict suffering on the German people and invade the borders of Germany and destroy Hitler."}, {"time": 8010, "text": "Like the center of gravity is the Nazi regime and Hitler."}, {"time": 8014, "text": "So it had a very basic begin and end."}, {"time": 8017, "text": "Begin, liberate France, invade Germany, destroy Hitler, reoccupy, rebuild."}, {"time": 8024, "text": "World War I, what are you fighting for?"}, {"time": 8026, "text": "Like, are you, I mean, and nobody even knew."}, {"time": 8029, "text": "You can go to the German general staff."}, {"time": 8031, "text": "They were like, even in 1917, they're like, the war was worth it because now we have Luxembourg."}, {"time": 8037, "text": "Like you killed 2 million of your citizens for fucking Luxembourg and like half of Belgium, which is now like a pond."}, {"time": 8042, "text": "And same thing, the French are like, well, the French more so they're defending their borders, but like, what are the British fighting for?"}, {"time": 8049, "text": "Why did hundreds of thousands of British people die?"}, {"time": 8051, "text": "In order to preserve the balance of power in Europe and prevent the Kaiser from having a port on the English Channel?"}, {"time": 8059, "text": "Like really, that's why?"}, {"time": 8061, "text": "That's more what wars are is they become these like atypical, they become these protracted conflicts with a necessary diplomatic resolution."}, {"time": 8073, "text": "It's not clean, it's very dirty."}, {"time": 8076, "text": "It usually leads in the outbreak of another war and another war and another war and a slow burn of ethnic conflict, which bubbles up."}, {"time": 8083, "text": "So that's why I look at that one even, because it's more typical of warfare and how it works."}, {"time": 8089, "text": "Exactly, it's kind of interesting."}, {"time": 8091, "text": "You're making me realize that World War II is one of the rare wars where you can make a strong case for it's a fight of good versus evil."}, {"time": 8099, "text": "Yeah, just war theory, obviously."}, {"time": 8101, "text": "Like, yeah, they're literally slaughtering Jews."}, {"time": 8102, "text": "Like, we have to kill them."}, {"time": 8104, "text": "And there's one person doing it."}, {"time": 8105, "text": "I mean, there's one person at the core."}, {"time": 8111, "text": "And it's short and there's a clear aggression."}, {"time": 8115, "text": "It's interesting that Dan Carlin has been avoiding Hitler as well."}, {"time": 8120, "text": "Yeah, probably for this reason."}, {"time": 8123, "text": "Probably for this reason."}, {"time": 8125, "text": "I mean, but it's complicated too, because there's a pressure."}, {"time": 8128, "text": "That guy has his demons."}, {"time": 8130, "text": "I love Dan so much."}, {"time": 8131, "text": "So this is the, I don't know if you feel this pressure, but as a creative, he feels the pressure of being maybe not necessarily correct, but maybe correct in the sense that his understanding, he gets to the bottom of why something happened, of why something happened, of what really happened."}, {"time": 8157, "text": "Get to the bottom of it before he can say something publicly about it."}, {"time": 8162, "text": "And he is tortured by that burden."}, {"time": 8164, "text": "I know, you know, he takes so much shit from the historical community for no reason."}, {"time": 8169, "text": "I think he's the greatest popularizer, quote unquote, of history."}, {"time": 8173, "text": "And I wish more people in history understood it that way."}, {"time": 8177, "text": "He was an inspiration to me."}, {"time": 8178, "text": "I mean, I do some videos sometimes on my Instagram now where I'll do like a book tour."}, {"time": 8182, "text": "I'll be like, here's my bookshelf of these presidents."}, {"time": 8184, "text": "And like, here's what I learned from this book and this book and this."}, {"time": 8186, "text": "And that was very much like a skill I learned from him of being like, you know, as a historian writes."}, {"time": 8193, "text": "You know, I just love the way he talks."}, {"time": 8195, "text": "He's like, in the mud."}, {"time": 8198, "text": "I mean, you know, he'll be like, quote, quote."}, {"time": 8200, "text": "I just, I love, he inspires me, man."}, {"time": 8204, "text": "He really does to like learn more."}, {"time": 8206, "text": "And I've read, I bought a lot of books because of Dan Carlin."}, {"time": 8209, "text": "He'll be, you know, because of this guy, because of that guy, in terms of, you know, another thing he does, which nobody else, and I'm probably guilty of this, he focuses on the actual people involved."}, {"time": 8219, "text": "Like he would tell the story of actual British soldiers in World War I."}, {"time": 8224, "text": "And I probably, and maybe you're guilty of this too, we over focus on what was happening in the German general staff, what was happening in the British general staff."}, {"time": 8232, "text": "And he doesn't make that mistake."}, {"time": 8234, "text": "That's why he tells real history."}, {"time": 8236, "text": "Yeah, and it gives it a feeling."}, {"time": 8238, "text": "The result is that there's a feeling, you get the feeling of what it was like to be there."}, {"time": 8244, "text": "You know, you're becoming, quickly becoming more and more popular."}, {"time": 8250, "text": "Speaking about political issues in part, do you feel a burden, like almost like the prison of your prior convictions of having to, being popular with a certain kind of audience and thereby unable to really think outside the box?"}, {"time": 8271, "text": "I had, I've really struggled with this."}, {"time": 8274, "text": "I came up in right wing media."}, {"time": 8276, "text": "I came up a much more doctrinaire conservative in my professional life."}, {"time": 8282, "text": "I wasn't always conservative."}, {"time": 8282, "text": "We can get to that later if you want."}, {"time": 8285, "text": "And I did feel an immense pressure after the election by people to say, wanted me to say the election was stolen."}, {"time": 8297, "text": "And I knew that I had a sizable part of my audience."}, {"time": 8301, "text": "Oh, well, here's the benefit."}, {"time": 8302, "text": "Most people know me from Rising, which is with Crystal and me."}, {"time": 8306, "text": "That is inherently a left right program."}, {"time": 8309, "text": "So it's a large audience."}, {"time": 8311, "text": "So I felt comfortable and I knew that I could still be fine in terms of my numbers, whatever, because a lot, many people knew me who were on the left."}, {"time": 8320, "text": "And if really, you know, my right listeners abandoned me, so be it."}, {"time": 8351, "text": "And I just wouldn't do it."}, {"time": 8353, "text": "And that was hard, man."}, {"time": 8355, "text": "Like I feel more politically homeless right now than I ever have, but I have realized in the last couple of months that's the best thing that ever happened to me."}, {"time": 8367, "text": "It's true freedom."}, {"time": 8368, "text": "I now, I say exactly what I think."}, {"time": 8372, "text": "And it's not that I wasn't doing that before."}, {"time": 8374, "text": "It's maybe I would avoid certain topics or like I would think about things more from a team perspective of like, am I making sure that, it's, I'm not saying I didn't fight it."}, {"time": 8386, "text": "And I still, I criticize the right plenty and Trump plenty before the election and more."}, {"time": 8391, "text": "It's more just like, I no longer feel as if I even have the illusion of a stake within the game."}, {"time": 8398, "text": "I'm like, I only look at myself as an outside observer and I will only call it as I see it truly."}, {"time": 8405, "text": "And I was aspiring to that before, but I had to have, in a way, Trump stop the steal thing."}, {"time": 8413, "text": "It like took my shackles off 100%."}, {"time": 8416, "text": "Cause I was like, no, this is bullshit."}, {"time": 8417, "text": "And I'm going to say it's bullshit."}, {"time": 8418, "text": "And I think it's bad."}, {"time": 8420, "text": "And I think it's bad for the Republican party."}, {"time": 8422, "text": "And if people in the Republican party don't agree with me on that, that's fine."}, {"time": 8426, "text": "I'm just not going to be necessarily like associated with you anymore."}, {"time": 8430, "text": "This is probably one of the first political liberal politics related conversations we've had."}, {"time": 8435, "text": "I mean, unless you count Michael Malice, who."}, {"time": 8438, "text": "He was great."}, {"time": 8441, "text": "He's the funny guy."}, {"time": 8442, "text": "He's not so much political as he is like burning down, man."}, {"time": 8447, "text": "He leans too far in anarchy for me."}, {"time": 8450, "text": "I think he's."}, {"time": 8451, "text": "There's a place for that."}, {"time": 8453, "text": "It's almost, well, first of all, he's working on a new book, which I really appreciate."}, {"time": 8457, "text": "Outside of the, he's working on like a big book for a while, which is White Pill."}, {"time": 8462, "text": "He's also working on this like short little thing, which is like anarchist handbook or something like that."}, {"time": 8471, "text": "It's like Anarchy for Idiots or something like that, which I think is really."}, {"time": 8479, "text": "Well, me being an idiot and being curious about anarchy seems useful."}, {"time": 8483, "text": "So I like those kinds of books."}, {"time": 8484, "text": "That's Russian heritage, man."}, {"time": 8486, "text": "Anarchist 101."}, {"time": 8489, "text": "I find those kinds of things a useful thought experiment because that's why it's frustrating to me when people talk about communism, socialism, or even capitalism, where they can't enjoy the thought experiment of like why did communism fail and maybe ask the question of like, is it possible to make communism succeed or are there good ideas in communism?"}, {"time": 8517, "text": "Like I enjoy the thought experiment, like the discourse of it, like the reasoning and like devil's advocate and all that."}, {"time": 8524, "text": "People have like, seem to not have patience for that."}, {"time": 8527, "text": "They're like, communism bad, red."}, {"time": 8529, "text": "I was obsessed with the question and still am."}, {"time": 8531, "text": "I will never be, I will never quench my thirst for Russian history."}, {"time": 8538, "text": "I love that period of 1890 to 1925."}, {"time": 8546, "text": "It's just like, it's so fucking crazy."}, {"time": 8550, "text": "Like the autocracy embodied in Czar Alexander."}, {"time": 8555, "text": "And then you get this like weird fail son, Nicholas, who is kind of a good guy, but also terrible."}, {"time": 8562, "text": "And also Russian autocracy itself is terrible."}, {"time": 8564, "text": "And then I just became obsessed with the question of like, why did the Bolshevik revolution succeed?"}, {"time": 8569, "text": "Because like people in Russia didn't necessarily want Bolshevism."}, {"time": 8573, "text": "People suffered a lot under Bolshevism and it led to Stalinism."}, {"time": 8578, "text": "How did Vladimir Lenin do it, right?"}, {"time": 8581, "text": "Like, and I became obsessed with that question."}, {"time": 8584, "text": "And it's still, I find it so interesting, which is that series of accidents of history, incredible boldness by Lenin, incredible real politic, smart, unpopular decisions made by Trotsky and Stalin, and just like the arrogance of the Czars and of the Russian like autocracy."}, {"time": 8611, "text": "But at the same time, there's all these like cultural implications of this, right?"}, {"time": 8615, "text": "In terms of like how it became hollowed out post Catherine the Great and all that."}, {"time": 8620, "text": "I was obsessed with autocracy because Russia wasn't actual autocracy."}, {"time": 8624, "text": "And like actually, and I'm like, it was there."}, {"time": 8626, "text": "Like they didn't even remove serfdom to like the civil war in America."}, {"time": 8632, "text": "Like, you know, and nobody really talks about it."}, {"time": 8635, "text": "And I just became, yeah, I was like, was Bolshevism a natural reaction to the excesses of Czarism?"}, {"time": 8643, "text": "There is a convenient explanation where that is true."}, {"time": 8647, "text": "But there were also a series of decisions made by Lenin and Stalin to kill many of the people in the center left and marginalized them and also not to associate with the more quote unquote, like amenable communists in order to make sure that their pure strain of Bolshevism was the only thing."}, {"time": 8668, "text": "And the reason I like that is because it comes back to a point I made earlier."}, {"time": 8671, "text": "It's all about intentionality, which is that you actually can will something into existence even if people don't want it."}, {"time": 8678, "text": "That was the craziest thing."}, {"time": 8679, "text": "Like nobody wanted this, but it's still ruled for half a century, more actually."}, {"time": 8685, "text": "I mean, almost 75 years."}, {"time": 8687, "text": "To think that there could have been a history of the Soviet Union that was dramatically different than Leninism, Stalinism, that was completely different."}, {"time": 8700, "text": "Like almost would be the American story."}, {"time": 8703, "text": "Yeah, easily."}, {"time": 8704, "text": "I mean, there's a world where, and I don't have all the characters, there's like Kerensky and then there was like whoever Lenin's number two, Stalin's chief rival."}, {"time": 8712, "text": "And even, I mean, look, even a Soviet Union led by Trotsky, that's a whole other world, right?"}, {"time": 8717, "text": "Like literally a whole other world."}, {"time": 8719, "text": "And yeah, it's just, I don't know."}, {"time": 8721, "text": "I find it so interesting."}, {"time": 8722, "text": "I will never not be fascinated by Russia."}, {"time": 8724, "text": "I always will."}, {"time": 8725, "text": "It's funny that I get to talk to you."}, {"time": 8726, "text": "Cause it's like, I read this book."}, {"time": 8728, "text": "I forget what it's called."}, {"time": 8729, "text": "It won, I think it won a Pulitzer prize."}, {"time": 8731, "text": "And it was like the story of, I tried to understand Russia post Crimea."}, {"time": 8737, "text": "Cause I came up amongst people who are much more like neoconservative and they're like, fuck Russia, Russia bad."}, {"time": 8743, "text": "And I was like, okay, like what do these people think?"}, {"time": 8746, "text": "And we have this narrative of like the fall of the Soviet Union."}, {"time": 8749, "text": "And then I read this book from the perspective of Russians who lived through the fall."}, {"time": 8754, "text": "And they were like, this is, I was like, this is terrible."}, {"time": 8756, "text": "Like actually the introduction of capitalism was awful."}, {"time": 8759, "text": "And like the rise of all these crazy oligarchs."}, {"time": 8763, "text": "That's why Putin was, came to power to like restore, restore order to the oligarchy."}, {"time": 8771, "text": "And he still talks to this day."}, {"time": 8773, "text": "Do you guys, I mean, that's always the threat of like, do you want to return to the nineties?"}, {"time": 8777, "text": "Do you want to return to Yeltsin?"}, {"time": 8780, "text": "But the thing is in the West, we have this like our own propaganda of like, no, Yeltsin was great."}, {"time": 8785, "text": "That was the golden age."}, {"time": 8785, "text": "What could have been with Russia?"}, {"time": 8787, "text": "And I was like, well, what do actual Russians think?"}, {"time": 8789, "text": "And so that, yeah, I'll always be fascinated by it."}, {"time": 8794, "text": "And then just like to understand the idea of feeling encircled by NATO and all of that, you have to understand like Russian defense theory all the way of going back to the czars has always been defense in depth in terms of having Estonia, Lithuania, and more as like protection of the heartland."}, {"time": 8814, "text": "I'm not justifying in this."}, {"time": 8815, "text": "So NATO shills like, please don't come after me."}, {"time": 8817, "text": "But look, Estonians like NATO."}, {"time": 8821, "text": "They want to be in NATO."}, {"time": 8822, "text": "So I don't want to minimize that."}, {"time": 8823, "text": "I'm more just saying like, I understand him and Russia much better having done that."}, {"time": 8828, "text": "And we are very incapable in America."}, {"time": 8831, "text": "I think this is probably because my parents are immigrants and I've traveled a lot."}, {"time": 8834, "text": "Of like putting yourself in the mind of people who aren't Western and haven't lived a history, especially our lives of America's fucking awesome."}, {"time": 8843, "text": "We're the number one country in the world."}, {"time": 8844, "text": "Like we're literally better than you, like in many ways."}, {"time": 8847, "text": "And they can't empathize with people who have suffered so much."}, {"time": 8853, "text": "And I just, yeah, it's just so interesting to me."}, {"time": 8856, "text": "What about if we could talk for just a brief moment about the human of Putin and power, you are clearly fascinated by power."}, {"time": 8868, "text": "Do you think power changed Putin?"}, {"time": 8871, "text": "Do you think power changes leaders?"}, {"time": 8874, "text": "If you look at the great leaders in history, whether it's LBJ, FDR, do you think power really changes people?"}, {"time": 8883, "text": "Like, is there a truth to that kind of old proverb?"}, {"time": 8886, "text": "It reveals, I think that's what it is."}, {"time": 8888, "text": "It reveals."}, {"time": 8889, "text": "So Putin was a much more deft politician, much more amenable to the West."}, {"time": 8895, "text": "If you think back, you know, to 2001 and more, right when he came, cause he was still, cause at that time his biggest problem was intra Russian politics, right?"}, {"time": 8904, "text": "Like it was all consolidating power within the oligarchy."}, {"time": 8907, "text": "Once he did that by around like 2007, there's that famous time when he spoke out against the West at the Munich security conference."}, {"time": 8916, "text": "I forget when it was."}, {"time": 8917, "text": "And that's when everybody in the audience was like, whoa."}, {"time": 8920, "text": "And he was talking about like NATO encirclement and like, we will not be beaten back by the West."}, {"time": 8925, "text": "Very shortly afterwards, like the Georgia invasion happens."}, {"time": 8929, "text": "And that was like a big wake up call of like, we will not be pushed around anymore."}, {"time": 8933, "text": "I mean, he said before publicly, like the worst thing that ever happened was the fall."}, {"time": 8937, "text": "Or what did he say?"}, {"time": 8938, "text": "He was like, the fall of the Soviet Union was a tragedy, right?"}, {"time": 8941, "text": "Of course, people in the West were like, what?"}, {"time": 8942, "text": "I'm like, I get it, right?"}, {"time": 8944, "text": "Like they were a superpower."}, {"time": 8945, "text": "And now their population is declining."}, {"time": 8948, "text": "Like it's like a Petro state."}, {"time": 8950, "text": "Like, I understand."}, {"time": 8952, "text": "I understand like how somebody could feel about that."}, {"time": 8955, "text": "I think it revealed his character, which is that I think he thinks of himself probably as he always has since 2001 as like this benevolent, almost as a benevolent dictator."}, {"time": 8969, "text": "He's like, without me, the whole system would collapse."}, {"time": 8971, "text": "I'm the only guy keeping all these people in check."}, {"time": 8975, "text": "Most Russians probably do support Putin because they feel like they support some form of functional government."}, {"time": 8983, "text": "And they view it as like a check against that, which is a long, has a long history within Russia too."}, {"time": 8990, "text": "So I don't know if it changed him."}, {"time": 8993, "text": "I think it just revealed him because it's not like he, I mean, he has a bill."}, {"time": 8996, "text": "You know, Navalny has put that like billion dollar palace and all that."}, {"time": 9001, "text": "Sometimes I feel like Putin does that for show."}, {"time": 9003, "text": "He doesn't seem like somebody who indulges in all that stuff."}, {"time": 9006, "text": "Or maybe we just don't see it."}, {"time": 9008, "text": "Well, I don't, it's very difficult for me to understand."}, {"time": 9011, "text": "I've been hanging out, thanks to Clubhouse."}, {"time": 9013, "text": "A lot of, I've gotten to learn a lot about the Navalny folks and it's been very educational."}, {"time": 9021, "text": "Made me ask a lot of important questions about what, you know, question a lot of my assumptions about what I do and don't know."}, {"time": 9029, "text": "But I'll just say that I do believe, you know, there's a lot of the Navalny folks say that Putin is incompetent and is a bad executive, like is bad at basically running government."}, {"time": 9044, "text": "But to me."}, {"time": 9046, "text": "Well, why do Russians not think that?"}, {"time": 9049, "text": "Well, they probably say propaganda."}, {"time": 9050, "text": "They would say it's the press."}, {"time": 9051, "text": "Yeah, they would say the control."}, {"time": 9052, "text": "There is a strong either control or pressure on the press, but I think there is a legitimate support and love of Putin in Russia that is not grounded in just misinformation and propaganda."}, {"time": 9065, "text": "There's legitimacy there."}, {"time": 9067, "text": "Mostly I tried to remain apolitical and actually genuinely remain apolitical."}, {"time": 9072, "text": "I am legitimately not interested in the politics of Russia of today."}, {"time": 9078, "text": "I feel I have some responsibility and I'll take that responsibility on as I need to."}, {"time": 9083, "text": "But my fascination as it is perhaps with you in part is in the historical figure of Putin."}, {"time": 9125, "text": "Those are the bickering of the day, just like we were saying, what will actually be remembered about this moment in history?"}, {"time": 9131, "text": "Totally, he's a transformational figure in Russian history."}, {"time": 9134, "text": "Really, like the bridge between the fall of the Soviet Union and the chaos of Yeltsin, that will be how he's remembered."}, {"time": 9141, "text": "The only question is what comes next and what he wants to come next."}, {"time": 9144, "text": "I'm always, I'm like, he's getting up."}, {"time": 9146, "text": "How old are you, 60 something?"}, {"time": 9147, "text": "Yeah, 60."}, {"time": 9148, "text": "So he would be, I think he would be 80."}, {"time": 9151, "text": "So with the change of the constitution, he cannot be president until 2034, I think it is."}, {"time": 9164, "text": "So he would be like 80 something and he would be in power for over 30 years, which is longer than Stalin."}, {"time": 9171, "text": "But he still seems to be."}, {"time": 9174, "text": "Seems fit."}, {"time": 9176, "text": "I think he's gonna be around for a long time."}, {"time": 9177, "text": "But this is a fascinating question that you ask, which is like, what does he want?"}, {"time": 9183, "text": "I don't, and this is where I think, given all of his behavior and more, I don't know if it's about money."}, {"time": 9189, "text": "I don't know if it's about enriching himself."}, {"time": 9191, "text": "Obviously he did, to the tune of billions and billions and billions of dollars."}, {"time": 9195, "text": "But I think he probably, he's as close to like an actual Russian nationalist, like at the top, who really does believe in Russia as its rightful superpower."}, {"time": 9206, "text": "Everything he does seems to stem from that opposition to NATO, intro to Syria, like wanting to play a large role in affairs, deeply distrustful and yet coveting of the European powers."}, {"time": 9220, "text": "Like, I could describe every czar in those same language."}, {"time": 9224, "text": "Like every czar falls into the exact same category."}, {"time": 9227, "text": "Yeah, and I mean, it makes me wonder, looking at some of the biggest leaders in human history, to ask the question of what was the motivation?"}, {"time": 9235, "text": "What was the motivation for even just the revolutionaries like Lenin, Trotsky, and Stalin?"}, {"time": 9240, "text": "What was the motivation?"}, {"time": 9242, "text": "Because it sure as hell seems like the motivation was at least in part driven by the idea, by ideas, not self interest of like power."}, {"time": 9255, "text": "For Lenin, it was, I think he was a true believer and an actual narcissist who thought he was the only one who could do it."}, {"time": 9261, "text": "Stalin, I do think just wanted power."}, {"time": 9263, "text": "And realized, well, I don't know."}, {"time": 9265, "text": "Look, he wrote very passionately when he was young."}, {"time": 9267, "text": "And he was, he really believed in communism."}, {"time": 9270, "text": "In the beginning he did."}, {"time": 9271, "text": "I'm always fascinated as I'm like, around 1920, what happened, right?"}, {"time": 9276, "text": "Post revolution, you crushed the whites."}, {"time": 9280, "text": "Now it's all about consolidation."}, {"time": 9282, "text": "That's where the games really began."}, {"time": 9284, "text": "And I'm like, I don't think that was about communism."}, {"time": 9288, "text": "Yeah, maybe it became a useful propaganda tool, but it still seemed like he believed in it."}, {"time": 9295, "text": "Whether it was, of course, this is the question."}, {"time": 9298, "text": "I mean, this is the problem with conspiracy theories for me."}, {"time": 9302, "text": "And this is legitimate criticism towards me about conspiracy theories, which is just because you're not like this doesn't mean others aren't like this."}, {"time": 9311, "text": "So like, I can't believe that somebody be like deeply two faced."}, {"time": 9316, "text": "Oh, I've met them, you're welcome to Washington."}, {"time": 9320, "text": "But like, I think that I would be able to detect like, no."}, {"time": 9327, "text": "Well, this, my question is, well, so there's differences."}, {"time": 9330, "text": "There's two face, like there's different levels of two face."}, {"time": 9335, "text": "Like what I mean is to be killing people and it's like house of cards style, right?"}, {"time": 9343, "text": "And still present a front like you're not killing people."}, {"time": 9349, "text": "I don't know if, I guess it's possible, but I just don't see that at scale."}, {"time": 9355, "text": "Like there's a lot of people like that."}, {"time": 9356, "text": "And I don't, I have trouble imagining some, that's such a compelling narrative that people like to say."}, {"time": 9366, "text": "Like people, that's the conspiratorial mindset."}, {"time": 9369, "text": "I think that skepticism was really powerful and important to have because it's true."}, {"time": 9374, "text": "A lot of powerful people abuse their power, but saying that about, I feel like people over assume that."}, {"time": 9381, "text": "It's like, I see that with use of steroids often in sports."}, {"time": 9385, "text": "People seem to make that claim about like everybody who's successful and I want to be very, I don't know."}, {"time": 9392, "text": "Something about me wants to be cautious because I want to give people a chance."}, {"time": 9397, "text": "Being purely cynical isn't helpful."}, {"time": 9399, "text": "People say this about me."}, {"time": 9400, "text": "He's only saying this to do this."}, {"time": 9402, "text": "But at the same time, being naively optimistic about everything is also a kind of pedophilic scheme."}, {"time": 9407, "text": "People are going to fuck you over."}, {"time": 9409, "text": "And more importantly, that doesn't bother me."}, {"time": 9412, "text": "More importantly, you're not going to be able to reason about how to create systems that are going to be robust to corruption, to malevolent parties."}, {"time": 9421, "text": "So in order to create, you have to have a healthy balance of both, I suppose, especially if you want to actually engineer things that work in this world that has evil in it."}, {"time": 9433, "text": "I can't believe there's a book of Hitler on the desk."}, {"time": 9437, "text": "We've mentioned a lot of books throughout this conversation."}, {"time": 9440, "text": "I wonder, and this makes me really curious to explore in a lot of depth the kind of books that you're interested in."}, {"time": 9450, "text": "I think you mentioned in your show that you provide recommendations."}, {"time": 9457, "text": "In the form of spoken word, can you beyond what we've already recommended mention books, whether it is historical, nonfiction, or whether it's more like philosophical or even fiction that had a big impact on your life?"}, {"time": 9472, "text": "Is there a few that you can mention?"}, {"time": 9474, "text": "I already talked about the Johnson books, so I'll leave that alone."}, {"time": 9476, "text": "Robert A. Caro, he's still alive, thank God."}, {"time": 9479, "text": "He's finishing the last book."}, {"time": 9481, "text": "I hope he makes it."}, {"time": 9483, "text": "So those Johnson books."}, {"time": 9485, "text": "Second, can I ask you a question about those books?"}, {"time": 9488, "text": "What the hell do you fit into so many pages?"}, {"time": 9491, "text": "Everything, man."}, {"time": 9492, "text": "Let me tell you this."}, {"time": 9493, "text": "So I'll just give you an anecdote."}, {"time": 9494, "text": "This is why I love these books."}, {"time": 9496, "text": "The beginning, the first book is about Lyndon Johnson."}, {"time": 9499, "text": "His life, when he gets elected to Congress, the book begins with a history of Texas and its weather patterns, and then of his great, great grandfather moving to Texas."}, {"time": 9512, "text": "Then the story of that, about a hundred or so pages in, you get to Lyndon Johnson."}, {"time": 9519, "text": "Which is you get."}, {"time": 9520, "text": "It's like a Tolstoy style retelling."}, {"time": 9522, "text": "This is the thing, it's not a biography, it's a story of the times."}, {"time": 9525, "text": "That's a great biography."}, {"time": 9527, "text": "So another one, this isn't part of my list, so don't do it, is Grant, Ron Chernow."}, {"time": 9534, "text": "Ron Chernow's Grant, it's a thousand pages."}, {"time": 9537, "text": "And the reason I tell everybody to read it is it's not just the story of Grant, it is the story of pre civil war America, the Mexican American war, the civil war and reconstruction, all told in the life of one person who was involved in all three."}, {"time": 9552, "text": "Most people don't know anything about the Mexican American war."}, {"time": 9555, "text": "Most people don't know anything about reconstruction."}, {"time": 9558, "text": "Now more so because people are talking, it's a hot topic now."}, {"time": 9561, "text": "I've been reading about it for years."}, {"time": 9562, "text": "That is another thing people need to learn a lot more about."}, {"time": 9566, "text": "In terms of non history books, the book that probably had the most impact on me, which is also a historical nonfiction is I am obsessed with Antarctic exploration."}, {"time": 9580, "text": "And it all began with a book called Shackleton's Incredible Journey, which is the collection of diaries of everybody who was on Shackleton's journey."}, {"time": 9591, "text": "For those who don't know, Shackleton was the last explorer of the heroic age of Antarctic exploration."}, {"time": 9599, "text": "He led a ship called the Endurance, which froze in the ice off the coast of Antarctica in 1914."}, {"time": 9610, "text": "And they didn't have radios over the last exploration, the last one without the age of radio."}, {"time": 9616, "text": "And he happens to freeze in the ice."}, {"time": 9618, "text": "And then the ship collapses after a year frozen in the ice."}, {"time": 9623, "text": "And this man leads his entire crew from that ship onto the ice with a team of dogs, survives out on the ice for another year with three little lifeboats and is able to get all of his men, every single one of them alive to an island hundreds of miles away called Elephant Island."}, {"time": 9644, "text": "And when they got there, he had to leave everybody behind except for six people."}, {"time": 9650, "text": "And him and two other guys, I'm forgetting their names, navigated by the stars 800 miles through the Drake Passage with seas of hundreds of feet to Prince, I think it's called Prince George's Island."}, {"time": 9665, "text": "And then when they got to Prince George's Island, they landed on the wrong side and they had to hike from one side to the other to go and meet the whalers."}, {"time": 9675, "text": "And every single one of those things was supposed to be impossible."}, {"time": 9678, "text": "Nobody was ever supposed to hike that island."}, {"time": 9681, "text": "It wasn't done again until like the 1980s with professional equipment."}, {"time": 9685, "text": "He did it after two years of starvation."}, {"time": 9688, "text": "Nobody was ever supposed to make it from Elephant Island to Prince George."}, {"time": 9693, "text": "The guy, they had to hold him steady, his legs, so that he could chart the stars."}, {"time": 9698, "text": "And if they miss this island, they're into open sea."}, {"time": 9701, "text": "They're dead."}, {"time": 9702, "text": "And then before that, how do you survive for a year on the ice?"}, {"time": 9706, "text": "On seals."}, {"time": 9707, "text": "And before that, he kept his crew from depression frozen one year in the ice."}, {"time": 9713, "text": "It's just an amazing story."}, {"time": 9715, "text": "And it made me obsessed with Antarctic exploration."}, {"time": 9718, "text": "So I've read like 15 books on it."}, {"time": 9720, "text": "What the hell is it about the human spirit?"}, {"time": 9722, "text": "That's the thing about Antarctica is it brings it out of you."}, {"time": 9725, "text": "So for example, I read another one recently called Mawson's Will."}, {"time": 9728, "text": "Douglas Mawson, he was an Australian."}, {"time": 9730, "text": "He was on one of the first Robert Frost expeditions."}, {"time": 9735, "text": "He leads an expedition down to the South."}, {"time": 9737, "text": "Him and a partner, they're leading explorations, 1908, something like that."}, {"time": 9743, "text": "They're going around Antarctica with dog teams."}, {"time": 9747, "text": "And what happens is they keep going over these snow bridges where there's a crevice, but it's covered in snow."}, {"time": 9754, "text": "And so one of the lead driver, the dogs go over and they plummet."}, {"time": 9760, "text": "And that sled takes with it."}, {"time": 9763, "text": "So the guy survives, but that sled takes all their food, half the dogs, their stove, the camping tent, the tent specifically designed for the snow, everything."}, {"time": 9776, "text": "And they're hundreds of miles away from base camp."}, {"time": 9779, "text": "He and this guy have to make it back there in time before the ship comes to come get them on an agreed upon date."}, {"time": 9787, "text": "And he makes it."}, {"time": 9788, "text": "But the guy he was with, he dies."}, {"time": 9791, "text": "And it's a crazy story."}, {"time": 9792, "text": "First of all, they have to eat the dogs."}, {"time": 9794, "text": "A really creepy part of Antarctic exploration is everyone ends up eating dogs at different points."}, {"time": 9800, "text": "And part of the theory, which is so crazy, is that the guy he was with was dying because they were eating dog liver."}, {"time": 9808, "text": "And dog liver has a lot of vitamin E, which if you eat too much of it, can give you like a poisoning."}, {"time": 9814, "text": "And so Mawson, by trying to help his friend, was giving him more liver."}, {"time": 9818, "text": "Of all the things that kills you."}, {"time": 9820, "text": "I know, it's dog liver."}, {"time": 9822, "text": "And so his friend ends up dying, have a horrific heart attack, all of that."}, {"time": 9826, "text": "Mawson crawls back hundreds of miles away, makes it back to base camp hours after the ship leaves."}, {"time": 9834, "text": "And two guys or a couple of guys stayed behind for him."}, {"time": 9837, "text": "And he basically has to recuperate for like six months before he can even walk again."}, {"time": 9842, "text": "But it's like you were saying about the human spirit."}, {"time": 9844, "text": "It's like Antarctica brings that out of people."}, {"time": 9847, "text": "Or Amundsen, the guy who made it to the South Pole, Robert Amundsen, oh my God."}, {"time": 9852, "text": "Like this guy trained his whole life in the ice from Norway to make it to the South Pole."}, {"time": 9860, "text": "And he beat Robert Frost, the British guy with all this money and all these, I could go on this forever."}, {"time": 9866, "text": "I'm obsessed with it."}, {"time": 9867, "text": "Well, first of all, I'm gonna take this part of the podcast."}, {"time": 9871, "text": "I'm gonna set it to music."}, {"time": 9872, "text": "I'm gonna listen to it."}, {"time": 9873, "text": "Cause I've been whining and bitching about running 48 miles of Goggins this next weekend."}, {"time": 9879, "text": "And this is gonna be so easy."}, {"time": 9881, "text": "I'm just gonna listen to this over and over in my head."}, {"time": 9883, "text": "You're gonna be."}, {"time": 9884, "text": "Elon's obsessed with Shackleton."}, {"time": 9885, "text": "He talks about him all the time."}, {"time": 9886, "text": "He uses, I was gonna ask you about that."}, {"time": 9888, "text": "He uses an example of that as an example of what Mars colonization would be like."}, {"time": 9898, "text": "No, Antarctica is as close to you can simulate that."}, {"time": 9903, "text": "Antarctica is as close to what you could simulate what it would get."}, {"time": 9906, "text": "That Nat Geo series on Mars, I'm not sure if you watched it, it's incredible."}, {"time": 9910, "text": "Elon's actually in it."}, {"time": 9911, "text": "And it's like, they get there, everything goes wrong."}, {"time": 9915, "text": "Somebody dies, like it's horrible."}, {"time": 9919, "text": "They can't find any water."}, {"time": 9920, "text": "It's not working."}, {"time": 9922, "text": "Is it like simulating the experience of what it'd be like to colonize?"}, {"time": 9925, "text": "So it's like a docu series where the fictionalized part is the like astronauts on Mars, but then they're interviewing people like Elon Musk and others who were the ones who like paved the way to get to Mars."}, {"time": 9938, "text": "So it's a really interesting concept."}, {"time": 9940, "text": "I think it's on Netflix."}, {"time": 9941, "text": "And yeah, I agree with him 100%, which is that the first guys to make, like for example, Robert Frost, who went to Australia, sorry, to Antarctica, the British explorer who was beaten to the South Pole three weeks by Robert Amundsen, he died on the way back."}, {"time": 9959, "text": "And the reason why is because he wasn't well prepared."}, {"time": 9961, "text": "He was arrogant."}, {"time": 9962, "text": "He didn't have the proper amounts of supplies."}, {"time": 9966, "text": "His team had terrible morale."}, {"time": 9968, "text": "Antarctica is a brutal place."}, {"time": 9969, "text": "If you fuck up one time, you die."}, {"time": 9972, "text": "And it's like, and this is what you read a lot about, which is the reason why such heroic characters like Shackleton Shine is a lot of people died."}, {"time": 9980, "text": "Like there were some people who got frozen in the eye."}, {"time": 9983, "text": "I mean, man, this again also came to the North exploration."}, {"time": 9987, "text": "So I read a lot about like the exploration of the North Pole and same thing."}, {"time": 9992, "text": "These unextraordinary men take people out into the ice and get frozen out there for years and shit goes so bad."}, {"time": 10000, "text": "They end up eating each other."}, {"time": 10002, "text": "They all die."}, {"time": 10003, "text": "There's a famous, one I'm forgetting his name, the British Franklin expedition, where they went searching for them for like 20 years."}, {"time": 10010, "text": "And they eventually came across a group of Inuit who were like, oh yeah, we saw some weird white men here like 15 years ago."}, {"time": 10016, "text": "And they find their bones and there's like saw marks, which showed that they were eating each other."}, {"time": 10021, "text": "So history remembers the ones who didn't eat each other."}, {"time": 10023, "text": "Yeah, well, yeah, we remember the ones who made it, but there are."}, {"time": 10029, "text": "And that would be the story of Mars as well."}, {"time": 10031, "text": "That will be the story of Mars."}, {"time": 10032, "text": "But, and nevertheless, that's the interesting thing about Antarctica."}, {"time": 10036, "text": "Nevertheless, something about human nature drives us to explore it."}, {"time": 10042, "text": "And that seems to be like, you know, a lot of people have this kind of, to me, frustrating conversations like, well, Earth is great, man."}, {"time": 10051, "text": "Why do we need to colonize Mars?"}, {"time": 10053, "text": "You just don't get it."}, {"time": 10056, "text": "It's the same people that say like, why are you running?"}, {"time": 10059, "text": "Like, why are you running a marathon?"}, {"time": 10061, "text": "What are you running from, man?"}, {"time": 10064, "text": "It's pushing the limits of the human mind of what's possible."}, {"time": 10071, "text": "It's George Mallory because it's there."}, {"time": 10075, "text": "And that's somehow actually the result of that, if you want to be pragmatic about it, there's something about pushing that limit that has side effects that you don't expect that will create a better world back home for the people, not necessarily on Earth, but like just in general, it raises the quality of life for everybody, even though the initial endeavor doesn't make any sense."}, {"time": 10099, "text": "The very fact of pushing the limits of what's possible then has side effects of benefiting everybody."}, {"time": 10108, "text": "And it's difficult to predict ahead of time what those benefits will be."}, {"time": 10113, "text": "Say with colonizing Mars, it's unclear what the benefits will be for Earth or in general with struggling."}, {"time": 10119, "text": "What did we get from the moon?"}, {"time": 10121, "text": "What did we get from Apollo, right?"}, {"time": 10123, "text": "Technically, and there were a lot of socialists at the time making this argument."}, {"time": 10126, "text": "They're like, all this money going, you know what?"}, {"time": 10129, "text": "We went to the fucking moon in 1969."}, {"time": 10132, "text": "That was amazing."}, {"time": 10133, "text": "The greatest feat in human history, period."}, {"time": 10137, "text": "What did we learn from it?"}, {"time": 10139, "text": "We learned about interstellar or interplanetary travel."}, {"time": 10144, "text": "We learned that we could do something off of a device less powerful than the computer in my pocket."}, {"time": 10150, "text": "Like the amount of potential locked within my pocket and your pocket, I mean, this is, if you were to define my policies in one way, it's greatness, like national, a quest for national greatness."}, {"time": 10163, "text": "There is no greatness without fulfilling the ultimate calling of the human spirit, which is more, it's not enough."}, {"time": 10171, "text": "And why should it be?"}, {"time": 10172, "text": "It wasn't enough."}, {"time": 10174, "text": "Our ancestors could have been content to sit, well, actually many of them were, were content to sit and say, these berries will be here for a long time."}, {"time": 10183, "text": "And they got eaten and they died."}, {"time": 10184, "text": "And it's the ones who got out and went to the next place and the next place and went across the Siberian land bridge and went across more."}, {"time": 10193, "text": "And it just did extraordinary things."}, {"time": 10195, "text": "The craziest ones, we are their offspring and we fail them if we don't go into space."}, {"time": 10201, "text": "That's how I would put it."}, {"time": 10203, "text": "You should run for president."}, {"time": 10205, "text": "I'm just pro space, man."}, {"time": 10207, "text": "I love space."}, {"time": 10208, "text": "No, you're pro doing difficult things and pushing, exploring the world in all of its forms."}, {"time": 10214, "text": "I hope that kind of spirit permeates politics too."}, {"time": 10218, "text": "That same kind of a... Can, can."}, {"time": 10221, "text": "I, well, it can, and I hope so."}, {"time": 10224, "text": "I don't know if you want to stay on it, but I think that was book number one or two."}, {"time": 10229, "text": "All right, all right."}, {"time": 10231, "text": "Well, this one is second, this actually is a corollary to that, which is sapiens."}, {"time": 10234, "text": "And I know that's a very normal, normie answer."}, {"time": 10237, "text": "One of the best selling book."}, {"time": 10238, "text": "I think there's a reason for that."}, {"time": 10240, "text": "Yuval Noah Harari."}, {"time": 10242, "text": "Okay, look, yes, he didn't do any new research."}, {"time": 10245, "text": "All he did was aggregate."}, {"time": 10246, "text": "I'm sure he's very controversial in the scientific community, but guess what?"}, {"time": 10249, "text": "He wrote a great book."}, {"time": 10250, "text": "It's a very easy to read general explanation of the rise of human history."}, {"time": 10258, "text": "And it helps challenge a lot of preconceptions."}, {"time": 10260, "text": "Are we special?"}, {"time": 10261, "text": "Are we an accident?"}, {"time": 10262, "text": "Are we more like a parasite?"}, {"time": 10264, "text": "Are we not?"}, {"time": 10265, "text": "What, is there a destiny to all of us?"}, {"time": 10268, "text": "You know, if anything, it's like what I just described, which is more."}, {"time": 10272, "text": "Move, move out."}, {"time": 10274, "text": "The evolution of money."}, {"time": 10275, "text": "Like, I know he gets a lot of hate, but I think that he writes it so clearly and well that for your average person to be able to read that, you will come away with a more clear understanding of the human race than before."}, {"time": 10288, "text": "And I think that that's why it's worth it."}, {"time": 10290, "text": "I agree with you 100%."}, {"time": 10292, "text": "I'm ashamed to, I usually don't bring up sapiens because it's like."}, {"time": 10296, "text": "Yeah, it's like, everybody's uncle has read it, but that's a good thing."}, {"time": 10300, "text": "It is one of the, I think it'll be remembered as one of the great books of this particular era."}, {"time": 10306, "text": "Yeah, because it's so clearly, it's like the selfish gene with Dawkins."}, {"time": 10310, "text": "I mean, it just aggregates so many ideas together and puts language to it that makes it very useful to talk about."}, {"time": 10317, "text": "So it is one of the great books."}, {"time": 10320, "text": "Another one is definitely Born to Run for the same reason by Christopher McDougall, which is that."}, {"time": 10326, "text": "I'm just gonna listen to this whole podcast next week."}, {"time": 10329, "text": "Well, you should because it, you are inheriting our most basic skill, which is running."}, {"time": 10335, "text": "And reimagining human history or reimagining like what we were as opposed to what we are is very useful because it helps you understand how to tap into primal aspects of your brain, which just drive you."}, {"time": 10352, "text": "And the reason I love McDougall's writing is because I love anybody who writes like this."}, {"time": 10357, "text": "Malcolm Gladwell, who else?"}, {"time": 10359, "text": "Michael Lewis, people who find characters to tell a bigger story."}, {"time": 10363, "text": "Michael Lewis finds characters to tell us the story of the financial crisis."}, {"time": 10368, "text": "Malcolm Gladwell writes, finds characters to tell us the story of learning new skills and outliers and whatever his latest book is, I forget what it's called."}, {"time": 10376, "text": "But McDougall tells the vignettes and a tiny story of a single person in the history of running and like how it's baked into your DNA."}, {"time": 10387, "text": "And I think there was just something very useful to that for me for being like, I don't need to go to the gym or like, I'm not saying, you should still go to the gym."}, {"time": 10395, "text": "I'll be clear."}, {"time": 10396, "text": "I'm saying like, in order to fulfill like who you are, you can actually tap into something that's the most basic."}, {"time": 10403, "text": "I don't know if, I'm sure if you listened to the David Cho episode with Joe Rogan."}, {"time": 10409, "text": "Oh, where he's the animal."}, {"time": 10411, "text": "With the baboon."}, {"time": 10412, "text": "When he goes hunting."}, {"time": 10412, "text": "And there's something to that, man."}, {"time": 10414, "text": "Where it's just like, they are living the way that we were supposed to."}, {"time": 10419, "text": "We're not supposed, well, I don't wanna put a normative judgment on it."}, {"time": 10422, "text": "They're living the way that we used to."}, {"time": 10425, "text": "There's something very fun."}, {"time": 10426, "text": "It feels more honest somehow to our true nature."}, {"time": 10428, "text": "There's a guy I follow on Instagram."}, {"time": 10430, "text": "I've come from, Paul Saladino, Carnivore MD."}, {"time": 10433, "text": "He just went over there to the Hadza to live with them."}, {"time": 10437, "text": "And I was watching his stuff just like, I was like, man, there's something in you that wants to go."}, {"time": 10443, "text": "I'm like, I wanna do that."}, {"time": 10445, "text": "I wouldn't be very good at it, but like I want to."}, {"time": 10447, "text": "I'm so glad that somebody who thinks deeply about politics is so fascinated with exploration and with the very basic nature, like human nature, nature of our existence."}, {"time": 10461, "text": "There's something in you."}, {"time": 10463, "text": "And still you're stuck in DC."}, {"time": 10465, "text": "For now, for now."}, {"time": 10466, "text": "Speaking of which, you're from Texas."}, {"time": 10472, "text": "What do you make of the future of Texas politically, culturally, economically?"}, {"time": 10479, "text": "I am in part moving, well, I'm moving to Austin."}, {"time": 10483, "text": "Congrats."}, {"time": 10484, "text": "But I'm also doing the Eric Weinstein advice, which is like, dude, you're not married."}, {"time": 10489, "text": "You don't have kids."}, {"time": 10491, "text": "There's no such thing as moving."}, {"time": 10492, "text": "What are you moving?"}, {"time": 10494, "text": "You're like your three suits and some shirts and underwear."}, {"time": 10499, "text": "What exactly is the move entail?"}, {"time": 10502, "text": "So I have nothing."}, {"time": 10503, "text": "So I'm basically, it's very just remain mobile, but there's a promise, there's a hope to Austin."}, {"time": 10512, "text": "Outside of just like friendships, I have no, it's a very different culture that Joe Rogan is creating."}, {"time": 10520, "text": "I'm mostly interested in what the next Silicon Valley will be, what the next hub of technological innovation."}, {"time": 10528, "text": "And there's a promise, maybe a dream for Austin being that next place."}, {"time": 10534, "text": "It's very possible."}, {"time": 10535, "text": "Doesn't have the baggage of some of the political things, maybe some of the sort of things that hold back the beauty of, that makes capitalism, that makes innovation so powerful, which is like meritocracy, which is excellence."}, {"time": 10555, "text": "Diversity is exceptionally important, but it should not be the only priority."}, {"time": 10561, "text": "It has to be something that coexists with a like insatiable drive towards excellence."}, {"time": 10570, "text": "And it seems like Texas is a nice place, like having a Austin, which is like a kind of this weird, I hope it stays weird, man."}, {"time": 10580, "text": "I love weird people."}, {"time": 10581, "text": "I don't know about that, but we can get into it."}, {"time": 10584, "text": "But there's this hope is it remains this weird place of brilliant innovation amidst a state that's like more conservative."}, {"time": 10596, "text": "So like there's a nice balance of everything."}, {"time": 10598, "text": "What are your thoughts about the future of Texas?"}, {"time": 10600, "text": "I think it's so fascinating to me because I never thought I would want to move back, but now I'm beginning to be convinced."}, {"time": 10610, "text": "So I'm going to stick to this clip."}, {"time": 10613, "text": "I am, I'm being honest and many Texas will hate me for this."}, {"time": 10616, "text": "But Texas was not a place that was kind to me, quote unquote."}, {"time": 10620, "text": "And this is because of my own parent."}, {"time": 10624, "text": "Look, I was raised in College Station, Texas, which is a town of 50,000."}, {"time": 10628, "text": "It's a university town."}, {"time": 10630, "text": "It exists only for the university."}, {"time": 10633, "text": "So it was a very, I did not get the full Texas experience purely speaking from a College Station experience."}, {"time": 10639, "text": "But growing up first generation, or I forget what it is, I'm the first American."}, {"time": 10646, "text": "I was born and raised in College Station."}, {"time": 10647, "text": "My parents are from India."}, {"time": 10650, "text": "Being raised in a town where the dominant culture was predominantly like white evangelical Christian was hard."}, {"time": 10658, "text": "Like it was just difficult."}, {"time": 10660, "text": "And I think of it, in the beginning, I would say like ages, like zero to like eight, it was like cultural ignorance, as in like they just don't know how to interact with you."}, {"time": 10673, "text": "And there was a level of, always there was like the evangelical kind of antipathy towards like you being not Christian."}, {"time": 10681, "text": "You know, my parents are Hindu."}, {"time": 10682, "text": "Like that's how I was raised."}, {"time": 10683, "text": "And so like, there was that."}, {"time": 10685, "text": "But 9 11 was very difficult."}, {"time": 10688, "text": "Like 9 11 happened when I was in third or fourth grade."}, {"time": 10693, "text": "And that changed everything, man."}, {"time": 10695, "text": "Like, I mean, our temple had to like print out T shirts."}, {"time": 10698, "text": "And I'm not saying this is a sob story, to be clear."}, {"time": 10700, "text": "I've still actually largely for my adult life identified on the political right."}, {"time": 10704, "text": "So don't take this as some like, you know, race manifesto."}, {"time": 10707, "text": "I'm just telling it like, this is what happened, which is that like we had, it was just hard to be proud, frankly, and to have some of the fallout from 9 11 and during Iraq."}, {"time": 10720, "text": "And the reason I am political is because I realize in myself, I have a strong rebellious nature against systems and structures of power."}, {"time": 10732, "text": "And the first people I ever rebelled against were all the people telling me to shut up and not question the Iraq war."}, {"time": 10740, "text": "So the reason I am in politics is because I hated George W. Bush with a passion and I hated the war."}, {"time": 10748, "text": "And I was so, again, my entire background is largely in national security for this reason, which is I was obsessed with the idea of like, how do we get people who are not gonna get us into these quagmire situations in positions of power?"}, {"time": 10761, "text": "That's how I became fascinated by power in the first place was all a question of how do this happen?"}, {"time": 10767, "text": "Like, how did this catastrophe happen?"}, {"time": 10770, "text": "I realized it's not as bad as like, you know, previous conflicts, but this one was mine."}, {"time": 10774, "text": "And to see how it changed our domestic politics forever."}, {"time": 10778, "text": "And so that was my rebellion."}, {"time": 10780, "text": "But it's funny, because I identified on the left when I was growing up, up until I was 18, I had also a funny two year stint."}, {"time": 10788, "text": "This is where everything kind of changed for me when I was 16, actually."}, {"time": 10791, "text": "I moved to Qatar, to Doha, Qatar, because my dad was a dean or associate dean of Texas A&M University at Doha."}, {"time": 10800, "text": "So my last two years of high school were at this."}, {"time": 10802, "text": "I went from this small town in Texas, and I love my parents because they could recognize that I had within me that I was not a small town kid."}, {"time": 10810, "text": "So they took me out of this country every chance they got."}, {"time": 10813, "text": "I traveled everywhere and constantly let me go."}, {"time": 10816, "text": "And so I went from school in College Station to like this ritzy private school, American school."}, {"time": 10824, "text": "Best thing that ever happened to me, because first of all, it got me out of College Station."}, {"time": 10829, "text": "Second, at that time, I had this annoying streak of, I wouldn't call it being anti America, but you don't appreciate America."}, {"time": 10838, "text": "Let me tell everybody out there listening, leave for a while, you will miss it so much."}, {"time": 10844, "text": "You do not know what it is like to not have freedom of speech until you don't have it."}, {"time": 10850, "text": "And I was going to high school with these guys in the Qatari royal family."}, {"time": 10857, "text": "And all I wanted to do was speak out of how they were pieces of shit for the way that they treated Indian citizens in that country who are basically used as slave labor."}, {"time": 10866, "text": "And I could not say one word because I knew I would be deported and I knew my dad would lose his job and my mom would lose her job and we would be forced out of the country."}, {"time": 10875, "text": "You don't know what it's like to live like that."}, {"time": 10877, "text": "Or to be in a society where like, you have like a high school girlfriend or something and you can't even touch in public or you're lectured for public decency."}, {"time": 10887, "text": "Like, listen, I've lived under a Gulf monarchy now."}, {"time": 10891, "text": "And that turned me into the most pro America guy ever."}, {"time": 10896, "text": "Like I came back so like Merica, like I still am because of that experience."}, {"time": 10903, "text": "Living abroad, like that will do it to you."}, {"time": 10906, "text": "Live in a non democracy."}, {"time": 10908, "text": "You have, even in Europe, I would say, you guys aren't living as free as we are here."}, {"time": 10913, "text": "It's awesome and I love it."}, {"time": 10915, "text": "You're ultimately another human being than the one who left Texas."}, {"time": 10919, "text": "So, I mean, have you actually considered moving to Texas and broadly just outside of your own story, what do you think is the future of Texas?"}, {"time": 10927, "text": "What is the future of Austin?"}, {"time": 10928, "text": "There's so much transformation seemingly happening now related to Silicon Valley, to California."}, {"time": 10935, "text": "That's what's been so hard to me, which is that since I left, it's changed dramatically, which is that it used to be like this conservative state where the main money to be made was oil."}, {"time": 10946, "text": "Petro, it was a Petro state, Houston, all of that."}, {"time": 10950, "text": "Austin was always weird, but it was more of a music town and a university town."}, {"time": 10954, "text": "It was not a tech town."}, {"time": 10955, "text": "But in the 10 years or so since I left, I have begun to realize, I'm like, well, the Texas I grew up in is over."}, {"time": 10963, "text": "It is not a deep red state in any sense of the term."}, {"time": 10968, "text": "The number one Uhaul route in the country pre pandemic already was San Francisco to Austin, okay?"}, {"time": 10974, "text": "So like you have this massive influx of people from California and New York."}, {"time": 10980, "text": "And the state, the composition of it is changed dramatically."}, {"time": 10984, "text": "The intra composition and the ultra, yeah."}, {"time": 10988, "text": "So the intra composition, it's become way more urban."}, {"time": 10990, "text": "It's from when I grew up, Texas was a much more rural state."}, {"time": 10993, "text": "Its politics were much more static."}, {"time": 10995, "text": "It looked much more like Rick Perry, like he was a very accurate representation of who we were."}, {"time": 11002, "text": "Now, I don't think that that's the case."}, {"time": 11005, "text": "Texas is now a dynamic economy, not just 100% reliant on oil because of its kind of like, I would call it like regulatory arbitrage relative to California and New York offers a large incentive to people who are more, I wouldn't say culturally liberal, but they're not necessarily like culturally conservative, like the people who I grew up with."}, {"time": 11027, "text": "That's changed the whole state's politics."}, {"time": 11029, "text": "Beto came two points away from beating Ted Cruz."}, {"time": 11031, "text": "I'm not saying the state's gonna go blue."}, {"time": 11033, "text": "I think the Republican party will just change and we'll have to readjust."}]}, {"title": "Silvio Micali: Cryptocurrency, Blockchain, Algorand, Bitcoin & Ethereum | Lex Fridman Podcast #168", "id": "zNdhgOk4-fE", "quotes": [{"time": 287, "text": "So if instead of this common knowledge is a very powerful tool for humanity."}, {"time": 296, "text": "So we return to it from a bunch of different perspectives, including like a technical perspective."}, {"time": 300, "text": "But you often talk about blockchain and some of these concepts of decentralization, scalability, security, all those kinds of things."}, {"time": 309, "text": "But one of the most maybe impactful, exciting things that leverage the blockchain, this kind of ledger idea of common knowledge is cryptocurrency."}, {"time": 325, "text": "So in the financial space."}, {"time": 325, "text": "So is there, can you say in the same kind of basic way, what is cryptocurrency in the context of this common knowledge and in the context of the blockchain?"}, {"time": 337, "text": "Cryptocurrency is a currency that is on such a ledger."}, {"time": 337, "text": "So imagine that on the ledger, initially, you know that somehow, say you and I are the only owner, each one, let's give it ourselves a billion each of whatever this unit."}, {"time": 352, "text": "Then I start writing on the ledger, I give 100 of these units to my sister, I give this much to my aunt."}, {"time": 361, "text": "And then now, because it's written on the ledger and everybody can see, my sister can give 57 of these units that she received from me to somebody else."}, {"time": 373, "text": "And that is money."}, {"time": 373, "text": "And that is money because you can see that somebody who tenders your payment has really the money there."}, {"time": 379, "text": "You don't have any more of a doubt when you want to sell an item."}, {"time": 386, "text": "If I write you a check, is the check covered?"}, {"time": 393, "text": "Or do I have the money at the moment of a transaction?"}, {"time": 393, "text": "You really see because the ledger is always updated."}, {"time": 398, "text": "What you see is what I see, what the merchant sees."}, {"time": 398, "text": "You know that the money, the money is the most powerful money system there is because it is totally transparent."}, {"time": 404, "text": "And so you know that you have been paid, and you know that the money is there, you have not to second guess anything else."}, {"time": 418, "text": "So the common knowledge applied there is you're basically mimicking the same kind of thing you would get in the physical space, which is if you give 100 bucks or 100 of that thing, whatever of that cryptocurrency to your sister, the actual transfer is as real as you giving like a basket of apples to your sister."}, {"time": 438, "text": "So in the case in the physical space, the common knowledge is in the physics of the atoms."}, {"time": 448, "text": "And then it's digital space, the common knowledge is in this ledger."}, {"time": 455, "text": "And so that transfer holds the same kind of power, but now it's operating in the digital space."}, {"time": 463, "text": "Again, I apologize for a set of ridiculous questions, but you mentioned cryptocurrencies and money."}, {"time": 472, "text": "What is money?"}, {"time": 472, "text": "Why do we have money?"}, {"time": 472, "text": "Do you think about this kind of from this high philosophical level at times of this tool, this idea that we humans have all kind of came up with and seem to be using effectively to do stuff?"}, {"time": 495, "text": "Money is a social construct, okay, in my opinion."}, {"time": 495, "text": "And this has been somehow people always felt that somehow money is a way to allow us to transact, even though we want different things."}, {"time": 502, "text": "So I have two sheep, and then you have one cow, and I want the cow, but you are looking for blankets instead, you know, so to have money is really simplifies this."}, {"time": 519, "text": "But at the end of it, that's why a bit was invented."}, {"time": 524, "text": "And you started with gold, you started with the coinage, then you started with the check."}, {"time": 529, "text": "But at the end of the day, money is essentially a social construct because you know that what you receive, you can actually spend with somebody else."}, {"time": 541, "text": "And so there is a kind of a social pact and social belief that you have."}, {"time": 541, "text": "At the end of the day, even barter requires these beliefs that other people are going to accept the quote unquote currency you offer them."}, {"time": 557, "text": "Because if I'm a mason, and you ask me to build a wall in your field, and I did, and you, in exchange, you give me a thousand sheep, what am I going to do?"}, {"time": 572, "text": "Eat them all?"}, {"time": 572, "text": "No, I have to feed them."}, {"time": 572, "text": "And if I don't feed them, they die, and my value is zero."}, {"time": 577, "text": "So in receiving this livestock, I must believe that somebody else will accept them in return for something else."}, {"time": 585, "text": "So money is a social belief, social shared belief system that makes people transact."}, {"time": 593, "text": "I didn't even think about that, that you're actually, you have a deep like network of beliefs about how society operates."}, {"time": 606, "text": "So the value is assigned even to sheep, based on that everyone will continue operating how they were previously operating."}, {"time": 612, "text": "Somebody will feed the sheep."}, {"time": 619, "text": "So that directly transfers to the space of money and then to the space of digital money, cryptocurrency."}, {"time": 626, "text": "Does it bother you sort of intellectually when this money that is a social construct is not directly tied to physical goods like gold, for example?"}, {"time": 640, "text": "Not at all, because after all, gold has some industrial value."}, {"time": 640, "text": "Nobody delights it."}, {"time": 640, "text": "It's a metal."}, {"time": 649, "text": "It doesn't oxidate."}, {"time": 649, "text": "It has some good things about it."}, {"time": 649, "text": "But does this industrial value really represent the value to which it now is traded?"}, {"time": 655, "text": "So gold is another way to express our belief."}, {"time": 661, "text": "I give you an ounce of gold, you treat it like, oh, somebody else will want this for doing something else."}, {"time": 667, "text": "So it is really this notion of this."}, {"time": 667, "text": "Money is a mental construct, is really, and is shared, is a social construct, I really believe."}, {"time": 674, "text": "And so some people feel that it's physical, so therefore gold exists."}, {"time": 681, "text": "Then, as you know now, countries, most sophisticated country right now, they print their own money and you believe that they are not going to exaggerate it with inflation."}, {"time": 695, "text": "Not everybody believes it, but at least they are not going to exaggerate it blatantly."}, {"time": 702, "text": "And therefore you receive it because you know that somebody else will accept it, will have faith in the currency and so on and so forth."}, {"time": 709, "text": "But whether it's gold, whether it's livestock, whatever it is, money is really a shared belief."}, {"time": 719, "text": "So there is something, you know, and I've been reading more and more about different cryptocurrencies."}, {"time": 727, "text": "There is a kind of belief that the scarcity of a particular resource like Bitcoin has a limited amount and it's tied to physical, you know, to proof of work."}, {"time": 734, "text": "So it's tied to physical reality in terms of how much you can mine effectively and so on."}, {"time": 743, "text": "That that's an important feature of money."}, {"time": 748, "text": "Do you think that's an important feature to be a part of whatever the money is?"}, {"time": 754, "text": "That is certainly a very useful part."}, {"time": 754, "text": "So at some point in time, you know, assume that money is something that all of a sudden we say, daisies are money, are the currency."}, {"time": 766, "text": "Then, you know, I offer you 10 daisies in payment of whatever goods and services you want to provide."}, {"time": 772, "text": "But at the end of the day, if you know that you can cultivate it and generate them at will, then perhaps, you know, you should not accept my payment."}, {"time": 779, "text": "Here is a bouquet of daisies."}, {"time": 788, "text": "So you need some kind of a scarcity."}, {"time": 788, "text": "The inability to create it suddenly out of nothing is unimportant."}, {"time": 794, "text": "And it's not an intrinsic necessity, but it's much easier to accept once you know that there is a fixed number of units of whatever currency there is and therefore you can mentally understand I'm getting, you know, this much of this piece of a pie and therefore I consider myself paid."}, {"time": 817, "text": "I understand what I'm receiving."}, {"time": 817, "text": "You described the goals of a blockchain."}, {"time": 823, "text": "You have a nice presentation on this as scalability, security, and decentralization."}, {"time": 829, "text": "And you challenged the blockchain trilemma that claims you can only have two of the three."}, {"time": 835, "text": "So let's talk about each."}, {"time": 835, "text": "What is scalability in the context of blockchain and cryptocurrency?"}, {"time": 842, "text": "What does scalability mean?"}, {"time": 842, "text": "So remember, we said that the blockchain is a ledger and each page receives a, gets some transaction and everybody can write in these pages of the ledger."}, {"time": 849, "text": "Nobody can be stopped from writing and everybody can read them."}, {"time": 856, "text": "Scalability means how fast can you write?"}, {"time": 861, "text": "Just imagine that you can write an entry in this special shared ledger once every hour."}, {"time": 868, "text": "Well, you know, what are you going to do if you have no one transaction of an hour, the world doesn't go around."}, {"time": 873, "text": "So you need to have scalability means here that you can then somehow write a lot of transaction and then you can read them and everybody can validate them."}, {"time": 887, "text": "And that is the speed and the number of transactions per second and the fact that they are shared."}, {"time": 894, "text": "So you want to have this speed not only in writing, but in sharing and in inspection for validity."}, {"time": 901, "text": "This is scalability."}, {"time": 901, "text": "The world is big."}, {"time": 901, "text": "The world wants to interact, the people want to interact with each other and you better be prepared to have a ledger in which you can write lots and lots and lots of transactions in this special way very, very, very quickly."}, {"time": 917, "text": "So maybe from a more mathematical perspective or can we say something about how much scalability is needed for a world that is big?"}, {"time": 927, "text": "Well, it really depends how many transactions you want, but remember that I think right now yet to go into at least 1000s of transactions per second, even if you look at credit cards, we are going to go from an average of 1600 to peaks of 20,000 or 40,000, something like this."}, {"time": 954, "text": "But remember, it's not only a question of a transaction per se, but the value is that the transaction is actually being shared and visible to everybody and the certainty that that is the case."}, {"time": 968, "text": "I can print on my own printer way more transactions, but nobody has the time to see or to inspect."}, {"time": 975, "text": "That doesn't count."}, {"time": 975, "text": "So you want scalability at this common knowledge level."}, {"time": 982, "text": "I also meant from a perspective of like a complexity analysis."}, {"time": 988, "text": "So when you get more and more people involved, doesn't need to scale in some kind of way that do you like to see certain kind of properties in order to say something is scalable?"}, {"time": 1002, "text": "I took a little bit implicitly that the people transacting are actually very different."}, {"time": 1008, "text": "So if there is a two people who can do thousands of transactions per second with each other, this is not so interesting."}, {"time": 1014, "text": "What do we really need is to say there are billions of people at any point in time, you know, thousands and thousands of them want to transact with each other and you want to support to that."}, {"time": 1023, "text": "So Algorand, it solves, so that's the company, the team of cryptographers and mathematicians, engineers, so on, that challenged the blockchain trilemma."}, {"time": 1037, "text": "So let's break it down in terms of achieving scalability."}, {"time": 1037, "text": "How do we achieve scalability in the space of blockchain, in the space of cryptocurrency?"}, {"time": 1045, "text": "So scalability, security, remember, and decentralization, right?"}, {"time": 1051, "text": "So that's what they want."}, {"time": 1051, "text": "What's the best way to approach?"}, {"time": 1056, "text": "Can we break it down?"}, {"time": 1056, "text": "Let's start with scalability and think about how do we achieve it?"}, {"time": 1056, "text": "Well, to achieve it one at a time is perhaps easy, even security."}, {"time": 1061, "text": "If nobody transacts, nobody loses money."}, {"time": 1068, "text": "So that is secure, but it's not scalable."}, {"time": 1068, "text": "So let me tell you, I'm a cryptographer, so I try to fight the bad guys."}, {"time": 1076, "text": "And what you want is that the vesselager that we discussed before cannot be tampered with."}, {"time": 1084, "text": "So you must think of it as a special link that nobody can erase."}, {"time": 1084, "text": "Then it has to be, everybody should be able to read and not to alter the pages or the content of the pages."}, {"time": 1102, "text": "That is actually easy cryptographically."}, {"time": 1102, "text": "Easy cryptographically means you can use tools invented 50 years ago, which in cryptographic time is prehistory, okay?"}, {"time": 1115, "text": "We cavemen working around and solve the problem in cryptography land."}, {"time": 1115, "text": "But there is really a fundamental problem, which is really almost a social, seems a political problem, is to say, who the hell chooses or publishes the next page of the ledger?"}, {"time": 1128, "text": "I mean, that is really the challenge."}, {"time": 1138, "text": "This ledger, you can always add a page because more and more transaction had to be written on there."}, {"time": 1143, "text": "And somebody has to assemble this transaction, put them on a page and add the next page."}, {"time": 1148, "text": "Who is the somebody who chooses the page and adds it on?"}, {"time": 1148, "text": "Who can be trusted to do it?"}, {"time": 1154, "text": "Assume it is me for what I'm being, not that I want to volunteer for the job, but then I would have more power than any absolute monarch in history, because I would have a tremendous power to say, these are the transactions that the entire world should see."}, {"time": 1165, "text": "And whatever I don't write, this transaction will never see the light of day."}, {"time": 1172, "text": "I mean, no one had any such a power in history."}, {"time": 1178, "text": "So it's very important to do that."}, {"time": 1178, "text": "And that is the quintessential problem in a blockchain."}, {"time": 1187, "text": "And people have thought about it to say, it's not me, it's not you."}, {"time": 1187, "text": "But for instance, in proof of work, what people say is, okay, it's not me, it's not you, you know what it is?"}, {"time": 1198, "text": "We make a very difficult, we invented a cryptographic puzzle, very hard to solve."}, {"time": 1204, "text": "The first one to solve it has the right to add one page to the ledger on behalf of everybody else."}, {"time": 1212, "text": "That now seems okay, because sometimes I solve a puzzle before you do, sometimes you solve before I do, or before somebody else solves it, it's okay."}, {"time": 1222, "text": "And presumably, the effort you put in is somehow correlated with how much trust you should be given to add to the ledger."}, {"time": 1233, "text": "Yeah, so somehow you want to make sure that you need to work because you want to prevent, you want to make sure that you get one solution every 10 minutes, say, like in a particular example of Bitcoin, so that it is very rare that two pages are added at the same time."}, {"time": 1251, "text": "Because if I solve a puzzle at the same time you do, it could happen that if it happens once or twice, we can survive it."}, {"time": 1258, "text": "But if it happens every other page is a double page, then which of the two is the real page, it becomes a problem."}, {"time": 1266, "text": "So that's why in Bitcoin, it is important to have a substantial amount of work so that no matter how many people try on Earth to solve a puzzle, you have one solution out of how many people are trying every 10 minutes."}, {"time": 1279, "text": "So that you have, you distance these pages, and you have the time to propagate through the network a solution and the page attached to it."}, {"time": 1291, "text": "And therefore, there is one page at a time that is added."}, {"time": 1291, "text": "And you say, well, why don't we do it?"}, {"time": 1298, "text": "We have a solution."}, {"time": 1298, "text": "Well, first of all, a page every 10 minutes is not fast enough."}, {"time": 1298, "text": "It's a question of scalability."}, {"time": 1306, "text": "And second of all, to ensure that no matter how many people try, you get one page every 10 minutes, one solution to the riddle every 10 minutes."}, {"time": 1313, "text": "This means that the riddle becomes very, very hard."}, {"time": 1320, "text": "And to have a chance to solve it within 10 minutes, you must have such an expensive apparatus in terms of specialized computers, not one, not two, but thousands and thousands of them."}, {"time": 1335, "text": "And they produce tons of heat, okay?"}, {"time": 1335, "text": "They dissipate heat like maniac."}, {"time": 1335, "text": "And then you have to refrigerate them too."}, {"time": 1340, "text": "And so then now you have air conditioning galore to add to the thing."}, {"time": 1346, "text": "It becomes so expensive that fewer and fewer and fewer people can actually compete in order to add to the page."}, {"time": 1353, "text": "And the problem becomes so crucial that in Bitcoin, depending on which day of the week you look at it, you are going to have two or three mining pools that are really the ones that are capable of controlling the chain."}, {"time": 1371, "text": "So you're saying that's almost like at least a centralization."}, {"time": 1378, "text": "It started being decentralized, but the expenses became higher and higher and higher."}, {"time": 1387, "text": "When the cost becomes higher and higher, fewer and fewer people can afford them."}, {"time": 1391, "text": "And then it becomes de facto centralized, right?"}, {"time": 1391, "text": "And a different type of approach is instead, for instance, a delegated proof of stake, which is also very easy to explain, essentially boils down to say, well, look at these 21 people, say, okay?"}, {"time": 1415, "text": "Don't they look honest?"}, {"time": 1415, "text": "Yes, they do."}, {"time": 1415, "text": "In fact, I believe that they're going to remain honest for the foreseeable future."}, {"time": 1420, "text": "So why don't we do ourselves a favor?"}, {"time": 1420, "text": "Let's entrust them to add the page on behalf of all of us to the ledger."}, {"time": 1426, "text": "But now we are going to say, is this centralized or decentralized?"}, {"time": 1434, "text": "Well, 21 is better than one, but to say is very little."}, {"time": 1439, "text": "So if you look at when people rebelled to centralize power, I don't know, the French revolutions, okay?"}, {"time": 1444, "text": "There was a monarch and the nobles."}, {"time": 1444, "text": "Were there 21 nobles?"}, {"time": 1444, "text": "No, there were thousands of them, but there were millions and millions of disempowered citizens."}, {"time": 1451, "text": "So one is centralized, 21 is also centralized, right?"}, {"time": 1458, "text": "So that's delegated proof of stake."}, {"time": 1458, "text": "Delegated."}, {"time": 1458, "text": "It's kind of like representative democracy, I guess."}, {"time": 1463, "text": "Yes, which is good."}, {"time": 1463, "text": "It's working great, right?"}, {"time": 1469, "text": "It's working great."}, {"time": 1469, "text": "Well, it's better than the single monarch, right?"}, {"time": 1469, "text": "There's problems."}, {"time": 1479, "text": "There are problems."}, {"time": 1479, "text": "And so we were looking for a different, when thinking about Algorand, for a different approach."}, {"time": 1489, "text": "And so we have an approach that is really, really decentralized because essentially it works as follows."}, {"time": 1496, "text": "You have a bunch of tokens, right?"}, {"time": 1496, "text": "These are the tokens that have equal power."}, {"time": 1504, "text": "And you have say 10 billions of tokens distributed to the entire world."}, {"time": 1512, "text": "And the owners, each token has a chance to add the ledger, equal probability to everybody else."}, {"time": 1521, "text": "In fact, actually, if you want, here is how it works."}, {"time": 1521, "text": "So think about by some magic cryptographic process, which is not magic, it's mathematics, but think of it as magic."}, {"time": 1529, "text": "Assume that you select a thousand tokens and so sometimes a random, okay?"}, {"time": 1536, "text": "And you have a guarantee that the random selected."}, {"time": 1543, "text": "And then the owners of these 1000 tokens somehow agree on the next page, they all sign it, and that is the next page."}, {"time": 1551, "text": "So it is clear that nobody has the power but in a while, one of your tokens is selected and you are in charge of this committee to select the next page."}, {"time": 1569, "text": "But this goes around very quickly."}, {"time": 1569, "text": "So, and if you look at this, the equation really is that it's not really centralized."}, {"time": 1576, "text": "And because for agreeing on the same page, it is important that the 1000 tokens that you randomly selected are in honest ends, the majority of them."}, {"time": 1592, "text": "So which, if the majority of the tokens are in honest ends, that is essentially true because if the majority of the tokens are in honest ends, if you select, say 90% of the people are, 90% of the tokens are in honest ends."}, {"time": 1606, "text": "So can you randomly select a thousand, in this thousand you find the 501 tokens in bad ends."}, {"time": 1611, "text": "Very, very improbable."}, {"time": 1618, "text": "So basically, when a large fraction of people are honest, then you can use randomness as a powerful tool to get decentralization."}, {"time": 1625, "text": "So what does honesty mean?"}, {"time": 1625, "text": "And now we're into the social side of things, which is how do we know that like the fraction, a large fraction of people or participating parties are honest?"}, {"time": 1643, "text": "That is an excellent question."}, {"time": 1643, "text": "So by the way, first of all, we should realize that the same thing is for every other system."}, {"time": 1648, "text": "When you look at proof of work, you rely that the majority of the mining power is in honest ends."}, {"time": 1653, "text": "When you look at delegated proof of stake, you rely that the majority of these 21 people are honest."}, {"time": 1661, "text": "What is the difference?"}, {"time": 1667, "text": "The difference is that in these other systems, you should say the whole economy is secure if the majority of this small piece of economy are honest."}, {"time": 1674, "text": "And that is a big question."}, {"time": 1684, "text": "But instead, in Algorand, in our approach, we say the whole economy is secure if the majority of the economy is honest."}, {"time": 1692, "text": "In other words, who can subvert Algorand is not a majority of a small group, but is a majority of the token holders had to conspire with each other in order to sink the very economy for which they own the majority of."}, {"time": 1704, "text": "That I think it is a bit harder to... Like a self destructive majority, essentially."}, {"time": 1709, "text": "And you're also making me realize that basically every system that we have in the world today assumes that the majority of participants is honest."}, {"time": 1723, "text": "The only difference is the majority of whom."}, {"time": 1723, "text": "And in some cases, the majority of a club and in our case is the majority of the whole system."}, {"time": 1733, "text": "The whole system."}, {"time": 1733, "text": "So through that kind of random sampling, you can achieve decentralization."}, {"time": 1742, "text": "You can achieve..."}, {"time": 1742, "text": "So the scalability, I understand."}, {"time": 1750, "text": "And then the security that you're referring to, basically the security comes from the fact that the sample selected would likely include honest people."}, {"time": 1756, "text": "So it's very difficult to..."}, {"time": 1756, "text": "So by the way, the security, as you mentioned, you're referring to is basically security against dishonesty, right?"}, {"time": 1771, "text": "Or manipulation or whatever."}, {"time": 1771, "text": "So essentially when what you're going to do is to the following and say, well, Silvio, I understood what you're saying, but somebody has to randomly randomly selected these tokens, then I believe you."}, {"time": 1782, "text": "So then who does this random selection?"}, {"time": 1786, "text": "And in Algorand, we do something a little bit unorthodox."}, {"time": 1792, "text": "Essentially is the token choose themselves at random."}, {"time": 1792, "text": "And you say, if you think about it, that seems to be a terrible idea."}, {"time": 1800, "text": "Because if you want to say, choose yourself at random, and whoever chooses himself is a thousand people committee, you choose the page for the rest of us."}, {"time": 1811, "text": "And because if I'm a bad person, I'm going to select myself over and over again, because I want to be part of the committee every single time."}, {"time": 1816, "text": "But not so fast."}, {"time": 1816, "text": "So what do we do in Algorand?"}, {"time": 1822, "text": "What does it mean that I select myself?"}, {"time": 1822, "text": "That each one of us, in the privacy of our own computer, actually a laptop, what you do is that you execute your own individual lottery."}, {"time": 1834, "text": "And think about that you pull a lever of a slot machine, you can only pull the lever once, not until you win, not enough times until you win."}, {"time": 1842, "text": "And when you pull the lever, case one, either you win, in such a case, you have a winning ticket."}, {"time": 1848, "text": "Or you lose, you don't get any winning ticket."}, {"time": 1854, "text": "So if you don't have a winning ticket, you can say anything you want about the next page in the ledger, nobody pays attention."}, {"time": 1860, "text": "But if you ever win a ticket, people say, Oh, wow, this is one of the 1000 winning tickets, we better pay attention to what he or she says."}, {"time": 1873, "text": "And that's how it works."}, {"time": 1873, "text": "And the lottery is a cryptographic lottery, which means that even if I am an entire nation, extremely powerful, with incredible computing powers, I don't have the ability to improve even minimally my probability of one of my token winning the lottery."}, {"time": 1887, "text": "And that's how it happens."}, {"time": 1893, "text": "So everybody pulls the lever, the 1000 random winners say, Oh, here is my winning ticket."}, {"time": 1901, "text": "And here is my opinion up or down about the block."}, {"time": 1901, "text": "These are the ones that count."}, {"time": 1906, "text": "And if you think about it, while this is distributed, because there is, in the case of Algon, there is 10 billion tokens and you selected 1000 of them more distributed than this, you cannot get."}, {"time": 1919, "text": "And then why is this scalable?"}, {"time": 1919, "text": "Because what do you have to do?"}, {"time": 1919, "text": "Okay, you have to do the lottery."}, {"time": 1926, "text": "How long the lottery takes?"}, {"time": 1926, "text": "It takes actually one microsecond."}, {"time": 1926, "text": "Whether you have one token or two tokens or a billion tokens is always one microsecond of computation, which is very fast."}, {"time": 1939, "text": "We don't hit the planet with a microsecond of computation."}, {"time": 1939, "text": "And finally, why is this secure?"}, {"time": 1947, "text": "Because even if I were a very evil and very, very powerful individual, I'm so powerful that I can corrupt anybody I want instantaneously in the world, whom would I want to corrupt?"}, {"time": 1955, "text": "The people in the committee so that I can choose the page of the ledger."}, {"time": 1962, "text": "But I do have a problem."}, {"time": 1962, "text": "I do not know whom I should corrupt."}, {"time": 1969, "text": "Should I corrupt this lady in Shanghai, this other guy in Paris?"}, {"time": 1976, "text": "Because I don't know."}, {"time": 1976, "text": "The winners are random, so I don't know whom I should corrupt."}, {"time": 1981, "text": "But once the winner comes forward and says, here is my winning ticket, and you propagate your winning ticket across the network, together with your opinion about the block, now I know who they are."}, {"time": 1991, "text": "For sure, I can corrupt all 1000 of them given to my incredible powers."}, {"time": 1998, "text": "Whatever they said, they already said, and their winning tickets and their opinions are virally propagated across the network."}, {"time": 2005, "text": "And I do not have the power, no more than the US government or any government has the power, to put back in the bottle a message virally propagated by WikiLeaks."}, {"time": 2017, "text": "So everything you just described is kind of is fascinating, a set of ideas."}, {"time": 2024, "text": "And, you know, online I've been reading quite a bit, and people are really excited about the set of ideas."}, {"time": 2030, "text": "Nevertheless, it is not the dominating technology today."}, {"time": 2030, "text": "So Bitcoin, in terms of cryptocurrency, is the most popular cryptocurrency, and then Ethereum, and so on."}, {"time": 2045, "text": "So it's useful to kind of comment."}, {"time": 2045, "text": "We already talked about proof of work a little bit."}, {"time": 2049, "text": "But what, in your sense, does Bitcoin get right?"}, {"time": 2049, "text": "And where is it lacking?"}, {"time": 2056, "text": "Okay, so the first thing that Bitcoin got right is to understand that there was the need of a cryptocurrency."}, {"time": 2062, "text": "And that, in my opinion, they deserve all the success because they said the time is right for this idea."}, {"time": 2069, "text": "Because very often, it's not enough to be right here to be right at the right time."}, {"time": 2074, "text": "And somebody got it right there."}, {"time": 2074, "text": "So hat off to Bitcoin for that."}, {"time": 2082, "text": "And so what they got right is that it is hard to subvert and change the ledger, to cancel a transaction."}, {"time": 2092, "text": "It's not impossible."}, {"time": 2092, "text": "That is very hard."}, {"time": 2092, "text": "What they did not get right is somehow that it is a great store of value, currency wise."}, {"time": 2100, "text": "But money is not only a question that you store it and you put under the mattress."}, {"time": 2107, "text": "Money wants to be transacted."}, {"time": 2107, "text": "And the transaction bitcoins are very little."}, {"time": 2113, "text": "So if you want to store value, everybody needs a store of value."}, {"time": 2113, "text": "Might as well use Bitcoin."}, {"time": 2119, "text": "I mean, it's the plan."}, {"time": 2119, "text": "But if you don't look at that for a moment, at least it's a great store of value."}, {"time": 2127, "text": "And everybody needs a store of value."}, {"time": 2127, "text": "But most of the time, we want to transact."}, {"time": 2127, "text": "We want to interact."}, {"time": 2132, "text": "We don't put the money under the mattress."}, {"time": 2132, "text": "So we wanted to embed."}, {"time": 2132, "text": "They didn't get it right."}, {"time": 2138, "text": "That is too slow to transact."}, {"time": 2138, "text": "Too few transactions."}, {"time": 2138, "text": "There's a scalability issue."}, {"time": 2145, "text": "Is it possible to build stuff on top of Bitcoin that sort of fixes the scalability?"}, {"time": 2145, "text": "I mean, this is the thing you look at."}, {"time": 2152, "text": "There's a bunch of technologies that kind of hit the right need at the right time and they have flaws, but we kind of build infrastructures on top of them over time to fix it as opposed to getting it right from the beginning."}, {"time": 2167, "text": "Or is it difficult to do?"}, {"time": 2174, "text": "Well, that is difficult to do."}, {"time": 2174, "text": "So you're talking to somebody that when I decided to throw my heart in the arena and I decided, first of all, as I said before, I much admire my predecessors."}, {"time": 2181, "text": "I mean, they got it right, a lot of things."}, {"time": 2187, "text": "And I really admire for that."}, {"time": 2187, "text": "But I had a choice to make."}, {"time": 2196, "text": "Either I patch something that has holes all over the place or I start from scratch."}, {"time": 2196, "text": "I decided to start from scratch because sometimes it's a better way."}, {"time": 2201, "text": "So what about Ethereum, which looks like proof of stake and a lot of different innovative ideas that kind of improve or seek to improve on some of the flaws of Bitcoin."}, {"time": 2212, "text": "Ethereum made another great idea."}, {"time": 2212, "text": "So they figured out that money and payments are important as they are."}, {"time": 2217, "text": "They are only the first level, the first stepping stone."}, {"time": 2225, "text": "The next level are smart contracts."}, {"time": 2225, "text": "And they were at the vision to say the people will need smart contract, which allow me and you to somehow to transact securely without being shopped around by a trusted third party, by a mediator."}, {"time": 2240, "text": "By the way, because mediators are hard to find."}, {"time": 2246, "text": "And in fact, maybe even impossible to find if you live in Thailand and I live in New Zealand, maybe we don't have a common person that we know and trust."}, {"time": 2252, "text": "And even if we find them, guess what?"}, {"time": 2259, "text": "They want to be paid."}, {"time": 2259, "text": "So much so that 6% of the world GDP goes into financial friction, which is essentially third party."}, {"time": 2268, "text": "So the head of right of the world needed that."}, {"time": 2273, "text": "But again, the scalability is not there."}, {"time": 2273, "text": "And the system of smart contracts in Ethereum is slow and expensive."}, {"time": 2284, "text": "And I believe that is not enough to satisfy the appetite and the need that we have for smart contracts."}, {"time": 2292, "text": "Well, what do you make of just as a small sort of aside in human history, perhaps it's a big one is NFT, the non fungible tokens."}, {"time": 2299, "text": "Do you find those interesting technically, or is it more interesting on the social side of things?"}, {"time": 2304, "text": "Well, both."}, {"time": 2304, "text": "I think NFTs are actually great."}, {"time": 2312, "text": "So you are an artist to create a song or it could be a piece of art."}, {"time": 2312, "text": "He has many unique representations of a unique piece where there is an artifact of something dreamed up by you and has unique representations that now you can trade."}, {"time": 2335, "text": "And the important part is that now you have this is not only the NFTs themselves, but the ability to trade them quickly, fast, securely, knowing who owns which rights."}, {"time": 2351, "text": "And that gives a totally new opportunity for content creators to be remunerated for what they do."}, {"time": 2358, "text": "But ultimately, you still have to have that scalability, security and decentralization to make it, you know, to make it work for bigger and bigger applications."}, {"time": 2373, "text": "I still wonder what kind of applications are yet to be like enabled by it because so much."}, {"time": 2378, "text": "The interesting thing about NFTs, you know, if you look outside of art is just like money, you can start playing with different social constructs, is you can start playing with the ideas."}, {"time": 2391, "text": "You can start playing with even like investing."}, {"time": 2401, "text": "Somebody was talking about almost creating an economy out of like creative people or influencers."}, {"time": 2410, "text": "Like if you start a YouTube channel or something like that, you can invest in that person and you can start trading their creations."}, {"time": 2415, "text": "And then almost like create a market out of people's ideas, out of people's creations, out of the people themselves that generate those creations."}, {"time": 2429, "text": "And there's a lot of interesting possibilities of what you can do with that."}, {"time": 2433, "text": "I mean, it seems ridiculous, but you're basically creating a hierarchy of value, maybe artificial in the digital world and are trading that."}, {"time": 2440, "text": "But in so doing are inspiring people to create."}, {"time": 2448, "text": "So maybe as a sort of our economy gets better and better and better where actual work in the physical space becomes less and less in terms of its importance, maybe we'll completely be operating in the digital space where these kinds of economies have more and more power."}, {"time": 2461, "text": "And then you have to have this kind of blockchains to the scalability, security, and decentralization."}, {"time": 2475, "text": "And then decentralization is of course the tricky one because people in power start to get nervous."}, {"time": 2483, "text": "Once in power, you're always nervous that you'll be supplanted by somebody else."}, {"time": 2489, "text": "But this is your job."}, {"time": 2489, "text": "Congratulations, you got the job, the top job, and now everybody wants it."}, {"time": 2494, "text": "Well, what is your sense about our time and the future hope about the decentralization of power?"}, {"time": 2502, "text": "Do you think that's something that we can actually achieve given that power corrupts and absolute power corrupts absolutely, and it's so wonderful to be absolutely powerful?"}, {"time": 2517, "text": "Well, good question."}, {"time": 2517, "text": "So first of all, I believe that by the way, there is a complex question, Lex, and like all the rest of your questions."}, {"time": 2530, "text": "I'm so very sorry."}, {"time": 2533, "text": "I am enjoying it."}, {"time": 2533, "text": "So there are two things."}, {"time": 2533, "text": "First of all, power has been centralized for a variety of reasons."}, {"time": 2539, "text": "When you want to get it, it's easier for somebody, even a single person, to grab power."}, {"time": 2544, "text": "But there is also some kind of a technology, lack thereof, that justified having power."}, {"time": 2553, "text": "Because in a society in which even communication, never mind blockchain, which is common knowledge, but even simple unilateral communication is hard, it is much easier to say, you do as I say."}, {"time": 2566, "text": "So there is a little bit of a technology barrier."}, {"time": 2579, "text": "But I think that now to get to this common knowledge, it is a totally different story."}, {"time": 2584, "text": "Now we have finally the technology for doing this."}, {"time": 2584, "text": "So that is one part."}, {"time": 2584, "text": "But I really believe that by having a distributed system, you have actually a much more stable and durable system."}, {"time": 2599, "text": "Because not only for corruption, but even for things that go astray, and given a long enough time by a strange version of Murphy's law, whatever goes wrong, goes wrong."}, {"time": 2604, "text": "And if the power is diffused, you actually are much more stable."}, {"time": 2613, "text": "If you look at any complex living being, it's distributed."}, {"time": 2623, "text": "I mean, I don't have somebody who says, okay, tell Silvio now it's time to eat."}, {"time": 2630, "text": "You have millions of cells in your body."}, {"time": 2630, "text": "You have billions of bacteria."}, {"time": 2634, "text": "Help me in the guts."}, {"time": 2634, "text": "We are in a soup that somehow keeps us alive."}, {"time": 2639, "text": "So strange enough, however, when we design systems, we design them centralized."}, {"time": 2639, "text": "We ourselves are distributed beings."}, {"time": 2649, "text": "And when we plan to say, okay, I want to create an architecture, how about I make a pyramid, I put this on the top and the power flows down."}, {"time": 2655, "text": "And so again, it's a little bit perhaps of a technology problem."}, {"time": 2664, "text": "But now the technology is there."}, {"time": 2669, "text": "So that is a big challenge to rethink how we want to organize power in a very large system and distribute a system, in my opinion, much more resilient."}, {"time": 2677, "text": "Let's put it this way."}, {"time": 2677, "text": "There was Italian compatriots, Machiavelli, who looked at the time, there was a bunch of small state democratic Republic of Florence and Venice and the other thing."}, {"time": 2693, "text": "And there was the Ottoman Empire that at the time was an empire and the Sultan was very centralized."}, {"time": 2698, "text": "And he made a political observation that goes roughly to say, whenever you have such a centralized thing, it's very hard to overtake that former government is centralized."}, {"time": 2709, "text": "But if you get it, it's so easy to keep the population."}, {"time": 2717, "text": "While instead these other things are much more resilient."}, {"time": 2717, "text": "When the power is distributed, it's going to be lasting for a much longer time."}, {"time": 2726, "text": "And ultimately maybe the human spirit wants that kind of resilience, wants that kind of distribution."}, {"time": 2733, "text": "It's just that we didn't have technology throughout history."}, {"time": 2736, "text": "Machiavelli didn't have the computer, the internet."}, {"time": 2743, "text": "That is certainly part of a reason."}, {"time": 2743, "text": "You've written an interesting blog post."}, {"time": 2743, "text": "If we just take a step out of the realm of bits and into the realm of governance, you wrote a blog post about making Algorand governance decentralized."}, {"time": 2756, "text": "Can you explain what that means, the philosophy behind that?"}, {"time": 2763, "text": "How you decentralized basically all aspects of this kind of system?"}, {"time": 2769, "text": "Let's start with the philosophy."}, {"time": 2769, "text": "I really believe that nothing fixed lasts very long."}, {"time": 2781, "text": "So I really believe that life is about intelligent adaptation."}, {"time": 2781, "text": "Things change, and we have to be nimble and adjust to change."}, {"time": 2790, "text": "When I see a lot of a crypto project, I'm actually very proud to say it's fixed in stone."}, {"time": 2802, "text": "Code is law."}, {"time": 2802, "text": "Law is code."}, {"time": 2802, "text": "I verify the code."}, {"time": 2802, "text": "It will never change."}, {"time": 2802, "text": "You go, wow."}, {"time": 2810, "text": "When I'm saying this is a recipe to me of disaster, not immediately, but soon."}, {"time": 2810, "text": "Just imagine you take an ocean liner, and you want to go, I don't know, from Lisbon to New York, and you set a course, iceberg, no iceberg, tempest, no tempest."}, {"time": 2824, "text": "You need a teal."}, {"time": 2824, "text": "You need to correct."}, {"time": 2835, "text": "You need to adjust."}, {"time": 2835, "text": "By the way, you would design Algorand with the idea that the code was evolving as the needs."}, {"time": 2845, "text": "Of course, there is a system in which every time there is an adjustment, you must have essentially a vote that right now is orchestrated at 90% of the stake."}, {"time": 2852, "text": "They say, okay, we are ready."}, {"time": 2859, "text": "We agree on the next version, and we pick up this version."}, {"time": 2859, "text": "So we are able to evolve without losing too many components left and right."}, {"time": 2865, "text": "But I think without evolving, any system essentially becomes aesthetic and is going to shrivel and die sooner or later."}, {"time": 2871, "text": "That is needed."}, {"time": 2881, "text": "What you want to do on the blockchain, you have a perfect platform in which you can log your wishes, your votes, your things, so that you have a guarantee that whatever vote you express is actually seen by everybody else."}, {"time": 2894, "text": "Everybody sees really the outcome, call it a referendum, of a change."}, {"time": 2900, "text": "And Vete is, in my opinion, a system that wants to live long as to adapt."}, {"time": 2908, "text": "There is an interesting question about leaders."}, {"time": 2908, "text": "I've talked to Vitalik Buterin."}, {"time": 2908, "text": "I'll probably talk to him again soon."}, {"time": 2913, "text": "He's one of the leaders, maybe one of the faces of the Ethereum project."}, {"time": 2920, "text": "You have Satoshi Nakamoto, who's the face of Bitcoin, I guess."}, {"time": 2920, "text": "But he's faceless."}, {"time": 2927, "text": "He, she, they."}, {"time": 2927, "text": "It does seem like in our whatever it is, maybe it's 20th century, maybe it's Machiavellian thinking, but we seek leaders."}, {"time": 2937, "text": "Leaders have value."}, {"time": 2937, "text": "Linus Torvalds, the leader of Linux, the open source development a lot."}, {"time": 2944, "text": "It's not that the leadership is sort of dogmatic, but it's inspiring."}, {"time": 2954, "text": "And it's also powerful in that through leaders, we propagate the vision."}, {"time": 2964, "text": "Like the vision of the project is more stable."}, {"time": 2964, "text": "Maybe not the details, but the vision."}, {"time": 2970, "text": "And so do you think there's value to, because there's a tension between decentralization and leadership, like in visionaries."}, {"time": 2976, "text": "What do you make of that tension?"}, {"time": 2981, "text": "So I really believe that, that's another great question."}, {"time": 2981, "text": "I think of it, I really believe in the power of emotions."}, {"time": 2987, "text": "I think the emotion are of a creative impulse of everybody else."}, {"time": 2992, "text": "And therefore it's very easy for a leader to be a physical person, a real being, and that interprets our emotions."}, {"time": 2999, "text": "And by the way, these emotions have to resonate."}, {"time": 3007, "text": "And what is good is that the more intimate our emotions are, the more universal they are, paradoxically."}, {"time": 3013, "text": "The more personal, the more everybody else somehow magically agrees and feels a bit of the same."}, {"time": 3019, "text": "And it's very important to have a leader in the initial phase that generates out of nothing something."}, {"time": 3026, "text": "That is important leadership."}, {"time": 3026, "text": "But then the true tested leadership is to disappear after you lead the community."}, {"time": 3031, "text": "So in my opinion, the quintessential leader according to my vision is George Washington."}, {"time": 3037, "text": "He served for one term, he served for another term, and then all of a sudden he retired and became a private citizen."}, {"time": 3048, "text": "And two hundred and change years later, we still are, with some defects, but we have done a lot of things right."}, {"time": 3060, "text": "And we have been able to evolve."}, {"time": 3060, "text": "That to me is success in leadership."}, {"time": 3065, "text": "While instead you contrast our experiment with a lot of our experiment."}, {"time": 3065, "text": "I've done so much so well that I want another four years."}, {"time": 3070, "text": "And why shouldn't I be only a four and I have another eight?"}, {"time": 3076, "text": "Why should it be another eight?"}, {"time": 3076, "text": "Give me 16 and I will fix all your problems."}, {"time": 3076, "text": "And then is the type, in my opinion, of failed leadership."}, {"time": 3081, "text": "Leadership ought to be really lead, ignite, and disappear."}, {"time": 3089, "text": "And if you don't disappear, the system is going to die with you."}, {"time": 3089, "text": "It is not a good idea for everybody else."}, {"time": 3094, "text": "So we've been talking a little bit about cryptocurrency, but is there spaces where this kind of blockchain ideas that you're describing, which I find fascinating, do you think they can revolutionize some other aspects of our world that's not just money?"}, {"time": 3112, "text": "A lot of things are going to be revolutionized is independent of finance."}, {"time": 3112, "text": "By the way, I really believe that finance is an incredible form of freedom."}, {"time": 3119, "text": "I mean, if I'm free to do everything I want, but I don't have the means to do anything, that's a bad idea."}, {"time": 3131, "text": "So I really think financial freedom is very, very important."}, {"time": 3131, "text": "But you just can say that against you know, censorship, you write something on the chain and now nobody can take it out."}, {"time": 3144, "text": "That is a very important way to express our view."}, {"time": 3144, "text": "And then the transparency that you give, because everybody can see what's happening on the blockchain."}, {"time": 3155, "text": "So transparency is not money."}, {"time": 3161, "text": "But I believe that transparency actually is a very important ingredient also of finance."}, {"time": 3161, "text": "Let's put this way, as much as I'm enthusiastic about blockchain and decentralized finance, and we have actually our expression, we're creating this future five, because as much as we want to do, we must agree that the first guarantee of financial growth and prosperity are really the legal system, the courts."}, {"time": 3191, "text": "Because we may not think about them and say, oh, the courts are a bunch of boring lawyers."}, {"time": 3196, "text": "But without them, I'm saying there is no certainty."}, {"time": 3196, "text": "There is no notion of equality."}, {"time": 3204, "text": "There is no notion that you can resolve your disputes thing."}, {"time": 3204, "text": "That's what thrives commerce and things."}, {"time": 3209, "text": "And so what I really believe that the blockchain actually makes a lot of this trust essentially automatic, but make it impossible to cheat in very way."}, {"time": 3215, "text": "You don't even need to go to court if nobody can change the ledger."}, {"time": 3221, "text": "So essentially it's a way of you cannot solve an illegal system that reduces to a blockchain."}, {"time": 3230, "text": "But what I'm saying, a big chunk of it can actually be guaranteed."}, {"time": 3235, "text": "And there is no reason why technology should be antagonistic to legal scholarship."}, {"time": 3243, "text": "It could be actually coexisting and one should start to doing the interest things that the technology alone cannot do."}, {"time": 3249, "text": "And then you go from there."}, {"time": 3249, "text": "But I think that essentially blockchain can affect all kinds of our behavior."}, {"time": 3263, "text": "So in some sense, the transparency, the required transparency ensures honesty, prevents corruption."}, {"time": 3270, "text": "So there's a lot of systems that could use that."}, {"time": 3270, "text": "And the legal system is one of them."}, {"time": 3274, "text": "There's a little bit of attention that I wonder if you can speak to where this kind of transparency, there's a tension with privacy."}, {"time": 3280, "text": "Is it possible to achieve privacy if wanted on a blockchain?"}, {"time": 3289, "text": "Do you have ideas about different technologies that can do that?"}, {"time": 3289, "text": "People have been playing with different ideas."}, {"time": 3295, "text": "And by the way, I'm a cryptographer."}, {"time": 3304, "text": "So I really believe in privacy and I believe in and I've devoted a big chunk of my life to guarantee privacy, even when it seems almost impossible to have it."}, {"time": 3313, "text": "And it is possible to have it also in the blockchain too."}, {"time": 3320, "text": "However, I believe in timing as well."}, {"time": 3320, "text": "And I believe that the people have the right to understand their system they live in."}, {"time": 3328, "text": "And right now people can understand the blockchain to be something that cannot be altered and is transparent."}, {"time": 3341, "text": "And that is good enough."}, {"time": 3350, "text": "And there is a pseudo privacy for the fact that who knows if this public key belongs to me or to you."}, {"time": 3359, "text": "And I can, when I want to change my money from one public key, I split it to other public keys, going to figure out which one is Silvio or all of them are Silvio or only one of Silvio."}, {"time": 3369, "text": "So you get some vanilla privacy, not the one I could talk."}, {"time": 3369, "text": "And I think it's good enough because, and it's important for now that we absorb this stage."}, {"time": 3375, "text": "Because in the next stage, we must understand the privacy tool rather than taking on faith."}, {"time": 3381, "text": "When the public starts saying, I believe in the scientists and whatever they say, I swear by them."}, {"time": 3387, "text": "And therefore, the term is private is private and nobody understands it very well."}, {"time": 3391, "text": "We need a much more educated about the tools we are using."}, {"time": 3395, "text": "And so I look forward to deploying more and more privacy on the blockchain, but we are not, I will not rush to it until the people understand and are behind whatever we have right now."}, {"time": 3413, "text": "So you build privacy on top of the power of the blockchain."}, {"time": 3413, "text": "You have to first understand the power of the blockchain."}, {"time": 3419, "text": "So Algorand is like one of the most exciting, technically at least from my perspective, technologies, ideas in this whole space."}, {"time": 3432, "text": "What's the future of Algorand look like?"}, {"time": 3432, "text": "Is it possible for it to dominate the world?"}, {"time": 3437, "text": "I certainly working very hard with a great team to give the best blockchain that one can demand and enjoy."}, {"time": 3446, "text": "And they said, I really believe that there is going to be, it's not a winner takes them all."}, {"time": 3455, "text": "So it's going to be a few blockchains and each one is going to have its own brand and it's going to be great at something."}, {"time": 3462, "text": "And sometimes it's scalability, sometimes it's your views, sometimes it's a thing."}, {"time": 3469, "text": "And it's important to have a dialogue between these things."}, {"time": 3476, "text": "And I'm sure, and I'm working very hard to make sure that Algorand is one of them, but I don't believe that it's even desirable to have a winner takes all because we need to express different things."}, {"time": 3491, "text": "But the important thing is going to have enough interoperability with various systems so that you can transfer your assets where you have the best tool to service them, whatever your needs are at the time."}, {"time": 3503, "text": "So there's an idea, I don't know, they call themselves Bitcoin maximalists, which is essentially the bet that the philosophy that Bitcoin will eat the world."}, {"time": 3516, "text": "So you're talking about, it's good to have variety."}, {"time": 3522, "text": "Their claim is it's good to have the best technology dominate the medium of exchange, the medium of store of value, the money, the digital currency space."}, {"time": 3538, "text": "What's your sense of the positives and the negatives of that?"}, {"time": 3543, "text": "So I feel people are smart and it's going to be very hard for anybody to win."}, {"time": 3543, "text": "And because people want more and more things."}, {"time": 3552, "text": "There is an Italian saying that translates well, I think."}, {"time": 3560, "text": "It goes, the appetite grows while eating."}, {"time": 3560, "text": "I think you understand what he means."}, {"time": 3560, "text": "So I say, I'm not hungry."}, {"time": 3567, "text": "Okay, food."}, {"time": 3567, "text": "Let me try this."}, {"time": 3567, "text": "So we want more and more and more."}, {"time": 3567, "text": "And when you find something like Bitcoin, which are already very good things to say, but it does something very well, but it's a static, I mean, store of value."}, {"time": 3579, "text": "Yes, I think it's a great way for the rest."}, {"time": 3579, "text": "You know, it would be a sad world if the world in which we are so anchoring down, so defensive that we want to store value and hide it under the mattress."}, {"time": 3593, "text": "I long for a world in which is open."}, {"time": 3599, "text": "People want to transact, interact with each other."}, {"time": 3599, "text": "And therefore, when you want to store value, one, perhaps one chain, where you want to have to transact, maybe is another."}, {"time": 3605, "text": "I'm not saying that, you know, one chain cannot be store of value or another thing, but I really believe, I believe in the ingenuity of people and in the innovation that is intrinsic to the human nature."}, {"time": 3625, "text": "We want always different things."}, {"time": 3625, "text": "So how can it be something invented, whatever it is decades ago, is going to fulfill the needs of our future generations."}, {"time": 3633, "text": "I'm not going to fulfill my needs, let alone my kids or their kids."}, {"time": 3633, "text": "We are going to have a different world and things will evolve."}, {"time": 3643, "text": "So you believe that life, intelligent life, is ultimately about adaptability and evolving."}, {"time": 3650, "text": "So static loses in the end."}, {"time": 3658, "text": "Let me ask the, well, first the ridiculous question."}, {"time": 3658, "text": "Do you have any clue who Satoshi Nakamoto is?"}, {"time": 3665, "text": "Is that even an interesting question?"}, {"time": 3672, "text": "Well, your questions are very interesting."}, {"time": 3672, "text": "So, and I think, so I would say, first of all, it's not me."}, {"time": 3679, "text": "And I can prove it because, you know, if I were Satoshi Nakamoto, I would have not found an algorithm."}, {"time": 3685, "text": "It takes a totally different principle to approach to the system."}, {"time": 3691, "text": "But the other thing, who is Satoshi Nakamoto?"}, {"time": 3691, "text": "You know what the right answer is?"}, {"time": 3691, "text": "It's not him or her or them."}, {"time": 3696, "text": "Satoshi Nakamoto is Bitcoin."}, {"time": 3696, "text": "Because to me, it's such a coherent proof of work that at the end, the creator and the creation identify themselves."}, {"time": 3706, "text": "So you say, okay, I understand Michelangelo."}, {"time": 3712, "text": "He did the Sistine Chapel."}, {"time": 3712, "text": "He did the St. Peter's Dome."}, {"time": 3717, "text": "He did the Moses of the Pieta statue."}, {"time": 3717, "text": "But besides this, who was Michelangelo?"}, {"time": 3724, "text": "That's the wrong question."}, {"time": 3724, "text": "It's his own work."}, {"time": 3724, "text": "That is Michelangelo."}, {"time": 3730, "text": "So I think that when you look at the Bitcoin is a piece of work that as it defects, yes, like anything human, but it was captivated the imaginations of millions of people as subverted the status quo."}, {"time": 3746, "text": "And I'm saying, you know, whoever this person of people are, he's living in this piece of work."}, {"time": 3754, "text": "I mean, it is Bitcoin."}, {"time": 3754, "text": "The idea of the work is bigger."}, {"time": 3754, "text": "We forget that sometimes."}, {"time": 3763, "text": "It's something about our biology likes to see a face and attach a face to the idea when really the idea is the thing we love."}, {"time": 3769, "text": "The idea is the thing that impact the idea is the thing that ultimately we, you know, Steve Jobs or somebody like that, we associate with the Mac or the iPhone with just everything he did at Apple."}, {"time": 3780, "text": "Apple, actually the company is Steve Jobs."}, {"time": 3780, "text": "Steve Jobs, the man is a pales in comparison to the creation."}, {"time": 3785, "text": "And the sense of aesthetics that has brought to the daily lives and very often aesthetic wins in the long, in the long, in the long game."}, {"time": 3799, "text": "And these are very elegant design product."}, {"time": 3799, "text": "And when you say, Oh, elegance, very few people care about it."}, {"time": 3805, "text": "Apparently millions and millions and millions and millions of people do because we are attacked by beauty and these are beautifully designed products."}, {"time": 3816, "text": "And, and, and, you know, and they've in addition to ever the technological aspect of the other thing."}, {"time": 3824, "text": "And I think, yes, that is, yeah, as the Stajewski said, beauty will save the world."}, {"time": 3830, "text": "So I'm, I'm with you on that one."}, {"time": 3830, "text": "It currently seems like cryptocurrency, all these different technologies are gathering a lot of excitement, not just in our discourse, but in their like scale of financial impact."}, {"time": 3847, "text": "A lot of companies are starting to invest in Bitcoin."}, {"time": 3854, "text": "Do you think that the main method of store value and exchange of value, basically money will soon or at some point in the century will become cryptocurrency?"}, {"time": 3869, "text": "So mind you, as I said, that the notion of cryptocurrency, like any other fundamental human notion has to evolve, but yes."}, {"time": 3876, "text": "So I think of it, uh, he has a lot of momentum behind it."}, {"time": 3885, "text": "Um, it's not only static as a visa programmable money as a smart contract."}, {"time": 3885, "text": "It allows a peer to peer interaction among people who don't even know each other."}, {"time": 3895, "text": "Uh, and they don't even, therefore I cannot even trust each other just because they never saw each other."}, {"time": 3906, "text": "So I think it's so powerful that, uh, uh, is going to do this said again, a particular cryptocurrency should develop and cryptocurrency will all develop."}, {"time": 3913, "text": "But the answer is yes, we are going towards a much more, uh, unless we have a society, a sudden crisis for different reasons, which nobody hopes there's always an asteroid."}, {"time": 3928, "text": "There's always something, uh, nuclear war and all the existential crisis that we kind of think about, including artificial intelligence."}, {"time": 3938, "text": "Uh, okay."}, {"time": 3938, "text": "You mentioned that, um, um, Michelangelo and Steve jobs, you know, set of ideas represents the person's work."}, {"time": 3950, "text": "So we talked about Algorand, which is a super interesting set of technologies, but, you know, he did also win the touring award."}, {"time": 3956, "text": "You have a bunch of, you have a bunch of ideas that are, you know, seminal ideas."}, {"time": 3965, "text": "So can we talk about cryptography for a little bit?"}, {"time": 3965, "text": "What is the most beautiful idea in cryptography or computer science or mathematics in general asking somebody who has explored the depths of all?"}, {"time": 3979, "text": "Well, there are a few contenders and, uh, either your work or, uh, or other words, uh, let's leave my work aside and, uh, and, uh, so, but one powerful idea and is, uh, both an old idea in some sense and a very, very modern one."}, {"time": 4009, "text": "And, uh, in my opinion is this idea of a one way function."}, {"time": 4009, "text": "So a function that easy to evaluate."}, {"time": 4017, "text": "So given X, you can compute F of X easily, but given F of X is very hard to go back to X."}, {"time": 4026, "text": "Think like breaking a glass, easy."}, {"time": 4026, "text": "Reconstruct the glass harder."}, {"time": 4026, "text": "Frying an egg, easy."}, {"time": 4026, "text": "From the fried egg to go back to the original egg, harder."}, {"time": 4037, "text": "If you want to be extreme, killing a living being, unfortunately, easy."}, {"time": 4044, "text": "The other way around, very hard."}, {"time": 4044, "text": "And so the fact that the notion of a function, whichever a recipe that is in front of your eyes to transform an X into F of X, and then from F of X, even though you see the recipe to transform it, you cannot go back to X."}, {"time": 4063, "text": "That in my opinion is one of the most elegant and momentous notions that there are."}, {"time": 4063, "text": "And it is a computational notion because of the difficulties in a computational sense."}, {"time": 4073, "text": "And it's a mathematical notion because we were talking about function."}, {"time": 4078, "text": "And it's so fruitful because that is actually the foundation of all cryptography."}, {"time": 4085, "text": "And let me tell you, it's an old notion because very often in any mythology that we think of, the most powerful gods or goddesses are the ones of X and the opposite of X, the gods of love and death."}, {"time": 4099, "text": "And when you take opposites, they don't just erase one another, you create something way more powerful."}, {"time": 4107, "text": "And this one, the function is extremely powerful because essentially becomes something that is easy for the good guys and hard for the bad guys."}, {"time": 4120, "text": "So for instance, in pseudo random number generation, the easy part of the function corresponds, you want to generate bits very quickly."}, {"time": 4129, "text": "And hard is predicting what the next bit is."}, {"time": 4134, "text": "It doesn't look the same."}, {"time": 4134, "text": "One is X f of X going from X f of X to X."}, {"time": 4142, "text": "Predicting bits."}, {"time": 4142, "text": "By a magic of reductions in mathematical apparatus, this simple function morphs itself into pseudo random generation."}, {"time": 4152, "text": "This simple function morphs itself in digital signature scheme in which digitally signing should be easy and forging should be and forging should be hard."}, {"time": 4163, "text": "Again, a digital signature is not going from X to f of X, but the magic and the richness of this notion is that it is so powerful that it morphs in all kinds of incredible constructs."}, {"time": 4177, "text": "And in both these two opposites coexist, the easy and the hard, and in my opinion is a very, very elegant notion."}, {"time": 4184, "text": "That simple notion ties together cryptography, and like you said, pseudo random number generation."}, {"time": 4192, "text": "You have work on pseudo random functions."}, {"time": 4200, "text": "What's the difference in those and the generators, the pseudo random number generators?"}, {"time": 4208, "text": "How do they work?"}, {"time": 4208, "text": "Let's go back to pseudo random number generation."}, {"time": 4208, "text": "First of all, people think that the pseudo random number generation generates a random number."}, {"time": 4216, "text": "Not true, because I don't believe that from nothing you can get something."}, {"time": 4219, "text": "So nothing from nothing."}, {"time": 4229, "text": "But randomness, you cannot create it out of nothing, but what you could do is that it can be expanded."}, {"time": 4269, "text": "Better than 50, 50."}, {"time": 4269, "text": "Of course, 50, 50, anybody can guess."}, {"time": 4275, "text": "But to be inferring something, you have to be a bit better."}, {"time": 4275, "text": "Then the effort to do this extra bit is so enormous that is de facto random."}, {"time": 4283, "text": "So that is a pseudo random generator, are these expanders of secret randomness, which goes extremely fast."}, {"time": 4289, "text": "Okay, that said, what is that?"}, {"time": 4297, "text": "Expanders of secret randomness, beautifully put."}, {"time": 4297, "text": "Okay, so every time somebody, if you're a programmer, is using a function that's not called pseudo random, it's called random usually, you know, these programming languages, and it's generating different, that's essentially expanding the secret randomness."}, {"time": 4314, "text": "In the past, actually, most of the library, they used something pre modern cryptography, unfortunately."}, {"time": 4320, "text": "They would be better served with 300 real seed random number, and then expand them properly, as we know now."}, {"time": 4338, "text": "But that has been a very old idea."}, {"time": 4338, "text": "In fact, one of the best philosophers have debated whether the world was deterministic or probabilistic."}, {"time": 4347, "text": "Very big questions, right?"}, {"time": 4353, "text": "Einstein says it does, it doesn't."}, {"time": 4353, "text": "But in fact, now we have a language that even at the Albert time was not around, but it was this complex theory of modern complexity based cryptography."}, {"time": 4365, "text": "And now we know that if the universe has 300 random bits, whether where is random or probabilistic or deterministic, it doesn't matter, because you can expand this initial seed of randomness forever in which all the experiments you could do, all the inferences you could do, all the things you could do, they are, you are not be able to distinguish them from truly random."}, {"time": 4388, "text": "So if you are not able to distinguish truly random from this super duper pseudo randomness, are they really different things?"}, {"time": 4402, "text": "So many to become really philosophical."}, {"time": 4402, "text": "So for things to be different, but I don't have in my lifetime, in the lifetime of the universe, any method to set them aside, well, I should be intellectually honest, say, well, pseudo random in this special fraction is as good as random."}, {"time": 4421, "text": "Do you think true randomness is possible?"}, {"time": 4428, "text": "So practically speaking, exactly as you said, if you're being honest, that the pseudo randomness approaches true randomness pretty quickly."}, {"time": 4438, "text": "But is it, maybe this is a philosophical question."}, {"time": 4438, "text": "Is there such a thing as true randomness?"}, {"time": 4445, "text": "Well, the answer is actually maybe, but if it exists, most probably it's expensive to get."}, {"time": 4454, "text": "And in any case, if I give you one of mine, you will never tell them apart by any other shape, no matter how much you work on it."}, {"time": 4466, "text": "So in some sense, if it exists or not, it really is a quote philosophical sense in the colloquial way to say that we cannot somehow pin it down."}, {"time": 4478, "text": "Do you ever, again, just to stay unphilosophical for a bit, for a brief moment, do you ever think about free will and whether that exists because ultimately free will sort of is this experience that we have, like we're making choices, even though it appears that, you know, the world is deterministic at the core."}, {"time": 4500, "text": "I mean, that's against the debate, but if it is in fact deterministic at the lowest possible level, at the physics level, how do you make, if it is deterministic, how do you make sense of the difference between the experience of us feeling like we're making a choice and the whole thing being deterministic?"}, {"time": 4525, "text": "So first of all, let me give you a gut reaction to the question."}, {"time": 4525, "text": "And the gut reaction is that it is important that we believe that there exists free will."}, {"time": 4530, "text": "And second of all, almost by weird logic, if we believe it exists, then it does exist."}, {"time": 4541, "text": "So it's very important for our social apparatus, for our sense of ourselves that it exists."}, {"time": 4548, "text": "And the moment in which, you know, we so want to, we almost conjure it up in existence."}, {"time": 4555, "text": "But again, I really feel that if you look at some point, the space of free will seems to shrink."}, {"time": 4562, "text": "We realize how more and more, how much of our, say, genetic apparatus dictates who we are, why we prefer certain things than others, right, and why we react to noises of music."}, {"time": 4577, "text": "We really prefer poetry and everything else."}, {"time": 4583, "text": "We may explain even all this."}, {"time": 4583, "text": "But at the end of the day, whether it exists in a philosophical sense or not, it's like randomness."}, {"time": 4591, "text": "If pseudo random is as good as random vis a vis lifetime of the universe, our experience, then it doesn't really matter."}, {"time": 4602, "text": "So, you know, we're talking about randomness."}, {"time": 4602, "text": "I wonder if I can weave in quantum mechanics for a brief moment."}, {"time": 4608, "text": "There's a, you know, a lot of advancements on the quantum computing side."}, {"time": 4615, "text": "So leveraging quantum mechanics to perform a new kind of computation, and there's concern of that being a threat to a lot of the basic assumptions that underlie cryptography."}, {"time": 4630, "text": "Do you think quantum computing will challenge a lot of cryptography?"}, {"time": 4630, "text": "Will cryptography be able to defend all those kinds of things?"}, {"time": 4640, "text": "So first of all, for the record, and not because I think it matters, but it's important to set the record, there are people who continue to contend that quantum mechanics exist, but that's nothing to do with computing."}, {"time": 4652, "text": "It's not going to accelerate it, at least, you know, very basic, you know, hard computation."}, {"time": 4657, "text": "That is a belief that you cannot take it out."}, {"time": 4657, "text": "I'm a little bit more agnostic about it, but I really believe, going back to whatever I said about the one way function."}, {"time": 4672, "text": "So one way function, what is it?"}, {"time": 4672, "text": "That is a cryptography."}, {"time": 4672, "text": "So does quantum computing challenge the one way function?"}, {"time": 4678, "text": "Essentially, you can boil it down to does quantum computing challenge the one way function."}, {"time": 4684, "text": "What is one way function?"}, {"time": 4684, "text": "Easy in one direction, hard in the other."}, {"time": 4689, "text": "Okay, but if quantum computing exists, when you define what it is easy, it's not easy by a classical computer and hard by a classical computer, but easy for a quantum computer, that's a bad idea."}, {"time": 4702, "text": "But once easy means it should be easy for a quantum and hard for also quantum."}, {"time": 4702, "text": "Then you can see that you are, yes, it's a challenge, but you have hope because you can absorb if one computing really realizes and becomes available according to the promises, then you can use them also for the easy part."}, {"time": 4724, "text": "And once you use it from the easy part, the choices that you have a one way function, they multiply."}, {"time": 4730, "text": "So, okay, so they particularly candidates of one way function, they not only candidates of one way function, they not be one way anymore, but quantum one way function may continue to exist."}, {"time": 4746, "text": "And so I really believe that for life to be meaningful, this one way function had to exist."}, {"time": 4758, "text": "Because just imagine that anything that is becomes easy to do."}, {"time": 4758, "text": "I mean, what kind of life is it?"}, {"time": 4768, "text": "I mean, so you need that."}, {"time": 4768, "text": "And if something is hard, but it's so hard to generate, you'll never find something which is hard for you."}, {"time": 4775, "text": "You want to that there is abundance, that is easy to produce hard problem."}, {"time": 4779, "text": "That's my opinion is why life is interesting, because pop up really, really speed."}, {"time": 4784, "text": "So in some sense, I almost think that I do hope they exist if they don't exist, somehow life is way less interesting than it actually is."}, {"time": 4799, "text": "It does seem like the one way function is fundamental to all of life, which is the emergence of the complexity that we see around us seem to require the one way function."}, {"time": 4812, "text": "I don't know if you play with cellular automata."}, {"time": 4812, "text": "That's just another formulation of."}, {"time": 4818, "text": "I know, but it's very simple."}, {"time": 4822, "text": "It's almost a very simple illustration of starting out with simple rules in one way, being able to generate incredible amounts of complexity."}, {"time": 4829, "text": "But then you ask the question, can I reverse that?"}, {"time": 4834, "text": "And it's just surprising how difficult it is to reverse that."}, {"time": 4834, "text": "It's surprising, even in constrained situations, it's very difficult to prove anything that it almost, I mean, the sad thing about it."}, {"time": 4852, "text": "Well, I don't know if it's sad, but it seems like we don't even have the mathematical tools to reverse engineer stuff."}, {"time": 4858, "text": "I don't know if they exist or not, but in the space of cellular automata, where you start with something simple and you create something incredibly complex, can you take something, a small picture of that complex and reverse engineer?"}, {"time": 4874, "text": "That's kind of what we're doing as scientists here."}, {"time": 4874, "text": "You're seeing the result of the complexity and you're trying to come up with some universal law that generate all of this."}, {"time": 4884, "text": "What is the theory of everything?"}, {"time": 4884, "text": "What are the basic physics laws that generated this whole thing?"}, {"time": 4889, "text": "And there's a hope that you should be able to do that, but it gets, it's difficult."}, {"time": 4895, "text": "But there is also some poetry on the fact that it's difficult because it gives us some mystery to life, without which, I mean, it's not so fun."}, {"time": 4900, "text": "Life is no business fun."}, {"time": 4908, "text": "Can we talk about interactive proofs a little bit and zero knowledge proofs?"}, {"time": 4915, "text": "So interactive proof actually is a modern realization and conceptualization of something that we knew was true, that is easy to go to lecture."}, {"time": 4926, "text": "In fact, that's my motivation."}, {"time": 4932, "text": "We invented schools to go to lecture."}, {"time": 4932, "text": "We don't say, oh, I'm the minister of education."}, {"time": 4932, "text": "I published this book."}, {"time": 4937, "text": "You read it."}, {"time": 4937, "text": "This is book for this year, this book for this year."}, {"time": 4937, "text": "We spend a lot of our treasury in educating our kids and in person, educating, go to class, interact with teacher, on the blackboard and chalk on my time."}, {"time": 4951, "text": "Now we can have a whiteboard and presumably you're going to have actually this magic pens and a display instead."}, {"time": 4957, "text": "But the idea is that interactively you can convey truth much more efficiently."}, {"time": 4966, "text": "We knew this psychologically."}, {"time": 4966, "text": "It's better to hear an explanation than just to belabor some paper."}, {"time": 4973, "text": "So interactive proofs is a way to do the following."}, {"time": 4980, "text": "Rather than doing some complicated, very long papers and possibly infinitely long proofs, exponentially long proofs, you say the following."}, {"time": 4986, "text": "If this theorem is true, there is a game that is associated to the theorem."}, {"time": 4992, "text": "If the theorem is true, this game, I have a winning strategy that I can win half of the time, no matter what you do."}, {"time": 5006, "text": "So then you say, well, is the theorem true?"}, {"time": 5006, "text": "You believe me."}, {"time": 5006, "text": "Why should I believe you?"}, {"time": 5006, "text": "Okay, let's play."}, {"time": 5010, "text": "If I prove that I have a strategy and I win the first time and I win the second time, then I lose a third time."}, {"time": 5018, "text": "But I win more than half of the time, or I win, say, all the time if the theorem is true, and at least at most half of the time if the theorem is false, you statistically get convinced."}, {"time": 5030, "text": "You can verify this quickly."}, {"time": 5030, "text": "And therefore, when the game typically is extremely fast, so you generate a miniature game in which if the theorem is true, I win all the time, and if the theorem is false, I can win at most half of the time."}, {"time": 5046, "text": "And if I win, win, win, win, win, win, win, win, you can deduce either the theorem is true, which most probably is my case of the week, or I've been very, very unlucky because it's like if I had 100 coin tosses and I got 100 heads."}, {"time": 5065, "text": "Very improbable."}, {"time": 5065, "text": "So that is a way."}, {"time": 5065, "text": "And so this transformation from the formal statement of a proof into a game that can be quickly played, and you can draw statistics how many times you win, is one of a big conquest of modern complexity theory."}, {"time": 5081, "text": "And in fact, actually has highlighted the notion of a proof as it really gives us a new insight of what to be true means and what truth is and what proofs are."}, {"time": 5097, "text": "So these are legitimately proofs."}, {"time": 5097, "text": "So what kind of mysteries can it allow us to unlock and prove?"}, {"time": 5105, "text": "You said truth."}, {"time": 5105, "text": "So what does it allow us?"}, {"time": 5117, "text": "What kind of truth does that allow us to arrive at?"}, {"time": 5117, "text": "So it enlarges the realm of what is provable because in some sense of the classical way of proving things was extremely inefficient from the verifier point of view."}, {"time": 5134, "text": "And so therefore, there is so much proof that you can take."}, {"time": 5134, "text": "But in this way, you can actually very quickly, in minutes, verify something that is the correctness of an assertion that otherwise would have taken a lifetime to belabor and check all the passages of a very, very, very long proof."}, {"time": 5156, "text": "And you better check all of them because if you don't check one line, an error can be in that line."}, {"time": 5162, "text": "And so you have to go linearly through all the stuff rather than bypass this."}, {"time": 5168, "text": "So you enlarge a tremendous amount what the proof is."}, {"time": 5168, "text": "And in addition, once you have the idea that essentially a proof system is something that allows me to convince you of a true statement, but does not allow me to convince you of a false statement, and that at the end is proof."}, {"time": 5188, "text": "Proof can be beautiful, should be elegant, but at the end is true or false."}, {"time": 5195, "text": "It is possible to prove the truth and it should be impossible or statistically extremely hard to prove something false."}, {"time": 5203, "text": "And if you do this, you can prove way, way more once you understand this."}, {"time": 5209, "text": "And on top of it, we got some insight like in this zero knowledge proofs that is in something which you took for granted where the same knowledge and verification are actually separate concepts."}, {"time": 5224, "text": "So you can verify that an assertion is correct without having any idea why this is so."}, {"time": 5231, "text": "And so people failed to say, if you want to verify something, you have to have the proof."}, {"time": 5238, "text": "Once you have the proof, you know why it's true, you have the proof itself."}, {"time": 5242, "text": "So somehow you can totally differentiate knowledge and verification validity."}, {"time": 5253, "text": "So totally, you can decide if something is true and still have no idea."}, {"time": 5257, "text": "Is there a good example in your mind?"}, {"time": 5258, "text": "Oh, actually, you know, at the beginning, we labored to find the first zero knowledge proof."}, {"time": 5267, "text": "Then we found a second, then we found a third."}, {"time": 5267, "text": "And then a few years later, actually, we proved a theorem which essentially says every theorem, no matter what about, can be explained in a zero knowledge way."}, {"time": 5281, "text": "So it's not a class of theorem, but all theorems."}, {"time": 5281, "text": "And it's a very powerful thing."}, {"time": 5281, "text": "So we were really, for thousands of years, bought this identity between knowledge and verification had to be hand in hand together, and for no reason at all."}, {"time": 5298, "text": "I mean, we had to develop a way of technology."}, {"time": 5303, "text": "As you know, I'm very big on technology because it makes us more human and make us understand more things than before."}, {"time": 5308, "text": "And I think that's a good thing."}, {"time": 5317, "text": "So this interactive proof process, there's power in games."}, {"time": 5323, "text": "And you've recently gotten into, recently, I'm not sure you can correct me, mechanism design."}, {"time": 5330, "text": "So first of all, maybe you can explain what mechanism design is and the fascinating space of playing with games and designing games."}, {"time": 5343, "text": "Mechanism design is that you want a certain behavior to arise."}, {"time": 5343, "text": "If you want to organize a societal structure or something, you want to have some orderly behavior to arise because it is important for your goals."}, {"time": 5357, "text": "But you know that people, they don't care what my goals are."}, {"time": 5366, "text": "They care about maximizing their utility."}, {"time": 5366, "text": "So put it crassly, making money."}, {"time": 5366, "text": "The more money, the better, so to speak."}, {"time": 5372, "text": "I'm exaggerating."}, {"time": 5376, "text": "Self interest in whatever way then."}, {"time": 5379, "text": "So what you want to do is, ideally, what you want to do is to design a game so that while people play it, so to maximize their self interest, they achieve the social goal and behavior that I want."}, {"time": 5396, "text": "That is really the best type of thing."}, {"time": 5396, "text": "And it is a very hard science and art to design these games."}, {"time": 5403, "text": "And it challenges us to actually come up with solution concepts for a way to analyzing the games that need to be broader."}, {"time": 5418, "text": "And I think game theory has developed a bunch of very compelling ways to analyze the game, that if the game has the best property, you can have a pretty good guarantee that it's going to be played in a given way."}, {"time": 5437, "text": "But as it turns out, and not surprisingly, these tools have a range of action like anything else."}, {"time": 5445, "text": "All these so called the technical resolution concept, the way to analyze the game, like dominant strategy equilibrium, if something comes to mind, would be very meaningful."}, {"time": 5454, "text": "But as a limited power, in some sense, the games that can be admit to such a way to be analyzed."}, {"time": 5465, "text": "There's a very specific kind of games and the rules are set, the constraints are set, the utilities are all set."}, {"time": 5471, "text": "So if you want to reason, if there is a way, say, that you can analyze a restricted class of games this way, but most games don't fall into this restricted class, then what do I do?"}, {"time": 5486, "text": "When you need to enlarge a way what a rational player can do."}, {"time": 5486, "text": "So for instance, in my opinion, at least in some of my, I played with this for a few years, and I was doing some exoteric things, I'm sure, in the space that was not exactly mainstream."}, {"time": 5504, "text": "And then I changed my interest in blockchain."}, {"time": 5511, "text": "But what I'm saying for a while I was doing."}, {"time": 5511, "text": "So for instance, to me, is a way in which I design the game, and you don't have the best move for you."}, {"time": 5518, "text": "The best move is the move that is best for you, no matter what the other players are doing."}, {"time": 5524, "text": "Sometimes a game doesn't have that, okay, it's too much to ask."}, {"time": 5528, "text": "But I can design the game such that given the option in front of you say, oh, these are really stupid for me, take them aside."}, {"time": 5535, "text": "But these, these are not stupid."}, {"time": 5541, "text": "So if you design the game so that in any combination of non stupid things that the player can do, I achieve what I want, I'm done."}, {"time": 5547, "text": "I don't care to find the very unique equilibrium."}, {"time": 5547, "text": "I don't give a damn."}, {"time": 5556, "text": "I want to say, well, as long as you don't do stupid things, and nobody else does stupid things, good social things outcome arise, I should be equally happy."}, {"time": 5561, "text": "And so I really believe that this type of analysis is possible and has a bigger radius."}, {"time": 5568, "text": "So it reaches more games, more classes or games."}, {"time": 5581, "text": "And after that, we have to enlarge it again."}, {"time": 5581, "text": "And it's going to be, we're going to have fun because human behavior can be conceptualized in many ways."}, {"time": 5587, "text": "And it's a long game."}, {"time": 5596, "text": "It's a long game."}, {"time": 5596, "text": "Do you have favorite games that you're looking at now?"}, {"time": 5596, "text": "I mean, I suppose your work with blockchain and Algorand is a kind of game that you're basically this mechanism design, design the game such that it's scalable, secure and decentralized, right?"}, {"time": 5606, "text": "And very often you have to say, and you must also design so that the incentives are, and tell you the truth, whatever little I learned from my venture in mechanism design is that incentives are very hard to design because people are very complex creatures."}, {"time": 5631, "text": "And so somehow the way we design Algorand is a totally different way, essentially with no incentives, essentially."}, {"time": 5639, "text": "But technically speaking, there is a notion that is actually believable, right?"}, {"time": 5648, "text": "So that to say people want to maximize their utility."}, {"time": 5656, "text": "Up to a point."}, {"time": 5656, "text": "Let me tell you."}, {"time": 5656, "text": "Assume that if you are honest, you make a hundred bucks."}, {"time": 5665, "text": "But if you are dishonest, no matter how dishonest you are, you can only make a hundred bucks and one cent."}, {"time": 5670, "text": "What are you going to be?"}, {"time": 5670, "text": "I'm saying, you know what?"}, {"time": 5675, "text": "Technically speaking, even that one cent, nobody bothers and say, how much am I going to make by honest?"}, {"time": 5682, "text": "A hundred."}, {"time": 5682, "text": "If I'm devious and if I'm a criminal, 100 bucks and one cent, you know, I might as well be honest."}, {"time": 5686, "text": "So that essentially is called, you know, Epsilon utility equilibrium, but I think it's good."}, {"time": 5691, "text": "And that's what we design essentially means that, you know, having no incentives is actually a good thing because prevent people from reasoning, how else are you going to gain the system?"}, {"time": 5707, "text": "But why can we achieve an algorithm to have no incentives and in Bitcoin instead, you have to pay the miners because they do a tremendous amount of work."}, {"time": 5718, "text": "Because if you have to do a lot of work, then you demand to be paid accordingly."}, {"time": 5726, "text": "Because you, right?"}, {"time": 5726, "text": "But if I'm going to say you have to add two and two equal to four, how much you want me to pay for this?"}, {"time": 5731, "text": "If you don't give me this, I don't add the two and two."}, {"time": 5735, "text": "I would say you can add two and two in your sleep."}, {"time": 5735, "text": "You don't need to be paid to add the two and two."}, {"time": 5768, "text": "Since you're Italian, Sicilian, I also heard rumors that you are a connoisseur of food."}, {"time": 5779, "text": "If I said today's the last day you get to be alive, you shouldn't have trusted me."}, {"time": 5786, "text": "You never know with a Russian whether you're going to make it out or not."}, {"time": 5786, "text": "Well, if you had one last meal, you can travel somewhere in the world."}, {"time": 5789, "text": "Either you make it or somebody else makes it."}, {"time": 5796, "text": "What's that going to look like?"}, {"time": 5796, "text": "If it's one last meal, I must say in this era of COVID, I have not been able to see my mom."}, {"time": 5804, "text": "My mom was a fantastic chef and had this very traditional food."}, {"time": 5816, "text": "As you know, the very traditional food are great for a reason, because they survived hundreds of years of culinary innovation."}, {"time": 5820, "text": "There is one very laborious thing, which is, you heard the name, which is parmigiana, but to do it is a piece of art."}, {"time": 5836, "text": "So many hours that only my mom could do it."}, {"time": 5836, "text": "If we have one last meal, I want a parmigiana."}, {"time": 5842, "text": "What's the laborious process?"}, {"time": 5842, "text": "Is it the ingredients?"}, {"time": 5842, "text": "Is it the actual process?"}, {"time": 5851, "text": "Is it the atmosphere and the humans involved?"}, {"time": 5856, "text": "The ingredient like in any other, in the Italian cuisine, believes in very few ingredients."}, {"time": 5865, "text": "If you take say quintessential Italian recipe, spaghetti pesto."}, {"time": 5865, "text": "Pesto is olive oil, very good extra virgin olive oil, basil, pine nuts, pepper, clove of garlic, not too much, otherwise you overpower everything."}, {"time": 5886, "text": "And then to do either two schools of thought, parmesan or pecorino or a mix of the two."}, {"time": 5895, "text": "I mentioned six ingredients."}, {"time": 5895, "text": "That is typical Italian."}, {"time": 5895, "text": "I understand that there are other cuisines, for instance, a French cuisine, which is extremely sophisticated and extremely combinatorial, or some Chinese cuisine, which has a lot of many more ingredients than this."}, {"time": 5913, "text": "And yet the art is to put them together a lot of things."}, {"time": 5913, "text": "In Italy is really the striving for simplicity, yet to find few ingredients, but the right ingredients to create something."}, {"time": 5925, "text": "So in parmigiana, the ingredients are eggplants, tomatoes, basil, but how to put them together and the process is an act of love, labor and love."}, {"time": 5934, "text": "You can spend the entire day, I'm not exaggerating, but the entire morning for sure to do it properly."}, {"time": 5949, "text": "Yeah, as a Japanese cuisine too, there's a mastery to the simplicity with the sushi."}, {"time": 5949, "text": "I don't know if you've seen Giorgio's of sushi, but there's a mastery to that that's propagated through the generations."}, {"time": 5959, "text": "You know, people love it when I ask about books."}, {"time": 5959, "text": "I don't know if books, whether fiction, nonfiction, technical or completely non technical had an impact on your life throughout."}, {"time": 5972, "text": "If there's anything you would recommend or even just mention as something that gave you an insight or moved you in some way."}, {"time": 5977, "text": "So I don't know if I can comment because in some sense you almost had to be Italian or to be such a scholar, but being Italian, one thing that really impressed me tremendously is the Divine Comedy."}, {"time": 5991, "text": "It is a medieval poem, a very long poem divided in three parts, hell, purgatory and paradise."}, {"time": 5999, "text": "And that is the non trivial story of a middle man gets into a crisis, personal crisis."}, {"time": 6007, "text": "And then out of this crisis he purifies, makes a catastrophe, purifies himself more and more and more until he's become capable of actually meeting God."}, {"time": 6028, "text": "And that is actually a complex story."}, {"time": 6028, "text": "So you have to get some very sophisticated language, maybe Latin at that point."}, {"time": 6035, "text": "We are talking about 1200s Italy, in Florence."}, {"time": 6045, "text": "And this guy instead, he chose his own dialect, not spoken outside his own immediate circle, a Florentine dialect."}, {"time": 6052, "text": "Actually, Dante really made Italian, Italian."}, {"time": 6052, "text": "How can you express such a sophisticated thing?"}, {"time": 6061, "text": "And then the point is that these words that nobody actually knew because they were essentially dialect and plus a bunch of very intricate rhymes in which they had to rhyme with things."}, {"time": 6076, "text": "And it turns out that by getting meaning from the things that rhyme, you essentially guess what the word means and you invent Italian and you communicate it by almost osmosis what you want."}, {"time": 6089, "text": "It's a miracle of communication."}, {"time": 6089, "text": "In a dialect, a very poor language, very unsophisticated to express very sophisticated situation."}, {"time": 6101, "text": "People love it, Italians and not Italian."}, {"time": 6101, "text": "But what I got of it is that very often limitations are our strength."}, {"time": 6112, "text": "Because if you limit yourself at a very poor language, somehow you get out of it and you achieve even better form of communication using a hyper sophisticated literary language with lots of resonance from the prior books so that you can actually instantaneously quote."}, {"time": 6128, "text": "He couldn't quote anything because nothing was written in Italian before him."}, {"time": 6133, "text": "So I really felt that limitations are our strength."}, {"time": 6133, "text": "And I think that rather than complaining about the limitations, we should embrace them because if we embrace our limitation, limited as we are, we find very creative solutions that people with less limitation we have, we would not even think about it."}, {"time": 6156, "text": "So limitations are kind of superpower if you choose to see it that way."}, {"time": 6161, "text": "Since you speak both languages, is there something that's lost in translation to you?"}, {"time": 6161, "text": "Is there something you can express in Italian that you can't in English and vice versa maybe?"}, {"time": 6169, "text": "Is there something you could say to the musicality of the language?"}, {"time": 6175, "text": "I mean, I've been to Italy a few times and I'm not sure if it's the actual words, but the people are certainly very, there's body language too."}, {"time": 6189, "text": "There's just the whole being is language."}, {"time": 6189, "text": "So I don't know if you miss some of that when you're speaking English in this country."}, {"time": 6196, "text": "In fact, actually, certainly I miss it."}, {"time": 6205, "text": "And somehow it was a sacrifice that I made consciously by the time I arrived."}, {"time": 6205, "text": "I knew that this, I was not going to express myself at that level."}, {"time": 6213, "text": "And it was actually a sacrifice because given to you also your mother tongue is Russian."}, {"time": 6220, "text": "So you know that you can be very expressive in your mother tongue and not very expressive in a new tongue, a new language."}, {"time": 6227, "text": "And then what people think of you in the new language, because when the precise of expression of things, it generates, it shows elegance or it shows knowledge or it shows as a census or it shows as a caste or education, whatever it is."}, {"time": 6248, "text": "So all of a sudden I found myself on the bottom."}, {"time": 6254, "text": "So I had to fight all my way up, back up."}, {"time": 6254, "text": "But what I'm saying, their limitations are actually our strength."}, {"time": 6262, "text": "In fact, it's a trick to limit yourself to exceed."}, {"time": 6262, "text": "And there are examples in history."}, {"time": 6270, "text": "If you think about Hernan Cortes, he goes to invade Mexico."}, {"time": 6270, "text": "He has what, a few hundred people with him and he has a hundred thousand people in arms on the other side."}, {"time": 6278, "text": "First thing he does, he limits himself."}, {"time": 6284, "text": "He sinks his own ship."}, {"time": 6284, "text": "There is no return."}, {"time": 6284, "text": "And at that point he actually manages."}, {"time": 6293, "text": "That's really profound."}, {"time": 6293, "text": "I actually, first of all, this inspiring to me, I feel like I have quite a few limitations, but more practically on the Russian side, I'm going to try to do a couple of really big and really tough interviews in Russian."}, {"time": 6307, "text": "Once COVID lifts a little bit, I'm traveling to Russia and I'll keep your advice in mind that the limitations is a kind of superpower."}, {"time": 6321, "text": "We should use it to our advantage because you do feel less, like you're not able to convey your wisdom in the Russian language."}, {"time": 6328, "text": "Cause I moved here when I was 13."}, {"time": 6328, "text": "So you don't, the parts of life you live under a certain language are the parts of life you're able to communicate."}, {"time": 6340, "text": "I became a thoughtful, deeply thoughtful human in English."}, {"time": 6348, "text": "But the pain from World War II, the music of the people that was instilled with me in Russian."}, {"time": 6356, "text": "So I can carry both of those and there's limitations in both."}, {"time": 6356, "text": "I can't say philosophically profound stuff in Russian, but I can't in English express like that melancholy feeling of like the people."}, {"time": 6368, "text": "And so combining those two, I'll somehow."}, {"time": 6371, "text": "Oh, beautifully said."}, {"time": 6371, "text": "Thanks for sharing."}, {"time": 6371, "text": "I totally understand you."}, {"time": 6378, "text": "You've accomplished some incredible things in the space of science, in the space of technology, in the space of theory and engineering."}, {"time": 6386, "text": "Do you have advice for somebody young, an undergraduate student, somebody in high school or anyone who just feels young about life or about career, about making their way in this world?"}, {"time": 6403, "text": "So I was telling before that I believe in emotion and my thing is to be true to your own emotion."}, {"time": 6411, "text": "And that I think that if you do that, you're doing well because it's a life well spent and you are going never tire because you want to solve all these emotional knots that always intrigued you from the beginning."}, {"time": 6425, "text": "And I really believe that to live meaningfully, creatively, and yet to live your emotional life."}, {"time": 6433, "text": "So I really believe that whether you're a scientist or an artist even more, but a scientist, I think of them as artists as well."}, {"time": 6440, "text": "If you are a human being, so you are really to live fully your emotions and to the extent possible, sometimes emotions can be overbearing and my advice is try to express them with more and more confident."}, {"time": 6459, "text": "Sometimes it's hard, but you are going to be much more fulfilled than by suppressing them."}, {"time": 6465, "text": "What about love?"}, {"time": 6465, "text": "One of the big ones."}, {"time": 6465, "text": "What role does that play?"}, {"time": 6470, "text": "That's the bigger part of emotions."}, {"time": 6470, "text": "It's a scary thing."}, {"time": 6470, "text": "It's a lot of vulnerability that comes with love, but there is also so much energy and power and love in all senses and in the traditional sense, but also in the sense of a broader sense for humanity, this feeling, this compassion that makes us one with other people and the suffering of other people."}, {"time": 6500, "text": "All of this is very scary stuff, but it's really the fabric of life."}, {"time": 6508, "text": "Well, the sad thing is it really hurts to lose it."}, {"time": 6518, "text": "Yes, that's why the vulnerability comes with it."}, {"time": 6518, "text": "That's the thing about emotion is the up and the down and the down seems to come always with up, but the up only comes with the down."}, {"time": 6531, "text": "Let me ask you about the ultimate down, which is unfortunately we humans are mortal or appear to be for the most part."}]}]