[{"title": "Elon Musk: Tesla Autopilot | Lex Fridman Podcast #18", "id": "dEv99vxKjVI", "quotes": [{"time": 341, "text": "And people do confirm that there's a car in front of me and the system sees there's a car in front of me, but to help people build an intuition of what computer vision is by showing some of the uncertainty."}, {"time": 353, "text": "Well, I think it's, in my car, I always look at the sort of the debug view."}, {"time": 357, "text": "And there's, there's two debug views."}, {"time": 359, "text": "Uh, one is augmented vision, uh, where, which I'm sure you've seen where it's basically, we draw boxes and labels around objects that are recognized."}, {"time": 370, "text": "And then there's a work called the visualizer, which is basically vector space representation, summing up the input from all sensors that doesn't, that doesn't, does not show any pictures, but it shows, uh, all of the, it's basically shows the car's view of, of, of the world in vector space."}, {"time": 392, "text": "Um, but I think this is very difficult for people to know, normal people to understand, they would not know what they're looking at."}, {"time": 399, "text": "So it's almost an HMI challenge to the current things that are being displayed is optimized for the general public understanding of what the system is capable of."}, {"time": 408, "text": "It's like, if you have no idea what, how computer vision works or anything, you can sort of look at the screen and see if the car knows what's going on."}, {"time": 415, "text": "And then if you're, you know, if you're a development engineer or if you're, you know, if you're, if you have the development build like I do, then you can see, uh, you know, all the debug information, but those would just be like total diverse to most people."}, {"time": 431, "text": "What's your view on how to best distribute effort."}, {"time": 434, "text": "So there's three, I would say technical aspects of autopilot that are really important."}, {"time": 438, "text": "So it's the underlying algorithms, like the neural network architecture, there's the data, so that the strain on, and then there's a hardware development."}, {"time": 446, "text": "There may be others, but so look, algorithm, data, hardware, you don't, you only have so much money, only have so much time, what do you think is the most important thing to, to, uh, allocate resources to, or do you see it as pretty evenly distributed between those three?"}, {"time": 463, "text": "We automatically get a fast amounts of data because all of our cars have eight external facing cameras and radar, and usually 12 ultrasonic sensors, uh, GPS, obviously, um, and, uh, IMU."}, {"time": 482, "text": "And so we basically have a fleet that has, uh, and we've got about 400,000 cars on the road that have that level of data, I think you keep quite close track of it actually."}, {"time": 495, "text": "So we're, we're approaching half a million cars on the road that have the full sensor suite."}, {"time": 501, "text": "Um, so this is, I'm, I'm not sure how many other cars on the road have the sensor suite, but I would be surprised if it's more than 5,000, which means that we have 99% of all the data."}, {"time": 515, "text": "So there's this huge inflow of data."}, {"time": 517, "text": "Massive inflow of data, and then we, it's, it's taken us about three years, but now we've finally developed our full self driving computer, which can process, uh, and in order of magnitude as much as the Nvidia system that we currently have in the, in the cars, and it's really just a, to use it, you've unplugged the Nvidia computer and plug the Tesla computer in and that's it."}, {"time": 541, "text": "And it's, it's, uh, in fact, we're not even, we're still exploring the boundaries of capabilities, uh, but we're able to run the cameras at full frame rate, full resolution, uh, not even crop the images and it's still got headroom even on one of the systems, the harder full self driving computer is really two computers, two systems on a chip that are fully redundant."}, {"time": 563, "text": "So you could put a bolt through basically any part of that system and it still works."}, {"time": 567, "text": "The redundancy, are they perfect copies of each other or also it's purely for redundancy as opposed to an argue machine kind of architecture where they're both making decisions."}, {"time": 577, "text": "This is purely for redundancy."}, {"time": 579, "text": "I think it would more like it's, if you have a twin engine aircraft, uh, commercial aircraft, the system will operate best if both systems are operating, but it's, it's capable of operating safely on one."}, {"time": 593, "text": "So, but as it is right now, we can just run, we're, we haven't even hit the, the, the edge of performance."}, {"time": 601, "text": "So there's no need to actually distribute functionality across both SOCs."}, {"time": 610, "text": "We can actually just run a full duplicate on, on, on each one."}, {"time": 613, "text": "Do you haven't really explored or hit the limit of this?"}, {"time": 617, "text": "Not yet at the limiter."}, {"time": 618, "text": "So the magic of deep learning is that it gets better with data."}, {"time": 622, "text": "You said there's a huge inflow of data, but the thing about driving the really valuable data to learn from is the edge cases."}, {"time": 632, "text": "So how do you, I mean, I've, I've heard you talk somewhere about, uh, autopilot disengagements being an important moment of time to use."}, {"time": 642, "text": "Is there other edge cases where you can, you know, you can, you can, you can drive, is there other edge cases or perhaps can you speak to those edge cases?"}, {"time": 653, "text": "What aspects of that might be valuable or if you have other ideas, how to discover more and more and more edge cases in driving?"}, {"time": 660, "text": "Well, there's a lot of things that are learned."}, {"time": 662, "text": "There are certainly edge cases where I say somebody is on autopilot and they, they take over and then, okay, that, that, that, that's a trigger that goes to our system that says, okay, did they take over for convenience or do they take over because the autopilot wasn't working properly."}, {"time": 679, "text": "There's also like, let's say we're, we're trying to figure out what is the optimal spline for traversing an intersection."}, {"time": 687, "text": "Um, then then the ones where there are no interventions and are the right ones."}, {"time": 693, "text": "So you then say, okay, when it looks like this, do the following."}, {"time": 698, "text": "And then, and then you get the optimal spline for a complex, uh, navigating a complex, uh, intersection."}, {"time": 704, "text": "So that's for this."}, {"time": 706, "text": "So there's kind of the common case you're trying to, uh, capture a huge amount of samples of a particular intersection, how, when things went right, and then there's the edge case where, uh, as you said, not for convenience, but something didn't go exactly right."}, {"time": 721, "text": "Somebody took over, somebody asserted manual control from autopilot."}, {"time": 725, "text": "And really like the way to look at this as view all input is error."}, {"time": 728, "text": "If the user had to do input, it does something all input is error."}, {"time": 732, "text": "That's a powerful line."}, {"time": 733, "text": "That's a powerful line to think of it that way, because they may very well be error, but if you want to exit the highway, or if you want to, uh, it's a navigation decision that all autopilot is not currently designed to do."}, {"time": 745, "text": "Then the driver takes over."}, {"time": 747, "text": "How do you know the difference?"}, {"time": 748, "text": "That's going to change with navigate an autopilot, which we were just released and without still confirm."}, {"time": 753, "text": "So the navigation, like lane change based, like a certain control in order to change, do a lane change or exit a freeway or, or doing a highway under change, the vast majority of that will go away with, um, the release that just went out."}, {"time": 769, "text": "So that, that I don't think people quite understand how big of a step that is."}, {"time": 774, "text": "Yeah, they don't."}, {"time": 775, "text": "So if you drive the car, then you do."}, {"time": 778, "text": "So you still have to keep your hands on the steering wheel currently when it does the automatic lane change."}, {"time": 783, "text": "What are, so there's, there's these big leaps through the development of autopilot through its history and what stands out to you as the big leaps?"}, {"time": 793, "text": "I would say this one, navigate an autopilot without, uh, confirm without having to confirm is a huge leap."}, {"time": 801, "text": "It is a huge leap."}, {"time": 802, "text": "It also automatically overtakes low cars."}, {"time": 804, "text": "So it's, it's both navigation, um, and seeking the fastest lane."}, {"time": 811, "text": "So it'll, it'll, it'll, you know, overtake a slow cause, um, and exit the freeway and take highway interchanges."}, {"time": 818, "text": "And, and then, uh, we have, uh, traffic lights, uh, recognition, which introduced initially as a, as a warning."}, {"time": 830, "text": "I mean, on the development version that I'm driving, the car fully, fully stops and goes at traffic lights."}, {"time": 836, "text": "So those are the steps, right?"}, {"time": 838, "text": "You've just mentioned something sort of inkling a step towards full autonomy."}, {"time": 842, "text": "What would you say are the biggest technological roadblocks to full self driving?"}, {"time": 848, "text": "Actually, I don't think, I think we just, the full self driving computer that we just, uh, that the Tesla, what we call the FSD computer, uh, that that's now in production."}, {"time": 860, "text": "Uh, so if you order, uh, any model SRX or any model three that has the full self driving package, you'll get the FSD computer."}, {"time": 869, "text": "That, that was, that's important to have enough, uh, base computation, uh, then refining the neural net and the control software, uh, which, but all of that can just be provided as an over there update."}, {"time": 913, "text": "So essentially buying a car today is an investment in the future."}, {"time": 916, "text": "You're essentially buying a car, you're buying the, I think the most profound thing is that if you buy a Tesla today, I believe you are buying an appreciating asset, not a depreciating asset."}, {"time": 930, "text": "So that's a really important statement there because if hardware is capable enough, that's the hard thing to upgrade usually."}, {"time": 937, "text": "So then the rest is a software problem."}, {"time": 941, "text": "Software has no marginal cost really."}, {"time": 944, "text": "But what's your intuition on the software side?"}, {"time": 948, "text": "How hard are the remaining steps to, to get it to where, um, you know, uh, the, the experience, uh, not just the safety, but the full experience is something that people would, uh, enjoy."}, {"time": 966, "text": "Well, I think people enjoy it very much so on, on, on the highways."}, {"time": 1009, "text": "In terms of enjoyability and something that people would, uh, would actually find a lot of use from the parking lot is a, is a really, you know, it's, it's rich of annoyance when you have to do it manually."}, {"time": 1020, "text": "So there's a lot of benefit to be gained from automation there."}, {"time": 1024, "text": "So let me start injecting the human into this discussion a little bit."}, {"time": 1028, "text": "Uh, so let's talk about, uh, the, the, the, the, the, the, the, the, the, the, about full autonomy."}, {"time": 1035, "text": "If you look at the current level four vehicles being tested on road, like Waymo and so on, they're only technically autonomous."}, {"time": 1043, "text": "They're really level two systems with just the different design philosophy, because there's always a safety driver in almost all cases and they're monitoring the system."}, {"time": 1053, "text": "Do you see Tesla's full self driving as still for a time to come requiring supervision of the human being."}, {"time": 1064, "text": "So it's capabilities are powerful enough to drive, but nevertheless requires the human to still be supervising, just like a safety driver is in a other fully autonomous vehicles."}, {"time": 1077, "text": "I think it will require detecting hands on wheel for at least, uh, six months or something like that from here."}, {"time": 1087, "text": "It really is a question of like, from a regulatory standpoint, uh, what, how much safer than a person does autopilot need to be for it to be okay to not monitor the car, you know, and, and this is a debate that one can have it."}, {"time": 1105, "text": "And then if you, but you need, you know, a large sample, a large amount of data."}, {"time": 1110, "text": "Um, so you can prove with high confidence, statistically speaking, that the car is dramatically safer than a person, um, and that adding in the person monitoring does not materially affect the safety."}, {"time": 1124, "text": "So it might need to be like two or 300% safer than a person."}, {"time": 1128, "text": "And how do you prove that incidents per mile incidents per mile crashes and fatalities, fatalities would be a factor, but there, there are just not enough fatalities to be statistically significant at scale, but there are enough."}, {"time": 1143, "text": "Crashes, you know, there are far more crashes than there are fatalities."}, {"time": 1148, "text": "So you can assess what is the probability of a crash that then there's another step which probability of injury and probability of permanent injury, the probability of death, and all of those need to be a much better than a person, uh, by at least perhaps 200%."}, {"time": 1168, "text": "And you think there's, uh, the ability to have a healthy discourse with the regulatory bodies on this topic?"}, {"time": 1176, "text": "I mean, there's no question that, um, but, um, regulators pay just disproportionate amount of attention to that, which generates press."}, {"time": 1184, "text": "This is just an objective fact."}, {"time": 1186, "text": "Um, and Tesla generates a lot of press."}, {"time": 1189, "text": "So the, you know, in the United States, this, I think almost, you know, uh, in the United States, this, I think almost 40,000 automotive deaths per year."}, {"time": 1201, "text": "Uh, but if there are four in Tesla, they'll probably receive a thousand times more press than anyone else."}, {"time": 1208, "text": "So the, the psychology of that is actually fascinating."}, {"time": 1211, "text": "I don't think we'll have enough time to talk about that, but I have to talk to you about the human side of things."}, {"time": 1216, "text": "So myself and our team at MIT recently released the paper on functional vigilance of drivers while using autopilot."}, {"time": 1223, "text": "This is work we've been doing since autopilot was first released publicly over three years ago, collecting video of driver faces and driver body."}, {"time": 1234, "text": "So I saw that you tweeted a quote from the abstract, so I can at least, uh, guess that you've glanced at it."}, {"time": 1242, "text": "Yeah, I read it."}, {"time": 1243, "text": "Can I talk you through what we found?"}, {"time": 1246, "text": "So it appears that in the data that we've collected, that drivers are maintaining functional vigilance such that we're looking at 18,000 disengagement from autopilot, 18,900 and annotating, were they able to take over control in a timely manner?"}, {"time": 1265, "text": "So they were there present looking at the road, uh, to take over control."}, {"time": 1269, "text": "So this, uh, goes against what, what many would predict from the body of literature on vigilance with automation."}, {"time": 1278, "text": "Now, the question is, do you think these results hold across the broader population?"}, {"time": 1283, "text": "So ours is just a small subset."}, {"time": 1285, "text": "Do you think, uh, one of the criticism is that, you know, there's a small minority of drivers that may be highly responsible where their vigilance decrement would increase with autopilot use?"}, {"time": 1298, "text": "I think this is all really going to be swept."}, {"time": 1300, "text": "I mean, the system's improving so much, so fast that this is going to be a mood point very soon where vigilance is like, if something's many times safer than a person, then adding a person, uh, does the, the, the effect on safety is, is limited."}, {"time": 1322, "text": "Um, and in fact, uh, it could be negative."}, {"time": 1330, "text": "So the, uh, the, so the fact that a human may, some percent of the population may, uh, exhibit a vigilance decrement will not affect overall statistics numbers of safety."}, {"time": 1341, "text": "No, in fact, I think it will become, uh, very, very quickly, maybe even towards the end of this year, but I'd say I'd be shocked if it's not next year."}, {"time": 1350, "text": "At the latest, that, um, having the person, having a human intervene will decrease safety decrease."}, {"time": 1358, "text": "It's like, imagine if you're an elevator and it used to be that there were elevator operators, um, and, and you couldn't go on an elevator by yourself and work the lever to move between floors."}, {"time": 1369, "text": "Um, and now, uh, nobody wants it an elevator operator because the automated elevator that stops the floors is much safer than the elevator operator."}, {"time": 1381, "text": "And in fact, it would be quite dangerous to have someone with a lever that can move the elevator between floors."}, {"time": 1387, "text": "So that's a, that's a really powerful statement and really interesting one."}, {"time": 1392, "text": "But I also have to ask from a user experience and from a safety perspective, one of the passions for me algorithmically is a camera based detection of, uh, of just sensing the human, but detecting what the driver is looking at, cognitive load, body pose on the computer vision side, that's a fascinating problem."}, {"time": 1410, "text": "But do you, and there's many in industry believe you have to have camera based driver monitoring."}, {"time": 1415, "text": "Do you think there could be benefit gained from driver monitoring?"}, {"time": 1419, "text": "If you have a system that's, that's at, that's at or below a human level reliability, then driver monitoring makes sense."}, {"time": 1428, "text": "But if your system is dramatically better, more likely to be better, more liable than, than a human, then drive monitoring monitoring is not just not help much."}, {"time": 1439, "text": "And, uh, like I said, you, you, just like, as an, you wouldn't want someone into like, you wouldn't want someone in the elevator, if you're in an elevator, do you really want someone with a big lever, some, some random person operating the elevator between floors?"}, {"time": 1452, "text": "I wouldn't trust that or rather have the buttons."}, {"time": 1457, "text": "You're optimistic about the pace of improvement of the system that from what you've seen with the full self driving car computer, the rate of improvement is exponential."}, {"time": 1468, "text": "So one of the other very interesting design choices early on that connects to this is the operational design domain of autopilot."}, {"time": 1478, "text": "So where autopilot is able to be turned on the, so contrast another vehicle system that we're studying is the Cadillac SuperCrew system."}, {"time": 1488, "text": "That's in terms of ODD, very constrained to particular kinds of highways, well mapped, tested, but it's much narrower than the ODD of Tesla vehicles."}, {"time": 1498, "text": "What's there's, there's pros and..."}, {"time": 1500, "text": "It's like ADD."}, {"time": 1504, "text": "That's a, that's a good line."}, {"time": 1506, "text": "Uh, what was the design decision, uh, what, in that different philosophy of thinking where there's pros and cons, what we see with, uh, a wide ODD is drive Tesla drivers are able to explore more the limitations of the system, at least early on, and they understand together with the instrument cluster display, they start to understand what are the capabilities."}, {"time": 1530, "text": "So that's a benefit."}, {"time": 1531, "text": "The con is you go, you're letting drivers use it basically anywhere."}, {"time": 1538, "text": "So anyway, that could detect lanes with confidence."}, {"time": 1541, "text": "Was there a philosophy, uh, design decisions that were challenging that were being made there or from the very beginning, was that, uh, done on purpose with intent?"}, {"time": 1554, "text": "Well, I mean, I think it's frankly, it's pretty crazy giving it, letting people drive a two ton death machine manually."}, {"time": 1561, "text": "Uh, that's crazy."}, {"time": 1563, "text": "Like, like in the future of people who are like, I can't believe anyone was just allowed to drive for one of these two ton death machines and they just drive wherever they wanted."}, {"time": 1574, "text": "Just like elevators."}, {"time": 1574, "text": "He was like, move the elevator with that lever, wherever you want."}, {"time": 1577, "text": "It can stop at halfway between floors if you want."}, {"time": 1582, "text": "It's pretty crazy."}, {"time": 1584, "text": "So it's going to seem like a mad thing in the future that people were driving cars."}, {"time": 1592, "text": "So I have a bunch of questions about the human psychology, about behavior and so on that would become that because, uh, you have faith in the AI system, uh, not faith, but, uh, the, both on the hardware side and the deep learning approach of learning from data will make it just far safer than humans."}, {"time": 1616, "text": "Recently, there are a few hackers who, uh, tricked autopilot to act in unexpected ways with adversarial examples."}, {"time": 1623, "text": "So we all know that neural network systems are very sensitive to minor disturbances to these adversarial examples on input."}, {"time": 1630, "text": "Do you think it's possible to defend against something like this for the broader, for the industry?"}, {"time": 1635, "text": "So can you elaborate on the, on the confidence behind that answer?"}, {"time": 1642, "text": "Um, well the, you know, neural net is just like a basic bunch of matrix math."}, {"time": 1647, "text": "Or you have to be like a very sophisticated, somebody who really understands neural nets and like basically reverse engineer how the matrix is being built and then create a little thing that's just exactly, um, causes the matrix math to be slightly off."}, {"time": 1664, "text": "But it's very easy to then block it, block that by, by having basically anti negative recognition."}, {"time": 1671, "text": "It's like if you, if the system sees something that looks like a matrix hack, uh, exclude it, so it's such an easy thing to do."}]}]