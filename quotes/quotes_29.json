[{"title": "Andrew Ng: Deep Learning, Education, and Real-World AI | Lex Fridman Podcast #73", "id": "0jspaMLxBig", "quotes": [{"time": 351, "text": "Or do you want to go to the office to film videos?"}, {"time": 354, "text": "And the thought of being able to help 100,000 people potentially learn machine learning, fortunately, that made me think, OK, I want to go to my office, go to my tiny little recording studio."}, {"time": 365, "text": "I would adjust my Logitech webcam, adjust my Wacom tablet, make sure my lapel mic was on, and then I would start recording often until 2 a.m. or 3 a.m."}, {"time": 375, "text": "I think unfortunately, that doesn't show that it was recorded that late at night, but it was really inspiring the thought that we could create content to help so many people learn about machine learning."}, {"time": 387, "text": "How did that feel?"}, {"time": 389, "text": "The fact that you're probably somewhat alone, maybe a couple of friends recording with a Logitech webcam and kind of going home alone at 1 or 2 a.m. at night and knowing that that's going to reach sort of thousands of people, eventually millions of people, what's that feeling like?"}, {"time": 408, "text": "I mean, is there a feeling of just satisfaction of pushing through?"}, {"time": 414, "text": "I think it's humbling."}, {"time": 415, "text": "And I wasn't thinking about what I was feeling."}, {"time": 417, "text": "I think one thing that I'm proud to say we got right from the early days was I told my whole team back then that the number one priority is to do what's best for learners, do what's best for students."}, {"time": 429, "text": "And so when I went to the recording studio, the only thing on my mind was what can I say?"}, {"time": 433, "text": "How can I design my slides?"}, {"time": 435, "text": "What I need to draw right to make these concepts as clear as possible for learners?"}, {"time": 440, "text": "I think I've seen sometimes instructors is tempting to, hey, let's talk about my work."}, {"time": 445, "text": "Maybe if I teach you about my research, someone will cite my papers a couple more times."}, {"time": 449, "text": "And I think one of the things we got right, launching the first few MOOCs and later building Coursera, was putting in place that bedrock principle of let's just do what's best for learners and forget about everything else."}, {"time": 460, "text": "And I think that that is a guiding principle turned out to be really important to the rise of the MOOC movement."}, {"time": 466, "text": "And the kind of learner you imagined in your mind is as broad as possible, as global as possible."}, {"time": 473, "text": "So really try to reach as many people interested in machine learning and AI as possible."}, {"time": 479, "text": "I really want to help anyone that had an interest in machine learning to break into the field."}, {"time": 485, "text": "And I think sometimes I've actually had people ask me, hey, why are you spending so much time explaining gradient descent?"}, {"time": 491, "text": "And my answer was, if I look at what I think the learner needs and what benefit from, I felt that having that a good understanding of the foundations coming back to the basics would put them in a better stead to then build on a long term career."}, {"time": 506, "text": "So try to consistently make decisions on that principle."}, {"time": 510, "text": "So one of the things you actually revealed to the narrow AI community at the time and to the world is that the amount of people who are actually interested in AI is much larger than we imagined."}, {"time": 523, "text": "By you teaching the class and how popular it became, it showed that, wow, this isn't just a small community of sort of people who go to NeurIPS and it's much bigger."}, {"time": 536, "text": "It's developers, it's people from all over the world."}, {"time": 539, "text": "I mean, I'm Russian, so everybody in Russia is really interested."}, {"time": 543, "text": "There's a huge number of programmers who are interested in machine learning, India, China, South America, everywhere."}, {"time": 550, "text": "There's just millions of people who are interested in machine learning."}, {"time": 553, "text": "So how big do you get a sense that the number of people is that are interested from your perspective?"}, {"time": 560, "text": "I think the number has grown over time."}, {"time": 562, "text": "I think it's one of those things that maybe it feels like it came out of nowhere, but it's an insight that building it, it took years."}, {"time": 568, "text": "It's one of those overnight successes that took years to get there."}, {"time": 573, "text": "My first foray into this type of online education was when we were filming my Stanford class and sticking the videos on YouTube and some other things."}, {"time": 580, "text": "We had uploaded the horrors and so on, but it's basically the one hour, 15 minute video that we put on YouTube."}, {"time": 587, "text": "And then we had four or five other versions of websites that I had built, most of which you would never have heard of because they reached small audiences, but that allowed me to iterate, allowed my team and me to iterate, to learn what are the ideas that work and what doesn't."}, {"time": 602, "text": "For example, one of the features I was really excited about and really proud of was build this website where multiple people could be logged into the website at the same time."}, {"time": 611, "text": "So today, if you go to a website, if you are logged in and then I want to log in, you need to log out because it's the same browser, the same computer."}, {"time": 618, "text": "But I thought, well, what if two people say you and me were watching a video together in front of a computer?"}, {"time": 624, "text": "What if a website could have you type your name and password, have me type my name and password, and then now the computer knows both of us are watching together and it gives both of us credit for anything we do as a group."}, {"time": 635, "text": "Influencers feature rolled it out in a high school in San Francisco."}, {"time": 639, "text": "We had about 20 something users."}, {"time": 642, "text": "Where's the teacher there?"}, {"time": 643, "text": "Sacred Heart Cathedral Prep, the teacher is great."}, {"time": 646, "text": "I mean, guess what?"}, {"time": 647, "text": "Zero people use this feature."}, {"time": 649, "text": "It turns out people studying online, they want to watch the videos by themselves."}, {"time": 653, "text": "So you can play back, pause at your own speed rather than in groups."}, {"time": 657, "text": "So that was one example of a tiny lesson learned out of many that allowed us to hone into the set of features."}, {"time": 664, "text": "It sounds like a brilliant feature."}, {"time": 666, "text": "So I guess the lesson to take from that is there's something that looks amazing on paper and then nobody uses it."}, {"time": 675, "text": "It doesn't actually have the impact that you think it might have."}, {"time": 678, "text": "And so, yeah, I saw that you really went through a lot of different features and a lot of ideas to arrive at Coursera, the final kind of powerful thing that showed the world that MOOCs can educate millions."}, {"time": 692, "text": "And I think with the whole machine learning movement as well, I think it didn't come out of nowhere."}, {"time": 698, "text": "Instead, what happened was as more people learn about machine learning, they will tell their friends and their friends will see how it's applicable to their work."}, {"time": 705, "text": "And then the community kept on growing."}, {"time": 708, "text": "And I think we're still growing."}, {"time": 710, "text": "I don't know in the future what percentage of all developers will be AI developers."}, {"time": 716, "text": "I could easily see it being north of 50%, right?"}, {"time": 718, "text": "Because so many AI developers broadly construed, not just people doing the machine learning modeling, but the people building infrastructure, data pipelines, all the software surrounding the core machine learning model maybe is even bigger."}, {"time": 734, "text": "I feel like today almost every software engineer has some understanding of the cloud."}, {"time": 739, "text": "Not all, but maybe this is my microcontroller developer that doesn't need to deal with the cloud."}, {"time": 744, "text": "But I feel like the vast majority of software engineers today are sort of having an appreciation of the cloud."}, {"time": 751, "text": "I think in the future, maybe we'll approach nearly 100% of all developers being in some way an AI developer or at least having an appreciation of machine learning."}, {"time": 761, "text": "And my hope is that there's this kind of effect that there's people who are not really interested in being a programmer or being into software engineering, like biologists, chemists, and physicists, even mechanical engineers, all these disciplines that are now more and more sitting on large data sets."}, {"time": 781, "text": "And here they didn't think they're interested in programming until they have this data set and they realize there's this set of machine learning tools that allow you to use the data set."}, {"time": 789, "text": "So they actually become, they learn to program and they become new programmers."}, {"time": 793, "text": "So like the, not just because you've mentioned a larger percentage of developers become machine learning people."}, {"time": 799, "text": "So it seems like more and more the kinds of people who are becoming developers is also growing significantly."}, {"time": 807, "text": "Yeah, I think once upon a time, only a small part of humanity was literate, could read and write."}, {"time": 814, "text": "And maybe you thought, maybe not everyone needs to learn to read and write."}, {"time": 817, "text": "You just go listen to a few monks read to you and maybe that was enough."}, {"time": 824, "text": "Or maybe you just need a few handful of authors to write the bestsellers and no one else needs to write."}, {"time": 830, "text": "But what we found was that by giving as many people, in some countries, almost everyone, basic literacy, it dramatically enhanced human to human communications."}, {"time": 839, "text": "And we can now write for an audience of one, such as if I send you an email or you send me an email."}, {"time": 844, "text": "I think in computing, we're still in that phase where so few people know how to code that the coders mostly have to code for relatively large audiences."}, {"time": 854, "text": "But if everyone, or most people became developers at some level, similar to how most people in developed economies are somewhat literate, I would love to see the owners of a mom and pop store be able to write a little bit of code to customize the TV display for their special this week."}, {"time": 872, "text": "And I think it will enhance human to computer communications, which is becoming more and more important today as well."}, {"time": 878, "text": "So you think it's possible that machine learning becomes kind of similar to literacy, where like you said, the owners of a mom and pop shop, is basically everybody in all walks of life would have some degree of programming capability?"}, {"time": 895, "text": "I could see society getting there."}, {"time": 898, "text": "There's one other interesting thing."}, {"time": 900, "text": "If I go talk to the mom and pop store, if I talk to a lot of people in their daily professions, I previously didn't have a good story for why they should learn to code."}, {"time": 909, "text": "We could give them some reasons."}, {"time": 911, "text": "But what I found with the rise of machine learning and data science is that I think the number of people with a concrete use for data science in their daily lives, in their jobs, may be even larger than the number of people who have concrete use for software engineering."}, {"time": 925, "text": "For example, if you run a small mom and pop store, I think if you can analyze the data about your sales, your customers, I think there's actually real value there, maybe even more than traditional software engineering."}, {"time": 937, "text": "So I find that for a lot of my friends in various professions, be it recruiters or accountants or people that work in the factories, which I deal with more and more these days, I feel if they were data scientists at some level, they could immediately use that in their work."}, {"time": 954, "text": "So I think that data science and machine learning may be an even easier entree into the developer world for a lot of people than the software engineering."}, {"time": 964, "text": "And I agree with that, but that's beautifully put."}, {"time": 966, "text": "But we live in a world where most courses and talks have slides, PowerPoint, keynote, and yet you famously often still use a marker and a whiteboard."}, {"time": 977, "text": "The simplicity of that is compelling, and for me at least, fun to watch."}, {"time": 982, "text": "So let me ask, why do you like using a marker and whiteboard, even on the biggest of stages?"}, {"time": 988, "text": "I think it depends on the concepts you want to explain."}, {"time": 992, "text": "For mathematical concepts, it's nice to build up the equation one piece at a time, and the whiteboard marker or the pen and stylus is a very easy way to build up the equation, to build up a complex concept one piece at a time while you're talking about it, and sometimes that enhances understandability."}, {"time": 1012, "text": "The downside of writing is that it's slow, and so if you want a long sentence, it's very hard to write that."}, {"time": 1017, "text": "So I think there are pros and cons, and sometimes I use slides, and sometimes I use a whiteboard or a stylus."}, {"time": 1023, "text": "The slowness of a whiteboard is also its upside, because it forces you to reduce everything to the basics."}, {"time": 1032, "text": "Some of your talks involve the whiteboard."}, {"time": 1034, "text": "I mean, you go very slowly, and you really focus on the most simple principles, and that's a beautiful, that enforces a kind of a minimalism of ideas that I think is surprising at least for me is great for education."}, {"time": 1051, "text": "Like a great talk, I think, is not one that has a lot of content."}, {"time": 1056, "text": "A great talk is one that just clearly says a few simple ideas, and I think the whiteboard somehow enforces that."}, {"time": 1066, "text": "Peter Abbeel, who's now one of the top roboticists and reinforcement learning experts in the world, was your first PhD student."}, {"time": 1074, "text": "So I bring him up just because I kind of imagine this must have been an interesting time in your life, and do you have any favorite memories of working with Peter, since you were your first student in those uncertain times, especially before deep learning really sort of blew up?"}, {"time": 1095, "text": "Any favorite memories from those times?"}, {"time": 1097, "text": "Yeah, I was really fortunate to have had Peter Abbeel as my first PhD student, and I think even my long term professional success builds on early foundations or early work that Peter was so critical to."}, {"time": 1109, "text": "So I was really grateful to him for working with me."}, {"time": 1114, "text": "What not a lot of people know is just how hard research was, and still is."}, {"time": 1122, "text": "Peter's PhD thesis was using reinforcement learning to fly helicopters."}, {"time": 1127, "text": "And so, even today, the website heli.stanford.edu, heli.stanford.edu is still up."}, {"time": 1133, "text": "You can watch videos of us using reinforcement learning to make a helicopter fly upside down, fly loose roses, so it's cool."}, {"time": 1139, "text": "It's one of the most incredible robotics videos ever, so people should watch it."}, {"time": 1143, "text": "Oh yeah, thank you."}, {"time": 1144, "text": "It's inspiring."}, {"time": 1145, "text": "That's from like 2008 or seven or six, like that range."}, {"time": 1150, "text": "Yeah, something like that."}, {"time": 1151, "text": "Yeah, so it was over 10 years old."}, {"time": 1152, "text": "That was really inspiring to a lot of people, yeah."}, {"time": 1155, "text": "What not many people see is how hard it was."}, {"time": 1158, "text": "So Peter and Adam Coase and Morgan Quigley and I were working on various versions of the helicopter, and a lot of things did not work."}, {"time": 1167, "text": "For example, it turns out one of the hardest problems we had was when the helicopter's flying around upside down, doing stunts, how do you figure out the position?"}, {"time": 1174, "text": "How do you localize the helicopter?"}, {"time": 1176, "text": "So we wanted to try all sorts of things."}, {"time": 1178, "text": "Having one GPS unit doesn't work because you're flying upside down, the GPS unit's facing down, so you can't see the satellites."}, {"time": 1184, "text": "So we experimented trying to have two GPS units, one facing up, one facing down."}, {"time": 1189, "text": "So if you flip over, that didn't work because the downward facing one couldn't synchronize if you're flipping quickly."}, {"time": 1195, "text": "Morgan Quigley was exploring this crazy, complicated configuration of specialized hardware to interpret GPS signals."}, {"time": 1203, "text": "Looking at the FPG is completely insane."}, {"time": 1206, "text": "Spent about a year working on that, didn't work."}, {"time": 1209, "text": "So I remember Peter, great guy, him and me, sitting down in my office looking at some of the latest things we had tried that didn't work and saying, done it, what now?"}, {"time": 1222, "text": "Because we tried so many things and it just didn't work."}, {"time": 1225, "text": "In the end, what we did, and Adam Coles was crucial to this, was put cameras on the ground and use cameras on the ground to localize the helicopter."}, {"time": 1235, "text": "And that solved the localization problem so that we could then focus on the reinforcement learning and inverse reinforcement learning techniques so it didn't actually make the helicopter fly."}, {"time": 1246, "text": "And I'm reminded, when I was doing this work at Stanford, around that time, there was a lot of reinforcement learning theoretical papers, but not a lot of practical applications."}, {"time": 1258, "text": "So the autonomous helicopter work for flying helicopters was one of the few practical applications of reinforcement learning at the time, which caused it to become pretty well known."}, {"time": 1270, "text": "I feel like we might have almost come full circle with today."}, {"time": 1273, "text": "There's so much buzz, so much hype, so much excitement about reinforcement learning."}, {"time": 1277, "text": "But again, we're hunting for more applications of all of these great ideas that David Kuhnke has come up with."}, {"time": 1283, "text": "What was the drive sort of in the face of the fact that most people are doing theoretical work?"}, {"time": 1290, "text": "What motivates you in the uncertainty and the challenges to get the helicopter sort of to do the applied work, to get the actual system to work?"}, {"time": 1299, "text": "Yeah, in the face of fear, uncertainty, sort of the setbacks that you mentioned for localization."}, {"time": 1305, "text": "I like stuff that works."}, {"time": 1308, "text": "So like, it's back to the shredder."}, {"time": 1310, "text": "You know, I like theory, but when I work on theory myself, and this is personal taste, I'm not saying anyone else should do what I do."}, {"time": 1318, "text": "But when I work on theory, I personally enjoy it more if I feel that the work I do will influence people, have positive impact, or help someone."}, {"time": 1330, "text": "I remember when many years ago, I was speaking with a mathematics professor, and it kind of just said, hey, why do you do what you do?"}, {"time": 1338, "text": "It kind of just said, hey, why do you do what you do?"}, {"time": 1341, "text": "And then he said, he had stars in his eyes when he answered."}, {"time": 1345, "text": "And this mathematician, not from Stanford, different university, he said, I do what I do because it helps me to discover truth and beauty in the universe."}, {"time": 1356, "text": "He had stars in his eyes when he said that."}, {"time": 1358, "text": "And I thought, that's great."}, {"time": 1361, "text": "I don't want to do that."}, {"time": 1362, "text": "I think it's great that someone does that, fully support the people that do it, a lot of respect for people that do that."}, {"time": 1366, "text": "But I am more motivated when I can see a line to how the work that my teams and I are doing helps people."}, {"time": 1376, "text": "The world needs all sorts of people."}, {"time": 1378, "text": "I'm just one type."}, {"time": 1379, "text": "I don't think everyone should do things the same way as I do."}, {"time": 1382, "text": "But when I delve into either theory or practice, if I personally have conviction that here's a pathway to help people, I find that more satisfying to have that conviction."}, {"time": 1395, "text": "That's your path."}, {"time": 1397, "text": "You were a proponent of deep learning before it gained widespread acceptance."}, {"time": 1403, "text": "What did you see in this field that gave you confidence?"}, {"time": 1406, "text": "What was your thinking process like in that first decade of the, I don't know what that's called, 2000s, the aughts?"}, {"time": 1413, "text": "Yeah, I can tell you the thing we got wrong and the thing we got right."}, {"time": 1416, "text": "The thing we really got wrong was the importance of, the early importance of unsupervised learning."}, {"time": 1422, "text": "So early days of Google Brain, we put a lot of effort into unsupervised learning rather than supervised learning."}, {"time": 1429, "text": "And there was this argument, I think it was around 2005 after NeurIPS, at that time called NIPS, but now NeurIPS had ended."}, {"time": 1438, "text": "And Jeff Hinton and I were sitting in the cafeteria outside the conference."}, {"time": 1442, "text": "We had lunch, we were just chatting."}, {"time": 1444, "text": "And Jeff pulled up this napkin."}, {"time": 1445, "text": "He started sketching this argument on a napkin."}, {"time": 1447, "text": "It was very compelling, as I'll repeat it."}, {"time": 1450, "text": "Human brain has about a hundred trillion."}, {"time": 1452, "text": "So there's 10 to the 14 synaptic connections."}, {"time": 1456, "text": "You will live for about 10 to the nine seconds."}, {"time": 1459, "text": "That's 30 years."}, {"time": 1460, "text": "You actually live for two by 10 to the nine, maybe three by 10 to the nine seconds."}, {"time": 1464, "text": "So just let's say 10 to the nine."}, {"time": 1466, "text": "So if each synaptic connection, each weight in your brain's neural network has just a one bit parameter, that's 10 to the 14 bits you need to learn in up to 10 to the nine seconds."}, {"time": 1478, "text": "10 to the nine seconds of your life."}, {"time": 1481, "text": "So via this simple argument, which is a lot of problems, it's very simplified."}, {"time": 1485, "text": "That's 10 to the five bits per second you need to learn in your life."}, {"time": 1489, "text": "And I have a one year old daughter."}, {"time": 1492, "text": "I am not pointing out 10 to five bits per second of labels to her."}, {"time": 1499, "text": "And I think I'm a very loving parent, but I'm just not gonna do that."}, {"time": 1504, "text": "So from this very crude, definitely problematic argument, there's just no way that most of what we know is through supervised learning."}, {"time": 1513, "text": "But where you get so many bits of information is from sucking in images, audio, those experiences in the world."}, {"time": 1519, "text": "And so that argument, and there are a lot of known forces argument you should go into, really convinced me that there's a lot of power to unsupervised learning."}, {"time": 1529, "text": "So that was the part that we actually maybe got wrong."}, {"time": 1532, "text": "I still think unsupervised learning is really important, but in the early days, 10, 15 years ago, a lot of us thought that was the path forward."}, {"time": 1541, "text": "Oh, so you're saying that that perhaps was the wrong intuition for the time."}, {"time": 1545, "text": "For the time, that was the part we got wrong."}, {"time": 1548, "text": "The part we got right was the importance of scale."}, {"time": 1551, "text": "So Adam Coates, another wonderful person, fortunate to have worked with him, he was in my group at Stanford at the time and Adam had run these experiments at Stanford showing that the bigger we train a learning algorithm, the better its performance."}, {"time": 1567, "text": "And it was based on that."}, {"time": 1569, "text": "There was a graph that Adam generated where the X axis, Y axis lines going up into the right."}, {"time": 1575, "text": "So the bigger you make this thing, the better its performance accuracy is the vertical axis."}, {"time": 1580, "text": "So it's really based on that chart that Adam generated that he gave me the conviction that you could scale these models way bigger than what we could on a few CPUs, which is where we had at Stanford that we could get even better results."}, {"time": 1591, "text": "And it was really based on that one figure that Adam generated that gave me the conviction to go with Sebastian Thrun to pitch starting a project at Google, which became the Google Brain project."}, {"time": 1603, "text": "The Brain, you go find a Google Brain."}, {"time": 1605, "text": "And there the intuition was scale will bring performance for the system."}, {"time": 1612, "text": "So we should chase a larger and larger scale."}, {"time": 1615, "text": "And I think people don't realize how groundbreaking of it."}, {"time": 1620, "text": "It's simple, but it's a groundbreaking idea that bigger data sets will result in better performance."}, {"time": 1625, "text": "It was controversial at the time."}, {"time": 1628, "text": "Some of my well meaning friends, senior people in the machine learning community, I won't name, but some of whom we know, my well meaning friends came and were trying to give me friendly, I was like, hey, Andrew, why are you doing this?"}, {"time": 1640, "text": "This is crazy."}, {"time": 1641, "text": "It's in the near natural architecture."}, {"time": 1643, "text": "Look at these architectures of building."}, {"time": 1644, "text": "You just want to go for scale?"}, {"time": 1645, "text": "Like this is a bad career move."}, {"time": 1647, "text": "So my well meaning friends, some of them were trying to talk me out of it."}, {"time": 1653, "text": "But I find that if you want to make a breakthrough, you sometimes have to have conviction and do something before it's popular, since that lets you have a bigger impact."}, {"time": 1663, "text": "Let me ask you just a small tangent on that topic."}, {"time": 1665, "text": "I find myself arguing with people saying that greater scale, especially in the context of active learning, so very carefully selecting the data set, but growing the scale of the data set is going to lead to even further breakthroughs in deep learning."}, {"time": 1682, "text": "And there's currently pushback at that idea that larger data sets are no longer, so you want to increase the efficiency of learning."}, {"time": 1691, "text": "You want to make better learning mechanisms."}, {"time": 1693, "text": "And I personally believe that bigger data sets will still, with the same learning methods we have now, will result in better performance."}, {"time": 1701, "text": "What's your intuition at this time on this dual side?"}, {"time": 1707, "text": "Do we need to come up with better architectures for learning or can we just get bigger, better data sets that will improve performance?"}, {"time": 1717, "text": "I think both are important and it's also problem dependent."}, {"time": 1720, "text": "So for a few data sets, we may be approaching a Bayes error rate or approaching or surpassing human level performance and then there's that theoretical ceiling that we will never surpass, so Bayes error rate."}, {"time": 1734, "text": "But then I think there are plenty of problems where we're still quite far from either human level performance or from Bayes error rate and bigger data sets with neural networks without further algorithmic innovation will be sufficient to take us further."}, {"time": 1750, "text": "But on the flip side, if we look at the recent breakthroughs using transforming networks or language models, it was a combination of novel architecture but also scale had a lot to do with it."}, {"time": 1760, "text": "If we look at what happened with GP2 and BERTZ, I think scale was a large part of the story."}, {"time": 1766, "text": "Yeah, that's not often talked about is the scale of the data set it was trained on and the quality of the data set because there's some, so it was like reddit threads that had, they were operated highly."}, {"time": 1779, "text": "So there's already some weak supervision on a very large data set that people don't often talk about, right?"}, {"time": 1787, "text": "I find that today we have maturing processes to managing code, things like Git, right?"}, {"time": 1793, "text": "Version control."}, {"time": 1794, "text": "It took us a long time to evolve the good processes."}, {"time": 1798, "text": "I remember when my friends and I were emailing each other C++ files in email, but then we had, was it CVS or version Git?"}, {"time": 1805, "text": "Maybe something else in the future."}, {"time": 1807, "text": "We're very mature in terms of tools for managing data and think about the clean data and how to solve down very hot, messy data problems."}, {"time": 1815, "text": "I think there's a lot of innovation there to be had still."}, {"time": 1817, "text": "I love the idea that you were versioning through email."}, {"time": 1821, "text": "I'll give you one example."}, {"time": 1823, "text": "When we work with manufacturing companies, it's not at all uncommon for there to be multiple labels that disagree with each other, right?"}, {"time": 1836, "text": "And so we would do the work in visual inspection."}, {"time": 1840, "text": "We will take, say, a plastic part and show it to one inspector and the inspector, sometimes very opinionated, they'll go, clearly, that's a defect."}, {"time": 1848, "text": "This scratch, unacceptable."}, {"time": 1849, "text": "Gotta reject this part."}, {"time": 1851, "text": "Take the same part to different inspector, different, very opinionated."}, {"time": 1854, "text": "Clearly, the scratch is small."}, {"time": 1856, "text": "Don't throw it away."}, {"time": 1857, "text": "You're gonna make us, you know."}, {"time": 1859, "text": "And then sometimes you take the same plastic part, show it to the same inspector in the afternoon, I suppose, in the morning, and very opinionated go, in the morning, they say, clearly, it's okay."}, {"time": 1868, "text": "In the afternoon, equally confident."}, {"time": 1870, "text": "Clearly, this is a defect."}, {"time": 1872, "text": "And so what is an AI team supposed to do if sometimes even one person doesn't agree with himself or herself in the span of a day?"}, {"time": 1880, "text": "So I think these are the types of very practical, very messy data problems that my teams wrestle with."}, {"time": 1890, "text": "In the case of large consumer internet companies where you have a billion users, you have a lot of data."}, {"time": 1895, "text": "You don't worry about it."}, {"time": 1896, "text": "Just take the average."}, {"time": 1897, "text": "It kind of works."}, {"time": 1898, "text": "But in a case of other industry settings, we don't have big data."}, {"time": 1902, "text": "If just a small data, very small data sets, maybe around 100 defective parts or 100 examples of a defect."}, {"time": 1909, "text": "If you have only 100 examples, these little labeling errors, if 10 of your 100 labels are wrong, that actually is 10% of your data set has a big impact."}, {"time": 1918, "text": "So how do you clean this up?"}, {"time": 1919, "text": "What are you supposed to do?"}, {"time": 1921, "text": "This is an example of the types of things that my teams, this is a landing AI example, are wrestling with to deal with small data, which comes up all the time once you're outside consumer internet."}, {"time": 1933, "text": "So then you invest more effort and time in thinking about the actual labeling process."}, {"time": 1938, "text": "What are the labels?"}, {"time": 1939, "text": "What are the how are disagreements resolved and all those kinds of like pragmatic real world problems."}, {"time": 1945, "text": "That's a fascinating space."}, {"time": 1947, "text": "Yeah, I find that actually when I'm teaching at Stanford, I increasingly encourage students at Stanford to try to find their own project for the end of term project, rather than just downloading someone else's nicely clean data set."}, {"time": 1961, "text": "It's actually much harder if you need to go and define your own problem and find your own data set, rather than you go to one of the several good websites, very good websites with clean scoped data sets that you could just work on."}, {"time": 1975, "text": "You're now running three efforts, the AI Fund, Landing AI, and deeplearning.ai."}, {"time": 1982, "text": "As you've said, the AI Fund is involved in creating new companies from scratch."}, {"time": 1986, "text": "Landing AI is involved in helping already established companies do AI and deeplearning.ai is for education of everyone else or of individuals interested in getting into the field and excelling in it."}, {"time": 1999, "text": "So let's perhaps talk about each of these areas."}, {"time": 2002, "text": "First, deeplearning.ai."}, {"time": 2005, "text": "How, the basic question, how does a person interested in deep learning get started in the field?"}, {"time": 2012, "text": "Deep learning.ai is working to create courses to help people break into AI."}, {"time": 2017, "text": "So my machine learning course that I taught through Stanford is one of the most popular courses on Coursera."}, {"time": 2025, "text": "To this day, it's probably one of the courses, sort of, if I asked somebody, how did you get into machine learning or how did you fall in love with machine learning or would get you interested, it always goes back to Andrew Ng at some point."}, {"time": 2038, "text": "I see, yeah, I'm sure."}, {"time": 2040, "text": "You've influenced, the amount of people you've influenced is ridiculous."}, {"time": 2043, "text": "So for that, I'm sure I speak for a lot of people say big thank you."}, {"time": 2047, "text": "No, yeah, thank you."}, {"time": 2049, "text": "I was once reading a news article, I think it was tech review and I'm gonna mess up the statistic, but I remember reading an article that said something like one third of all programmers are self taught."}, {"time": 2063, "text": "I may have the number one third, around me was two thirds, but when I read that article, I thought this doesn't make sense."}, {"time": 2068, "text": "Everyone is self taught."}, {"time": 2069, "text": "So, cause you teach yourself."}, {"time": 2071, "text": "I don't teach people."}, {"time": 2072, "text": "That's well put."}, {"time": 2073, "text": "Yeah, so how does one get started in deep learning and where does deeplearning.ai fit into that?"}, {"time": 2080, "text": "So the deep learning specialization offered by deeplearning.ai is I think it was Coursera's top specialization."}, {"time": 2089, "text": "It might still be."}, {"time": 2090, "text": "So it's a very popular way for people to take that specialization to learn about everything from neural networks to how to tune in your network to what is a ConvNet to what is a RNN or a sequence model or what is an attention model."}, {"time": 2105, "text": "And so the deep learning specialization steps everyone through those algorithms so you deeply understand it and can implement it and use it for whatever application."}, {"time": 2115, "text": "From the very beginning."}, {"time": 2116, "text": "So what would you say are the prerequisites for somebody to take the deep learning specialization in terms of maybe math or programming background?"}, {"time": 2125, "text": "Yeah, need to understand basic programming since there are programming exercises in Python and the math prereq is quite basic."}, {"time": 2134, "text": "So no calculus is needed."}, {"time": 2135, "text": "If you know calculus is great, you get better intuitions but deliberately try to teach that specialization without requiring calculus."}, {"time": 2142, "text": "So I think high school math would be sufficient."}, {"time": 2147, "text": "If you know how to multiply two matrices, I think that's great."}, {"time": 2152, "text": "So a little basic linear algebra is great."}, {"time": 2154, "text": "Basic linear algebra, even very, very basic linear algebra in some programming."}, {"time": 2180, "text": "Could you briefly mention some of the key concepts in deep learning that students should learn that you envision them learning in the first few months in the first year or so?"}, {"time": 2189, "text": "So if you take the deep learning specialization, you learn the foundations of what is a neural network."}, {"time": 2194, "text": "How do you build up a neural network from a single logistic unit to a stack of layers to different activation functions."}, {"time": 2203, "text": "You learn how to train the neural networks."}, {"time": 2204, "text": "One thing I'm very proud of in that specialization is we go through a lot of practical knowhow of how to actually make these things work."}, {"time": 2212, "text": "So what are the differences between different optimization algorithms?"}, {"time": 2215, "text": "What do you do if the algorithm overfits or how do you tell if the algorithm is overfitting?"}, {"time": 2219, "text": "When do you collect more data?"}, {"time": 2220, "text": "When should you not bother to collect more data?"}, {"time": 2223, "text": "I find that even today, unfortunately, there are engineers that will spend six months trying to pursue a particular direction such as collect more data because we heard more data is valuable but sometimes you could run some tests and could have figured out six months earlier that for this particular problem, collecting more data isn't going to cut it."}, {"time": 2243, "text": "So just don't spend six months collecting more data."}, {"time": 2246, "text": "Spend your time modifying the architecture or trying something else."}, {"time": 2250, "text": "So go through a lot of the practical knowhow so that when someone, when you take the deep learning specialization, you have those skills to be very efficient in how you build these networks."}, {"time": 2261, "text": "So dive right in to play with the network, to train it, to do the inference on a particular data set, to build intuition about it without building it up too big to where you spend, like you said, six months learning, building up your big project without building any intuition of a small aspect of the data that could already tell you everything you need to know about that data."}, {"time": 2285, "text": "Yes, and also the systematic frameworks of thinking for how to go about building practical machine learning."}, {"time": 2292, "text": "Maybe to make an analogy, when we learn to code, we have to learn the syntax of some programming language, right?"}, {"time": 2297, "text": "Be it Python or C++ or Octave or whatever."}, {"time": 2301, "text": "But the equally important or maybe even more important part of coding is to understand how to string together these lines of code into coherent things."}, {"time": 2308, "text": "So when should you put something in a function column?"}, {"time": 2311, "text": "When should you not?"}, {"time": 2312, "text": "How do you think about abstraction?"}, {"time": 2314, "text": "So those frameworks are what makes a programmer efficient even more than understanding the syntax."}, {"time": 2321, "text": "I remember when I was an undergrad at Carnegie Mellon, one of my friends would debug their code by first trying to compile it, and then it was C++ code."}, {"time": 2330, "text": "And then every line in the syntax error, they want to get rid of the syntax errors as quickly as possible."}, {"time": 2336, "text": "Well, they would delete every single line of code with a syntax error."}, {"time": 2339, "text": "So really efficient for getting rid of syntax errors for horrible debugging errors."}, {"time": 2342, "text": "So I think we learn how to debug."}, {"time": 2345, "text": "And I think in machine learning, the way you debug a machine learning program is very different than the way you do binary search or whatever, or use a debugger, trace through the code in traditional software engineering."}, {"time": 2357, "text": "So it's an evolving discipline, but I find that the people that are really good at debugging machine learning algorithms are easily 10x, maybe 100x faster at getting something to work."}, {"time": 2368, "text": "And the basic process of debugging is, so the bug in this case, why isn't this thing learning, improving, sort of going into the questions of overfitting and all those kinds of things?"}, {"time": 2380, "text": "That's the logical space that the debugging is happening in with neural networks."}, {"time": 2386, "text": "Yeah, often the question is, why doesn't it work yet?"}, {"time": 2390, "text": "Or can I expect it to eventually work?"}, {"time": 2392, "text": "And what are the things I could try?"}, {"time": 2394, "text": "Change the architecture, more data, more regularization, different optimization algorithm, different types of data."}, {"time": 2401, "text": "So to answer those questions systematically, so that you don't spend six months hitting down the blind alley before someone comes and says, why did you spend six months doing this?"}, {"time": 2412, "text": "What concepts in deep learning do you think students struggle the most with?"}, {"time": 2416, "text": "Or sort of is the biggest challenge for them was to get over that hill."}, {"time": 2423, "text": "It hooks them and it inspires them and they really get it."}, {"time": 2428, "text": "Similar to learning mathematics, I think one of the challenges of deep learning is that there are a lot of concepts that build on top of each other."}, {"time": 2436, "text": "If you ask me what's hard about mathematics, I have a hard time pinpointing one thing."}, {"time": 2440, "text": "Is it addition, subtraction?"}, {"time": 2442, "text": "Is it a carry?"}, {"time": 2443, "text": "Is it multiplication?"}, {"time": 2444, "text": "There's just a lot of stuff."}, {"time": 2445, "text": "I think one of the challenges of learning math and of learning certain technical fields is that there are a lot of concepts and if you miss a concept, then you're kind of missing the prerequisite for something that comes later."}, {"time": 2458, "text": "So in the deep learning specialization, try to break down the concepts to maximize the odds of each component being understandable."}, {"time": 2466, "text": "So when you move on to the more advanced thing, we learn confidence, hopefully you have enough intuitions from the earlier sections to then understand why we structure confidence in a certain way and then eventually why we built RNNs and LSTMs or attention models in a certain way building on top of the earlier concepts."}, {"time": 2487, "text": "Actually, I'm curious, you do a lot of teaching as well."}, {"time": 2490, "text": "Do you have a favorite, this is the hard concept moment in your teaching?"}, {"time": 2499, "text": "Well, I don't think anyone's ever turned the interview on me."}, {"time": 2503, "text": "I'm glad you get first."}, {"time": 2506, "text": "I think that's a really good question."}, {"time": 2508, "text": "Yeah, it's really hard to capture the moment when they struggle."}, {"time": 2511, "text": "I think you put it really eloquently."}, {"time": 2513, "text": "I do think there's moments that are like aha moments that really inspire people."}, {"time": 2519, "text": "I think for some reason, reinforcement learning, especially deep reinforcement learning is a really great way to really inspire people and get what the use of neural networks can do."}, {"time": 2533, "text": "Even though neural networks really are just a part of the deep RL framework, but it's a really nice way to paint the entirety of the picture of a neural network being able to learn from scratch, knowing nothing and explore the world and pick up lessons."}, {"time": 2549, "text": "I find that a lot of the aha moments happen when you use deep RL to teach people about neural networks, which is counterintuitive."}, {"time": 2557, "text": "I find like a lot of the inspired sort of fire in people's passion, people's eyes, it comes from the RL world."}, {"time": 2564, "text": "Do you find reinforcement learning to be a useful part of the teaching process or no?"}, {"time": 2571, "text": "I still teach reinforcement learning in one of my Stanford classes and my PhD thesis was on reinforcement learning."}, {"time": 2577, "text": "So I clearly loved a few."}, {"time": 2579, "text": "I find that if I'm trying to teach students the most useful techniques for them to use today, I end up shrinking the amount of time I talk about reinforcement learning."}, {"time": 2588, "text": "It's not what's working today."}, {"time": 2590, "text": "Now, our world changes so fast."}, {"time": 2592, "text": "Maybe this will be totally different in a couple of years."}, {"time": 2595, "text": "But I think we need a couple more things for reinforcement learning to get there."}, {"time": 2600, "text": "One of my teams is looking to reinforcement learning for some robotic control tasks."}, {"time": 2603, "text": "So I see the applications, but if you look at it as a percentage of all of the impact of the types of things we do, it's at least today outside of playing video games, right?"}, {"time": 2615, "text": "In a few of the games, the scope."}, {"time": 2618, "text": "Actually, at NeurIPS, a bunch of us were standing around saying, hey, what's your best example of an actual deploy reinforcement learning application?"}, {"time": 2625, "text": "And among like senior machine learning researchers, right?"}, {"time": 2629, "text": "And again, there are some emerging ones, but there are not that many great examples."}, {"time": 2635, "text": "I think you're absolutely right."}, {"time": 2638, "text": "The sad thing is there hasn't been a big impactful real world application of reinforcement learning."}, {"time": 2644, "text": "I think its biggest impact to me has been in the toy domain, in the game domain, in the small example."}, {"time": 2651, "text": "That's what I mean for educational purpose."}, {"time": 2653, "text": "It seems to be a fun thing to explore in your networks with."}, {"time": 2685, "text": "The amount of fun I've seen people have with reinforcement learning has been great, but not in the applied impact in the real world setting."}, {"time": 2692, "text": "So it's a trade off, how much impact you want to have versus how much fun you want to have."}, {"time": 2696, "text": "Yeah, that's really cool."}, {"time": 2698, "text": "And I feel like the world actually needs all sorts."}, {"time": 2701, "text": "Even within machine learning, I feel like deep learning is so exciting, but the AI team shouldn't just use deep learning."}, {"time": 2708, "text": "I find that my teams use a portfolio of tools."}, {"time": 2711, "text": "And maybe that's not the exciting thing to say, but some days we use a neural net, some days we use a PCA."}, {"time": 2719, "text": "Actually, the other day, I was sitting down with my team looking at PCA residuals, trying to figure out what's going on with PCA applied to manufacturing problem."}, {"time": 2725, "text": "And some days we use a probabilistic graphical model, some days we use a knowledge draft, which is one of the things that has tremendous industry impact."}, {"time": 2733, "text": "But the amount of chatter about knowledge drafts in academia is really thin compared to the actual real world impact."}, {"time": 2739, "text": "So I think reinforcement learning should be in that portfolio."}, {"time": 2742, "text": "And then it's about balancing how much we teach all of these things."}, {"time": 2745, "text": "And the world should have diverse skills."}, {"time": 2747, "text": "It'd be sad if everyone just learned one narrow thing."}, {"time": 2751, "text": "Yeah, the diverse skill help you discover the right tool for the job."}, {"time": 2754, "text": "What is the most beautiful, surprising or inspiring idea in deep learning to you?"}, {"time": 2760, "text": "Something that captivated your imagination."}, {"time": 2764, "text": "Is it the scale that could be, the performance that could be achieved with scale?"}, {"time": 2768, "text": "Or is there other ideas?"}, {"time": 2771, "text": "I think that if my only job was being an academic researcher, if an unlimited budget and didn't have to worry about short term impact and only focus on long term impact, I'd probably spend all my time doing research on unsupervised learning."}, {"time": 2787, "text": "I still think unsupervised learning is a beautiful idea."}, {"time": 2791, "text": "At both this past NeurIPS and ICML, I was attending workshops or listening to various talks about self supervised learning, which is one vertical segment maybe of unsupervised learning that I'm excited about."}, {"time": 2805, "text": "Maybe just to summarize the idea, I guess you know the idea about describing fleet."}, {"time": 2808, "text": "No, please."}]}]