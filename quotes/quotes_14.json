[{"title": "Christof Koch: Consciousness | Lex Fridman Podcast #2", "id": "piHkfmeU7Wo", "quotes": [{"time": 324, "text": "Some people call it subjective feeling."}, {"time": 326, "text": "Some people call it phenomenology."}, {"time": 329, "text": "Some people call it qualia of the philosopher."}, {"time": 331, "text": "But they all denote the same thing."}, {"time": 332, "text": "It feels like something in the famous word of the philosopher Thomas Nagel."}, {"time": 337, "text": "It feels like something to be a bat or to be an American or to be angry or to be sad or to be in love or to have pain."}, {"time": 349, "text": "And that is what experience is, any possible experience."}, {"time": 353, "text": "Could be as mundane as just sitting in a chair."}, {"time": 355, "text": "Could be as exalted as having a mystical moment in deep meditation."}, {"time": 361, "text": "Those are just different forms of experiences."}, {"time": 363, "text": "Experience."}, {"time": 364, "text": "So if you were to sit down with maybe the next, skip a couple generations, of IBM Watson, something that won Jeopardy, what is the gap, I guess the question is, between Watson, that might be much smarter than you, than us, than any human alive, but may not have experience, what is the gap?"}, {"time": 387, "text": "Well, so that's a big, big question."}, {"time": 390, "text": "That's occupied people for the last, certainly last 50 years since we, you know, since the advent, the birth of computers."}, {"time": 399, "text": "That's a question Alan Turing tried to answer."}, {"time": 400, "text": "And of course he did it in this indirect way by proposing a test, an operational test."}, {"time": 406, "text": "But that's not really, that's, you know, he tried to get at what does it mean for a person to think, and then he had this test, right?"}, {"time": 412, "text": "You lock them away, and then you have a communication with them, and then you try to guess after a while whether that is a person or whether it's a computer system."}, {"time": 420, "text": "There's no question that now or very soon, you know, Alexa or Siri or, you know, Google now will pass this test, right?"}, {"time": 427, "text": "And you can game it, but you know, ultimately, certainly in your generation, there will be machines that will speak with complete poise that will remember everything you ever said."}, {"time": 436, "text": "They'll remember every email you ever had, like Samantha, remember in the movie Her?"}, {"time": 442, "text": "There's no question it's going to happen."}, {"time": 444, "text": "But of course, the key question is, does it feel like anything to be Samantha in the movie Her?"}, {"time": 449, "text": "Or does it feel like anything to be Watson?"}, {"time": 452, "text": "And there one has to very, very strongly think there are two different concepts here that we co mingle."}, {"time": 459, "text": "There is the concept of intelligence, natural or artificial, and there is a concept of consciousness, of experience, natural or artificial."}, {"time": 467, "text": "Those are very, very different things."}, {"time": 469, "text": "Now, historically, we associate consciousness with intelligence."}, {"time": 474, "text": "Because we live in a world, leaving aside computers, of natural selection, where we're surrounded by creatures, either our own kin that are less or more intelligent, or we go across species."}, {"time": 486, "text": "Some are more adapted to a particular environment."}, {"time": 488, "text": "Others are less adapted, whether it's a whale or dog, or you go talk about a paramecium or a little worm."}, {"time": 495, "text": "And we see the complexity of the nervous system goes from one cell to specialized cells, to a worm that has three nets, that has 30 percent of its cells are nerve cells, to creature like us or like a blue whale that has 100 billion, even more nerve cells."}, {"time": 510, "text": "And so based on behavioral evidence and based on the underlying neuroscience, we believe that as these creatures become more complex, they are better adapted to their particular ecological niche, and they become more conscious, partly because their brain grows."}, {"time": 526, "text": "And we believe consciousness, unlike the ancient, ancient people thought most, almost every culture thought that consciousness with intelligence has to do with your heart."}, {"time": 535, "text": "And you still see that today."}, {"time": 536, "text": "You see, honey, I love you with all my heart."}, {"time": 539, "text": "But what you should actually say is, no, honey, I love you with all my lateral hypothalamus."}, {"time": 544, "text": "And for Valentine's Day, you should give your sweetheart, you know, hypothalamus, a piece of chocolate and not a heart shaped chocolate."}, {"time": 551, "text": "Anyway, so we still have this language, but now we believe it's a brain."}, {"time": 554, "text": "And so we see brains of different complexity and we think, well, they have different levels of consciousness."}, {"time": 559, "text": "They're capable of different experiences."}, {"time": 565, "text": "But now we confront the world where we know where we're beginning to engineer intelligence."}, {"time": 572, "text": "And it's radical unclear whether the intelligence we're engineering has anything to do with consciousness and whether it can experience anything."}, {"time": 580, "text": "Because fundamentally, what's the difference?"}, {"time": 582, "text": "Intelligence is about function."}, {"time": 584, "text": "Intelligence no matter exactly how you define it, sort of adaptation to new environments, being able to learn and quickly understand, you know, the setup of this and what's going on and who are the actors and what's going to happen next."}, {"time": 595, "text": "That's all about function."}, {"time": 598, "text": "Consciousness is not about function."}, {"time": 600, "text": "Consciousness is about being."}, {"time": 602, "text": "It's in some sense much fundamental."}, {"time": 605, "text": "You can see this in several cases."}, {"time": 608, "text": "You can see it, for instance, in the case of the clinic."}, {"time": 612, "text": "When you're dealing with patients who are, let's say, had a stroke or had were in traffic accident, et cetera, they're pretty much immobile."}, {"time": 620, "text": "Terri Schiavo, you may have heard historically, she was a person here in the 90s in Florida."}, {"time": 626, "text": "Her heart stood still."}, {"time": 627, "text": "She was reanimated."}, {"time": 628, "text": "And then for the next 14 years, she was what's called in a vegetative state."}, {"time": 631, "text": "So there are thousands of people in a vegetative state."}, {"time": 634, "text": "So they're, you know, they're, you know, they're like this."}, {"time": 636, "text": "Occasionally, they open their eyes for two, three, four, five, six, eight hours, and then close their eyes."}, {"time": 641, "text": "They have sleep wake cycle."}, {"time": 642, "text": "Occasionally, they have behaviors."}, {"time": 644, "text": "They do like, you know, but there's no way that you can establish a lawful relationship between what you say or the doctor says or the mom says and what the patient does."}, {"time": 655, "text": "So there isn't any behavior, yet in some of these people, there is still experience."}, {"time": 663, "text": "You can design and build brain machine interfaces where you can see there's still experience something."}, {"time": 669, "text": "And of course, these cases of locked in state, there's this famous book called The Diving Bell and the Butterfly, where you had an editor, a French editor, he had a stroke in the brainstem, unable to move except his vertical eyes, eye movement."}, {"time": 682, "text": "He could just move his eyes up and down."}, {"time": 685, "text": "And he dictated an entire book."}, {"time": 687, "text": "And some people even lose this at the end."}, {"time": 690, "text": "All the evidence seems to suggest that they're still in there."}, {"time": 693, "text": "In this case, you have no behavior, you have consciousness."}, {"time": 697, "text": "Second case is tonight, like all of us, you're going to go to sleep, close your eyes, you go to sleep, you will wake up inside your sleeping body, and you will have conscious experiences."}, {"time": 707, "text": "They are different from everyday experience."}, {"time": 709, "text": "You might fly, you might not be surprised that you're flying, you might meet a long dead pet, childhood dog, and you're not surprised that you're meeting them."}, {"time": 718, "text": "But you have conscious experience of love, of hate, they can be very emotional."}, {"time": 722, "text": "Your body during this state, typically it's REM state, sends an active signal to your motor neurons to paralyze you."}, {"time": 729, "text": "It's called atonia."}, {"time": 731, "text": "Because if you don't have that, like some patients, what do you do?"}, {"time": 734, "text": "You act out your dreams."}, {"time": 735, "text": "You get, for example, REM behavioral disorder, which is bad juju to get."}, {"time": 740, "text": "Third case is pure experience."}, {"time": 742, "text": "So I recently had this, what some people call a mystical experience."}, {"time": 747, "text": "I went to Singapore and went into a flotation tank."}, {"time": 752, "text": "So this is a big tub filled with water, that's body temperature and Epsom salt."}, {"time": 757, "text": "You strip completely naked, you lie inside of it, you close the lid."}, {"time": 761, "text": "Darkness."}, {"time": 762, "text": "Complete darkness, soundproof."}, {"time": 764, "text": "So very quickly, you become bodiless because you're floating and you're naked."}, {"time": 768, "text": "You have no rings, no watch, no nothing."}, {"time": 770, "text": "You don't feel your body anymore."}, {"time": 772, "text": "There's no sound, soundless."}, {"time": 774, "text": "There's no photon, sightless, timeless, because after a while, early on you actually hear your heart, but then you sort of adapt to that and then sort of the passage of time ceases."}, {"time": 788, "text": "And if you train yourself, like in a meditation, not to think, early on you think a lot."}, {"time": 792, "text": "It's a little bit spooky."}, {"time": 793, "text": "You feel somewhat uncomfortable or you think, well, I'm going to get bored."}, {"time": 797, "text": "And if you try to not to think actively, you become mindless."}, {"time": 800, "text": "There you are, bodiless, timeless, you know, soundless, sightless, mindless, but you're in a conscious experience."}, {"time": 808, "text": "You're not asleep."}, {"time": 811, "text": "You are a being of pure, you're a pure being."}, {"time": 813, "text": "There isn't any function."}, {"time": 814, "text": "You aren't doing any computation."}, {"time": 816, "text": "You're not remembering."}, {"time": 817, "text": "You're not projecting."}, {"time": 818, "text": "You're not planning."}, {"time": 819, "text": "Yet you are fully conscious."}, {"time": 820, "text": "You're fully conscious."}, {"time": 821, "text": "There's something going on there."}, {"time": 822, "text": "It could be just a side effect."}, {"time": 824, "text": "So what is the... You mean epiphenomena."}, {"time": 827, "text": "So what's the select, meaning why, what is the function of you being able to lay in this sensory free deprivation tank and still have a conscious experience?"}, {"time": 841, "text": "Evolutionary?"}, {"time": 842, "text": "Evolutionary."}, {"time": 843, "text": "Obviously we didn't evolve with flotation tanks in our environment."}, {"time": 846, "text": "I mean, so biology is notoriously bad at asking why question, telenormical question."}, {"time": 851, "text": "Why do we have two eyes?"}, {"time": 852, "text": "Why don't we have four eyes like some teachers or three eyes or something?"}, {"time": 855, "text": "Well, no, there's probably, there is a function to that, but we're not very good at answering those questions."}, {"time": 861, "text": "We can speculate endlessly where biology is very, or science is very good about mechanistic question."}, {"time": 866, "text": "Why is there a charge in the universe?"}, {"time": 868, "text": "We find a certain universe where there are positive and negative charges."}, {"time": 871, "text": "Why does quantum mechanics hold?"}, {"time": 873, "text": "You know, why doesn't some other theory hold?"}, {"time": 876, "text": "Quantum mechanics holding our universe is very unclear why."}, {"time": 878, "text": "So telenormical question, why questions are difficult to answer."}, {"time": 882, "text": "There's some relationship between complexity, brain processing power and consciousness."}, {"time": 889, "text": "But however, in these cases, in these three examples I gave, one is an everyday experience at night."}, {"time": 894, "text": "The other one is trauma."}, {"time": 895, "text": "And third one is in principle, you can, everybody can have these sort of mystical experiences."}, {"time": 900, "text": "You have a dissociation of function from, of intelligence from consciousness."}, {"time": 909, "text": "You caught me asking a why question."}, {"time": 912, "text": "Let me ask a question that's not a why question."}, {"time": 915, "text": "You're giving a talk later today on the Turing test for intelligence and consciousness, drawing lines between the two."}, {"time": 921, "text": "So is there a scientific way to say there's consciousness present in this entity or not?"}, {"time": 928, "text": "And to anticipate your answer, cause you, you will also, there's a neurobiological answer."}, {"time": 934, "text": "So we can test the human brain, but if you take a machine brain that you don't know tests for yet, how would you even begin to approach a test if there's consciousness present in this thing?"}, {"time": 947, "text": "That's a really good question."}, {"time": 948, "text": "So let me take it in two steps."}, {"time": 949, "text": "So as you point out for, for, for, for humans, let's just stick with humans."}, {"time": 954, "text": "There's now a test called the Zap and Zip is a procedure where you ping the brain using transcranial magnetic stimulation."}, {"time": 960, "text": "You look at the electrical reverberations essentially using EG, and then you can measure the complexity of this brain response."}, {"time": 967, "text": "And you can do this in awake people, in asleep, normal people, you can do it in awake people and then anesthetize them."}, {"time": 973, "text": "You can do it in patients."}, {"time": 975, "text": "And it, it, it has a hundred percent accuracy that in all those cases, when you're clear, the patient or the person is either conscious or unconscious, the complexity is either high or low."}, {"time": 984, "text": "And then you can adopt these techniques to similar creatures like monkeys and dogs and, and, and mice that have very similar brains."}, {"time": 992, "text": "Now of course you, you point out that may not help you because we don't have a cortex, you know, and if I send a magnetic pulse into my iPhone or my computer, it's probably going to break something."}, {"time": 1001, "text": "So we don't have that."}, {"time": 1002, "text": "So what we need ultimately, we need a theory of consciousness."}, {"time": 1007, "text": "We can't just rely on our intuition."}, {"time": 1009, "text": "Our intuition is, well, yeah, if somebody talks, they're conscious."}, {"time": 1012, "text": "However, then there are all these patients, children, babies don't talk, right?"}, {"time": 1016, "text": "But we believe that, that the babies also have conscious experiences, right?"}, {"time": 1021, "text": "And then there are all these patients I mentioned and they don't talk."}, {"time": 1024, "text": "When you dream, you can't talk because you're paralyzed."}, {"time": 1027, "text": "So what we ultimately need, we can't just rely on our intuition."}, {"time": 1031, "text": "We need a theory of conscience that tells us what is it about a piece of matter?"}, {"time": 1035, "text": "What is it about a piece of highly excitable matter like the brain or like a computer that gives rise to conscious experience?"}, {"time": 1041, "text": "We all believe, none of us believes anymore in the old story."}, {"time": 1044, "text": "It's a soul, right?"}, {"time": 1045, "text": "That used to be the most common explanation that most people accept that instill a lot of people today believe, well, there's, there's God endowed only us with a special thing that animals don't have."}, {"time": 1055, "text": "Rene Descartes famously said, a dog, if you hit it with your carriage may yell, may cry, but it doesn't have this special thing."}, {"time": 1061, "text": "It doesn't have the magic, the magic soul."}, {"time": 1065, "text": "It doesn't have res cogitans, the soul."}, {"time": 1066, "text": "Now we believe that isn't the case anymore."}, {"time": 1068, "text": "So what is the difference between brains and, and these guys, silicon?"}, {"time": 1075, "text": "And in particular, once their behavior matches."}, {"time": 1078, "text": "So if you have Siri or Alexa in 20 years from now that she can talk just as good as any possible human, what grounds do you have to say she's not conscious in particular, if she says it's of course she will, well, of course I'm conscious."}, {"time": 1091, "text": "You ask her how are you doing?"}, {"time": 1092, "text": "And she'll say, well, you know, they, they'll generate some way to, of course she'll behave like a, like a person."}, {"time": 1099, "text": "Now there's several differences."}, {"time": 1101, "text": "One is, so this relates to the problem, the very hard, why is consciousness a hard problem?"}, {"time": 1108, "text": "It's because it's subjective, right?"}, {"time": 1110, "text": "Only I have it, for only I know I have direct experience of my own consciousness."}, {"time": 1116, "text": "I don't have experience in your consciousness."}, {"time": 1118, "text": "Now I assume as a sort of a Bayesian person who believes in probability theory and all of that, you know, I can do, I can do an abduction to the, to the best available facts."}, {"time": 1126, "text": "I deduce your brain is very similar to mine."}, {"time": 1128, "text": "If I put you in a scanner, your brain is roughly going to behave the same way as I do."}, {"time": 1133, "text": "If, if, if, you know, if I give you this muesli and ask you, how does it taste?"}, {"time": 1136, "text": "You tell me things that, you know, that, that I would also say more or less, right?"}, {"time": 1140, "text": "So I infer based on all of that, that you're conscious."}, {"time": 1142, "text": "Now with theory, I can't do that."}, {"time": 1143, "text": "So there I really need a theory that tells me what is it about, about any system, this or this, that makes it conscious."}, {"time": 1151, "text": "We have such a theory."}, {"time": 1153, "text": "So the integrated information theory, but let me first, maybe as an introduction for people who are not familiar, Descartes, can you, you talk a lot about pan, panpsychism."}, {"time": 1164, "text": "Can you describe what, uh, physicalism versus dualism?"}, {"time": 1169, "text": "This you, you mentioned the soul, what, what is the history of that idea?"}, {"time": 1173, "text": "What is the idea of panpsychism or no, the debate really, uh, out of which panpsychism can, um, emerge of, of, of, um, dualism versus, uh, physicalism or do you not see panpsychism as fitting into that?"}, {"time": 1189, "text": "No, you can argue there's some, okay, so let's step back."}, {"time": 1192, "text": "So panpsychism is a very ancient belief that's been around, uh, I mean, Plato and Aristotle talks about it, uh, modern philosophers talk about it."}, {"time": 1201, "text": "Of course, in Buddhism, the idea is very prevalent that, I mean, there are different versions of it."}, {"time": 1207, "text": "One version says everything is ensouled, everything, rocks and stones and dogs and people and forest and iPhones, all of us all, right?"}, {"time": 1214, "text": "All matter is ensouled."}, {"time": 1215, "text": "That's sort of one version."}, {"time": 1217, "text": "Another version is that all biology, all creatures, small or large, from a single cell to a giant sequoia tree feel like something."}, {"time": 1226, "text": "This one I think is somewhat more realistic."}, {"time": 1228, "text": "Um, so the different versions, what do you mean by feel like something, have, have feelings, have some kind of, it feels like something, it may well be possible that it feels like something to be a paramecium."}, {"time": 1239, "text": "I think it's pretty likely it feels like something to be a bee or a mouse or a dog."}, {"time": 1247, "text": "So, so that you can see that's also, so panpsychism is very broad and you can, so some people, for example, Bertrand Russell, tried to advocate this, this idea, it's called Rasselian Monism, that that panpsychism is really physics viewed from the inside."}, {"time": 1264, "text": "So the idea is that physics is very good at describing relationship among objects like charges or like gravity, right?"}, {"time": 1272, "text": "You know, describe the relationship between curvature and mass distribution, okay?"}, {"time": 1276, "text": "That's the relationship among things."}, {"time": 1278, "text": "Physics doesn't really describe the ultimate reality itself."}, {"time": 1281, "text": "It's just relationship among, you know, quarks or all these other stuff from like a third person observer."}, {"time": 1290, "text": "And consciousness is what physics feels from the inside."}, {"time": 1291, "text": "So my conscious experience, it's the way the physics of my brain, particularly my cortex feels from the inside."}, {"time": 1298, "text": "And so if you are paramecium, you got to remember, you say paramecium, well, that's a pretty dumb creature."}, {"time": 1303, "text": "It is, but it has already a billion different molecules, probably, you know, 5,000 different proteins assembled in a highly, highly complex system that no single person, no computer system so far on this planet has ever managed to accurately simulate."}, {"time": 1319, "text": "Its complexity vastly escapes us."}, {"time": 1322, "text": "And it may well be that that little thing feels like a tiny bit."}, {"time": 1324, "text": "Now, it doesn't have a voice in the head like me."}, {"time": 1326, "text": "It doesn't have expectations."}, {"time": 1327, "text": "You know, it doesn't have all that complex things, but it may well feel like something."}, {"time": 1333, "text": "So this is really interesting."}, {"time": 1334, "text": "Can we draw some lines and maybe try to understand the difference between life, intelligence and consciousness?"}, {"time": 1343, "text": "How do you see all of those?"}, {"time": 1345, "text": "If you had to define what is a living thing, what is a conscious thing and what is an intelligent thing?"}, {"time": 1352, "text": "Do those intermix for you or are they totally separate?"}, {"time": 1355, "text": "So A, that's a question that we don't have a full answer to."}, {"time": 1358, "text": "A lot of the stuff we're talking about today is full of mysteries and fascinating ones, right?"}, {"time": 1363, "text": "For example, you can go to Aristotle, who's probably the most important scientist and philosopher who's ever lived in, certainly in Western culture."}, {"time": 1369, "text": "He had this idea, it's called hylomorphism."}, {"time": 1371, "text": "It's quite popular these days, that there are different forms of soul."}, {"time": 1375, "text": "The soul is really the form of something."}, {"time": 1377, "text": "He says, all biological creatures have a vegetative soul."}, {"time": 1380, "text": "That's life principle."}, {"time": 1381, "text": "Today, we think we understand something more than it is biochemistry and nonlinear thermodynamics."}, {"time": 1387, "text": "Then he said they have a sensitive soul."}, {"time": 1389, "text": "Only animals and humans have also a sensitive soul or a petitive soul."}, {"time": 1395, "text": "They can see, they can smell, and they have drives."}, {"time": 1398, "text": "They want to reproduce, they want to eat, et cetera."}, {"time": 1401, "text": "And then only humans have what he called a rational soul, okay?"}, {"time": 1406, "text": "And that idea then made it into Christendom and then the rational soul is the one that lives forever."}, {"time": 1411, "text": "He was very unclear."}, {"time": 1412, "text": "He wasn't really, I mean, different readings of Aristotle give different, whether did he believe that rational soul was immortal or not."}, {"time": 1418, "text": "I probably think he didn't."}, {"time": 1419, "text": "But then, of course, that made it through Plato into Christianity, and then this soul became immortal and then became the connection to God."}, {"time": 1428, "text": "So you ask me, essentially, what is our modern conception of these three, Aristotle would have called them different forms."}, {"time": 1436, "text": "Life, we think we know something about it, at least life on this planet, right?"}, {"time": 1440, "text": "Although we don't understand how to originate it, but it's been difficult to rigorously pin down."}, {"time": 1445, "text": "You see this in modern definitions of death."}, {"time": 1448, "text": "In fact, right now, there's a conference ongoing, again, that tries to define legally and medically what is death."}, {"time": 1455, "text": "It used to be very simple."}, {"time": 1456, "text": "Death is you stop breathing, your heart stops beating, you're dead, totally uncontroversial."}, {"time": 1461, "text": "If you're unsure, you wait another 10 minutes."}, {"time": 1463, "text": "If the patient doesn't breathe, he's dead."}, {"time": 1465, "text": "Well, now we have ventilators, we have heart pacemakers, so it's much more difficult to define what death is."}, {"time": 1470, "text": "Typically, death is defined as the end of life and life is defined before death."}, {"time": 1475, "text": "Okay, so we don't have really very good definitions."}, {"time": 1479, "text": "Intelligence, we don't have a rigorous definition."}, {"time": 1481, "text": "We know something how to measure, it's called IQ or G factors, right?"}, {"time": 1486, "text": "And we're beginning to build it in a narrow sense, right?"}, {"time": 1490, "text": "Like go, AlphaGo and Watson and, you know, Google cars and Uber cars and all of that, it's still narrow AI and some people are thinking about artificial general intelligence."}, {"time": 1501, "text": "But roughly, as we said before, it's something to do with ability to learn and to adapt to new environments."}, {"time": 1506, "text": "But that is, as I said, also, it's radical difference from experience."}, {"time": 1511, "text": "And it's very unclear if you build a machine that has AGI, it's not at all a priori, it's not at all clear that this machine will have consciousness, it may or may not."}, {"time": 1520, "text": "So let's ask it the other way, do you think if you were to try to build an artificial general intelligence system, do you think figuring out how to build artificial consciousness would help you get to an AGI?"}, {"time": 1534, "text": "So or put another way, do you think intelligent requires consciousness?"}, {"time": 1540, "text": "In human, it goes hand in hand."}, {"time": 1543, "text": "In human, or I think in biology, consciousness, intelligence goes hand in hand, quay is illusion because the brain evolved to be highly complex, complexity via the theory integrated information theory is sort of ultimately is what is closely tied to consciousness."}, {"time": 1559, "text": "Ultimately it's causal power upon itself."}, {"time": 1561, "text": "And so in evolved systems, they go together."}, {"time": 1565, "text": "In artificial system, particularly in digital machines, they do not go together."}, {"time": 1569, "text": "And if you ask me point blank, is Alexa 20.0 in the year 2040, when she can easily pass every Turing test, is she conscious?"}, {"time": 1578, "text": "No, even if she claims she's conscious."}, {"time": 1581, "text": "In fact, you could even do a more radical version of this thought experiment."}, {"time": 1584, "text": "You can build a computer simulation of the human brain."}, {"time": 1586, "text": "You know what Henry Markham in the Blue Brain Project or the Human Brain Project in Switzerland is trying to do."}, {"time": 1592, "text": "Let's grant them all the success."}, {"time": 1593, "text": "So in 10 years, we have this perfect simulation of the human brain."}, {"time": 1596, "text": "Every neuron is simulated and it has a larynx and it has motor neurons."}, {"time": 1600, "text": "It has a Broca's area and of course they'll talk and they'll say, hi, I just woke up."}, {"time": 1605, "text": "I feel great."}, {"time": 1606, "text": "OK, even that computer simulation that can in principle map onto your brain will not be conscious."}, {"time": 1612, "text": "Because it simulates, it's a difference between the simulated and the real."}, {"time": 1616, "text": "So it simulates the behavior associated with consciousness."}, {"time": 1619, "text": "It might be, it will, if it's done properly, will have all the intelligence that that particular person they're simulating has."}, {"time": 1626, "text": "But simulating intelligence is not the same as having conscious experiences."}, {"time": 1630, "text": "And I give you a really nice metaphor that engineers and physicists typically get."}, {"time": 1635, "text": "I can write down Einstein's field equation, nine or ten equations that describe the link in general relativity between curvature and mass."}, {"time": 1643, "text": "I can do that."}, {"time": 1644, "text": "I can run this on my laptop to predict that the central, the black hole at the center of our galaxy will be so massive that it will twist space time around it so no light can escape."}, {"time": 1657, "text": "It's a black hole."}, {"time": 1658, "text": "But funny, have you ever wondered why doesn't this computer simulation suck me in?"}, {"time": 1664, "text": "It simulates gravity, but it doesn't have the causal power of gravity."}, {"time": 1669, "text": "That's a huge difference."}, {"time": 1670, "text": "So it's a difference between the real and the simulator, just like it doesn't get wet inside a computer when the computer runs code that simulates a weather storm."}, {"time": 1679, "text": "And so in order to have, to have artificial consciousness, you have to give it the same causal power as the human brain."}, {"time": 1686, "text": "You have to build so called a neuromorphic machine that has hardware that is very similar to the human brain, not a digital clocked phenomenon computer."}, {"time": 1696, "text": "So that's, just to clarify though, you think that consciousness is not required to create human level intelligence."}, {"time": 1705, "text": "It seems to accompany in the human brain, but for machine not."}, {"time": 1711, "text": "So maybe just because this is AGI, let's dig in a little bit about what we mean by intelligence."}, {"time": 1719, "text": "So one thing is the G factor, these kind of IQ tests of intelligence."}, {"time": 1724, "text": "But I think if you, maybe another way to say, so in 2040, 2050, people will have Siri that is just really impressive."}, {"time": 1734, "text": "Do you think people will say Siri is intelligent?"}, {"time": 1738, "text": "Intelligence is this amorphous thing."}, {"time": 1741, "text": "So to be intelligent, it seems like you have to have some kind of connections with other human beings in a sense that you have to impress them with your intelligence."}, {"time": 1751, "text": "And there feels, you have to somehow operate in this world full of humans."}, {"time": 1757, "text": "And for that, there feels like there has to be something like consciousness."}, {"time": 1761, "text": "So you think you can have just the world's best natural NLP system, natural language understanding generation, and that will be, that will get us happy and say, you know what, we've created an AGI."}, {"time": 1773, "text": "I don't know happy, but yes, I do believe we can get what we call high level functional intelligence, particular sort of the G, you know, this fluid like intelligence that we cherish, particularly at a place like MIT, right, in machines."}, {"time": 1791, "text": "I see a priori no reasons, and I see a lot of reason to believe it's going to happen very, you know, over the next 50 years or 30 years."}, {"time": 1798, "text": "So for beneficial AI, for creating an AI system that's, so you mentioned ethics, that is exceptionally intelligent but also does not do, does, you know, aligns its values with our values as humanity."}, {"time": 1812, "text": "Do you think then it needs consciousness?"}, {"time": 1814, "text": "Yes, I think that that is a very good argument that if we're concerned about AI and the threat of AI, a la Nick Bostrom, existentialist threat, I think having an intelligence that has empathy, right, why do we find abusing a dog, why do most of us find that abhorrent, abusing any animal, right?"}, {"time": 1833, "text": "Why do we find that abhorrent because we have this thing called empathy, which if you look at the Greek really means feeling with, I feel a path of empathy, I have feeling with you."}, {"time": 1843, "text": "I see somebody else suffer that isn't even my conspecific, it's not a person, it's not my wife or my kids, it's a dog, but I feel naturally most of us, not all of us, most of us will feel emphatic."}, {"time": 1855, "text": "And so it may well be in the long term interest of survival of homo sapiens sapiens that if we do build AGI and it really becomes very powerful that it has an emphatic response and doesn't just exterminate humanity."}, {"time": 1871, "text": "So as part of the full conscious experience to create a consciousness, artificial or in our human consciousness, do you think fear, maybe we're going to get into the earlier days with Nietzsche and so on, but do you think fear and suffering are essential to have consciousness?"}, {"time": 1890, "text": "Do you have to have the full range of experience to have a system that has experience or can you have a system that only has very particular kinds of very positive experiences?"}, {"time": 1901, "text": "Look you can have in principle, people have done this in the rat where you implant an electrode in the hypothalamus, the pleasure center of the rat and the rat stimulates itself above and beyond anything else."}, {"time": 1912, "text": "It doesn't care about food or natural sex or drink anymore, it just stimulates itself because it's such a pleasurable feeling."}, {"time": 1920, "text": "I guess it's like an orgasm just you have all day long."}, {"time": 1924, "text": "And so a priori I see no reason why you need a great variety."}, {"time": 1931, "text": "Now clearly to survive that wouldn't work, right?"}, {"time": 1934, "text": "But if I'd engineered artificially, I don't think you need a great variety of conscious experience."}, {"time": 1943, "text": "You could have just pleasure or just fear."}, {"time": 1945, "text": "It might be a terrible existence, but I think that's possible at least on conceptual logical ground."}, {"time": 1951, "text": "Because any real creature whether artificially engineered, you want to give it fear, the fear of extinction that we all have."}, {"time": 1958, "text": "And you also want to give it positive repetitive states, states that you want the machine encouraged to do because they give the machine positive feedback."}, {"time": 1968, "text": "So you mentioned panpsychism, to jump back a little bit, everything having some kind of mental property."}, {"time": 1977, "text": "How do you go from there to something like human consciousness?"}, {"time": 1982, "text": "So everything having some elements of consciousness, is there something special about human consciousness?"}, {"time": 1988, "text": "So it's not everything."}, {"time": 1990, "text": "Like a spoon, the form of panpsychism I think about doesn't ascribe consciousness to anything like this, the spoon on my liver."}, {"time": 2000, "text": "However, the theory, the integrated information theory does say that the system, even one that looks from the outside relatively simple, at least if they have this internal causal power, it does feel like something."}, {"time": 2015, "text": "The theory a priori doesn't say anything what's special about human."}, {"time": 2018, "text": "Biologically we know the one thing that's special about human is we speak and we have an overblown sense of our own importance."}, {"time": 2028, "text": "We believe we're exceptional and we're just God's gift to the universe."}, {"time": 2034, "text": "But behaviorally the main thing that we have, we can plan over the long term, we have language and that gives us an enormous amount of power and that's why we are the current dominant species on the planet."}, {"time": 2045, "text": "So you mentioned God, you grew up a devout Roman Catholic family, so with consciousness you're sort of exploring some really deeply fundamental human things that religion also touches on."}, {"time": 2062, "text": "Where does religion fit into your thinking about consciousness?"}, {"time": 2067, "text": "You've grown throughout your life and changed your views on religion as far as I understand."}, {"time": 2071, "text": "Yeah, I mean I'm now much closer to, I'm not a Roman Catholic anymore, I don't believe there's sort of this God, the God I was educated to believe in, sits somewhere in the fullness of time, I'll be united in some sort of everlasting bliss, I just don't see any evidence for that."}, {"time": 2089, "text": "Look, the world, the night is large and full of wonders, there are many things that I don't understand, I think many things that we as a cult, look we don't even understand more than 4% of all the universe, dark matter, dark energy, we have no idea what it is, maybe it's lost socks, what do I know?"}, {"time": 2106, "text": "So all I can tell you is it's sort of my current religious or spiritual sentiment is much closer to some form of Buddhism, without the reincarnation unfortunately, there's no evidence for it than reincarnation."}, {"time": 2120, "text": "So can you describe the way Buddhism sees the world a little bit?"}, {"time": 2125, "text": "Well so they talk about, so when I spent several meetings with the Dalai Lama and what always impressed me about him, he really, unlike for example let's say the Pope or some Cardinal, he always emphasized minimizing the suffering of all creatures."}, {"time": 2140, "text": "So they have this, from the early beginning they look at suffering in all creatures, not just in people, but in everybody, this universal and of course by degrees, an animal in general is less capable of suffering than a well developed, normally developed human and they think consciousness pervades in this universe and they have these techniques, you can think of them like mindfulness etc."}, {"time": 2166, "text": "and meditation that tries to access what they claim of this more fundamental aspect of reality."}, {"time": 2194, "text": "The only thing you directly are acquainted with is this world that's populated with things in images and sounds in your head and touches and all of that."}, {"time": 2203, "text": "I actually have a question, so it sounds like you kind of have a rich life, you talk about rock climbing and it seems like you really love literature and consciousness is all about experiencing things, so do you think that has helped your research on this topic?"}, {"time": 2220, "text": "Yes, particularly if you think about it, the various states, so for example when you do rock climbing or now I do rowing, crew rowing and a bike every day, you can get into this thing called the zone and I've always wanted about it, particularly with respect to consciousness because it's a strangely addictive state."}, {"time": 2292, "text": "You I think you touch the root of being, that's really what you're touching there, you're getting close to the root of being and that's very different from intelligence."}, {"time": 2301, "text": "So what do you think about the simulation hypothesis, simulation theory, the idea that we all live in a computer simulation?"}, {"time": 2308, "text": "Rapture for nerds."}, {"time": 2311, "text": "I think it's as likely as the hypothesis had engaged hundreds of scholars for many centuries, are we all just existing in the mind of God?"}, {"time": 2322, "text": "And this is just a modern version of it, it's equally plausible."}, {"time": 2327, "text": "People love talking about these sort of things, I know they're book written about this simulation hypothesis, if that's what people want to do, that's fine, it seems rather esoteric, it's never testable."}, {"time": 2338, "text": "But it's not useful for you to think of in those terms, so maybe connecting to the questions of free will which you've talked about, I vaguely remember you saying that the idea that there's no free will, it makes you very uncomfortable."}, {"time": 2353, "text": "So what do you think about free will from a physics perspective, from a conscious perspective, what does it all fit?"}, {"time": 2360, "text": "Okay, so from the physics perspective, leaving aside quantum mechanics, we believe we live in a fully deterministic world, right?"}, {"time": 2367, "text": "But then comes of course quantum mechanics, so now we know that certain things are in principle not predictable, which as you said I prefer, because the idea that the initial condition of the universe and then everything else, we're just acting out the initial condition of the universe, that doesn't... It's not a romantic notion."}, {"time": 2387, "text": "Now when it comes to consciousness, I think we do have certain freedom."}, {"time": 2390, "text": "We are much more constrained by physics of course and by our past and by our own conscious desires and what our parents told us and what our environment tells us."}, {"time": 2399, "text": "We all know that, right?"}, {"time": 2400, "text": "There's hundreds of experiments that show how we can be influenced."}, {"time": 2418, "text": "These are things where you really deliberate and I think under those conditions, you are as free as you can be."}, {"time": 2424, "text": "When you bring your entire being, your entire conscious being to that question and try to analyze it under all the various conditions, then you make a decision, you are as free as you can ever be."}, {"time": 2438, "text": "That is I think what free will is."}, {"time": 2440, "text": "It's not a will that's totally free to do anything it wants."}, {"time": 2444, "text": "That's not possible."}, {"time": 2446, "text": "So as Jack mentioned, you actually write a blog about books you've read, amazing books from, I'm Russian, from Bulgakov, Neil Gaiman, Carl Sagan, Murakami."}, {"time": 2461, "text": "So what is a book that early in your life transformed the way you saw the world, something that changed your life?"}, {"time": 2469, "text": "Nietzsche I guess did."}, {"time": 2470, "text": "That's Brooks R. Truster because he talks about some of these problems."}, {"time": 2474, "text": "He was one of the first discoverer of the unconscious."}, {"time": 2477, "text": "This is a little bit before Freud when he was in the air."}, {"time": 2483, "text": "He makes all these claims that people sort of under the guise or under the mass of charity actually are very noncharitable."}, {"time": 2492, "text": "So he is sort of really the first discoverer of the great land of the unconscious and that really struck me."}, {"time": 2501, "text": "And what do you think about the unconscious, what do you think about Freud, what do you think about these ideas?"}, {"time": 2507, "text": "Just like dark matter in the universe, what's over there in that unconscious?"}, {"time": 2512, "text": "I mean much more than we think."}, {"time": 2513, "text": "This is what a lot of last 100 years of research has shown."}, {"time": 2517, "text": "So I think he was a genius, misguided towards the end, but he started out as a neuroscientist."}, {"time": 2522, "text": "He contributed, he did the studies on the lamprey, he contributed himself to the neuron hypothesis, the idea that there are discrete units that we call nerve cells now."}, {"time": 2533, "text": "And then he wrote about the unconscious and I think it's true, there's lots of stuff happening."}, {"time": 2540, "text": "You feel this particular when you're in a relationship and it breaks asunder, right?"}, {"time": 2545, "text": "And then you have this terrible, you can have love and hate and lust and anger and all of it's mixed in."}, {"time": 2551, "text": "And when you try to analyze yourself, why am I so upset?"}, {"time": 2555, "text": "It's very, very difficult to penetrate to those basements, those caverns in your mind because the prying eyes of conscious doesn't have access to those, but they're there in the amygdala or lots of other places."}, {"time": 2568, "text": "They make you upset or angry or sad or depressed and it's very difficult to try to actually uncover the reason."}, {"time": 2574, "text": "You can go to a shrink, you can talk with your friend endlessly, you construct finally a story why this happened, why you love her or don't love her or whatever, but you don't really know whether that actually happened because you simply don't have access to those parts of the brain and they're very powerful."}, {"time": 2589, "text": "Do you think that's a feature or a bug of our brain?"}, {"time": 2592, "text": "The fact that we have this deep, difficult to dive into subconscious?"}, {"time": 2596, "text": "I think it's a feature because otherwise, look, we are like any other brain or nervous system or computer, we are severely band limited."}, {"time": 2608, "text": "If everything I do, every emotion I feel, every eye movements I make, if all of that had to be under the control of consciousness, I wouldn't be here."}, {"time": 2622, "text": "What you do early on, your brain, you have to be conscious when you learn things like typing or like riding on a bike, but then what you do, you train up routes, I think that involve basal ganglia and striatum."}, {"time": 2634, "text": "You train up different parts of your brain and then once you do it automatically like typing, you can show you do it much faster without even thinking about it because you've got these highly specialized, what Frans Krik and I call zombie agents, they're taking care of that while your consciousness can sort of worry about the abstract sense of the text you want to write."}, {"time": 2652, "text": "I think that's true for many, many things."}, {"time": 2655, "text": "But for the things like all the fights you had with an ex girlfriend, things that you would think are not useful to still linger somewhere in the subconscious."}, {"time": 2665, "text": "So that seems like a bug that it would stick to there."}, {"time": 2668, "text": "You think it would be better if you can analyze it and then get it out of the system."}, {"time": 2671, "text": "Better to get it out of the system or just forget it ever happened."}, {"time": 2674, "text": "That seems a very buggy kind of."}, {"time": 2677, "text": "Well yeah, in general we don't have, and that's probably functional, we don't have an ability unless it's extreme, there are cases, clinical dissociations, right?"}, {"time": 2685, "text": "When people are heavily abused, when they completely repress the memory, but that doesn't happen in normal people."}, {"time": 2693, "text": "We don't have an ability to remove traumatic memories and of course we suffer from that."}, {"time": 2699, "text": "On the other hand, probably if you had the ability to constantly wipe your memory, you'd probably do it to an extent that isn't useful to you."}, {"time": 2707, "text": "So yeah, it's a good question to balance."}, {"time": 2711, "text": "So on the books, as Jack mentioned, correct me if I'm wrong, but broadly speaking, academia and the different scientific disciplines, certainly in engineering, reading literature seems to be a rare pursuit."}, {"time": 2726, "text": "So I'm wrong on this, but that's in my experience, most people read much more technical text and do not sort of escape or seek truth in literature."}, {"time": 2736, "text": "It seems like you do."}, {"time": 2738, "text": "So what do you think is the value, what do you think literature adds to the pursuit of scientific truth?"}, {"time": 2743, "text": "Do you think it's good, it's useful for everybody?"}, {"time": 2746, "text": "Gives you access to a much wider array of human experiences."}, {"time": 2752, "text": "How valuable do you think it is?"}, {"time": 2754, "text": "Well if you want to understand human nature and nature in general, then I think you have to better understand a wide variety of experiences, not just sitting in a lab staring at a screen and having a face flashed onto you for a hundred milliseconds and pushing a button."}, {"time": 2768, "text": "That's what I used to do, that's what most psychologists do."}, {"time": 2770, "text": "There's nothing wrong with that, but you need to consider lots of other strange states."}, {"time": 2776, "text": "And literature is a shortcut for this."}, {"time": 2778, "text": "Well yeah, because literature, that's what literature is all about, all sorts of interesting experiences that people have, the contingency of it, the fact that women experience the world different, black people experience the world different."}, {"time": 2792, "text": "The one way to experience that is reading all these different literature and try to find out."}, {"time": 2796, "text": "You see, everything is so relative."}, {"time": 2797, "text": "You read a book 300 years ago, they thought about certain problems very, very differently than us today."}, {"time": 2803, "text": "We today, like any culture, think we know it all."}, {"time": 2806, "text": "That's common to every culture."}, {"time": 2807, "text": "Every culture believes at its heyday they know it all."}, {"time": 2810, "text": "And then you realize, well, there's other ways of viewing the universe and some of them may have lots of things in their favor."}, {"time": 2816, "text": "So this is a question I wanted to ask about time scale or scale in general."}, {"time": 2822, "text": "When you, with IIT or in general, try to think about consciousness, try to think about these ideas, we kind of naturally think in human time scales, and also entities that are sized close to humans."}, {"time": 2838, "text": "Do you think of things that are much larger and much smaller as containing consciousness?"}, {"time": 2842, "text": "And do you think of things that take, you know, eons to operate in their conscious cause effect?"}, {"time": 2853, "text": "That's a very good question."}, {"time": 2855, "text": "So I think a lot about small creatures because experimentally, you know, a lot of people work on flies and bees, right?"}, {"time": 2861, "text": "So most people just think they are automata, they're just bugs for heaven's sake, right?"}, {"time": 2865, "text": "But if you look at their behavior, like bees, they can recognize individual humans."}, {"time": 2868, "text": "They have this very complicated way to communicate."}, {"time": 2872, "text": "If you've ever been involved or you know your parents when they bought a house, what sort of agonizing decision that is."}, {"time": 2877, "text": "And bees have to do that once a year, right, when they swarm in the spring."}, {"time": 2881, "text": "And then they have this very elaborate way, they have free and scouts, they go to the individual sites, they come back, they have this power, this dance, literally, where they dance for several days, they try to recruit other deets, this very complicated decision rate, when they finally, once they make a decision, the entire swarm, the scouts warm up the entire swarm and then go to one location."}, {"time": 2898, "text": "They don't go to 50 locations, they go to one location that the scouts have agreed upon by themselves."}, {"time": 2903, "text": "If we look at the circuit complexity, it's 10 times more denser than anything we have in our brain."}, {"time": 2908, "text": "Now they only have a million neurons, but the neurons are amazingly complex."}, {"time": 2911, "text": "Complex behavior, very complicated circuitry, so there's no question they experience something, their life is very different, they're tiny, they only live, you know, for, well, workers live maybe for two months."}, {"time": 2922, "text": "So I think, and IIT tells you this, in principle, the substrate of consciousness is the substrate that maximizes the cause effect power over all possible spatial temporal grains."}, {"time": 2933, "text": "So when I think about, for example, do you know the science fiction story, The Black Cloud?"}, {"time": 2936, "text": "Okay, it's a classic by Fred Hoyle, the astronomer."}, {"time": 2940, "text": "He has this cloud intervening between the earth and the sun and leading to some sort of, to global cooling, this is written in the 50s."}, {"time": 2949, "text": "It turns out you can, using the radio dish, they communicate with actually an entity, it's actually an intelligent entity, and they sort of, they convince it to move away."}, {"time": 2986, "text": "And so there may be forms of consciousness that we simply don't recognize for what they are because they are so radical different from anything you and I are used to."}, {"time": 2995, "text": "Again, that's why it's good to read or to watch science fiction movies, well, to think about this."}, {"time": 3000, "text": "Do you know Stanislav Lem, this Polish science fiction writer, he wrote Solaris and was turned into a Hollywood movie?"}, {"time": 3008, "text": "His best novel is in the 60s, a very engineer, he's an engineer in background."}, {"time": 3013, "text": "His most interesting novel is called The Victorious, where human civilization, they have this mission to this planet and everything is destroyed and they discover machines, humans got killed and then these machines took over and there was this machine evolution, Darwinian evolution, he talks about this very vividly."}, {"time": 3032, "text": "And finally, the dominant machine intelligence organism that survived were gigantic clouds of little hexagonal universal cellular automata."}, {"time": 3042, "text": "This was written in the 60s, so typically they're all lying on the ground individual by themselves, but in times of crisis, they can communicate, they assemble into gigantic nets into clouds of trillions of these particles and then they become hyper intelligent and they can beat anything that humans can throw at it."}, {"time": 3060, "text": "It's very beautiful and compelling where you have an intelligence where finally the humans leave the planet, they're simply unable to understand and comprehend this creature."}, {"time": 3069, "text": "They can say, well, either we can nuke the entire planet and destroy it or we just have to leave because fundamentally it's an alien, it's so alien from us and our ideas that we cannot communicate with them."}, {"time": 3080, "text": "Yeah, actually in conversation, so you're talking to us, Steven Wolf from Brought Up is that there could be ideas that you already have these artificial general intelligence like super smart or maybe conscious beings in the cellular automata, we just don't know how to talk to them."}, {"time": 3097, "text": "So it's the language of communication, but you don't know what to do with it."}, {"time": 3101, "text": "So that's one sort of view is consciousness is only something you can measure."}, {"time": 3106, "text": "So it's not conscious if you can't measure it."}, {"time": 3110, "text": "So you're making an ontological and an epistemic statement."}, {"time": 3113, "text": "One is it's just like seeing the multiverses, that might be true, but I can't communicate with them."}, {"time": 3120, "text": "I can't have any knowledge of them."}, {"time": 3121, "text": "That's an epistemic argument."}, {"time": 3123, "text": "So those are two different things."}, {"time": 3124, "text": "So it may well be possible."}, {"time": 3125, "text": "Look, in another case that's happening right now, people are building these mini organoids."}, {"time": 3129, "text": "Do you know what this is?"}, {"time": 3130, "text": "So you can take stem cells from under your arm, put it in a dish, add four transcription factors and then you can induce them to grow into large, well, large, they're a few millimeters."}, {"time": 3139, "text": "They're like a half a million neurons that look like nerve cells in a dish called mini organoids at Harvard, at Stanford, everywhere they're building them."}, {"time": 3147, "text": "It may well be possible that they're beginning to feel like something, but we can't really communicate with them right now."}, {"time": 3153, "text": "So people are beginning to think about the ethics of this."}, {"time": 3156, "text": "So yes, he may be perfectly right, but it's one question, are they conscious or not?"}, {"time": 3161, "text": "It's a totally separate question."}, {"time": 3163, "text": "How would I know?"}, {"time": 3164, "text": "Those are two different things."}, {"time": 3165, "text": "If you could give advice to a young researcher, sort of dreaming of understanding or creating human level intelligence or consciousness, what would you say?"}]}, {"title": "Juergen Schmidhuber: Godel Machines, Meta-Learning, and LSTMs | Lex Fridman Podcast #11", "id": "3FIo6evmweo", "quotes": [{"time": 645, "text": "Today, we already have a universal problem solver like that."}, {"time": 650, "text": "However, it's not practical because the overhead, the constant overhead is so large that for the small kinds of problems that we want to solve in this little biosphere."}, {"time": 664, "text": "By the way, when you say small, you're talking about things that fall within the constraints of our computational systems."}, {"time": 670, "text": "So they can seem quite large to us mere humans, right?"}, {"time": 674, "text": "That's right, yeah."}, {"time": 675, "text": "So they seem large and even unsolvable in a practical sense today, but they are still small compared to almost all problems because almost all problems are large problems, which are much larger than any constant."}, {"time": 691, "text": "Do you find it useful as a person who has dreamed of creating a general learning system, has worked on creating one, has done a lot of interesting ideas there, to think about P versus NP, this formalization of how hard problems are, how they scale, this kind of worst case analysis type of thinking, do you find that useful?"}, {"time": 716, "text": "Or is it only just a mathematical, it's a set of mathematical techniques to give you intuition about what's good and bad."}, {"time": 725, "text": "So P versus NP, that's super interesting from a theoretical point of view."}, {"time": 731, "text": "And in fact, as you are thinking about that problem, you can also get inspiration for better practical problem solvers."}, {"time": 741, "text": "On the other hand, we have to admit that at the moment, the best practical problem solvers for all kinds of problems that we are now solving through what is called AI at the moment, they are not of the kind that is inspired by these questions."}, {"time": 758, "text": "There we are using general purpose computers such as recurrent neural networks, but we have a search technique which is just local search gradient descent to try to find a program that is running on these recurrent networks, such that it can solve some interesting problems such as speech recognition or machine translation and something like that."}, {"time": 783, "text": "And there is very little theory behind the best solutions that we have at the moment that can do that."}, {"time": 790, "text": "Do you think that needs to change?"}, {"time": 792, "text": "Do you think that will change?"}, {"time": 794, "text": "Or can we go, can we create a general intelligent systems without ever really proving that that system is intelligent in some kind of mathematical way, solving machine translation perfectly or something like that, within some kind of syntactic definition of a language, or can we just be super impressed by the thing working extremely well and that's sufficient?"}, {"time": 815, "text": "There's an old saying, and I don't know who brought it up first, which says, there's nothing more practical than a good theory."}, {"time": 823, "text": "And a good theory of problem solving under limited resources, like here in this universe or on this little planet, has to take into account these limited resources."}, {"time": 841, "text": "And so probably there is locking a theory, which is related to what we already have, these asymptotically optimal problem solvers, which tells us what we need in addition to that to come up with a practically optimal problem solver."}, {"time": 862, "text": "So I believe we will have something like that."}, {"time": 867, "text": "And maybe just a few little tiny twists are necessary to change what we already have, to come up with that as well."}, {"time": 876, "text": "As long as we don't have that, we admit that we are taking suboptimal ways and recurrent neural networks and long short term memory for equipped with local search techniques."}, {"time": 890, "text": "And we are happy that it works better than any competing methods, but that doesn't mean that we think we are done."}, {"time": 900, "text": "You've said that an AGI system will ultimately be a simple one."}, {"time": 905, "text": "A general intelligence system will ultimately be a simple one."}, {"time": 908, "text": "Maybe a pseudocode of a few lines will be able to describe it."}, {"time": 911, "text": "Can you talk through your intuition behind this idea, why you feel that at its core, intelligence is a simple algorithm?"}, {"time": 926, "text": "Experience tells us that the stuff that works best is really simple."}, {"time": 933, "text": "So the asymptotically optimal ways of solving problems, if you look at them, they're just a few lines of code, it's really true."}, {"time": 941, "text": "Although they are these amazing properties, just a few lines of code."}, {"time": 945, "text": "Then the most promising and most useful practical things, maybe don't have this proof of optimality associated with them."}, {"time": 957, "text": "However, they are also just a few lines of code."}, {"time": 960, "text": "The most successful recurrent neural networks, you can write them down in five lines of pseudocode."}, {"time": 968, "text": "That's a beautiful, almost poetic idea, but what you're describing there is the lines of pseudocode are sitting on top of layers and layers of abstractions in a sense."}, {"time": 982, "text": "So you're saying at the very top, it'll be a beautifully written sort of algorithm."}, {"time": 991, "text": "But do you think that there's many layers of abstractions we have to first learn to construct?"}, {"time": 996, "text": "Yeah, of course, we are building on all these great abstractions that people have invented over the millennia, such as matrix multiplications and real numbers and basic arithmetics and calculus and derivations of error functions and derivatives of error functions and stuff like that."}, {"time": 1024, "text": "So without that language that greatly simplifies our way of thinking about these problems, we couldn't do anything."}, {"time": 1034, "text": "So in that sense, as always, we are standing on the shoulders of the giants who in the past simplified the problem of problem solving so much that now we have a chance to do the final step."}, {"time": 1049, "text": "So the final step will be a simple one."}, {"time": 1053, "text": "If we take a step back through all of human civilization and just the universe in general, how do you think about evolution and what if creating a universe is required to achieve this final step?"}, {"time": 1067, "text": "What if going through the very painful and inefficient process of evolution is needed to come up with this set of abstractions that ultimately lead to intelligence?"}, {"time": 1077, "text": "Do you think there's a shortcut or do you think we have to create something like our universe in order to create something like human level intelligence?"}, {"time": 1089, "text": "So far, the only example we have is this one, this universe in which we are living."}, {"time": 1094, "text": "Do you think we can do better?"}, {"time": 1100, "text": "Maybe not, but we are part of this whole process."}, {"time": 1104, "text": "So apparently, so it might be the case that the code that runs the universe is really, really simple."}, {"time": 1113, "text": "Everything points to that possibility because gravity and other basic forces are really simple laws that can be easily described also in just a few lines of code basically."}, {"time": 1126, "text": "And then there are these other events that the apparently random events in the history of the universe, which as far as we know at the moment don't have a compact code, but who knows?"}, {"time": 1140, "text": "Maybe somebody in the near future is going to figure out the pseudo random generator which is computing whether the measurement of that spin up or down thing here is going to be positive or negative."}, {"time": 1157, "text": "Underlying quantum mechanics."}, {"time": 1160, "text": "Do you ultimately think quantum mechanics is a pseudo random number generator?"}, {"time": 1164, "text": "So it's all deterministic."}, {"time": 1166, "text": "There's no randomness in our universe."}, {"time": 1168, "text": "Does God play dice?"}, {"time": 1171, "text": "So a couple of years ago, a famous physicist, quantum physicist, Anton Zeilinger, he wrote an essay in nature and it started more or less like that."}, {"time": 1185, "text": "One of the fundamental insights of the 20th century was that the universe is fundamentally random on the quantum level."}, {"time": 1200, "text": "And that whenever you measure spin up or down or something like that, a new bit of information enters the history of the universe."}, {"time": 1212, "text": "And while I was reading that, I was already typing the response and they had to publish it."}, {"time": 1217, "text": "Because I was right, that there is no evidence, no physical evidence for that."}, {"time": 1225, "text": "So there's an alternative explanation where everything that we consider random is actually pseudo random, such as the decimal expansion of pi, 3.141 and so on, which looks random, but isn't."}, {"time": 1241, "text": "So pi is interesting because every three digits sequence, every sequence of three digits appears roughly one in a thousand times."}, {"time": 1253, "text": "And every five digit sequence appears roughly one in 10,000 times, what you would expect if it was random."}, {"time": 1264, "text": "But there's a very short algorithm, a short program that computes all of that."}, {"time": 1269, "text": "So it's extremely compressible."}, {"time": 1271, "text": "And who knows, maybe tomorrow, somebody, some grad student at CERN goes back over all these data points, better decay and whatever, and figures out, oh, it's the second billion digits of pi or something like that."}, {"time": 1286, "text": "We don't have any fundamental reason at the moment to believe that this is truly random and not just a deterministic video game."}, {"time": 1296, "text": "If it was a deterministic video game, it would be much more beautiful."}, {"time": 1300, "text": "Because beauty is simplicity."}, {"time": 1303, "text": "And many of the basic laws of the universe, like gravity and the other basic forces are very simple."}, {"time": 1311, "text": "So very short programs can explain what these are doing."}, {"time": 1316, "text": "And it would be awful and ugly."}, {"time": 1320, "text": "The universe would be ugly."}, {"time": 1321, "text": "The history of the universe would be ugly if for the extra things, the random, the seemingly random data points that we get all the time, that we really need a huge number of extra bits to describe all these extra bits of information."}, {"time": 1342, "text": "So as long as we don't have evidence that there is no short program that computes the entire history of the entire universe, we are, as scientists, compelled to look further for that shortest program."}, {"time": 1359, "text": "Your intuition says there exists a program that can backtrack to the creation of the universe."}, {"time": 1368, "text": "So it can give the shortest path to the creation of the universe."}, {"time": 1371, "text": "Including all the entanglement things and all the spin up and down measures that have been taken place since 13.8 billion years ago."}, {"time": 1386, "text": "So we don't have a proof that it is random."}, {"time": 1391, "text": "We don't have a proof that it is compressible to a short program."}, {"time": 1396, "text": "But as long as we don't have that proof, we are obliged as scientists to keep looking for that simple explanation."}, {"time": 1404, "text": "So you said the simplicity is beautiful or beauty is simple."}, {"time": 1407, "text": "Either one works."}, {"time": 1409, "text": "But you also work on curiosity, discovery, the romantic notion of randomness, of serendipity, of being surprised by things that are about you."}, {"time": 1425, "text": "In our poetic notion of reality, we think it's kind of like, poetic notion of reality, we think as humans require randomness."}, {"time": 1436, "text": "So you don't find randomness beautiful."}, {"time": 1439, "text": "You find simple determinism beautiful."}, {"time": 1449, "text": "Because the explanation becomes shorter."}, {"time": 1453, "text": "A universe that is compressible to a short program is much more elegant and much more beautiful than another one, which needs an almost infinite number of bits to be described."}, {"time": 1468, "text": "As far as we know, many things that are happening in this universe are really simple in terms of short programs that compute gravity and the interaction between elementary particles and so on."}, {"time": 1483, "text": "So all of that seems to be very, very simple."}, {"time": 1485, "text": "Every electron seems to reuse the same subprogram all the time, as it is interacting with other elementary particles."}, {"time": 1498, "text": "If we now require an extra oracle injecting new bits of information all the time for these extra things which are currently not understood, such as better decay, then the whole description length of the data that we can observe of the history of the universe would become much longer and therefore uglier."}, {"time": 1533, "text": "And uglier."}, {"time": 1534, "text": "Again, simplicity is elegant and beautiful."}, {"time": 1538, "text": "The history of science is a history of compression progress."}, {"time": 1542, "text": "Yes, so you've described sort of as we build up abstractions and you've talked about the idea of compression."}, {"time": 1552, "text": "How do you see this, the history of science, the history of humanity, our civilization, and life on Earth as some kind of path towards greater and greater compression?"}, {"time": 1564, "text": "What do you mean by that?"}, {"time": 1565, "text": "How do you think about that?"}, {"time": 1566, "text": "Indeed, the history of science is a history of compression progress."}, {"time": 1572, "text": "What does that mean?"}, {"time": 1574, "text": "Hundreds of years ago there was an astronomer whose name was Kepler and he looked at the data points that he got by watching planets move."}, {"time": 1585, "text": "And then he had all these data points and suddenly it turned out that he can greatly compress the data by predicting it through an ellipse law."}, {"time": 1598, "text": "So it turns out that all these data points are more or less on ellipses around the sun."}, {"time": 1605, "text": "And another guy came along whose name was Newton and before him Hooke."}, {"time": 1611, "text": "And they said the same thing that is making these planets move like that is what makes the apples fall down."}, {"time": 1622, "text": "And it also holds for stones and for all kinds of other objects."}, {"time": 1631, "text": "And suddenly many, many of these observations became much more compressible because as long as you can predict the next thing, given what you have seen so far, you can compress it."}, {"time": 1643, "text": "And you don't have to store that data extra."}, {"time": 1645, "text": "This is called predictive coding."}, {"time": 1649, "text": "And then there was still something wrong with that theory of the universe and you had deviations from these predictions of the theory."}, {"time": 1657, "text": "And 300 years later another guy came along whose name was Einstein."}, {"time": 1662, "text": "And he was able to explain away all these deviations from the predictions of the old theory through a new theory which was called the general theory of relativity."}, {"time": 1677, "text": "Which at first glance looks a little bit more complicated and you have to warp space and time but you can't phrase it within one single sentence which is no matter how fast you accelerate and how hard you decelerate and no matter what is the gravity in your local network, light speed always looks the same."}, {"time": 1701, "text": "And from that you can calculate all the consequences."}, {"time": 1705, "text": "So it's a very simple thing and it allows you to further compress all the observations because certainly there are hardly any deviations any longer that you can measure from the predictions of this new theory."}, {"time": 1720, "text": "So all of science is a history of compression progress."}, {"time": 1725, "text": "You never arrive immediately at the shortest explanation of the data but you're making progress."}, {"time": 1732, "text": "Whenever you are making progress you have an insight."}, {"time": 1736, "text": "You see oh first I needed so many bits of information to describe the data, to describe my falling apples, my video of falling apples, I need so many data, so many pixels have to be stored."}, {"time": 1748, "text": "But then suddenly I realize no there is a very simple way of predicting the third frame in the video from the first two."}, {"time": 1756, "text": "And maybe not every little detail can be predicted but more or less most of these orange blobs that are coming down they accelerate in the same way which means that I can greatly compress the video."}, {"time": 1768, "text": "And the amount of compression, progress, that is the depth of the insight that you have at that moment."}, {"time": 1777, "text": "That's the fun that you have, the scientific fun, the fun in that discovery."}, {"time": 1782, "text": "And we can build artificial systems that do the same thing."}, {"time": 1786, "text": "They measure the depth of their insights as they are looking at the data which is coming in through their own experiments and we give them a reward, an intrinsic reward in proportion to this depth of insight."}, {"time": 1800, "text": "And since they are trying to maximize the rewards they get they are suddenly motivated to come up with new action sequences, with new experiments that have the property that the data that is coming in as a consequence of these experiments has the property that they can learn something about, see a pattern in there which they hadn't seen yet before."}, {"time": 1828, "text": "So there is an idea of power play that you described, a training in general problem solver in this kind of way of looking for the unsolved problems."}, {"time": 1838, "text": "Can you describe that idea a little further?"}, {"time": 1840, "text": "It's another very simple idea."}, {"time": 1842, "text": "So normally what you do in computer science, you have some guy who gives you a problem and then there is a huge search space of potential solution candidates and you somehow try them out and you have more less sophisticated ways of moving around in that search space until you finally found a solution which you consider satisfactory."}, {"time": 1872, "text": "That's what most of computer science is about."}, {"time": 1875, "text": "Power play just goes one little step further and says let's not only search for solutions to a given problem but let's search to pairs of problems and their solutions where the system itself has the opportunity to phrase its own problem."}, {"time": 1897, "text": "So we are looking suddenly at pairs of problems and their solutions or modifications of the problem solver that is supposed to generate a solution to that new problem."}, {"time": 1911, "text": "And this additional degree of freedom allows us to build career systems that are like scientists in the sense that they not only try to solve and try to find answers to existing questions, no they are also free to pose their own questions."}, {"time": 1933, "text": "So if you want to build an artificial scientist you have to give it that freedom and power play is exactly doing that."}, {"time": 1939, "text": "So that's a dimension of freedom that's important to have but how hard do you think that, how multidimensional and difficult the space of then coming up with your own questions is."}, {"time": 1955, "text": "So it's one of the things that as human beings we consider to be the thing that makes us special, the intelligence that makes us special is that brilliant insight that can create something totally new."}, {"time": 1969, "text": "So now let's look at the extreme case, let's look at the set of all possible problems that you can formally describe which is infinite, which should be the next problem that a scientist or power play is going to solve."}, {"time": 1988, "text": "Well, it should be the easiest problem that goes beyond what you already know."}, {"time": 1997, "text": "So it should be the simplest problem that the current problem solver that you have which can already solve 100 problems that he cannot solve yet by just generalizing."}, {"time": 2010, "text": "So it has to be new, so it has to require a modification of the problem solver such that the new problem solver can solve this new thing but the old problem solver cannot do it and in addition to that we have to make sure that the problem solver doesn't forget any of the previous solutions."}, {"time": 2031, "text": "And so by definition power play is now trying always to search in this pair of, in the set of pairs of problems and problems over modifications for a combination that minimize the time to achieve these criteria."}, {"time": 2048, "text": "So it's always trying to find the problem which is easiest to add to the repertoire."}, {"time": 2054, "text": "So just like grad students and academics and researchers can spend their whole career in a local minima stuck trying to come up with interesting questions but ultimately doing very little."}, {"time": 2067, "text": "Do you think it's easy in this approach of looking for the simplest unsolvable problem to get stuck in a local minima?"}, {"time": 2075, "text": "Is not never really discovering new, you know really jumping outside of the 100 problems that you've already solved in a genuine creative way?"}, {"time": 2087, "text": "No, because that's the nature of power play that it's always trying to break its current generalization abilities by coming up with a new problem which is beyond the current horizon."}, {"time": 2100, "text": "Just shifting the horizon of knowledge a little bit out there, breaking the existing rules such that the new thing becomes solvable but wasn't solvable by the old thing."}, {"time": 2135, "text": "So in the paper with the amazing title, Formal Theory of Creativity, Fun and Intrinsic Motivation, you talk about discovery as intrinsic reward, so if you view humans as intelligent agents, what do you think is the purpose and meaning of life for us humans?"}, {"time": 2156, "text": "You've talked about this discovery, do you see humans as an instance of power play, agents?"}, {"time": 2164, "text": "Humans are curious and that means they behave like scientists, not only the official scientists but even the babies behave like scientists and they play around with their toys to figure out how the world works and how it is responding to their actions and that's how they learn about gravity and everything."}, {"time": 2187, "text": "In 1990 we had the first systems like that which would just try to play around with the environment and come up with situations that go beyond what they knew at that time and then get a reward for creating these situations and then becoming more general problem solvers and being able to understand more of the world."}, {"time": 2209, "text": "I think in principle that curiosity strategy or more sophisticated versions of what I just described, they are what we have built in as well because evolution discovered that's a good way of exploring the unknown world and a guy who explores the unknown world has a higher chance of solving the mystery that he needs to survive in this world."}, {"time": 2240, "text": "On the other hand, those guys who were too curious they were weeded out as well so you have to find this trade off."}, {"time": 2248, "text": "Evolution found a certain trade off."}, {"time": 2250, "text": "Apparently in our society there is a certain percentage of extremely explorative guys and it doesn't matter if they die because many of the others are more conservative."}, {"time": 2265, "text": "It would be surprising to me if that principle of artificial curiosity wouldn't be present in almost exactly the same form here."}, {"time": 2278, "text": "In our brains."}, {"time": 2280, "text": "You are a bit of a musician and an artist."}, {"time": 2283, "text": "Continuing on this topic of creativity, what do you think is the role of creativity and intelligence?"}, {"time": 2290, "text": "So you've kind of implied that it's essential for intelligence if you think of intelligence as a problem solving system, as ability to solve problems."}, {"time": 2303, "text": "But do you think it's essential, this idea of creativity?"}, {"time": 2307, "text": "We never have a program, a sub program that is called creativity or something."}, {"time": 2314, "text": "It's just a side effect of what our problem solvers do."}, {"time": 2317, "text": "They are searching a space of problems, a space of candidates, of solution candidates until they hopefully find a solution to a given problem."}, {"time": 2328, "text": "But then there are these two types of creativity and both of them are now present in our machines."}, {"time": 2334, "text": "The first one has been around for a long time, which is human gives problem to machine, machine tries to find a solution to that."}, {"time": 2343, "text": "And this has been happening for many decades and for many decades machines have found creative solutions to interesting problems where humans were not aware of these particularly creative solutions but then appreciated that the machine found that."}, {"time": 2360, "text": "The second is the pure creativity."}, {"time": 2363, "text": "That I would call, what I just mentioned, I would call the applied creativity, like applied art where somebody tells you now make a nice picture of this Pope and you will get money for that."}, {"time": 2377, "text": "So here is the artist and he makes a convincing picture of the Pope and the Pope likes it and gives him the money."}, {"time": 2386, "text": "And then there is the pure creativity which is more like the power play and the artificial curiosity thing where you have the freedom to select your own problem."}, {"time": 2397, "text": "Like a scientist who defines his own question to study and so that is the pure creativity if you will as opposed to the applied creativity which serves another."}, {"time": 2414, "text": "And in that distinction there is almost echoes of narrow AI versus general AI."}, {"time": 2419, "text": "So this kind of constrained painting of a Pope seems like the approaches of what people are calling narrow AI and pure creativity seems to be, maybe I am just biased as a human but it seems to be an essential element of human level intelligence."}, {"time": 2441, "text": "Is that what you are implying?"}, {"time": 2444, "text": "To a degree?"}, {"time": 2446, "text": "If you zoom back a little bit and you just look at a general problem solving machine which is trying to solve arbitrary problems then this machine will figure out in the course of solving problems that it is good to be curious."}, {"time": 2460, "text": "So all of what I said just now about this prewired curiosity and this will to invent new problems that the system doesn't know how to solve yet should be just a byproduct of the general search."}, {"time": 2475, "text": "However, apparently evolution has built it into us because it turned out to be so successful, a prewiring, a bias, a very successful exploratory bias that we are born with."}, {"time": 2494, "text": "And you have also said that consciousness in the same kind of way may be a byproduct of problem solving."}, {"time": 2501, "text": "Do you find this an interesting byproduct?"}, {"time": 2505, "text": "Do you think it is a useful byproduct?"}, {"time": 2507, "text": "What are your thoughts on consciousness in general?"}, {"time": 2509, "text": "Or is it simply a byproduct of greater and greater capabilities of problem solving that is similar to creativity in that sense?"}, {"time": 2521, "text": "We never have a procedure called consciousness in our machines."}, {"time": 2525, "text": "However, we get as side effects of what these machines are doing things that seem to be closely related to what people call consciousness."}, {"time": 2536, "text": "So for example, already in 1990 we had simple systems which were basically recurrent networks and therefore universal computers trying to map incoming data into actions that lead to success."}, {"time": 2553, "text": "Maximizing reward in a given environment, always finding the charging station in time whenever the battery is low and negative signals are coming from the battery, always find the charging station in time without bumping against painful obstacles on the way."}, {"time": 2570, "text": "So complicated things but very easily motivated."}, {"time": 2574, "text": "And then we give these little guys a separate recurrent neural network which is just predicting what's happening if I do that and that."}, {"time": 2584, "text": "What will happen as a consequence of these actions that I'm executing."}, {"time": 2589, "text": "And it's just trained on the long and long history of interactions with the world."}, {"time": 2593, "text": "So it becomes a predictive model of the world basically."}, {"time": 2598, "text": "And therefore also a compressor of the observations of the world because whatever you can predict you don't have to store extra."}, {"time": 2607, "text": "So compression is a side effect of prediction."}, {"time": 2610, "text": "And how does this recurrent network compress?"}, {"time": 2613, "text": "Well, it's inventing little subprograms, little subnetworks that stand for everything that frequently appears in the environment like bottles and microphones and faces, maybe lots of faces in my environment so I'm learning to create something like a prototype face and a new face comes along and all I have to encode are the deviations from the prototype."}, {"time": 2636, "text": "So it's compressing all the time the stuff that frequently appears."}, {"time": 2640, "text": "There's one thing that appears all the time that is present all the time when the agent is interacting with its environment which is the agent itself."}, {"time": 2652, "text": "But just for data compression reasons it is extremely natural for this recurrent network to come up with little subnetworks that stand for the properties of the agents, the hand, the other actuators and all the stuff that you need to better encode the data which is influenced by the actions of the agent."}, {"time": 2674, "text": "So there just as a side effect of data compression during problem solving you have internal self models."}, {"time": 2685, "text": "Now you can use this model of the world to plan your future and that's what we also have done since 1990."}, {"time": 2694, "text": "So the recurrent network which is the controller which is trying to maximize reward can use this model of the network of the world, this model network of the world, this predictive model of the world to plan ahead and say let's not do this action sequence, let's do this action sequence instead because it leads to more predicted reward."}, {"time": 2714, "text": "And whenever it is waking up these little subnetworks that stand for itself then it is thinking about itself and it is thinking about itself and it is exploring mentally the consequences of its own actions and now you tell me what is still missing."}, {"time": 2736, "text": "Missing the next, the gap to consciousness."}, {"time": 2741, "text": "That's a really beautiful idea that if life is a collection of data and life is a process of compressing that data to act efficiently in that data you yourself appear very often."}, {"time": 2757, "text": "So it's useful to form compressions of yourself and it's a really beautiful formulation of what consciousness is a necessary side effect."}, {"time": 2765, "text": "It's actually quite compelling to me."}, {"time": 2771, "text": "You've described RNNs, developed LSTMs, long short term memory networks that are a type of recurrent neural networks that have gotten a lot of success recently."}, {"time": 2784, "text": "So these are networks that model the temporal aspects in the data, temporal patterns in the data and you've called them the deepest of the neural networks."}, {"time": 2795, "text": "So what do you think is the value of depth in the models that we use to learn?"}, {"time": 2801, "text": "Since you mentioned the long short term memory and the LSTM I have to mention the names of the brilliant students who made that possible."}, {"time": 2812, "text": "First of all my first student ever Sepp Hochreiter who had fundamental insights already in his diploma thesis."}, {"time": 2819, "text": "Then Felix Geers who had additional important contributions."}, {"time": 2824, "text": "Alex Gray is a guy from Scotland who is mostly responsible for this CTC algorithm which is now often used to train the LSTM to do the speech recognition on all the Google Android phones and whatever and Siri and so on."}, {"time": 2841, "text": "So these guys without these guys I would be nothing."}, {"time": 2847, "text": "It's a lot of incredible work."}, {"time": 2849, "text": "What is now the depth?"}, {"time": 2850, "text": "What is the importance of depth?"}, {"time": 2852, "text": "Well most problems in the real world are deep in the sense that the current input doesn't tell you all you need to know about the environment."}, {"time": 2864, "text": "So instead you have to have a memory of what happened in the past and often important parts of that memory are dated."}, {"time": 2874, "text": "They are pretty old."}, {"time": 2876, "text": "So when you're doing speech recognition for example and somebody says 11 then that's about half a second or something like that which means it's already 50 time steps."}, {"time": 2891, "text": "And another guy or the same guy says 7."}, {"time": 2895, "text": "So the ending is the same even but now the system has to see the distinction between 7 and 11 and the only way it can see the difference is it has to store that 50 steps ago there was an S or an L, 11 or 7."}, {"time": 2914, "text": "So there you have already a problem of depth 50 because for each time step you have something like a virtual layer in the expanded unrolled version of this recurrent network which is doing the speech recognition."}, {"time": 2928, "text": "So these long time lags they translate into problem depth."}, {"time": 2933, "text": "And most problems in this world are such that you really have to look far back in time to understand what is the problem and to solve it."}, {"time": 2945, "text": "But just like with LSTMs you don't necessarily need to when you look back in time remember every aspect you just need to remember the important aspects."}, {"time": 2955, "text": "The network has to learn to put the important stuff into memory and to ignore the unimportant noise."}, {"time": 2963, "text": "But in that sense deeper and deeper is better or is there a limitation?"}, {"time": 2970, "text": "I mean LSTM is one of the great examples of architectures that do something beyond just deeper and deeper networks."}, {"time": 2982, "text": "There's clever mechanisms for filtering data, for remembering and forgetting."}, {"time": 2987, "text": "So do you think that kind of thinking is necessary?"}, {"time": 2991, "text": "If you think about LSTMs as a leap, a big leap forward over traditional vanilla RNNs, what do you think is the next leap within this context?"}, {"time": 3002, "text": "So LSTM is a very clever improvement but LSTM still don't have the same kind of ability to see far back in the past as us humans do."}, {"time": 3014, "text": "The credit assignment problem across way back not just 50 time steps or 100 or 1000 but millions and billions."}, {"time": 3024, "text": "It's not clear what are the practical limits of the LSTM when it comes to looking back."}, {"time": 3031, "text": "Already in 2006 I think we had examples where it not only looked back tens of thousands of steps but really millions of steps."}, {"time": 3041, "text": "And Juan Perez Ortiz in my lab I think was the first author of a paper where we really, was it 2006 or something, had examples where it learned to look back for more than 10 million steps."}, {"time": 3057, "text": "So for most problems of speech recognition it's not necessary to look that far back but there are examples where it does."}, {"time": 3067, "text": "Now the looking back thing, that's rather easy because there is only one past but there are many possible futures and so a reinforcement learning system which is trying to maximize its future expected reward and doesn't know yet which of these many possible futures should I select given this one single past is facing problems that the LSTM by itself cannot solve."}, {"time": 3096, "text": "So the LSTM is good for coming up with a compact representation of the history and observations and actions so far but now how do you plan in an efficient and good way among all these, how do you select one of these many possible action sequences that a reinforcement learning system has to consider to maximize reward in this unknown future?"}, {"time": 3126, "text": "We have this basic setup where you have one recurrent network which gets in the video and the speech and whatever and it's executing actions and it's trying to maximize reward so there is no teacher who tells it what to do at which point in time."}, {"time": 3145, "text": "And then there's the other network which is just predicting what's going to happen if I do that and that and that could be an LSTM network and it learns to look back all the way to make better predictions of the next time step."}, {"time": 3161, "text": "So essentially although it's predicting only the next time step it is motivated to learn to put into memory something that happened maybe a million steps ago because it's important to memorize that if you want to predict that at the next time step, the next event."}, {"time": 3179, "text": "Now how can a model of the world like that, a predictive model of the world be used by the first guy?"}, {"time": 3187, "text": "Let's call it the controller and the model, the controller and the model."}, {"time": 3192, "text": "How can the model be used by the controller to efficiently select among these many possible futures?"}, {"time": 3199, "text": "The naive way we had about 30 years ago was let's just use the model of the world as a stand in, as a simulation of the world and millisecond by millisecond we plan the future and that means we have to roll it out really in detail and it will work only if the model is really good and it will still be inefficient because we have to look at all these possible futures and there are so many of them."}, {"time": 3226, "text": "So instead what we do now since 2015 in our CM systems, controller model systems, we give the controller the opportunity to learn by itself how to use the potentially relevant parts of the M, of the model network to solve new problems more quickly."}, {"time": 3245, "text": "And if it wants to, it can learn to ignore the M and sometimes it's a good idea to ignore the M because it's really bad, it's a bad predictor in this particular situation of life where the controller is currently trying to maximize reward."}, {"time": 3262, "text": "However, it can also learn to address and exploit some of the subprograms that came about in the model network through compressing the data by predicting it."}, {"time": 3276, "text": "So it now has an opportunity to reuse that code, the algorithmic information in the model network to reduce its own search space such that it can solve a new problem more quickly than without the model."}, {"time": 3293, "text": "Compression."}, {"time": 3294, "text": "So you're ultimately optimistic and excited about the power of RL, of reinforcement learning in the context of real systems."}, {"time": 3306, "text": "So you see RL as a potential having a huge impact beyond just sort of the M part is often developed on supervised learning methods."}, {"time": 3319, "text": "You see RL as a for problems of self driving cars or any kind of applied cyber robotics."}, {"time": 3328, "text": "That's the correct interesting direction for research in your view?"}, {"time": 3334, "text": "I do think so."}, {"time": 3335, "text": "We have a company called Nasence which has applied reinforcement learning to little Audis which learn to park without a teacher."}, {"time": 3347, "text": "The same principles were used of course."}, {"time": 3350, "text": "So these little Audis, they are small, maybe like that, so much smaller than the real Audis."}, {"time": 3357, "text": "But they have all the sensors that you find in the real Audis."}, {"time": 3361, "text": "You find the cameras, the LIDAR sensors."}, {"time": 3363, "text": "They go up to 120 kilometers an hour if they want to."}, {"time": 3369, "text": "And they have pain sensors basically and they don't want to bump against obstacles and other Audis and so they must learn like little babies to park."}, {"time": 3381, "text": "Take the raw vision input and translate that into actions that lead to successful parking behavior which is a rewarding thing."}, {"time": 3390, "text": "And yes, they learn that."}, {"time": 3392, "text": "So we have examples like that and it's only in the beginning."}, {"time": 3397, "text": "This is just the tip of the iceberg and I believe the next wave of AI is going to be all about that."}, {"time": 3404, "text": "So at the moment, the current wave of AI is about passive pattern observation and prediction and that's what you have on your smartphone and what the major companies on the Pacific Rim are using to sell you ads to do marketing."}, {"time": 3422, "text": "That's the current sort of profit in AI and that's only one or two percent of the world economy."}, {"time": 3428, "text": "Which is big enough to make these companies pretty much the most valuable companies in the world."}, {"time": 3435, "text": "But there's a much, much bigger fraction of the economy going to be affected by the next wave which is really about machines that shape the data through their own actions."}, {"time": 3447, "text": "Do you think simulation is ultimately the biggest way that those methods will be successful in the next 10, 20 years?"}, {"time": 3456, "text": "We're not talking about 100 years from now."}, {"time": 3458, "text": "We're talking about sort of the near term impact of RL."}, {"time": 3462, "text": "Do you think really good simulation is required or is there other techniques like imitation learning, observing other humans operating in the real world?"}, {"time": 3473, "text": "Where do you think the success will come from?"}, {"time": 3477, "text": "So at the moment, we have a tendency of using physics simulations to learn behavior from machines that learn to solve problems that humans also do not know how to solve."}, {"time": 3492, "text": "However, this is not the future because the future is in what little babies do."}, {"time": 3498, "text": "They don't use a physics engine to simulate the world."}, {"time": 3502, "text": "No, they learn a predictive model of the world which maybe sometimes is wrong in many ways but captures all kinds of important abstract high level predictions which are really important to be successful."}, {"time": 3517, "text": "And that's what was the future 30 years ago when we started that type of research but it's still the future and now we know much better how to go there to move forward and to really make working systems based on that where you have a learning model of the world, a model of the world that learns to predict what's going to happen if I do that and that."}, {"time": 3541, "text": "And then the controller uses that model to more quickly learn successful action sequences."}, {"time": 3550, "text": "And then of course always this curiosity thing."}, {"time": 3553, "text": "In the beginning, the model is stupid so the controller should be motivated to come up with experiments with action sequences that lead to data that improve the model."}, {"time": 3563, "text": "Do you think improving the model, constructing an understanding of the world in this connection is now the popular approaches that have been successful are grounded in ideas of neural networks."}, {"time": 3578, "text": "But in the 80s with expert systems, there's symbolic AI approaches which to us humans are more intuitive in the sense that it makes sense that you build up knowledge in this knowledge representation."}, {"time": 3592, "text": "What kind of lessons can we draw into our current approaches from expert systems from symbolic AI?"}, {"time": 3600, "text": "So I became aware of all of that in the 80s and back then logic programming was a huge thing."}, {"time": 3608, "text": "Was it inspiring to you yourself?"}, {"time": 3610, "text": "Did you find it compelling?"}, {"time": 3612, "text": "Because a lot of your work was not so much in that realm, right?"}, {"time": 3617, "text": "It was more in the learning systems."}, {"time": 3618, "text": "Yes and no, but we did all of that."}, {"time": 3620, "text": "So my first publication ever actually was 1987, was the implementation of genetic algorithm of a genetic programming system in Prolog."}, {"time": 3634, "text": "So Prolog, that's what you learn back then which is a logic programming language and the Japanese, they have this huge fifth generation AI project which was mostly about logic programming back then."}, {"time": 3649, "text": "Although neural networks existed and were well known back then and deep learning has existed since 1965, since this guy in the Ukraine, Iwakunenko, started it."}, {"time": 3662, "text": "But the Japanese and many other people, they focused really on this logic programming and I was influenced to the extent that I said, okay, let's take these biologically inspired algorithms like evolution, programs, and implement that in the language which I know, which was Prolog, for example, back then."}, {"time": 3696, "text": "Well, Markus Futter's universal algorithm for solving all well defined problems has a proof searcher on board so that's very much logic programming."}, {"time": 3706, "text": "Without that it would not be asymptotically optimal."}, {"time": 3710, "text": "But then on the other hand, because we are very pragmatic guys also, we focused on recurrent neural networks and suboptimal stuff such as gradient based search and program space rather than provably optimal things."}, {"time": 3729, "text": "The logic programming certainly has a usefulness when you're trying to construct something provably optimal or provably good or something like that."}, {"time": 3739, "text": "But is it useful for practical problems?"}, {"time": 3742, "text": "It's really useful for our theorem proving."}, {"time": 3744, "text": "The best theorem provers today are not neural networks."}, {"time": 3748, "text": "No, they are logic programming systems and they are much better theorem provers than most math students in the first or second semester."}, {"time": 3758, "text": "But for reasoning, for playing games of Go or chess or for robots, autonomous vehicles that operate in the real world or object manipulation, you think learning."}, {"time": 3771, "text": "Yeah, as long as the problems have little to do with theorem proving themselves, then as long as that is not the case, you just want to have better pattern recognition."}, {"time": 3785, "text": "So to build a self driving car, you want to have better pattern recognition and pedestrian recognition and all these things."}, {"time": 3794, "text": "You want to minimize the number of false positives, which is currently slowing down self driving cars in many ways."}, {"time": 3803, "text": "All of that has very little to do with logic programming."}, {"time": 3807, "text": "What are you most excited about in terms of directions of artificial intelligence at this moment in the next few years in your own research and in the broader community?"}, {"time": 3821, "text": "So I think in the not so distant future, we will have for the first time little robots that learn like kids."}, {"time": 3833, "text": "I will be able to say to the robot, look here robot, we are going to assemble a smartphone."}, {"time": 3841, "text": "Let's take this slab of plastic and the screwdriver and let's screw in the screw like that."}, {"time": 3849, "text": "Not like that, like that."}, {"time": 3854, "text": "And I don't have a data glove or something."}, {"time": 3857, "text": "He will see me and he will hear me and he will try to do something with his own actuators, which will be really different from mine, but he will understand the difference and will learn to imitate me, but not in the supervised way where a teacher is giving target signals for all his muscles all the time."}, {"time": 3880, "text": "No, by doing this high level imitation where he first has to learn to imitate me and then to interpret these additional noises coming from my mouth as helping, helpful signals to do that better."}, {"time": 3894, "text": "And then it will by itself come up with faster ways and more efficient ways of doing the same thing."}, {"time": 3903, "text": "And finally I stop his learning algorithm and make a million copies and sell it."}, {"time": 3910, "text": "And so at the moment this is not possible, but we already see how we are going to get there."}, {"time": 3916, "text": "And you can imagine to the extent that this works economically and cheaply, it's going to change everything."}, {"time": 3925, "text": "Almost all of production is going to be affected by that."}, {"time": 3931, "text": "And a much bigger wave, a much bigger AI wave is coming than the one that we are currently witnessing, which is mostly about passive pattern recognition on your smartphone."}, {"time": 3942, "text": "This is about active machines that shapes data through the actions they are executing and they learn to do that in a good way."}, {"time": 3952, "text": "So many of the traditional industries are going to be affected by that."}, {"time": 3957, "text": "All the companies that are building machines will equip these machines with cameras and other sensors and they are going to learn to solve all kinds of problems through interaction with humans, but also a lot on their own to improve what they already can do."}, {"time": 3980, "text": "And lots of old economy is going to be affected by that."}, {"time": 3984, "text": "And in recent years I have seen that old economy is actually waking up and realizing that this is the case."}, {"time": 3992, "text": "Are you optimistic about that future?"}, {"time": 3994, "text": "Are you concerned?"}, {"time": 3996, "text": "There is a lot of people concerned in the near term about the transformation of the nature of work, the kind of ideas that you just suggested would have a significant impact of what kind of things could be automated."}, {"time": 4012, "text": "Are you nervous about that future?"}, {"time": 4014, "text": "And looking a little bit farther into the future, there are people like Gila Musk, Stuart Russell, concerned about the existential threats of that future."}, {"time": 4026, "text": "So in the near term, job loss, in the long term existential threat, are these concerns to you or are you ultimately optimistic?"}, {"time": 4035, "text": "So let's first address the near future."}, {"time": 4042, "text": "We have had predictions of job losses for many decades."}, {"time": 4048, "text": "For example, when industrial robots came along, many people predicted that lots of jobs are going to get lost."}, {"time": 4058, "text": "And in a sense, they were right, because back then there were car factories and hundreds of people in these factories assembled cars, and today the same car factories have hundreds of robots and maybe three guys watching the robots."}, {"time": 4079, "text": "On the other hand, those countries that have lots of robots per capita, Japan, Korea, Germany, Switzerland, and a couple of other countries, they have really low unemployment rates."}, {"time": 4094, "text": "Somehow, all kinds of new jobs were created."}, {"time": 4098, "text": "Back then, nobody anticipated those jobs."}, {"time": 4103, "text": "And decades ago, I always said, it's really easy to say which jobs are going to get lost, but it's really hard to predict the new ones."}, {"time": 4116, "text": "200 years ago, who would have predicted all these people making money as YouTube bloggers, for example?"}, {"time": 4126, "text": "200 years ago, 60% of all people used to work in agriculture."}, {"time": 4134, "text": "Today, maybe 1%."}, {"time": 4137, "text": "But still, only, I don't know, 5% unemployment."}, {"time": 4142, "text": "Lots of new jobs were created, and Homo Ludens, the playing man, is inventing new jobs all the time."}, {"time": 4151, "text": "Most of these jobs are not existentially necessary for the survival of our species."}, {"time": 4159, "text": "There are only very few existentially necessary jobs, such as farming and building houses and warming up the houses, but less than 10% of the population is doing that."}, {"time": 4171, "text": "And most of these newly invented jobs are about interacting with other people in new ways, through new media and so on, getting new types of kudos and forms of likes and whatever, and even making money through that."}, {"time": 4188, "text": "So, Homo Ludens, the playing man, doesn't want to be unemployed, and that's why he's inventing new jobs all the time."}, {"time": 4197, "text": "And he keeps considering these jobs as really important and is investing a lot of energy and hours of work into those new jobs."}, {"time": 4208, "text": "That's quite beautifully put."}, {"time": 4210, "text": "We're really nervous about the future because we can't predict what kind of new jobs will be created."}, {"time": 4215, "text": "But you're ultimately optimistic that we humans are so restless that we create and give meaning to newer and newer jobs, totally new, things that get likes on Facebook or whatever the social platform is."}, {"time": 4232, "text": "So what about long term existential threat of AI, where our whole civilization may be swallowed up by these ultra super intelligent systems?"}, {"time": 4245, "text": "Maybe it's not going to be swallowed up, but I'd be surprised if we humans were the last step in the evolution of the universe."}, {"time": 4258, "text": "You've actually had this beautiful comment somewhere that I've seen saying that, quite insightful, artificial general intelligence systems, just like us humans, will likely not want to interact with humans, they'll just interact amongst themselves."}, {"time": 4278, "text": "Just like ants interact amongst themselves and only tangentially interact with humans."}, {"time": 4285, "text": "And it's quite an interesting idea that once we create AGI, they will lose interest in humans and compete for their own Facebook likes and their own social platforms."}, {"time": 4296, "text": "So within that quite elegant idea, how do we know in a hypothetical sense that there's not already intelligence systems out there?"}, {"time": 4309, "text": "How do you think broadly of general intelligence greater than us?"}, {"time": 4314, "text": "How do we know it's out there?"}, {"time": 4316, "text": "How do we know it's around us?"}, {"time": 4319, "text": "And could it already be?"}]}, {"title": "George Hotz: Comma.ai, OpenPilot, and Autonomous Vehicles | Lex Fridman Podcast #31", "id": "iwcYp-XT7UI", "quotes": [{"time": 226, "text": "I just read that you talked about escaping the simulation or something like that."}, {"time": 231, "text": "So maybe you can tell me a little bit about the theme and the message there too."}, {"time": 235, "text": "It wasn't a very practical talk about how to actually escape a simulation."}, {"time": 240, "text": "It was more about a way of restructuring an us versus them narrative."}, {"time": 245, "text": "If we continue on the path we're going with technology, I think we're in big trouble, like as a species and not just as a species, but even as me as an individual member of the species."}, {"time": 259, "text": "So if we could change rhetoric to be more like to think upwards, like to think about that we're in a simulation and how we could get out, already we'd be on the right path."}, {"time": 272, "text": "What you actually do once you do that, well, I assume I would have acquired way more intelligence in the process of doing that."}, {"time": 278, "text": "So I'll just ask that."}, {"time": 279, "text": "So the thinking upwards, what kind of ideas, what kind of breakthrough ideas do you think thinking in that way could inspire?"}, {"time": 287, "text": "And why did you say upwards?"}, {"time": 289, "text": "Upwards."}, {"time": 290, "text": "Into space?"}, {"time": 291, "text": "Are you thinking sort of exploration in all forms?"}, {"time": 294, "text": "The space narrative that held for the modernist generation doesn't hold as well for the postmodern generation."}, {"time": 304, "text": "What's the space narrative?"}, {"time": 305, "text": "Are we talking about the same space, the three dimensional space?"}, {"time": 307, "text": "No, no, no, space, like going on space, like building like Elon Musk, like we're going to build rockets, we're going to go to Mars, we're going to colonize the universe."}, {"time": 313, "text": "And the narrative you're referring, I was born in the Soviet Union, you're referring to the race to space."}, {"time": 317, "text": "The race to space, yeah."}, {"time": 318, "text": "Explore, okay."}, {"time": 319, "text": "That was a great modernist narrative."}, {"time": 323, "text": "It doesn't seem to hold the same weight in today's culture."}, {"time": 327, "text": "I'm hoping for good postmodern narratives that replace it."}, {"time": 332, "text": "So let's think, so you work a lot with AI."}, {"time": 335, "text": "So AI is one formulation of that narrative."}, {"time": 339, "text": "There could be also, I don't know how much you do in VR and AR."}, {"time": 343, "text": "That's another, I know less about it, but every time I play with it in our research, it's fascinating, that virtual world."}, {"time": 349, "text": "Are you interested in the virtual world?"}, {"time": 351, "text": "I would like to move to virtual reality."}, {"time": 355, "text": "In terms of your work?"}, {"time": 356, "text": "No, I would like to physically move there."}, {"time": 358, "text": "The apartment I can rent in the cloud is way better than the apartment I can rent in the real world."}, {"time": 363, "text": "Well, it's all relative, isn't it?"}, {"time": 364, "text": "Because others will have very nice apartments too, so you'll be inferior in the virtual world as well."}, {"time": 369, "text": "No, but that's not how I view the world, right?"}, {"time": 371, "text": "I don't view the world, I mean, it's a very almost zero sum ish way to view the world."}, {"time": 376, "text": "Say like, my great apartment isn't great because my neighbor has one too."}, {"time": 380, "text": "No, my great apartment is great because look at this dishwasher, man."}, {"time": 384, "text": "You just touch the dish and it's washed, right?"}, {"time": 386, "text": "And that is great in and of itself if I have the only apartment or if everybody had the apartment."}, {"time": 392, "text": "So you have fundamental gratitude."}, {"time": 394, "text": "The world first learned of George Hots in August 2007, maybe before then, but certainly in August 2007 when you were the first person to unlock, carry unlock an iPhone."}, {"time": 408, "text": "How did you get into hacking?"}, {"time": 410, "text": "What was the first system you discovered vulnerabilities for and broke into?"}, {"time": 416, "text": "So that was really kind of the first thing."}, {"time": 421, "text": "I had a book in 2006 called Grey Hat Hacking."}, {"time": 426, "text": "And I guess I realized that if you acquired these sort of powers, you could control the world."}, {"time": 436, "text": "But I didn't really know that much about computers back then."}, {"time": 440, "text": "I started with electronics."}, {"time": 442, "text": "The first iPhone hack was physical."}, {"time": 444, "text": "Cardware."}, {"time": 445, "text": "You had to open it up and pull an address line high."}, {"time": 448, "text": "And it was because I didn't really know about software exploitation."}, {"time": 451, "text": "I learned that all in the next few years and I got very good at it."}, {"time": 453, "text": "But back then I knew about like how memory chips are connected to processors and stuff."}, {"time": 458, "text": "You knew about software and programming."}, {"time": 460, "text": "You just didn't know."}, {"time": 464, "text": "So your view of the world and computers was physical, was hardware."}, {"time": 469, "text": "Actually, if you read the code that I released with that in August 2007, it's atrocious."}, {"time": 475, "text": "What language was it?"}, {"time": 476, "text": "C. C, nice."}, {"time": 478, "text": "And in a broken sort of state machine ask C. I didn't know how to program."}, {"time": 484, "text": "So how did you learn to program?"}, {"time": 487, "text": "What was your journey?"}, {"time": 488, "text": "Cause I mean, we'll talk about it."}, {"time": 490, "text": "You've live streamed some of your programming."}, {"time": 492, "text": "This chaotic, beautiful mess."}, {"time": 494, "text": "How did you arrive at that?"}, {"time": 496, "text": "Years and years of practice."}, {"time": 498, "text": "I interned at Google after the summer after the iPhone unlock."}, {"time": 504, "text": "And I did a contract for them where I built hardware for Street View and I wrote a software library to interact with it."}, {"time": 511, "text": "And it was terrible code."}, {"time": 514, "text": "And for the first time I got feedback from people who I respected saying, no, like don't write code like this."}, {"time": 522, "text": "Now, of course, just getting that feedback is not enough."}, {"time": 525, "text": "The way that I really got good was I wanted to write this thing like that could emulate and then visualize like arm binaries."}, {"time": 537, "text": "Cause I wanted to hack the iPhone better."}, {"time": 539, "text": "And I didn't like that I couldn't like see what the, I couldn't single step through the processor because I had no debugger on there, especially for the low level things like the boot rum and the bootloader."}, {"time": 547, "text": "So I tried to build this tool to do it."}, {"time": 550, "text": "And I built the tool once and it was terrible."}, {"time": 553, "text": "I built the tool a second time, it was terrible."}, {"time": 555, "text": "I built the tool a third time."}, {"time": 556, "text": "This was by the time I was at Facebook, it was kind of okay."}, {"time": 558, "text": "And then I built the tool a fourth time when I was a Google intern again in 2014."}, {"time": 562, "text": "And that was the first time I was like, this is finally usable."}, {"time": 565, "text": "How do you pronounce this Kira?"}, {"time": 567, "text": "Kira, yeah."}, {"time": 568, "text": "So it's essentially the most efficient way to visualize the change of state of the computer as the program is running."}, {"time": 577, "text": "That's what you mean by debugger."}, {"time": 578, "text": "Yeah, it's a timeless debugger."}, {"time": 581, "text": "So you can rewind just as easily as going forward."}, {"time": 585, "text": "Think about if you're using GDB, you have to put a watch on a variable."}, {"time": 587, "text": "If you wanna see if that variable changes."}, {"time": 589, "text": "In Kira, you can just click on that variable and then it shows every single time when that variable was changed or accessed."}, {"time": 596, "text": "Think about it like Git for your computers, the run log."}, {"time": 599, "text": "So there's like a deep log of the state of the computer as the program runs and you can rewind."}, {"time": 607, "text": "Why isn't that, maybe it is, maybe you can educate me."}, {"time": 611, "text": "Why isn't that kind of debugging used more often?"}, {"time": 614, "text": "Cause the tooling's bad."}, {"time": 616, "text": "Well, two things."}, {"time": 617, "text": "One, if you're trying to debug Chrome, Chrome is a 200 megabyte binary that runs slowly on desktops."}, {"time": 625, "text": "So that's gonna be really hard to use for that."}, {"time": 627, "text": "But it's really good to use for like CTFs and for boot roms and for small parts of code."}, {"time": 633, "text": "So it's hard if you're trying to debug like massive systems."}, {"time": 636, "text": "What's a CTF and what's a boot rom?"}, {"time": 638, "text": "A boot rom is the first code that executes the minute you give power to your iPhone."}, {"time": 643, "text": "And CTF where these competitions that I played capture the flag."}, {"time": 646, "text": "Capture the flag, I was gonna ask you about that."}, {"time": 648, "text": "What are those, look at, I watched a couple of videos on YouTube, those look fascinating."}, {"time": 652, "text": "What have you learned about maybe at the high level of vulnerability of systems from these competitions?"}, {"time": 660, "text": "I feel like in the heyday of CTFs, you had all of the best security people in the world challenging each other and coming up with new toy exploitable things over here."}, {"time": 673, "text": "And then everybody, okay, who can break it?"}, {"time": 675, "text": "And when you break it, you get like, there's like a file on the server called flag."}, {"time": 679, "text": "And then there's a program running, listening on a socket that's vulnerable."}, {"time": 682, "text": "So you write an exploit, you get a shell, and then you cat flag, and then you type the flag into like a web based scoreboard and you get points."}, {"time": 689, "text": "So the goal is essentially, to find an exploit in the system that allows you to run shell, to run arbitrary code on that system."}, {"time": 697, "text": "That's one of the categories."}, {"time": 700, "text": "That's like the pwnable category."}, {"time": 703, "text": "Pwnable?"}, {"time": 704, "text": "Yeah, pwnable."}, {"time": 705, "text": "It's like, you know, you pwn the program."}, {"time": 707, "text": "It's a program that's, yeah."}, {"time": 708, "text": "Yeah, you know, first of all, I apologize."}, {"time": 714, "text": "I'm gonna say it's because I'm Russian, but maybe you can help educate me."}, {"time": 720, "text": "Some video game like misspelled own way back in the day."}, {"time": 722, "text": "Yeah, and it's just, I wonder if there's a definition."}, {"time": 726, "text": "I'll have to go to Urban Dictionary for it."}, {"time": 728, "text": "It'll be interesting to see what it says."}, {"time": 729, "text": "Okay, so what was the heyday of CTF, by the way?"}, {"time": 732, "text": "But was it, what decade are we talking about?"}, {"time": 735, "text": "I think like, I mean, maybe unbiased because it's the era that I played, but like 2011 to 2015, because the modern CTF scene is similar to the modern competitive programming scene."}, {"time": 752, "text": "You have people who like do drills."}, {"time": 754, "text": "You have people who practice."}, {"time": 755, "text": "And then once you've done that, you've turned it less into a game of generic computer skill and more into a game of, okay, you drill on these five categories."}, {"time": 764, "text": "And then before that, it wasn't, it didn't have like as much attention as it had."}, {"time": 772, "text": "I don't know, they were like, I won $30,000 once in Korea for one of these competitions."}, {"time": 776, "text": "Holy crap."}, {"time": 776, "text": "Yeah, they were, they were, that was."}, {"time": 777, "text": "So that means, I mean, money is money, but that means there was probably good people there."}, {"time": 783, "text": "Are the challenges human constructed or are they grounded in some real flaws and real systems?"}, {"time": 790, "text": "Usually they're human constructed, but they're usually inspired by real flaws."}, {"time": 795, "text": "What kind of systems are imagined is really focused on mobile."}, {"time": 799, "text": "Like what has vulnerabilities these days?"}, {"time": 800, "text": "Is it primarily mobile systems like Android?"}, {"time": 805, "text": "Oh, everything does."}, {"time": 806, "text": "Yeah, of course."}, {"time": 808, "text": "The price has kind of gone up because less and less people can find them."}, {"time": 811, "text": "And what's happened in security is now if you want to like jailbreak an iPhone, you don't need one exploit anymore, you need nine."}, {"time": 817, "text": "Nine chained together, what would it mean?"}, {"time": 820, "text": "Okay, so it's really, what's the benefit speaking higher level philosophically about hacking?"}, {"time": 828, "text": "I mean, it sounds from everything I've seen about you, you just love the challenge and you don't want to do anything."}, {"time": 834, "text": "You don't want to bring that exploit out into the world and do any actual, let it run wild."}, {"time": 841, "text": "You just want to solve it and then you go on to the next thing."}, {"time": 845, "text": "Oh yeah, I mean, doing criminal stuff's not really worth it."}, {"time": 848, "text": "And I'll actually use the same argument for why I don't do defense for why I don't do crime."}, {"time": 855, "text": "If you want to defend a system, say the system has 10 holes, right?"}, {"time": 859, "text": "If you find nine of those holes as a defender, you still lose because the attacker gets in through the last one."}, {"time": 865, "text": "If you're an attacker, you only have to find one out of the 10."}, {"time": 868, "text": "But if you're a criminal, if you log on with a VPN nine out of the 10 times, but one time you forget, you're done."}, {"time": 877, "text": "Because you're caught, okay."}, {"time": 879, "text": "Because you only have to mess up once to be caught as a criminal."}, {"time": 882, "text": "That's why I'm not a criminal."}, {"time": 885, "text": "But okay, let me, because I was having a discussion with somebody just at a high level about nuclear weapons actually, why we're having blown ourselves up yet."}, {"time": 896, "text": "And my feeling is all the smart people in the world, if you look at the distribution of smart people, smart people are generally good."}, {"time": 906, "text": "And then this other person I was talking to, Sean Carroll, the physicist, and he was saying, no, good and bad people are evenly distributed amongst everybody."}, {"time": 913, "text": "My sense was good hackers are in general good people and they don't want to mess with the world."}, {"time": 920, "text": "What's your sense?"}, {"time": 921, "text": "I'm not even sure about that."}, {"time": 925, "text": "Like, I have a nice life."}, {"time": 930, "text": "Crime wouldn't get me anything."}, {"time": 934, "text": "But if you're good and you have these skills, you probably have a nice life too, right?"}, {"time": 938, "text": "Right, you can use it for other things."}, {"time": 940, "text": "But is there an ethical, is there a little voice in your head that says, well, yeah, if you could hack something to where you could hurt people and you could earn a lot of money doing it though, not hurt physically perhaps, but disrupt their life in some kind of way, isn't there a little voice that says?"}, {"time": 964, "text": "One, I don't really care about money."}, {"time": 966, "text": "So like the money wouldn't be an incentive."}, {"time": 968, "text": "The thrill might be an incentive."}, {"time": 970, "text": "But when I was 19, I read Crime and Punishment."}, {"time": 974, "text": "And that was another great one that talked me out of ever really doing crime."}, {"time": 979, "text": "Cause it's like, that's gonna be me."}, {"time": 981, "text": "I'd get away with it, but it would just run through my head."}, {"time": 985, "text": "Even if I got away with it, you know?"}, {"time": 986, "text": "And then you do crime for long enough, you'll never get away with it."}, {"time": 989, "text": "In the end, that's a good reason to be good."}, {"time": 992, "text": "I wouldn't say I'm good."}, {"time": 993, "text": "I would just say I'm not bad."}, {"time": 994, "text": "You're a talented programmer and a hacker in a good positive sense of the word."}, {"time": 1000, "text": "You've played around, found vulnerabilities in various systems."}, {"time": 1004, "text": "What have you learned broadly about the design of systems and so on from that whole process?"}, {"time": 1013, "text": "You learn to not take things for what people say they are, but you look at things for what they actually are."}, {"time": 1027, "text": "I understand that's what you tell me it is, but what does it do?"}, {"time": 1032, "text": "And you have nice visualization tools to really know what it's really doing."}, {"time": 1036, "text": "Oh, I wish."}, {"time": 1037, "text": "I'm a better programmer now than I was in 2014."}, {"time": 1040, "text": "I said, Kira, that was the first tool that I wrote that was usable."}, {"time": 1043, "text": "I wouldn't say the code was great."}, {"time": 1045, "text": "I still wouldn't say my code is great."}, {"time": 1048, "text": "So how was your evolution as a programmer except practice?"}, {"time": 1051, "text": "So you started with C. At which point did you pick up Python?"}, {"time": 1055, "text": "Because you're pretty big in Python now."}, {"time": 1057, "text": "Now, yeah, in college."}, {"time": 1059, "text": "I went to Carnegie Mellon when I was 22."}, {"time": 1062, "text": "I went back."}, {"time": 1063, "text": "I'm like, all right, I'm gonna take all your hardest CS courses."}, {"time": 1066, "text": "We'll see how I do, right?"}, {"time": 1067, "text": "Like, did I miss anything by not having a real undergraduate education?"}, {"time": 1071, "text": "Took operating systems, compilers, AI, and they're like a freshman wheat or math course."}, {"time": 1078, "text": "And... Operating systems, some of those classes you mentioned are pretty tough, actually."}, {"time": 1085, "text": "At least the 2012, circa 2012, operating systems and compilers were two of the, they were the best classes I've ever taken in my life."}, {"time": 1094, "text": "Because you write an operating system and you write a compiler."}, {"time": 1098, "text": "I wrote my operating system in C and I wrote my compiler in Haskell, but somehow I picked up Python that semester as well."}, {"time": 1106, "text": "I started using it for the CTFs, actually."}, {"time": 1108, "text": "That's when I really started to get into CTFs and CTFs, you're all, it's a race against the clock."}, {"time": 1113, "text": "So I can't write things in C. Oh, there's a clock component."}, {"time": 1116, "text": "So you really want to use the programming languages so you can be fastest."}, {"time": 1118, "text": "48 hours, pwn as many of these challenges as you can."}, {"time": 1121, "text": "Pwn."}, {"time": 1122, "text": "Yeah, you got like a hundred points of challenge."}, {"time": 1123, "text": "Whatever team gets the most."}, {"time": 1126, "text": "You were both at Facebook and Google for a brief stint."}, {"time": 1131, "text": "With Project Zero actually at Google for five months where you developed Kira."}, {"time": 1136, "text": "What was Project Zero about in general?"}, {"time": 1139, "text": "What, I'm just curious about the security efforts in these companies."}, {"time": 1145, "text": "Well, Project Zero started the same time I went there."}, {"time": 1148, "text": "What years are there?"}, {"time": 1153, "text": "So that was right at the beginning of Project Zero."}, {"time": 1155, "text": "It's small."}, {"time": 1156, "text": "It's Google's offensive security team."}, {"time": 1161, "text": "I'll try to give the best public facing explanation that I can."}, {"time": 1166, "text": "So the idea is basically these vulnerabilities exist in the world."}, {"time": 1173, "text": "Nation states have them."}, {"time": 1175, "text": "Some high powered bad actors have them."}, {"time": 1179, "text": "Sometime people will find these vulnerabilities and submit them in bug bounties to the companies."}, {"time": 1187, "text": "But a lot of the companies don't really care."}, {"time": 1189, "text": "They don't even fix the bug."}, {"time": 1191, "text": "It doesn't hurt for there to be a vulnerability."}, {"time": 1193, "text": "So Project Zero is like, we're going to do it different."}, {"time": 1195, "text": "We're going to announce a vulnerability and we're going to give them 90 days to fix it."}, {"time": 1199, "text": "And then whether they fix it or not, we're going to drop the zero day."}, {"time": 1204, "text": "We're going to drop the weapon."}, {"time": 1204, "text": "That's so cool."}, {"time": 1205, "text": "That is so cool."}, {"time": 1207, "text": "I love the deadlines."}, {"time": 1209, "text": "Oh, that's so cool."}, {"time": 1210, "text": "Give them real deadlines."}, {"time": 1212, "text": "And I think it's done a lot for moving the industry forward."}, {"time": 1215, "text": "I watched your coding sessions on the streamed online."}, {"time": 1220, "text": "You code things up, the basic projects, usually from scratch."}, {"time": 1224, "text": "I would say sort of as a programmer myself, just watching you that you type really fast and your brain works in both brilliant and chaotic ways."}, {"time": 1234, "text": "I don't know if that's always true, but certainly for the live streams."}, {"time": 1237, "text": "So it's interesting to me because I'm more, I'm much slower and systematic and careful."}, {"time": 1243, "text": "And you just move, I mean, probably in order of magnitude faster."}, {"time": 1248, "text": "So I'm curious, is there a method to your madness?"}, {"time": 1251, "text": "Is it just who you are?"}, {"time": 1253, "text": "There's pros and cons."}, {"time": 1254, "text": "There's pros and cons to my programming style."}, {"time": 1258, "text": "And I'm aware of them."}, {"time": 1259, "text": "Like if you ask me to like get something up and working quickly with like an API that's kind of undocumented, I will do this super fast because I will throw things at it until it works."}, {"time": 1270, "text": "If you ask me to take a vector and rotate it 90 degrees and then flip it over the XY plane, I'll spam program for two hours and won't get it."}, {"time": 1282, "text": "Oh, because it's something that you could do with a sheet of paper, think through design, and then just, do you really just throw stuff at the wall and you get so good at it that it usually works?"}, {"time": 1294, "text": "I should become better at the other kind as well."}, {"time": 1296, "text": "Sometimes I'll do things methodically."}, {"time": 1299, "text": "It's nowhere near as entertaining on the Twitch streams."}, {"time": 1301, "text": "I do exaggerate it a bit on the Twitch streams as well."}, {"time": 1303, "text": "The Twitch streams, I mean, what do you want to see a game or you want to see actions per minute, right?"}, {"time": 1306, "text": "I'll show you APM for programming too."}, {"time": 1308, "text": "Yeah, I recommend people go to it."}, {"time": 1310, "text": "I think I watched, I watched probably several hours of you, like I've actually left you programming in the background while I was programming because you made me, it was like watching a really good gamer."}, {"time": 1323, "text": "It's like energizes you because you're like moving so fast."}, {"time": 1326, "text": "It's so, it's awesome."}, {"time": 1327, "text": "It's inspiring and it made me jealous that like, because my own programming is inadequate in terms of speed."}, {"time": 1335, "text": "Oh, I was like."}, {"time": 1337, "text": "So I'm twice as frantic on the live streams as I am when I code without them."}, {"time": 1342, "text": "It's super entertaining."}, {"time": 1343, "text": "So I wasn't even paying attention to what you were coding, which is great."}, {"time": 1347, "text": "It's just watching you switch windows and Vim I guess is the most."}, {"time": 1351, "text": "Yeah, there's Vim on screen."}, {"time": 1353, "text": "I've developed the workload at Facebook and stuck with it."}, {"time": 1355, "text": "How do you learn new programming tools, ideas, techniques these days?"}, {"time": 1359, "text": "What's your like a methodology for learning new things?"}, {"time": 1362, "text": "So I wrote for comma, the distributed file systems out in the world are extremely complex."}, {"time": 1370, "text": "Like if you want to install something like like like Ceph, Ceph is I think the like open infrastructure distributed file system, or there's like newer ones like seaweed FS, but these are all like 10,000 plus line projects."}, {"time": 1386, "text": "I think some of them are even a hundred thousand line and just configuring them as a nightmare."}, {"time": 1391, "text": "So I wrote, I wrote one, it's 200 lines and it's, it uses like NGINX and volume servers and has this little master server that I wrote in Go."}, {"time": 1401, "text": "And the way I go, this, if I would say that I'm proud per line of any code I wrote, maybe there's some exploits that I think are beautiful."}, {"time": 1409, "text": "And then this, this is 200 lines."}, {"time": 1411, "text": "And just the way that I thought about it, I think was very good."}, {"time": 1414, "text": "And the reason it's very good is because that was the fourth version of it that I wrote."}, {"time": 1417, "text": "And I had three versions that I threw away."}, {"time": 1419, "text": "You mentioned, did you say Go?"}, {"time": 1420, "text": "I wrote in Go, yeah."}, {"time": 1421, "text": "In Go."}, {"time": 1422, "text": "Is that a functional language?"}, {"time": 1423, "text": "I forget what Go is."}, {"time": 1425, "text": "Go is Google's language."}, {"time": 1428, "text": "It's not functional."}, {"time": 1429, "text": "It's some, it's like in a way it's C++, but easier."}, {"time": 1436, "text": "It's, it's strongly typed."}, {"time": 1438, "text": "It has a nice ecosystem around it."}, {"time": 1439, "text": "When I first looked at it, I was like, this is like Python, but it takes twice as long to do anything."}, {"time": 1445, "text": "Now that I've, OpenPilot is migrating to C, but it still has large Python components."}, {"time": 1450, "text": "I now understand why Python doesn't work for large code bases and why you want something like Go."}, {"time": 1456, "text": "So why, why doesn't Python work for, so even most, speaking for myself at least, like we do a lot of stuff, basically demo level work with autonomous vehicles and most of the work is Python."}, {"time": 1469, "text": "Why doesn't Python work for large code bases?"}, {"time": 1472, "text": "Because, well, lack of type checking is a big part."}, {"time": 1477, "text": "So errors creep in."}, {"time": 1480, "text": "And like, you don't know, the compiler can tell you like nothing, right?"}, {"time": 1485, "text": "So everything is either, you know, like, like syntax errors, fine."}, {"time": 1489, "text": "But if you misspell a variable in Python, the compiler won't catch that."}, {"time": 1493, "text": "There's like linters that can catch it some of the time."}, {"time": 1496, "text": "There's no types."}, {"time": 1497, "text": "This is really the biggest downside."}, {"time": 1500, "text": "And then, well, Python's slow, but that's not related to it."}, {"time": 1502, "text": "Well, maybe it's kind of related to it, so it's lack of."}, {"time": 1504, "text": "So what's, what's in your toolbox these days?"}, {"time": 1506, "text": "Is it Python?"}, {"time": 1508, "text": "I need to move to something else."}, {"time": 1510, "text": "My adventure into dependently typed languages, I love these languages."}, {"time": 1514, "text": "They just have like syntax from the 80s."}, {"time": 1518, "text": "What do you think about JavaScript?"}, {"time": 1521, "text": "ES6, like the modern, or TypeScript?"}, {"time": 1523, "text": "JavaScript is, the whole ecosystem is unbelievably confusing."}, {"time": 1529, "text": "NPM updates a package from 0.2.2 to 0.2.5, and that breaks your Babel linter, which translates your ES5 into ES6, which doesn't run on, so."}, {"time": 1539, "text": "Why do I have to compile my JavaScript again, huh?"}, {"time": 1542, "text": "It may be the future, though."}, {"time": 1544, "text": "You think about, I mean, I've embraced JavaScript recently, just because, just like I've continually embraced PHP, it seems that these worst possible languages live on for the longest, like cockroaches never die."}, {"time": 1558, "text": "Well, it's in the browser, and it's fast."}, {"time": 1560, "text": "It's fast."}, {"time": 1562, "text": "It's in the browser, and compute might stay, become, you know, the browser."}, {"time": 1566, "text": "It's unclear what the role of the browser is in terms of distributed computation in the future, so."}, {"time": 1573, "text": "JavaScript is definitely here to stay."}, {"time": 1576, "text": "It's interesting if autonomous vehicles will run on JavaScript one day."}, {"time": 1579, "text": "I mean, you have to consider these possibilities."}, {"time": 1581, "text": "Well, all our debug tools are JavaScript."}, {"time": 1584, "text": "We actually just open sourced them."}, {"time": 1586, "text": "We have a tool, Explorer, which you can annotate your disengagements, and we have a tool, Cabana, which lets you analyze the can traffic from the car."}, {"time": 1592, "text": "So basically, anytime you're visualizing something about the log, you're using JavaScript."}, {"time": 1597, "text": "Well, the web is the best UI toolkit by far, so."}, {"time": 1601, "text": "And then, you know what?"}, {"time": 1602, "text": "You're coding in JavaScript."}, {"time": 1602, "text": "We have a React guy."}, {"time": 1603, "text": "He's good."}, {"time": 1604, "text": "React, nice."}, {"time": 1606, "text": "Let's get into it."}, {"time": 1606, "text": "So let's talk autonomous vehicles."}, {"time": 1609, "text": "You founded Comma AI."}, {"time": 1611, "text": "Let's, at a high level, how did you get into the world of vehicle automation?"}, {"time": 1617, "text": "Can you also just, for people who don't know, tell the story of Comma AI?"}, {"time": 1622, "text": "So I was working at this AI startup, and a friend approached me, and he's like, dude, I don't know where this is going, but the coolest applied AI problem today is self driving cars."}, {"time": 1636, "text": "I'm like, well, absolutely."}, {"time": 1638, "text": "You want to meet with Elon Musk, and he's looking for somebody to build a vision system for autopilot."}, {"time": 1647, "text": "This is when they were still on AP1."}, {"time": 1649, "text": "They were still using Mobileye."}, {"time": 1650, "text": "Elon, back then, was looking for a replacement, and he brought me in, and we talked about a contract where I would deliver something that meets Mobileye level performance."}, {"time": 1661, "text": "I would get paid $12 million if I could deliver it tomorrow, and I would lose $1 million for every month I didn't deliver."}, {"time": 1667, "text": "So I was like, okay, this is a great deal."}, {"time": 1669, "text": "This is a super exciting challenge."}, {"time": 1672, "text": "You know what?"}, {"time": 1673, "text": "Even if it takes me 10 months, I get $2 million."}, {"time": 1676, "text": "Maybe I can finish up in five."}, {"time": 1677, "text": "Maybe I don't finish it at all, and I get paid nothing, and I can still work for 12 months for free."}, {"time": 1680, "text": "So maybe just take a pause on that."}, {"time": 1682, "text": "I'm also curious about this because I've been working in robotics for a long time, and I'm curious to see a person like you just step in and sort of somewhat naive, but brilliant, right?"}, {"time": 1691, "text": "So that's the best place to be because you basically full steam take on a problem."}, {"time": 1697, "text": "How confident, how, from that time, because you know a lot more now, at that time, how hard do you think it is to solve all of autonomous driving?"}, {"time": 1705, "text": "I remember I suggested to Elon in the meeting putting a GPU behind each camera to keep the compute local."}, {"time": 1715, "text": "This is an incredibly stupid idea."}, {"time": 1718, "text": "I leave the meeting 10 minutes later, and I'm like, I could have spent a little bit of time thinking about this problem before I went in."}, {"time": 1722, "text": "Why is it a stupid idea?"}, {"time": 1724, "text": "Oh, just send all your cameras to one big GPU."}, {"time": 1726, "text": "You're much better off doing that."}, {"time": 1729, "text": "You said behind every camera have a GPU."}, {"time": 1730, "text": "Every camera have a small GPU."}, {"time": 1731, "text": "I was like, oh, I'll put the first few layers of my comms there."}, {"time": 1734, "text": "Ugh, why'd I say that?"}, {"time": 1736, "text": "That's possible."}, {"time": 1736, "text": "It's possible, but it's a bad idea."}, {"time": 1738, "text": "It's not obviously a bad idea."}, {"time": 1740, "text": "Pretty obviously bad, but whether it's actually a bad idea or not, I left that meeting with Elon, beating myself up."}, {"time": 1745, "text": "I'm like, why'd I say something stupid?"}, {"time": 1747, "text": "Yeah, you haven't at least thought through every aspect of it, yeah."}, {"time": 1752, "text": "He's very sharp too."}, {"time": 1753, "text": "Usually in life, I get away with saying stupid things and then kind of course, oh, right away he called me out about it."}, {"time": 1758, "text": "And usually in life, I get away with saying stupid things and then a lot of times people don't even notice and I'll correct it and bring the conversation back."}, {"time": 1768, "text": "But with Elon, it was like, nope, okay, well."}, {"time": 1771, "text": "That's not at all why the contract fell through."}, {"time": 1773, "text": "I was much more prepared the second time I met him."}, {"time": 1775, "text": "Yeah, but in general, how hard did you think it is?"}, {"time": 1779, "text": "Like 12 months is a tough timeline."}, {"time": 1783, "text": "Oh, I just thought I'd clone Mobileye IQ3."}, {"time": 1785, "text": "I didn't think I'd solve level five self driving or anything."}, {"time": 1788, "text": "So the goal there was to do lane keeping, good lane keeping."}, {"time": 1792, "text": "I saw, my friend showed me the outputs from a Mobileye and the outputs from a Mobileye was just basically two lanes at a position of a lead car."}, {"time": 1799, "text": "I'm like, I can gather a data set and train this net in weeks and I did."}, {"time": 1804, "text": "Well, first time I tried the implementation of Mobileye in a Tesla, I was really surprised how good it is."}, {"time": 1811, "text": "It's going incredibly good."}, {"time": 1812, "text": "Cause I thought it's just cause I've done a lot of computer vision, I thought it'd be a lot harder to create a system that that's stable."}, {"time": 1820, "text": "So I was personally surprised, you know, have to admit it."}, {"time": 1825, "text": "Cause I was kind of skeptical before trying it."}, {"time": 1827, "text": "Cause I thought it would go in and out a lot more."}, {"time": 1831, "text": "It would get disengaged a lot more and it's pretty robust."}, {"time": 1836, "text": "So what, how hard is the problem when you tackled it?"}, {"time": 1842, "text": "So I think AP1 was great."}, {"time": 1844, "text": "Like Elon talked about disengagements on the 405 down in LA with like the lane marks are kind of faded and the Mobileye system would drop out."}, {"time": 1853, "text": "Like I had something up and working that I would say was like the same quality in three months."}, {"time": 1862, "text": "Same quality, but how do you know?"}, {"time": 1864, "text": "You say stuff like that confidently, but you can't, and I love it, but the question is you can't, you're kind of going by feel cause you test it out."}, {"time": 1875, "text": "Like I would take, I borrowed my friend's Tesla."}, {"time": 1878, "text": "I would take AP1 out for a drive and then I would take my system out for a drive."}, {"time": 1882, "text": "And it seems reasonably like the same."}, {"time": 1885, "text": "So the 405, how hard is it to create something that could actually be a product that's deployed?"}, {"time": 1894, "text": "I mean, I've read an article where Elon, this respondent said something about you saying that to build autopilot is more complicated than a single George Hodge level job."}, {"time": 1911, "text": "How hard is that job to create something that would work across globally?"}, {"time": 1918, "text": "Why don't think globally is the challenge?"}, {"time": 1920, "text": "But Elon followed that up by saying it's gonna take two years in a company of 10 people."}, {"time": 1924, "text": "And here I am four years later with a company of 12 people."}, {"time": 1927, "text": "And I think we still have another two to go."}, {"time": 1929, "text": "Two years, so yeah."}, {"time": 1931, "text": "So what do you think about how Tesla is progressing with autopilot of V2, V3?"}, {"time": 1939, "text": "I think we've kept pace with them pretty well."}, {"time": 1943, "text": "I think navigate and autopilot is terrible."}, {"time": 1946, "text": "We had some demo features internally of the same stuff and we would test it."}, {"time": 1952, "text": "And I'm like, I'm not shipping this even as like open source software to people."}, {"time": 1955, "text": "Why do you think it's terrible?"}, {"time": 1957, "text": "Consumer Reports does a great job of describing it."}, {"time": 1959, "text": "Like when it makes a lane change, it does it worse than a human."}, {"time": 1963, "text": "You shouldn't ship things like autopilot, open pilot."}, {"time": 1966, "text": "They lane keep better than a human."}, {"time": 1969, "text": "If you turn it on for a stretch of a highway, like an hour long, it's never gonna touch a lane line."}, {"time": 1976, "text": "Human will touch probably a lane line twice."}, {"time": 1978, "text": "You just inspired me."}, {"time": 1980, "text": "I don't know if you're grounded in data on that."}, {"time": 1982, "text": "I read your paper."}, {"time": 1983, "text": "Okay, but that's interesting."}, {"time": 1985, "text": "I wonder actually how often we touch lane lines in general, like a little bit, because it is."}, {"time": 1993, "text": "I could answer that question pretty easily with the common data set."}, {"time": 1995, "text": "Yeah, I'm curious."}, {"time": 1996, "text": "I've never answered it."}, {"time": 1998, "text": "I just, two is like my personal."}, {"time": 1999, "text": "It feels right."}, {"time": 2002, "text": "Because every time you touch a lane, that's a source of a little bit of stress and kind of lane keeping is removing that stress."}, {"time": 2009, "text": "That's ultimately the biggest value add honestly is just removing the stress of having to stay in lane."}, {"time": 2015, "text": "And I think honestly, I don't think people fully realize, first of all, that that's a big value add, but also that that's all it is."}, {"time": 2024, "text": "And that not only, I find it a huge value add."}, {"time": 2028, "text": "I drove down when we moved to San Diego, I drove down in a enterprise rental car and I missed it."}, {"time": 2033, "text": "So I missed having the system so much."}, {"time": 2035, "text": "It's so much more tiring to drive without it."}, {"time": 2040, "text": "It is that lane centering."}, {"time": 2042, "text": "That's the key feature."}, {"time": 2046, "text": "And in a way, it's the only feature that actually adds value to people's lives in autonomous vehicles today."}, {"time": 2052, "text": "Waymo does not add value to people's lives."}, {"time": 2053, "text": "It's a more expensive, slower Uber."}, {"time": 2055, "text": "Maybe someday it'll be this big cliff where it adds value, but I don't usually believe it."}, {"time": 2059, "text": "It is fascinating."}, {"time": 2060, "text": "I haven't talked to, this is good."}, {"time": 2062, "text": "Cause I haven't, I have intuitively, but I think we're making it explicit now."}, {"time": 2068, "text": "I actually believe that really good lane keeping is a reason to buy a car."}, {"time": 2077, "text": "Will be a reason to buy a car and it's a huge value add."}, {"time": 2079, "text": "I've never, until we just started talking about it, I haven't really quite realized it."}, {"time": 2083, "text": "That I've felt with Elon's chase of level four is not the correct chase."}, {"time": 2092, "text": "It was on, cause you should just say Tesla has the best as if from a Tesla perspective, say, Tesla has the best lane keeping."}, {"time": 2100, "text": "Comma AI should say, Comma AI is the best lane keeping."}, {"time": 2104, "text": "And that is it."}, {"time": 2106, "text": "So do you think?"}, {"time": 2107, "text": "You have to do the longitudinal as well."}, {"time": 2109, "text": "You can't just lane keep."}, {"time": 2110, "text": "You have to do ACC, but ACC is much more forgiving than lane keep, especially on the highway."}, {"time": 2117, "text": "By the way, are you Comma AI's camera only, correct?"}, {"time": 2121, "text": "No, we use the radar."}, {"time": 2123, "text": "From the car, you're able to get the, okay."}, {"time": 2125, "text": "Hmm?"}, {"time": 2126, "text": "We can do a camera only now."}, {"time": 2128, "text": "It's gotten to the point, but we leave the radar there as like a, it's fusion now."}, {"time": 2133, "text": "Okay, so let's maybe talk through some of the system specs on the hardware."}, {"time": 2137, "text": "What's the hardware side of what you're providing?"}, {"time": 2142, "text": "What's the capabilities on the software side with OpenPilot and so on?"}, {"time": 2146, "text": "So OpenPilot, as the box that we sell, that it runs on, it's a phone in a plastic case."}, {"time": 2154, "text": "It's nothing special."}, {"time": 2155, "text": "We sell it without the software."}, {"time": 2156, "text": "So you buy the phone, it's just easy."}, {"time": 2159, "text": "It'll be easy set up, but it's sold with no software."}, {"time": 2163, "text": "OpenPilot right now is about to be 0.6."}, {"time": 2167, "text": "When it gets to 1.0, I think we'll be ready for a consumer product."}, {"time": 2170, "text": "We're not gonna add any new features."}, {"time": 2171, "text": "We're just gonna make the lane keeping really, really good."}, {"time": 2174, "text": "Okay, I got it."}, {"time": 2175, "text": "So what do we have right now?"}, {"time": 2176, "text": "It's a Snapdragon 820."}, {"time": 2180, "text": "It's a Sony IMX 298 forward facing camera."}, {"time": 2184, "text": "Driver monitoring camera, it's just a selfie camera on the phone."}, {"time": 2187, "text": "And a CAN transceiver, maybe there's a little thing called PANDAS."}, {"time": 2193, "text": "And they talk over USB to the phone and then they have three CAN buses that they talk to the car."}, {"time": 2199, "text": "One of those CAN buses is the radar CAN bus."}, {"time": 2202, "text": "One of them is the main car CAN bus and the other one is the proxy camera CAN bus."}, {"time": 2206, "text": "We leave the existing camera in place so we don't turn AEB off."}, {"time": 2210, "text": "Right now, we still turn AEB off if you're using our longitudinal, but we're gonna fix that before 1.0."}, {"time": 2216, "text": "Wow, that's cool."}, {"time": 2217, "text": "And it's CAN both ways."}, {"time": 2219, "text": "So how are you able to control vehicles?"}, {"time": 2223, "text": "So we proxy, the vehicles that we work with already have a lane keeping assist system."}, {"time": 2230, "text": "So lane keeping assist can mean a huge variety of things."}, {"time": 2233, "text": "It can mean it will apply a small torque to the wheel after you've already crossed a lane line by a foot, which is the system in the older Toyotas versus like, I think Tesla still calls it lane keeping assist, where it'll keep you perfectly in the center of the lane on the highway."}, {"time": 2252, "text": "You can control, like with the joystick, the car."}, {"time": 2255, "text": "So these cars already have the capability of drive by wire."}, {"time": 2257, "text": "So is it trivial to convert a car that it operates with?"}, {"time": 2265, "text": "OpenPILOT is able to control the steering?"}, {"time": 2268, "text": "Oh, a new car or a car that we, so we have support now for 45 different makes of cars."}, {"time": 2272, "text": "What are the cars in general?"}, {"time": 2274, "text": "Mostly Hondas and Toyotas."}, {"time": 2276, "text": "We support almost every Honda and Toyota made this year."}, {"time": 2281, "text": "And then a bunch of GMs, a bunch of Subarus, a bunch of Chevys."}, {"time": 2285, "text": "It doesn't have to be like a Prius, it could be a Corolla as well."}, {"time": 2287, "text": "Oh, the 2020 Corolla is the best car with OpenPILOT."}, {"time": 2290, "text": "It just came out."}, {"time": 2291, "text": "The actuator has less lag than the older Corolla."}, {"time": 2295, "text": "I think I started watching a video with your, I mean, the way you make videos is awesome."}, {"time": 2301, "text": "You're just literally at the dealership streaming."}, {"time": 2304, "text": "Yeah, I had my friend on the phone, I'm like, bro, you wanna stream for an hour?"}, {"time": 2307, "text": "Yeah, and basically, like if stuff goes a little wrong, you're just like, you just go with it."}, {"time": 2313, "text": "Yeah, I love it."}, {"time": 2313, "text": "Well, it's real."}, {"time": 2314, "text": "Yeah, it's real."}, {"time": 2315, "text": "That's so beautiful and it's so in contrast to the way other companies would put together a video like that."}, {"time": 2324, "text": "Kind of why I like to do it like that."}, {"time": 2326, "text": "I mean, if you become super rich one day and successful, I hope you keep it that way because I think that's actually what people love, that kind of genuine."}, {"time": 2334, "text": "Oh, it's all that has value to me."}, {"time": 2336, "text": "Money has no, if I sell out to like make money, I sold out, it doesn't matter."}, {"time": 2341, "text": "What do I get?"}, {"time": 2342, "text": "Yacht?"}, {"time": 2343, "text": "I don't want a yacht."}, {"time": 2344, "text": "And I think Tesla's actually has a small inkling of that as well with Autonomy Day."}, {"time": 2351, "text": "They did reveal more than, I mean, of course, there's marketing communications, you could tell, but it's more than most companies would reveal, which is, I hope they go towards that direction more, other companies, GM, Ford."}, {"time": 2363, "text": "Oh, Tesla's gonna win level five."}, {"time": 2365, "text": "They really are."}, {"time": 2366, "text": "So let's talk about it."}, {"time": 2367, "text": "You think, you're focused on level two currently?"}, {"time": 2372, "text": "Currently."}, {"time": 2373, "text": "We're gonna be one to two years behind Tesla getting to level five."}, {"time": 2378, "text": "We're Android, right?"}, {"time": 2379, "text": "We're Android."}, {"time": 2380, "text": "You're Android."}, {"time": 2381, "text": "I'm just saying, once Tesla gets it, we're one to two years behind."}, {"time": 2383, "text": "I'm not making any timeline on when Tesla's gonna get it."}, {"time": 2386, "text": "You did, that was brilliant."}, {"time": 2387, "text": "I'm sorry, Tesla investors, if you think you're gonna have an autonomous Robo Taxi fleet by the end of the year."}, {"time": 2392, "text": "Yeah, so that's."}, {"time": 2393, "text": "I'll bet against that."}, {"time": 2394, "text": "So what do you think about this?"}, {"time": 2397, "text": "The most level four companies are kind of just doing their usual safety driver, doing full autonomy kind of testing."}, {"time": 2408, "text": "And then Tesla does basically trying to go from lane keeping to full autonomy."}, {"time": 2415, "text": "What do you think about that approach?"}, {"time": 2416, "text": "How successful would it be?"}, {"time": 2418, "text": "It's a ton better approach."}, {"time": 2420, "text": "Because Tesla is gathering data on a scale that none of them are."}, {"time": 2425, "text": "They're putting real users behind the wheel of the cars."}, {"time": 2429, "text": "It's, I think, the only strategy that works."}, {"time": 2433, "text": "The incremental."}, {"time": 2434, "text": "Well, so there's a few components to Tesla approach that's more than just the incrementalists."}, {"time": 2438, "text": "What you spoke with is the ones, the software, so over the air software updates."}, {"time": 2443, "text": "Necessity."}, {"time": 2444, "text": "I mean Waymo crews have those too."}, {"time": 2446, "text": "Those aren't."}, {"time": 2448, "text": "Those differentiate from the automakers."}, {"time": 2449, "text": "Right, no lane keeping systems have, no cars with lane keeping system have that except Tesla."}, {"time": 2455, "text": "And the other one is the data, the other direction, which is the ability to query the data."}, {"time": 2461, "text": "I don't think they're actually collecting as much data as people think, but the ability to turn on collection and turn it off."}, {"time": 2469, "text": "So I'm both in the robotics world and the psychology human factors world."}, {"time": 2475, "text": "Many people believe that level two autonomy is problematic because of the human factor."}, {"time": 2480, "text": "Like the more the task is automated, the more there's a vigilance decrement."}, {"time": 2486, "text": "You start to fall asleep."}, {"time": 2487, "text": "You start to become complacent, start texting more and so on."}, {"time": 2492, "text": "Cause if we're talking about transition from lane keeping to full autonomy, if you're spending 80% of the time, not supervising the machine, do you worry about what that means to the safety of the drivers?"}, {"time": 2507, "text": "One, we don't consider open pilot to be 1.0 until we have 100% driver monitoring."}, {"time": 2512, "text": "You can cheat right now, our driver monitoring system."}, {"time": 2515, "text": "There's a few ways to cheat it."}, {"time": 2516, "text": "They're pretty obvious."}, {"time": 2518, "text": "We're working on making that better."}, {"time": 2519, "text": "Before we ship a consumer product that can drive cars, I want to make sure that I have driver monitoring that you can't cheat."}, {"time": 2525, "text": "What's like a successful driver monitoring system look like?"}, {"time": 2527, "text": "Is it all about just keeping your eyes on the road?"}, {"time": 2531, "text": "Well, a few things."}, {"time": 2532, "text": "So that's what we went with at first for driver monitoring."}, {"time": 2536, "text": "I'm checking, I'm actually looking at where your head is looking."}, {"time": 2539, "text": "The camera's not that high resolution."}, {"time": 2540, "text": "Eyes are a little bit hard to get."}, {"time": 2541, "text": "Well, head is this big."}, {"time": 2542, "text": "I mean, that's."}, {"time": 2543, "text": "Head is good."}, {"time": 2544, "text": "And actually a lot of it, just psychology wise, to have that monitor constantly there, it reminds you that you have to be paying attention."}, {"time": 2553, "text": "But we want to go further."}, {"time": 2555, "text": "We just hired someone full time to come on to do the driver monitoring."}, {"time": 2557, "text": "I want to detect phone in frame and I want to make sure you're not sleeping."}, {"time": 2562, "text": "How much does the camera see of the body?"}, {"time": 2564, "text": "This one, not enough."}, {"time": 2568, "text": "The next one, everything."}, {"time": 2570, "text": "Well, it's interesting, Fisheye, because we're doing just data collection, not real time."}, {"time": 2575, "text": "But Fisheye is a beautiful, being able to capture the body."}, {"time": 2579, "text": "And the smartphone is really like the biggest problem."}, {"time": 2583, "text": "I'll show you."}, {"time": 2584, "text": "I can show you one of the pictures from our new system."}, {"time": 2586, "text": "Awesome, so you're basically saying the driver monitoring will be the answer to that."}, {"time": 2593, "text": "I think the other point that you raised in your paper is good as well."}, {"time": 2596, "text": "You're not asking a human to supervise a machine without giving them the, they can take over at any time."}, {"time": 2604, "text": "Our safety model, you can take over."}, {"time": 2605, "text": "We disengage on both the gas or the brake."}, {"time": 2607, "text": "We don't disengage on steering."}, {"time": 2608, "text": "I don't feel you have to."}, {"time": 2610, "text": "But we disengage on gas or brake."}, {"time": 2611, "text": "So it's very easy for you to take over and it's very easy for you to reengage."}, {"time": 2616, "text": "That switching should be super cheap."}, {"time": 2619, "text": "The cars that require, even autopilot requires a double press."}, {"time": 2622, "text": "That's almost, I see, I don't like that."}, {"time": 2624, "text": "And then the cancel, to cancel in autopilot, you either have to press cancel, which no one knows what that is, so they press the brake."}, {"time": 2631, "text": "But a lot of times you don't actually want to press the brake."}, {"time": 2633, "text": "You want to press the gas."}, {"time": 2634, "text": "So you should cancel on gas."}, {"time": 2635, "text": "Or wiggle the steering wheel, which is bad as well."}, {"time": 2637, "text": "Wow, that's brilliant."}, {"time": 2638, "text": "I haven't heard anyone articulate that point."}, {"time": 2641, "text": "Oh, this is all I think about."}, {"time": 2643, "text": "It's the, because I think, I think actually Tesla has done a better job than most automakers at making that frictionless."}, {"time": 2652, "text": "But you just described that it could be even better."}, {"time": 2656, "text": "I love Super Cruise as an experience once it's engaged."}, {"time": 2661, "text": "I don't know if you've used it, but getting the thing to try to engage."}, {"time": 2665, "text": "Yeah, I've used the, I've driven Super Cruise a lot."}, {"time": 2667, "text": "So what's your thoughts on the Super Cruise system?"}, {"time": 2669, "text": "You disengage Super Cruise and it falls back to ACC."}, {"time": 2672, "text": "So my car's like still accelerating."}, {"time": 2674, "text": "It feels weird."}, {"time": 2676, "text": "Otherwise, when you actually have Super Cruise engaged on the highway, it is phenomenal."}, {"time": 2681, "text": "We bought that Cadillac."}, {"time": 2682, "text": "We just sold it."}, {"time": 2683, "text": "But we bought it just to like experience this."}, {"time": 2685, "text": "And I wanted everyone in the office to be like, this is what we're striving to build."}, {"time": 2689, "text": "GM pioneering with the driver monitoring."}, {"time": 2692, "text": "You like their driver monitoring system?"}, {"time": 2695, "text": "It has some bugs."}, {"time": 2696, "text": "If there's a sun shining back here, it'll be blind to you."}, {"time": 2701, "text": "But overall, mostly, yeah."}, {"time": 2703, "text": "That's so cool that you know all this stuff."}, {"time": 2705, "text": "I don't often talk to people that, because it's such a rare car, unfortunately, currently."}, {"time": 2710, "text": "We bought one explicitly for this."}, {"time": 2712, "text": "We lost like 25K in the deprecation, but I feel it's worth it."}, {"time": 2716, "text": "I was very pleasantly surprised that GM system was so innovative and really wasn't advertised much, wasn't talked about much."}, {"time": 2728, "text": "And I was nervous that it would die, that it would disappear."}, {"time": 2731, "text": "Well, they put it on the wrong car."}, {"time": 2733, "text": "They should have put it on the Bolt and not some weird Cadillac that nobody bought."}, {"time": 2736, "text": "I think that's gonna be into, they're saying at least it's gonna be into their entire fleet."}, {"time": 2741, "text": "So what do you think about, as long as we're on the driver monitoring, what do you think about Elon Musk's claim that driver monitoring is not needed?"}, {"time": 2751, "text": "Normally, I love his claims."}, {"time": 2753, "text": "That one is stupid."}, {"time": 2756, "text": "And, you know, he's not gonna have his level five fleet by the end of the year."}, {"time": 2761, "text": "Hopefully he's like, okay, I was wrong."}, {"time": 2764, "text": "I'm gonna add driver monitoring."}, {"time": 2766, "text": "Because when these systems get to the point that they're only messing up once every thousand miles, you absolutely need driver monitoring."}, {"time": 2774, "text": "So let me play, cause I agree with you, but let me play devil's advocate."}, {"time": 2777, "text": "One possibility is that without driver monitoring, people are able to monitor, self regulate, monitor themselves."}, {"time": 2788, "text": "You know, that, so your idea is."}, {"time": 2790, "text": "You've seen all the people sleeping in Teslas?"}, {"time": 2793, "text": "Yeah, well, I'm a little skeptical of all the people sleeping in Teslas because I've stopped paying attention to that kind of stuff because I want to see real data."}, {"time": 2805, "text": "It's too much glorified."}, {"time": 2807, "text": "It doesn't feel scientific to me."}, {"time": 2808, "text": "So I want to know how many people are really sleeping in Teslas versus sleeping."}, {"time": 2814, "text": "I was driving here sleep deprived in a car with no automation."}, {"time": 2819, "text": "I was falling asleep."}, {"time": 2820, "text": "I agree that it's hypey."}, {"time": 2822, "text": "It's just like, you know what?"}, {"time": 2824, "text": "If you want to put driver monitoring, I rented a, my last autopilot experience was I rented a model three in March and drove it around."}, {"time": 2832, "text": "The wheel thing is annoying."}, {"time": 2833, "text": "And the reason the wheel thing is annoying, we use the wheel thing as well, but we don't disengage on wheel."}, {"time": 2838, "text": "For Tesla, you have to touch the wheel just enough to trigger the torque sensor, to tell it that you're there, but not enough as to disengage it, which don't use it for two things."}, {"time": 2850, "text": "Don't disengage on wheel."}, {"time": 2851, "text": "You don't have to."}, {"time": 2852, "text": "That whole experience, wow, beautifully put."}, {"time": 2855, "text": "All of those elements, even if you don't have driver monitoring, that whole experience needs to be better."}, {"time": 2861, "text": "Driver monitoring, I think would make, I mean, I think Super Cruise is a better experience once it's engaged over autopilot."}, {"time": 2868, "text": "I think Super Cruise is a transition to engagement and disengagement are significantly worse."}, {"time": 2874, "text": "Well, there's a tricky thing, because if I were to criticize Super Cruise is, it's a little too crude."}, {"time": 2880, "text": "And I think like six seconds or something, if you look off road, it'll start warning you."}, {"time": 2885, "text": "It's some ridiculously long period of time."}, {"time": 2889, "text": "And just the way, I think it's basically, it's a binary."}, {"time": 2895, "text": "It should be adaptive."}, {"time": 2897, "text": "Yeah, it needs to learn more about you."}, {"time": 2899, "text": "It needs to communicate what it sees about you more."}, {"time": 2904, "text": "Tesla shows what it sees about the external world."}, {"time": 2907, "text": "It would be nice if Super Cruise would tell us what it sees about the internal world."}, {"time": 2910, "text": "It's even worse than that."}, {"time": 2911, "text": "You press the button to engage and it just says Super Cruise unavailable."}, {"time": 2917, "text": "Yeah, that transparency is good."}, {"time": 2921, "text": "We've renamed the driver monitoring packet to driver state."}, {"time": 2925, "text": "Driver state."}, {"time": 2926, "text": "We have car state packet, which has the state of the car."}, {"time": 2928, "text": "And you have driver state packet, which has the state of the driver."}, {"time": 2930, "text": "So what is the... Estimate their BAC."}, {"time": 2933, "text": "What's BAC?"}, {"time": 2934, "text": "Blood alcohol content."}, {"time": 2937, "text": "You think that's possible with computer vision?"}, {"time": 2943, "text": "To me, it's an open question."}, {"time": 2944, "text": "I haven't looked into it too much."}, {"time": 2946, "text": "Actually, I quite seriously looked at the literature."}, {"time": 2948, "text": "It's not obvious to me that from the eyes and so on, you can tell."}, {"time": 2951, "text": "You might need stuff from the car as well."}, {"time": 2953, "text": "You might need how they're controlling the car, right?"}, {"time": 2955, "text": "And that's fundamentally at the end of the day, what you care about."}, {"time": 2958, "text": "But I think, especially when people are really drunk, they're not controlling the car nearly as smoothly as they would look at them walking, right?"}, {"time": 2965, "text": "The car is like an extension of the body."}, {"time": 2967, "text": "So I think you could totally detect."}, {"time": 2969, "text": "And if you could fix people who are drunk, distracted, asleep, if you fix those three."}, {"time": 2972, "text": "Yeah, that's huge."}, {"time": 2975, "text": "So what are the current limitations of open pilot?"}, {"time": 2978, "text": "What are the main problems that still need to be solved?"}, {"time": 2981, "text": "We're hopefully fixing a few of them in 06."}, {"time": 2985, "text": "We're not as good as autopilot at stop cars."}, {"time": 2989, "text": "So if you're coming up to a red light at 55, so it's the radar stopped car problem, which is responsible for two autopilot accidents, it's hard to differentiate a stopped car from a signpost."}, {"time": 3003, "text": "Yeah, a static object."}, {"time": 3005, "text": "So you have to fuse."}, {"time": 3006, "text": "You have to do this visually."}, {"time": 3007, "text": "There's no way from the radar data to tell the difference."}, {"time": 3009, "text": "Maybe you can make a map, but I don't really believe in mapping at all anymore."}, {"time": 3013, "text": "Wait, wait, wait, what, you don't believe in mapping?"}, {"time": 3016, "text": "So you basically, the open pilot solution is saying react to the environment as you see it, just like human beings do."}, {"time": 3024, "text": "And then eventually, when you want to do navigate on open pilot, I'll train the net to look at ways."}, {"time": 3029, "text": "I'll run ways in the background, I'll train a confident way."}, {"time": 3032, "text": "Are you using GPS at all?"}, {"time": 3034, "text": "We use it to ground truth."}, {"time": 3035, "text": "We use it to very carefully ground truth the paths."}, {"time": 3038, "text": "We have a stack which can recover relative to 10 centimeters over one minute."}, {"time": 3042, "text": "And then we use that to ground truth exactly where the car went in that local part of the environment, but it's all local."}, {"time": 3048, "text": "How are you testing in general, just for yourself, like experiments and stuff?"}, {"time": 3053, "text": "Where are you located?"}, {"time": 3058, "text": "So you basically drive around there, collect some data, and watch the performance?"}, {"time": 3063, "text": "We have a simulator now."}, {"time": 3064, "text": "And we have, our simulator is really cool."}, {"time": 3066, "text": "Our simulator is not, it's not like a Unity based simulator."}, {"time": 3069, "text": "Our simulator lets us load in real state."}, {"time": 3072, "text": "What do you mean?"}, {"time": 3073, "text": "We can load in a drive and simulate what the system would have done on the historical data."}, {"time": 3080, "text": "Ooh, nice."}, {"time": 3083, "text": "So what, yeah."}, {"time": 3084, "text": "Right now we're only using it for testing, but as soon as we start using it for training, that's it."}, {"time": 3089, "text": "That's all that matters."}, {"time": 3090, "text": "What's your feeling about the real world versus simulation?"}, {"time": 3093, "text": "Do you like simulation for training, if this moves to training?"}, {"time": 3095, "text": "So we have to distinguish two types of simulators, right?"}, {"time": 3100, "text": "There's a simulator that is completely fake."}, {"time": 3104, "text": "I could get my car to drive around in GTA."}, {"time": 3107, "text": "I feel that this kind of simulator is useless."}, {"time": 3111, "text": "You're never, there's so many."}, {"time": 3114, "text": "My analogy here is like, OK, fine."}, {"time": 3116, "text": "You're not solving the computer vision problem, but you're solving the computer graphics problem."}, {"time": 3122, "text": "And you don't think you can get very far by creating ultra realistic graphics?"}, {"time": 3127, "text": "No, because you can create ultra realistic graphics of the road, now create ultra realistic behavioral models of the other cars."}, {"time": 3134, "text": "Oh, well, I'll just use myself driving."}, {"time": 3136, "text": "No, you won't."}, {"time": 3138, "text": "You need actual human behavior, because that's what you're trying to learn."}, {"time": 3143, "text": "Driving does not have a spec."}, {"time": 3145, "text": "The definition of driving is what humans do when they drive."}, {"time": 3149, "text": "Whatever Waymo does, I don't think it's driving."}, {"time": 3153, "text": "Well, I think actually Waymo and others, if there's any use for reinforcement learning, I've seen it used quite well."}, {"time": 3160, "text": "I study pedestrians a lot, too, is try to train models from real data of how pedestrians move, and try to use reinforcement learning models to make pedestrians move in human like ways."}, {"time": 3169, "text": "By that point, you've already gone so many layers, you detected a pedestrian?"}, {"time": 3175, "text": "Did you hand code the feature vector of their state?"}, {"time": 3180, "text": "Did you guys learn anything from computer vision before deep learning?"}, {"time": 3184, "text": "Well, OK, I feel like this is."}, {"time": 3187, "text": "So perception to you is the sticking point."}, {"time": 3190, "text": "I mean, what's the hardest part of the stack here?"}, {"time": 3193, "text": "There is no human understandable feature vector separating perception and planning."}, {"time": 3203, "text": "That's the best way I can put that."}, {"time": 3205, "text": "There is no, so it's all together, and it's a joint problem."}, {"time": 3209, "text": "So you can take localization."}, {"time": 3211, "text": "Localization and planning, there is a human understandable feature vector between these two things."}, {"time": 3215, "text": "I mean, OK, so I have like three degrees position, three degrees orientation, and those derivatives, maybe those second derivatives."}, {"time": 3221, "text": "That's human understandable."}, {"time": 3223, "text": "That's physical."}, {"time": 3225, "text": "Between perception and planning, so like Waymo has a perception stack and then a planner."}, {"time": 3233, "text": "And one of the things Waymo does right is they have a simulator that can separate those two."}, {"time": 3240, "text": "They can like replay their perception data and test their system, which is what I'm talking about about like the two different kinds of simulators."}, {"time": 3246, "text": "There's the kind that can work on real data, and there's the kind that can't work on real data."}, {"time": 3250, "text": "Now, the problem is that I don't think you can hand code a feature vector, right?"}, {"time": 3256, "text": "Like you have some list of like, oh, here's my list of cars in the scenes."}, {"time": 3259, "text": "Here's my list of pedestrians in the scene."}, {"time": 3261, "text": "This isn't what humans are doing."}, {"time": 3263, "text": "What are humans doing?"}, {"time": 3264, "text": "Global."}, {"time": 3267, "text": "And you're saying that's too difficult to hand engineer."}, {"time": 3271, "text": "I'm saying that there is no state vector given a perfect."}, {"time": 3275, "text": "I could give you the best team of engineers in the world to build a perception system and the best team to build a planner."}, {"time": 3280, "text": "All you have to do is define the state vector that separates those two."}, {"time": 3283, "text": "I'm missing the state vector that separates those two."}, {"time": 3289, "text": "So what is the output of your perception system?"}, {"time": 3293, "text": "Output of the perception system, it's, OK, well, there's several ways to do it."}, {"time": 3301, "text": "One is the SLAM components localization."}, {"time": 3303, "text": "The other is drivable area, drivable space."}, {"time": 3305, "text": "Drivable space, yeah."}, {"time": 3306, "text": "And then there's the different objects in the scene."}, {"time": 3310, "text": "And different objects in the scene over time, maybe, to give you input to then try to start modeling the trajectories of those objects."}, {"time": 3322, "text": "I can give you a concrete example of something you missed."}, {"time": 3325, "text": "So say there's a bush in the scene."}, {"time": 3328, "text": "Humans understand that when they see this bush that there may or may not be a car behind that bush."}, {"time": 3334, "text": "Drivable area and a list of objects does not include that."}, {"time": 3337, "text": "Humans are doing this constantly at the simplest intersections."}, {"time": 3340, "text": "So now you have to talk about occluded area."}, {"time": 3344, "text": "But even that, what do you mean by occluded?"}, {"time": 3347, "text": "OK, so I can't see it."}, {"time": 3349, "text": "Well, if it's the other side of a house, I don't care."}, {"time": 3351, "text": "What's the likelihood that there's a car in that occluded area?"}, {"time": 3355, "text": "And if you say, OK, we'll add that, I can come up with 10 more examples that you can't add."}, {"time": 3361, "text": "Certainly, occluded area would be something that Simulator would have because it's simulating the entire occlusion is part of it."}, {"time": 3371, "text": "Occlusion is part of a vision stack."}, {"time": 3372, "text": "But what I'm saying is if you have a hand engineered, if your perception system output can be written in a spec document, it is incomplete."}, {"time": 3382, "text": "Yeah, I mean, certainly, it's hard to argue with that because in the end, that's going to be true."}, {"time": 3390, "text": "Yeah, and I'll tell you what the output of our perception system is."}, {"time": 3393, "text": "It's a 1,024 dimensional vector, trained by neural net."}, {"time": 3397, "text": "Oh, you know that."}, {"time": 3398, "text": "No, it's 1,024 dimensions of who knows what."}, {"time": 3403, "text": "Because it's operating on real data."}, {"time": 3406, "text": "And that's the perception."}, {"time": 3408, "text": "That's the perception state."}, {"time": 3410, "text": "Think about an autoencoder for faces."}, {"time": 3413, "text": "If you have an autoencoder for faces and you say it has 256 dimensions in the middle, and I'm taking a face over here and projecting it to a face over here."}, {"time": 3422, "text": "Can you hand label all 256 of those dimensions?"}, {"time": 3426, "text": "Well, no, but those have to generate automatically."}, {"time": 3429, "text": "But even if you tried to do it by hand, could you come up with a spec between your encoder and your decoder?"}, {"time": 3437, "text": "No, because it wasn't designed, but there."}, {"time": 3440, "text": "No, no, no, but if you could design it."}, {"time": 3443, "text": "If you could design a face reconstructor system, could you come up with a spec?"}, {"time": 3449, "text": "No, but I think we're missing here a little bit."}, {"time": 3452, "text": "I think you're just being very poetic about expressing a fundamental problem of simulators, that they're going to be missing so much that the feature vector will just look fundamentally different in the simulated world than the real world."}, {"time": 3471, "text": "I'm not making a claim about simulators."}, {"time": 3473, "text": "I'm making a claim about the spec division between perception and planning, even in your system."}, {"time": 3480, "text": "Just in general."}, {"time": 3483, "text": "If you're trying to build a car that drives, if you're trying to hand code the output of your perception system, like saying, here's a list of all the cars in the scene, here's a list of all the people, here's a list of the occluded areas, here's a vector of drivable areas, it's insufficient."}, {"time": 3496, "text": "And if you start to believe that, you realize that what Waymo and Cruz are doing is impossible."}, {"time": 3500, "text": "Currently, what we're doing is the perception problem is converting the scene into a chessboard."}, {"time": 3509, "text": "And then you reason some basic reasoning around that chessboard."}, {"time": 3513, "text": "And you're saying that really, there's a lot missing there."}, {"time": 3518, "text": "First of all, why are we talking about this?"}, {"time": 3520, "text": "Because isn't this a full autonomy?"}, {"time": 3522, "text": "Is this something you think about?"}, {"time": 3524, "text": "Oh, I want to win self driving cars."}, {"time": 3527, "text": "So your definition of win includes?"}, {"time": 3531, "text": "Level four or five."}, {"time": 3533, "text": "Level five."}, {"time": 3533, "text": "I don't think level four is a real thing."}, {"time": 3535, "text": "I want to build the AlphaGo of driving."}, {"time": 3541, "text": "So AlphaGo is really end to end."}, {"time": 3546, "text": "Is, yeah, it's end to end."}, {"time": 3549, "text": "And do you think this whole problem, is that also kind of what you're getting at with the perception and the planning?"}, {"time": 3556, "text": "Is that this whole problem, the right way to do it is really to learn the entire thing."}, {"time": 3561, "text": "I'll argue that not only is it the right way, it's the only way that's going to exceed human performance."}, {"time": 3568, "text": "It's certainly true for Go."}, {"time": 3569, "text": "Everyone who tried to hand code Go things built human inferior things."}, {"time": 3573, "text": "And then someone came along and wrote some 10,000 line thing that doesn't know anything about Go that beat everybody."}, {"time": 3579, "text": "It's 10,000 lines."}, {"time": 3581, "text": "True, in that sense, the open question then that maybe I can ask you is driving is much harder than Go."}, {"time": 3593, "text": "The open question is how much harder?"}, {"time": 3596, "text": "So how, because I think the Elon Musk approach here with planning and perception is similar to what you're describing, which is really turning into not some kind of modular thing, but really do formulate it as a learning problem and solve the learning problem with scale."}, {"time": 3613, "text": "So how many years, put one is how many years would it take to solve this problem or just how hard is this freaking problem?"}, {"time": 3621, "text": "Well, the cool thing is I think there's a lot of value that we can deliver along the way."}, {"time": 3630, "text": "I think that you can build lane keeping assist actually plus adaptive cruise control, plus, okay, looking at ways, extends to like all of driving."}, {"time": 3645, "text": "Yeah, most of driving, right?"}, {"time": 3647, "text": "Oh, your adaptive cruise control treats red lights like cars, okay."}, {"time": 3651, "text": "So let's jump around."}, {"time": 3652, "text": "You mentioned that you didn't like navigate an autopilot."}, {"time": 3655, "text": "What advice, how would you make it better?"}, {"time": 3657, "text": "Do you think as a feature that if it's done really well, it's a good feature?"}, {"time": 3662, "text": "I think that it's too reliant on like hand coded hacks for like, how does navigate an autopilot do a lane change?"}, {"time": 3670, "text": "It actually does the same lane change every time and it feels mechanical."}, {"time": 3674, "text": "Humans do different lane changes."}, {"time": 3675, "text": "Humans sometime will do a slow one, sometimes do a fast one."}, {"time": 3678, "text": "Navigate an autopilot, at least every time I use it, it is the identical lane change."}, {"time": 3682, "text": "How do you learn?"}, {"time": 3684, "text": "I mean, this is a fundamental thing actually is the braking and then accelerating something that's still, Tesla probably does it better than most cars, but it still doesn't do a great job of creating a comfortable natural experience."}, {"time": 3699, "text": "And navigate an autopilot is just lane changes and extension of that."}, {"time": 3704, "text": "So how do you learn to do a natural lane change?"}, {"time": 3709, "text": "So we have it and I can talk about how it works."}, {"time": 3712, "text": "So I feel that we have the solution for lateral."}, {"time": 3718, "text": "We don't yet have the solution for longitudinal."}, {"time": 3720, "text": "There's a few reasons longitudinal is harder than lateral."}, {"time": 3723, "text": "The lane change component, the way that we train on it very simply is like our model has an input for whether it's doing a lane change or not."}, {"time": 3734, "text": "And then when we train the end to end model, we hand label all the lane changes, cause you have to."}, {"time": 3739, "text": "I've struggled a long time about not wanting to do that, but I think you have to."}, {"time": 3744, "text": "Or the training data."}, {"time": 3745, "text": "For the training data, right?"}, {"time": 3746, "text": "Oh, we actually, we have an automatic ground truther which automatically labels all the lane changes."}, {"time": 3750, "text": "Was that possible?"}, {"time": 3751, "text": "To automatically label the lane changes?"}, {"time": 3753, "text": "Yeah, detect the lane, I see when it crosses it, right?"}, {"time": 3754, "text": "And I don't have to get that high percent accuracy, but it's like 95, good enough."}, {"time": 3758, "text": "Now I set the bit when it's doing the lane change in the end to end learning."}, {"time": 3764, "text": "And then I set it to zero when it's not doing a lane change."}, {"time": 3767, "text": "So now if I wanted to do a lane change at test time, I just put the bit to a one and it'll do a lane change."}, {"time": 3772, "text": "Yeah, but so if you look at the space of lane change, you know, some percentage, not a hundred percent that we make as humans is not a pleasant experience cause we messed some part of it up."}, {"time": 3782, "text": "It's nerve wracking to change the look, you have to see, it has to accelerate."}, {"time": 3786, "text": "How do we label the ones that are natural and feel good?"}, {"time": 3789, "text": "You know, that's the, cause that's your ultimate criticism."}, {"time": 3793, "text": "The current navigate and autopilot just doesn't feel good."}, {"time": 3796, "text": "Well, the current navigate and autopilot is a hand coded policy written by an engineer in a room who probably went out and tested it a few times on the 280."}, {"time": 3805, "text": "Probably a more, a better version of that, but yes."}, {"time": 3809, "text": "That's how we would have written it at Comma AI."}, {"time": 3811, "text": "Maybe Tesla did, Tesla, they tested it in the end."}, {"time": 3813, "text": "That might've been two engineers."}, {"time": 3815, "text": "Two engineers, yeah."}, {"time": 3817, "text": "No, but so if you learn the lane change, if you learn how to do a lane change from data, just like you have a label that says lane change and then you put it in when you want it to do the lane change, it'll automatically do the lane change that's appropriate for the situation."}, {"time": 3831, "text": "Now, to get at the problem of some humans do bad lane changes, we haven't worked too much on this problem yet."}, {"time": 3839, "text": "It's not that much of a problem in practice."}, {"time": 3843, "text": "My theory is that all good drivers are good in the same way and all bad drivers are bad in different ways."}, {"time": 3849, "text": "And we've seen some data to back this up."}, {"time": 3851, "text": "Well, beautifully put."}, {"time": 3852, "text": "So you just basically, if that's true hypothesis, then your task is to discover the good drivers."}, {"time": 3859, "text": "The good drivers stand out because they're in one cluster and the bad drivers are scattered all over the place and your net learns the cluster."}, {"time": 3867, "text": "Yeah, that's, so you just learn from the good drivers and they're easy to cluster."}, {"time": 3873, "text": "In fact, we learned from all of them and the net automatically learns the policy that's like the majority, but we'll eventually probably have to filter them out."}, {"time": 3878, "text": "If that theory is true, I hope it's true because the counter theory is there is many clusters, maybe arbitrarily many clusters of good drivers."}, {"time": 3893, "text": "Because if there's one cluster of good drivers, you can at least discover a set of policies."}, {"time": 3897, "text": "You can learn a set of policies, which would be good universally."}, {"time": 3901, "text": "That would be a nice, that would be nice if it's true."}, {"time": 3904, "text": "And you're saying that there is some evidence that."}, {"time": 3906, "text": "Let's say lane changes can be clustered into four clusters."}, {"time": 3910, "text": "There's this finite level of."}, {"time": 3912, "text": "I would argue that all four of those are good clusters."}, {"time": 3915, "text": "All the things that are random are noise and probably bad."}, {"time": 3918, "text": "And which one of the four you pick, or maybe it's 10 or maybe it's 20."}, {"time": 3921, "text": "You can learn that."}, {"time": 3922, "text": "It's context dependent."}, {"time": 3923, "text": "It depends on the scene."}, {"time": 3924, "text": "And the hope is it's not too dependent on the driver."}, {"time": 3931, "text": "The hope is that it all washes out."}, {"time": 3934, "text": "The hope is that there's, that the distribution's not bimodal."}, {"time": 3936, "text": "The hope is that it's a nice Gaussian."}, {"time": 3939, "text": "So what advice would you give to Tesla, how to fix, how to improve navigating autopilot?"}, {"time": 3944, "text": "That's the lessons that you've learned from Comm AI?"}, {"time": 3948, "text": "The only real advice I would give to Tesla is please put driver monitoring in your cars."}, {"time": 3952, "text": "With respect to improving it?"}, {"time": 3955, "text": "You can't do that anymore."}, {"time": 3955, "text": "I decided to interrupt, but you know, there's a practical nature of many of hundreds of thousands of cars being produced that don't have a good driver facing camera."}, {"time": 3965, "text": "The Model 3 has a selfie cam."}, {"time": 3967, "text": "Is it not good enough?"}, {"time": 3968, "text": "Did they not put IR LEDs for night?"}, {"time": 3971, "text": "But I do know that it's fisheye and it's relatively low resolution."}, {"time": 3975, "text": "So it's really not designed."}, {"time": 3977, "text": "It wasn't designed for driver monitoring."}, {"time": 3978, "text": "You can hope that you can kind of scrape up and have something from it."}, {"time": 3985, "text": "But why didn't they put it in today?"}, {"time": 3987, "text": "Put it in today."}, {"time": 3989, "text": "Every time I've heard Karpathy talk about the problem and talking about like software 2.0 and how the machine learning is gobbling up everything, I think this is absolutely the right strategy."}, {"time": 3997, "text": "I think that he didn't write navigate on autopilot."}, {"time": 4000, "text": "I think somebody else did and kind of hacked it on top of that stuff."}, {"time": 4003, "text": "I think when Karpathy says, wait a second, why did we hand code this lane change policy with all these magic numbers?"}, {"time": 4008, "text": "We're gonna learn it from data."}, {"time": 4009, "text": "They'll fix it."}, {"time": 4010, "text": "They already know what to do there."}, {"time": 4011, "text": "Well, that's Andrei's job is to turn everything into a learning problem and collect a huge amount of data."}, {"time": 4017, "text": "The reality is though, not every problem can be turned into a learning problem in the short term."}, {"time": 4024, "text": "In the end, everything will be a learning problem."}, {"time": 4027, "text": "The reality is like if you wanna build L5 vehicles today, it will likely involve no learning."}, {"time": 4035, "text": "And that's the reality is, so at which point does learning start?"}, {"time": 4040, "text": "It's the crutch statement that LiDAR is a crutch."}, {"time": 4043, "text": "At which point will learning get up to part of human performance?"}, {"time": 4047, "text": "It's over human performance on ImageNet, classification, on driving, it's a question still."}, {"time": 4054, "text": "It is a question."}, {"time": 4055, "text": "I'll say this, I'm here to play for 10 years."}, {"time": 4059, "text": "I'm not here to try to, I'm here to play for 10 years and make money along the way."}, {"time": 4063, "text": "I'm not here to try to promise people that I'm gonna have my L5 taxi network up and working in two years."}, {"time": 4068, "text": "Do you think that was a mistake?"}, {"time": 4070, "text": "What do you think was the motivation behind saying that?"}, {"time": 4073, "text": "Other companies are also promising L5 vehicles with very different approaches in 2020, 2021, 2022."}, {"time": 4081, "text": "If anybody would like to bet me that those things do not pan out, I will bet you."}, {"time": 4086, "text": "Even money, even money, I'll bet you as much as you want."}, {"time": 4090, "text": "So are you worried about what's going to happen?"}, {"time": 4093, "text": "Cause you're not in full agreement on that."}, {"time": 4096, "text": "What's going to happen when 2022, 21 come around and nobody has fleets of autonomous vehicles?"}, {"time": 4102, "text": "Well, you can look at the history."}, {"time": 4105, "text": "If you go back five years ago, they were all promised by 2018 and 2017."}, {"time": 4109, "text": "But they weren't that strong of promises."}, {"time": 4112, "text": "I mean, Ford really declared pretty, I think not many have declared as like definitively as they have now these dates."}, {"time": 4122, "text": "Well, okay, so let's separate L4 and L5."}, {"time": 4125, "text": "Do I think that it's possible for Waymo to continue to kind of like hack on their system until it gets to level four in Chandler, Arizona?"}, {"time": 4135, "text": "When there's no safety driver?"}, {"time": 4136, "text": "Chandler, Arizona?"}, {"time": 4139, "text": "By, sorry, which year are we talking about?"}, {"time": 4142, "text": "Oh, I even think that's possible by like 2020, 2021."}, {"time": 4146, "text": "But level four, Chandler, Arizona, not level five, New York City."}, {"time": 4150, "text": "Level four, meaning some very defined streets, it works out really well."}, {"time": 4157, "text": "Very defined streets."}, {"time": 4158, "text": "And then practically these streets are pretty empty."}, {"time": 4160, "text": "If most of the streets are covered in Waymo's, Waymo can kind of change the definition of what driving is."}, {"time": 4169, "text": "If your self driving network is the majority of cars in an area, they only need to be safe with respect to each other and all the humans will need to learn to adapt to them."}, {"time": 4178, "text": "Now go drive in downtown New York."}, {"time": 4181, "text": "Well, yeah, that's."}, {"time": 4182, "text": "I mean, already you can talk about autonomy and like on farms, it already works great because you can really just follow the GPS line."}, {"time": 4191, "text": "So what does success look like for common AI?"}, {"time": 4195, "text": "What are the milestones?"}, {"time": 4197, "text": "Like where you can sit back with some champagne and say, we did it, boys and girls?"}, {"time": 4204, "text": "Well, it's never over."}, {"time": 4207, "text": "You must drink champagne and celebrate."}, {"time": 4210, "text": "So what is a good, what are some wins?"}, {"time": 4213, "text": "A big milestone that we're hoping for by mid next year is profitability of the company."}, {"time": 4223, "text": "And we're gonna have to revisit the idea of selling a consumer product, but it's not gonna be like the comma one."}, {"time": 4232, "text": "When we do it, it's gonna be perfect."}, {"time": 4235, "text": "Open pilot has gotten so much better in the last two years."}, {"time": 4239, "text": "We're gonna have a few features."}, {"time": 4241, "text": "We're gonna have a hundred percent driver monitoring."}, {"time": 4243, "text": "We're gonna disable no safety features in the car."}, {"time": 4247, "text": "Actually, I think it'd be really cool what we're doing right now."}, {"time": 4249, "text": "Our project this week is we're analyzing the data set and looking for all the AEB triggers from the manufacturer systems."}, {"time": 4255, "text": "We have better data set on that than the manufacturers."}, {"time": 4259, "text": "How much, just how many, does Toyota have 10 million miles of real world driving to know how many times their AEB triggered?"}, {"time": 4265, "text": "So let me give you, cause you asked, right?"}, {"time": 4268, "text": "Financial advice."}, {"time": 4270, "text": "Cause I work with a lot of automakers and one possible source of money for you, which I'll be excited to see you take on is basically selling the data."}, {"time": 4284, "text": "So, which is something that most people, and not selling in a way where here, here at Automaker, but creating, we've done this actually at MIT, not for money purposes, but you could do it for significant money purposes and make the world a better place by creating a consortia where automakers would pay in and then they get to have free access to the data."}, {"time": 4306, "text": "And I think a lot of people are really hungry for that and would pay significant amount of money for it."}, {"time": 4314, "text": "Here's the problem with that."}, {"time": 4315, "text": "I like this idea all in theory."}, {"time": 4316, "text": "It'd be very easy for me to give them access to my servers and we already have all open source tools to access this data."}, {"time": 4322, "text": "It's in a great format."}, {"time": 4323, "text": "We have a great pipeline, but they're gonna put me in the room with some business development guy."}, {"time": 4330, "text": "And I'm gonna have to talk to this guy and he's not gonna know most of the words I'm saying."}, {"time": 4335, "text": "I'm not willing to tolerate that."}, {"time": 4337, "text": "Okay, Mick Jagger."}, {"time": 4338, "text": "No, no, no, no, no."}, {"time": 4339, "text": "I think I agree with you."}, {"time": 4341, "text": "I'm the same way, but you just tell them the terms and there's no discussion needed."}, {"time": 4344, "text": "If I could just tell them the terms, Yeah."}, {"time": 4348, "text": "and like, all right, who wants access to my data?"}, {"time": 4351, "text": "I will sell it to you for, let's say, you want a subscription?"}, {"time": 4357, "text": "I'll sell to you for 100K a month."}, {"time": 4360, "text": "Anyone."}, {"time": 4361, "text": "100K a month."}, {"time": 4363, "text": "I'll give you access to this data subscription."}, {"time": 4366, "text": "Yeah, I think that's kind of fair."}, {"time": 4366, "text": "Came up with that number off the top of my head."}, {"time": 4368, "text": "If somebody sends me like a three line email where it's like, we would like to pay 100K a month to get access to your data."}, {"time": 4374, "text": "We would agree to like reasonable privacy terms of the people who are in the data set."}, {"time": 4378, "text": "I would be happy to do it, but that's not going to be the email."}, {"time": 4381, "text": "The email is going to be, hey, do you have some time in the next month where we can sit down and we can, I don't have time for that."}, {"time": 4386, "text": "We're moving too fast."}, {"time": 4388, "text": "You could politely respond to that email, but not saying, I don't have any time for your bullshit."}, {"time": 4393, "text": "You say, oh, well, unfortunately these are the terms."}, {"time": 4395, "text": "And so this is, we try to, we brought the cost down for you in order to minimize the friction and communication."}, {"time": 4403, "text": "Here's the, whatever it is, one, two million dollars a year and you have access."}, {"time": 4408, "text": "And it's not like I get that email from like, but okay, am I going to reach out?"}, {"time": 4412, "text": "Am I going to hire a business development person who's going to reach out to the automakers?"}, {"time": 4417, "text": "I got you."}, {"time": 4418, "text": "If they reached into me, I'm not going to ignore the email."}, {"time": 4420, "text": "I'll come back with something like, yeah, if you're willing to pay 100K a month for access to the data, I'm happy to set that up."}, {"time": 4426, "text": "That's worth my engineering time."}, {"time": 4428, "text": "That's actually quite insightful of you."}, {"time": 4430, "text": "Probably because many of the automakers are quite a bit old school, there will be a need to reach out and they want it, but there'll need to be some communication."}, {"time": 4440, "text": "Mobileye circa 2015 had the lowest R&D spend of any chip maker, like per, per, and you look at all the people who work for them and it's all business development people because the car companies are impossible to work with."}, {"time": 4456, "text": "So you're, you have no patience for that and you're, you're legit Android, huh?"}, {"time": 4460, "text": "I have something to do, right?"}, {"time": 4461, "text": "Like, like it's not like, it's not like, I don't, like, I don't mean to like be a dick and say like, I don't have patience for that, but it's like that stuff doesn't help us with our goal of winning self driving cars."}, {"time": 4470, "text": "If I want money in the short term, if I showed off like the actual, like the learning tech that we have, it's, it's somewhat sad."}, {"time": 4479, "text": "Like it's years and years ahead of everybody else's."}, {"time": 4482, "text": "Not to, maybe not Tesla's."}, {"time": 4483, "text": "I think Tesla has some more stuff to us actually."}, {"time": 4486, "text": "I think Tesla has similar stuff, but when you compare it to like what the Toyota Research Institute has, you're not even close to what we have."}, {"time": 4493, "text": "No comments."}, {"time": 4494, "text": "But I also can't, I have to take your comments."}, {"time": 4498, "text": "I intuitively believe you, but I have to take it with a grain of salt because I mean, you are an inspiration because you basically don't care about a lot of things that other companies care about."}, {"time": 4510, "text": "You don't try to bullshit in a sense, like make up stuff."}, {"time": 4516, "text": "So to drive up valuation, you're really very real and you're trying to solve the problem and admire that a lot."}, {"time": 4522, "text": "What I don't necessarily fully can't trust you on, with all due respect, is how good it is, right?"}, {"time": 4528, "text": "I can only, but I also know how bad others are."}, {"time": 4533, "text": "I'll say two things about, trust but verify, right?"}, {"time": 4536, "text": "I'll say two things about that."}, {"time": 4538, "text": "One is try, get in a 2020 Corolla and try open pilot 0.6 when it comes out next month."}, {"time": 4546, "text": "I think already you'll look at this and you'll be like, this is already really good."}, {"time": 4551, "text": "And then I could be doing that all with hand labelers and all with like the same approach that Mobileye uses."}, {"time": 4557, "text": "When we release a model that no longer has the lanes in it, that only outputs a path, then think about how we did that machine learning and then right away when you see, and that's gonna be an open pilot, that's gonna be an open pilot before 1.0."}, {"time": 4573, "text": "When you see that model, you'll know that everything I'm saying is true because how else did I get that model?"}, {"time": 4577, "text": "You know what I'm saying is true about the simulator."}, {"time": 4579, "text": "Yeah, yeah, this is super exciting, that's super exciting."}, {"time": 4582, "text": "But like, you know, I listened to your talk with Kyle and Kyle was originally building the aftermarket system and he gave up on it because of technical challenges, because of the fact that he's gonna have to support 20 to 50 cars, we support 45, because what is he gonna do when the manufacturer ABS system triggers?"}, {"time": 4603, "text": "We have alerts and warnings to deal with all of that and all the cars."}, {"time": 4606, "text": "And how is he going to formally verify it?"}, {"time": 4608, "text": "Well, I got 10 million miles of data, it's probably better, it's probably better verified than the spec."}, {"time": 4613, "text": "Yeah, I'm glad you're here talking to me."}, {"time": 4617, "text": "This is, I'll remember this day, because it's interesting."}, {"time": 4621, "text": "If you look at Kyle's from cruise, I'm sure they have a large number of business development folks and you work with, he's working with GM, you could work with Argo AI, working with Ford."}, {"time": 4633, "text": "It's interesting because chances that you fail, business wise, like bankrupt, are pretty high."}, {"time": 4641, "text": "And yet, it's the Android model, is you're actually taking on the problem."}, {"time": 4646, "text": "So that's really inspiring, I mean."}, {"time": 4648, "text": "Well, I have a long term way for Comma to make money too."}, {"time": 4650, "text": "And one of the nice things when you really take on the problem, which is my hope for Autopilot, for example, is things you don't expect, ways to make money or create value that you don't expect will pop up."}, {"time": 4663, "text": "Oh, I've known how to do it since kind of, 2017 is the first time I said it."}, {"time": 4668, "text": "Which part, to know how to do which part?"}, {"time": 4670, "text": "Our long term plan is to be a car insurance company."}, {"time": 4672, "text": "Insurance, yeah, I love it, yep, yep."}, {"time": 4675, "text": "I make driving twice as safe."}, {"time": 4676, "text": "Not only that, I have the best data such to know who statistically is the safest drivers."}, {"time": 4679, "text": "And oh, oh, we see you, we see you driving unsafely, we're not gonna insure you."}, {"time": 4685, "text": "And that causes a bifurcation in the market because the only people who can't get Comma insurance are the bad drivers, Geico can insure them, their premiums are crazy high, our premiums are crazy low."}, {"time": 4695, "text": "We'll win car insurance, take over that whole market."}, {"time": 4699, "text": "If we win, if we win."}, {"time": 4701, "text": "But that's what I'm saying, how do you turn Comma into a $10 billion company?"}, {"time": 4705, "text": "So you, Elon Musk, who else?"}, {"time": 4709, "text": "Who else is thinking like this and working like this in your view?"}, {"time": 4713, "text": "Who are the competitors?"}, {"time": 4714, "text": "Are there people seriously, I don't think anyone that I'm aware of is seriously taking on lane keeping, like where it's a huge business that turns eventually into full autonomy that then creates, yeah, like that creates other businesses on top of it and so on."}, {"time": 4733, "text": "Thinks insurance, thinks all kinds of ideas like that."}, {"time": 4736, "text": "Do you know anyone else thinking like this?"}, {"time": 4742, "text": "I mean, my sense is everybody turns to that in like four or five years."}, {"time": 4747, "text": "Like Ford, once the autonomy doesn't fall through."}, {"time": 4751, "text": "But at this time."}, {"time": 4752, "text": "Elon's the iOS."}, {"time": 4754, "text": "By the way, he paved the way for all of us."}, {"time": 4756, "text": "It's the iOS, true."}, {"time": 4757, "text": "I would not be doing Comma AI today if it was not for those conversations with Elon."}, {"time": 4763, "text": "And if it were not for him saying like, I think he said like, well, obviously we're not gonna use LiDAR, we use cameras, humans use cameras."}, {"time": 4771, "text": "So what do you think about that?"}, {"time": 4772, "text": "How important is LiDAR?"}, {"time": 4773, "text": "Everybody else on L5 is using LiDAR."}, {"time": 4776, "text": "What are your thoughts on his provocative statement that LiDAR is a crutch?"}, {"time": 4781, "text": "See, sometimes he'll say dumb things, like the driver monitoring thing, but sometimes he'll say absolutely, completely, 100% obviously true things."}, {"time": 4788, "text": "Of course LiDAR is a crutch."}, {"time": 4790, "text": "It's not even a good crutch."}, {"time": 4793, "text": "You're not even using it."}, {"time": 4793, "text": "Oh, they're using it for localization."}, {"time": 4797, "text": "Which isn't good in the first place."}, {"time": 4798, "text": "If you have to localize your car to centimeters in order to drive, like that's not driving."}, {"time": 4804, "text": "Currently not doing much machine learning I thought for LiDAR data."}, {"time": 4807, "text": "Meaning like to help you in the task of, general task of perception."}, {"time": 4812, "text": "The main goal of those LiDARs on those cars I think is actually localization more than perception."}, {"time": 4818, "text": "Or at least that's what they use them for."}, {"time": 4820, "text": "Yeah, that's true."}, {"time": 4820, "text": "If you want to localize to centimeters, you can't use GPS."}, {"time": 4823, "text": "The fanciest GPS in the world can't do it."}, {"time": 4825, "text": "Especially if you're under tree cover and stuff."}, {"time": 4826, "text": "With LiDAR you can do this pretty easily."}, {"time": 4828, "text": "So you really, they're not taking on, I mean in some research they're using it for perception, but, and they're certainly not, which is sad, they're not fusing it well with vision."}, {"time": 4838, "text": "They do use it for perception."}, {"time": 4840, "text": "I'm not saying they don't use it for perception, but the thing that, they have vision based and radar based perception systems as well."}, {"time": 4847, "text": "You could remove the LiDAR and keep around a lot of the dynamic object perception."}, {"time": 4854, "text": "You want to get centimeter accurate localization?"}, {"time": 4856, "text": "Good luck doing that with anything else."}, {"time": 4859, "text": "So what should Cruz, Waymo do?"}, {"time": 4862, "text": "Like what would be your advice to them now?"}, {"time": 4866, "text": "I mean Waymo is actually, they're, I mean they're doing, they're serious."}, {"time": 4871, "text": "Waymo out of the ball of them are quite so serious about the long game."}, {"time": 4876, "text": "If L5 is a lot, requires 50 years, I think Waymo will be the only one left standing at the end with the, given the financial backing that they have."}, {"time": 4886, "text": "Buku Google bucks."}, {"time": 4888, "text": "I'll say nice things about both Waymo and Cruz."}, {"time": 4893, "text": "Nice is good."}, {"time": 4895, "text": "Waymo is by far the furthest along with technology."}, {"time": 4899, "text": "Waymo has a three to five year lead on all the competitors."}, {"time": 4904, "text": "If that, if the Waymo looking stack works, maybe three year lead."}, {"time": 4909, "text": "If the Waymo looking stack works, they have a three year lead."}, {"time": 4912, "text": "Now I argue that Waymo has spent too much money to recapitalize, to gain back their losses in those three years."}, {"time": 4920, "text": "Also self driving cars have no network effect like that."}, {"time": 4923, "text": "Uber has a network effect."}, {"time": 4924, "text": "You have a market, you have drivers and you have riders."}, {"time": 4927, "text": "Self driving cars, you have capital and you have riders."}, {"time": 4929, "text": "There's no network effect."}, {"time": 4931, "text": "If I want to blanket a new city in self driving cars, I buy the off the shelf Chinese knockoff self driving cars and I buy enough of them in the city."}, {"time": 4937, "text": "I can't do that with drivers."}, {"time": 4938, "text": "And that's why Uber has a first mover advantage that no self driving car company will."}, {"time": 4944, "text": "Can you disentangle that a little bit?"}, {"time": 4946, "text": "Uber, you're not talking about Uber, the autonomous vehicle Uber."}, {"time": 4949, "text": "You're talking about the Uber car, the, yeah."}, {"time": 4951, "text": "I'm Uber."}, {"time": 4952, "text": "I open for business in Austin, Texas, let's say."}, {"time": 4956, "text": "I need to attract both sides of the market."}, {"time": 4958, "text": "I need to both get drivers on my platform and riders on my platform."}, {"time": 4962, "text": "And I need to keep them both sufficiently happy, right?"}, {"time": 4965, "text": "Riders aren't gonna use it if it takes more than five minutes for an Uber to show up."}, {"time": 4969, "text": "Drivers aren't gonna use it if they have to sit around all day and there's no riders."}, {"time": 4972, "text": "So you have to carefully balance a market."}, {"time": 4974, "text": "And whenever you have to carefully balance a market, there's a great first mover advantage because there's a switching cost for everybody, right?"}, {"time": 4981, "text": "The drivers and the riders would have to switch at the same time."}, {"time": 4984, "text": "Let's even say that, you know, let's say a Luber shows up and Luber somehow, you know, agrees to do things at a bigger, you know, we're just gonna, we've done it more efficiently, right?"}, {"time": 4997, "text": "Luber is only takes 5% of a cut instead of the 10% that Uber takes."}, {"time": 5001, "text": "No one is gonna switch because the switching cost is higher than that 5%."}, {"time": 5005, "text": "So you actually can, in markets like that, you have a first mover advantage."}, {"time": 5010, "text": "Autonomous vehicles of the level five variety have no first mover advantage."}, {"time": 5014, "text": "If the technology becomes commoditized, say I wanna go to a new city, look at the scooters."}, {"time": 5019, "text": "It's gonna look a lot more like scooters."}, {"time": 5021, "text": "Every person with a checkbook can blanket a city in scooters."}, {"time": 5025, "text": "And that's why you have 10 different scooter companies."}, {"time": 5027, "text": "Which one's gonna win?"}, {"time": 5028, "text": "It's a race to the bottom."}, {"time": 5029, "text": "It's a terrible market to be in because there's no market for scooters."}, {"time": 5035, "text": "And the scooters don't get a say in whether they wanna be bought and deployed to a city or not."}, {"time": 5039, "text": "So the, yeah."}, {"time": 5040, "text": "We're gonna entice the scooters with subsidies and deals and."}, {"time": 5043, "text": "So whenever you have to invest that capital, it doesn't."}, {"time": 5046, "text": "It doesn't come back."}, {"time": 5048, "text": "That can't be your main criticism of the Waymo approach."}, {"time": 5052, "text": "Oh, I'm saying even if it does technically work."}, {"time": 5054, "text": "Even if it does technically work, that's a problem."}, {"time": 5058, "text": "I don't know if I were to say, I would say you're already there."}, {"time": 5063, "text": "I haven't even thought about that, but I would say the bigger challenge is the technical approach."}, {"time": 5069, "text": "So Waymo's cruises."}, {"time": 5071, "text": "And not just the technical approach, but of creating value."}, {"time": 5074, "text": "I still don't understand how you beat Uber, the human driven cars."}, {"time": 5083, "text": "In terms of financially, it doesn't make sense to me that people wanna get in an autonomous vehicle."}, {"time": 5090, "text": "I don't understand how you make money."}, {"time": 5092, "text": "In the longterm, yes."}, {"time": 5094, "text": "Like real longterm."}, {"time": 5096, "text": "But it just feels like there's too much capital investment needed."}, {"time": 5099, "text": "Oh, and they're gonna be worse than Ubers because they're gonna stop for every little thing, everywhere."}, {"time": 5106, "text": "I'll say a nice thing about cruise."}, {"time": 5107, "text": "That was my nice thing about Waymo."}, {"time": 5108, "text": "They're three years ahead."}, {"time": 5109, "text": "Wait, what was the nice?"}, {"time": 5110, "text": "Oh, because they're three."}, {"time": 5110, "text": "They're three years technically ahead of everybody."}, {"time": 5112, "text": "Their tech stack is great."}, {"time": 5114, "text": "My nice thing about cruise is GM buying them was a great move for GM."}, {"time": 5120, "text": "For $1 billion, GM bought an insurance policy against Waymo."}, {"time": 5125, "text": "They put, cruise is three years behind Waymo."}, {"time": 5130, "text": "That means Google will get a monopoly on the technology for at most three years."}, {"time": 5136, "text": "And if technology works, so you might not even be right about the three years, it might be less."}, {"time": 5141, "text": "Might be less."}, {"time": 5142, "text": "Cruise actually might not be that far behind."}, {"time": 5144, "text": "I don't know how much Waymo has waffled around or how much of it actually is just that long tail."}, {"time": 5150, "text": "If that's the best you could say in terms of nice things, that's more of a nice thing for GM that that's the smart insurance policy."}, {"time": 5158, "text": "It's a smart insurance policy."}, {"time": 5159, "text": "I mean, I think that's how, I can't see cruise working out any other."}, {"time": 5165, "text": "For cruise to leapfrog Waymo would really surprise me."}, {"time": 5170, "text": "Yeah, so let's talk about the underlying assumption of everything is."}, {"time": 5173, "text": "We're not gonna leapfrog Tesla."}, {"time": 5177, "text": "Tesla would have to seriously mess up for us because you're."}, {"time": 5180, "text": "Okay, so the way you leapfrog, right?"}, {"time": 5183, "text": "Is you come up with an idea or you take a direction perhaps secretly that the other people aren't taking."}, {"time": 5191, "text": "And so the cruise, Waymo, even Aurora."}, {"time": 5198, "text": "I don't know Aurora, Zooks is the same stack as well."}, {"time": 5200, "text": "They're all the same code base even."}, {"time": 5201, "text": "And they're all the same DARPA Urban Challenge code base."}, {"time": 5205, "text": "So the question is, do you think there's a room for brilliance and innovation that will change everything?"}, {"time": 5210, "text": "Like say, okay, so I'll give you examples."}, {"time": 5213, "text": "It could be if revolution and mapping, for example, that allow you to map things, do HD maps of the whole world, all weather conditions somehow really well, or revolution and simulation to where the all the way you said before becomes incorrect."}, {"time": 5240, "text": "That kind of thing."}, {"time": 5241, "text": "Any room for breakthrough innovation?"}, {"time": 5244, "text": "What I said before about, oh, they actually get the whole thing."}, {"time": 5247, "text": "Well, I'll say this about, we divide driving into three problems and I actually haven't solved the third yet, but I haven't had you how to do it."}, {"time": 5254, "text": "So there's the static."}, {"time": 5256, "text": "The static driving problem is assuming you are the only car on the road, right?"}, {"time": 5260, "text": "And this problem can be solved 100% with mapping and localization."}, {"time": 5263, "text": "This is why farms work the way they do."}, {"time": 5265, "text": "If all you have to deal with is the static problem and you can statically schedule your machines, right?"}, {"time": 5270, "text": "It's the same as like statically scheduling processes."}, {"time": 5272, "text": "You can statically schedule your tractors to never hit each other on their paths, right?"}, {"time": 5276, "text": "Cause they know the speed they go at."}, {"time": 5277, "text": "So that's the static driving problem."}, {"time": 5280, "text": "Maps only helps you with the static driving problem."}, {"time": 5283, "text": "Yeah, the question about static driving, you've just made it sound like it's really easy."}, {"time": 5288, "text": "Static driving is really easy."}, {"time": 5291, "text": "How easy?"}, {"time": 5293, "text": "How, well, cause the whole drifting out of lane, when Tesla drifts out of lane, it's failing on the fundamental static driving problem."}, {"time": 5302, "text": "Tesla is drifting out of lane?"}, {"time": 5304, "text": "The static driving problem is not easy for the world."}, {"time": 5307, "text": "The static driving problem is easy for one route."}, {"time": 5311, "text": "One route and one weather condition with one state of lane markings and like no deterioration, no cracks in the road."}, {"time": 5320, "text": "No, I'm assuming you have a perfect localizer."}, {"time": 5322, "text": "So that's solved for the weather condition and the lane marking condition."}, {"time": 5325, "text": "But that's the problem is, how do you have a perfect localizer?"}, {"time": 5328, "text": "Perfect localizers are not that hard to build."}, {"time": 5330, "text": "Okay, come on now, with LIDAR?"}, {"time": 5333, "text": "With LIDAR, yeah."}, {"time": 5334, "text": "Oh, with LIDAR, okay."}, {"time": 5335, "text": "With LIDAR, yeah, but you use LIDAR, right?"}, {"time": 5336, "text": "Like use LIDAR, build a perfect localizer."}, {"time": 5338, "text": "Building a perfect localizer without LIDAR, it's gonna be hard."}, {"time": 5344, "text": "You can get 10 centimeters without LIDAR, you can get one centimeter with LIDAR."}, {"time": 5347, "text": "I'm not even concerned about the one or 10 centimeters."}, {"time": 5349, "text": "I'm concerned if every once in a while, you're just way off."}, {"time": 5352, "text": "Yeah, so this is why you have to carefully make sure you're always tracking your position."}, {"time": 5359, "text": "You wanna use LIDAR camera fusion, but you can get the reliability of that system up to 100,000 miles, and then you write some fallback condition where it's not that bad if you're way off, right?"}, {"time": 5372, "text": "I think that you can get it to the point, it's like ASLD that you're never in a case where you're way off and you don't know it."}, {"time": 5378, "text": "Yeah, okay, so this is brilliant."}, {"time": 5380, "text": "So that's the static."}, {"time": 5380, "text": "Static."}, {"time": 5382, "text": "We can, especially with LIDAR and good HG maps, you can solve that problem."}, {"time": 5387, "text": "No, I just disagree with your word easy."}, {"time": 5390, "text": "The static problem's so easy."}, {"time": 5391, "text": "It's very typical for you to say something is easy."}, {"time": 5394, "text": "It's not as challenging as the other ones, okay."}, {"time": 5396, "text": "Well, okay, maybe it's obvious how to solve it."}, {"time": 5398, "text": "The third one's the hardest."}, {"time": 5400, "text": "And a lot of people don't even think about the third one and even see it as different from the second one."}, {"time": 5403, "text": "So the second one is dynamic."}, {"time": 5405, "text": "The second one is like, say there's an obvious example is like a car stopped at a red light, right?"}, {"time": 5410, "text": "You can't have that car in your map because you don't know whether that car is gonna be there or not."}, {"time": 5414, "text": "So you have to detect that car in real time and then you have to do the appropriate action, right?"}, {"time": 5421, "text": "Also, that car is not a fixed object."}, {"time": 5424, "text": "That car may move and you have to predict what that car will do, right?"}, {"time": 5428, "text": "So this is the dynamic problem."}, {"time": 5431, "text": "So you have to deal with this."}, {"time": 5432, "text": "This involves, again, like you're gonna need models of other people's behavior."}, {"time": 5439, "text": "Are you including in that, I don't wanna step on the third one."}, {"time": 5443, "text": "But are you including in that your influence on people?"}, {"time": 5446, "text": "Ah, that's the third one."}, {"time": 5449, "text": "That's the third one."}, {"time": 5449, "text": "We call it the counterfactual."}, {"time": 5453, "text": "I just talked to Judea Pearl who's obsessed with counterfactuals."}, {"time": 5455, "text": "And the counterfactual."}, {"time": 5456, "text": "Oh yeah, yeah, I read his books."}, {"time": 5458, "text": "So the static and the dynamic Yeah."}, {"time": 5461, "text": "Our approach right now for lateral will scale completely to the static and dynamic."}, {"time": 5467, "text": "The counterfactual, the only way I have to do it yet, the thing that I wanna do once we have all of these cars is I wanna do reinforcement learning on the world."}, {"time": 5476, "text": "I'm always gonna turn the exploiter up to max."}, {"time": 5478, "text": "I'm not gonna have them explore."}, {"time": 5480, "text": "But the only real way to get at the counterfactual is to do reinforcement learning because the other agents are humans."}, {"time": 5487, "text": "So that's fascinating that you break it down like that."}, {"time": 5490, "text": "I agree completely."}, {"time": 5491, "text": "I've spent my life thinking about this problem."}, {"time": 5494, "text": "And part of it, because you're slightly insane, it's good."}, {"time": 5501, "text": "Not my life."}, {"time": 5502, "text": "Just the last four years."}, {"time": 5503, "text": "You have some nonzero percent of your brain has a madman in it, which is good."}, {"time": 5511, "text": "That's a really good feature."}, {"time": 5512, "text": "But there's a safety component to it that I think sort of with counterfactuals and so on that would just freak people out."}, {"time": 5520, "text": "How do you even start to think about just in general?"}, {"time": 5523, "text": "I mean, you've had some friction with NHTSA and so on."}, {"time": 5527, "text": "I am frankly exhausted by safety engineers."}, {"time": 5534, "text": "The prioritization on safety over innovation to a degree where it kills, in my view, kills safety in the long term."}, {"time": 5546, "text": "So the counterfactual thing, they just actually exploring this world of how do you interact with dynamic objects and so on."}, {"time": 5553, "text": "How do you think about safety?"}, {"time": 5554, "text": "You can do reinforcement learning without ever exploring."}, {"time": 5558, "text": "And I said that, so you can think about your, in reinforcement learning, it's usually called a temperature parameter."}, {"time": 5564, "text": "And your temperature parameter is how often you deviate from the argmax."}, {"time": 5568, "text": "I could always set that to zero and still learn."}, {"time": 5570, "text": "And I feel that you'd always want that set to zero on your actual system."}, {"time": 5574, "text": "But the problem is you first don't know very much."}, {"time": 5578, "text": "And so you're going to make mistakes."}, {"time": 5579, "text": "So the learning, the exploration happens through mistakes."}, {"time": 5582, "text": "Yeah, but okay."}, {"time": 5583, "text": "So the consequences of a mistake."}, {"time": 5586, "text": "Open pilot and autopilot are making mistakes left and right."}, {"time": 5589, "text": "We have 700 daily active users, a thousand weekly active users."}, {"time": 5594, "text": "Open pilot makes tens of thousands of mistakes a week."}, {"time": 5598, "text": "These mistakes have zero consequences."}, {"time": 5601, "text": "These mistakes are, oh, I wanted to take this exit and it went straight."}, {"time": 5606, "text": "So I'm just going to carefully touch the wheel."}, {"time": 5608, "text": "The humans catch them."}, {"time": 5610, "text": "And the human disengagement is labeling that reinforcement learning in a completely consequence free way."}, {"time": 5617, "text": "So driver monitoring is the way you ensure they keep."}, {"time": 5620, "text": "They keep paying attention."}, {"time": 5622, "text": "How is your messaging?"}, {"time": 5623, "text": "Say I gave you a billion dollars, you would be scaling it now."}, {"time": 5627, "text": "Oh, I couldn't scale it with any amount of money."}, {"time": 5629, "text": "I'd raise money if I could, if I had a way to scale it."}, {"time": 5631, "text": "Yeah, you're now not focused on scale."}, {"time": 5633, "text": "I don't know how to do, oh, like I guess I could sell it to more people, but I want to make the system better."}, {"time": 5637, "text": "Better, better."}, {"time": 5637, "text": "And I don't know how to, I mean."}, {"time": 5638, "text": "But what's the messaging here?"}, {"time": 5641, "text": "I got a chance to talk to Elon and he basically said that the human factor doesn't matter."}, {"time": 5649, "text": "You know, the human doesn't matter because the system will perform, there'll be sort of a, sorry to use the term, but like a singular, like a point where it gets just much better."}, {"time": 5657, "text": "And so the human, it won't really matter."}, {"time": 5660, "text": "But it seems like that human catching the system when it gets into trouble is like the thing which will make something like reinforcement learning work."}, {"time": 5672, "text": "So how do you think messaging for Tesla, for you should change, for the industry in general should change?"}, {"time": 5679, "text": "I think our messaging is pretty clear."}, {"time": 5680, "text": "At least like our messaging wasn't that clear in the beginning and I do kind of fault myself for that."}, {"time": 5685, "text": "We are proud right now to be a level two system."}, {"time": 5688, "text": "We are proud to be level two."}, {"time": 5690, "text": "If we talk about level four, it's not with the current hardware."}, {"time": 5693, "text": "It's not gonna be just a magical OTA upgrade."}, {"time": 5695, "text": "It's gonna be new hardware."}, {"time": 5697, "text": "It's gonna be very carefully thought out."}, {"time": 5699, "text": "Right now, we are proud to be level two and we have a rigorous safety model."}, {"time": 5703, "text": "I mean, not like, okay, rigorous, who knows what that means, but we at least have a safety model and we make it explicit as in safety.md in OpenPilot."}, {"time": 5711, "text": "And it says, seriously though, safety.md."}, {"time": 5717, "text": "This is brilliant, this is so Android."}, {"time": 5718, "text": "Well, this is the safety model and I like to have conversations like, sometimes people will come to you and they're like, your system's not safe."}, {"time": 5729, "text": "Okay, have you read my safety docs?"}, {"time": 5731, "text": "Would you like to have an intelligent conversation about this?"}, {"time": 5733, "text": "And the answer is always no."}, {"time": 5734, "text": "They just like scream about, it runs Python."}, {"time": 5738, "text": "Okay, what?"}, {"time": 5739, "text": "So you're saying that because Python's not real time, Python not being real time never causes disengagements."}, {"time": 5744, "text": "Disengagements are caused by, the model is QM."}, {"time": 5747, "text": "But safety.md says the following, first and foremost, the driver must be paying attention at all times."}, {"time": 5755, "text": "I still consider the software to be alpha software until we can actually enforce that statement, but I feel it's very well communicated to our users."}, {"time": 5763, "text": "Two more things."}, {"time": 5764, "text": "One is the user must be able to easily take control of the vehicle at all times."}, {"time": 5770, "text": "So if you step on the gas or brake with OpenPilot, it gives full manual control back to the user or press the cancel button."}, {"time": 5778, "text": "Step two, the car will never react so quickly, we define so quickly to be about one second, that you can't react in time."}, {"time": 5787, "text": "And we do this by enforcing torque limits, braking limits and acceleration limits."}, {"time": 5791, "text": "So we have like our torque limits way lower than Tesla's."}, {"time": 5796, "text": "This is another potential."}, {"time": 5799, "text": "If I could tweak Autopilot, I would lower their torque limit and I would add driver monitoring."}, {"time": 5802, "text": "Because Autopilot can jerk the wheel hard."}, {"time": 5806, "text": "OpenPilot can't."}, {"time": 5807, "text": "We limit, and all this code is open source, readable."}, {"time": 5812, "text": "And I believe now it's all Misra C compliant."}, {"time": 5814, "text": "What's that mean?"}, {"time": 5817, "text": "Misra is like the automotive coding standard."}, {"time": 5820, "text": "At first, I've come to respect."}, {"time": 5823, "text": "I've been reading like the standards lately and I've come to respect them."}, {"time": 5825, "text": "They're actually written by very smart people."}, {"time": 5827, "text": "Yeah, they're brilliant people actually."}, {"time": 5829, "text": "They have a lot of experience."}, {"time": 5831, "text": "They're sometimes a little too cautious, but in this case, it pays off."}, {"time": 5836, "text": "Misra is written by like computer scientists."}, {"time": 5838, "text": "And you can tell by the language they use."}, {"time": 5839, "text": "You can tell by the language they use, they talk about like whether certain conditions in Misra are decidable or undecidable."}, {"time": 5846, "text": "And you mean like the halting problem?"}, {"time": 5848, "text": "And yes, all right, you've earned my respect."}, {"time": 5851, "text": "I will read carefully what you have to say and we wanna make our code compliant with that."}, {"time": 5855, "text": "All right, so you're proud level two, beautiful."}, {"time": 5858, "text": "So you were the founder and I think CEO of Kama AI, then you were the head of research."}, {"time": 5864, "text": "What the heck are you now?"}, {"time": 5866, "text": "What's your connection to Kama AI?"}, {"time": 5867, "text": "I'm the president, but I'm one of those like unelected presidents of like a small dictatorship country, not one of those like elected presidents."}, {"time": 5875, "text": "Oh, so you're like Putin when he was like the, yeah, I got you."}, {"time": 5879, "text": "So there's a, what's the governance structure?"}, {"time": 5882, "text": "What's the future of Kama AI?"}, {"time": 5884, "text": "I mean, yeah, it's a business."}, {"time": 5887, "text": "Do you want, are you just focused on getting things right now, making some small amount of money in the meantime and then when it works, it works and you scale."}, {"time": 5897, "text": "Our burn rate is about 200K a month and our revenue is about 100K a month."}, {"time": 5903, "text": "So we need to forex our revenue, but we haven't like tried very hard at that yet."}, {"time": 5908, "text": "And the revenue is basically selling stuff online."}, {"time": 5910, "text": "Yeah, we sell stuff shop.kama.ai."}, {"time": 5912, "text": "Is there other, well, okay, so you'll have to figure out the revenue."}, {"time": 5915, "text": "That's our only, see, but to me, that's like respectable revenues."}, {"time": 5920, "text": "We make it by selling products to consumers who are honest and transparent about what they are."}, {"time": 5925, "text": "Most actually level four companies, right?"}, {"time": 5930, "text": "Cause you could easily start blowing up like smoke, like overselling the hype and feeding into, getting some fundraisers."}, {"time": 5939, "text": "Oh, you're the guy, you're a genius because you hacked the iPhone."}, {"time": 5941, "text": "Oh, I hate that, I hate that."}, {"time": 5943, "text": "Yeah, well, I can trade my social capital for more money."}, {"time": 5946, "text": "I did it once, I almost regret it doing it the first time."}, {"time": 5950, "text": "Well, on a small tangent, what's your, you seem to not like fame and yet you're also drawn to fame."}, {"time": 5958, "text": "Where are you on that currently?"}, {"time": 5964, "text": "Have you had some introspection, some soul searching?"}, {"time": 5967, "text": "Yeah, I actually, I've come to a pretty stable position on that."}, {"time": 5972, "text": "Like after the first time, I realized that I don't want attention from the masses."}, {"time": 5976, "text": "I want attention from people who I respect."}, {"time": 5980, "text": "Who do you respect?"}, {"time": 5981, "text": "I can give a list of people."}, {"time": 5983, "text": "So are these like Elon Musk type characters?"}, {"time": 5987, "text": "Yeah, well, actually, you know what?"}, {"time": 5990, "text": "I'll make it more broad than that."}, {"time": 5991, "text": "I won't make it about a person, I respect skill."}, {"time": 5994, "text": "I respect people who have skills, right?"}, {"time": 5996, "text": "And I would like to like be, I'm not gonna say famous, but be like known among more people who have like real skills."}, {"time": 6006, "text": "Who in cars do you think have skill, not do you respect?"}, {"time": 6015, "text": "Oh, Kyle Vogt has skill."}, {"time": 6017, "text": "A lot of people at Waymo have skill and I respect them."}, {"time": 6020, "text": "I respect them as engineers."}, {"time": 6023, "text": "Like I can think, I mean, I think about all the times in my life where I've been like dead set on approaches and they turn out to be wrong."}, {"time": 6029, "text": "So, I mean, this might, I might be wrong."}, {"time": 6031, "text": "I accept that."}, {"time": 6032, "text": "I accept that there's a decent chance that I'm wrong."}, {"time": 6036, "text": "And actually, I mean, having talked to Chris Hermsons, Sterling Anderson, those guys, I mean, I deeply respect Chris."}, {"time": 6043, "text": "I just admire the guy."}, {"time": 6046, "text": "He's legit."}, {"time": 6047, "text": "When you drive a car through the desert when everybody thinks it's impossible, that's legit."}, {"time": 6052, "text": "And then I also really respect the people who are like writing the infrastructure of the world, like the Linus Torvalds and the Chris Lattiners."}, {"time": 6057, "text": "They were doing the real work."}, {"time": 6059, "text": "I know, they're doing the real work."}, {"time": 6060, "text": "This, having talked to Chris, like Chris Lattiners, you realize, especially when they're humble, it's like you realize, oh, you guys, we're just using your, Oh yeah."}, {"time": 6070, "text": "All the hard work that you did."}, {"time": 6071, "text": "Yeah, that's incredible."}, {"time": 6073, "text": "What do you think, Mr. Anthony Lewandowski, what do you, he's another mad genius."}, {"time": 6081, "text": "Sharp guy, oh yeah."}, {"time": 6082, "text": "What, do you think he might long term become a competitor?"}, {"time": 6087, "text": "Oh, to comma?"}, {"time": 6088, "text": "Well, so I think that he has the other right approach."}, {"time": 6092, "text": "I think that right now there's two right approaches."}, {"time": 6095, "text": "One is what we're doing, and one is what he's doing."}, {"time": 6097, "text": "Can you describe, I think it's called Pronto AI."}, {"time": 6099, "text": "He started a new thing."}, {"time": 6100, "text": "Do you know what the approach is?"}, {"time": 6102, "text": "I actually don't know."}, {"time": 6103, "text": "Embark is also doing the same sort of thing."}, {"time": 6105, "text": "The idea is almost that you want to, so if you're, I can't partner with Honda and Toyota."}, {"time": 6111, "text": "Honda and Toyota are like 400,000 person companies."}, {"time": 6116, "text": "It's not even a company at that point."}, {"time": 6118, "text": "I don't think of it like, I don't personify it."}, {"time": 6120, "text": "I think of it like an object, but a trucker drives for a fleet, maybe that has like, some truckers are independent."}, {"time": 6129, "text": "Some truckers drive for fleets with a hundred trucks."}, {"time": 6131, "text": "There are tons of independent trucking companies out there."}, {"time": 6134, "text": "Start a trucking company and drive your costs down or figure out how to drive down the cost of trucking."}, {"time": 6143, "text": "Another company that I really respect is Nato."}, {"time": 6145, "text": "Actually, I respect their business model."}, {"time": 6147, "text": "Nato sells a driver monitoring camera and they sell it to fleet owners."}, {"time": 6153, "text": "If I owned a fleet of cars and I could pay 40 bucks a month to monitor my employees, this is gonna, it like reduces accidents 18%."}, {"time": 6165, "text": "It's so like that, in the space, that is like the business model that I like most respect."}, {"time": 6172, "text": "Cause they're creating value today."}, {"time": 6174, "text": "Yeah, which is a, that's a huge one."}, {"time": 6177, "text": "How do we create value today with some of this?"}, {"time": 6179, "text": "And the lane keeping thing is huge."}, {"time": 6181, "text": "And it sounds like you're creeping in or full steam ahead on the driver monitoring too, which I think actually where the short term value, if you can get it right."}, {"time": 6190, "text": "I still, I'm not a huge fan of the statement that everything has to have driver monitoring."}, {"time": 6195, "text": "I agree with that completely, but that statement usually misses the point that to get the experience of it right is not trivial."}, {"time": 6201, "text": "Oh no, not at all."}, {"time": 6202, "text": "In fact, like, so right now we have, I think the timeout depends on speed of the car, but we want to depend on like the scene state."}, {"time": 6212, "text": "If you're on like an empty highway, it's very different if you don't pay attention than if like you're like coming up to a traffic light."}, {"time": 6222, "text": "And longterm, it should probably learn from the driver because that's to do, I watched a lot of video."}, {"time": 6228, "text": "We've built a smartphone detector just to analyze how people are using smartphones and people are using it very differently."}, {"time": 6233, "text": "It's a texting styles."}, {"time": 6237, "text": "There's."}, {"time": 6238, "text": "We haven't watched nearly enough of the videos."}, {"time": 6240, "text": "We haven't, I got millions of miles of people driving cars."}, {"time": 6242, "text": "In this moment, I spent a large fraction of my time just watching videos because it's never fails to learn."}, {"time": 6250, "text": "Like it never, I've never failed from a video watching session to learn something I didn't know before."}, {"time": 6255, "text": "In fact, I usually like when I eat lunch, I'll sit, especially when the weather is good and just watch pedestrians with an eye to understand like from a computer vision eye, just to see can this model, can you predict, what are the decisions made?"}, {"time": 6270, "text": "And there's so many things that we don't understand."}, {"time": 6273, "text": "This is what I mean about the state vector."}, {"time": 6274, "text": "Yeah, it's, I'm trying to always think like, cause I'm understanding in my human brain, how do we convert that into, how hard is the learning problem here?"}, {"time": 6284, "text": "I guess is the fundamental question."}, {"time": 6286, "text": "So something that's from a hacking perspective, this is always comes up, especially with folks."}, {"time": 6294, "text": "Well, first the most popular question is the trolley problem, right?"}, {"time": 6298, "text": "So that's not a sort of a serious problem."}, {"time": 6301, "text": "There are some ethical questions I think that arise."}, {"time": 6306, "text": "Maybe you wanna, do you think there's any ethical, serious ethical questions?"}, {"time": 6311, "text": "We have a solution to the trolley problem at Comm.ai."}, {"time": 6314, "text": "Well, so there is actually an alert in our code, ethical dilemma detected."}, {"time": 6318, "text": "It's not triggered yet."}, {"time": 6318, "text": "We don't know how yet to detect the ethical dilemmas, but we're a level two system."}, {"time": 6322, "text": "So we're going to disengage and leave that decision to the human."}, {"time": 6325, "text": "You're such a troll."}, {"time": 6326, "text": "No, but the trolley problem deserves to be trolled."}, {"time": 6328, "text": "Yeah, that's a beautiful answer actually."}, {"time": 6332, "text": "I know, I gave it to someone who was like, sometimes people will ask, like you asked about the trolley problem, like you can have a kind of discussion about it."}, {"time": 6338, "text": "Like you get someone who's like really like earnest about it because it's the kind of thing where, if you ask a bunch of people in an office, whether we should use a SQL stack or a no SQL stack, if they're not that technical, they have no opinion."}, {"time": 6350, "text": "But if you ask them what color they want to paint the office, everyone has an opinion on that."}, {"time": 6354, "text": "And that's why the trolley problem is..."}, {"time": 6356, "text": "I mean, that's a beautiful answer."}, {"time": 6357, "text": "Yeah, we're able to detect the problem and we're able to pass it on to the human."}, {"time": 6361, "text": "Wow, I've never heard anyone say it."}, {"time": 6363, "text": "This is your nice escape route."}, {"time": 6366, "text": "Okay, but..."}, {"time": 6367, "text": "Proud level two."}, {"time": 6368, "text": "I'm proud level two."}, {"time": 6370, "text": "So the other thing that people have some concern about with AI in general is hacking."}, {"time": 6377, "text": "So how hard is it, do you think, to hack an autonomous vehicle, either through physical access or through the more sort of popular now, these adversarial examples on the sensors?"}, {"time": 6388, "text": "Okay, the adversarial examples one."}, {"time": 6390, "text": "You want to see some adversarial examples that affect humans, right?"}, {"time": 6394, "text": "Oh, well, there used to be a stop sign here, but I put a black bag over the stop sign and then people ran it, adversarial, right?"}, {"time": 6403, "text": "Like there's tons of human adversarial examples too."}, {"time": 6408, "text": "The question in general about like security, if you saw something just came out today and like there are always such hypey headlines about like how navigate on autopilot was fooled by a GPS spoof to take an exit."}, {"time": 6421, "text": "At least that's all they could do was take an exit."}, {"time": 6423, "text": "If your car is relying on GPS in order to have a safe driving policy, you're doing something wrong."}, {"time": 6430, "text": "If you're relying, and this is why V2V is such a terrible idea."}, {"time": 6434, "text": "V2V now relies on both parties getting communication right."}, {"time": 6439, "text": "This is not even, so I think of safety, security is like a special case of safety, right?"}, {"time": 6448, "text": "Safety is like we put a little, you know, piece of caution tape around the hole so that people won't walk into it by accident."}, {"time": 6455, "text": "Security is like put a 10 foot fence around the hole so you actually physically cannot climb into it with barbed wire on the top and stuff, right?"}, {"time": 6462, "text": "So like if you're designing systems that are like unreliable, they're definitely not secure."}, {"time": 6468, "text": "Your car should always do something safe using its local sensors."}, {"time": 6473, "text": "And then the local sensor should be hardwired."}, {"time": 6475, "text": "And then could somebody hack into your CAN bus and turn your steering wheel on your brakes?"}, {"time": 6478, "text": "Yes, but they could do it before common AI too, so."}, {"time": 6482, "text": "Let's think out of the box on some things."}, {"time": 6484, "text": "So do you think teleoperation has a role in any of this?"}, {"time": 6489, "text": "So remotely stepping in and controlling the cars?"}, {"time": 6493, "text": "No, I think that if the safety operation by design requires a constant link to the cars, I think it doesn't work."}, {"time": 6507, "text": "So that's the same argument you're using for V2I, V2V?"}, {"time": 6511, "text": "Well, there's a lot of non safety critical stuff you can do with V2I."}, {"time": 6515, "text": "I like V2I, I like V2I way more than V2V."}, {"time": 6517, "text": "Because V2I is already like, I already have internet in the car, right?"}, {"time": 6520, "text": "There's a lot of great stuff you can do with V2I."}, {"time": 6524, "text": "Like for example, you can, well, I already have V2I, Waze is V2I, right?"}, {"time": 6528, "text": "Waze can route me around traffic jams."}, {"time": 6530, "text": "That's a great example of V2I."}, {"time": 6532, "text": "And then, okay, the car automatically talks to that same service, like it works."}, {"time": 6535, "text": "So it's improving the experience, but it's not a fundamental fallback for safety."}, {"time": 6539, "text": "No, if any of your things that require wireless communication are more than QM, like have an ASL rating, it shouldn't be."}, {"time": 6550, "text": "You previously said that life is work and that you don't do anything to relax."}, {"time": 6557, "text": "So how do you think about hard work?"}, {"time": 6560, "text": "What do you think it takes to accomplish great things?"}, {"time": 6564, "text": "And there's a lot of people saying that there needs to be some balance."}, {"time": 6568, "text": "You need to, in order to accomplish great things, you need to take some time off, you need to reflect and so on."}, {"time": 6573, "text": "Now, and then some people are just insanely working, burning the candle on both ends."}, {"time": 6581, "text": "I think I was trolling in the Siraj interview when I said that."}, {"time": 6584, "text": "Off camera, right before I smoked a little bit of weed, like, you know, come on, this is a joke, right?"}, {"time": 6589, "text": "Like I do nothing to relax."}, {"time": 6590, "text": "Look where I am, I'm at a party, right?"}, {"time": 6592, "text": "Yeah, yeah, yeah, that's true."}, {"time": 6595, "text": "So no, no, of course I don't."}, {"time": 6598, "text": "When I say that life is work though, I mean that like, I think that what gives my life meaning is work."}, {"time": 6604, "text": "I don't mean that every minute of the day you should be working."}, {"time": 6606, "text": "I actually think this is not the best way to maximize results."}, {"time": 6609, "text": "I think that if you're working 12 hours a day, you should be working smarter and not harder."}, {"time": 6614, "text": "Well, so work gives you meaning."}, {"time": 6617, "text": "For some people, other sorts of meaning is personal relationships, like family and so on."}, {"time": 6624, "text": "You've also, in that interview with Siraj, or the trolling, mentioned that one of the things you look forward to in the future is AI girlfriends."}, {"time": 6634, "text": "So that's a topic that I'm very much fascinated by, not necessarily girlfriends, but just forming a deep connection with AI."}, {"time": 6642, "text": "What kind of system do you imagine when you say AI girlfriend, whether you were trolling or not?"}, {"time": 6647, "text": "No, that one I'm very serious about."}, {"time": 6649, "text": "And I'm serious about that on both a shallow level and a deep level."}, {"time": 6653, "text": "I think that VR brothels are coming soon and are going to be really cool."}, {"time": 6657, "text": "It's not cheating if it's a robot."}, {"time": 6659, "text": "I see the slogan already."}, {"time": 6663, "text": "But there's, I don't know if you've watched, or just watched the Black Mirror episode."}, {"time": 6668, "text": "I watched the latest one, yeah."}, {"time": 6671, "text": "Oh, the Ashley 2 one?"}, {"time": 6675, "text": "No, where there's two friends who are having sex with each other in... Oh, in the VR game."}, {"time": 6681, "text": "In the VR game."}, {"time": 6682, "text": "It's just two guys, but one of them was a female, yeah."}, {"time": 6687, "text": "Which is another mind blowing concept."}, {"time": 6689, "text": "That in VR, you don't have to be the form."}, {"time": 6693, "text": "You can be two animals having sex."}, {"time": 6698, "text": "I mean, I'll see how nice that the software maps the nerve endings, right?"}, {"time": 6700, "text": "Yeah, it's huge."}, {"time": 6701, "text": "I mean, yeah, they sweep a lot of the fascinating, really difficult technical challenges under the rug, like assuming it's possible to do the mapping of the nerve endings, then..."}, {"time": 6711, "text": "I wish, yeah, I saw that, the way they did it with the little like stim unit on the head, that'd be amazing."}, {"time": 6716, "text": "So, well, no, no, on a shallow level, like you could set up like almost a brothel with like real dolls and Oculus Quests, write some good software."}, {"time": 6726, "text": "I think it'd be a cool novelty experience."}, {"time": 6729, "text": "But no, on a deeper, like emotional level, I mean, yeah, I would really like to fall in love with a machine."}, {"time": 6738, "text": "Do you see yourself having a long term relationship of the kind monogamous relationship that we have now with a robot, with a AI system even, not even just a robot?"}, {"time": 6752, "text": "So I think about maybe my ideal future."}, {"time": 6758, "text": "When I was 15, I read Eliezer Yudkowsky's early writings on the singularity and like that AI is going to surpass human intelligence massively."}, {"time": 6773, "text": "He made some Moore's law based predictions that I mostly agree with."}, {"time": 6777, "text": "And then I really struggled for the next couple of years of my life."}, {"time": 6781, "text": "Like, why should I even bother to learn anything?"}, {"time": 6783, "text": "It's all gonna be meaningless when the machines show up."}, {"time": 6787, "text": "Maybe when I was that young, I was still a little bit more pure and really like clung to that."}, {"time": 6793, "text": "And then I'm like, well, the machines ain't here yet, you know, and I seem to be pretty good at this stuff."}, {"time": 6796, "text": "Let's try my best, you know, like what's the worst that happens."}, {"time": 6801, "text": "But the best possible future I see is me sort of merging with the machine."}, {"time": 6806, "text": "And the way that I personify this is in a long term monogamous relationship with a machine."}, {"time": 6812, "text": "Oh, you don't think there's a room for another human in your life, if you really truly merge with another machine?"}, {"time": 6819, "text": "I mean, I see merging."}, {"time": 6820, "text": "I see like the best interface to my brain is like the same relationship interface to merge with an AI, right?"}, {"time": 6829, "text": "What does that merging feel like?"}, {"time": 6832, "text": "I've seen couples who've been together for a long time."}, {"time": 6835, "text": "And like, I almost think of them as one person, like couples who spend all their time together and... That's fascinating."}, {"time": 6842, "text": "You're actually putting, what does that merging actually looks like?"}, {"time": 6846, "text": "It's not just a nice channel."}, {"time": 6848, "text": "Like a lot of people imagine it's just an efficient link, search link to Wikipedia or something."}, {"time": 6854, "text": "I don't believe in that."}, {"time": 6855, "text": "But it's more, you're saying that there's the same kind of relationship you have with another human, that's a deep relationship."}, {"time": 6860, "text": "That's what merging looks like."}, {"time": 6862, "text": "That's pretty..."}, {"time": 6864, "text": "I don't believe that link is possible."}, {"time": 6866, "text": "I think that that link, so you're like, oh, I'm gonna download Wikipedia right to my brain."}, {"time": 6870, "text": "My reading speed is not limited by my eyes."}, {"time": 6873, "text": "My reading speed is limited by my inner processing loop."}, {"time": 6876, "text": "And to like bootstrap that sounds kind of unclear how to do it and horrifying."}, {"time": 6882, "text": "But if I am with somebody and I'll use a somebody who is making a super sophisticated model of me and then running simulations on that model, I'm not gonna get into the question whether the simulations are conscious or not."}, {"time": 6895, "text": "I don't really wanna know what it's doing."}, {"time": 6898, "text": "But using those simulations to play out hypothetical futures for me, deciding what things to say to me, to guide me along a path."}, {"time": 6906, "text": "And that's how I envision it."}, {"time": 6908, "text": "So on that path to AI of superhuman level intelligence, you've mentioned that you believe in the singularity, that singularity is coming."}, {"time": 6918, "text": "Again, could be trolling, could be not, could be part, all trolling has truth in it."}, {"time": 6923, "text": "I don't know what that means anymore."}, {"time": 6924, "text": "What is the singularity?"}, {"time": 6925, "text": "Yeah, so that's really the question."}, {"time": 6928, "text": "How many years do you think before the singularity, what form do you think it will take?"}, {"time": 6932, "text": "Does that mean fundamental shifts in capabilities of AI?"}, {"time": 6935, "text": "Or does it mean some other kind of ideas?"}, {"time": 6939, "text": "Maybe that's just my roots, but."}, {"time": 6941, "text": "So I can buy a human beings worth of compute for like a million bucks today."}, {"time": 6946, "text": "It's about one TPU pod V3."}, {"time": 6947, "text": "I want like, I think they claim a hundred pay to flops."}, {"time": 6950, "text": "That's being generous."}, {"time": 6950, "text": "I think humans are actually more like 20."}]}, {"title": "Dmitri Dolgov: Waymo and the Future of Self-Driving Cars | Lex Fridman Podcast #147", "id": "P6prRXkI5HM", "quotes": [{"time": 277, "text": "It was, uh, like, uh, I think there are 300, 320 by 200, uh, whatever it was."}, {"time": 283, "text": "I think that kind of the earlier, that's the resolution, right?"}, {"time": 286, "text": "And I actually think the reason why this company wanted to buy it is not like the fancy graphics or the implementation."}, {"time": 291, "text": "That was maybe the idea, uh, of my actual game, the idea of the game."}, {"time": 297, "text": "Well, one of the things I, it's so funny."}, {"time": 299, "text": "I'm used to play this game called golden X and the simplicity of the graphics and something about the simplicity of the music, like it's still haunts me."}, {"time": 310, "text": "I don't know if that's a childhood thing."}, {"time": 312, "text": "I don't know if that's the same thing for call of duty these days for young kids, but I still think that the simple one of the games are simple."}, {"time": 321, "text": "That simple purity makes for like allows your imagination to take over and thereby creating a more magical experience."}, {"time": 330, "text": "Like now with better and better graphics, it feels like your imagination doesn't get to, uh, create worlds, which is kind of interesting."}, {"time": 338, "text": "Um, it could be just an old man on a porch, like way waving at kids these days that have no respect."}, {"time": 344, "text": "But I still think that graphics almost get in the way of the experience."}, {"time": 350, "text": "Flip a bird."}, {"time": 351, "text": "Yeah, I don't know if the imagination is closed."}, {"time": 357, "text": "I don't yet, but that that's more about games that op like that's more like Tetris world where they optimally masterfully, like create a fun, short term dopamine experience versus I'm more referring to like role playing games where there's like a story you can live in it for months or years."}, {"time": 378, "text": "Um, like, uh, there's an elder scroll series, which is probably my favorite set of games that was a magical experience."}, {"time": 386, "text": "And that the graphics are terrible."}, {"time": 388, "text": "The characters were all randomly generated, but they're, I don't know."}, {"time": 391, "text": "That's it pulls you in."}, {"time": 393, "text": "There's a story."}, {"time": 394, "text": "It's like an interactive version of an elder scrolls Tolkien world."}, {"time": 400, "text": "And you get to live in it."}, {"time": 403, "text": "I miss it."}, {"time": 404, "text": "It's one of the things that suck about being an adult is there's no, you have to live in the real world as opposed to the elder scrolls world, you know, whatever brings you joy, right?"}, {"time": 414, "text": "Minecraft, right?"}, {"time": 415, "text": "Minecraft is a great example."}, {"time": 416, "text": "You create, like it's not the fancy graphics, but it's the creation of your own worlds."}, {"time": 421, "text": "Yeah, that one is crazy."}, {"time": 422, "text": "You know, one of the pitches for being a parent that people tell me is that you can like use the excuse of parenting to, to go back into the video game world."}, {"time": 432, "text": "And like, like that's like, you know, father, son, father, daughter time, but really you just get to play video games with your kids."}, {"time": 439, "text": "So anyway, at that time, did you have any ridiculously ambitious dreams of where as a creator, you might go as an engineer?"}, {"time": 449, "text": "Did you, what, what did you think of yourself as, as an engineer, as a tinker, or did you want to be like an astronaut or something like that?"}, {"time": 457, "text": "You know, I'm tempted to make something up about, you know, robots, uh, engineering or, you know, mysteries of the universe, but that's not the actual memory that pops into my mind when you, when you asked me about childhood dreams."}, {"time": 468, "text": "So I'll actually share the, the, the real thing, uh, when I was maybe four or five years old, I, you know, as we all do, I thought about, you know, what I wanted to do when I grow up and I had this dream of being a traffic control cop."}, {"time": 488, "text": "Uh, you know, they don't have those today's I think, but you know, back in the eighties and in Russia, uh, you probably are familiar with that Lex."}, {"time": 495, "text": "They had these, uh, you know, police officers that would stand in the middle of intersection all day and they would have their like stripe back, black and white batons that they would use to control the flow of traffic and, you know, for whatever reasons, I was strangely infatuated with this whole process and like that, that was my dream."}, {"time": 512, "text": "Uh, that's what I wanted to do when I grew up and, you know, my parents, uh, both physics profs, by the way, I think were, you know, a little concerned, uh, with that level of ambition coming from their child."}, {"time": 524, "text": "Uh, uh, you know, that age."}, {"time": 526, "text": "Well, that it's an interesting, I don't know if you can relate, but I very much love that idea."}, {"time": 532, "text": "I have a OCD nature that I think lends itself very close to the engineering mindset, which is you want to kind of optimize, you know, solve a problem by create, creating an automated solution, like a, like a set of rules, that set of rules you can follow and then thereby make it ultra efficient."}, {"time": 554, "text": "I don't know if that's, it was of that nature."}, {"time": 557, "text": "I certainly have that."}, {"time": 558, "text": "There's like fact, like SimCity and factory building games, all those kinds of things kind of speak to that engineering mindset, or did you just like the uniform?"}, {"time": 567, "text": "I think it was more of the latter."}, {"time": 568, "text": "I think it was the uniform and the, you know, the, the stripe baton that made cars go in the right directions."}, {"time": 576, "text": "But I guess, you know, I, it is, I did end up, uh, I guess, uh, you know, working on the transportation industry one way or another uniform."}, {"time": 584, "text": "No, but that's right."}, {"time": 586, "text": "Maybe, maybe, maybe it was my, you know, deep inner infatuation with the, you know, traffic control batons that led to this career."}, {"time": 595, "text": "What, uh, when did you, when was the leap from programming to robotics?"}, {"time": 600, "text": "That happened later."}, {"time": 601, "text": "That was after grad school, uh, after, and I actually, the most self driving cars was I think my first real hands on introduction to robotics."}, {"time": 610, "text": "But I never really had that much hands on experience in school and training."}, {"time": 614, "text": "I, you know, worked on applied math and physics."}, {"time": 617, "text": "Then in college, I did more half, uh, abstract computer science."}, {"time": 623, "text": "And it was after grad school that I really got involved in robotics, which was actually self driving cars."}, {"time": 629, "text": "And, you know, that was a big flip."}, {"time": 632, "text": "What, uh, what grad school?"}, {"time": 634, "text": "So I went to grad school in Michigan, and then I did a postdoc at Stanford, uh, which is, that was the postdoc where I got to play with self driving cars."}, {"time": 642, "text": "So we'll return there."}, {"time": 643, "text": "Let's go back to, uh, to Moscow."}, {"time": 646, "text": "So, uh, you know, for episode 100, I talked to my dad and also I grew up with my dad, I guess."}, {"time": 653, "text": "Uh, so I had to put up with them for many years and, uh, he, he went to the FISTIEG or MIPT, it's weird to say in English, cause I've heard all this in Russian, Moscow Institute of Physics and Technology."}, {"time": 669, "text": "And to me, that was like, I met some super interesting, as a child, I met some super interesting characters."}, {"time": 677, "text": "It felt to me like the greatest university in the world, the most elite university in the world, and just the people that I met that came out of there were like, not only brilliant, but also special humans."}, {"time": 692, "text": "It seems like that place really tested the soul, uh, both like in terms of technically and like spiritually."}, {"time": 700, "text": "So that could be just the romanticization of that place."}, {"time": 703, "text": "I'm not sure, but so maybe you can speak to it, but is it correct to say that you spent some time at FISTIEG?"}, {"time": 711, "text": "Uh, I got my bachelor's and master's in physics and math there."}, {"time": 743, "text": "I went back there."}, {"time": 744, "text": "Yeah, that's exactly the reaction most of my peers in college had."}, {"time": 748, "text": "But, you know, perhaps a little bit stronger that like, you know, point me out as this crazy kid, were your parents supportive of that?"}, {"time": 755, "text": "My games, your previous question, they, uh, they supported me and, you know, letting me kind of pursue my passions and the things that I was interested in."}, {"time": 763, "text": "That's a bold move."}, {"time": 764, "text": "What was it like there?"}, {"time": 765, "text": "It was interesting, you know, definitely fairly hardcore on the fundamentals of, you know, math and physics and, uh, you know, lots of good memories, uh, from, you know, from those times."}, {"time": 776, "text": "So Stanford."}, {"time": 777, "text": "How'd you get into autonomous vehicles?"}, {"time": 779, "text": "I had the great fortune, uh, and great honor to join Stanford's DARPA urban challenge team."}, {"time": 787, "text": "And, uh, 2006 there, this was a third in the sequence of the DARPA challenges."}, {"time": 792, "text": "There were two grand challenges prior to that."}, {"time": 794, "text": "And then in 2007, they held the DARPA urban challenge."}, {"time": 799, "text": "So, you know, I was doing my, my postdoc I had, I joined the team and, uh, worked on motion planning, uh, for, you know, that, that competition."}, {"time": 810, "text": "So for people who might not know, I know from, from certain autonomous vehicles is a funny world in a certain circle of people, everybody knows everything."}, {"time": 819, "text": "And then the certain circle, uh, nobody knows anything in terms of general public."}, {"time": 826, "text": "It's, it's a good question of what to talk about, but I do think that the urban challenge is worth revisiting."}, {"time": 830, "text": "It's a fun little challenge."}, {"time": 836, "text": "One that, first of all, like sparked so much, so many incredible minds to focus on one of the hardest problems of our time in artificial intelligence."}, {"time": 846, "text": "So that's, that's a success from a perspective of a single little challenge."}, {"time": 851, "text": "But can you talk about like, what did the challenge involve?"}, {"time": 854, "text": "So were there pedestrians, were there other cars, what was the goal?"}, {"time": 858, "text": "Uh, who was on the team?"}, {"time": 860, "text": "How long did it take any fun, fun sort of specs?"}, {"time": 866, "text": "So the way the challenge was constructed and just a little bit of backgrounding, as I mentioned, this was the third, uh, competition in that series."}, {"time": 874, "text": "The first year we're at the grand challenge called the grand challenge."}, {"time": 876, "text": "The goal there was to just drive in a completely static environment."}, {"time": 880, "text": "You know, you had to drive in a desert, uh, that was very successful."}, {"time": 885, "text": "So then DARPA followed with what they called the urban challenge, where the goal was to have, you know, build vehicles that could operate in more dynamic environments and, you know, share them with other vehicles."}, {"time": 896, "text": "There were no pedestrians there, but what DARPA did is they took over an abandoned air force base."}, {"time": 902, "text": "Uh, and it was kind of like a little fake city that they built out there."}, {"time": 906, "text": "And they had a bunch of, uh, robots, uh, you know, cars, uh, that were autonomous, uh, in there all at the same time."}, {"time": 913, "text": "Uh, mixed in with other vehicles driven by professional, uh, drivers and each car, uh, had a mission and so there's a crude map that they received, uh, beginning and they had a mission and go here and then there and over here."}, {"time": 928, "text": "Um, and they kind of all were sharing this environment at the same time."}, {"time": 932, "text": "They had to interact with each other."}, {"time": 934, "text": "They had to interact with the human drivers."}, {"time": 936, "text": "There's this very first, very rudimentary, um, version of, uh, self driving car that, you know, could operate, uh, and, uh, in a, in an environment, you know, shared with other dynamic actors that, as you said, you know, really, you know, many ways, you know, kickstarted this whole industry."}, {"time": 955, "text": "So who was on the team and how'd you do?"}, {"time": 959, "text": "Uh, I came in second."}, {"time": 962, "text": "Uh, perhaps that was my contribution to the team."}, {"time": 965, "text": "I think the Stanford team came in first in the DARPA challenge."}, {"time": 990, "text": "Uh, so is there interesting mistakes?"}, {"time": 993, "text": "Is there interesting challenges that stand out to you as some, like, taught you, um, a good technical lesson or a good philosophical lesson from that time?"}, {"time": 1003, "text": "Uh, you know, definitely, definitely a very memorable time, not really challenged, but like one of the most vivid memories that I have from the time."}, {"time": 1012, "text": "And I think that was actually one of the days that really got me hooked, uh, on this whole field was, uh, the first time I got to run my software and I got to software on the car and, uh, I was working on a part of our planning algorithm, uh, that had to navigate in parking lots."}, {"time": 1033, "text": "So it was something that, you know, called free space emotion planning."}, {"time": 1036, "text": "So the very first version of that, uh, was, you know, we tried on the car, it was on Stanford's campus, uh, in the middle of the night and you had this little course constructed with cones, uh, in the middle of a parking lot."}, {"time": 1048, "text": "So we're there in like 3 am, you know, by the time we got the code to, you know, uh, uh, you know, compile and turn over, uh, and, you know, it drove, I could actually did something quite reasonable and, you know, it was of course very buggy at the time and had all kinds of problems, but it was pretty darn magical."}, {"time": 1068, "text": "I remember going back and, you know, later at night and trying to fall asleep and just, you know, being unable to fall asleep for the rest of the night, uh, just my mind was blown."}, {"time": 1077, "text": "Just like, and that, that, that's what I've been doing ever since for more than a decade, uh, in terms of challenges and, uh, you know, interesting memories, like on the day of the competition, uh, it was pretty nerve wrecking."}, {"time": 1090, "text": "Uh, I remember standing there with Mike Montemarillo, who was, uh, the software lead and wrote most of the code."}, {"time": 1095, "text": "I think I did one little part of the planner, Mike, you know, incredibly that, you know, pretty much the rest of it, uh, with, with, you know, a bunch of other incredible people, but I remember standing on the day of the competition, uh, you know, watching the car, you know, with Mike and cars are completely empty, right?"}, {"time": 1112, "text": "They're all there lined up in the beginning of the race and then, you know, DARPA sends them, you know, on their mission one by one."}, {"time": 1118, "text": "So then leave and Mike, you just, they had these sirens, they all had their different silence silence, right?"}, {"time": 1123, "text": "Each siren had its own personality, if you will."}, {"time": 1126, "text": "So, you know, off they go and you don't see them."}, {"time": 1128, "text": "You just kind of, and then every once in a while they come a little bit closer to where the audience is and you can kind of hear, you know, the sound of your car and then, you know, it seems to be moving along."}, {"time": 1137, "text": "So that, you know, gives you hope."}, {"time": 1138, "text": "And then, you know, it goes away and you can't hear it for too long."}, {"time": 1141, "text": "You start getting anxious, right?"}, {"time": 1142, "text": "So it's a little bit like, you know, sending your kids to college and like, you know, kind of you invested in them."}, {"time": 1145, "text": "You hope you, you, you, you, you, you, you build it properly, but like, it's still, uh, anxiety inducing."}, {"time": 1178, "text": "Very scenic though."}, {"time": 1179, "text": "So most people go there for the scenery."}, {"time": 1181, "text": "Um, yeah, it's a beautiful campus."}, {"time": 1185, "text": "I'm like, unlike Stanford."}, {"time": 1186, "text": "So for people, yeah, that's true."}, {"time": 1188, "text": "Unlike Stanford, for people who don't know, CMU is one of the great robotics and sort of artificial intelligence universities in the world, CMU, Carnegie Mellon university, okay, sorry, go ahead."}, {"time": 1198, "text": "Good, good PSA."}, {"time": 1199, "text": "So in the part that I contributed to, which was navigating parking lots and the way that part of the mission work is, uh, you in a parking lot, you would get from DARPA an outline of the map."}, {"time": 1215, "text": "You basically get this, you know, giant polygon that defined the perimeter of the parking lot, uh, and there would be an entrance and, you know, so maybe multiple entrances or access to it, and then you would get a goal, uh, within that open space, uh, X, Y, you know, heading where the car had to park and had no information about the optical, so obstacles that the car might encounter there."}, {"time": 1236, "text": "So it had to navigate a kind of completely free space, uh, from the entrance to the parking lot into that parking space."}, {"time": 1243, "text": "And then, uh, once parked there, it had to, uh, exit the parking lot, you know, while of course, I'm counting and reasoning about all the obstacles that it encounters in real time."}, {"time": 1254, "text": "So, uh, Our interpretation, or at least my interpretation of the rules was that you had to reverse out of the parking spot."}, {"time": 1263, "text": "And that's what our cars did."}, {"time": 1264, "text": "Even if there's no obstacle in front, that's not what CMU's car did."}, {"time": 1268, "text": "And it just kind of drove right through."}, {"time": 1270, "text": "So there's still a debate."}, {"time": 1272, "text": "And of course, you know, as you stop and then reverse out and go out the different way that costs you some time."}, {"time": 1276, "text": "And so there's still a debate whether, you know, it was my poor implementation that cost us extra time or whether it was, you know, CMU, uh, violating an important rule of the competition."}, {"time": 1287, "text": "And, you know, I have my own, uh, opinion here in terms of other bugs."}, {"time": 1290, "text": "And like, uh, I, I have to apologize to Mike Montemarila, uh, for sharing this on air, but it is actually, uh, one of the more memorable ones."}, {"time": 1298, "text": "Uh, and it's something that's kind of become a bit of, uh, a metaphor and a label in the industry, uh, since then, I think, you know, at least in some circles, it's called the victory circle or victory lap."}, {"time": 1309, "text": "Um, and, uh, uh, our cars did that."}, {"time": 1313, "text": "So in one of the missions in the urban challenge, in one of the courses, uh, there was this big oval, right by the start and finish of the race."}, {"time": 1322, "text": "So the ARPA had a lot of the missions would finish kind of in that same location."}, {"time": 1325, "text": "Uh, and it was pretty cool because you could see the cars come by, you know, kind of finished that part leg of the trip, that leg of the mission, and then, you know, go on and finish the rest of it."}, {"time": 1335, "text": "Uh, and other vehicles would, you know, come hit their waypoint, uh, and, you know, exit the oval and off they would go."}, {"time": 1344, "text": "Our car on the hand, which hit the checkpoint, and then it would do an extra lap around the oval and only then, you know, uh, leave and go on its merry way."}, {"time": 1351, "text": "So over the course of the full day, it accumulated, uh, uh, some extra time and the problem was that we had a bug where it wouldn't, you know, start reasoning about the next waypoint and plan a route to get to that next point until it hit a previous one."}, {"time": 1362, "text": "And in that particular case, by the time you hit the, that, that one, it was too late for us to consider the next one and kind of make a lane change."}, {"time": 1369, "text": "So at every time we would do like an extra lap."}, {"time": 1370, "text": "So, you know, and that's the Stanford victory lap."}, {"time": 1375, "text": "The victory lap."}, {"time": 1377, "text": "Oh, that's there's, I feel like there's something philosophically profound in there somehow, but, uh, I mean, ultimately everybody is a winner in that kind of competition."}, {"time": 1386, "text": "And it led to sort of famously to the creation of, um, Google self driving car project and now Waymo."}, {"time": 1395, "text": "So can we, uh, give an overview of how is Waymo born?"}, {"time": 1400, "text": "How's the Google self driving car project born?"}, {"time": 1403, "text": "What's the, what is the mission?"}, {"time": 1406, "text": "What is it is the engineering kind of, uh, set of milestones that it seeks to accomplish, there's a lot of questions in there."}, {"time": 1415, "text": "Uh, yeah, uh, I don't know, kind of the DARPA urban challenge and the DARPA and previous DARPA grand challenges, uh, kind of led, I think to a very large degree to that next step and then, you know, Larry and Sergey, um, uh, Larry Page and Sergey Brin, uh, uh, Google founders course, uh, I saw that competition and believed in the technology."}, {"time": 1434, "text": "So, you know, the Google self driving car project was born, you know, at that time."}, {"time": 1439, "text": "And we started in 2009, it was a pretty small group of us, about a dozen people, uh, who came together, uh, to, to work on this project at Google."}, {"time": 1449, "text": "At that time we saw an incredible early result in the DARPA urban challenge."}, {"time": 1458, "text": "I think we're all incredibly excited, uh, about where we got to and we believed in the future of the technology, but we still had a very, you know, very, you know, rudimentary understanding of the problem space."}, {"time": 1471, "text": "So the first goal of this project in 2009 was to really better understand what we're up against."}, {"time": 1479, "text": "Uh, and, you know, with that goal in mind, when we started the project, we created a few milestones for ourselves, uh, that."}, {"time": 1488, "text": "Maximized learnings."}, {"time": 1489, "text": "Well, the two milestones were, you know, uh, one was to drive a hundred thousand miles in autonomous mode, which was at that time, you know, orders of magnitude that, uh, more than anybody has ever done."}, {"time": 1501, "text": "And the second milestone was to drive 10 routes, uh, each one was a hundred miles long, uh, and there were specifically chosen to become extra spicy and extra complicated and sample the full complexity of the, that, that, uh, domain."}, {"time": 1518, "text": "Um, uh, and you had to drive each one from beginning to end with no intervention, no human intervention."}, {"time": 1524, "text": "So you would get to the beginning of the course, uh, you would press the button that would engage in autonomy and you had to go for a hundred miles, you know, beginning to end, uh, with no interventions."}, {"time": 1535, "text": "Um, and it sampled again, the full complexity of driving conditions."}, {"time": 1540, "text": "Some, uh, were on freeways."}, {"time": 1542, "text": "We had one route that went all through all the freeways and all the bridges in the Bay area."}, {"time": 1546, "text": "You know, we had, uh, some that went around Lake Tahoe and kind of mountains, uh, roads."}, {"time": 1552, "text": "We had some that drove through dense urban, um, environments like in downtown Palo Alto and through San Francisco."}, {"time": 1559, "text": "So it was incredibly, uh, interesting, uh, to work on."}, {"time": 1564, "text": "And it, uh, it took us just under two years, uh, about a year and a half, a little bit more to finish both of these milestones."}, {"time": 1574, "text": "And in that process, uh, you know, it was an incredible amount of fun, probably the most fun I had in my professional career."}, {"time": 1582, "text": "And you're just learning so much."}, {"time": 1584, "text": "You are, you know, the goal here is to learn and prototype."}, {"time": 1586, "text": "You're not yet starting to build a production system, right?"}, {"time": 1589, "text": "So you just, you were, you know, this is when you're kind of working 24 seven and you're hacking things together."}, {"time": 1594, "text": "And you also don't know how hard this is."}, {"time": 1597, "text": "I mean, that's the point."}, {"time": 1598, "text": "Like, so, I mean, that's an ambitious, if I put myself in that mindset, even still, that's a really ambitious set of goals."}, {"time": 1606, "text": "Like just those two picking, picking 10 different, difficult, spicy challenges."}, {"time": 1616, "text": "And then having zero interventions."}, {"time": 1619, "text": "So like not saying gradually we're going to like, you know, over a period of 10 years, we're going to have a bunch of routes and gradually reduce the number of interventions, you know, that literally says like, by as soon as possible, we want to have zero and on hard roads."}, {"time": 1637, "text": "So like, to me, if I was facing that, it's unclear that whether that takes two years or whether that takes 20 years."}, {"time": 1646, "text": "I mean, it took us under two."}, {"time": 1647, "text": "I guess that that speaks to a really big difference between doing something once and having a prototype where you are going after, you know, learning about the problem versus how you go about engineering a product that, you know, where you look at, you know, you do properly do evaluation, you look at metrics, you drive down and you're confident that you can do that."}, {"time": 1700, "text": "That's another really important moment."}, {"time": 1701, "text": "Is there some memories of technical lessons or just one, like, what did you learn about the problem of driving from that experience?"}, {"time": 1742, "text": "Like what the hell is driving as an autonomous, or maybe I'm again romanticizing it, but is it, is there, is there some valuable lessons you picked up over there at those two years?"}, {"time": 1758, "text": "A ton."}, {"time": 1786, "text": "But we've tried, we've sampled enough of the problem space and we've made enough rapid success, even, you know, with technology of 2009, 2010, that it gave us confidence to then, you know, pursue this as a real product."}, {"time": 1804, "text": "So the next step, you mentioned the milestones that you had in the, in those two years, what are the next milestones that then led to the creation of Waymo and beyond?"}, {"time": 1814, "text": "Yeah, we had a, it was a really interesting journey and, you know, Waymo came a little bit later, then, you know, we completed those milestones in 2010."}, {"time": 1825, "text": "That was the pivot when we decided to focus on actually building a product using this technology."}, {"time": 1832, "text": "The initial couple of years after that, we were focused on a freeway, you know, what you would call a driver assist, maybe, you know, an L3 driver assist program."}, {"time": 1842, "text": "Then around 2013, we've learned enough about the space and thought more deeply about, you know, the product that we wanted to build, that we pivoted, we pivoted towards this vision of building a driver and deploying it fully driverless vehicles without a person."}, {"time": 1862, "text": "And that that's the path that we've been on since then."}, {"time": 1865, "text": "And very, it was exactly the right decision for us."}, {"time": 1868, "text": "So there was a moment where you're also considered like, what is the right trajectory here?"}, {"time": 1874, "text": "What is the right role of automation in the, in the task of driving?"}, {"time": 1878, "text": "There's still, it wasn't from the early days, obviously you want to go fully autonomous."}, {"time": 1884, "text": "From the early days, it was not."}, {"time": 1885, "text": "I think it was in 20, around 2013, maybe that we've, that became very clear and we made that pivot and also became very clear and that it's either the way you go building a driver assist system is, you know, fundamentally different from how you go building a fully driverless vehicle."}, {"time": 1903, "text": "So, you know, we've pivoted towards the ladder and that's what we've been working on ever since."}, {"time": 1910, "text": "And so that was around 2013, then there's sequence of really meaningful for us really important defining milestones since then."}, {"time": 1920, "text": "And in 2015, we had our first, actually the world's first fully driverless trade on public roads."}, {"time": 1935, "text": "It was in a custom built vehicle that we had."}, {"time": 1937, "text": "I must've seen those."}, {"time": 1938, "text": "We called them the Firefly, that, you know, funny looking marshmallow looking thing."}, {"time": 1942, "text": "And we put a passenger, his name was Steve Mann, you know, great friend of our project from the early days, the man happens to be blind."}, {"time": 1954, "text": "So we put them in that vehicle."}, {"time": 1956, "text": "The car had no steering wheel, no pedals."}, {"time": 1958, "text": "It was an uncontrolled environment."}, {"time": 1960, "text": "You know, no, you know, lead or chase cars, no police escorts."}, {"time": 1964, "text": "And, you know, we did that trip a few times in Austin, Texas."}, {"time": 1967, "text": "So that was a really big milestone."}, {"time": 1969, "text": "But that was in Austin."}, {"time": 1972, "text": "And, you know, we only, but at that time we're only, it took a tremendous amount of engineering."}, {"time": 1977, "text": "It took a tremendous amount of validation to get to that point."}, {"time": 1981, "text": "But, you know, we only did it a few times."}, {"time": 1983, "text": "We only did that."}, {"time": 1984, "text": "It was a fixed route."}, {"time": 1985, "text": "It was not kind of a controlled environment, but it was a fixed route."}, {"time": 1988, "text": "And we only did a few times."}, {"time": 1990, "text": "Then in 2016, end of 2016, beginning of 2017 is when we founded Waymo, the company."}, {"time": 2000, "text": "That's when we kind of, that was the next phase of the project where I wanted, we believed in kind of the commercial vision of this technology."}, {"time": 2010, "text": "And it made sense to create an independent entity, you know, within that alphabet umbrella to pursue this product at scale."}, {"time": 2019, "text": "Beyond that in 2017, later in 2017 was another really huge step for us."}, {"time": 2026, "text": "Really big milestone where we started, I think it was October of 2017 where when we started regular driverless operations on public roads, that first day of operations, we drove in one day."}, {"time": 2042, "text": "And that first day, a hundred miles and driverless fashion."}, {"time": 2045, "text": "And then we've now the most, the most important thing about that milestone was not that, you know, a hundred miles in one day, but that it was the start of kind of regular ongoing driverless operations."}, {"time": 2054, "text": "And when you say driverless, it means no driver."}, {"time": 2059, "text": "So on that first day, we actually hit a mix and in some, we didn't want to like, you know, be on YouTube and Twitter that same day."}, {"time": 2067, "text": "So in, in many of the rides we had somebody in the driver's seat, but they could not disengage like the car, not disengage, but actually on that first day, some of the miles were driven and just completely empty driver's seat."}, {"time": 2112, "text": "And now we'll talk about more and more where there's literally no driver."}, {"time": 2117, "text": "So that's another, the interesting case of where the driver's not supposed to disengage, that's like a nice middle ground, they're still there, but they're not supposed to disengage, but really there's the case when there's no, okay, there's something magical about there being nobody in the driver's seat."}, {"time": 2176, "text": "There's something about like the steering wheel, cause we perhaps romanticize the notion of the steering wheel, it's so essential to our conception, our 20th century conception of a car and it turning the steering wheel with nobody in driver's seat, that to me, I think maybe to others, it's really powerful."}, {"time": 2194, "text": "Like this thing is in control and then there's this leap of trust that you give."}, {"time": 2199, "text": "Like I'm going to put my life in the hands of this thing that's in control."}, {"time": 2202, "text": "So in that sense, when there's no, but no driver in the driver's seat, that's a magical moment for robots."}, {"time": 2209, "text": "So I'm, I've gotten a chance to last year to take a ride in a, in a way more vehicle and that, that was the magical moment."}, {"time": 2214, "text": "There's like nobody in the driver's seat."}, {"time": 2218, "text": "It's, it's like the little details."}, {"time": 2218, "text": "You would think it doesn't matter whether there's a driver or not, but like if there's no driver and the steering wheel is turning on its own, I don't know."}, {"time": 2227, "text": "That's magical."}, {"time": 2233, "text": "It's absolutely magical."}, {"time": 2233, "text": "I, I have taken many of these rides and like completely empty car, no human in the car pulls up, you know, you call it on your cell phone."}, {"time": 2242, "text": "It pulls up, you get in, it takes you on its way."}, {"time": 2242, "text": "There's nobody in the car, but you, right?"}, {"time": 2247, "text": "That's something called, you know, fully driverless, you know, our writer only mode of operation."}, {"time": 2251, "text": "It, it is magical."}, {"time": 2251, "text": "It is, you know, transformative."}, {"time": 2259, "text": "This is what we hear from our writers."}, {"time": 2259, "text": "It kind of really changes your experience."}, {"time": 2264, "text": "And not like that, that really is what unlocks the real potential of this technology."}, {"time": 2268, "text": "But, you know, coming back to our journey, you know, that was 2017 when we started, you know, truly driverless operations."}, {"time": 2278, "text": "Then in 2018, we've launched our public commercial service that we called Waymo One in Phoenix."}, {"time": 2285, "text": "In 2019, we started offering truly driverless writer only rides to our early rider population of users."}, {"time": 2293, "text": "And then, you know, 2020 has also been a pretty interesting year."}, {"time": 2302, "text": "One of the first ones, less about technology, but more about the maturing and the growth of Waymo as a company."}, {"time": 2311, "text": "We raised our first round of external financing this year, you know, we were part of Alphabet."}, {"time": 2317, "text": "So obviously we have access to, you know, significant resources but as kind of on the journey of Waymo maturing as a company, it made sense for us to, you know, partially go externally in this round."}, {"time": 2325, "text": "So, you know, we're raised about $3.2 billion from that round."}, {"time": 2330, "text": "We've also started putting our fifth generation of our driver, our hardware, that is on the new vehicle, but it's also a qualitatively different set of self driving hardware."}, {"time": 2350, "text": "That is now on the JLR pace."}, {"time": 2350, "text": "So that was a very important step for us."}, {"time": 2359, "text": "Hardware specs, fifth generation."}, {"time": 2359, "text": "I think it'd be fun to maybe, I apologize if I'm interrupting, but maybe talk about maybe the generations with a focus on what we're talking about on the fifth generation in terms of hardware specs, like what's on this car."}, {"time": 2376, "text": "So we separated out, you know, the actual car that we are driving from the self driving hardware we put on it."}, {"time": 2381, "text": "Right now we have, so this is, as I mentioned, the fifth generation, you know, we've gone through, we started, you know, building our own hardware, you know, many, many years ago."}, {"time": 2389, "text": "And that, you know, Firefly vehicle also had the hardware suite that was mostly designed, engineered, and built in house."}, {"time": 2401, "text": "Lighters are one of the more important components that we design and build from the ground up."}, {"time": 2407, "text": "So on the fifth generation of our drivers of our self driving hardware that we're switching to right now, we have, as with previous generations, in terms of sensing, we have lighters, cameras, and radars, and we have a pretty beefy computer that processes all that information and makes decisions in real time on board the car."}, {"time": 2433, "text": "So in all of the, and it's really a qualitative jump forward in terms of the capabilities and the various parameters and the specs of the hardware compared to what we had before and compared to what you can kind of get off the shelf in the market today."}, {"time": 2451, "text": "Meaning from fifth to fourth or from fifth to first?"}, {"time": 2454, "text": "Definitely from first to fifth, but also from the fourth."}, {"time": 2457, "text": "That was the world's dumbest question."}, {"time": 2458, "text": "Definitely from fourth to fifth, as well as the last step is a big step forward."}, {"time": 2467, "text": "So everything's in house."}, {"time": 2467, "text": "So like LIDAR is built in house and cameras are built in house?"}, {"time": 2475, "text": "You know, it's different."}, {"time": 2475, "text": "We work with partners and there's some components that we get from our manufacturing and supply chain partners."}, {"time": 2479, "text": "What exactly is in house is a bit different."}, {"time": 2486, "text": "We do a lot of custom design on all of our sensing modalities, lighters, radars, cameras, you know, exactly."}, {"time": 2497, "text": "There's lighters are almost exclusively in house and some of the technologies that we have, some of the fundamental technologies there are completely unique to Waymo."}, {"time": 2505, "text": "That is also largely true about radars and cameras."}, {"time": 2511, "text": "It's a little bit more of a mix in terms of what we do ourselves versus what we get from partners."}, {"time": 2517, "text": "Is there something super sexy about the computer that you can mention that's not top secret?"}, {"time": 2521, "text": "Like for people who enjoy computers for, I mean, there's a lot of machine learning involved, but there's a lot of just basic compute."}, {"time": 2532, "text": "You have to probably do a lot of signal processing on all the different sensors."}, {"time": 2537, "text": "You have to integrate everything has to be in real time."}, {"time": 2540, "text": "There's probably some kind of redundancy type of situation."}, {"time": 2543, "text": "Is there something interesting you can say about the computer for the people who love hardware?"}, {"time": 2547, "text": "It does have all of the characteristics, all the properties that you just mentioned."}, {"time": 2554, "text": "Redundancy, very beefy compute for general processing, as well as inference and ML models."}, {"time": 2561, "text": "It is some of the more sensitive stuff that I don't want to get into for IP reasons, but it can be shared a little bit in terms of the specs of the sensors that we have on the car."}, {"time": 2574, "text": "We actually shared some videos of what our lighters see in the world."}, {"time": 2580, "text": "We have 29 cameras."}, {"time": 2580, "text": "We have five lighters."}, {"time": 2585, "text": "We have six radars on these vehicles, and you can get a feel for the amount of data that they're producing."}, {"time": 2589, "text": "That all has to be processed in real time to do perception, to do complex reasoning."}, {"time": 2596, "text": "That kind of gives you some idea of how beefy those computers are, but I don't want to get into specifics of exactly how we build them."}, {"time": 2602, "text": "Okay, well, let me try some more questions that you can get into the specifics of, like GPU wise."}, {"time": 2605, "text": "Is that something you can get into?"}, {"time": 2608, "text": "I know that Google works with GPUs and so on."}, {"time": 2608, "text": "I mean, for machine learning folks, it's kind of interesting."}, {"time": 2613, "text": "Or is there no... How do I ask it?"}, {"time": 2618, "text": "I've been talking to people in the government about UFOs and they don't answer any questions."}, {"time": 2623, "text": "So this is how I feel right now asking about GPUs."}, {"time": 2626, "text": "But is there something interesting that you could reveal?"}, {"time": 2631, "text": "Or is it just... Or leave it up to our imagination, some of the compute."}, {"time": 2637, "text": "Is there any, I guess, is there any fun trickery?"}, {"time": 2642, "text": "Like I talked to Chris Latner for a second time and he was a key person about GPUs, and there's a lot of fun stuff going on in Google in terms of hardware that optimizes for machine learning."}, {"time": 2655, "text": "Is there something you can reveal in terms of how much, you mentioned customization, how much customization there is for hardware for machine learning purposes?"}, {"time": 2663, "text": "I'm going to be like that government person who bought UFOs."}, {"time": 2666, "text": "I guess I will say that it's really... Compute is really important."}, {"time": 2674, "text": "We have very data hungry and compute hungry ML models all over our stack."}, {"time": 2681, "text": "And this is where both being part of Alphabet, as well as designing our own sensors and the entire hardware suite together, where on one hand you get access to really rich raw sensor data that you can pipe from your sensors into your compute platform and build like build the whole pipe from sensor raw sensor data to the big compute as then have the massive compute to process all that data."}, {"time": 2714, "text": "And this is where we're finding that having a lot of control of that hardware part of the stack is really advantageous."}, {"time": 2721, "text": "One of the fascinating magical places to me again, might not be able to speak to the details, but it is the other compute, which is like, we're just talking about a single car, but the driving experience is a source of a lot of fascinating data."}, {"time": 2739, "text": "And you have a huge amount of data coming in on the car and the infrastructure of storing some of that data to then train or to analyze or so on."}, {"time": 2747, "text": "That's a fascinating piece of it that I understand a single car."}, {"time": 2752, "text": "I don't understand how you pull it all together in a nice way."}, {"time": 2760, "text": "Is that something that you could speak to in terms of the challenges of seeing the network of cars and then bringing the data back and analyzing things that like edge cases of driving, be able to learn on them to improve the system to see where things went wrong, where things went right and analyze all that kind of stuff."}, {"time": 2780, "text": "Is there something interesting there from an engineering perspective?"}, {"time": 2814, "text": "And this is where being part of Alphabet has once again been tremendously advantageous because we consume an incredible amount of compute for ML infrastructure."}, {"time": 2826, "text": "We build a lot of custom frameworks to get good at data mining, finding the interesting edge cases for training and for evaluation of the system for both training and evaluating some components and your sub parts of the system and various ML models, as well as the evaluating the entire system and simulation."}, {"time": 2851, "text": "That first piece that you mentioned that cars communicating to each other, essentially, I mean, through perhaps through a centralized point, but what that's fascinating too, how much does that help you?"}, {"time": 2860, "text": "Like if you imagine, you know, right now the number of way more vehicles is whatever X. I don't know if you can talk to what that number is, but it's not in the hundreds of millions yet."}, {"time": 2870, "text": "And imagine if the whole world is way more vehicles, like that changes potentially the power of connectivity."}, {"time": 2879, "text": "Like the more cars you have, I guess, actually, if you look at Phoenix, cause there's enough vehicles, there's enough, when there's like some level of density, you can start to probably do some really interesting stuff with the fact that cars can negotiate, can be, can communicate with each other and thereby make decisions."}, {"time": 2901, "text": "Is there something interesting there that you can talk to about like, how does that help with the driving problem from, as compared to just a single car solving the driving problem by itself?"}, {"time": 2915, "text": "Yeah, it's a spectrum."}, {"time": 2915, "text": "I first and say that, you know, it's, it helps and it helps in various ways, but it's not required right now with the way we build our system, like each cars can operate independently."}, {"time": 2926, "text": "They can operate with no connectivity."}, {"time": 2929, "text": "So I think it is important that, you know, you have a fully autonomous, fully capable driver that, you know, computerized driver that each car has."}, {"time": 2939, "text": "Then, you know, they do share information and they share information in real time."}, {"time": 2943, "text": "It really, really helps."}, {"time": 2946, "text": "So the way we do this today is, you know, whenever one car encounters something interesting in the world, whether it might be an accident or a new construction zone, that information immediately gets, you know, uploaded over the air and it's propagated to the rest of the fleet."}, {"time": 2963, "text": "So, and that's kind of how we think about maps as priors in terms of the knowledge of our drivers, of our fleet of drivers that is distributed across the fleet and it's updated in real time."}, {"time": 2978, "text": "So that's one use case."}, {"time": 3006, "text": "You know, it's not part of kind of your updating your static prior of the map of the world, but it's more of a dynamic information that could be relevant to the decisions that another car is making real time."}, {"time": 3014, "text": "So you can see them exchanging that information and you can build on that."}, {"time": 3016, "text": "But again, I see that as an advantage, but it's not a requirement."}, {"time": 3023, "text": "So what about the human in the loop?"}, {"time": 3023, "text": "So when I got a chance to drive with a ride in a Waymo, you know, there's customer service."}, {"time": 3034, "text": "So like there is somebody that's able to dynamically like tune in and help you out."}, {"time": 3039, "text": "What role does the human play in that picture?"}, {"time": 3048, "text": "That's a fascinating like, you know, the idea of teleoperation, be able to remotely control a vehicle."}, {"time": 3053, "text": "So here, what we're talking about is like, like frictionless, like a human being able to in a in a frictionless way, sort of help you out."}, {"time": 3063, "text": "I don't know if they're able to actually control the vehicle."}, {"time": 3070, "text": "Is that something you could talk to?"}, {"time": 3070, "text": "To be clear, we don't do teleporation."}, {"time": 3074, "text": "I kind of believe in teleporation for various reasons."}, {"time": 3076, "text": "That's not what we have in our cars."}, {"time": 3079, "text": "We do, as you mentioned, have, you know, version of, you know, customer support."}, {"time": 3082, "text": "You know, we call it life health."}, {"time": 3084, "text": "In fact, we find it that it's very important for our ride experience, especially if it's your first trip, you've never been in a fully driverless ride or only way more vehicle you get in, there's nobody there."}, {"time": 3095, "text": "And so you can imagine having all kinds of, you know, questions in your head, like how this thing works."}, {"time": 3100, "text": "So we've put a lot of thought into kind of guiding our, our writers or customers through that experience, especially for the first time they get some information on the phone."}, {"time": 3109, "text": "If the fully driverless vehicle is used to service their trip, when you get into the car, we have an in car, you know, screen and audio that kind of guides them and explains what to expect."}, {"time": 3121, "text": "They also have a button that they can push that will connect them to, you know, a real life human being that they can talk to, right, about this whole process."}, {"time": 3133, "text": "So that's one aspect of it."}, {"time": 3133, "text": "There is, you know, I should mention that there is another function that humans provide to our cars, but it's not teleoperation."}, {"time": 3141, "text": "You can think of it a little bit more like, you know, fleet assistance, kind of like, you know, traffic control that you have, where our cars, again, they're responsible on their own for making all of the decisions, all of the driving decisions that don't require connectivity."}, {"time": 3157, "text": "They, you know, anything that is safety or latency critical is done, you know, purely autonomously by onboard, our onboard system."}, {"time": 3169, "text": "But there are situations where, you know, if connectivity is available, when a car encounters a particularly challenging situation, you can imagine like a super hairy scene of an accident, the cars will do their best, they will recognize that it's an off nominal situation, they will do their best to come up with the right interpretation, the best course of action in that scenario."}, {"time": 3187, "text": "But if connectivity is available, they can ask for confirmation from, you know, human assistant to kind of confirm those actions and perhaps provide a little bit of kind of contextual information and guidance."}, {"time": 3202, "text": "So October 8th was when you're talking about the was Waymo launched the fully self, the public version of its fully driverless, that's the right term, I think, service in Phoenix."}, {"time": 3218, "text": "Is that October 8th?"}, {"time": 3218, "text": "It was the introduction of fully driverless, right, our only vehicles into our public Waymo One service."}, {"time": 3223, "text": "Okay, so that's that's amazing."}, {"time": 3227, "text": "So it's like anybody can get into Waymo in Phoenix."}, {"time": 3231, "text": "So we previously had early people in our early rider program, taking fully driverless rides in Phoenix."}, {"time": 3241, "text": "And just this a little while ago, we opened on October 8th, we opened that mode of operation to the public."}, {"time": 3246, "text": "So I can download the app and go on a ride."}, {"time": 3249, "text": "There's a lot more demand right now for that service."}, {"time": 3254, "text": "And then we have capacity."}, {"time": 3257, "text": "So we're kind of managing that."}, {"time": 3257, "text": "But that's exactly the way to describe it."}, {"time": 3260, "text": "So there's more demand than you can handle."}, {"time": 3262, "text": "Like what has been reception so far?"}, {"time": 3268, "text": "I mean, okay, so this is a product, right?"}, {"time": 3274, "text": "That's a whole nother discussion of like how compelling of a product it is."}, {"time": 3278, "text": "But it's also like one of the most kind of transformational technologies of the 21st century."}, {"time": 3283, "text": "So it's also like a tourist attraction."}, {"time": 3288, "text": "Like it's fun to, you know, to be a part of it."}, {"time": 3288, "text": "So it'd be interesting to see like, what do people say?"}, {"time": 3292, "text": "What do people, what have been the feedback so far?"}, {"time": 3296, "text": "You know, still early days, but so far, the feedback has been incredible, incredibly positive."}, {"time": 3304, "text": "They, you know, we asked them for feedback during the ride, we asked them for feedback after the ride as part of their trip."}, {"time": 3310, "text": "We asked them some questions, we asked them to rate the performance of our driver."}, {"time": 3312, "text": "Most by far, you know, most of our drivers give us five stars in our app, which is absolutely great to see."}, {"time": 3321, "text": "And you know, that's and we're they're also giving us feedback on you know, things we can improve."}, {"time": 3326, "text": "And you know, that's that's one of the main reasons we're doing this as Phoenix and you know, over the last couple of years, and every day today, we are just learning a tremendous amount of new stuff from our users."}, {"time": 3335, "text": "There's there's no substitute for actually doing the real thing, actually having a fully driverless product out there in the field with, you know, users that are actually paying us money to get from point A to point B."}, {"time": 3348, "text": "So this is a legitimate like, there's a paid service."}, {"time": 3351, "text": "And the idea is you use the app to go from point A to point B."}, {"time": 3356, "text": "And then what what are the A's?"}, {"time": 3359, "text": "What are the what's the freedom of the of the starting and ending places?"}, {"time": 3363, "text": "It's an area of geography where that service is enabled."}, {"time": 3367, "text": "It's a decent size of geography of territory."}, {"time": 3372, "text": "It's actually larger than the size of San Francisco."}, {"time": 3376, "text": "And you know, within that, you have full freedom of, you know, selecting where you want to go."}, {"time": 3380, "text": "You know, of course, there's some and you on your app, you get a map, you tell the car where you want to be picked up, where you want the car to pull over and pick you up."}, {"time": 3391, "text": "And then you tell it where you want to be dropped off."}, {"time": 3393, "text": "And of course, there are some exclusions, right?"}, {"time": 3394, "text": "You want to be you know, you were in terms of where the car is allowed to pull over, right?"}, {"time": 3397, "text": "So that you can do."}, {"time": 3400, "text": "But you know, besides that, it's amazing."}, {"time": 3400, "text": "It's not like a fixed just would be very I guess."}, {"time": 3403, "text": "Maybe that's what's the question behind your question."}, {"time": 3405, "text": "But it's not a, you know, preset set of yes, I guess."}, {"time": 3407, "text": "So within the geographic constraints with that within that area anywhere else, it can be you can be picked up and dropped off anywhere."}, {"time": 3416, "text": "And you know, people use them on like all kinds of trips."}, {"time": 3419, "text": "They we have and we have an incredible spectrum of riders."}, {"time": 3422, "text": "We I think the youngest actually have car seats them and we have, you know, people taking their kids and rides."}, {"time": 3427, "text": "I think the youngest riders we had on cars are, you know, one or two years old, you know, and the full spectrum of use cases people you can take them to, you know, schools to, you know, go grocery shopping, to restaurants, to bars, you know, run errands, you know, go shopping, etc, etc."}, {"time": 3441, "text": "You can go to your office, right?"}, {"time": 3444, "text": "Like the full spectrum of use cases, and people are going to use them in their daily lives to get around."}, {"time": 3451, "text": "And we see all kinds of really interesting use cases and that that that's providing us incredibly valuable experience that we then, you know, use to improve our product."}, {"time": 3463, "text": "So as somebody who's been on done a few long rants with Joe Rogan and others about the toxicity of the internet and the comments and the negativity in the comments, I'm fascinated by feedback."}, {"time": 3476, "text": "I believe that most people are good and kind and intelligent and can provide, like, even in disagreement, really fascinating ideas."}, {"time": 3487, "text": "So on a product side, it's fascinating to me, like, how do you get the richest possible user feedback, like, to improve?"}, {"time": 3494, "text": "What's, what are the channels that you use to measure?"}, {"time": 3499, "text": "Because, like, you're no longer, that's one of the magical things about autonomous vehicles is it's not like it's frictionless interaction with the human."}, {"time": 3512, "text": "So like, you don't get to, you know, it's just giving a ride."}, {"time": 3515, "text": "So like, how do you get feedback from people to in order to improve?"}, {"time": 3520, "text": "Yeah, great question, various mechanisms."}, {"time": 3520, "text": "So as part of the normal flow, we ask people for feedback, they as the car is driving around, we have on the phone and in the car, and we have a touchscreen in the car, you can actually click some buttons and provide real time feedback on how the car is doing, and how the car is handling a particular situation, you know, both positive and negative."}, {"time": 3540, "text": "So that's one channel, we have, as we discussed, customer support or life help, where, you know, if a customer wants to, has a question, or he has some sort of concern, they can talk to a person in real time."}, {"time": 3553, "text": "So that that is another mechanism that gives us feedback."}, {"time": 3556, "text": "At the end of a trip, you know, we also ask them how things went, they give us comments, and you know, star rating."}, {"time": 3565, "text": "And you know, if it's, we also, you know, ask them to explain what you know, one, well, and you know, what could be improved."}, {"time": 3573, "text": "And we have our writers providing very rich feedback, they're a lot, a large fraction is very passionate, very excited about this technology."}, {"time": 3584, "text": "So we get really good feedback."}, {"time": 3585, "text": "We also run UXR studies, right, you know, specific and that are kind of more, you know, go more in depth."}, {"time": 3593, "text": "And we will run both kind of lateral and longitudinal studies, where we have deeper engagement with our customers, you know, we have our user experience research team, tracking over time, that's things about longitudinal is cool."}, {"time": 3607, "text": "That's that's exactly right."}, {"time": 3607, "text": "And you know, that's another really valuable feedback, source of feedback."}, {"time": 3612, "text": "And we're just covering a tremendous amount, right?"}, {"time": 3616, "text": "People go grocery shopping, and they like want to load, you know, 20 bags of groceries in our cars and like that, that's one workflow that you maybe don't think about, you know, getting just right when you're building the driverless product."}, {"time": 3629, "text": "I have people like, you know, who bike as part of their trip."}, {"time": 3634, "text": "So they, you know, bike somewhere, then they get on our cars, they take apart their bike, they load into our vehicle, then go and that's, you know, how they, you know, where we want to pull over and how that, you know, get in and get out process works, provides very useful feedback in terms of what makes a good pickup and drop off location, we get really valuable feedback."}, {"time": 3655, "text": "And in fact, we had to do some really interesting work with high definition maps, and thinking about walking directions."}, {"time": 3665, "text": "And if you imagine you're in a store, right in some giant space, and then you know, you want to be picked up somewhere, like if you just drop a pin at a current location, which is maybe in the middle of a shopping mall, like what's the best location for the car to come pick you up?"}, {"time": 3676, "text": "And you can have simple heuristics where you're just going to take your you know, you clean in distance and find the nearest spot where the car can pull over that's closest to you."}, {"time": 3685, "text": "But oftentimes, that's not the most convenient one."}, {"time": 3688, "text": "You know, I have many anecdotes where that heuristic breaks in horrible ways."}, {"time": 3692, "text": "One example that I often mentioned is somebody wanted to be, you know, dropped off in Phoenix."}, {"time": 3698, "text": "And you know, we got car picked location that was close, the closest to there, you know, where the pin was dropped on the map in terms of, you know, latitude and longitude."}, {"time": 3711, "text": "But it happened to be on the other side of a parking lot that had this row of cacti."}, {"time": 3718, "text": "And the poor person had to like walk all around the parking lot to get to where they wanted to be in 110 degree heat."}, {"time": 3724, "text": "So that, you know, that was about so then, you know, we took all take all of these, all that feedback from our users and incorporate it into our system and improve it."}, {"time": 3730, "text": "Yeah, I feel like that's like requires AGI to solve the problem of like, when you're, which is a very common case, when you're in a big space of some kind, like apartment building, it doesn't matter, it's some large space."}, {"time": 3744, "text": "And then you call the, like a Waymo from there, right?"}, {"time": 3749, "text": "Like, whatever, it doesn't matter, ride share vehicle."}, {"time": 3752, "text": "And like, where's the pin supposed to drop?"}, {"time": 3757, "text": "I feel like that's, you don't think, I think that requires AGI."}, {"time": 3761, "text": "I'm gonna, in order to solve."}, {"time": 3761, "text": "Okay, the alternative, which I think the Google search engine is taught is like, there's something really valuable about the perhaps slightly dumb answer, but a really powerful one, which is like, what was done in the past by others?"}, {"time": 3778, "text": "Like, what was the choice made by others?"}, {"time": 3782, "text": "That seems to be like in terms of Google search, when you have like billions of searches, you could, you could see which, like when they recommend what you might possibly mean, they suggest based on not some machine learning thing, which they also do, but like, on what was successful for others in the past and finding a thing that they were happy with."}, {"time": 3803, "text": "Is that integrated at all?"}, {"time": 3803, "text": "Waymo, like what, what pickups worked for others?"}, {"time": 3807, "text": "I think you're exactly right."}, {"time": 3811, "text": "So there's a real, it's an interesting problem."}, {"time": 3814, "text": "Naive solutions have interesting failure modes."}, {"time": 3814, "text": "So there's definitely lots of things that can be done to improve."}, {"time": 3828, "text": "And both learning from, you know, what works, but doesn't work in actual heal from getting richer data and getting more information about the environment and richer maps."}, {"time": 3841, "text": "But you're absolutely right, that there's something like there's some properties of solutions that in terms of the effect that they have on users so much, much, much better than others, right?"}, {"time": 3850, "text": "And predictability and understandability is important."}, {"time": 3851, "text": "So you can have maybe something that is not quite as optimal, but is very natural and predictable to the user and kind of works the same way all the time."}, {"time": 3861, "text": "And that matters, that matters a lot for the user experience."}, {"time": 3865, "text": "And but you know, to get to the basics, the pretty fundamental property is that the car actually arrives where you told it to, right?"}, {"time": 3875, "text": "Like, you can always, you know, change it, see it on the map, and you can move it around if you don't like it."}, {"time": 3879, "text": "And but like, that property that the car actually shows up reliably is critical, which, you know, where compared to some of the human driven analogs, I think, you know, you can have more predictability."}, {"time": 3921, "text": "And of course, you get the position of the car and the route on the map."}, {"time": 3923, "text": "But and they actually follow that route, of course."}, {"time": 3926, "text": "But it can also share some really interesting information about what it's doing."}, {"time": 3929, "text": "So, you know, our cars, as they are coming to pick you up, if it's come, if a car is coming up to a stop sign, it will actually show you that like, it's there sitting, because it's at a stop sign or a traffic light will show you that it's got, you know, sitting at a red light."}, {"time": 3942, "text": "So, you know, they're like little things, right?"}, {"time": 3944, "text": "But I find those little touches really interesting, really magical."}, {"time": 3951, "text": "And it's just, you know, little things like that, that you can do to kind of delight your users."}, {"time": 3957, "text": "You know, this makes me think of, there's some products that I just love."}, {"time": 3962, "text": "Like, there's a there's a company called Rev, Rev.com, where I like for this podcast, for example, I can drag and drop a video."}, {"time": 3973, "text": "And then they do all the captioning."}, {"time": 3977, "text": "It's humans doing the captioning, but they connect, they automate everything of connecting you to the humans, and they do the captioning and transcription."}, {"time": 3987, "text": "It's all effortless."}, {"time": 3987, "text": "And it like, I remember when I first started using them, I was like, life's good."}, {"time": 3989, "text": "Like, because it was so painful to figure that out earlier."}, {"time": 3995, "text": "The same thing with something called iZotope RX, this company I use for cleaning up audio, like the sound cleanup they do."}, {"time": 4003, "text": "It's like drag and drop, and it just cleans everything up very nicely."}, {"time": 4009, "text": "Another experience like that I had with Amazon OneClick purchase, first time."}, {"time": 4012, "text": "I mean, other places do that now, but just the effortlessness of purchasing, making it frictionless."}, {"time": 4020, "text": "It kind of communicates to me, like, I'm a fan of design."}, {"time": 4024, "text": "I'm a fan of products that you can just create a really pleasant experience."}, {"time": 4028, "text": "The simplicity of it, the elegance just makes you fall in love with it."}, {"time": 4032, "text": "So on the, do you think about this kind of stuff?"}, {"time": 4036, "text": "I mean, it's exactly what we've been talking about."}, {"time": 4039, "text": "It's like the little details that somehow make you fall in love with the product."}, {"time": 4045, "text": "Is that, we went from like urban challenge days, where love was not part of the conversation, probably."}, {"time": 4050, "text": "And to this point where there's a, where there's human beings and you want them to fall in love with the experience."}, {"time": 4059, "text": "Is that something you're trying to optimize for?"}, {"time": 4062, "text": "Try to think about, like, how do you create an experience that people love?"}, {"time": 4068, "text": "I think that's the vision is removing any friction or complexity from getting our users, our writers to where they want to go."}, {"time": 4082, "text": "Making that as simple as possible."}, {"time": 4082, "text": "And then, you know, beyond that, just transportation, making things and goods get to their destination as seamlessly as possible."}, {"time": 4093, "text": "I talked about a drag and drop experience where I kind of express your intent and then it just magically happens."}, {"time": 4100, "text": "And for our writers, that's what we're trying to get to is you download an app and you click and car shows up."}, {"time": 4103, "text": "It's the same car."}, {"time": 4108, "text": "It's very predictable."}, {"time": 4108, "text": "It's a safe and high quality experience."}, {"time": 4113, "text": "And then it gets you in a very reliable, very convenient, frictionless way to where you want to be."}, {"time": 4123, "text": "And along the journey, I think we also want to do little things to delight our users."}, {"time": 4127, "text": "Like the ride sharing companies, because they don't control the experience, I think they can't make people fall in love necessarily with the experience."}, {"time": 4140, "text": "Or maybe they, they haven't put in the effort, but I think if I were to speak to the ride sharing experience I currently have, it's just very, it's just very convenient, but there's a lot of room for like falling in love with it."}, {"time": 4156, "text": "Like we can speak to sort of car companies, car companies do this."}, {"time": 4160, "text": "Well, you can fall in love with a car, right?"}, {"time": 4162, "text": "And be like a loyal car person, like whatever."}, {"time": 4162, "text": "Like I like badass hot rods, I guess, 69 Corvette."}, {"time": 4166, "text": "And at this point, you know, you can't really, cars are so, owning a car is so 20th century, man."}, {"time": 4175, "text": "But is there something about the Waymo experience where you hope that people will fall in love with it?"}, {"time": 4183, "text": "Is that part of it?"}, {"time": 4183, "text": "Or is it part of, is it just about making a convenient ride, not ride sharing, I don't know what the right term is, but just a convenient A to B autonomous transport or like, do you want them to fall in love with Waymo?"}, {"time": 4202, "text": "To maybe elaborate a little bit."}, {"time": 4202, "text": "I mean, almost like from a business perspective, I'm curious, like how, do you want to be in the background invisible or do you want to be like a source of joy that's in very much in the foreground?"}, {"time": 4215, "text": "I want to provide the best, most enjoyable transportation solution."}, {"time": 4224, "text": "And that means building it, building our product and building our service in a way that people do."}, {"time": 4234, "text": "Kind of use in a very seamless, frictionless way in their day to day lives."}, {"time": 4241, "text": "And I think that does mean, you know, in some way falling in love in that product, right, just kind of becomes part of your routine."}, {"time": 4248, "text": "It comes down my mind to safety, predictability of the experience, and privacy aspects of it, right?"}, {"time": 4262, "text": "Our cars, you get the same car, you get very predictable behavior."}, {"time": 4267, "text": "And you get a lot of different things."}, {"time": 4271, "text": "And that is important."}, {"time": 4271, "text": "And if you're going to use it in your daily life, privacy, and when you're in a car, you can do other things."}, {"time": 4278, "text": "You're spending a bunch, just another space where you're spending a significant part of your life."}, {"time": 4284, "text": "And so not having to share it with other people who you don't want to share it with, I think is a very nice property."}, {"time": 4287, "text": "Maybe you want to take a phone call or do something else in the vehicle."}, {"time": 4294, "text": "And, you know, safety on the quality of the driving, as well as the physical safety of not having to share that ride is important to a lot of people."}, {"time": 4305, "text": "What about the idea that when there's somebody like a human driving, and they do a rolling stop on a stop sign, like sometimes like, you know, you get an Uber or Lyft or whatever, like human driver, and, you know, they can be a little bit aggressive as drivers."}, {"time": 4327, "text": "It feels like there's not all aggression is bad."}, {"time": 4327, "text": "Now that may be a wrong, again, 20th century conception of driving."}, {"time": 4337, "text": "Maybe it's possible to create a driving experience."}, {"time": 4341, "text": "Like if you're in the back, busy doing something, maybe aggression is not a good thing."}, {"time": 4344, "text": "It's a very different kind of experience perhaps."}, {"time": 4347, "text": "But it feels like in order to navigate this world, you need to, how do I phrase this?"}, {"time": 4352, "text": "You need to kind of bend the rules a little bit, or at least test the rules."}, {"time": 4358, "text": "I don't know what language politicians use to discuss this, but whatever language they use, you like flirt with the rules."}, {"time": 4368, "text": "But like you sort of have a bit of an aggressive way of driving that asserts your presence in this world, thereby making other vehicles and people respect your presence and thereby allowing you to sort of navigate through intersections in a timely fashion."}, {"time": 4386, "text": "I don't know if any of that made sense, but like, how does that fit into the experience of driving autonomously?"}, {"time": 4398, "text": "It's a lot of thoughts."}, {"time": 4398, "text": "This is you're hitting on a very important point of a number of behavioral components and, you know, parameters that make your driving feel assertive and natural and comfortable and predictable."}, {"time": 4414, "text": "Our cars will follow rules, right?"}, {"time": 4417, "text": "They will do the safest thing possible in all situations."}, {"time": 4419, "text": "Let me be clear on that."}, {"time": 4419, "text": "But if you think of really, really good drivers, just think about professional lemon drivers, right?"}, {"time": 4427, "text": "They will follow the rules."}, {"time": 4429, "text": "They're very, very smooth, and yet they're very efficient."}, {"time": 4433, "text": "But they're assertive."}, {"time": 4433, "text": "They're comfortable for the people in the vehicle."}, {"time": 4438, "text": "They're predictable for the other people outside the vehicle that they share the environment with."}, {"time": 4443, "text": "And that's the kind of driver that we want to build."}, {"time": 4446, "text": "And you think if maybe there's a sport analogy there, right?"}, {"time": 4451, "text": "You can do in very many sports, the true professionals are very efficient in their movements, right?"}, {"time": 4460, "text": "They don't do like, you know, hectic flailing, right?"}, {"time": 4465, "text": "They're, you know, smooth and precise, right?"}, {"time": 4465, "text": "And they get the best results."}, {"time": 4469, "text": "So that's the kind of driver that we want to build."}, {"time": 4470, "text": "In terms of, you know, aggressiveness."}, {"time": 4470, "text": "Yeah, you can like, you know, roll through the stop signs."}, {"time": 4473, "text": "You can do crazy lane changes."}, {"time": 4475, "text": "It typically doesn't get you to your destination faster."}, {"time": 4478, "text": "Typically not the safest or most predictable, very most comfortable thing to do."}, {"time": 4480, "text": "But there is a way to do both."}, {"time": 4485, "text": "And that's what we're doing."}, {"time": 4489, "text": "We're trying to build the driver that is safe, comfortable, smooth, and predictable."}, {"time": 4493, "text": "Yeah, that's a really interesting distinction."}, {"time": 4498, "text": "I think in the early days of autonomous vehicles, the vehicles felt cautious as opposed to efficient."}, {"time": 4503, "text": "And I'm still probably, but when I rode in the Waymo, I mean, there was, it was, it was quite assertive."}, {"time": 4513, "text": "It moved pretty quickly."}, {"time": 4513, "text": "Like, yeah, then he's one of the surprising feelings was that it actually, it went fast."}, {"time": 4522, "text": "And it didn't feel like, awkwardly cautious than autonomous vehicle."}, {"time": 4528, "text": "Like, like, so I've also programmed autonomous vehicles and everything I've ever built was felt awkwardly, either overly aggressive."}, {"time": 4534, "text": "Okay, especially when it was my code, or like, awkwardly cautious is the way I would put it."}, {"time": 4544, "text": "And Waymo's vehicle felt like, assertive and I think efficient is like the right terminology here."}, {"time": 4557, "text": "It wasn't, and I also like the professional limo driver, because we often think like, you know, an Uber driver or a bus driver or a taxi."}, {"time": 4566, "text": "This is the funny thing is people think they track taxi drivers are professionals."}, {"time": 4569, "text": "They, I mean, it's, it's like, that that's like saying, I'm a professional walker, just because I've been walking all my life."}, {"time": 4580, "text": "I think there's an art to it, right?"}, {"time": 4580, "text": "And if you take it seriously as an art form, then there's a certain way that mastery looks like."}, {"time": 4590, "text": "It's interesting to think about what does mastery look like in driving?"}, {"time": 4593, "text": "And perhaps what we associate with like aggressiveness is unnecessary, like, it's not part of the experience of driving."}, {"time": 4603, "text": "It's like, unnecessary fluff, that efficiency, you can be, you can create a good driving experience within the rules."}, {"time": 4620, "text": "That's, I mean, you're the first person to tell me this."}, {"time": 4623, "text": "So it's, it's kind of interesting."}, {"time": 4623, "text": "I need to think about this, but that's exactly what it felt like with Waymo."}, {"time": 4627, "text": "I kind of had this intuition."}, {"time": 4627, "text": "Maybe it's the Russian thing."}, {"time": 4630, "text": "I don't know that you have to break the rules in life to get anywhere, but maybe, maybe it's possible that that's not the case in driving."}, {"time": 4639, "text": "I have to think about that, but it certainly felt that way on the streets of Phoenix when I was there in Waymo, that, that, that that was a very pleasant experience and it wasn't frustrating in that like, come on, move already kind of feeling."}, {"time": 4652, "text": "It wasn't, that wasn't there."}, {"time": 4655, "text": "I mean, that's what, that's what we're going after."}, {"time": 4657, "text": "I don't think you have to pick one."}, {"time": 4657, "text": "I think truly good driving."}, {"time": 4661, "text": "It gives you both efficiency, a certainness, but also comfort and predictability and safety."}, {"time": 4665, "text": "And, you know, it's, that's what fundamental improvements in the core capabilities truly unlock."}, {"time": 4674, "text": "And you can kind of think of it as, you know, a precision and recall trade off."}, {"time": 4679, "text": "You have certain capabilities of your model."}, {"time": 4681, "text": "And then it's very easy when, you know, you have some curve of precision and recall, you can move things around and can choose your operating point and your training of precision versus recall, false positives versus false negatives."}, {"time": 4690, "text": "But then, and you know, you can tune things on that curve and be kind of more cautious or more aggressive, but then aggressive is bad or, you know, cautious is bad, but true capabilities come from actually moving the whole curve up."}, {"time": 4702, "text": "And then you are kind of on a very different plane of those trade offs."}, {"time": 4708, "text": "And that, that's what we're trying to do here is to move the whole curve up."}, {"time": 4711, "text": "Before I forget, let's talk about trucks a little bit."}, {"time": 4714, "text": "So I also got a chance to check out some of the Waymo trucks."}, {"time": 4719, "text": "I'm not sure if we want to go too much into that space, but it's a fascinating one."}, {"time": 4724, "text": "So maybe we can mention at least briefly, you know, Waymo is also now doing autonomous trucking and how different like philosophically and technically is that whole space of problems."}, {"time": 4738, "text": "It's one of our two big products and you know, commercial applications of our driver, right?"}, {"time": 4746, "text": "Hailing and deliveries."}, {"time": 4749, "text": "You know, we have Waymo One and Waymo Via moving people and moving goods."}, {"time": 4752, "text": "You know, trucking is an example of moving goods."}, {"time": 4756, "text": "We've been working on trucking since 2017."}, {"time": 4761, "text": "It is a very interesting space."}, {"time": 4761, "text": "And your question of how different is it?"}, {"time": 4771, "text": "It has this really nice property that the first order challenges, like the science, the hard engineering, whether it's, you know, hardware or, you know, onboard software or off board software, all of the, you know, systems that you build for, you know, training your ML models for, you know, evaluating your time system."}, {"time": 4788, "text": "Like those fundamentals carry over."}, {"time": 4791, "text": "Like the true challenges of, you know, driving perception, semantic understanding, prediction, decision making, planning, evaluation, the simulator, ML infrastructure, those carry over."}, {"time": 4804, "text": "Like the data and the application and kind of the domains might be different, but the most difficult problems, all of that carries over between the domains."}, {"time": 4816, "text": "So that's very nice."}, {"time": 4819, "text": "So that's how we approach it."}, {"time": 4819, "text": "We're kind of build investing in the core, the technical core."}, {"time": 4822, "text": "And then there's specialization of that core technology to different product lines, to different commercial applications."}, {"time": 4830, "text": "So on just to tease it apart a little bit on trucks."}, {"time": 4834, "text": "So starting with the hardware, the configuration of the sensors is different."}, {"time": 4842, "text": "They're different physically, geometrically, you know, different vehicles."}, {"time": 4846, "text": "So for example, we have two of our main laser on the trucks on both sides so that we have, you know, not have the blind spots."}, {"time": 4854, "text": "Whereas on the JLR eye pace, we have, you know, one of it sitting at the very top, but the actual sensors are almost the same."}, {"time": 4862, "text": "Now we're largely the same."}, {"time": 4862, "text": "So all of the investment that over the years we've put into building our custom lighters, custom radars, pulling the whole system together, that carries over very nicely."}, {"time": 4873, "text": "Then, you know, on the perception side, the like the fundamental challenges of seeing, understanding the world, whether it's, you know, object detection, classification, you know, tracking, semantic understanding, all that carries over."}, {"time": 4885, "text": "You know, yes, there's some specialization when you're driving on freeways, you know, range becomes more important."}, {"time": 4891, "text": "The domain is a little bit different."}, {"time": 4893, "text": "But again, the fundamentals carry over very, very nicely."}, {"time": 4896, "text": "Same, and you guess you get into prediction or decision making, right, the fundamentals of what it takes to predict what other people are going to do to find the long tail to improve your system in that long tail of behavior prediction and response that carries over right and so on and so on."}, {"time": 4916, "text": "So I mean, that's pretty exciting."}, {"time": 4916, "text": "By the way, does Waymo via include using the smaller vehicles for transportation of goods?"}, {"time": 4925, "text": "That's an interesting distinction."}, {"time": 4925, "text": "So I would say there's three interesting modes of operation."}, {"time": 4933, "text": "So one is moving humans, one is moving goods, and one is like moving nothing, zero occupancy, meaning like you're going to the destination, your empty vehicle."}, {"time": 4941, "text": "I mean, it's the third is the less of it."}, {"time": 4947, "text": "If that's the entirety of it, it's the less, you know, exciting from the commercial perspective."}, {"time": 4951, "text": "Well, I mean, in terms of like, if you think about what's inside a vehicle as it's moving, because it does, you know, some significant fraction of the vehicle's movement has to be empty."}, {"time": 4965, "text": "I mean, it's kind of fascinating."}, {"time": 4965, "text": "Maybe just on that small point, is there different control and like policies that are applied for zero occupancy vehicle?"}, {"time": 4977, "text": "So vehicle with nothing in it, or is it just move as if there is a person inside?"}, {"time": 4984, "text": "What was with some subtle differences?"}, {"time": 4989, "text": "As a first order approximation, there are no differences."}, {"time": 4989, "text": "And if you think about, you know, safety and comfort and quality of driving, only part of it has to do with the people or the goods inside of the vehicle."}, {"time": 5006, "text": "But you don't want to be, you know, you want to drive smoothly, as we discussed, not for the purely for the benefit of whatever you have inside the car, right?"}, {"time": 5014, "text": "It's also for the benefit of the people outside kind of fitting naturally and predictably into that whole environment, right?"}, {"time": 5021, "text": "So, you know, yes, there are some second order things you can do, you can change your route, and you optimize maybe kind of your fleet, things at the fleet scale."}, {"time": 5030, "text": "And you would take into account whether some of your you know, some of your cars are actually, you know, serving a useful trip, whether with people or with goods, whereas, you know, other cars are, you know, driving completely empty to that next valuable trip that they're going to provide."}, {"time": 5045, "text": "But that those are mostly second order effects."}, {"time": 5049, "text": "So Phoenix is, is an incredible place."}, {"time": 5054, "text": "And what you've announced in Phoenix is, it's kind of amazing."}, {"time": 5058, "text": "But, you know, that's just like one city."}, {"time": 5063, "text": "How do you take over the world?"}, {"time": 5063, "text": "I mean, I'm asking for a friend."}, {"time": 5070, "text": "One step at a time."}, {"time": 5075, "text": "Is that a cartoon pinky in the brain?"}, {"time": 5075, "text": "But, you know, gradually is a true answer."}, {"time": 5080, "text": "So I think the heart of your question is, can you ask a better question than I asked?"}, {"time": 5088, "text": "You're asking a great question."}, {"time": 5088, "text": "Answer that one."}, {"time": 5088, "text": "I'm just gonna, you know, phrase it in the terms that I want to answer."}, {"time": 5096, "text": "You know, where are we today?"}, {"time": 5101, "text": "And, you know, what happens next?"}, {"time": 5101, "text": "And what does it take to go beyond Phoenix?"}, {"time": 5104, "text": "And what does it take to get this technology to more places and more people around the world, right?"}, {"time": 5113, "text": "So our next big area of focus is exactly that."}, {"time": 5123, "text": "Larger scale commercialization and just, you know, scaling up."}, {"time": 5126, "text": "If I think about, you know, the main, and, you know, Phoenix gives us that platform and gives us that foundation of upon which we can build."}, {"time": 5139, "text": "And it's, there are few really challenging aspects of this whole problem that you have to pull together in order to build the technology in order to deploy it into the field to go from a driverless car to a fleet of cars that are providing a service, and then all the way to commercialization."}, {"time": 5169, "text": "So, and then, you know, this is what we have in Phoenix."}, {"time": 5174, "text": "We've taken the technology from a proof point to an actual deployment and have taken our driver from, you know, one car to a fleet that can provide a service."}, {"time": 5185, "text": "Beyond that, if I think about what it will take to scale up and, you know, deploy in, you know, more places with more customers, I tend to think about three main dimensions, three main axes of scale."}, {"time": 5201, "text": "One is the core technology, you know, the hardware and software core capabilities of our driver."}, {"time": 5211, "text": "The second dimension is evaluation and deployment."}, {"time": 5216, "text": "And the third one is the, you know, product, commercial, and operational excellence."}, {"time": 5221, "text": "So you can talk a bit about where we are along, you know, each one of those three dimensions about where we are today and, you know, what has, what will happen next."}, {"time": 5231, "text": "On, you know, the core technology, you know, the hardware and software, you know, together comprise a driver, we, you know, obviously have that foundation that is providing fully driverless trips to our customers as we speak, in fact."}, {"time": 5250, "text": "And we've learned a tremendous amount from that."}, {"time": 5254, "text": "So now what we're doing is we are incorporating all those lessons into some pretty fundamental improvements in our core technology, both on the hardware side and on the software side to build a more general, more robust solution that then will enable us to massively scale beyond Phoenix."}, {"time": 5274, "text": "So on the hardware side, all of those lessons are now incorporated into this fifth generation hardware platform that is, you know, being deployed right now."}, {"time": 5289, "text": "And that's the platform, the fourth generation, the thing that we have right now driving in Phoenix, it's good enough to operate fully driverlessly, you know, night and day, you know, various speeds and various conditions, but the fifth generation is the platform upon which we want to go to massive scale."}, {"time": 5305, "text": "We, in turn, we've really made qualitative improvements in terms of the capability of the system, the simplicity of the architecture, the reliability of the redundancy."}, {"time": 5315, "text": "It is designed to be manufacturable at very large scale and, you know, provides the right unit economics."}, {"time": 5322, "text": "So that's the next big step for us on the hardware side."}, {"time": 5326, "text": "That's already there for scale, the version five."}, {"time": 5329, "text": "And is that coincidence or should we look into a conspiracy theory that it's the same version as the pixel phone?"}, {"time": 5335, "text": "Is that what's the hardware?"}, {"time": 5339, "text": "They neither confirm nor deny."}, {"time": 5339, "text": "So, sorry."}, {"time": 5344, "text": "So that's the, okay, that's that axis."}, {"time": 5348, "text": "So similarly, you know, hardware is a very discreet jump, but, you know, similar to how we're making that change from the fourth generation hardware to the fifth, we're making similar improvements on the software side to make it more, you know, robust and more general and allow us to kind of quickly scale beyond Phoenix."}, {"time": 5362, "text": "So that's the first dimension of core technology."}, {"time": 5367, "text": "How do you measure your system?"}, {"time": 5367, "text": "How do you evaluate it?"}, {"time": 5374, "text": "How do you build a release and deployment process where, you know, with confidence, you can, you know, regularly release new versions of your driver into a fleet?"}, {"time": 5385, "text": "How do you get good at it so that it is not, you know, a huge tax on your researchers and engineers that, you know, so you can, how do you build all these, you know, processes, the frameworks, the simulation, the evaluation, the data science, the validation, so that, you know, people can focus on improving the system and kind of the releases just go out the door and get deployed across the fleet."}, {"time": 5404, "text": "So we've gotten really good at that in Phoenix."}, {"time": 5407, "text": "That's been a tremendously difficult problem, but that's what we have in Phoenix right now that gives us that foundation."}, {"time": 5415, "text": "And now we're working on kind of incorporating all the lessons that we've learned to make it more efficient, to go to new places, you know, and scale up and just kind of, you know, stamp things out."}, {"time": 5422, "text": "So that's that second dimension of evaluation and deployment."}, {"time": 5425, "text": "And the third dimension is product, commercial, and operational excellence, right?"}, {"time": 5433, "text": "And again, Phoenix there is providing an incredibly valuable platform."}, {"time": 5438, "text": "You know, that's why we're doing things end to end in Phoenix."}, {"time": 5440, "text": "We're learning, as you know, we discussed a little earlier today, tremendous amount of really valuable lessons from our users getting really incredible feedback."}, {"time": 5450, "text": "And we'll continue to iterate on that and incorporate all those lessons into making our product, you know, even better and more convenient for our users."}, {"time": 5461, "text": "So you're converting this whole process in Phoenix into something that could be copy and pasted elsewhere."}, {"time": 5466, "text": "So like, perhaps you didn't think of it that way when you were doing the experimentation in Phoenix, but so how long did you basically, and you can correct me, but you've, I mean, it's still early days, but you've taken the full journey in Phoenix, right?"}, {"time": 5484, "text": "As you were saying of like what it takes to basically automate."}, {"time": 5489, "text": "I mean, it's not the entirety of Phoenix, right?"}, {"time": 5491, "text": "But I imagine it can encompass the entirety of Phoenix."}, {"time": 5496, "text": "That's some near term date, but that's not even perhaps important."}, {"time": 5501, "text": "Like as long as it's a large enough geographic area."}, {"time": 5503, "text": "So what, how copy pastable is that process currently and how like, you know, like when you copy and paste in Google docs, I think now in, or in word, you can like apply source formatting or apply destination formatting."}, {"time": 5529, "text": "So how, when you copy and paste the Phoenix into like, say Boston, how do you apply the destination formatting?"}, {"time": 5534, "text": "Like how much of the core of the entire process of bringing an actual public transportation, autonomous transportation service to a city is there in Phoenix that you understand enough to copy and paste into Boston or wherever?"}, {"time": 5555, "text": "So we're not quite there yet."}, {"time": 5559, "text": "We're not at a point where we're kind of massively copy and pasting all over the place."}, {"time": 5611, "text": "And that's what we're doing right now."}, {"time": 5618, "text": "We're incorporating all those things that we learned into that next system that then will allow us to kind of copy and paste all over the place and to massively scale to, you know, more users and more locations."}, {"time": 5627, "text": "I mean, you know, just talk a little bit about, you know, what does that mean along those different dimensions?"}, {"time": 5632, "text": "So on the hardware side, for example, again, it's that switch from the fourth to the fifth generation."}, {"time": 5637, "text": "And the fifth generation is designed to kind of have that property."}, {"time": 5640, "text": "Can you say what other cities you're thinking about?"}, {"time": 5644, "text": "Like, I'm thinking about, sorry, we're in San Francisco now."}, {"time": 5649, "text": "I thought I want to move to San Francisco, but I'm thinking about moving to Austin."}, {"time": 5652, "text": "I don't know why people are not being very nice about San Francisco currently, but maybe it's a small, maybe it's in vogue right now."}, {"time": 5663, "text": "But Austin seems, I visited there and it was, I was in a Walmart."}, {"time": 5668, "text": "It's funny, these moments like turn your life."}, {"time": 5672, "text": "There's this very nice woman with kind eyes, just like stopped and said, he looks so handsome in that tie, honey, to me."}, {"time": 5678, "text": "This has never happened to me in my life, but just the sweetness of this woman is something I've never experienced, certainly on the streets of Boston, but even in San Francisco where people wouldn't, that's just not how they speak or think."}, {"time": 5697, "text": "There's a warmth to Austin that love."}, {"time": 5697, "text": "And since Waymo does have a little bit of a history there, is that a possibility?"}, {"time": 5704, "text": "Is this your version of asking the question of like, you know, Dimitri, I know you can't share your commercial and deployment roadmap, but I'm thinking about moving to San Francisco, Austin, like, you know, blink twice if you think I should move to it."}, {"time": 5716, "text": "You got me."}, {"time": 5719, "text": "You know, we've been testing all over the place."}, {"time": 5719, "text": "I think we've been testing more than 25 cities."}, {"time": 5723, "text": "We drive in San Francisco."}, {"time": 5726, "text": "We drive in, you know, Michigan for snow."}, {"time": 5731, "text": "We are doing significant amount of testing in the Bay Area, including San Francisco, which is not like, because we're talking about the very different thing, which is like a full on large geographic area, public service."}, {"time": 5740, "text": "You can't share and you, okay."}, {"time": 5746, "text": "What about Moscow?"}, {"time": 5746, "text": "When is that happening?"}, {"time": 5754, "text": "Take on Yandex."}, {"time": 5754, "text": "I'm not paying attention to those folks."}, {"time": 5758, "text": "They're doing, you know, there's a lot of fun."}, {"time": 5758, "text": "I mean, maybe as a way of a question, you didn't speak to sort of like policy or like, is there tricky things with government and so on?"}, {"time": 5775, "text": "Like, is there other friction that you've encountered except sort of technological friction of solving this very difficult problem?"}, {"time": 5785, "text": "Is there other stuff that you have to overcome when deploying a public service in a city?"}, {"time": 5793, "text": "It's very important."}, {"time": 5793, "text": "So we put significant effort in creating those partnerships and you know, those relationships with governments at all levels, local governments, municipalities, state level, federal level."}, {"time": 5810, "text": "We've been engaged in very deep conversations from the earliest days of our projects."}, {"time": 5817, "text": "Whenever at all of these levels, whenever we go to test or operate in a new area, we always lead with a conversation with the local officials."}, {"time": 5830, "text": "But the result of that investment is that no, it's not challenges we have to overcome, but it is very important that we continue to have this conversation."}, {"time": 5839, "text": "I love politicians too."}, {"time": 5839, "text": "Okay, so Mr. Elon Musk said that LiDAR is a crutch."}, {"time": 5852, "text": "I wouldn't characterize it exactly that way."}, {"time": 5852, "text": "I know I think LiDAR is very important."}, {"time": 5856, "text": "It is a key sensor that we use just like other modalities, right?"}, {"time": 5862, "text": "As we discussed, our cars use cameras, LiDAR and radars."}, {"time": 5866, "text": "They are all very important."}, {"time": 5866, "text": "They are at the kind of the physical level."}, {"time": 5872, "text": "They are very different."}, {"time": 5872, "text": "They have very different, you know, physical characteristics."}, {"time": 5880, "text": "Cameras are passive."}, {"time": 5880, "text": "LiDARs and radars are active."}, {"time": 5883, "text": "Use different wavelengths."}, {"time": 5883, "text": "So that means they complement each other very nicely and together combined, they can be used to build a much safer and much more capable system."}, {"time": 5900, "text": "So, you know, to me it's more of a question, you know, why the heck would you handicap yourself and not use one or more of those sensing modalities when they, you know, undoubtedly just make your system more capable and safer."}, {"time": 5912, "text": "Now, it, you know, what might make sense for one product or one business might not make sense for another one."}, {"time": 5928, "text": "So if you're talking about driver assist technologies, you make certain design decisions and you make certain trade offs and make different ones if you are building a driver that you deploy in fully driverless vehicles."}, {"time": 5939, "text": "And, you know, in LiDAR specifically, when this question comes up, I, you know, typically the criticisms that I hear or, you know, the counterpoints is that cost and aesthetics."}, {"time": 5956, "text": "And I don't find either of those, honestly, very compelling."}, {"time": 5960, "text": "So on the cost side, there's nothing fundamentally prohibitive about, you know, the cost of LiDARs."}, {"time": 5964, "text": "You know, radars used to be very expensive before people started, you know, before people made certain advances in technology and, you know, started to manufacture them at massive scale and deploy them in vehicles, right?"}, {"time": 5975, "text": "You know, similar with LiDARs."}, {"time": 6003, "text": "And, you know, that improvement will continue."}, {"time": 6007, "text": "So I think, you know, cost is not a real issue."}, {"time": 6010, "text": "Second one is, you know, aesthetics."}, {"time": 6014, "text": "You know, I don't think that's, you know, a real issue either."}, {"time": 6018, "text": "Beauty is in the eye of the beholder."}, {"time": 6018, "text": "You can make LiDAR sexy again."}, {"time": 6022, "text": "I think it is sexy."}, {"time": 6022, "text": "Like, honestly, I think form all of function."}, {"time": 6025, "text": "You know, I was actually, somebody brought this up to me."}, {"time": 6030, "text": "I mean, all forms of LiDAR, even like the ones that are like big, you can make look, I mean, you can make look beautiful."}, {"time": 6040, "text": "There's no sense in which you can't integrate it into design."}, {"time": 6044, "text": "Like, there's all kinds of awesome designs."}, {"time": 6044, "text": "I don't think small and humble is beautiful."}, {"time": 6047, "text": "It could be like, you know, brutalism or like, it could be like harsh corners."}, {"time": 6055, "text": "I mean, like I said, like hot rods."}, {"time": 6055, "text": "Like, I don't like, I don't necessarily like, like, oh man, I'm going to start so much controversy with this."}, {"time": 6062, "text": "I don't like Porsches."}, {"time": 6067, "text": "The Porsche 911, like everyone says it's the most beautiful."}, {"time": 6070, "text": "It's like, it's like a baby car."}, {"time": 6075, "text": "But everyone, it's beauty is in the eye of the beholder."}, {"time": 6075, "text": "You're already looking at me like, what is this kid talking about?"}, {"time": 6078, "text": "I'm happy to talk about."}, {"time": 6078, "text": "You're digging your own hole."}, {"time": 6084, "text": "The form and function and my take on the beauty of the hardware that we put on our vehicles, you know, I will not comment on your Porsche monologue."}, {"time": 6094, "text": "So, but aesthetics, fine."}, {"time": 6094, "text": "But there's an underlying, like, philosophical question behind the kind of lighter question is like, how much of the problem can be solved with computer vision, with machine learning?"}, {"time": 6111, "text": "So I think without sort of disagreements and so on, it's nice to put it on the spectrum because Waymo is doing a lot of machine learning as well."}, {"time": 6123, "text": "It's interesting to think how much of driving, if we look at five years, 10 years, 50 years down the road, what can be learned in almost more and more and more end to end way."}, {"time": 6135, "text": "If we look at what Tesla is doing with, as a machine learning problem, they're doing a multitask learning thing where it's just, they break up driving into a bunch of learning tasks and they have one single neural network and they're just collecting huge amounts of data that's training that."}, {"time": 6150, "text": "I've recently hung out with George Hotz."}, {"time": 6153, "text": "I don't know if you know George."}, {"time": 6157, "text": "I love him so much."}, {"time": 6157, "text": "He's just an entertaining human being."}, {"time": 6161, "text": "We were off mic talking about Hunter S. Thompson."}, {"time": 6161, "text": "He's the Hunter S. Thompson of autonomous driving."}, {"time": 6165, "text": "So he, I didn't realize this with comma AI, but they're like really trying to end to end."}, {"time": 6173, "text": "They're the machine, like looking at the machine learning problem, they're really not doing multitask learning, but it's computing the drivable area as a machine learning task and hoping that like down the line, this level two system, this driver assistance will eventually lead to allowing you to have a fully autonomous vehicle."}, {"time": 6195, "text": "There's an underlying deep philosophical question there, technical question of how much of driving can be learned."}, {"time": 6202, "text": "So LiDAR is an effective tool today for actually deploying a successful service in Phoenix, right?"}, {"time": 6209, "text": "That's safe, that's reliable, et cetera, et cetera."}, {"time": 6213, "text": "But the question, and I'm not saying you can't do machine learning on LiDAR, but the question is that like how much of driving can be learned eventually."}, {"time": 6227, "text": "Can we do fully autonomous?"}, {"time": 6227, "text": "That's learned."}, {"time": 6229, "text": "You know, learning is all over the place and plays a key role in every part of our system."}, {"time": 6236, "text": "As you said, I would, you know, decouple the sensing modalities from the, you know, ML and the software parts of it."}, {"time": 6245, "text": "LiDAR, radar, cameras, like it's all machine learning."}, {"time": 6249, "text": "All of the object detection classification, of course, like that's what, you know, these modern deep nets and count nets are very good at."}, {"time": 6255, "text": "You feed them raw data, massive amounts of raw data, and that's actually what our custom build LiDARs and radars are really good at."}, {"time": 6263, "text": "And radars, they don't just give you point estimates of, you know, objects in space, they give you raw, like, physical observations."}, {"time": 6268, "text": "And then you take all of that raw information, you know, there's colors of the pixels, whether it's, you know, LiDARs returns and some auxiliary information."}, {"time": 6274, "text": "It's not just distance, right?"}, {"time": 6276, "text": "And, you know, angle and distance is much richer information that you get from those returns, plus really rich information from the radars."}, {"time": 6282, "text": "You fuse it all together and you feed it into those massive ML models that then, you know, lead to the best results in terms of, you know, object detection, classification, state estimation."}, {"time": 6295, "text": "So there's a side to interop, but there is a fusion."}, {"time": 6295, "text": "I mean, that's something that people didn't do for a very long time, which is like at the sensor fusion level, I guess, like early on fusing the information together, whether so that the the sensory information that the vehicle receives from the different modalities or even from different cameras is combined before it is fed into the machine learning models."}, {"time": 6319, "text": "Yeah, so I think this is one of the trends you're seeing more of that you mentioned end to end."}, {"time": 6321, "text": "There's different interpretation of end to end."}, {"time": 6321, "text": "There is kind of the purest interpretation of I'm going to like have one model that goes from raw sensor data to like, you know, steering torque and, you know, gas breaks."}, {"time": 6332, "text": "That, you know, that's too much."}, {"time": 6335, "text": "I don't think that's the right way to do it."}, {"time": 6337, "text": "There's more, you know, smaller versions of end to end where you're kind of doing more end to end learning or core training or depropagation of kind of signals back and forth across the different stages of your system."}, {"time": 6348, "text": "There's, you know, really good ways it gets into some fairly complex design choices where on one hand you want modularity and decomposability, decomposability of your system."}, {"time": 6357, "text": "But on the other hand, you don't want to create interfaces that are too narrow or too brittle to engineered where you're giving up on the generality of the solution or you're unable to properly propagate signal, you know, reach signal forward and losses and, you know, back so you can optimize the whole system jointly."}, {"time": 6399, "text": "Like the field over the last, you know, decade has been evolving in more kind of joint fusion, more end to end models that are, you know, solving some of these tasks, you know, jointly and there's tremendous power in that and, you know, that's the progression that kind of our technology, our stack has been on as well."}, {"time": 6414, "text": "Now to your, you know, that so I would decouple the kind of sensing and how that information is fused from the role of ML and the entire stack."}, {"time": 6421, "text": "And, you know, I guess it's, there's trade offs and, you know, modularity and how do you inject inductive bias into your system?"}, {"time": 6431, "text": "All right, this is, there's tremendous power in being able to do that."}, {"time": 6435, "text": "So, you know, we have, there's no part of our system that is not heavily, that does not heavily, you know, leverage data driven development or state of the art ML."}, {"time": 6449, "text": "But there's mapping, there's a simulator, there's perception, you know, object level, you know, perception, whether it's semantic understanding, prediction, decision making, you know, so forth and so on."}, {"time": 6462, "text": "It's, you know, of course, object detection and classification, like you're finding pedestrians and cars and cyclists and, you know, cones and signs and vegetation and being very good at estimating kind of detection, classification, and state estimation."}, {"time": 6471, "text": "There's just stable stakes, like that's step zero of this whole stack."}, {"time": 6474, "text": "You can be incredibly good at that, whether you use cameras or light as a radar, but that's just, you know, that's stable stakes, that's just step zero."}, {"time": 6483, "text": "Beyond that, you get into the really interesting challenges of semantic understanding at the perception level, you get into scene level reasoning, you get into very deep problems that have to do with prediction and joint prediction and interaction, so the interaction between all the actors in the environment, pedestrians, cyclists, other cars, and you get into decision making, right?"}, {"time": 6499, "text": "So, how do you build a lot of systems?"}, {"time": 6502, "text": "So, we leverage ML very heavily in all of these components."}, {"time": 6506, "text": "I do believe that the best results you achieve by kind of using a hybrid approach and having different types of ML, having different models with different degrees of inductive bias that you can have, and combining kind of model, you know, free approaches with some model based approaches and some rule based, physics based systems."}, {"time": 6529, "text": "So, you know, one example I can give you is traffic lights."}, {"time": 6534, "text": "There's a problem of the detection of traffic light state, and obviously that's a great problem for, you know, computer vision confidence, or, you know, that's their bread and butter, right?"}, {"time": 6545, "text": "That's how you build that."}, {"time": 6545, "text": "But then the interpretation of, you know, of a traffic light, that you're gonna need to learn that, right?"}, {"time": 6551, "text": "You don't need to build some, you know, complex ML model that, you know, infers with some, you know, precision and recall that red means stop."}, {"time": 6562, "text": "Like, it's a very clear engineered signal with very clear semantics, right?"}, {"time": 6565, "text": "So you want to induce that bias, like how you induce that bias, and that whether, you know, it's a constraint or a cost, you know, function in your stack, but like it is important to be able to inject that, like, clear semantic signal into your stack."}, {"time": 6580, "text": "And, you know, that's what we do."}, {"time": 6584, "text": "And, but then the question of, like, and that's when you apply it to yourself, when you are making decisions whether you want to stop for a red light, you know, or not."}, {"time": 6594, "text": "But if you think about how other people treat traffic lights, we're back to the ML version of that."}, {"time": 6597, "text": "You know they're supposed to stop for a red light, but that doesn't mean they will."}, {"time": 6602, "text": "So then you're back in the, like, very heavy ML domain where you're picking up on, like, very subtle cues about, you know, they have to do with the behavior of objects, pedestrians, cyclists, cars, and the whole, you know, entire configuration of the scene that allow you to make accurate predictions on whether they will, in fact, stop or run a red light."}, {"time": 6622, "text": "So it sounds like already for Waymo, like, machine learning is a huge part of the stack."}, {"time": 6629, "text": "So it's a huge part of, like, not just, so obviously the first, the level zero, or whatever you said, which is, like, just the object detection of things that, you know, with no other machine learning can do, but also starting to do prediction behavior and so on to model the, what other, what the other parties in the scene, entities in the scene are going to do."}, {"time": 6651, "text": "So machine learning is more and more playing a role in that as well."}, {"time": 6655, "text": "I think we've been going back to the, you know, earliest days, like, you know, DARPA, the DARPA Grand Challenge, our team was leveraging, you know, machine learning."}, {"time": 6665, "text": "It was, like, pre, you know, ImageNet, and it was a very different type of ML, but, and I think actually it was before my time, but the Stanford team during the Grand Challenge had a very interesting machine learned system that would, you know, use LiDAR and camera."}, {"time": 6678, "text": "We've been driving in the desert, and it, we had built the model where it would kind of extend the range of free space reasoning."}, {"time": 6686, "text": "We get a clear signal from LiDAR, and then it had a model that said, hey, like, this stuff on camera kind of sort of looks like this stuff in LiDAR, and I know this stuff that I'm seeing in LiDAR, I'm very confident it's free space, so let me extend that free space zone into the camera range that would allow the vehicle to drive faster."}, {"time": 6703, "text": "And then we've been building on top of that and kind of staying and pushing the state of the art in ML, in all kinds of different ML over the years."}, {"time": 6708, "text": "And in fact, from the early days, I think, you know, 2010 is probably the year where Google, maybe 2011 probably, got pretty heavily involved in machine learning, kind of deep nuts, and at that time it was probably the only company that was very heavily investing in kind of state of the art ML and self driving cars."}, {"time": 6731, "text": "And they go hand in hand."}, {"time": 6736, "text": "And we've been on that journey ever since."}, {"time": 6736, "text": "We're doing, pushing a lot of these areas in terms of research at Waymo, and we collaborate very heavily with the researchers in Alphabet, and all kinds of ML, supervised ML, unsupervised ML, published some interesting research papers in the space, especially recently."}, {"time": 6757, "text": "It's just a super active learning as well."}, {"time": 6761, "text": "Yeah, so super, super active."}, {"time": 6761, "text": "Of course, there's, you know, kind of the more mature stuff, like, you know, ConvNets for, you know, object detection."}, {"time": 6768, "text": "But there's some really interesting, really active work that's happening in kind of more, you know, in bigger models and, you know, models that have more structure to them, you know, not just, you know, large bitmaps and reason about temporal sequences."}, {"time": 6786, "text": "And some of the interesting breakthroughs that you've, you know, we've seen in language models, right?"}, {"time": 6790, "text": "You know, transformers, you know, GPT3 inference."}, {"time": 6794, "text": "There's some really interesting applications of some of the core breakthroughs to those problems of, you know, behavior prediction, as well as, you know, decision making and planning, right?"}, {"time": 6804, "text": "You can think about it, kind of the the behavior, how, you know, the path, the trajectories, the how people drive."}, {"time": 6811, "text": "They have kind of a share, a lot of the fundamental structure, you know, this problem."}, {"time": 6814, "text": "There's, you know, sequential, you know, nature."}, {"time": 6818, "text": "There's a lot of structure in this representation."}, {"time": 6821, "text": "There is a strong locality, kind of like in sentences, you know, words that follow each other."}, {"time": 6825, "text": "They're strongly connected, but there's also kind of larger context that doesn't have that locality, and you also see that in driving, right?"}, {"time": 6831, "text": "What, you know, is happening in the scene as a whole has very strong implications on, you know, the kind of the next step in that sequence where whether you're, you know, predicting what other people are going to do, whether you're making your own decisions, or whether in the simulator you're building generative models of, you know, humans walking, cyclists riding, and other cars driving."}, {"time": 6850, "text": "That's all really fascinating, like how it's fascinating to think that transformer models and all this, all the breakthroughs in language and NLP that might be applicable to like driving at the higher level, at the behavioral level, that's kind of fascinating."}, {"time": 6864, "text": "Let me ask about pesky little creatures called pedestrians and cyclists."}, {"time": 6867, "text": "They seem, so humans are a problem."}, {"time": 6867, "text": "If we can get rid of them, I would."}, {"time": 6872, "text": "But unfortunately, they're all sort of a source of joy and love and beauty, so let's keep them around."}, {"time": 6879, "text": "They're also our customers."}, {"time": 6879, "text": "For your perspective, yes, yes, for sure."}, {"time": 6883, "text": "They're a source of money, very good."}, {"time": 6886, "text": "But I don't even know where I was going."}, {"time": 6886, "text": "Oh yes, pedestrians and cyclists, you know, they're a fascinating injection into the system of uncertainty of like a game theoretic dance of what to do."}, {"time": 6900, "text": "And also they have perceptions of their own, and they can tweet about your product, so you don't want to run them over from that perspective."}, {"time": 6917, "text": "I mean, I don't know, I'm joking a lot, but I think in seriousness, like, you know, pedestrians are a complicated computer vision problem, a complicated behavioral problem."}, {"time": 6927, "text": "Is there something interesting you could say about what you've learned from a machine learning perspective, from also an autonomous vehicle, and a product perspective about just interacting with the humans in this world?"}, {"time": 6942, "text": "Yeah, just to state on record, we care deeply about the safety of pedestrians, you know, even the ones that don't have Twitter accounts."}, {"time": 6952, "text": "But yes, I'm glad, I'm glad somebody does."}, {"time": 6957, "text": "But you know, in all seriousness, safety of vulnerable road users, pedestrians or cyclists, is one of our highest priorities."}, {"time": 6967, "text": "We do a tremendous amount of testing and validation, and put a very significant emphasis on, you know, the capabilities of our systems that have to do with safety around those unprotected vulnerable road users."}, {"time": 6983, "text": "You know, cars, just, you know, discussed earlier in Phoenix, we have completely empty cars, completely driverless cars, you know, driving in this very large area, and you know, some people use them to, you know, go to school, so they'll drive through school zones, right?"}, {"time": 6995, "text": "So, kids are kind of the very special class of those vulnerable user road users, right?"}, {"time": 6999, "text": "You want to be, you know, super, super safe, and super, super cautious around those."}, {"time": 7002, "text": "So, we take it very, very, very seriously."}, {"time": 7005, "text": "And you know, what does it take to be good at it?"}, {"time": 7010, "text": "You know, an incredible amount of performance across your whole stack."}, {"time": 7015, "text": "You know, starts with hardware, and again, you want to use all sensing modalities available to you."}, {"time": 7025, "text": "Imagine driving on a residential road at night, and kind of making a turn, and you don't have, you know, headlights covering some part of the space, and like, you know, a kid might run out."}, {"time": 7036, "text": "And you know, lighters are amazing at that."}, {"time": 7036, "text": "They see just as well in complete darkness as they do during the day, right?"}, {"time": 7040, "text": "So, just again, it gives you that extra, you know, margin in terms of, you know, capability, and performance, and safety, and quality."}, {"time": 7052, "text": "And in fact, we oftentimes, in these kinds of situations, we have our system detect something, in some cases even earlier than our trained operators in the car might do, right?"}, {"time": 7062, "text": "Especially, you know, in conditions like, you know, very dark nights."}, {"time": 7066, "text": "So, starts with sensing, then, you know, perception has to be incredibly good."}, {"time": 7070, "text": "And you have to be very, very good at kind of detecting pedestrians in all kinds of situations, and all kinds of environments, including, you know, people in weird poses, people kind of running around, and you know, being partially occluded."}, {"time": 7089, "text": "So, you know, that's step number one, right?"}, {"time": 7093, "text": "Then, you have to have in very high accuracy, and very low latency, in terms of your reactions to, you know, what, you know, these actors might do, right?"}, {"time": 7101, "text": "And we've put a tremendous amount of engineering, and tremendous amount of validation, in to make sure our system performs properly."}, {"time": 7110, "text": "And, you know, oftentimes, it does require a very strong reaction to do the safe thing."}, {"time": 7115, "text": "And, you know, we actually see a lot of cases like that."}, {"time": 7118, "text": "That's the long tail of really rare, you know, really, you know, crazy events that contribute to the safety around pedestrians."}, {"time": 7128, "text": "Like, one example that comes to mind, that we actually happened in Phoenix, where we were driving along, and I think it was a 45 mile per hour road, so you have pretty high speed traffic, and there was a sidewalk next to it, and there was a cyclist on the sidewalk."}, {"time": 7143, "text": "And as we were in the right lane, right next to the side, so it was a multi lane road, so as we got close to the cyclist on the sidewalk, it was a woman, you know, she tripped and fell."}, {"time": 7157, "text": "Just, you know, fell right into the path of our vehicle, right?"}, {"time": 7160, "text": "And our, you know, car, you know, this was actually with a test driver, our test drivers, did exactly the right thing."}, {"time": 7169, "text": "They kind of reacted, and came to stop."}, {"time": 7169, "text": "It requires both very strong steering, and, you know, strong application of the brake."}, {"time": 7173, "text": "And then we simulated what our system would have done in that situation, and it did, you know, exactly the same thing."}, {"time": 7179, "text": "And that speaks to, you know, all of those components of really good state estimation and tracking."}, {"time": 7186, "text": "And, like, imagine, you know, a person on a bike, and they're falling over, and they're doing that right in front of you, right?"}, {"time": 7192, "text": "So you have to be really, like, things are changing."}, {"time": 7192, "text": "The appearance of that whole thing is changing, right?"}, {"time": 7194, "text": "And a person goes one way, they're falling on the road, they're, you know, being flat on the ground in front of you."}, {"time": 7200, "text": "You know, the bike goes flying the other direction."}, {"time": 7203, "text": "Like, the two objects that used to be one, they're now, you know, are splitting apart, and the car has to, like, detect all of that."}, {"time": 7209, "text": "Like, milliseconds matter, and it doesn't, you know, it's not good enough to just brake."}, {"time": 7212, "text": "You have to, like, steer and brake, and there's traffic around you."}, {"time": 7215, "text": "So, like, it all has to come together, and it was really great to see in this case, and other cases like that, that we're actually seeing in the wild, that our system is, you know, performing exactly the way that we would have liked, and is able to, you know, avoid collisions like this."}, {"time": 7230, "text": "That's such an exciting space for robotics."}, {"time": 7232, "text": "Like, in that split second to make decisions of life and death."}, {"time": 7237, "text": "The stakes are high, in a sense, but it's also beautiful that for somebody who loves artificial intelligence, the possibility that an AI system might be able to save a human life."}, {"time": 7249, "text": "That's kind of exciting as a problem, like, to wake up."}, {"time": 7253, "text": "It's terrifying, probably, for an engineer to wake up, and to think about, but it's also exciting because it's, like, it's in your hands."}, {"time": 7261, "text": "Let me try to ask a question that's often brought up about autonomous vehicles, and it might be fun to see if you have anything interesting to say, which is about the trolley problem."}, {"time": 7274, "text": "So, a trolley problem is an interesting philosophical construct that highlights, and there's many others like it, of the difficult ethical decisions that we humans have before us in this complicated world."}, {"time": 7289, "text": "So, specifically is the choice between if you are forced to choose to kill a group X of people versus a group Y of people, like one person."}, {"time": 7302, "text": "If you did nothing, you would kill one person, but if you would kill five people, and if you decide to swerve out of the way, you would only kill one person."}, {"time": 7311, "text": "Do you do nothing, or you choose to do something?"}, {"time": 7315, "text": "You can construct all kinds of, sort of, ethical experiments of this kind that, I think, at least on a positive note, inspire you to think about, like, introspect what are the physics of our morality, and there's usually not good answers there."}, {"time": 7336, "text": "I think people love it because it's just an exciting thing to think about."}, {"time": 7340, "text": "I think people who build autonomous vehicles usually roll their eyes, because this is not, this one as constructed, this, like, literally never comes up in reality."}, {"time": 7354, "text": "You never have to choose between killing one or, like, one of two groups of people, but I wonder if you can speak to, is there some something interesting to you as an engineer of autonomous vehicles that's within the trolley problem, or maybe more generally, are there difficult ethical decisions that you find that an algorithm must make?"}, {"time": 7378, "text": "On the specific version of the trolley problem, which one would you do, if you're driving?"}, {"time": 7383, "text": "The question itself is a profound question, because we humans ourselves cannot answer, and that's the very point."}, {"time": 7391, "text": "I would kill both."}, {"time": 7398, "text": "Yeah, humans, I think you're exactly right in that, you know, humans are not particularly good."}, {"time": 7401, "text": "I think they're kind of phrased as, like, what would a computer do, but, like, humans, you know, are not very good, and actually oftentimes I think that, you know, freezing and kind of not doing anything, because, like, you've taken a few extra milliseconds to just process, and then you end up, like, doing the worst of the possible outcomes, right?"}, {"time": 7415, "text": "So, I do think that, as you've pointed out, it can be a bit of a distraction, and it can be a bit of a kind of red herring."}, {"time": 7422, "text": "I think it's an interesting, you know, discussion in the realm of philosophy, right?"}, {"time": 7427, "text": "But in terms of what, you know, how that affects the actual engineering and deployment of self driving vehicles, it's not how you go about building a system, right?"}, {"time": 7437, "text": "We've talked about how you engineer a system, how you, you know, go about evaluating the different components and, you know, the safety of the entire thing."}, {"time": 7449, "text": "How do you kind of inject the, you know, various model based, safety based arguments, and, like, yes, you reason at parts of the system, you know, you reason about the probability of a collision, the severity of that collision, right?"}, {"time": 7464, "text": "And that is incorporated, and there's, you know, you have to properly reason about the uncertainty that flows through the system, right?"}, {"time": 7467, "text": "So, you know, those, you know, factors definitely play a role in how the cars then behave, but they tend to be more of, like, the emergent behavior."}, {"time": 7476, "text": "And what you see, like, you're absolutely right that these, you know, clear theoretical problems that they, you know, you don't encounter that in the system, and really kind of being back to our previous discussion of, like, what, you know, what, you know, which one do you choose?"}, {"time": 7489, "text": "Well, you know, oftentimes, like, you made a mistake earlier."}, {"time": 7493, "text": "Like, you shouldn't be in that situation in the first place, right?"}, {"time": 7497, "text": "And in reality, the system comes up."}, {"time": 7500, "text": "If you build a very good, safe, and capable driver, you have enough, you know, clues in the environment that you drive defensively, so you don't put yourself in that situation, right?"}, {"time": 7508, "text": "And again, you know, it has, you know, this, if you go back to that analogy of, you know, precision and recoil, like, okay, you can make a, you know, very hard trade off, but like, neither answer is really good."}, {"time": 7519, "text": "But what instead you focus on is kind of moving the whole curve up, and then you focus on building the right capability on the right defensive driving, so that, you know, you don't put yourself in the situation like this."}, {"time": 7528, "text": "I don't know if you have a good answer for this, but people love it when I ask this question about books."}, {"time": 7535, "text": "Are there books in your life that you've enjoyed, philosophical, fiction, technical, that had a big impact on you as an engineer or as a human being?"}, {"time": 7547, "text": "You know, everything from science fiction to a favorite textbook."}, {"time": 7550, "text": "Is there three books that stand out that you can think of?"}, {"time": 7553, "text": "So I would, you know, that impacted me, I would say, and this one is, you probably know it well, but not generally well known, I think, in the U.S., or kind of internationally, The Master and Margarita."}, {"time": 7571, "text": "It's one of, actually, my favorite books."}, {"time": 7576, "text": "It is, you know, by Russian, it's a novel by Russian author Mikhail Bulgakov, and it's just, it's a great book."}, {"time": 7586, "text": "It's one of those books that you can, like, reread your entire life, and it's very accessible."}, {"time": 7588, "text": "You can read it as a kid, and, like, it's, you know, the plot is interesting."}, {"time": 7617, "text": "Like, it makes you think one of those books that, you know, is good and makes you think, but also has, like, this really, you know, silly, quirky, dark sense of, you know, humor."}, {"time": 7627, "text": "It captures the Russian soul more than many, perhaps, many other books."}, {"time": 7630, "text": "On that, like, slight note, just out of curiosity, one of the saddest things is I've read that book in English."}, {"time": 7637, "text": "Did you, by chance, read it in English or in Russian?"}, {"time": 7642, "text": "In Russian, only in Russian, and I actually, that is a question I had, kind of posed to myself every once in a while, like, I wonder how well it translates, if it translates at all, and there's the language aspect of it, and then there's the cultural aspect, so I, actually, I'm not sure if, you know, either of those would work well in English."}, {"time": 7659, "text": "Now, I forget their names, but, so, when the COVID lifts a little bit, I'm traveling to Paris for several reasons."}, {"time": 7663, "text": "One is just, I've never been to Paris, I want to go to Paris, but there's the most famous translators of Dostoevsky, Tolstoy, of most of Russian literature live there."}, {"time": 7723, "text": "So, from what I understand, Dostoevsky translates easier, others don't as much."}, {"time": 7770, "text": "There's a few Russian people that I think are truly special human beings, and I feel, like, I sometimes encounter this with some incredible scientists, and maybe you encounter this as well at some point in your life, that it feels like because of the language barrier, their ideas are lost to history."}, {"time": 7840, "text": "I mean, I know it's a silly concept, but it's a fundamental one, because how do you translate, and that's the thing that Google Translate is also facing as a more machine learning problem, but I wonder as a more bigger problem for AI, how do we capture the magic that's there in the language?"}, {"time": 7863, "text": "I think that's a really interesting, really challenging problem."}, {"time": 7868, "text": "If you do read it, Master and Margarita in English, sorry, in Russian, I'd be curious to get your opinion, and I think part of it is language, but part of it's just, you know, centuries of culture, that, you know, the cultures are different, so it's hard to connect that."}, {"time": 7888, "text": "Okay, so that was my first one, right?"}, {"time": 7888, "text": "You had two more."}, {"time": 7888, "text": "The second one I would probably pick is the science fiction by the Strogatsky brothers."}, {"time": 7895, "text": "You know, it's up there with, you know, Isaac Asimov and, you know, Ray Bradbury and, you know, company."}, {"time": 7898, "text": "The Strogatsky brothers kind of appealed more to me."}, {"time": 7903, "text": "I think it made more of an impression on me growing up."}, {"time": 7907, "text": "I apologize if I'm showing my complete ignorance."}, {"time": 7913, "text": "I'm so weak on sci fi."}, {"time": 7913, "text": "What did they write?"}, {"time": 7917, "text": "Oh, Roadside Picnic, Heart to Be a God, Beetle in an Ant Hill, Monday Starts on Saturday."}, {"time": 7927, "text": "Like, it's not just science fiction."}, {"time": 7934, "text": "It also has very interesting, you know, interpersonal and societal questions, and some of the language is just completely hilarious."}, {"time": 7947, "text": "That's the one."}, {"time": 7947, "text": "Monday Starts on Saturday."}, {"time": 7947, "text": "So, I need to read."}, {"time": 7951, "text": "Okay, oh boy."}, {"time": 7951, "text": "You put that in the category of science fiction?"}, {"time": 7956, "text": "That one is, I mean, this was more of a silly, you know, humorous work."}, {"time": 7959, "text": "I mean, there is kind of..."}, {"time": 7963, "text": "It's profound too, right?"}, {"time": 7963, "text": "Science fiction, right?"}, {"time": 7963, "text": "It's about, you know, this research institute, and it has deep parallels to serious research, but the setting, of course, is that they're working on, you know, magic, right?"}, {"time": 7973, "text": "And there's a lot of stuff."}, {"time": 7976, "text": "And that's their style, right?"}, {"time": 7980, "text": "And, you know, other books are very different, right?"}, {"time": 7980, "text": "You know, Heart to Be a God, right?"}, {"time": 7983, "text": "It's about kind of this higher society being injected into this primitive world, and how they operate there, and some of the very deep ethical questions there, right?"}, {"time": 7993, "text": "And, like, they've got this full spectrum."}, {"time": 7993, "text": "Some is, you know, more about kind of more adventure style."}, {"time": 7996, "text": "But, like, I enjoy all of their books."}, {"time": 7999, "text": "There's just, you know, probably a couple."}, {"time": 8001, "text": "Actually, one I think that they consider their most important work."}, {"time": 8004, "text": "I think it's The Snail on a Hill."}, {"time": 8004, "text": "I'm not exactly sure how it translates."}, {"time": 8009, "text": "I tried reading a couple times."}, {"time": 8009, "text": "I still don't get it."}, {"time": 8012, "text": "But everything else I fully enjoyed."}, {"time": 8012, "text": "And, like, for one of my birthdays as a kid, I got, like, their entire collection, like, occupied a giant shelf in my room, and then, like, over the holidays, I just, like, you know, my parents couldn't drag me out of the room, and I read the whole thing cover to cover."}, {"time": 8024, "text": "And I really enjoyed it."}, {"time": 8029, "text": "And that's one more."}, {"time": 8029, "text": "For the third one, you know, maybe a little bit darker, but, you know, comes to mind is Orwell's 1984."}, {"time": 8036, "text": "And, you know, you asked what made an impression on me and the books that people should read."}, {"time": 8041, "text": "That one, I think, falls in the category of both."}, {"time": 8043, "text": "You know, definitely it's one of those books that you read, and you just kind of, you know, put it down and you stare in space for a while."}, {"time": 8051, "text": "You know, that kind of work."}, {"time": 8051, "text": "I think there's, you know, lessons there."}, {"time": 8056, "text": "People should not ignore."}, {"time": 8059, "text": "And, you know, nowadays, with, like, everything that's happening in the world, I, like, can't help it, but, you know, have my mind jump to some, you know, parallels with what Orwell described."}, {"time": 8069, "text": "And, like, there's this whole, you know, concept of double think and ignoring logic and, you know, holding completely contradictory opinions in your mind and not have that not bother you and, you know, sticking to the party line at all costs."}, {"time": 8084, "text": "Like, you know, there's something there."}, {"time": 8088, "text": "If anything, 2020 has taught me, and I'm a huge fan of Animal Farm, which is a kind of friendly, as a friend of 1984 by Orwell."}, {"time": 8097, "text": "It's kind of another thought experiment of how our society may go in directions that we wouldn't like it to go."}, {"time": 8107, "text": "But if anything that's been kind of heartbreaking to an optimist about 2020 is that that society is kind of fragile."}, {"time": 8118, "text": "Like, we have this, this is a special little experiment we have going on."}, {"time": 8125, "text": "And not, it's not unbreakable."}, {"time": 8125, "text": "Like, we should be careful to, like, preserve whatever the special thing we have going on."}, {"time": 8132, "text": "I mean, I think 1984 and these books, The Brave New World, they're helpful in thinking, like, stuff can go wrong in nonobvious ways."}, {"time": 8143, "text": "And it's, like, it's up to us to preserve it."}, {"time": 8148, "text": "And it's, like, it's a responsibility."}, {"time": 8148, "text": "It's been weighing heavy on me because, like, for some reason, like, more than my mom follows me on Twitter and I feel like I have, like, now somehow a responsibility to do this world."}, {"time": 8163, "text": "And it dawned on me that, like, me and millions of others are, like, the little ants that maintain this little colony, right?"}, {"time": 8172, "text": "So we have a responsibility not to be, I don't know what the right analogy is, but I'll put a flamethrower to the place."}, {"time": 8180, "text": "We want to not do that."}, {"time": 8183, "text": "And there's interesting complicated ways of doing that as 1984 shows."}, {"time": 8187, "text": "It could be through bureaucracy."}, {"time": 8187, "text": "It could be through incompetence."}, {"time": 8189, "text": "It could be through misinformation."}, {"time": 8193, "text": "It could be through division and toxicity."}, {"time": 8196, "text": "I'm a huge believer in, like, that love will be the, somehow, the solution."}, {"time": 8199, "text": "So, love and robots."}, {"time": 8199, "text": "Love and robots, yeah."}, {"time": 8206, "text": "Unfortunately, I think it's less of a flamethrower type of thing."}]}, {"title": "Tim Dillon: Comedy, Power, Conspiracy Theories, and Freedom | Lex Fridman Podcast #156", "id": "8wYZjOzfTUk", "quotes": [{"time": 264, "text": "In the same way that anger, your tombstone would arouse will last longer."}, {"time": 270, "text": "And that's deeply like a human thing."}, {"time": 273, "text": "Like why do we attach happiness to the way we should remember others?"}, {"time": 278, "text": "It could be just anger."}, {"time": 280, "text": "I know so many people who will have deeply complicated feelings when..."}, {"time": 285, "text": "I did drugs for many years and I spent time with some wild people."}, {"time": 290, "text": "And their parents were also wild people."}, {"time": 293, "text": "And some of their parents have done crazy things to them."}, {"time": 298, "text": "And have created situations that were not productive for child rearing."}, {"time": 306, "text": "And so I know that when those people die, it's going to be a very mixed bag."}, {"time": 311, "text": "Like there's going to be a lot of complex emotions."}, {"time": 313, "text": "Like, hey, we loved that guy."}, {"time": 316, "text": "But also when we look back, he was a horrible father, a horrible husband, but he was fun."}, {"time": 325, "text": "And we don't put enough stock in that, but that will be a push and pull."}, {"time": 329, "text": "And I'll be the one kind of bringing up like, hey, he was a lot of fun."}, {"time": 333, "text": "He was a lot."}, {"time": 333, "text": "Remember when he stuck us, one of the things this particular person I'm talking about, we were at a bar and me and my friend were there, we're having dinner."}, {"time": 342, "text": "And his father, who was an alcoholic, a guy that would go out every night and didn't work, refused to work, would lie and say he was going to work and then go to a bar."}, {"time": 353, "text": "I mean, just a fun person."}, {"time": 355, "text": "And we were sitting at this bar restaurant and the bartender, we see his father walk up to the bartender and say, point at us, point at our table and go and put the thumbs up."}, {"time": 367, "text": "And the bartender nodded."}, {"time": 368, "text": "And then the father walked over to our table and he said, listen, I just want to let you know I just bought you dinner."}, {"time": 374, "text": "And I looked at his son and I said, he's a pretty good guy."}, {"time": 377, "text": "And then he climbed over the little fence down to the water and got in his little boat."}, {"time": 381, "text": "It was a little cigarette boat and he just drove away."}, {"time": 383, "text": "And then about an hour later, we went and we said, I think that guy took care of the bill."}, {"time": 388, "text": "But she said, well, go talk to the bartender."}, {"time": 390, "text": "So we talked to the bartender and he goes, he handed us a bill and the bill was for like $1,000."}, {"time": 396, "text": "And we said, wait a minute, what the hell's going on?"}, {"time": 398, "text": "And he goes, the guy that left an hour ago said, you were going to take care of his bill."}, {"time": 402, "text": "He's been drinking here all week."}, {"time": 404, "text": "And we go, what are you talking about?"}, {"time": 406, "text": "And he goes, remember, he pointed at you."}, {"time": 407, "text": "He put the thumbs up and you guys waved."}, {"time": 410, "text": "You remember that?"}, {"time": 412, "text": "And the guy go, and we went, yeah."}, {"time": 413, "text": "And I just looked at my friends, my friend and I went, you know, your dad is just, we're going to remember him for all kinds of reasons."}, {"time": 420, "text": "But to you, he was fun."}, {"time": 421, "text": "He was a lot of fun."}, {"time": 422, "text": "He wasn't my dad, but I spent a lot of time with him."}, {"time": 424, "text": "I was in two boating accidents with him."}, {"time": 427, "text": "You know, two boating accidents."}, {"time": 428, "text": "Alcohol involved, drugs involved."}, {"time": 430, "text": "Yes, he was, usually alcohol was involved when he left his house and when he was at home as well."}, {"time": 435, "text": "But I was in two boating accidents."}, {"time": 437, "text": "And do you know how fun someone has to be to get in a second boating accident?"}, {"time": 442, "text": "Do you know what a good time someone has to be to get in a boat with them after you've already gotten in one wreck?"}, {"time": 450, "text": "Never get fooled again."}, {"time": 451, "text": "What was that line?"}, {"time": 452, "text": "George Bush, never get fooled again."}, {"time": 455, "text": "Yeah, so if you're getting fooled again, you know, there's a reason for it, but he was a fun guy."}, {"time": 459, "text": "He did have a death wish."}, {"time": 460, "text": "The second boating accident, he grabbed me and said, you can't hang out with me anymore."}, {"time": 463, "text": "And I said, why?"}, {"time": 464, "text": "He goes, I'm trying to kill myself."}, {"time": 465, "text": "And I was like, oh."}, {"time": 467, "text": "And then I understood that like all of the fun under the fun lived a very destructive person who not only was destructive, but wanted to die."}, {"time": 477, "text": "So speaking of fun people that want to die, I don't know if you're, we can go Hunter S. Thompson, but Charles Bukowski."}, {"time": 485, "text": "I don't know if you're aware of the guy."}, {"time": 486, "text": "I'm aware of him, sure."}, {"time": 487, "text": "I've read some of his stuff."}, {"time": 488, "text": "So his tombstone says, I just want to ask you a question about it."}, {"time": 492, "text": "His tombstone says, don't try."}, {"time": 496, "text": "What do you think about that advice as a way to approach life?"}, {"time": 499, "text": "I think for many people, it's a good advice because the people that are going to try will do anyway."}, {"time": 506, "text": "And the people that need to be told, there's a whole cottage industry now of motivational speakers and life coaches and gurus that tell people that they all have to own their own business and be their own boss and be a disruptor and get into industries."}, {"time": 525, "text": "That's incredibly unrealistic for most people."}, {"time": 527, "text": "Most people are not suited for that."}, {"time": 530, "text": "And the Gary Vees of the world that tell everybody that they should just hustle and grind and hustle and grind."}, {"time": 534, "text": "They're very light on the specifics of what they should actually do."}, {"time": 538, "text": "Yeah, I think a lot of people, that's not horrible advice to give to a lot of people."}, {"time": 542, "text": "I think my generation got horrible advice from our parents, from our teachers."}, {"time": 547, "text": "And that advice was follow your dreams and nobody, and that was it, by the way."}, {"time": 552, "text": "There was no like, what are your dreams?"}, {"time": 554, "text": "Are they realistic?"}, {"time": 555, "text": "What happens when they don't work out?"}, {"time": 557, "text": "Will your dreams make you happy?"}, {"time": 558, "text": "Are your dreams real?"}, {"time": 560, "text": "Do they exist on earth?"}, {"time": 562, "text": "Can you follow, anybody follow your dreams?"}, {"time": 565, "text": "You can be anything you want to be."}, {"time": 566, "text": "Horrible advice, horrible advice."}, {"time": 569, "text": "Worst advice you could ever give a generation of people."}, {"time": 575, "text": "If you were talking to somebody and you were trying to make them succeed, are there any two worse pieces of advice to give them than follow your dreams and you can be anything you want to be?"}, {"time": 588, "text": "Those to me are the two most destructive pieces of information I've ever heard."}, {"time": 593, "text": "So let me push back because."}, {"time": 594, "text": "Okay, that's fair."}, {"time": 595, "text": "This is."}, {"time": 595, "text": "Many people do."}, {"time": 597, "text": "So yeah, this is like a rigorous journalistic interview."}, {"time": 601, "text": "Larry King, by the way, passed away today."}, {"time": 604, "text": "So I'm taking over the."}, {"time": 605, "text": "It's very sad."}, {"time": 606, "text": "I'm carrying the."}, {"time": 608, "text": "RIP King."}, {"time": 609, "text": "Yeah, what was I even gonna say?"}, {"time": 611, "text": "Oh, let me push back on the follow your dream thing is I come from an immigrant family where I was always working extremely hard at stuff, like in a stupid way."}, {"time": 624, "text": "I would, I love, there's something about me that loves hitting my head against the wall over and over and over until either my head breaks or the wall breaks."}, {"time": 632, "text": "Just like, I love that dedication for no purpose whatsoever."}, {"time": 636, "text": "It's like the mouse that's stuck in a cage or whatever."}, {"time": 639, "text": "And no, and everybody always told me, my family, the people around me, the sort of the epitome of what I could achieve is to be kind of a stable job."}, {"time": 652, "text": "You know, the old like lawyer doctor, in my case, it's like scientists and so on."}, {"time": 657, "text": "But I had these dreams at this fire, you know, about love robots."}, {"time": 663, "text": "And that nobody ever gave me permission to pursue those dreams."}, {"time": 668, "text": "I know you're supposed to grab it yourself."}, {"time": 670, "text": "Nobody's supposed to give you permission, but there's something about just people saying, you know, fuck what everyone else thinks, like giving you permission, a parent or somebody like that saying, do your own thing."}, {"time": 683, "text": "Go become an actor, go become like, do the crazy thing you're not supposed to do, an artist, go build a company, quit school, all that kind of stuff."}, {"time": 693, "text": "That's the push back against the, follow your dreams as bad advice."}, {"time": 698, "text": "In mass, if you were to look at, in mass, if you were to look at statistically how few people that works out for, I'm just, no, but let's be very honest."}, {"time": 707, "text": "Be very honest."}, {"time": 708, "text": "So I mean like, yeah, if you're gonna go be an, hey, I was broke for 10 years before I became a, before I was making money as a comedian."}, {"time": 715, "text": "I didn't need Gary Vaynerchuk to tell me to follow my thing, right?"}, {"time": 719, "text": "And here's the other thing."}, {"time": 720, "text": "I was kind of funny and like, I was kind of, a lot of things were in my favor of being a comedian, right?"}, {"time": 727, "text": "I had this kind of crazy fucked up life."}, {"time": 729, "text": "I had a lot of stories."}, {"time": 730, "text": "I had exhausted, I was willing to fail."}, {"time": 732, "text": "I had failed before."}, {"time": 734, "text": "I was broke."}, {"time": 735, "text": "I didn't care about being broke."}, {"time": 736, "text": "I knew how to be broke."}, {"time": 738, "text": "I had, I was shameless to a degree."}, {"time": 741, "text": "I was, I would get on a stage night after night and be laughed at."}, {"time": 744, "text": "I would, I had a high threshold for being embarrassed."}, {"time": 748, "text": "I had a high threshold for people thinking that I was a scumbag, right?"}, {"time": 751, "text": "And showing up at family parties and being like, yeah, I still really don't have a job."}, {"time": 755, "text": "And I'm just, I work at comedy clubs kind of, and I get booked when I can."}, {"time": 761, "text": "And I was, you know, suited for it."}, {"time": 764, "text": "There's this idea that people can just roam around the world injecting themselves into other things they have no aptitude for at all."}, {"time": 776, "text": "And will that to happen?"}, {"time": 778, "text": "A small percentage of people might be able to do that, but the vast majority of people have something they might key into that they're meant to do."}, {"time": 786, "text": "Like you loved robots, you love technology, and you found a place in that world where you thrive."}, {"time": 792, "text": "But I think many people, a lot of people love robots, right?"}, {"time": 796, "text": "So a lot of people think everything you do is interesting."}, {"time": 798, "text": "I think your shit is fascinating."}, {"time": 800, "text": "I watch you or podcasts, and I think it's very interesting."}, {"time": 803, "text": "I have no place in your world."}, {"time": 807, "text": "I have no place in that world."}, {"time": 809, "text": "I don't like remedial math."}, {"time": 812, "text": "I don't like community college math."}, {"time": 815, "text": "I think it's a waste of my time."}, {"time": 817, "text": "What do you think about robot?"}, {"time": 818, "text": "Would you ever buy a robot for your home?"}, {"time": 821, "text": "What will it do?"}, {"time": 823, "text": "I'd be a companion, a friend."}, {"time": 824, "text": "Oh yeah, I mean, I would like to start replacing friends and family with robots immediately."}, {"time": 829, "text": "I mean, truly, truly."}, {"time": 831, "text": "I mean, I'm not even kidding."}, {"time": 832, "text": "Like I would like to have a Thanksgiving with four robots."}, {"time": 837, "text": "I'm dead serious."}, {"time": 838, "text": "Are they into QAnon?"}, {"time": 840, "text": "Like are the robots, when do the robots start going crazy?"}, {"time": 845, "text": "That's my question is like, how long do the robots live with me before they are also a problem and I got to replace them?"}, {"time": 853, "text": "You're gonna indoctrinate the robot."}, {"time": 855, "text": "The robot's gonna call me like my aunt does and talk about coronavirus for an hour every morning and tell me everyone in America who's died of coronavirus."}, {"time": 862, "text": "One of the things I enjoy in life is how terrified people like you, I'm a huge fan by the way, get a robot."}, {"time": 872, "text": "Well, I'm concerned about AI completely getting rid of the need for human beings because human beings, I mean, usually you go out in the street and you go, so few of these people are necessary, even now."}, {"time": 886, "text": "Even now you look at people and you go, they're hanging on by a thread, right?"}, {"time": 891, "text": "And you can just imagine how many jobs are gonna get replaced, how many industries are going to be completely remade with AI and the pace of change worries me a little bit because we do a very bad job in this country of mitigation when we have problems."}, {"time": 907, "text": "We don't do a great job."}, {"time": 908, "text": "We did not great job with COVID, right?"}, {"time": 911, "text": "We don't do a good job."}, {"time": 912, "text": "It's just something we don't do well."}, {"time": 913, "text": "We're good in booms and busts."}, {"time": 915, "text": "We're good when it's good."}, {"time": 917, "text": "And we're actually, we kind of know how to kind of like, hey, we're bottomed out."}, {"time": 920, "text": "We're like a gambling addict in this country."}, {"time": 922, "text": "We like, we know what it feels like to be outside of an OTB at 9 a.m. drinking coffee and smoking cigarettes going, I'm gonna build it back."}, {"time": 929, "text": "And we know what it's like to win, but anything in between, it seems not that great."}, {"time": 935, "text": "So to me, it feels like are we gonna be able to like help people that are displaced and that have their jobs taken by, I mean, do you not fear sort of a world where you have a lot of artificial intelligence replacing workers and then what happens?"}, {"time": 953, "text": "There's a lot of fears around artificial intelligence."}, {"time": 956, "text": "One of them is, yes, displacement of jobs, workers."}, {"time": 959, "text": "That's technology in general."}, {"time": 961, "text": "That's just any kind of new innovations displace jobs."}, {"time": 966, "text": "I'm less worried about that."}, {"time": 969, "text": "I'm more worried about other impacts of artificial intelligence."}, {"time": 971, "text": "For example, the nature of our discourse, like social, the effects of algorithms on the way we communicate with each other, the spread of information, what that information looks like, the creation of silos, all that kind of stuff."}, {"time": 983, "text": "I think that would just make worse the effects that the displacement of jobs has."}, {"time": 992, "text": "I think ultimately, I have a hope that technology creates more opportunities than it destroys."}, {"time": 997, "text": "I hope so too."}, {"time": 998, "text": "So in that sense, AI to me is an exciting possibility, but the challenges this world presents will create divisions, will create chaos and so on."}, {"time": 1012, "text": "So I'm more focused on the way we deal as a society with that chaos, the way we talk to each other."}, {"time": 1018, "text": "Creating the platform that's healthy for that."}, {"time": 1020, "text": "Now, as a comedian creator, whatever you want to call it, people that put out content, the gatekeepers are now algorithmic, right?"}, {"time": 1030, "text": "So they are kind of almost AI ready."}, {"time": 1032, "text": "So if you are a person that puts out YouTube videos, podcasts, whatever you're doing, it used to be a guy in the back of the room with a cigar saying, I like you or get him out of here."}, {"time": 1047, "text": "Now, it's an algorithm you barely understand."}, {"time": 1050, "text": "I've talked to people at YouTube, but I don't know if they understand the algorithm."}, {"time": 1056, "text": "This is fascinating."}, {"time": 1058, "text": "Because I speak to people at YouTube and I go, hey, man, what's going on here?"}, {"time": 1061, "text": "One of my episode titles of my podcast was called Knife Fight in Malibu."}, {"time": 1065, "text": "It was about real estate."}, {"time": 1067, "text": "And it was because a realtor in Malibu, I was trying to get a summer rental, which I can't really afford, but I don't think that's a huge problem."}, {"time": 1075, "text": "I follow my dreams."}, {"time": 1076, "text": "So I called a realtor and she said, listen, she goes, I don't know what the government's saying, but she goes, it's a real knife fight out here."}, {"time": 1083, "text": "You know, an old grizzled woman, real realtor, tanned skin, sig out the mouth, driving a Porsche."}, {"time": 1088, "text": "It's a real knife fight out here."}, {"time": 1090, "text": "Her entire life had become real estate."}, {"time": 1092, "text": "Her soul had been hollowed out."}, {"time": 1094, "text": "Her kids hate her."}, {"time": 1095, "text": "No one's made her come in years, but she just loves heated kitchen floors infused."}, {"time": 1100, "text": "She's a demon from hell and we need them, truly."}, {"time": 1103, "text": "We're getting rid of them."}, {"time": 1104, "text": "It's not good."}, {"time": 1106, "text": "And she goes, it's a real knife fight out here."}, {"time": 1107, "text": "So we put that in the episode title."}, {"time": 1110, "text": "And of course, I guess some algorithm thought that we were showing like people stabbing each other in a Wendy's and we got like demonetized."}, {"time": 1117, "text": "Did we get demonetized?"}, {"time": 1121, "text": "We lost a lot of views because we were kicked out of whatever out, like we're just kicked out."}, {"time": 1124, "text": "And then I was asking YouTube about it."}, {"time": 1126, "text": "They were kind of understanding it."}, {"time": 1127, "text": "But even the people that work there didn't truly seem to understand the algorithm."}, {"time": 1131, "text": "So can you explain to me how that works where they barely know what's going on?"}, {"time": 1135, "text": "No, they do not understand the full dynamics of the monster or the amazing thing that they've created."}, {"time": 1141, "text": "It's the amount of content that's being created is larger than anyone understands."}, {"time": 1146, "text": "Like this is huge."}, {"time": 1147, "text": "They can't deal with it."}, {"time": 1148, "text": "The teams aren't large enough to deal with it."}, {"time": 1150, "text": "There's like special cases."}, {"time": 1153, "text": "So if you fall into the category of special case, so we can maybe talk about that, like a Donald Trump, where you like actually have meetings about what to do with this particular account."}, {"time": 1162, "text": "But everything outside of that is all algorithms."}, {"time": 1164, "text": "They get reported by people and they get, like if enough people report a particular video, a particular tweet, it rises up to where humans look over it."}, {"time": 1176, "text": "But the initial step of the reporting and the rising up to the human supervision is done by algorithm."}, {"time": 1186, "text": "And they don't understand the dynamics of that because we're talking about billions of tweets."}, {"time": 1190, "text": "We're talking about hundreds of thousands of hours of video uploaded every day."}, {"time": 1198, "text": "Now, the hilarity of it is that most of the YouTube algorithm is based on the title."}, {"time": 1209, "text": "And the description is a small contribution in terms of filtering, in terms of the knife fight situation."}, {"time": 1214, "text": "And that's all they can do."}, {"time": 1217, "text": "They don't have algorithms at all that are able to process the content of the video."}, {"time": 1222, "text": "So they try to also infer information based on if you're watching all of these QAnon videos or something like that, or Flat Earth videos, and you also watch, are really excitedly watching the whole knife fight in Malibu video, that says that increases the chance that the knife fight is a dangerous video for society or something like that."}, {"time": 1248, "text": "Based on their contribution."}, {"time": 1249, "text": "So people are watching something, because I watch QAnon and Flat Earth videos to ridicule them."}, {"time": 1256, "text": "That, you know what I mean?"}, {"time": 1257, "text": "I watch these videos and I make fun of them on my show."}, {"time": 1259, "text": "But what's interesting is, if I then go watch something else, I'm increasing the likelihood that that video is gonna get looked at as potentially subversive or dangerous."}, {"time": 1269, "text": "So they make decisions about who you are, who you are as a human being, as a watcher, as a visual user, based on the clusters of videos you're in."}, {"time": 1277, "text": "But those clusters are not manually determined."}, {"time": 1280, "text": "They're automatically clustered."}, {"time": 1283, "text": "It's so weird."}, {"time": 1284, "text": "We have titles where they got upset about, I don't even understand."}, {"time": 1289, "text": "Like we had a title that was so innocuous, in my opinion, and the title of the episode was called Bomb Disney World."}, {"time": 1296, "text": "And I was asking people to consider bombing Disney World."}, {"time": 1301, "text": "And YouTube got angry at that."}, {"time": 1303, "text": "So you don't know why."}, {"time": 1305, "text": "You can never understand why."}, {"time": 1306, "text": "You could have said Disney World is the bombs."}, {"time": 1310, "text": "It's just rearranging."}, {"time": 1312, "text": "That's what it probably meant."}, {"time": 1312, "text": "I wasn't saying do it, but I was saying let's start thinking about plans to do, not let's do it, but let's get in the mind."}, {"time": 1321, "text": "Let's change the conversation."}, {"time": 1323, "text": "I think it's very interesting because as a comedian, you don't wanna live in that world of worrying about algorithms."}, {"time": 1328, "text": "You don't wanna worry about deplatforming and shadowbanning."}, {"time": 1330, "text": "I mean, all these conversations that I've had with other comedians about shadowbanning, I mean, it's hilarious."}, {"time": 1334, "text": "We all call each other, I think I'm being shadowbanned."}, {"time": 1336, "text": "Are you being shadowbanned?"}, {"time": 1338, "text": "Nobody knew what that word was a month ago, I mean, a year ago, but everyone now is convinced that everything they do that isn't succeeding is being shadowbanned."}, {"time": 1346, "text": "So it's this new paranoia, this algorithmic paranoia now that we all kinda have because there are genuine instances of people being taken out of an algorithm, you know, rightly or wrongly, however you wanna believe."}, {"time": 1362, "text": "But then there are also things that just don't perform as well for a myriad of reasons."}, {"time": 1366, "text": "And then we're all saying like, well, they're against me."}, {"time": 1370, "text": "They're shutting me down."}, {"time": 1371, "text": "And you don't know if that's true or not, you know?"}, {"time": 1374, "text": "What do you think about this moment in history, which was really troubling to me?"}, {"time": 1381, "text": "We could talk about several troubling aspects, but one is Amazon removing Parler from AWS."}, {"time": 1389, "text": "To me, that was the most clearly troubling."}, {"time": 1393, "text": "It felt like it created a more dangerous world when the infrastructure on which you have competing medium of communications now puts its finger on the scale, now influences who wins and who loses."}, {"time": 1410, "text": "Absolutely, you're right."}, {"time": 1412, "text": "And what you're always told is like, if you don't like Twitter, create your own service."}, {"time": 1417, "text": "Or if you don't like something, you can do your own thing."}, {"time": 1420, "text": "Or if you are, and basically because, you know, tech, you have to be in business with one of five companies."}, {"time": 1426, "text": "And I think it's like Amazon, Facebook, Google, YouTube, and Twitter, whatever, they're like, you know, I mean, Amazon puts everything on the cloud, you know, Google and YouTube, it's all basically the SEO and the advertising."}, {"time": 1437, "text": "And you got to get your name out there."}, {"time": 1438, "text": "You don't wanna be buried in it."}, {"time": 1439, "text": "Like, because you have to do business with it, it's a cartel of these companies."}, {"time": 1443, "text": "You understand it better than anybody that you are prevented, truly."}, {"time": 1447, "text": "And I think whatever you think about Parler, whatever you think about what people are saying on Parler, whatever you think about Alex Jones, whatever you thought about Milianopolis, the state has an interest in, and has always had an interest in crushing dissent."}, {"time": 1465, "text": "This is what the state has done."}, {"time": 1466, "text": "This is how they, you know, retain the power they have by eliminating dissent where they can."}, {"time": 1474, "text": "Now, because you don't have, you know, three broadcast networks anymore, and a handful of newspapers that were all run, by the way, by people that had been either compromised or happily, you know, happily going with the program, and you have this wild west of the internet, people like me, people that make, I make funny content that I hope is funny, but a lot of it is wild and crazy."}, {"time": 1499, "text": "I say a lot of wild and crazy things."}, {"time": 1501, "text": "They're very funny."}, {"time": 1502, "text": "I say a lot of wild and crazy things about powerful people."}, {"time": 1505, "text": "You mock the powerful in there by bringing them down a notch."}, {"time": 1509, "text": "We'll probably talk about it, but humor is one of the tools to balance the powers in society."}, {"time": 1518, "text": "And to make people feel better about things and to, you know, whatever the case may be, right?"}, {"time": 1522, "text": "That's my goal is to kind of like, hey, people have had a shitty day."}, {"time": 1525, "text": "If this video or podcast makes you laugh, that's great."}, {"time": 1529, "text": "I think that it won't ever, it was never gonna stop at Alex Jones."}, {"time": 1532, "text": "Not that I think he should have been taking off everything the way he was, but this keeps going until we have sanitized all of social media."}, {"time": 1542, "text": "And what they really want it to be is what Instagram is kind of becoming, which is a marketplace of, you could just go and buy sneakers, go buy a sweatshirt, go buy jeans, go buy this, go buy that."}, {"time": 1553, "text": "And the idea of the free exchange of information seems to be the old internet."}, {"time": 1558, "text": "And it seems the new internet seems to be, you know, hyper, and I'm a capitalist, but this seems to be like hyper capitalist in the sense of like, they only want you consuming things and they don't want you thinking too much."}, {"time": 1572, "text": "And that seems to be where it's heading."}, {"time": 1573, "text": "I've even seen that with Instagram where it's like everything on Instagram is like, buy a sweatshirt, you know?"}, {"time": 1579, "text": "And I'm like, all right, man."}, {"time": 1581, "text": "Hey man, if I want a sweatshirt, I'll get it."}, {"time": 1583, "text": "Like, relax."}, {"time": 1585, "text": "You know, just every ad seems to be encouraging consumption, but very few things seem geared towards, hey, let's have a dialogue or let's, and not that Instagram was ever great for that, but like, if everything's are geared now towards content on Instagram, a lot of it seems geared towards shopping."}, {"time": 1604, "text": "See, I don't know, that's an interesting point."}, {"time": 1606, "text": "I don't know if the consumerism that capitalism leads to is necessarily gets in the way of nuanced conversation."}, {"time": 1613, "text": "I feel like you could still sell Tim Dillon sweatshirts and have a difficult nuanced conversation or mock the current president, the previous president, mock the powerful, all that kind of stuff."}, {"time": 1625, "text": "Yeah, we try."}, {"time": 1626, "text": "We try to balance that."}, {"time": 1627, "text": "Do you have sweatshirts?"}, {"time": 1629, "text": "Are they on sale now, fake business?"}, {"time": 1632, "text": "We do, fake business sweatshirt with the Enron logo, fake business, because I do fake business all the time."}, {"time": 1637, "text": "It would be nice if you talk about Alex Jones if you plug the sweatshirt during that conversation."}, {"time": 1641, "text": "Yeah, we'll do that, absolutely."}, {"time": 1643, "text": "But what I tend to worry about with, I see social media and technology existing to flatten society."}, {"time": 1652, "text": "It makes people very boring."}, {"time": 1654, "text": "All of the experiences kids have right now are online."}, {"time": 1658, "text": "Many of their closest friendships are online."}, {"time": 1660, "text": "Their first relationships are online."}, {"time": 1662, "text": "The culture is very homogenous, and I think it's eliminating characters."}, {"time": 1667, "text": "It's eliminating interesting people."}, {"time": 1669, "text": "It's making people into AI."}, {"time": 1672, "text": "All of their tastes."}, {"time": 1673, "text": "Whoa, whoa, whoa, whoa, whoa."}, {"time": 1673, "text": "Yeah, yeah, yeah, yeah, yeah, that's right."}, {"time": 1674, "text": "AI could be Charles Bukowski as well."}, {"time": 1676, "text": "Let's not get crazy."}, {"time": 1677, "text": "It's not there yet, right?"}, {"time": 1679, "text": "I mean, the $75,000 dog is not doing anything."}, {"time": 1683, "text": "So we're not there yet."}, {"time": 1686, "text": "Listen, I hate people."}, {"time": 1687, "text": "I get why you like AI so much."}, {"time": 1688, "text": "I hate people too, and I'm very amenable to AI, and I agree with you."}, {"time": 1692, "text": "Listen, I think the future, we gotta get everyone out of here."}, {"time": 1695, "text": "I'm with you on that, so don't think I'm."}, {"time": 1698, "text": "He's manipulating my mind and my."}, {"time": 1700, "text": "That's why the flash of light in your eyes when you talked about that dog was so much more than any person."}, {"time": 1707, "text": "And I get it, by the way."}, {"time": 1708, "text": "I hate people, but if we could."}, {"time": 1710, "text": "They're not excited."}, {"time": 1710, "text": "If we could just use robots to kill most of them, I think that would be good for society."}, {"time": 1715, "text": "I'm with that too, but I think that social media flattens people."}, {"time": 1720, "text": "Flattening the personalities of characters."}, {"time": 1722, "text": "Flatten the personalities of people, man."}, {"time": 1723, "text": "And it's just, you know, when's the last time?"}, {"time": 1725, "text": "Like, I like the idea of like, you know, and I'm, you know, somebody showing up to high school with like a backpack and taking out an old CD and being like, hey man, here's this band you've never heard of that I love or whatever, you gotta get into this."}, {"time": 1738, "text": "And I'm like, you know, when I talk to young, you know, I have friends that have younger brothers and everything."}, {"time": 1742, "text": "And I know that the dominant culture was always dominant."}, {"time": 1744, "text": "I'm not an idiot, but like, I feel like it's harder to be unique and original now because so much of what's promoted is just this way to kind of corral people into believing and thinking a certain set of ideals that's constantly shifting and evolving."}, {"time": 1760, "text": "And people are just caught up in that."}, {"time": 1763, "text": "And to me, it gets very boring very quickly."}, {"time": 1767, "text": "I hate being bored and that's what it is."}, {"time": 1769, "text": "I don't know what to do with that because at the same time, podcasts are really popular, long form podcasts are really popular and people are hungry for those kinds of conversations."}, {"time": 1778, "text": "There's a lot of dangerous ideas, quote unquote, flowing, being spread around through podcasts, meaning just like debates."}, {"time": 1787, "text": "You know, so that's still popular."}, {"time": 1789, "text": "So I don't know what to."}, {"time": 1791, "text": "That gives me hope, I guess."}, {"time": 1793, "text": "And like I said, I look at the negative a lot because that's what I usually make fun of, but there's a lot of positive stuff happening too."}, {"time": 1800, "text": "Let's talk a bit about Alex Jones."}, {"time": 1804, "text": "So you've gotten a chance to talk to him while you were on the Joe Rogan Experience."}, {"time": 1809, "text": "I've been on Alex's show."}, {"time": 1810, "text": "I've talked, I've had Alex on my show."}, {"time": 1812, "text": "I've talked to Alex for three hours in front of, I guess it was maybe like 15 million people right on Joe's show."}, {"time": 1819, "text": "It was a really wild conversation."}, {"time": 1820, "text": "I think it was one of the coolest moments in broadcasting that clearly that I've ever been a part of."}, {"time": 1826, "text": "But I think it goes in the lexicon of like, these are big podcasts."}, {"time": 1831, "text": "Like I think it's one of the biggest podcasts."}, {"time": 1833, "text": "A week before the election, Alex Jones."}, {"time": 1835, "text": "I'm really grateful that Joe gave me the opportunity to be there."}, {"time": 1838, "text": "And it was just an amazing conversation to watch."}, {"time": 1841, "text": "What was the shirt you wore?"}, {"time": 1843, "text": "Fridges Lane."}, {"time": 1844, "text": "It was a fun joke that no one in tech got because we all know how funny they are."}, {"time": 1848, "text": "But the tech writers, which is mainly blue haired."}, {"time": 1850, "text": "I do not agree with these statements."}, {"time": 1851, "text": "It's mainly blue haired people whose goal in life is to find things to give them orgasms with."}, {"time": 1857, "text": "If you want to dye your hair blue, it's your choice."}, {"time": 1860, "text": "I respect it."}, {"time": 1861, "text": "Yeah, but is it your choice?"}, {"time": 1862, "text": "But at the end of the day, it's like, all the tech writers, like a lot of people just, and I'm not, I'm just maligning tech unfairly."}, {"time": 1868, "text": "But a lot of people that sense there's a humor were like, he's advocating for human trafficking."}, {"time": 1872, "text": "I'm like, it's clearly a joke because we're coming off the believe all women."}, {"time": 1876, "text": "We're coming off that."}, {"time": 1877, "text": "And it's very funny to just say Fridges Lane, hey man, believe all women."}, {"time": 1881, "text": "Like, it's just our politics and our public sphere is so schizophrenic right now that when you point that out, people are going to be angry with you."}, {"time": 1889, "text": "But that was a fun shirt to wear."}, {"time": 1891, "text": "But on Alex, you know, I was one of the people that found him really entertaining, that the same kind of thing as with Bukowski, these kinds of personalities that are wild, crazy, full of ideas."}, {"time": 1906, "text": "They don't have to be grounded in truth at all, or they can be grounded in truth a little bit."}, {"time": 1910, "text": "Like, he's just playing with ideas, like a jazz musician, screaming sometimes."}, {"time": 1915, "text": "Obviously he has some demons."}, {"time": 1917, "text": "Sometimes he's super angry for no reason whatsoever at some weird thing that he's constructing in his own head."}, {"time": 1924, "text": "Sometimes he's super loving and peaceful, especially lately that I've heard him, I don't know if you've seen with him, with Michael Malice, where he's doing, like Malice was doing, like telling Alex Jones, I love you, Alex."}, {"time": 1937, "text": "Just this loving kind of softness and kindness underneath it all."}, {"time": 1941, "text": "I don't know what to make of any of it."}, {"time": 1942, "text": "And then there's this huge number of people that tell me that Alex Jones is dangerous for society."}, {"time": 1949, "text": "So what do you do with that?"}, {"time": 1950, "text": "Do you think he's dangerous for society?"}, {"time": 1952, "text": "Do you think he is one of the sort of entertaining personalities of our time that shouldn't be suppressed or somewhere in between?"}, {"time": 1959, "text": "I don't think that Alex per se is dangerous for society."}, {"time": 1963, "text": "I think the greater danger for society comes again from stifling all dissent, right?"}, {"time": 1970, "text": "All, like anybody with a voice that uses it, that critiques the government, and putting all of those people in a category and getting rid of them is incredibly dangerous."}, {"time": 1980, "text": "To me, more so."}, {"time": 1981, "text": "I think the biggest problem that Alex has ever had was when he questioned the Sandy Hook shooting."}, {"time": 1988, "text": "And that really was, because it really is this identifiable incident that you can look at where it did get away from him and a lot of his fans who, the people that are attracted to conspiracy stuff, and I have some of those fans, some of them are really smart people, some of them are mentally unwell."}, {"time": 2003, "text": "A lot of them happen to be mentally unwell."}, {"time": 2005, "text": "So when you have a fan base of people where some of them are mentally unwell, and you are questioning tragic events, okay?"}, {"time": 2013, "text": "And Alex was right about Epstein."}, {"time": 2015, "text": "He was right about a lot of things, and he's got no credit for that."}, {"time": 2018, "text": "And I understand that this, sometimes when you write about 10 things and you're wrong about something, and the thing you're wrong about is so offensive to people, you're never gonna get any credit for being right, even though you were right more than when you were wrong."}, {"time": 2032, "text": "The problem was a lot of his fans who were crazy stalked, harassed these families and accused them of being actors and accused them of faking their children's deaths."}, {"time": 2042, "text": "It was just horrific experience."}, {"time": 2046, "text": "And Alex is tied to that."}, {"time": 2048, "text": "And how much he inspired that by what he did on his show, I don't know because I haven't watched hours and hours of that particular thing, the whole Sandy Hook thing."}, {"time": 2062, "text": "If you listen to him, he says, I really covered it."}, {"time": 2064, "text": "I kind of covered it and moved on."}, {"time": 2066, "text": "Other people go, no, he spent a long time on it."}, {"time": 2069, "text": "But that's the real danger of going into that territory over and over again, going everything's a false flag or everything's fake."}, {"time": 2077, "text": "I think Alex has actually been kind of reasonable."}, {"time": 2079, "text": "He's resisted a lot of the politics of racial resentment on the alt right, for example, he's resisted that."}, {"time": 2086, "text": "He's resisted the antisemitic currents of a lot of that politics."}, {"time": 2091, "text": "He's resisted a lot of the virulently anti trans or anti gay stuff."}, {"time": 2096, "text": "Now he does dip his toe into the water of like the culture wars, of course he does."}, {"time": 2100, "text": "But I've never really seen him, and I could be wrong about this, embrace white nationalism or identitarianism."}, {"time": 2108, "text": "I've never seen him really go antisemitic."}, {"time": 2110, "text": "I've never seen him take that route."}, {"time": 2112, "text": "When I grew up and I would turn him on every now and then, he was talking about NAFTA, the WTO, he's talking about 9 11, he was talking about the world trade organizations and a lot of these big conferences, whether it was the Bilderberg group, whether it was a Bohemian Grove, which he infiltrated."}, {"time": 2128, "text": "And he was talking about, hey, here are the most powerful people in the world."}, {"time": 2131, "text": "Here's what they're doing."}, {"time": 2132, "text": "And here's how it affects you."}, {"time": 2134, "text": "And that was interesting to me because no one else was really talking about it except Alex Jones, occasionally Art Bell on WABC."}, {"time": 2142, "text": "You'd listen to him at night, right?"}, {"time": 2145, "text": "I think Alex became very controversial when he decided to back Donald Trump."}, {"time": 2150, "text": "And then he has a considerable following and a considerable audience that he was then able to marshal in the direction of supporting Donald Trump."}, {"time": 2159, "text": "That was when the spotlight, because then he was talking to Trump, Trump did his show, Alex Jones just got bigger, right?"}, {"time": 2167, "text": "And he blew up, that's the term, right?"}, {"time": 2169, "text": "He blew off, he put out the Good HBO special, whatever you wanna call it."}, {"time": 2174, "text": "He has a hit song, he blew up."}, {"time": 2176, "text": "And then people started looking at the things that he was associated with."}, {"time": 2180, "text": "The Sandy Hook thing is a blemish on his record."}, {"time": 2182, "text": "I do believe he regrets it."}, {"time": 2183, "text": "But again, I do see the point of the families who are like, dude, fuck this guy forever."}, {"time": 2187, "text": "This is the worst thing I ever went through."}, {"time": 2189, "text": "It's a very tough, I understand the people that say that."}, {"time": 2195, "text": "I understand, and I understand the people that go, when you have tech companies that act in a coordinated manner to just get rid of someone, they don't have any way to defend themselves."}, {"time": 2206, "text": "It's a little terrifying when you think about that power being abused and how wouldn't it be?"}, {"time": 2213, "text": "Do you think he should have not have been banned from all these platforms?"}, {"time": 2217, "text": "I don't think, I do think that if you are a private company, right?"}, {"time": 2221, "text": "I do think, and this is where you run into this problem."}, {"time": 2224, "text": "I don't know if these tech companies were government utilities, would that decrease people's likelihood of being banned?"}, {"time": 2232, "text": "So I understand the benefit of them being treated like public utilities and people thinking they have the right to a Twitter."}, {"time": 2241, "text": "I've never, I don't know, I have very little confidence."}, {"time": 2245, "text": "I mean, the government's trying to roll out a vaccine in California and we vaccinated like five people."}, {"time": 2249, "text": "I mean, in terms of what we need to do in the state, right?"}, {"time": 2252, "text": "So maybe if it was a government utility, I do think someone like Alex, like there should be some process."}, {"time": 2260, "text": "So if you're gonna get rid of someone, they should have a way to defend themselves."}, {"time": 2264, "text": "There should be more democratic process that you can go through than just being unilaterally taken off something."}, {"time": 2274, "text": "But like, then you run into the, you're like, am I gonna say that everyone deserves?"}, {"time": 2278, "text": "No, if you're threatening or harassing people or threatening to kill them, publishing their private information, if you're committing crimes on these platforms, obviously the people that own these platforms are gonna be like, we're not gonna allow this to happen."}, {"time": 2290, "text": "So I understand that there is a line, right?"}, {"time": 2294, "text": "There is some, like people that say there's no line aren't really thinking, like there is a line."}, {"time": 2299, "text": "I just thought that line seems to be moving all the time and it seems to be a very hard thing to police."}, {"time": 2304, "text": "But I don't think you can remove a guy off everything and then also bank accounts won't give him debit cards or credit cards, I don't know if you talked to him about that, but like, you know, there were financial institutions that were refusing to let him park his money there."}, {"time": 2318, "text": "So, I mean, it really does get pretty terrifying pretty quickly."}, {"time": 2324, "text": "Probably without any transparency from those companies."}, {"time": 2326, "text": "So you're right, it feels like there should be a process of just having, for him to defend himself."}, {"time": 2334, "text": "I think there needs to be a process for people to defend themselves."}, {"time": 2339, "text": "Every day I wake up and I go, is something I said in a video gonna get taken out of context, is somebody gonna get angry, is somebody gonna be, you know, I say wild stuff because that's what makes me laugh, that's what makes my friends laugh and that's what makes my audience laugh."}, {"time": 2352, "text": "So I never ever, people, you know, whatever political side you come down on, I think if you make your living speaking, it's always interesting to me if you are pro the deplatforming, that's odd."}, {"time": 2367, "text": "It's interesting to consider a kind of a jury context to where, you know, there's transparency about why your video about bombing Disney World might be taken down, like it gets taken down and then there is, it's almost like creating a little court case, a mini court case and not in a legal sense, but in the public sphere."}, {"time": 2391, "text": "And then people should be able to have, you know, we pick representatives of our current society and have a discussion about that and make a real vote."}, {"time": 2400, "text": "You know, just have like jury locks himself up in a discussion, that kind of process might be necessary."}, {"time": 2408, "text": "Right now, what happens is Twitter is completely, first of all, they're just mostly not aware of everything they're doing, there's too much stuff, but the stuff they're aware about, they make the decision in closed doors meetings and without any transparency to the rest of the company actually, but also transparency to the rest of the world."}, {"time": 2429, "text": "And so, and then all they say is we're making decisions because the people, they use things like violence."}, {"time": 2437, "text": "So violence equals bad and if this person is quote unquote, inciting violence, therefore that gives us enough reason to ban them without any kind of process."}, {"time": 2448, "text": "I mean, it's interesting, I'm torn in the whole thing."}, {"time": 2451, "text": "If it was indeed, there's no transparency about it, but if Parler was indeed inciting violence, like if there was brewing of violence, potential violence where, you know, thousands of people might die because of some kind of riot, like this is the scary thing about mob, about when a lot of people get together."}, {"time": 2501, "text": "Well, in fairness to defend the people at the Capitol, they didn't shoot the cop, they bludgeoned him to death with a fire extinguisher."}, {"time": 2510, "text": "So I do wanna just kind of put that out as a defense of them."}, {"time": 2514, "text": "Listen, I'm sure there was some wild shit going on on Parler and I think the problem, here's the problem, right, there's a lot of people that just wanna go on these sites and say they wanna kill everyone."}, {"time": 2526, "text": "And the problem is, you know, at what point do you shut them all down?"}, {"time": 2531, "text": "Like I think a lot of people are just living in a world where they're powerless, they don't have any political power, they don't have any economic power, right?"}, {"time": 2539, "text": "They can't throw their money around."}, {"time": 2542, "text": "They don't have healthcare, their job security isn't great."}, {"time": 2546, "text": "They might be living in a community that doesn't have the resources they would like it to have."}, {"time": 2551, "text": "They're not happy and thrilled."}, {"time": 2554, "text": "And then they have these sites where they can go on and just say, man, I'd like to fucking burn it all down."}, {"time": 2559, "text": "And distinguishing a guy blowing off steam and saying wild stuff from a genuine threat is a very hard thing to do, you know?"}, {"time": 2569, "text": "Like I've threatened to kill, I got banned from Airbnb, I threatened to kill the people that banned me, comedically, comedically, this is a joke."}, {"time": 2580, "text": "I'm not going to kill you, this is a joke because I'm blowing off steam and I'm angry."}, {"time": 2585, "text": "Do you know how many people that my parents, like my dad's like, I'm gonna fucking kill this guy, my mom's like, I'm gonna fucking kill."}, {"time": 2591, "text": "They were talking about each other."}, {"time": 2593, "text": "But none of it ever happened, but we should be, I think you have to create a space for people to threaten to overthrow the government as long as they don't violently do it."}, {"time": 2606, "text": "I mean, does that make any sense?"}, {"time": 2608, "text": "I mean, as long as they're not gonna go hurt innocent people, what are you gonna do?"}, {"time": 2613, "text": "Like there's so many people out there that, that's why a lot of these things like 4chan, these sites, a lot of people going on there, they just wanna say the most fucked up shit because it's the thing that gives them, they can laugh or they can release steam and it is immature, it is stupid."}, {"time": 2628, "text": "It's not productive, it's not, you know, but at the end of the day, if you're not gonna give people health insurance, you gotta give them something."}, {"time": 2637, "text": "It's like when someone in this country dies that everyone disagrees with, right?"}, {"time": 2641, "text": "Political figure, media figure, a lot of people dance on their grave online and then everyone, people goes, and the other side will always do it."}, {"time": 2649, "text": "Like if a conservative dies and everyone goes, great, conservatives goes, this is grotesque that you, and then when RBG dies, they all have parties and the conservatives go, great."}, {"time": 2660, "text": "You have to let people in this country enjoy the deaths of their enemies."}, {"time": 2666, "text": "You do because they don't have much else."}, {"time": 2669, "text": "Again, if you gave them other things, you might say, guy, you can go get an E operation."}, {"time": 2674, "text": "Why don't you stop?"}, {"time": 2676, "text": "But if they're working for shit wages and you haven't figured out a way to treat them, treat their cancer diagnosis, and they don't like, I mean, life, you know, you gotta, you gotta derive pleasure from something, right?"}, {"time": 2694, "text": "It's an interesting point that anger is a good valve, like to, if your life is suffering, that there's something very powerful about anger, but I still have hope that it doesn't have to be."}, {"time": 2707, "text": "I mean, that kind of channeling into anger that then becomes hate led us into a lot of troubles in human history."}, {"time": 2715, "text": "So you have to be careful empowering people too much in that anger, especially, I think my, I think I understand why people are nervous about Parler, about Twitter and so on."}, {"time": 2730, "text": "Because all that shit talking about violence was now paired with let's get together at this location."}, {"time": 2740, "text": "This was a new thing."}, {"time": 2741, "text": "Like it's not just being on whatever platform talking shit, it's saying we're going to in physical space meet."}, {"time": 2749, "text": "And then everybody got, all these platforms got nervous."}, {"time": 2752, "text": "Well, what happens when all these shit talkers, all these angry people that are just steam, letting off steam meet in a physical space."}, {"time": 2761, "text": "And there was probably overreach, almost definitely overreach, but I can understand why they were nervous."}, {"time": 2768, "text": "There doesn't seem to be, and this is when Trump got elected and when you have like, whatever you have, right?"}, {"time": 2771, "text": "Whether you have riots in Portland and Seattle, where you have the Antifa people doing crazy things, you have like the people storming the Capitol."}, {"time": 2778, "text": "There never seems to be a ton of an examination of why these ideas are becoming popular."}, {"time": 2784, "text": "Why are people so angry?"}, {"time": 2786, "text": "What is leading people to this?"}, {"time": 2789, "text": "What about their lives is to the point where they need to show up at these places?"}, {"time": 2794, "text": "And like, and obviously there's going to be people on the fringe."}, {"time": 2797, "text": "There'll always be the mentally unwell."}, {"time": 2798, "text": "There'll always be people that want to destroy society."}, {"time": 2801, "text": "But when you look at how popular, large, long discredited things, whether it's fascism, totalitarian communism, all of these things are like, why are they back?"}, {"time": 2813, "text": "Why are they back in a big way?"}, {"time": 2814, "text": "And why are people so fed up with the status quo that they're finding solace in the most extreme discredited theories of how to run and operate societies, theories that have led to deaths of a lot of people."}, {"time": 2831, "text": "So to me, I'm like, if those people at the Capitol, yes, if they were going to work, if they were able to go out and drink at Chili's, if they were able to get a fucking checkup, right?"}, {"time": 2849, "text": "Like if their job paid a little bit better, and I'm not saying that this is all the reason, right?"}, {"time": 2854, "text": "I'm sure that there's a lot of people there that are doing quite well and they're still nuts."}, {"time": 2858, "text": "But like the anger and the rage that's boiling to the surface of this society, does it come from the fact that across the board people in very different areas and with very different political beliefs feel like they are being fucked over and there's nothing they can do about it."}, {"time": 2879, "text": "That's what the baseline to me, they look at the people that run the country and run the world, whether they're tech titans, the guys that you talked to, or whether they're people that run the government, whether they're people that run large banks, large media companies, the people that have created this kind of infrastructure that everyone lives in, these people are incredibly powerless."}, {"time": 2903, "text": "And when you push people to that point, logically, sadly, and unfortunately, the next thing does seem to be violence."}, {"time": 2913, "text": "Yeah, the thing that troubles me a lot is you said nobody's asking why these beliefs are out there, but sometimes it's not even acknowledged that people are hurting, people are angry, just even acknowledging that all the conspiracy theories that are out there, acknowledging that they're out there."}, {"time": 2935, "text": "And then people are thinking about it and talking about it just because otherwise, so it's not acknowledged in this nuanced way."}, {"time": 2943, "text": "What happens is you say, okay, 70 million people are white supremacists."}, {"time": 2947, "text": "It's just throwing a kind of blanket statement."}, {"time": 2952, "text": "And of course that gets them angrier and makes them feel more powerless."}, {"time": 2959, "text": "And that ultimately, that's what's been painful for me to see is that there's not an acknowledgement that most people are good."}, {"time": 2972, "text": "There's circumstances where it's just you're pissed off."}, {"time": 2977, "text": "Because you are powerless."}, {"time": 2978, "text": "I mean, most of us are powerless."}, {"time": 2979, "text": "You could fall in with a bad crowd."}, {"time": 2982, "text": "That's the thing, you can just fall in."}, {"time": 2984, "text": "And it doesn't mean that there's not blame."}, {"time": 2987, "text": "Obviously you have agency, you're a person."}, {"time": 2991, "text": "But the idea that you could be rehabilitated, you could do something stupid or you could fall into a group of people that are, and then in a few years you can go, what the fuck was I doing?"}, {"time": 3002, "text": "I'm an ex drug addict."}, {"time": 3003, "text": "I know what it's like to go from being one thing to being another thing."}, {"time": 3006, "text": "I'm still a drug addict."}, {"time": 3007, "text": "If I would use drugs right now or drink, I would still be addicted to them."}, {"time": 3011, "text": "I mean, it's not something that I can ever change about myself, but I know what it's like to go from one thing to another thing."}, {"time": 3016, "text": "So when you look at racism or whatever ism, homophobia, misogyny, whatever you're looking at, antisemitism, and you go, that's a fixed condition where nobody's ever going to be able to change."}, {"time": 3028, "text": "Nobody's ever gonna be able to be rehabilitated."}, {"time": 3030, "text": "Nobody's ever going to be able to reimagine themselves in a different way."}, {"time": 3035, "text": "To me, you're just, you're throwing away someone and you're making them feel helpless and worthless."}, {"time": 3041, "text": "And that's gonna lead to antisocial behavior that spills out into the violence."}, {"time": 3045, "text": "We don't have a very redemptive society."}, {"time": 3048, "text": "That's a huge factor."}, {"time": 3050, "text": "We don't have a redemptive society."}, {"time": 3052, "text": "That's why I like O.J."}, {"time": 3052, "text": "Simpson."}, {"time": 3054, "text": "Because O.J."}, {"time": 3054, "text": "Simpson, yes, he did a bad thing supposedly."}, {"time": 3058, "text": "But he's very kind now on Twitter and he makes very nice points about how we all have to get involved in the political process and he's on golf courses and I like watching people golf."}, {"time": 3067, "text": "I don't do it, but I like watching him do it."}, {"time": 3070, "text": "And he's like an elder statesman because I remember him from the naked gun."}, {"time": 3073, "text": "And I choose to forgive him for whatever happened there, which I don't know."}, {"time": 3080, "text": "But I choose to forgive him really for, I mean, obviously, what they say is he cut his wife's head off."}, {"time": 3087, "text": "But I can look past that and redeem him because he's very stable on Twitter and he's a good, like I see all these people going crazy on Twitter and I'm like, O.J."}, {"time": 3097, "text": "'s lived a full life."}, {"time": 3101, "text": "I think there's a benefit to that."}, {"time": 3103, "text": "There's a benefit to kind of living a full life."}, {"time": 3105, "text": "Yeah, how many of us have not at least tried to murder somebody?"}, {"time": 3108, "text": "100%, listen, O.J."}, {"time": 3108, "text": "'s had the highs and the lows, but he did it on his terms."}, {"time": 3116, "text": "And there's a real."}, {"time": 3117, "text": "It's like a Frank Sinatra song."}, {"time": 3119, "text": "Yeah, he did it my way."}, {"time": 3120, "text": "I mean, there's a benefit to that."}, {"time": 3122, "text": "And he seems like a very well adjusted person now."}, {"time": 3124, "text": "So I mean, I don't know, how is that a fact?"}, {"time": 3127, "text": "But it is a fact and that's an uncomfortable fact."}, {"time": 3129, "text": "Well, this is a strong case of forgiveness in one of the more extreme cases, I suppose."}, {"time": 3136, "text": "But yeah, there's not a process of forgiveness."}, {"time": 3138, "text": "It seems like people just take a single event from your, sometimes a single statement from your past and use that as a categorical like capture of the essence of this particular human being."}, {"time": 3151, "text": "So murder might be a thing that you should get a time out for a little while."}, {"time": 3158, "text": "Murder is bad."}, {"time": 3159, "text": "Murder, and let's just say that."}, {"time": 3162, "text": "Murder is not good."}, {"time": 3164, "text": "I'm glad you make this definitive statement."}, {"time": 3166, "text": "O.J."}, {"time": 3166, "text": "is an interesting cat because you're like, he's very stable on Twitter."}, {"time": 3173, "text": "He's very like, he's like, let's take a look at it, guys."}, {"time": 3175, "text": "Like we need more of his energy."}, {"time": 3178, "text": "I know like, yes, it was bad."}, {"time": 3180, "text": "He killed the woman in the waiter."}, {"time": 3183, "text": "I was not for that."}, {"time": 3184, "text": "I wish he didn't do that."}, {"time": 3185, "text": "But the trial, the O.J."}, {"time": 3185, "text": "Simpson trial was such a fun thing."}, {"time": 3190, "text": "And like you said, we need more fun people in society."}, {"time": 3192, "text": "Speaking of fun people, you've, your politics have been all over the place."}, {"time": 3199, "text": "I mean, imagine not, imagine someone whose politics weren't all over the place."}, {"time": 3204, "text": "It would seem odd."}, {"time": 3206, "text": "In the 10 years that I've been politically conscious, just because I'm 35 and 20."}, {"time": 3210, "text": "No, I've probably been conscious for over two decades, but like Democrats have become Republicans, Republicans become Democrats."}, {"time": 3216, "text": "I remember when Ann Coulter said, we need to, he defended George W. Bush when he said, we need to go out and Christianize or modernize the Arab world."}, {"time": 3224, "text": "We need to democratize the Arab world."}, {"time": 3225, "text": "And then Ann Coulter backed Donald Trump."}, {"time": 3228, "text": "And all the right wing in America believed in nation building."}, {"time": 3231, "text": "They believed in going out and democratizing areas that might breed radical terrorists, whether it was Iraq or wherever you were going, toppling regimes and instituting new democratic norms in those countries."}, {"time": 3245, "text": "That was the right wing point of view when I grew up."}, {"time": 3247, "text": "Then the right wing switched to, we are going to be isolationist."}, {"time": 3253, "text": "We're going to take care of America."}, {"time": 3255, "text": "First and foremost, we're not going to go into other countries."}, {"time": 3258, "text": "And then the Democrats who, when I grew up, were doves and the right wing people were more hawkish."}, {"time": 3263, "text": "And the Democrats were like, the military solutions aren't the way."}, {"time": 3267, "text": "We need to have multilateral diplomatic coalitions to solve all the problems."}, {"time": 3272, "text": "Now, Rachel Maddow's like, let's nuke Russia every night on MSNBC."}, {"time": 3277, "text": "The Democrats are like, we need strong presence in Syria."}, {"time": 3281, "text": "We need a strong presence."}, {"time": 3283, "text": "We need to counter Putin all over the globe."}, {"time": 3285, "text": "We need to get, so they're more hawkish on things."}, {"time": 3288, "text": "So literally I have watched two political parties literally flip and it's crazy to watch."}, {"time": 3294, "text": "And in some sense I've watched that as well because when I first saw Barack Obama, I admired that he was against the war."}, {"time": 3303, "text": "This is whatever, maybe before he was a Senator, he spoke out against the Iraq war."}, {"time": 3310, "text": "And then it doesn't feel like, it feels like his administration was more hawkish than dovish in a sense with all the drone attacks, with the sort of inability to pull back, or at least in mass efficiently pull back from all the military involvement that we have all over the world."}, {"time": 3334, "text": "So, and just the language."}, {"time": 3336, "text": "What I think is interesting about that, what's interesting about Obama, cause this is a very interesting study, is that presidents are controlled in very different ways."}, {"time": 3343, "text": "Presidents can be controlled by different factors, power factions within Washington."}, {"time": 3351, "text": "I think one of the reasons that Obama was maybe, you had a very close relationship with John Brennan, he was a CIA director."}, {"time": 3385, "text": "They go, they call it like blue book information, which is five levels above top secret, and they go like, hey man, a guy in Iran at a cafe said he's blowing everything up next week, and you know, I mean, it's the same thing as Parler, you don't know if it's true or not."}, {"time": 3399, "text": "But now the president's making a decision on usually a lot of uncorroborated intelligence that goes into a presentation for the president, where you're just terrified every day, and you don't want a terrorist attack on your watch."}, {"time": 3411, "text": "Now, so why are they getting all this information?"}, {"time": 3413, "text": "Because a lot of the people in Washington have an interest in perpetual, constant, ongoing warfare, and there's a lot of financial gain to be had from that."}, {"time": 3422, "text": "So they're sneaking their information into the presentations that are going to the president, and then the president is now behaving and going, fuck, I don't want a bomb going off, we gotta do what we gotta do."}, {"time": 3433, "text": "And whatever version of that happens, that is really kind of what is happening, whereas the presidents are being controlled by forces that are outside of the political sphere, but very much still in it."}, {"time": 3447, "text": "And they have a lot of, that's what the deep state is."}, {"time": 3449, "text": "You know, Trump, there's a lot of ridiculing Trump of going, the deep state doesn't exist."}, {"time": 3453, "text": "It absolutely exists, there's been books about it written by liberal journalists."}, {"time": 3456, "text": "The deep state is only a term for unelected, largely, power factions in Washington, DC, that outlive any presidential administration."}, {"time": 3467, "text": "These are people that might work at the State Department, they might work at the Defense Department."}, {"time": 3472, "text": "These are people that are not always working officially in any government capacity."}, {"time": 3477, "text": "They might be private companies, they might be military contractors, they might be people at Boeing or Raytheon or General Dynamics."}, {"time": 3486, "text": "And they constitute a group of people that Trump kind of called the swamp, but Trump had really no interest in draining the swamp."}, {"time": 3494, "text": "But he articulated these things, and this is what it is."}, {"time": 3498, "text": "You have a lot of interested parties that have budgets that they want, big budgets."}, {"time": 3504, "text": "Everybody wants a budget in Washington, whether you know what it is, they want money."}, {"time": 3509, "text": "And these are the people who really control press."}, {"time": 3511, "text": "So this idea that the president is the be all end all has got to be smashed, which is why the horse race model of politics and being like, is it right wing?"}, {"time": 3519, "text": "Is it left wing?"}, {"time": 3520, "text": "Is it, what team am I on and what color am I wearing?"}, {"time": 3523, "text": "It's very simplistic, but the reality is this is an empire."}, {"time": 3527, "text": "It's past its peak."}, {"time": 3529, "text": "We're in trouble."}, {"time": 3530, "text": "The United States is an empire past its peak."}, {"time": 3531, "text": "Yeah, I mean, that's just, you could prove that case in court."}, {"time": 3535, "text": "Well, let's go to court right now."}, {"time": 3537, "text": "But I do love the more complex idea that there's just human beings who crave power and seek ways to attain that power through different ways."}, {"time": 3548, "text": "If you have Barack Obama or George Bush or Donald Trump, there's different attack vectors."}, {"time": 3556, "text": "There's different ways to attain that power and then you can use that to leverage."}, {"time": 3559, "text": "And it probably doesn't have to be just in Washington, DC."}, {"time": 3563, "text": "There's people who crave power all over the world."}, {"time": 3566, "text": "Of course, but where we are now in Los Angeles, these people are all good."}, {"time": 3571, "text": "LA."}, {"time": 3572, "text": "Studio executives and people that I, from what I understand, they treat everyone fairly and they're nice, but he sees the bad guys, but out here in LA, everyone's lovely."}, {"time": 3583, "text": "So amidst this fun exploration in your mind through the political landscape that you've done over the past couple of decades that you've been conscious politically, where does Donald Trump fit into this picture for you?"}, {"time": 3602, "text": "Well, he didn't, right?"}, {"time": 3604, "text": "Cause we didn't, he wasn't political until four years ago, right?"}, {"time": 3607, "text": "He got political very quickly before."}, {"time": 3610, "text": "I mean, he was always firing off crazy tweets about where Obama was born or whatever, but he was, he got into politics like very quickly and then he became the president, right?"}, {"time": 3619, "text": "So it was like, we didn't, I knew him as Donald Trump, this crazy New York city character, the coast of the apprentice."}, {"time": 3626, "text": "I didn't think much about him."}, {"time": 3627, "text": "He was just constant, you know, like he was just this constant figure."}, {"time": 3631, "text": "Like I don't think much about Warren Buffett."}, {"time": 3633, "text": "Like I know like Trump's like, he's married to a new show girl all the time and he's always opening another casino and he's on TV."}, {"time": 3641, "text": "Wait, Warren Buffett really?"}, {"time": 3641, "text": "No, Trump."}, {"time": 3642, "text": "Trump, but like Warren Buffett is the opposite, right?"}, {"time": 3644, "text": "Warren Buffett's like been married for a billion years, lives in a little house in Omaha, but these are the, that's what I associate Trump."}, {"time": 3650, "text": "Like I don't think about Warren Buffett."}, {"time": 3652, "text": "I don't think about these people."}, {"time": 3653, "text": "They're just guys that I've known forever that have like, you know, you associate certain things with them, right?"}, {"time": 3662, "text": "And Trump, we always associated with kind of vulgar, garish, new money, billionaire, married a lot, you know, casinos, Miss Universe pageants."}, {"time": 3670, "text": "But again, you know, but it makes perfect sense that he really was able to become president at the moment where we were about to have Hillary Clinton versus Jeb Bush."}, {"time": 3682, "text": "And I think Americans felt like this is, now the oligarchy is spitting right in our face."}, {"time": 3687, "text": "You're not even making it feel like there's an appearance of democracy."}, {"time": 3692, "text": "We have two crime families vowing for control of the country every four years."}, {"time": 3697, "text": "And then there was this rogue kind of upstart guy that was really about himself."}, {"time": 3702, "text": "You know, Trump doesn't really care that much about the, I mean, really was summarized perfectly when he left and he just said, hey, have a good life."}, {"time": 3708, "text": "That's what he said before he got on Andrews Air Force Base."}, {"time": 3711, "text": "If you watch his speech, he goes, hey, have a good life."}, {"time": 3713, "text": "That's what he really feel."}, {"time": 3716, "text": "Like, hey, have a good life."}, {"time": 3718, "text": "I'm gonna get on a plane right now and fly to a castle I own in Florida."}, {"time": 3725, "text": "And really, I'm not gonna think too much about you people outside of how I can get more attention in the future."}, {"time": 3732, "text": "Can I ask you like a therapy question?"}, {"time": 3734, "text": "What is your favorite and least favorite quality of Donald Trump?"}, {"time": 3741, "text": "So my least favorite quality of Donald Trump, I think because there's a few of them, his lack of empathy, complete and total lack of empathy."}, {"time": 3755, "text": "I don't feel that he cares about human beings on any level."}, {"time": 3759, "text": "And I feel like that's, maybe it should be a requirement, right?"}, {"time": 3763, "text": "I mean, I don't think he cares."}, {"time": 3765, "text": "I think it's obvious that he doesn't care."}, {"time": 3766, "text": "I mean, he sent, you know, basically he's saying like, they're in there, Mike Pence is in there."}, {"time": 3770, "text": "He knows that his people are going to get, try to get into a Capitol."}, {"time": 3774, "text": "I mean, those motherfuckers are not gonna have jobs."}, {"time": 3776, "text": "They're gonna go to federal prison and he doesn't care."}, {"time": 3780, "text": "As long as they're storming the Capitol to prove the point that he thinks he won the election, he has no concern for these people, his followers."}, {"time": 3788, "text": "He leads them lambs to the slaughter, right?"}, {"time": 3791, "text": "So that's not a respectable quality."}, {"time": 3793, "text": "My favorite quality of Donald Trump is his willingness to call bullshit."}, {"time": 3798, "text": "So his willingness to call bullshit out."}, {"time": 3800, "text": "He doesn't play the game."}, {"time": 3802, "text": "He will, you know, when people say about Putin, Putin kills people, he goes, we kill a lot of people here too."}, {"time": 3806, "text": "Like he's willing and able to break the fourth wall and say things that no politician has ever said."}, {"time": 3813, "text": "He's willing to call out hypocrisy, you know, of course not his own, but the media, the members of the political establishment, that's a laudable quality."}, {"time": 3823, "text": "It's an entertaining quality, right?"}, {"time": 3825, "text": "We all like it."}, {"time": 3826, "text": "I love, I'm like this guy saying something that a lot of people want said."}, {"time": 3830, "text": "That being said, it's coupled with no real work or action."}, {"time": 3834, "text": "So it's not coupled with anything behind it that he just wants to, we did an episode of my podcast once where it's like essentially he's like criticizing the deep state, he wants a deeper state."}, {"time": 3843, "text": "He wants a deeper state."}, {"time": 3844, "text": "Like he hired his daughter and her husband."}, {"time": 3847, "text": "I mean, this is not a guy that's interested in transparency and openness."}, {"time": 3851, "text": "He's a guy that would just prefer, he wants to run the mafia state."}, {"time": 3856, "text": "But he shakes up the norms of social discourse, political discourse, and that people are just hungry for that."}, {"time": 3864, "text": "Like he got banned from Twitter, from all the different platforms."}, {"time": 3869, "text": "Do you think, is there an argument to be made for and against banning Twitter?"}, {"time": 3873, "text": "There's always arguments to be made for everything."}, {"time": 3875, "text": "A permanent ban seems to be an overreaction to me."}, {"time": 3878, "text": "He's the president of the United States."}, {"time": 3879, "text": "It also rearranges the power, like whether you like him or hate him, love him or hate him, he was the president."}, {"time": 3885, "text": "We've elevated Twitter is now more powerful than the president."}, {"time": 3888, "text": "It's like, do you want that to be longterm the salute, that the reality, like now Jack at Twitter is more powerful than the president of the United States."}, {"time": 3896, "text": "Is that a good paradigm going forward?"}, {"time": 3901, "text": "I'm not, listen, maybe give him a little time out for a few days."}, {"time": 3905, "text": "I think a time out, a little spanking, certainly, but I don't know if a permanent ban across the board on every social media."}, {"time": 3911, "text": "I mean, they banned them on Grindr."}, {"time": 3913, "text": "I mean, this is how hilarious it is, right?"}, {"time": 3914, "text": "I mean, they banned them across the board on everything."}, {"time": 3917, "text": "I don't think he could get an Airbnb now, neither can I, but like, I don't think he can do anything."}, {"time": 3922, "text": "Again, I just, I look back and there's so many people, my very smart, intelligent friends that go, yeah, but who cares?"}, {"time": 3927, "text": "Yeah, but he's bad."}, {"time": 3928, "text": "Yeah, but blah, blah, blah."}, {"time": 3929, "text": "Yeah, but I don't like Milianopolis."}, {"time": 3931, "text": "Yeah, but blah, blah, blah, blah, blah."}, {"time": 3932, "text": "And I'm like, you have such faith."}, {"time": 3935, "text": "You have such faith that it's always gonna be the people you dislike that are banned."}, {"time": 3940, "text": "It's always gonna be the, it's never gonna be you."}, {"time": 3943, "text": "Man, you have so much faith in the government."}, {"time": 3945, "text": "You have so much faith in tech oligarchs you've never met."}, {"time": 3948, "text": "You have so much faith in the security state that they're gonna always make the right decisions and they're not gonna penalize people that shouldn't be penalized."}, {"time": 3956, "text": "To me, I'm like, wow, I've never had that much faith in any human being ever, including myself."}, {"time": 3962, "text": "I wouldn't want that power."}, {"time": 3963, "text": "I would start deplatforming people that I hate."}, {"time": 3965, "text": "I would deplatform my aunt, you know what I mean?"}, {"time": 3968, "text": "I would deplatform everyone I know."}, {"time": 3970, "text": "I mean, so it's such an insane power to give somebody, like who gets heard, who gets to speak?"}, {"time": 3976, "text": "Yeah, I'm worried about the effect it has on people like you, actually."}, {"time": 3980, "text": "Of being, like everybody's a little more nervous in what they say."}, {"time": 3988, "text": "And that is a big problem."}, {"time": 3990, "text": "Because then you're just like longterm unmasked, like we're talking about."}, {"time": 3993, "text": "It has an effect where people just become more bland."}, {"time": 3997, "text": "Yeah, self censorship, anxiety, all of these things go into it."}, {"time": 4003, "text": "We try to fight it."}, {"time": 4004, "text": "I try to fight it."}, {"time": 4004, "text": "I think I gotta still do what makes me laugh and what makes me laugh is often fucked up."}, {"time": 4009, "text": "And it's often, it's not always fucked up in a way that it's gonna get me thrown off something, but I think pushing certain buttons is funny to me, so I gotta keep doing that."}, {"time": 4020, "text": "Part of the problem is that so many of the lines are blurred, right?"}, {"time": 4023, "text": "So you have comedians that are commentators and commentators that are comedians and politicians."}, {"time": 4028, "text": "So it's harder to get the defense of like, hey, I'm a comedian, leave me alone."}, {"time": 4031, "text": "That defense becomes harder when all of these lines are blurring."}, {"time": 4035, "text": "Everybody's kind of everything now."}, {"time": 4038, "text": "So like people say to me, you should run for office and they're serious and I'm like, you're crazy, but they're serious."}, {"time": 4043, "text": "Like, so the blurring of everything means that people aren't in their lanes as much and that you go, well, this guy is dangerous because he's not just making a joke."}, {"time": 4054, "text": "He's doing something else and he's using humor."}, {"time": 4058, "text": "And I'm like, I'm really not."}, {"time": 4058, "text": "I'm really just trying to make a joke."}, {"time": 4060, "text": "That's all, that's really what I'm trying to do."}, {"time": 4062, "text": "But I do think that because of the flattening, there's a lot of people out there that go, they take aim at humor because they go, humor is where bad ideas can kind of start and flourish."}, {"time": 4074, "text": "But don't you, to put some responsibility on you, don't you think humor is a way to, that you are the modern, like Jordan Peterson style intellectual, that humor is actually a tool of."}, {"time": 4088, "text": "It can be."}, {"time": 4089, "text": "Changing the zeitgeist, changing the social norms."}, {"time": 4090, "text": "It absolutely can be, but it also cannot be."}, {"time": 4092, "text": "I don't think it's any one thing and I think there's a lot of pressure for a comedian."}, {"time": 4097, "text": "You can be funny and right."}, {"time": 4098, "text": "You can be funny and wrong."}, {"time": 4101, "text": "If your goal is to be right, you might end up being right and not funny."}, {"time": 4105, "text": "So the reality is funny has to come first."}, {"time": 4107, "text": "There are brilliant people that have been funny and correct according to people, right?"}, {"time": 4113, "text": "But at the end of the day, people that put way too much faith in what comedy is, most of what comedy is, is people showing up to strip malls and telling jokes for an hour while people eat chicken fingers and they all get drunk and they laugh and they feel a little bit better about their lives."}, {"time": 4128, "text": "That's really the majority of comedy."}, {"time": 4130, "text": "Then there's like 10 famous people that are really famous that do a version of that in an arena."}, {"time": 4135, "text": "But the amount of cultural power they have has always been greatly exaggerated."}, {"time": 4139, "text": "My uncles loved George Carlin, who was anti military industrial complex, anti this, anti that."}, {"time": 4145, "text": "And then they would go vote for Ronald Reagan."}, {"time": 4147, "text": "They didn't care."}, {"time": 4150, "text": "It's not as powerful as you think."}, {"time": 4152, "text": "I wish it was."}, {"time": 4153, "text": "It feels good."}, {"time": 4155, "text": "It feels good for me to say I am the new thing."}, {"time": 4158, "text": "It really isn't."}, {"time": 4159, "text": "It truly isn't."}, {"time": 4160, "text": "No one is, comedians are the people that get on stage and say, we're fucked up."}, {"time": 4164, "text": "We're drug addicts."}, {"time": 4166, "text": "We're sex addicts."}, {"time": 4167, "text": "We're fat."}, {"time": 4168, "text": "We're gross."}, {"time": 4168, "text": "We can't manage our money."}, {"time": 4169, "text": "We can't stop eating."}, {"time": 4171, "text": "We can't stop fucking doing horrible things."}, {"time": 4173, "text": "We're liars."}, {"time": 4173, "text": "We're narcissists."}, {"time": 4174, "text": "We're scumbags."}, {"time": 4175, "text": "We're the people that get out and say that."}, {"time": 4177, "text": "Only a psychopath would look at us and go, show me the way."}, {"time": 4183, "text": "I disagree with you because then I'm a psychopath."}, {"time": 4186, "text": "Well, and that's, I mean, I don't think, no pushback here."}, {"time": 4191, "text": "That's another issue."}, {"time": 4194, "text": "But you know what I'm saying."}, {"time": 4195, "text": "Well, and I don't because, I mean, I understand you using this as a psychological tool for yourself to give yourself freedom."}, {"time": 4203, "text": "But the reality is you are one of the rare comedians like a George Carlin who is, besides being funny."}, {"time": 4210, "text": "When I hear things like that, I'm like, okay, you're being very sweet."}, {"time": 4212, "text": "But like, I agree."}, {"time": 4214, "text": "I understand what you're saying."}, {"time": 4214, "text": "I do stuff that makes, hopefully makes you think."}, {"time": 4217, "text": "I hope that's what good comedy is."}, {"time": 4218, "text": "But I think I try to do that."}, {"time": 4221, "text": "But I also would hate to feel shackled to the idea of that I had to make a point and that point had to be correct."}, {"time": 4231, "text": "I think the best comedy makes fun of everything."}, {"time": 4233, "text": "It makes fun of both sides."}, {"time": 4234, "text": "And then there's a deeper truth about humanity revealed."}, {"time": 4238, "text": "But then what happens is people take that deeper truth and go, let's politicize it."}, {"time": 4242, "text": "But what does he mean?"}, {"time": 4243, "text": "Is it the right or the left?"}, {"time": 4244, "text": "And I'm like, I'm doing something that I think speaks to hopefully people on both sides for everybody."}, {"time": 4249, "text": "Cause I'm making fun of people on the left and the right and in the center and people that don't care and people that do care."}, {"time": 4253, "text": "And I'm trying to figure out a way to do it."}, {"time": 4255, "text": "But then immediately anything of value in this culture right now is like, how do we politicize it?"}, {"time": 4259, "text": "How do we put it in a box?"}, {"time": 4260, "text": "So yes, I think comedy can produce a lot of inherently valuable things, reflective, thoughtful things."}, {"time": 4267, "text": "But then immediately, can it be put in this box where all of those things can be used politically?"}, {"time": 4274, "text": "And unfortunately, like when they say like, comedy is a great way to speak truth to power."}, {"time": 4277, "text": "It is, but I don't know how much it changes things."}, {"time": 4283, "text": "I don't know how much a joke can dethrone a king."}, {"time": 4288, "text": "I know the idea is nice, but let's look at the practical applications."}, {"time": 4294, "text": "I mean, we had brilliant comics, Bill Hicks, George Carlin, Richard Pryor."}, {"time": 4300, "text": "We had people talk about so many problems in society, illustrate them, put a spotlight on them."}, {"time": 4307, "text": "And we still have them."}, {"time": 4308, "text": "They're worse now than they've ever been."}, {"time": 4311, "text": "I think the society is better."}, {"time": 4312, "text": "And so to push back in my perspective, it's very possible that those voices were the exact reason we have the world today, which I do believe is actually, I mean, on the boring old measures of what makes a good world, which is the amount of violence in the world, the amount of opportunity that all those kinds of measures, even happiness, all of those things measured, things have been improving."}, {"time": 4339, "text": "Steven Pinker gets a lot of shit for this, but he's really good at articulating how the data says pretty clearly that the world is getting better."}, {"time": 4346, "text": "And it's arguable that the freedoms we do enjoy currently are thanks to the comedic voices or the people who mock."}, {"time": 4354, "text": "So to me, it's possible that humor is the very thing that saves the world."}, {"time": 4359, "text": "Humor is the very thing that keeps, is the balance of power in the world."}, {"time": 4364, "text": "But I think a lot of the things that those guys criticize, whether it was militarism or the elites, the lying, the corruption, the bribery, that's still going on."}, {"time": 4373, "text": "And it's always gonna go on, right?"}, {"time": 4374, "text": "Because that's the nature of human beings."}, {"time": 4376, "text": "We call it out, we point it out, but we don't have a plan to change."}, {"time": 4381, "text": "It's not really our job."}, {"time": 4382, "text": "And I think that too much now is like, well, comedians should have a, like, I don't tell people who to vote for."}, {"time": 4389, "text": "Like the idea that comedians went and told people who to vote for, it's like, to me, it's crazy."}, {"time": 4393, "text": "I understand like people have strong opinions, but like, I believe I have a job."}, {"time": 4397, "text": "And my job is to make you laugh or whatever, maybe make you think, but like, my job is not to tell you who to vote for."}, {"time": 4403, "text": "I mean, it's absurd."}, {"time": 4404, "text": "But see, the thing you do by the comedy, like on your Twitter, that people should definitely follow."}, {"time": 4410, "text": "I believe that, Jim J. Dillon, I agree with you."}, {"time": 4413, "text": "Oh, on this point of, I agree with you wholeheartedly."}, {"time": 4417, "text": "That people should follow you."}, {"time": 4418, "text": "Yeah, you give me, you give me freedom to think on my own."}, {"time": 4425, "text": "Meaning like you're shaking things up to where I don't feel constrained about what I can think about."}, {"time": 4431, "text": "And that's awesome."}, {"time": 4434, "text": "So you're not telling me what to think, you're giving me the freedom to think."}, {"time": 4437, "text": "And that's what great comedy does, is I don't often agree with George Carlin."}, {"time": 4444, "text": "He can get pretty political sometimes."}, {"time": 4446, "text": "But just the ability to do that's so rare."}, {"time": 4450, "text": "Podcasts do that too now."}, {"time": 4451, "text": "Like there's certain people that can really just challenge you to, even when you disagree with them, to sort of be like, oh, it's okay to think about this kind of stuff."}, {"time": 4459, "text": "Yeah, and I appreciate that, because that's awesome."}, {"time": 4461, "text": "And I mean, that's great."}, {"time": 4463, "text": "And a guy like you, who's a brilliant guy, that's great."}, {"time": 4465, "text": "If I'm giving you the license to think, then man, the world is completely fucked."}, {"time": 4470, "text": "But I'm happy about that."}, {"time": 4472, "text": "No, it's... Well, you know."}, {"time": 4475, "text": "Speaking about the world being completely fucked, Alex Jones turned on QAnon."}, {"time": 4480, "text": "I know almost nothing..."}, {"time": 4481, "text": "It's a very tough match."}, {"time": 4482, "text": "They had a rough marriage."}, {"time": 4483, "text": "They fought it."}, {"time": 4484, "text": "They fought it out for years."}, {"time": 4486, "text": "And eventually we just knew someone was gonna leave someone."}, {"time": 4490, "text": "Hewlett tried to leave him a few months ago."}, {"time": 4492, "text": "Oh, so... Yeah, he was staying at someone else's house."}, {"time": 4495, "text": "The car wasn't in the driveway."}, {"time": 4498, "text": "Well, the thing about QAnon that makes it a lot of fun is it's kind of a make it up as you go along."}, {"time": 4504, "text": "I'm a drug addict, right?"}, {"time": 4506, "text": "So often my lies aren't planned."}, {"time": 4509, "text": "They're in the moment."}, {"time": 4510, "text": "A lot of what I do on the podcast, a lot, you know, it's all in the moment."}, {"time": 4512, "text": "I'll have an idea what I wanna talk about, and I rant and I go."}, {"time": 4514, "text": "And I've been like stoned, and I show up at home, and my parents are like, what's going on?"}, {"time": 4519, "text": "There was $50 on the mantle."}, {"time": 4521, "text": "Now it's not there."}, {"time": 4522, "text": "And I'm like, well, and I gotta make something up on the spot, right?"}, {"time": 4528, "text": "I've been, you know, are you drinking again?"}, {"time": 4533, "text": "And then you gotta have a, well, you were gone for two days."}, {"time": 4535, "text": "No one knows where you were."}, {"time": 4536, "text": "And somebody said you left your car."}, {"time": 4537, "text": "Well, I was at, well, this is, I was at a sales conference and I left my car."}, {"time": 4542, "text": "I flew to Phoenix."}, {"time": 4543, "text": "Like, I understand what that is."}, {"time": 4545, "text": "QAnon is an ever evolving conspiracy theory where the events are happening in the past, in the present, and in the future."}, {"time": 4552, "text": "Every conspiracy theory is like Kennedy, something like that, that there's a lot of truth in that, or all truth."}, {"time": 4557, "text": "But at the end of the day, it's like you're looking back from 30,000 feet, analyzing little things that have already happened."}, {"time": 4562, "text": "QAnon's like, so I think Alex is kind of like got a little tired of the constant evolving nature of that conspiracy theory."}, {"time": 4571, "text": "So he's not a fan of like the jazz that is QAnon."}, {"time": 4574, "text": "So they're not, because they're improvising constantly."}, {"time": 4575, "text": "They're improvising."}, {"time": 4576, "text": "Alex is like, hey man, I was on board a little bit, but at the end of the day, it's getting a little annoying because it can turn on you."}, {"time": 4582, "text": "Eventually you become part of the conspiracy."}, {"time": 4585, "text": "Alex is controlled opposition."}, {"time": 4586, "text": "That's what they'll say."}, {"time": 4587, "text": "Eventually you, because QAnon just eats things."}, {"time": 4591, "text": "So it's a conspiracy that just eats things."}, {"time": 4593, "text": "The minute you start to say, hey man, maybe that's not, it just eats you and go, well, you're in on it."}, {"time": 4598, "text": "Everyone's in on it."}, {"time": 4599, "text": "Everyone's a satanic pedophile."}, {"time": 4601, "text": "Everyone that questions it is eating children."}, {"time": 4603, "text": "And you go, wait a minute, that seems illogical."}, {"time": 4606, "text": "But now there's not enough children."}, {"time": 4608, "text": "Now there's not enough."}, {"time": 4609, "text": "And I think QAnon's over now, unfortunately, because for these people, but I think fortunately for them, they're gonna have to find a new hobby."}, {"time": 4617, "text": "But I think it's over now because even the best QAnon people now are starting to go, hey man, this might not be going down the way we thought."}, {"time": 4623, "text": "But they've literally gone as far as to say that like Biden and Trump switched faces."}, {"time": 4627, "text": "Trump's actually still the president except Biden."}, {"time": 4630, "text": "You have to be a real moron now."}, {"time": 4633, "text": "You gotta be real stupid now."}, {"time": 4636, "text": "It's at the end."}, {"time": 4637, "text": "Like it was cool when the Epstein stuff happened, QAnon was like, it was party at Q."}, {"time": 4642, "text": "And then when the Hunter Biden laptop stuff started to happen, they were like dancing, like it's time."}, {"time": 4648, "text": "And then Biden wins and they're like, wait, whoa."}, {"time": 4654, "text": "And it's just like, it's the day after the party."}, {"time": 4656, "text": "QAnon, if you ever went to a party in high school or college, QAnon right now is the day after the party."}, {"time": 4660, "text": "You wake up, it's 12 noon."}, {"time": 4663, "text": "The sun is hitting you in the face."}, {"time": 4664, "text": "You're hung over."}, {"time": 4665, "text": "There's a stench of disgusting beer and cigarettes all over the house."}, {"time": 4668, "text": "You're like, what the fuck happened here?"}, {"time": 4670, "text": "I gotta get out of here and get a bacon, egg and cheese."}, {"time": 4673, "text": "That's what QAnon is."}, {"time": 4675, "text": "They gotta sober up, get out of that house, get a bacon, egg and cheese and go, man, we were fucking whacked."}, {"time": 4680, "text": "We were high, dude."}, {"time": 4682, "text": "I thought Nancy Pelosi was eating children for four years and that Donald Trump was gonna put her in Guantanamo Bay."}, {"time": 4688, "text": "Wow, that was, cause I mean, it's interesting."}, {"time": 4692, "text": "People had to do that after the sixties."}, {"time": 4694, "text": "They were like, yeah, I just did a bunch of acid and I lived in a ranch in Malibu and fucked everyone I ever saw."}, {"time": 4699, "text": "And they're like, I thought that was the way the world was gonna go and I followed some shaman guy, some guru who just wanted to fuck me and 10 other people that were living there."}, {"time": 4708, "text": "And we did that for three years."}, {"time": 4710, "text": "Apparently we never created the utopia we thought we were gonna have."}, {"time": 4713, "text": "And now I'm back working here at Allstate Insurance and we have great policies and we'd love you to come in the office so we can break them down for you."}, {"time": 4722, "text": "It all ends folks, all the love, all the bullshit ends, but it's fun, they have so much fun."}, {"time": 4727, "text": "QAnon was hard to get mad at because they were, this was all they had."}, {"time": 4733, "text": "Yeah, and they were quite good at it."}, {"time": 4736, "text": "And they were good at it and it was a lot of desperate people, but they were also rich idiots."}, {"time": 4742, "text": "There's also like dumb rich people and those are like the saddest people in Q cause it's like they should, they have the resources to do other things, but they just love Q."}, {"time": 4753, "text": "They're like, I'm just into this."}, {"time": 4754, "text": "And I'm like, you're rich, go do something."}, {"time": 4758, "text": "How in curious are you?"}, {"time": 4760, "text": "Go to the Amazon, go bird walk."}, {"time": 4763, "text": "I don't know, but they're, you know, so."}, {"time": 4765, "text": "Play golf."}, {"time": 4765, "text": "It's sad, but they're like done now."}, {"time": 4766, "text": "I mean, it's over."}, {"time": 4769, "text": "I see you think this is the."}, {"time": 4771, "text": "I think everything's ending."}, {"time": 4771, "text": "My whole thing is that Trump's out, QAnon's over, the quarantine is gonna end."}, {"time": 4775, "text": "Everything's gonna go back to something that's more recognizable."}, {"time": 4780, "text": "I think that."}, {"time": 4782, "text": "Are you optimistic about the 2021 and what."}, {"time": 4784, "text": "To a degree in certain aspects, I have optimism."}, {"time": 4788, "text": "And then I have, I have short term optimism and longterm pessimism."}, {"time": 4792, "text": "Meaning that I think in the short term, things can get better."}, {"time": 4795, "text": "I think longterm, because there's so many forces that are out of our control that are evolving in ways I barely understand that are carving up society."}, {"time": 4802, "text": "It's gonna be very tough longterm to be completely optimistic."}, {"time": 4807, "text": "Like, Hey, it's gonna be great."}, {"time": 4808, "text": "It's gonna be good forever."}, {"time": 4809, "text": "But short term, I think, yeah, this quarantine will end."}, {"time": 4812, "text": "Things will get better."}, {"time": 4812, "text": "The economy will get a little better."}, {"time": 4814, "text": "The constant Trump craziness will die down a little bit."}, {"time": 4818, "text": "That's my hope."}, {"time": 4819, "text": "And people can go back to focusing on things that matter, which is the things that are near you and close to you."}, {"time": 4826, "text": "Yeah, the humans around you."}, {"time": 4827, "text": "Humans around you, not Nancy Pelosi."}, {"time": 4830, "text": "I have uncles that talk about Nancy Pelosi."}, {"time": 4832, "text": "I'm like, you've never met her."}, {"time": 4833, "text": "You'll never meet her, shut up."}, {"time": 4836, "text": "And I have a belief that this kind of local love and kindness that you naturally can have for human beings that you actually know can be expanded at scale through the social networks that we use, that we build."}, {"time": 4852, "text": "Twitter is currently failing at that miserably."}, {"time": 4854, "text": "That would be great."}, {"time": 4855, "text": "But that's..."}, {"time": 4856, "text": "If we were able to increase the love through the social networks, that would be great."}, {"time": 4860, "text": "It feels very hard to."}, {"time": 4863, "text": "It's a worthy challenge."}, {"time": 4864, "text": "You've tweeted, one of the underreported reasons conspiracy theories take hold is because some of them are true."}, {"time": 4873, "text": "What conspiracy theories do you believe that are sort of important for people to think about, would you say?"}, {"time": 4884, "text": "Kennedy was not killed by a lone gunman with no connections to any other situation, government."}, {"time": 4891, "text": "I believe that JFK was removed from office by a group of people that had very different interests."}, {"time": 4901, "text": "This is the question of like deep state."}, {"time": 4902, "text": "So these are powerful people that are able now to dictate through basically the threat of violence what the presidents, the surface powerful people in our society."}, {"time": 4913, "text": "Yeah, I mean, again, I'm not..."}, {"time": 4915, "text": "I want another investigation into 9 11, not because I think that George Bush pressed a button and made 9 11 happen, but because we invaded the country of Iraq."}, {"time": 4923, "text": "And then we, 15 out of 19 hijackers were from Saudi Arabia."}, {"time": 4929, "text": "There was tons of stuff in the 9 11 report that didn't make sense to anybody."}, {"time": 4932, "text": "There's tons of stuff about that day that I feel like we just don't know."}, {"time": 4936, "text": "Yeah, that's..."}, {"time": 4938, "text": "That's when I, my little aunt life touched upon conspiracy theory world and first learned about Alex Jones is when 9 11 happened."}, {"time": 4947, "text": "It was very frustrating to me how poorly the reporting and the transparency around what exactly happened, who knew what, all that kind of a basic information that you would hope the government would release, reveal, and use as like a lesson for how we prevent this."}, {"time": 4965, "text": "Instead, it felt like a lot of stuff was being hidden in order to manipulate some kind of machine that leads us to war."}, {"time": 4974, "text": "Yeah, I mean, I just don't feel like we've gotten the full story."}, {"time": 4977, "text": "I don't know what the full story is."}, {"time": 4978, "text": "I can't, I don't know what it is, but I don't feel like we've gotten the full story."}, {"time": 4982, "text": "Yeah, there are groups of powerful pedophiles, right?"}, {"time": 4986, "text": "Whether they're in the Catholic church or they're in the government or wherever they are, they are able to cover things up that they do."}, {"time": 4991, "text": "They're able to silence people that try to out them in terms of like, you know, disrupt their operations."}, {"time": 4996, "text": "QAnon has nuggets of truth."}, {"time": 4998, "text": "It just went crazy."}, {"time": 5000, "text": "Any conspiracy theory that involves the Knights Templar and also Chrissy Teigen is probably wrong, you know?"}, {"time": 5007, "text": "What's the Knights Templar?"}, {"time": 5008, "text": "Well, it was just this group of Knights back in the day."}, {"time": 5012, "text": "You know, it's that supposedly secret meetings."}, {"time": 5014, "text": "And like in every conspiracy, they talk about like, you know, if you go deep enough, it's like the Knights Templar, the Rosicrucians, you know, all of these secret groups throughout history, the Illuminati, the... Oh, and there's a thread that connects all of this."}, {"time": 5026, "text": "Oh yes, it connects it all to David Spade."}, {"time": 5029, "text": "I mean, it's a little much."}, {"time": 5030, "text": "Well, how do you, if you're David Spade, defend yourself, by the way?"}, {"time": 5033, "text": "You ignore it because it's hilarious."}, {"time": 5034, "text": "And I know David Spade."}, {"time": 5035, "text": "It's like Hollywood's kind of boring."}, {"time": 5037, "text": "Yes, there are sex orgies."}, {"time": 5038, "text": "I'm not invited."}, {"time": 5039, "text": "I'm sure there's shit going on."}, {"time": 5040, "text": "Kids do get abused, women get abused."}, {"time": 5042, "text": "I'll invite you to one."}, {"time": 5043, "text": "Please, we got the $75,000 dog and then we'll get one."}, {"time": 5048, "text": "But, you know, me and David Spade, we go out to sushi restaurants, like, and you sit there and you listen to people complain."}, {"time": 5055, "text": "That's what a lot of it is."}, {"time": 5056, "text": "What a lot of Hollywood is is deeply sad tragedy that people don't understand that some of it is nefarious and dark and there are problems and there are real power brokers here."}, {"time": 5066, "text": "It's a dark town, 100%."}, {"time": 5069, "text": "But the idea that everybody that lives here is in some wide ranging vast conspiracy isn't true."}, {"time": 5074, "text": "It ignores how humdrum, boring, deeply sad most people's lives are in Hollywood."}, {"time": 5081, "text": "And it ignores how sad fame is in general."}, {"time": 5084, "text": "Fame's a sad thing."}, {"time": 5086, "text": "Not always, but a lot of times it's a sad thing."}, {"time": 5089, "text": "It's fleeting, it's ephemeral, it doesn't last."}, {"time": 5092, "text": "It separates you from other people."}, {"time": 5095, "text": "It's isolating."}, {"time": 5097, "text": "It can be traumatic depending on what's going on."}, {"time": 5099, "text": "Obviously it's better than the alternative."}, {"time": 5101, "text": "If you're trying to be famous, it's better to be famous than not famous, right?"}, {"time": 5106, "text": "But it's a mixed bag to a degree."}, {"time": 5109, "text": "There are things about it that aren't great."}, {"time": 5111, "text": "And Hollywood has a deep undercurrent of sadness of people that have not realized their dreams and people that have realized them."}, {"time": 5118, "text": "Both of those people."}, {"time": 5121, "text": "The people that win Olympic gold medals can sometimes suffer from depression."}, {"time": 5125, "text": "They've lost."}, {"time": 5126, "text": "Well, somebody said, and I forget who said it, it's a great quote, it's not mine."}, {"time": 5129, "text": "I think it's from a book, or it might be from a TV show."}, {"time": 5131, "text": "Sometimes I quote something and they're like, \"'That's from like, Charlotte's Web.\""}, {"time": 5135, "text": "I'm like, oh."}, {"time": 5136, "text": "The two worst things are, oh, I think it's from the movie Limitless."}, {"time": 5139, "text": "I'm like an idiot."}, {"time": 5140, "text": "But anyway, thanks for having me on."}, {"time": 5142, "text": "Tomorrow you're gonna make some genius."}, {"time": 5143, "text": "I will not publish this."}, {"time": 5146, "text": "It's from the movie, and I think he says, \"'The two worst things in the world are not good.\""}, {"time": 5150, "text": "Oh, you know what's not from Limitless?"}, {"time": 5152, "text": "I think it's from the movie where Nicolas Cage sold weapons."}, {"time": 5158, "text": "It was called Lord of War."}, {"time": 5159, "text": "It's a little better than Limitless."}, {"time": 5160, "text": "That's a good movie."}, {"time": 5161, "text": "It's a great movie."}, {"time": 5162, "text": "He said, the two worst things in the world are not getting what you want and getting it."}, {"time": 5166, "text": "So the undercurrents of sadness that run through Hollywood are, there are two rivers that converge, and there are people that just never had it, and people that have it and go, now what?"}, {"time": 5174, "text": "And so it's a sad place, a tragic place."}, {"time": 5176, "text": "And there's a lot of, it's boring."}, {"time": 5177, "text": "That's what people don't realize is like, it's actually kind of boring."}, {"time": 5180, "text": "Well, life is kind of boring."}, {"time": 5181, "text": "Life is kind of boring."}, {"time": 5182, "text": "But there's also like, you know, so I think QAnon's this way to make a lot of it seem like it's super exciting."}, {"time": 5188, "text": "And listen, I don't want to diminish the experiences of people who've been abused here, because there is a lot of horror here."}, {"time": 5193, "text": "But the whole QAnon thing was like, everybody in everything is doing, and that's not true."}, {"time": 5198, "text": "Well, see, just to linger on that a little bit is, Bill Gates, the conspiracy theories around Bill Gates bother me because, this is me, dumb, naive Lex, thinks that Bill Gates did a lot of good for this world."}, {"time": 5214, "text": "First, by creating a company that empowered personal computers."}, {"time": 5218, "text": "And second, by donating a ton of money for like treating malaria in Africa and all those kinds of things."}, {"time": 5226, "text": "And there's these huge amounts of conspiracies, I think, based on like just replies to whenever Bill Gates does anything."}, {"time": 5235, "text": "Like, to me, the top replies should be about how inspiring that guy is, to donate so much money."}, {"time": 5242, "text": "And so sorry to, the thing I'm struggling with is, if I'm Bill Gates, like, how do you behave differently?"}, {"time": 5252, "text": "How do you show people that you're, if you're not, I don't know, doing creepy stuff that they're saying he's doing?"}, {"time": 5258, "text": "Well, I think part of it is that he's done some really good stuff, right?"}, {"time": 5262, "text": "He's an innovative guy, he's on the vanguard of a lot of things, but he's also the antichrist."}, {"time": 5267, "text": "And I think that that is, you know, they're not mutually exclusive."}, {"time": 5271, "text": "He is the prince of darkness, as well as some, no."}, {"time": 5274, "text": "Here's my deal with Bill Gates."}, {"time": 5275, "text": "He's a Batman villain billionaire, meaning that he's not a villain, but he's got all this money, right?"}, {"time": 5279, "text": "Here's the thing, and I love Musk and all these guys, I know you love these guys."}, {"time": 5282, "text": "Listen, when you have the kind of money that these guys have and you have the vision that they have, and they want society to look a certain way, and a lot of them are doing great things, people, they need to get better at the pushback."}, {"time": 5293, "text": "They need to get a little better."}, {"time": 5294, "text": "When somebody says, hey man, what's going on over there?"}, {"time": 5296, "text": "Bill Gates needs to be a little better at going, here's what, because, you know, Bill Gates has the money."}, {"time": 5303, "text": "You know, I think once he wanted to shoot a missile of dust at the atmosphere to help global warming, and a lot of scientists were like, hey man, that might not be the way to do it."}, {"time": 5311, "text": "But no one in history, like so few people in history have had the resources to even have that thought, that if you have the resources to have that thought, and you have designs on the way you want society to look, whether it's public health policy or vaccinations, whatever, you have to get a little better at dealing with legitimate critiques."}, {"time": 5326, "text": "And obviously you're not defending yourself against people that say you're the Antichrist, but like, you need to get a little better."}, {"time": 5331, "text": "And I feel like Bill Gates and some of those people at that level are like, ugh, PR is kind of like, you know."}, {"time": 5337, "text": "They're terrible at it."}, {"time": 5340, "text": "Him and Zuckerberg are really bad at it."}, {"time": 5341, "text": "Zuckerberg's horrible at it."}, {"time": 5342, "text": "He seems especially bad at public."}, {"time": 5348, "text": "Yeah, and it makes me feel so bad because the problem with being a billionaire is you lose touch with reality if you're not careful."}, {"time": 5356, "text": "I think Elon is good at, at least so far, maintaining touch with reality."}, {"time": 5362, "text": "No, if you look at the name of his child, you can clearly see."}, {"time": 5365, "text": "Listen, I do like him, and I do think what he's done with Tesla, you know, my producer has a Tesla, and he never shuts up about it."}, {"time": 5371, "text": "Most people that have Teslas never shut up about them, and they think they're part of the development team at SpaceX, and I like that he's created a world where people can get excited about a $37,000 car and never shut the fuck up about it to the point where I have to threaten people with physical violence to get them to stop telling me about that their car drives itself."}, {"time": 5390, "text": "Oh, you should get a Tesla."}, {"time": 5391, "text": "Maybe have a few less drinks and a few fewer Vicodin, and you can drive yourself."}, {"time": 5395, "text": "Have you thought about getting a Tesla?"}, {"time": 5397, "text": "I've never thought about it."}, {"time": 5397, "text": "You should get a Tesla."}, {"time": 5398, "text": "I don't like them, they're minimalist."}, {"time": 5399, "text": "I don't like, I want more."}, {"time": 5402, "text": "I want more."}, {"time": 5403, "text": "Get the Cybertruck."}, {"time": 5404, "text": "I want a Cybertruck."}, {"time": 5404, "text": "I'm just being a, trolling you by being a salesman."}, {"time": 5407, "text": "My producer wants a Cybertruck."}, {"time": 5409, "text": "I want a stagecoach."}, {"time": 5410, "text": "Old school, stagecoach, horse thief shit."}, {"time": 5415, "text": "It's going back to that."}, {"time": 5416, "text": "I live in an area with a lot of horses."}, {"time": 5418, "text": "It's going back to like whipping a horse."}, {"time": 5420, "text": "I want an animal to shriek while I go by."}, {"time": 5422, "text": "You want more suffering in the world, not less."}, {"time": 5427, "text": "Oh, I think we need it."}, {"time": 5428, "text": "Okay, but I just don't like that billionaire is a bad word."}, {"time": 5433, "text": "And it's not necessarily, not every billionaire is a pedophile."}, {"time": 5437, "text": "I know, but the problem is a lot of like, it's just, you know, Epstein was very smart at like just getting people at that house and taking photos of them."}, {"time": 5444, "text": "Nobody knew what they were doing, but it's like, it was one of those things where it's like, Epstein was the most social guy ever."}, {"time": 5449, "text": "Like every photo he's like, hey, and it's like everyone that's ever done anything in the world has been at that fucking island."}, {"time": 5457, "text": "Every human being is like in a photo."}, {"time": 5459, "text": "It's just weird, like I'm in, like it's funny me and my friends get together."}, {"time": 5462, "text": "We don't ever take photos, right?"}, {"time": 5464, "text": "Like last night, a few people, it was my birthday yesterday, I'm 17."}, {"time": 5467, "text": "And my friends came over and we're just eating dinner, right?"}, {"time": 5471, "text": "And we had a fun night, and just four people that are over, nobody, right?"}, {"time": 5474, "text": "Nobody ever thought like, let's, hey, I wanna remember it."}, {"time": 5478, "text": "Let's take photos, I'm 36, woo!"}, {"time": 5481, "text": "But everything Epstein did, there's just photos of everybody, it's interesting."}, {"time": 5486, "text": "Do you think Jeffrey Epstein killed himself?"}, {"time": 5489, "text": "No, I think he was killed by that guy, that guy that they put in his cell, that lunatic, who was that big muscled guy."}, {"time": 5498, "text": "I think he was just, he did it for money, kept his mouth shut."}, {"time": 5502, "text": "Money from whom do you think?"}, {"time": 5503, "text": "Mossad, MI6, CIA, all three."}, {"time": 5507, "text": "So there's a lot of pressure from a lot of different powerful people."}, {"time": 5509, "text": "Probably Mossad, CIA more."}, {"time": 5512, "text": "I mean, it seems very clear that he was working inside of a honeypot intelligence operation."}, {"time": 5517, "text": "Ghislaine Maxwell's father was an Israeli super spy."}, {"time": 5521, "text": "Ghislaine Maxwell's working for Israeli intelligence."}, {"time": 5523, "text": "It would be odd to think, and of course the CIA knows about everything that Israeli intelligence is doing with Americans."}, {"time": 5528, "text": "So I would think that it's a very cozy relationship with those two intelligence agencies."}, {"time": 5533, "text": "And I think if you ran it by anyone, I think if you ran it by French intelligence, they'd go, yeah, no, get him."}, {"time": 5539, "text": "I don't think there was any intelligence service in the world whose job is to protect the powerful people that live in their countries that was against him getting whacked."}, {"time": 5547, "text": "But do you think it's possible that he's just an evil person who is after manipulating people and also was a pedophile?"}, {"time": 5553, "text": "So that there's a bigger thing."}, {"time": 5556, "text": "It's not factual that there's a bigger thing."}, {"time": 5557, "text": "Evil people don't get handed."}, {"time": 5559, "text": "Those are your facts, Tim Dillon."}, {"time": 5560, "text": "No, there's the facts of the case."}, {"time": 5562, "text": "You don't get handed a 65."}, {"time": 5564, "text": "Show me another evil guy who was handed a $65 million place by Les Wexner."}, {"time": 5570, "text": "Show me another evil guy that got that type of a handshake deal where he was basically let off without anything after a judge had made a very sweetheart deal for him after he was accused of molesting a 14 year old."}, {"time": 5586, "text": "Show me another evil guy that doesn't have that kind of backing that has those types of friends, those connections, those types of properties."}, {"time": 5593, "text": "Show me multiple passports all over the world."}, {"time": 5596, "text": "So show me a guy without anyone backing him that's doing it."}, {"time": 5600, "text": "Why did they, so you think he's just an evil guy who is doing this for whom is his own just shits and giggles."}, {"time": 5606, "text": "He's just getting off on it."}, {"time": 5608, "text": "Human nature, yeah."}, {"time": 5609, "text": "Human nature, huh?"}, {"time": 5610, "text": "It's human nature."}, {"time": 5611, "text": "$70 million limestone mansion."}, {"time": 5613, "text": "I'm being visibly mocked."}, {"time": 5614, "text": "Yeah, is it human nature?"}, {"time": 5616, "text": "And it's like poetry."}, {"time": 5617, "text": "I don't think it's human nature."}, {"time": 5618, "text": "I think they manipulated human nature, but I think they did it."}, {"time": 5623, "text": "I think JustLane, I think Epstein was really just a functionary and I think JustLane was kind of a pimp and Epstein was kind of a guy that made the money okay and hid money and things like that and worked for a lot of powerful people."}, {"time": 5636, "text": "I don't believe in lone pedophiles anymore."}, {"time": 5640, "text": "I don't even believe that."}, {"time": 5641, "text": "If you're a pedophile, you're like in a group."}, {"time": 5647, "text": "Well, I'm not even going there, but staying on JustLane, so you believe there's some power in her."}, {"time": 5653, "text": "What do you think happens to her now?"}, {"time": 5655, "text": "Like what are the differences?"}, {"time": 5657, "text": "I mean, I don't know what'll happen to her, but I imagine she'll get some type of deal, closed door thing years from now when people don't really care about the case and she'll serve some time in a very lax thing or she'll be killed."}, {"time": 5671, "text": "I mean, again, it's like if she was doing what she was doing, which is I believe a fact that she was compromising powerful people so that they could be blackmailed by the intelligence services of the US and Israel, probably, I don't see how she wasn't doing that."}, {"time": 5691, "text": "Someone's black, someone's using the photos and the tapes, right?"}, {"time": 5695, "text": "Someone's using that against these people."}, {"time": 5697, "text": "Someone wants to control these people."}, {"time": 5699, "text": "Well, who and why?"}, {"time": 5700, "text": "That's the real question."}, {"time": 5702, "text": "And I think the real question is you wanna exert control over congressmen and senators and presidents because they have the power to make decisions to affect the, but the CIA just works for a lot of very wealthy people."}, {"time": 5715, "text": "That's what the CIA, so how the CIA started, right?"}, {"time": 5718, "text": "It was lawyers, bankers."}, {"time": 5719, "text": "They're protecting financial interests of multinational corporations all over the world, overthrowing democratically elected governments, going in and doing subterfuge campaigns, encouraging terror."}, {"time": 5730, "text": "They were doing all kinds of crazy stuff."}, {"time": 5731, "text": "I don't see why that would change."}, {"time": 5733, "text": "I think that's who they still represent."}, {"time": 5734, "text": "And I think those people want certain policies and certain people pushed forward."}, {"time": 5740, "text": "And I think those people are controlled."}, {"time": 5742, "text": "And I think one of the ways to control people is their sexual problems."}, {"time": 5746, "text": "And that's the way they did it."}, {"time": 5749, "text": "I wish there was a way to, because everything you just said now is."}, {"time": 5754, "text": "It makes a lot of sense, doesn't it?"}, {"time": 5756, "text": "I'm being indoctrinated on air."}, {"time": 5760, "text": "You think there's just a, Jeff Ramsey is just a fun, random guy who just wanted to make home movies of presidents?"}, {"time": 5768, "text": "Well, you think I'm just some random guy."}, {"time": 5769, "text": "I'm just trying to sell myself as somebody who's friendly with the American audience."}, {"time": 5774, "text": "I believe you are backed by people that want people to be more comfortable with robot dogs."}, {"time": 5780, "text": "I believe that."}, {"time": 5781, "text": "I believe you're pushed to be the happy face of AI."}, {"time": 5783, "text": "Which is why I will edit this part."}, {"time": 5784, "text": "They shouldn't pick the happier face."}, {"time": 5788, "text": "No editing."}, {"time": 5788, "text": "Joe Rogan's rule, no editing."}, {"time": 5790, "text": "This is live."}, {"time": 5791, "text": "No, I mean, I wish there was a way to, for some of the conspiracy theories, to prove that that's not the case."}, {"time": 5797, "text": "Like what the CIA is."}, {"time": 5799, "text": "There is some possibility in my mind that institutions like the CIA and different kinds of organizations are driven less by organized malevolence and more by just incompetence."}, {"time": 5814, "text": "Just bureaucracy, being incompetent."}, {"time": 5816, "text": "I think that argument gets less and less persuasive when you look at all the things they've been able to do."}, {"time": 5823, "text": "It's very certain, just like you said, that there's a bunch of them that have done, because there's some conspiracy theories that are dramatic and true."}, {"time": 5834, "text": "The question is, I wish there was a way to prove that some of them are not."}, {"time": 5839, "text": "And it's very difficult, because so much is shrouded in mystery."}, {"time": 5842, "text": "Like one of the things I'm bothered by is when people accuse other athletes of using steroids, for example."}, {"time": 5848, "text": "And it's just, yes, a lot of people use steroids, but it sucks that people just don't believe you."}, {"time": 5855, "text": "There's some incredible athletes that look shredded, that look just incredible performers, and everybody just says that they're on steroids."}, {"time": 5863, "text": "They kind of assume."}, {"time": 5864, "text": "Yeah, I mean, and people accuse me all the time of being on performance enhancing drugs and steroids."}, {"time": 5870, "text": "And it is hard, but what I remind them is, it's what my appearance is a result of dedication."}, {"time": 5878, "text": "But no, it's hard work, diet, exercise, dedication."}, {"time": 5882, "text": "Are you on keto?"}, {"time": 5884, "text": "I'm on, I'm on keto."}, {"time": 5885, "text": "I'm doing a version of, you're keto, right?"}, {"time": 5888, "text": "So I'm doing a version of keto right now with Brad."}, {"time": 5891, "text": "And it's, do you see what I mean?"}, {"time": 5893, "text": "You carb up in order to be able."}, {"time": 5895, "text": "So it's keto with sugar."}, {"time": 5896, "text": "It's called keto plus sugar."}, {"time": 5898, "text": "And it's a good diet for, I grew up in the 90s when nobody ever lost weight sadly, because every diet was like, you can eat what you want, just be accountable."}, {"time": 5908, "text": "No one even knew what that meant."}, {"time": 5910, "text": "So it would be like my mother being like, if you have chocolate chip pancakes, have a glass of water."}, {"time": 5915, "text": "Just take a walk around the block."}, {"time": 5917, "text": "You can go to McDonald's three times a day."}, {"time": 5920, "text": "Just walk around the block."}, {"time": 5921, "text": "It's what my parents used to say."}, {"time": 5922, "text": "My mother would be like, just walk around the block."}, {"time": 5924, "text": "You're fine."}, {"time": 5926, "text": "Gonna have a cigarette?"}, {"time": 5927, "text": "Walk 20 steps, walk 20 steps back."}, {"time": 5930, "text": "It's exercise."}, {"time": 5931, "text": "So, you know, there's too many conspiracies out there."}, {"time": 5934, "text": "A lot of them aren't true."}, {"time": 5935, "text": "A lot of them are bitter, angry people trying to justify their own impotence, not being able to do anything in life."}, {"time": 5941, "text": "And they're like the people that have done something in life, they're all nefarious."}, {"time": 5944, "text": "It's all, the car just attacked against me."}, {"time": 5945, "text": "That's 100% true, 100%."}, {"time": 5948, "text": "It attracts usually people that have not figured out a way to succeed or haven't succeeded on the level that they want to."}, {"time": 5957, "text": "But that also being true, there is a fair amount of fuckery going on and provable."}, {"time": 5965, "text": "And, you know, we just have to, I think, separate, know that these things are often inflated or not true, but know that sometimes they are true."}, {"time": 5976, "text": "Otherwise it wouldn't exist."}, {"time": 5977, "text": "If there was no, if there was nothing to JFK, there was nothing to 9 11, if people felt like they were being dealt with honestly, this wouldn't exist."}, {"time": 5987, "text": "I mean, this exists because there are real questions that people have that don't get answered for whatever reason."}, {"time": 5993, "text": "And then the vacuum of the refusal to answer those questions, that information vacuum is filled with people like Alex Jones, who are curious and sometimes they're right and sometimes they're horribly wrong."}, {"time": 6005, "text": "And sometimes they're all over the place."}, {"time": 6007, "text": "And they're good storytellers and people love stories."}, {"time": 6009, "text": "And then when there's an absence of actual."}, {"time": 6011, "text": "Alex is a uniquely American person, like a very interesting, I don't know how many countries, like how many people make a living as a conspiracy theorist, a good living in other countries, right?"}, {"time": 6020, "text": "It's very rare, right?"}, {"time": 6021, "text": "I mean, it's very interesting."}, {"time": 6022, "text": "And he became like, I know people that knew him when he was a kid, because I'd go to Austin and perform a lot."}, {"time": 6027, "text": "And he was a guy that would take a bullhorn and yell at cops because he thought DEI checkpoints were unconstitutional."}, {"time": 6032, "text": "That's what he was doing in college."}, {"time": 6033, "text": "And he's just went through, he was hated by the right."}, {"time": 6035, "text": "He was hated by the Bush people."}, {"time": 6037, "text": "He was hated by them."}, {"time": 6038, "text": "And he went from being this guy that was considered like a leftist even, like even though he was never a leftist, he was considered this like enemy of mainstream conservatism."}, {"time": 6050, "text": "Like he was not considered a guy that wasn't a patriot, wasn't this, wasn't that."}, {"time": 6055, "text": "And he just, wow, like he whines and whines and ends up just being this confidant of a Republican president, very divisive Republican president."}, {"time": 6064, "text": "And he becomes this populist and everything like that."}, {"time": 6066, "text": "It's really wild to watch that."}, {"time": 6068, "text": "But I mean, I do think he should retire eventually just so we could get some, I don't know, it seems like it's a lot to keep doing."}, {"time": 6074, "text": "Well, I hope this world allows for Alex Jones to continue having a voice because just like you said, he's a, use the word fun, but really he shakes up the norms of our discourse."}, {"time": 6088, "text": "I do too."}, {"time": 6089, "text": "I do think we need to put more value."}, {"time": 6090, "text": "I think entertainment, we do need to say that like there are people that should be allowed to have a voice for entertainment purposes."}, {"time": 6098, "text": "And that's part of what Donald Trump, now that he's not the president, come on, let the guy, let him talk."}, {"time": 6106, "text": "Who do you think is the best comedian of all time?"}, {"time": 6109, "text": "Oh, that's a great question."}, {"time": 6110, "text": "Greatest of all time."}, {"time": 6113, "text": "You mentioned Carlin, your uncle's liking Carlin."}, {"time": 6118, "text": "Well, Carlin is great."}, {"time": 6120, "text": "Carlin is really hard to argue with, but Chappelle is also really great."}, {"time": 6128, "text": "Louis C.K."}, {"time": 6128, "text": "is really great."}, {"time": 6131, "text": "I don't know that there's what Joan Rivers is great."}, {"time": 6135, "text": "You smile at that."}, {"time": 6136, "text": "Well, she's a beast of a comic."}, {"time": 6138, "text": "I'm not aware of her standup actually."}, {"time": 6139, "text": "She's a beast of a comic."}, {"time": 6140, "text": "Ask Rogue and ask any of them."}, {"time": 6143, "text": "Kennison's great."}, {"time": 6144, "text": "So what makes a great comic do you think in the history of comedy?"}, {"time": 6149, "text": "Just like that."}, {"time": 6149, "text": "Said something at the moment in a way, found a way to communicate with people in the funniest possible way at that moment and illustrated larger truths about life in what they did."}, {"time": 6164, "text": "And I think that guys like Louis and Chappelle and Pryor and Kennison and Hicks, people like Joan Rivers have done that."}, {"time": 6173, "text": "And even modern people, people like Maria Bamford's an amazing comedian."}, {"time": 6177, "text": "It's just a different style of comedy per se, but she's an amazing comedian."}, {"time": 6183, "text": "Cat Williams is an amazing comedian."}, {"time": 6185, "text": "He really is."}, {"time": 6186, "text": "Does he have any, was he the one of the things you kind of mentioned, the communities you mentioned, they were kind of fearless in saying the difficult things that needs to be said."}, {"time": 6195, "text": "Cat Williams is more, I don't remember his comedy, but I think it's just more wild out there."}, {"time": 6200, "text": "Well, to an extent that you can watch it."}, {"time": 6201, "text": "He's got stuff."}, {"time": 6202, "text": "He talks about stuff."}, {"time": 6203, "text": "He talks about race brilliantly."}, {"time": 6204, "text": "He talks about America brilliantly."}, {"time": 6206, "text": "No, I think there's a lot of stuff there."}, {"time": 6208, "text": "Of course, Chris Rock."}, {"time": 6209, "text": "Of Chris Rock, of course."}, {"time": 6210, "text": "It's so hard."}, {"time": 6211, "text": "You can't really pick one."}, {"time": 6212, "text": "You just gotta, there's a class of people that throughout this history of this business, which is not that long of a history."}, {"time": 6218, "text": "It's pretty much within the last century, that have been really influential."}, {"time": 6224, "text": "Sometimes it's style, the way they deliver things."}, {"time": 6227, "text": "Sometimes it's substance of how they, what they're saying, or sometimes it's just a style of what they're saying."}, {"time": 6232, "text": "And we're only talking about standup comedians, right?"}, {"time": 6235, "text": "So there's a million great comedians."}, {"time": 6236, "text": "If we're gonna talk about Jim Carrey and Adam Sandler and Chris Farley, these are brilliant."}, {"time": 6241, "text": "And those guys are bigger influences on comedy, I think, than standups, really, truly."}, {"time": 6246, "text": "So there's so many brilliant people in the business."}, {"time": 6249, "text": "Who was, for you, influential, just early on?"}, {"time": 6252, "text": "Hicks was influential, because I'd watch Bill Hicks, and I'd be like, this guy's saying crazy shit on stage, and this is the only way he can get away with it, is because it's so funny."}, {"time": 6260, "text": "And he was calling out the military industrial complex, and he was talking about the first Gulf War."}, {"time": 6265, "text": "I remember he said a joke that I heard."}, {"time": 6267, "text": "It made me sit up straight, and he goes, he was in Canada, and he said, we had a war in the States."}, {"time": 6271, "text": "He was talking about the first Gulf War."}, {"time": 6273, "text": "And he said, I was in the unenviable position of being for the war, but against the troops."}, {"time": 6278, "text": "And to me, I love that joke."}, {"time": 6280, "text": "It was so funny to me, and I was like, oh, you can't get away with that anywhere other than standing on a stage."}, {"time": 6286, "text": "You couldn't ever say that in an office, really."}, {"time": 6288, "text": "And this was before, like, it was like PC, and they said, the other thing, I always knew that comedians had to say shit and have it be funny enough that you couldn't get away with it in polite society."}, {"time": 6299, "text": "That was why it was a dark theater or a dark nightclub."}, {"time": 6302, "text": "That's when people had a few drinks."}, {"time": 6303, "text": "That's what the art form was, and that's why."}, {"time": 6306, "text": "So a guy like that was influential because I started watching him."}, {"time": 6309, "text": "And then, of course, I loved SNL when I was a kid, and I would watch Chris Farley, and I would watch people like even John Belushi going back in the day, but I'd watch Adam Sandler and Will Ferrell and all these guys."}, {"time": 6320, "text": "I mean, there's so many funny people, but Bill Hicks was kind of funny."}, {"time": 6324, "text": "And then Patrice O Neill was probably my favorite comedian who's made me laugh more than anybody else."}, {"time": 6329, "text": "So I think it was you, actually, that maybe on your podcast, we're talking about Patrice O Neill and that he was actually vicious to others."}, {"time": 6340, "text": "I think he was a little mean to other people, but he was very good to people that he liked, I guess."}, {"time": 6344, "text": "I think he was like not, I mean, he wasn't, and I've never met him."}, {"time": 6347, "text": "I have no inside info, but from what I've heard, he was like no nonsense guy, right?"}, {"time": 6351, "text": "He just said what he wanted to say."}, {"time": 6353, "text": "But I think in terms of comedians, I don't know of anyone funnier than Patrice O Neill who said, in modern times, that said more about our society than him."}, {"time": 6363, "text": "I mean, he was just a brilliantly funny guy."}, {"time": 6365, "text": "On the radio, he was funny."}, {"time": 6366, "text": "On his specials, he was funny."}, {"time": 6368, "text": "Everywhere, he was funny."}, {"time": 6370, "text": "And there's something else to be said about the whole medium of comedians doing podcasts."}, {"time": 6375, "text": "Because it unlocks a weird, special, new thing that changed everything."}, {"time": 6380, "text": "I mean, Rogan started with that."}, {"time": 6382, "text": "You're doing that."}, {"time": 6385, "text": "I think that's a whole nother form of like standups, the ones that have a lot to say."}, {"time": 6391, "text": "Almost like we get to witness the process of the creation of the jokes in a way, or the mind."}, {"time": 6399, "text": "The sort of the evolution of the mind behind the jokes."}, {"time": 6405, "text": "Comedians relate to social media."}, {"time": 6407, "text": "Comedians, comedy's, it's a performance based medium."}, {"time": 6412, "text": "So it's about getting up and doing it, getting up in a club, getting up in a theater, getting up in a bar, getting up wherever you can get up."}, {"time": 6418, "text": "And comedy for years was about performance."}, {"time": 6423, "text": "And then on the higher end, it was about movies and TV shows."}, {"time": 6426, "text": "But we were very slow to get on YouTube."}, {"time": 6429, "text": "We're very slow to adapt to technology."}, {"time": 6431, "text": "We're very slow to monetize anything we did on the internet."}, {"time": 6436, "text": "So podcasting was a way for comics and funny people to kind of get into that space, start earning money."}, {"time": 6443, "text": "And now because of the pandemic, it's really become essential."}, {"time": 6447, "text": "And it helps you, and even without the pandemic, it was how you were building a fan base."}, {"time": 6452, "text": "And that's like, but comics were very reticent to embrace social media at all because they thought it was cheap and they didn't like it."}, {"time": 6459, "text": "And they thought the people on it were idiots and were unfunny and it was just a blatant, whatever it was, whether it was a money grab or it was just too commercial in a sense where they're like, hey, look at me."}, {"time": 6469, "text": "Like it was just goofy, right?"}, {"time": 6471, "text": "And then comics, I think got displaced because all the YouTubers came in and all the social media stars came in and they really knocked comics off because now people are much more, like if you ask anyone under 30 who their favorite comedian is, they say David Dobrik."}, {"time": 6488, "text": "And there's nothing wrong with that."}, {"time": 6489, "text": "David's a funny guy, but like what you, not especially to me a ton, but that's okay."}, {"time": 6497, "text": "I don't, but he makes people laugh, so he's funny."}, {"time": 6501, "text": "But he's what people, that's a comedian now."}, {"time": 6504, "text": "So comics got beat by other people coming into a digital space before they did laying the groundwork and taking it over."}, {"time": 6514, "text": "And now comics are just trying to stay alive."}, {"time": 6518, "text": "Like even my podcast, which is people really like it, thank God, and I love doing it."}, {"time": 6523, "text": "The Tim Dillon Show."}, {"time": 6525, "text": "I was late, you know, I mean, I was, I just, you know, I've been podcasting for a long time, but really dedicating myself and putting the resources behind it, I was late to it."}, {"time": 6535, "text": "Like, I was like, hey, I'm telling jokes on stage, which is great, but I should have been allocating more time to building an infrastructure online."}, {"time": 6542, "text": "And I wasn't doing it and a lot of comics weren't doing it."}, {"time": 6544, "text": "Funny comics weren't doing it."}, {"time": 6546, "text": "Comics should be doing it."}, {"time": 6548, "text": "And I think when the pandemic ends, a lot of comics will just keep doing live standup, but I will keep, obviously I'm gonna go back on the road and do live standup, but I will keep doing this podcast and building digitally too."}, {"time": 6557, "text": "But you're also exploring ideas."}, {"time": 6559, "text": "You're doing like short videos and so on."}, {"time": 6561, "text": "You're trying to look for different mediums of how to be funny."}, {"time": 6566, "text": "I wanna be funny everywhere."}, {"time": 6568, "text": "I love making things too."}, {"time": 6569, "text": "My producer, Ben Avery, is like a brilliant editor and comedic mind, even though he's not a standup."}, {"time": 6576, "text": "He's able to, he understands funny, he understands what makes me funny."}, {"time": 6579, "text": "We're able to make these really, I mean, some of those videos, they're just brilliant little videos, even though they're tiny little videos, they're fucking as funny as anything."}, {"time": 6587, "text": "And it's not me."}, {"time": 6588, "text": "It's me working with somebody else to make something really great."}, {"time": 6592, "text": "And it's that relationship that's very important."}, {"time": 6596, "text": "In some sense, the medium of a short video is a challenge, just like the medium of a short tweet."}, {"time": 6603, "text": "How to say something."}, {"time": 6604, "text": "I mean, whatever the flavor is of what's in your heart, what's in your mind, how to say it, whether it's the goal is funny or something, or just an expressing idea."}, {"time": 6615, "text": "I think the whole thing that's important to us is that it's an extension of, really like an extension of your friendship in a way."}, {"time": 6622, "text": "Like, are you guys laughing at it?"}, {"time": 6624, "text": "Are you guys making each other laugh about this idea?"}, {"time": 6627, "text": "And if that's the case, other people are going to laugh at it."}, {"time": 6631, "text": "I think so much of the old medium was like, everything was top down."}, {"time": 6635, "text": "Okay, pitch me this idea."}, {"time": 6637, "text": "I pitch it to the showrunner."}, {"time": 6638, "text": "They pitch it to the network."}, {"time": 6639, "text": "They pitch it to this, to that, to that."}, {"time": 6642, "text": "Standards and practices, sales, and we got to go through everything."}, {"time": 6645, "text": "Now it's just like, are me and a few buddies or even just one buddy laughing at this idea?"}, {"time": 6651, "text": "Does it captivate us?"}, {"time": 6652, "text": "And do we see it visually?"}, {"time": 6655, "text": "And also a great line from Roseanne, a guy, not Roseanne, but a guy that worked on Roseanne, the old Roseanne, the great one."}, {"time": 6663, "text": "He said, is it funny with the sound off?"}, {"time": 6667, "text": "That's what we try to do."}, {"time": 6669, "text": "Is it funny with the sound off?"}, {"time": 6670, "text": "When you see me in the dumb things, or me in the Meghan McCain, or me in the thing, is it funny with the sound off?"}, {"time": 6675, "text": "And if it's funny with the sound off, you have a good starting point."}, {"time": 6678, "text": "That's hilarious, because you, I would say you're one of the people, because most people are not funny with the sound off, most comedians."}, {"time": 6686, "text": "Like you, Will Ferrell's another example of that."}, {"time": 6688, "text": "There's something about when I click on one of your videos, it's funny, just like the first thing I see, just your face."}, {"time": 6696, "text": "We, well, thank you."}, {"time": 6697, "text": "That's very sweet."}, {"time": 6698, "text": "But I mean, thank God."}, {"time": 6700, "text": "I mean, that's what we try to do, right?"}, {"time": 6701, "text": "We're trying to be funny."}, {"time": 6703, "text": "So we're trying to be funny."}, {"time": 6705, "text": "Can we talk about love a little bit?"}, {"time": 6708, "text": "So you came out of the closet as being gay when you were 25."}, {"time": 6713, "text": "Yeah, it was late, very late."}, {"time": 6715, "text": "Very late."}, {"time": 6716, "text": "Before then."}, {"time": 6717, "text": "By today's standards."}, {"time": 6718, "text": "During and after, how has your view on love evolved?"}, {"time": 6725, "text": "It's so hard to say, because like I would, I'd like to make a very like Disneyfied statement about like that you can't be in love secretively."}, {"time": 6735, "text": "You should be honest."}, {"time": 6736, "text": "Love should all be about honesty, but that's not true."}, {"time": 6739, "text": "There's people that are in love that are lying to everyone else, but they're deeply in love."}, {"time": 6745, "text": "I would love to say something like, honesty is an ingredient for love, you know?"}, {"time": 6750, "text": "But I don't know, maybe honesty with each other."}, {"time": 6753, "text": "But I mean, I think there's a lot of people in the world that aren't honest."}, {"time": 6756, "text": "My view on love is super important."}, {"time": 6759, "text": "I think that it's, a lot of society in America is all about love."}, {"time": 6764, "text": "We don't tend to focus on other things in terms of like, you know, friendship or sustainability of that."}, {"time": 6774, "text": "Cause I think that a lot, I know a lot of people in relationships where it's like, I don't know, they're not, they are, they love each other, but like, it's also a rock solid couple because they are, they're very compatible in many other ways."}, {"time": 6789, "text": "So I think that like, They're friends."}, {"time": 6791, "text": "They have, right."}, {"time": 6792, "text": "I see friendship and love as the same thing."}, {"time": 6793, "text": "There's just parts of it that are, right?"}, {"time": 6795, "text": "So it's like, I look at it as like, there is, there needs to be more than just like that, like amazing, like chemistry or physical attraction that is this chemical thing that happens."}, {"time": 6808, "text": "There should be like some underlying, I mean, again, that's from what I, that's what I've observed as really long lasting, successful relationships."}, {"time": 6817, "text": "Well, is there something about coming out that, that was, that you took away, that you remember as profound, Yes."}, {"time": 6828, "text": "That it was my, that I, it wasn't society, it was me."}, {"time": 6832, "text": "So there were kids that were out in my high school that I waited years later to do it."}, {"time": 6838, "text": "That was no one's fault but my own."}, {"time": 6840, "text": "So I was taking a cowardly way out and a lot of people."}, {"time": 6843, "text": "So I could blame society or like, oh, I lived in a conservative area and I grew up in that."}, {"time": 6849, "text": "You should take responsibility for your own decisions."}, {"time": 6851, "text": "And if you're being cowardly, admit that you're being cowardly."}, {"time": 6854, "text": "So that's what I took out of it is that it's not society's fault that you chose to be a coward."}, {"time": 6859, "text": "Society will never be perfect."}, {"time": 6861, "text": "You have to be honest when you're ready to be honest or however you want to be honest, but it's not somebody, too much now is it's everyone else's fault that you didn't take, make a hard choice or a hard decision."}, {"time": 6871, "text": "So that's kind of what I took out of it."}, {"time": 6873, "text": "So now in retrospect, you see yourself as, were being afraid."}, {"time": 6878, "text": "Do you think at the time?"}, {"time": 6880, "text": "Well, I wanted people to like me, which is the disease of humanity, right?"}, {"time": 6885, "text": "Is that we want to be liked."}, {"time": 6886, "text": "And what happens is if you want people to like you and love you even, you want people to feel comfortable with you."}, {"time": 6892, "text": "And those were people like your family?"}, {"time": 6893, "text": "Friends more."}, {"time": 6895, "text": "My family I would always, could always throw in the street, but I'm kidding."}, {"time": 6899, "text": "I mean, but I am not, but my friends, my circle of friends, which I were my family at the time when you're a senior, when you're 10th, 11th grade in high school, your friends are your family."}, {"time": 6910, "text": "Like that's your, so you don't want to do anything that puts you on the outside of the circle."}, {"time": 6915, "text": "It's just thinking back to that fear."}, {"time": 6916, "text": "Is there things you're afraid of now?"}, {"time": 6919, "text": "That you're not doing, you're afraid to do?"}, {"time": 6921, "text": "I'm afraid of all kinds of things."}, {"time": 6923, "text": "I'm afraid of not being good at my job, not being funny, letting people down, not putting out products that are good, whether it's the podcast every week or stand up or the videos, like I'm afraid of like, there's a ton of people that really enjoy what we do."}, {"time": 6940, "text": "So when you're in that position, you're nervous that you're going to start doing things that they don't like."}, {"time": 6945, "text": "So the new things you want to do, the evolution you want to do, you want to make sure you're evolving in the right way."}, {"time": 6951, "text": "You want to make sure that you're doing things that are consistent with why people liked you, but also you don't want to put yourself in a box and limit what you can be going forward."}, {"time": 6959, "text": "So like, I had a talk with the CEO of NBC Universal once."}, {"time": 6962, "text": "I was doing some internal sketch for them."}, {"time": 6965, "text": "And I was playing like a cab driver and he was a, and he's not the current CEO, but he's a former CEO."}, {"time": 6970, "text": "And I said to him, what's the hardest part of running a corporation of this size?"}, {"time": 6974, "text": "And he said something very interesting."}, {"time": 6977, "text": "He said, the hardest part is maximizing the current profit model of what you have at the same time, getting ready, getting ready, getting the company ready for where it's going to be in five years."}, {"time": 6987, "text": "He said, those are often at odds."}, {"time": 6989, "text": "And that's the toughest thing."}, {"time": 6990, "text": "He goes, cause I could just bang out everything I got to do right now."}, {"time": 6994, "text": "And we're going to make a lot of money doing this, but am I devoting enough resources into digital so that in five years, when that's where everything lives, are we competitive in that space?"}, {"time": 7026, "text": "What should I, should I have a bigger presence on TikTok?"}, {"time": 7029, "text": "Should I have a bigger presence here?"}, {"time": 7030, "text": "Should I have a business, or should I be on Twitch?"}, {"time": 7032, "text": "Should I be doing this?"}, {"time": 7032, "text": "Should I be doing that?"}, {"time": 7033, "text": "What am I not doing that I should be doing that I'll regret not doing?"}, {"time": 7037, "text": "And those are, those are the conversations I think I have in my own head all the time."}, {"time": 7041, "text": "And I guess there's parallels to coming out as gay or just parallels in like a career path so you're taking all that, that's ultimately just fear."}, {"time": 7049, "text": "It's fear."}, {"time": 7051, "text": "It's the fear of, you know, the best thing that happened in my career was that I came to LA."}, {"time": 7057, "text": "I didn't have an idea of what was going to happen."}, {"time": 7061, "text": "I met somebody who was really committed to making funny things that we just wanted to be funny."}, {"time": 7070, "text": "No one would let us be funny."}, {"time": 7071, "text": "We didn't have Comedy Central letting us be funny."}, {"time": 7073, "text": "We didn't have HBO, we didn't have Netflix."}, {"time": 7075, "text": "We just had a garage and a phone in the beginning and then a camera and then a thing."}, {"time": 7080, "text": "And we just wanted to be funny."}, {"time": 7081, "text": "And that was the greatest risk really I took because I was like, well, I don't know what else is going to happen right now, but I just want to be funny."}, {"time": 7088, "text": "And funny saved my life, right?"}, {"time": 7090, "text": "I mean, funny got me out of drugs."}, {"time": 7091, "text": "Funny probably got me out of the closet."}, {"time": 7092, "text": "Funny was the thing that I was able to do that made everything okay in my own head."}, {"time": 7096, "text": "So I was like, as long as I'm being funny, something good will happen."}, {"time": 7099, "text": "So we did that and then something really cool happened that we were able to do a lot of cool things, but that's what it is."}, {"time": 7105, "text": "It's fear that keeps you from being the better version of yourself."}, {"time": 7109, "text": "Your mom, I mean, you have so many complicated, fascinating parts of your story."}, {"time": 7115, "text": "Your mom, as you were growing up, suffered."}, {"time": 7119, "text": "Schizophrenic, yeah."}, {"time": 7120, "text": "Well, from mental illness, yeah, schizophrenia."}, {"time": 7123, "text": "Can you tell her story and how that relationship has changed over the years?"}, {"time": 7126, "text": "Yeah, well, she was always eccentric and always, you know, the terms for schizophrenia in an Irish Catholic household where we didn't talk about anything were eccentric, fun."}, {"time": 7137, "text": "There's a theme to this conversation."}, {"time": 7138, "text": "She's unpredictable."}, {"time": 7139, "text": "She's a wire, she was a live wire."}, {"time": 7144, "text": "Any of the words you would use to describe somebody who was a fucking lunatic, but you wouldn't say that."}, {"time": 7151, "text": "Pop that spin."}, {"time": 7152, "text": "Right, she started experiencing symptoms probably early on in her life, but she also, I think, started really manifesting them when I was in my mid teens, so like 14, 13, 14 area."}, {"time": 7169, "text": "And she got really, really bad."}, {"time": 7170, "text": "And then I think she was institutionalized about 10 years ago, a little over 10 years ago."}, {"time": 7175, "text": "And she could really no longer live on her own."}, {"time": 7177, "text": "She was unable to go to work."}, {"time": 7179, "text": "She was unable to function."}, {"time": 7180, "text": "So I visit her when I can."}, {"time": 7182, "text": "Obviously, I'm not in New York."}, {"time": 7182, "text": "Whenever I go to New York, I visit her."}, {"time": 7184, "text": "She's aware of what I do, my career and everything like that."}, {"time": 7187, "text": "She has good days and bad days, but mental illness is a thing that's very tough."}, {"time": 7191, "text": "We don't talk about it as a society."}, {"time": 7193, "text": "People with mental problems don't get that much attention."}, {"time": 7197, "text": "We tend to think that they did something wrong or that they deserve it or that they are to be ignored."}, {"time": 7204, "text": "And we don't devote a lot of resources into it, which is unfortunate because then you have the junk gurus come in and go like, let's diagnose your mental illness off Instagram."}, {"time": 7212, "text": "And it's like, that's not the move."}, {"time": 7215, "text": "Do you love her?"}, {"time": 7219, "text": "I love her, but I also remember her that isn't her now."}, {"time": 7224, "text": "And when someone has mental illness that's severe, you make peace with their death before they die."}, {"time": 7231, "text": "Wow, yeah."}, {"time": 7232, "text": "Because the part of them that you love and remember a lot of cases is not evident or obvious."}, {"time": 7241, "text": "Now, my mother's still a loving person that I love, but the fun, her ability to be present in the moment and to not, that is lost with the progression of realness so that you still love her."}, {"time": 7256, "text": "And I mean, again, your parents, the time horizons you have with your parents are unknown."}, {"time": 7261, "text": "People don't know."}, {"time": 7262, "text": "I have friends that their parents were in their lives for their entire life."}, {"time": 7266, "text": "And I have friends whose parents were in their life, but my mother was a very, she knew what I was."}, {"time": 7270, "text": "When I was a little kid, I was an actor."}, {"time": 7271, "text": "When I was like six to 12, my mother knew that I was a performer."}, {"time": 7274, "text": "She knew what I was and what I'd ultimately do."}, {"time": 7276, "text": "She recognized that in me."}, {"time": 7277, "text": "And when I said to her, I want to audition for shows, I want to be on stage, I want to be on this, I want to do this, she let me do it because she knew who I was and she didn't want to get in the way of me being a human being, a fully realized person at six."}, {"time": 7290, "text": "So that's probably the best thing a parent can do for a kid is let them be who they are."}, {"time": 7295, "text": "And my mother did that."}, {"time": 7297, "text": "So that, I mean, that's good."}, {"time": 7300, "text": "We ate too much fast food."}, {"time": 7302, "text": "There were negatives, but she did let me be who I was."}, {"time": 7304, "text": "That's why you want to throw them out into the street."}, {"time": 7306, "text": "Yeah, sometimes."}, {"time": 7310, "text": "But coming to accept the mortality of her, I guess, identity as you remember it from childhood, do you ponder your own mortality?"}, {"time": 7326, "text": "I'm afraid of death."}, {"time": 7326, "text": "I don't like the idea of death, but I know it's happening."}, {"time": 7330, "text": "I know it's going to happen eventually."}, {"time": 7332, "text": "I don't love it."}, {"time": 7334, "text": "I think about, I want to do some good stuff that people can look back at."}, {"time": 7336, "text": "And I think I'm proud of the show where if people look back at the show, I don't know how comedy ages or whatever, but I think I put out a lot of stuff and I want to continue to put out stuff and I want to put out a few specials that people can look back at and go, oh, this guy was really funny in this really crazy, he lived in the latter part of this century when all this shit was going on."}, {"time": 7353, "text": "And he kind of made fun of it."}, {"time": 7355, "text": "And he did something to make people's lives a little better just by having a few laughs."}, {"time": 7363, "text": "What do you think about, this is something like in the podcast context, do you think you'll have just one or two or three shows out of thousands maybe that are like the truly special ones?"}, {"time": 7376, "text": "That's probably the case."}, {"time": 7377, "text": "Or do you think it's an entirety of the body of work?"}, {"time": 7380, "text": "I think people will take 10 minute clips from all different shows and put them together."}, {"time": 7385, "text": "And there's a highlight."}, {"time": 7386, "text": "Yeah, like a highlight reel of just like, these are like the best things that he's ever done or the best rants he's ever had, the best things, whatever."}, {"time": 7393, "text": "So the legacy would be that this was an important voice in a very weird time."}, {"time": 7398, "text": "I would hope that that's part of it."}, {"time": 7401, "text": "And I hope that I continue to be, you say important, I say funny, but hopefully I continue to be a voice."}, {"time": 7408, "text": "And that's what I think when I think about death, I think about like, what do people come on earth to do?"}, {"time": 7413, "text": "And I think I came, I think my main purpose on this planet other than to experience whatever love or worthiness or whatever is to entertain people."}, {"time": 7424, "text": "And there's a lot of people in comedy right now that are not entertainers, and that's really the problem."}, {"time": 7429, "text": "But, and they got into comedy sort of the way that you can walk into the wrong store in a mall and then not realize you're in the wrong store and try on a bunch of clothes and then go, fuck, I wasted my whole afternoon."}, {"time": 7440, "text": "But I think I've always kind of been an entertainer and that's what I wanna do."}, {"time": 7444, "text": "There's a, unfortunately, sadly, a lot of people that look up to you."}, {"time": 7448, "text": "That is a horrible thing, but life is a nightmare."}, {"time": 7454, "text": "If you were to give them advice, young folks, people in college, maybe even high school, but people in their 20s about what to do with their life, whether it's career, whether it's just life in general, what would you say?"}, {"time": 7467, "text": "Ignore everyone."}, {"time": 7469, "text": "Make a few good friends."}, {"time": 7472, "text": "Truly have honest conversations with yourself about your, when do you feel the most alive?"}, {"time": 7482, "text": "Figure that out."}, {"time": 7484, "text": "When and how do you feel the most alive?"}, {"time": 7490, "text": "Try to figure out a job or a career that can replicate that feeling."}, {"time": 7496, "text": "Don't listen to anyone."}, {"time": 7497, "text": "Don't listen to your parents."}, {"time": 7498, "text": "Don't listen to the gurus on the internet."}, {"time": 7503, "text": "Figure out where you feel the most alive."}, {"time": 7507, "text": "Where do you feel excited?"}, {"time": 7509, "text": "Where does your pulse quicken?"}, {"time": 7511, "text": "What do you feel matters?"}, {"time": 7513, "text": "When you're in a situation, do you feel like it matters?"}, {"time": 7517, "text": "What situation was that?"}, {"time": 7518, "text": "What got you excited?"}, {"time": 7520, "text": "What thing did you walk into where you looked around and were taken back and you're like, wow, this is amazing?"}, {"time": 7527, "text": "And I'm filled with awe."}, {"time": 7528, "text": "If you can figure out a life where you can excite yourself, you might not use drugs or alcohol or a sex addiction or gambling or irresponsibility."}, {"time": 7541, "text": "You might not have to get your fucking kicks in very destructive places if you can get them in a productive place."}, {"time": 7548, "text": "Well, you had a pretty weaving life that's full of mistakes and so on."}, {"time": 7556, "text": "Many mistakes."}, {"time": 7559, "text": "Is that, are mistakes a bug or a feature?"}, {"time": 7562, "text": "Like, do you recommend embrace the mistakes, make a bunch of them?"}, {"time": 7566, "text": "Depends what they are, right?"}, {"time": 7568, "text": "Well, you've had the full spectrum."}, {"time": 7569, "text": "I've had a lot, but a lot of mine could have sunk me."}, {"time": 7573, "text": "Like, they sound like fun when I talk about them, but they actually could have sunk me."}, {"time": 7577, "text": "And they were all part of what made me funny, but I don't know."}, {"time": 7582, "text": "I would never tell anyone else to just light their life on fire and hope it all works out on the other end."}, {"time": 7588, "text": "It would be pretty irresponsible."}, {"time": 7590, "text": "But hey, at the end of the day, it's like, you're gonna, we get, there's, you know, I think one of my themes is that there's too much."}, {"time": 7601, "text": "We give the power."}, {"time": 7602, "text": "We think we have too, the power of choice has been elevated on our society to an unhealthy degree."}, {"time": 7610, "text": "I think people are, I think you could get really good at something, but you're born with a certain aptitude."}, {"time": 7615, "text": "It might be to be a deal maker, might be to be an athlete."}, {"time": 7618, "text": "It might be to be an artist."}, {"time": 7619, "text": "It might be to be a romantic, just fall in and out of love, in and out of love, in and out of love."}, {"time": 7624, "text": "It might be to be like a world traveler."}, {"time": 7625, "text": "Like, but whatever you are, I think you are."}, {"time": 7628, "text": "I think that there's something about you that makes you something."}, {"time": 7631, "text": "And if you can figure it out and then refine, you're not gonna be good at it per se."}, {"time": 7635, "text": "But if you're an athlete, it might not mean that you're going to be a great athlete in the history, but it might mean you're the best coach anyone's ever had, or you're the person that, you know, builds a local scene for young athletes or whatever."}, {"time": 7647, "text": "If you are a really good deal maker, it doesn't mean you're gonna be Warren Buffett, but it might mean you're somebody who enjoys making deals all the time and things like that."}, {"time": 7656, "text": "Like if you're an entertainer, it might mean that you are an entertainer."}, {"time": 7660, "text": "It might mean that you are in the world of entertainment because you love it so much that if you lack the skillset to really pursue it on a degree, you just want to be like, there's a thing inside of you that makes you what you are."}, {"time": 7675, "text": "I think, I look at certain people and I go, you were born to be that thing."}, {"time": 7680, "text": "The whole purpose is to find it."}, {"time": 7681, "text": "I was a juror on that murder trial in Long Island and the woman who's the DA, I'm like, you were born to do this."}, {"time": 7687, "text": "You were born to put murderers away and this guy killed the mother of his children."}, {"time": 7692, "text": "I mean, he's a bad guy, but like, I was like, you are really good at what you do."}, {"time": 7695, "text": "She has a strong belief in whatever her moral code is and what her justice and ethics are."}, {"time": 7700, "text": "And she wants to communicate that to people."}, {"time": 7702, "text": "She was very good at doing what she did."}, {"time": 7705, "text": "I don't know the facts of the case."}, {"time": 7706, "text": "I didn't really listen."}, {"time": 7707, "text": "He seemed guilty, so I just voted guilty."}, {"time": 7709, "text": "But I didn't really listen to her, but I heard the shape of her mouth was very bovine, like a cow, and it conferred a certain level of expertise that I enjoyed."}, {"time": 7719, "text": "Well, it's funny."}, {"time": 7719, "text": "I mean, you could see, you're half joking."}, {"time": 7722, "text": "Yes, but I'm serious."}, {"time": 7723, "text": "You can often see that people just, they found their place."}, {"time": 7727, "text": "They found their role."}, {"time": 7728, "text": "They found their thing."}, {"time": 7729, "text": "They found their thing, and that's kind of the purpose of life."}, {"time": 7732, "text": "And once you are in a place that seems sticky, like the place that seems right, that's one of the problems with the generation that you're speaking to, is there's always a feeling like I should keep exploring, keep exploring."}, {"time": 7745, "text": "But it's okay to stay in a place that you found that works."}, {"time": 7748, "text": "Yeah, and listen, sometimes the best place you'll find is like when people are like, when did you feel really excited and alive?"}, {"time": 7755, "text": "It's like doing nothing."}, {"time": 7759, "text": "You know, like that's the other thing."}, {"time": 7760, "text": "It's like some people are gonna be like, I feel really excited and alive, and I'm laying in my backyard in a hammock."}, {"time": 7765, "text": "And I just wanted the simplest life and not have to do much, and I don't like doing anything."}, {"time": 7770, "text": "And I love laying around and going, wow, the sky looks good today."}, {"time": 7773, "text": "Bill Gates goes, the sky looks good today."}, {"time": 7774, "text": "Let's shoot a missile into it."}, {"time": 7776, "text": "He wants to do shit, right?"}, {"time": 7777, "text": "So it's like in between that and nothing is you can find something."}, {"time": 7782, "text": "But in that process, for you personally, I mean, for me and for others, I think there's a struggle."}, {"time": 7789, "text": "When you look in the, when Tim and Dylan looks in the mirror, do you love yourself or do you hate yourself?"}, {"time": 7794, "text": "Well, a lot of times I think I'm Amy Schumer, so I'm confused."}, {"time": 7799, "text": "I'm a detente to myself all the time."}, {"time": 7801, "text": "I don't love myself or hate myself."}, {"time": 7803, "text": "Addicts have a very bad problem where you can't just fall in love with yourself and you can't hate yourself."}, {"time": 7810, "text": "Both of them lead you to a negative place."}, {"time": 7812, "text": "You try to stay kind of even keel."}, {"time": 7814, "text": "I don't go like, hey man, you put out a video, get all these views, things are great."}, {"time": 7818, "text": "You sold a bunch of tickets."}, {"time": 7819, "text": "Let's fucking go out and like, maybe let's, hey man, let's have that drink that you've been waiting for for 11 years."}, {"time": 7824, "text": "And I don't look at myself and go, you ate a burger yesterday."}, {"time": 7827, "text": "You're a piece of shit."}, {"time": 7828, "text": "You're horrible."}, {"time": 7829, "text": "You'll never get into the shape you want."}, {"time": 7833, "text": "I try not to get too low or too high."}, {"time": 7835, "text": "Both of them are not good for my particular mind."}, {"time": 7838, "text": "Okay, I gotta ask, we kind of spoke about 2021 and you being potentially hopeful, hopeful short term, cynical long term."}, {"time": 7849, "text": "So let me ask, I forgot to ask, are you moving to Austin?"}, {"time": 7855, "text": "I mean, I don't think so immediately."}, {"time": 7857, "text": "I love Joe."}, {"time": 7858, "text": "I love what he's trying to do down there."}, {"time": 7859, "text": "I'm appreciative of everything that he's done for not only me, but for comedy in general."}, {"time": 7864, "text": "And I think as things happen in Austin and unfold is such a political answer, but as things unfold, I will consider it more and more."}, {"time": 7871, "text": "But I mean, I think I got another year in LA."}, {"time": 7874, "text": "So you've spoken so nicely about this magical place that is Los Angeles."}, {"time": 7880, "text": "LA is very funny."}, {"time": 7882, "text": "You think there's a place for comedy in LA?"}, {"time": 7885, "text": "There will always be a place for comedy in LA."}, {"time": 7887, "text": "So it's gonna be a place for comedy in New York."}, {"time": 7889, "text": "I mean, the question is how thriving of a comedy scene is Austin gonna be?"}, {"time": 7893, "text": "And Joe can probably make it one, but as of right now, it isn't."}, {"time": 7898, "text": "So that would be him doing that."}, {"time": 7899, "text": "But the question, there's a lot of people escaping Los Angeles, but I know better about New York."}, {"time": 7904, "text": "There's a lot of really brilliant people."}, {"time": 7906, "text": "Let them go."}, {"time": 7907, "text": "There's other people."}, {"time": 7909, "text": "It's like, this is the fear thing."}, {"time": 7910, "text": "It's like, no, but all the brilliant people are leaving."}, {"time": 7913, "text": "There'll be other people and they'll fill their shoes the way that they've done throughout history."}, {"time": 7917, "text": "And I think that New York and LA, listen, maybe in five to 10 years, they're not the two cities."}, {"time": 7922, "text": "It would be real rough in five years when this pandemic's over for people in Australia to go, dude, you gotta go to America and you gotta visit Charleston and Austin."}, {"time": 7934, "text": "Let's be adults here."}, {"time": 7935, "text": "Let's be adults."}, {"time": 7936, "text": "It's still gonna be New York and LA for a while."}, {"time": 7938, "text": "LA is an absolute hellscape, but I don't think you're gonna replace California with another place."}, {"time": 7948, "text": "And also, everyone's making decisions now because we're literally in the midst of a pandemic we've never had before."}, {"time": 7954, "text": "We've never had this before."}, {"time": 7955, "text": "Joe loved California up until the pandemic."}, {"time": 7957, "text": "He had problems with it."}, {"time": 7959, "text": "Like, we all have problems with it."}, {"time": 7960, "text": "There's a lot of benefits to being here."}, {"time": 7962, "text": "I think a lot of us made pretty bad decisions in 2020 because we were all locked up and stuck with our own thoughts."}, {"time": 7968, "text": "But, so it's funny, there's parallels because I don't necessarily, you know, I'm obviously a fan of comedy, but I don't care where comics move."}, {"time": 7979, "text": "But there's a parallel move that's happening, set of decisions which do influence my decision making, which is where to start a business that's tech centered."}, {"time": 7987, "text": "And that's more about the San Francisco, Silicon Valley."}, {"time": 7992, "text": "And there is a lot of people leaving there."}, {"time": 7995, "text": "That's already."}, {"time": 7996, "text": "And they're going to Austin."}, {"time": 7996, "text": "Well, Austin, there's a, I think, there's a bunch of different places."}, {"time": 8001, "text": "Phoenix, there's Denver."}, {"time": 8003, "text": "Austin will probably be a massive tech hub."}, {"time": 8006, "text": "Elon's there."}, {"time": 8007, "text": "It seems like it's all, everything about Austin says that it's going to be a massive tech hub."}, {"time": 8013, "text": "I just don't know if that means it'll be a massive comedy hub."}, {"time": 8016, "text": "I don't know if those two can actually coexist."}, {"time": 8018, "text": "It's interesting because."}, {"time": 8019, "text": "Yeah, I don't, I think, you know, comedy suffered in New York and LA when everyone got super rich."}, {"time": 8025, "text": "Like, you know, it just wasn't as cool."}, {"time": 8027, "text": "It's still much more fun on the road."}, {"time": 8028, "text": "It's still more fun to perform for people that want and need to laugh in strip malls than it is to perform for hedge fund managers and with their dates and, you know, Instagram models in LA."}, {"time": 8040, "text": "Comedy on the road is much more fun."}, {"time": 8041, "text": "So maybe in the spirit of that, Austin becomes, but you know, you know, if Austin is just colonized by tech bros and stuff like, yeah, I mean, sure, sure it'll be fun and it'll be great."}, {"time": 8050, "text": "I think Joe's made LA a scene."}, {"time": 8053, "text": "So if anyone's going to make Austin a scene, it's Joe."}, {"time": 8057, "text": "Yeah, and I like the, on the Elon side, which is what I'm much more familiar with, the promise of the possibility of what that could become because there's a lot of problems in Silicon Valley."}, {"time": 8067, "text": "And of course it might be naive to think that just because it's like the grass is greener thing, which is just because the place where you come from has a lot of problems, doesn't mean you can just create a new place that's not going to have those problems."}, {"time": 8079, "text": "Yeah, there's homelessness in Austin."}, {"time": 8081, "text": "There are problems in Austin."}, {"time": 8082, "text": "I mean, I think that with, by the way, with the influx of very rich people to an area, sometimes that helps things, but sometimes it just makes things more polarizing and it puts a spotlight on those problems and makes those problems even bigger, right?"}, {"time": 8095, "text": "So, I mean, I don't know that it's necessarily, it's hard to predict."}, {"time": 8099, "text": "I just know that LA right now is funny."}, {"time": 8101, "text": "It's funny that there's 15 year old TikTokers making millions of dollars dancing in a house while the world burns."}, {"time": 8106, "text": "That is very funny."}, {"time": 8107, "text": "Well, it's for your style of humor, yes."}, {"time": 8111, "text": "The absurdity of the world is that it's... No one cares about Hollywood starlets and actresses and actors and everyone goes, hey, fuck you."}, {"time": 8117, "text": "Even though they've won three Academy Awards, they're all being replaced by just mediocre dancer 15 year olds."}, {"time": 8123, "text": "I mean, it's like there's something hilarious about this city and it will burn in hell, but so will everything."}, {"time": 8131, "text": "Eventually the sun will die out and we will all be gone unless we colonize outside of our solar system."}, {"time": 8138, "text": "But I just sit here, I'm struggling with this because Boston, I'm currently at MIT, Boston doesn't feel like the right place to start a business in the tech sector."}, {"time": 8152, "text": "And so I'm choosing, I'm looking at San Francisco the way it is and I'm looking at Austin."}, {"time": 8156, "text": "Oh, Austin, clearly."}, {"time": 8158, "text": "So it seems clear, but it's such a difficult thing to predict what a place will look like in 10 years and 15 years and 20 years."}, {"time": 8168, "text": "And it's so hard to predict if you'll like it or not until you're there."}, {"time": 8172, "text": "And this is speaking to risk, there's not really a good reason for me to move anywhere."}, {"time": 8178, "text": "There's not a good reason to do anything in life."}, {"time": 8181, "text": "Part of me wants to just fucking do it and whatever and see what happens."}, {"time": 8186, "text": "Do you like Boston, do you like other things about Boston besides the tech thing?"}, {"time": 8190, "text": "You like MIT."}, {"time": 8191, "text": "MIT, that's the problem."}, {"time": 8193, "text": "Do you like the food in Boston?"}, {"time": 8195, "text": "Do you eat food?"}, {"time": 8196, "text": "I haven't eaten food or been outside for years."}, {"time": 8199, "text": "And I mean, that's probably the better version."}, {"time": 8202, "text": "But you're keto forever."}, {"time": 8204, "text": "You've been keto for a long time."}, {"time": 8205, "text": "Yeah, keto, fasting for a long time."}, {"time": 8209, "text": "15 years fasting, eating once or twice a day."}, {"time": 8214, "text": "But no sugar ever, no like and no pasta ever, no bread ever."}, {"time": 8220, "text": "No pasta, no bread, no, except like, so my source of... You could kind of live anywhere because like going out is such a big part of what city you live in."}, {"time": 8230, "text": "And like, do you like the food there?"}, {"time": 8231, "text": "Do you like the restaurants?"}, {"time": 8232, "text": "Can you meet people?"}, {"time": 8233, "text": "Whatever, but it's like, you really can just kind of... Yeah, so not married, no kids."}, {"time": 8237, "text": "Right, you have freedom."}, {"time": 8238, "text": "Me too, I have freedom."}, {"time": 8240, "text": "And that's, we have the curse of being vegan."}, {"time": 8243, "text": "We have too many choices."}, {"time": 8248, "text": "We don't have somebody else going, what about like, we don't have to justify our decisions to anyone."}, {"time": 8251, "text": "So we can just kind of like let our minds go run wild."}, {"time": 8254, "text": "So you just got to hone the instinct of just what feels right and just fucking do it."}, {"time": 8261, "text": "I think Austin with Joe down there and Elon down there, Austin seems like a real no brainer move for you."}, {"time": 8266, "text": "To try, you know, why the hell not?"}, {"time": 8269, "text": "And then I think I should go to MIT."}, {"time": 8271, "text": "Like, I mean, I think I should give those nerds a piece of my mind that you should go to."}, {"time": 8279, "text": "I was in an Uber pool once with a kid from MIT and I was eating this thing from Bova's Bakery."}, {"time": 8285, "text": "I forget what it was."}, {"time": 8286, "text": "It was like a, it's so good."}, {"time": 8289, "text": "You don't know Bova's Bakery, right?"}, {"time": 8290, "text": "Yeah, it's in Boston, it's famous."}, {"time": 8292, "text": "I was eating a thing and I was like covered in chocolate."}, {"time": 8294, "text": "This kid, like this little nerd, like this little like, you know, USB drive with feet was just staring at me and they just dropped him off at MIT."}, {"time": 8301, "text": "And he like scurried away."}, {"time": 8302, "text": "But that's a big school that, doesn't the NSA recruit out of their heavy, like MIT, places like that?"}, {"time": 8307, "text": "I can't, I can't speak to that."}, {"time": 8310, "text": "But what, this is a ridiculous question I sometimes ask myself when I'm alone."}, {"time": 8318, "text": "Do you think about the big existential kind of, why the hell we're here?"}, {"time": 8323, "text": "It's a cosmic kind of joke kind of in a weird way, right?"}, {"time": 8326, "text": "I mean, Joe said it the other day on, maybe it was you saying that like, he was just like, you know, by the time you figure out what it is, you're out of here."}, {"time": 8335, "text": "You know, it's kind of interesting."}, {"time": 8336, "text": "Or you even start to figure out what it is, you're out of here."}, {"time": 8339, "text": "It's like, that's kind of funny."}]}, {"title": "Bret Weinstein: Truth, Science, and Censorship in the Time of a Pandemic | Lex Fridman Podcast #194", "id": "TG6BuSjwP4o", "quotes": [{"time": 409, "text": "So like, I don't know what to attribute the parkour to, like biomechanics of how our bodies can move, or is it the mind?"}, {"time": 418, "text": "Like how much percent wise, is it the entirety of the hierarchies of biology that we've been talking about, or is it just all the mind?"}, {"time": 429, "text": "The way to think about creatures is that every creature is two things simultaneously."}, {"time": 434, "text": "A creature is a machine of sorts, right?"}, {"time": 437, "text": "It's not a machine in the, I call it an aqueous machine, right?"}, {"time": 442, "text": "And it's run by an aqueous computer, right?"}, {"time": 444, "text": "So it's not identical to our technological machines."}, {"time": 449, "text": "But every creature is both a machine that does things in the world sufficient to accumulate enough resources to continue surviving, to reproduce."}, {"time": 459, "text": "It is also a potential."}, {"time": 461, "text": "So each creature is potentially, for example, the most recent common ancestor of some future clade of creatures that will look very different from it."}, {"time": 470, "text": "And if a creature is very, very good at being a creature, but not very good in terms of the potential it has going forward, then that lineage will not last very long into the future because change will throw at challenges that its descendants will not be able to meet."}, {"time": 487, "text": "So the thing about humans is we are a generalist platform, and we have the ability to swap out our software to exist in many, many different niches."}, {"time": 500, "text": "And I was once watching an interview with this British group of parkour experts who were being, they were discussing what it is they do and how it works."}, {"time": 511, "text": "And what they essentially said is, look, you're tapping into deep monkey stuff, right?"}, {"time": 519, "text": "And I thought, yeah, that's about right."}, {"time": 521, "text": "And anybody who is proficient at something like skiing or skateboarding, you know, has the experience of flying down the hill on skis, for example, bouncing from the top of one mogul to the next."}, {"time": 539, "text": "And if you really pay attention, you will discover that your conscious mind is actually a spectator."}, {"time": 545, "text": "It's there, it's involved in the experience, but it's not driving."}, {"time": 549, "text": "Some part of you knows how to ski, and it's not the part of you that knows how to think."}, {"time": 552, "text": "And I would just say that what accounts for this flexibility in humans is the ability to bootstrap a new software program and then drive it into the unconscious layer where it can be applied very rapidly."}, {"time": 570, "text": "And, you know, I will be shocked if the exact thing doesn't exist in robotics."}, {"time": 576, "text": "You know, if you programmed a robot to deal with circumstances that were novel to it, how would you do it?"}, {"time": 581, "text": "It would have to look something like this."}, {"time": 583, "text": "There's a certain kind of magic, you're right, with the consciousness being an observer."}, {"time": 588, "text": "When you play guitar, for example, or piano for me, music, when you get truly lost in it, I don't know what the heck is responsible for the flow of the music, the kind of the loudness of the music going up and down, the timing, the intricate, like even the mistakes, all those things, that doesn't seem to be the conscious mind."}, {"time": 609, "text": "It is just observing, and yet it's somehow intricately involved."}, {"time": 614, "text": "More, like, because you mentioned parkour, the dance is like that too."}, {"time": 618, "text": "When you start up in tango dancing, if when you truly lose yourself in it, then it's just like you're an observer, and how the hell is the body able to do that?"}, {"time": 629, "text": "And not only that, it's the physical motion is also creating the emotion, the, like, the damn is good to be alive feeling."}, {"time": 640, "text": "So, but then that's also intricately connected to the full biology stack that we're operating in."}, {"time": 647, "text": "I don't know how difficult it is to replicate that."}, {"time": 650, "text": "We're talking offline about Boston Dynamics robots."}, {"time": 654, "text": "They've recently been, they did both parkour, they did flips, they've also done some dancing, and it's something I think a lot about because what most people don't realize because they don't look deep enough is those robots are hard coded to do those things."}, {"time": 673, "text": "The robots didn't figure it out by themselves, and yet the fundamental aspect of what it means to be human is that process of figuring out, of making mistakes, and then there's something about overcoming those challenges and the mistakes and, like, figuring out how to lose yourself in the magic of the dancing or just movement is what it means to be human."}, {"time": 695, "text": "That learning process, so that's what I want to do with the, almost as a fun side thing with the Boston Dynamics robots, is to have them learn and see what they figure out, even if they make mistakes."}, {"time": 710, "text": "I want to let Spot make mistakes and in so doing discover what it means to be alive, discover beauty, because I think that's the essential aspect of mistakes."}, {"time": 725, "text": "Boston Dynamics folks want Spot to be perfect because they don't want Spot to ever make mistakes because it wants to operate in the factories, it wants to be very safe and so on."}, {"time": 736, "text": "For me, if you construct the environment, if you construct a safe space for robots and allow them to make mistakes, something beautiful might be discovered, but that requires a lot of brain power."}, {"time": 749, "text": "So Spot is currently very dumb and I'm gonna give it a brain."}, {"time": 754, "text": "So first make it see, currently it can't see, meaning computer vision, it has to understand its environment, it has to see all the humans, but then also has to be able to learn, learn about its movement, learn how to use its body to communicate with others, all those kinds of things that dogs know how to do well, humans know how to do somewhat well."}, {"time": 774, "text": "I think that's a beautiful challenge, but first you have to allow the robot to make mistakes."}, {"time": 780, "text": "Well, I think your objective is laudable, but you're gonna realize that the Boston Dynamics folks are right the first time Spot poops on your rug."}, {"time": 791, "text": "I hear the same thing about kids and so on."}, {"time": 793, "text": "I still wanna have kids."}, {"time": 794, "text": "No, you should, it's a great experience."}, {"time": 798, "text": "So let me step back into what you said in a couple of different places."}, {"time": 801, "text": "One, I have always believed that the missing element in robotics and artificial intelligence is a proper development, right?"}, {"time": 810, "text": "It is no accident, it is no mere coincidence that human beings are the most dominant species on planet Earth and that we have the longest childhoods of any creature on Earth by far, right?"}, {"time": 822, "text": "The development is the key to the flexibility."}, {"time": 824, "text": "And so the capability of a human at adulthood is the mirror image, it's the flip side of our helplessness at birth."}, {"time": 837, "text": "So I'll be very interested to see what happens in your robot project if you do not end up reinventing childhood for robots, which of course is foreshadowed in 2001 quite brilliantly."}, {"time": 850, "text": "But I also wanna point out, you can see this issue of your conscious mind becoming a spectator very well if you compare tennis to table tennis, right?"}, {"time": 864, "text": "If you watch a tennis game, you could imagine that the players are highly conscious as they play."}, {"time": 872, "text": "You cannot imagine that if you've ever played ping pong decently."}, {"time": 876, "text": "A volley in ping pong is so fast that your conscious mind, if your reactions had to go through your conscious mind, you wouldn't be able to play."}, {"time": 884, "text": "So you can detect that your conscious mind, while very much present, isn't there."}, {"time": 889, "text": "And you can also detect where consciousness does usefully intrude."}, {"time": 894, "text": "If you go up against an opponent in table tennis that knows a trick that you don't know how to respond to, you will suddenly detect that something about your game is not effective, and you will start thinking about what might be, how do you position yourself so that move that puts the ball just in that corner of the table or something like that doesn't catch you off guard."}, {"time": 915, "text": "And this, I believe, is we highly conscious folks, those of us who try to think through things very deliberately and carefully, mistake consciousness for the highest kind of thinking."}, {"time": 930, "text": "And I really think that this is an error."}, {"time": 933, "text": "Consciousness is an intermediate level of thinking."}, {"time": 936, "text": "What it does is it allows you, it's basically like uncompiled code."}, {"time": 940, "text": "And it doesn't run very fast."}, {"time": 942, "text": "It is capable of being adapted to new circumstances."}, {"time": 945, "text": "But once the code is roughed in, it gets driven into the unconscious layer, and you become highly effective at whatever it is."}, {"time": 952, "text": "And from that point, your conscious mind basically remains there to detect things that aren't anticipated by the code you've already written."}, {"time": 960, "text": "And so I don't exactly know how one would establish this, how one would demonstrate it."}, {"time": 967, "text": "But it must be the case that the human mind contains sandboxes in which things are tested, right?"}, {"time": 975, "text": "Maybe you can build a piece of code and run it in parallel next to your active code so you can see how it would have done comparatively."}, {"time": 983, "text": "But there's gotta be some way of writing new code and then swapping it in."}, {"time": 988, "text": "And frankly, I think this has a lot to do with things like sleep cycles."}, {"time": 991, "text": "Very often, when I get good at something, I often don't get better at it while I'm doing it."}, {"time": 996, "text": "I get better at it when I'm not doing it, especially if there's time to sleep and think on it."}, {"time": 1001, "text": "So there's some sort of new program swapping in for old program phenomenon, which will be a lot easier to see in machines."}, {"time": 1010, "text": "It's gonna be hard with the wetware."}, {"time": 1013, "text": "I like, I mean, it is true, because somebody that played, I played tennis for many years, I do still think the highest form of excellence in tennis is when the conscious mind is a spectator."}, {"time": 1025, "text": "So the compiled code is the highest form of being human."}, {"time": 1031, "text": "And then consciousness is just some specific compiler."}, {"time": 1036, "text": "You used to have like Borland C++ compiler."}, {"time": 1039, "text": "You could just have different kind of compilers."}, {"time": 1042, "text": "Ultimately, the thing that by which we measure the power of life, the intelligence of life is the compiled code."}, {"time": 1051, "text": "And you can probably do that compilation all kinds of ways."}, {"time": 1054, "text": "Yeah, I'm not saying that tennis is played consciously and table tennis isn't."}, {"time": 1058, "text": "I'm saying that because tennis is slowed down by the just the space on the court, you could imagine that it was your conscious mind playing."}, {"time": 1067, "text": "But when you shrink the court down, It becomes obvious."}, {"time": 1069, "text": "It becomes obvious that your conscious mind is just present rather than knowing where to put the paddle."}, {"time": 1074, "text": "And weirdly for me, I would say this probably isn't true in a podcast situation."}, {"time": 1081, "text": "But if I have to give a presentation, especially if I have not overly prepared, I often find the same phenomenon when I'm giving the presentation."}, {"time": 1090, "text": "My conscious mind is there watching some other part of me present, which is a little jarring, I have to say."}, {"time": 1097, "text": "Well, that means you've gotten good at it."}, {"time": 1100, "text": "Not let the conscious mind get in the way of the flow of words."}, {"time": 1104, "text": "Yeah, that's the sensation to be sure."}, {"time": 1107, "text": "And that's the highest form of podcasting too."}, {"time": 1109, "text": "I mean, that's what it looks like when a podcast is really in the pocket, like Joe Rogan, just having fun and just losing themselves."}, {"time": 1119, "text": "And that's something I aspire to as well, just losing yourself in conversation."}, {"time": 1123, "text": "Somebody that has a lot of anxiety with people, like I'm such an introvert."}, {"time": 1128, "text": "I was scared before you showed up."}, {"time": 1129, "text": "I'm scared right now."}, {"time": 1130, "text": "There's just anxiety."}, {"time": 1132, "text": "There's just, it's a giant mess."}, {"time": 1135, "text": "It's hard to lose yourself."}, {"time": 1136, "text": "It's hard to just get out of the way of your own mind."}, {"time": 1140, "text": "Yeah, actually, trust is a big component of that."}, {"time": 1144, "text": "Your conscious mind retains control if you are very uncertain."}, {"time": 1151, "text": "But when you do get into that zone when you're speaking, I realize it's different for you with English as a second language, although maybe you present in Russian and it happens."}, {"time": 1160, "text": "But do you ever hear yourself say something and you think, oh, that's really good, right?"}, {"time": 1165, "text": "Like you didn't come up with it, some other part of you that you don't exactly know came up with it?"}, {"time": 1171, "text": "I don't think I've ever heard myself in that way because I have a much louder voice that's constantly yelling in my head at, why the hell did you say that?"}, {"time": 1183, "text": "There's a very self critical voice that's much louder."}, {"time": 1187, "text": "So I'm very, maybe I need to deal with that voice, but it's been like, what is it called?"}, {"time": 1193, "text": "Like a megaphone just screaming so I can't hear the other voice that says, good job, you said that thing really nicely."}, {"time": 1198, "text": "So I'm kind of focused right now on the megaphone person in the audience versus the positive, but that's definitely something to think about."}, {"time": 1207, "text": "It's been productive, but the place where I find gratitude and beauty and appreciation of life is in the quiet moments when I don't talk, when I listen to the world around me, when I listen to others, when I talk, I'm extremely self critical in my mind."}, {"time": 1226, "text": "When I produce anything out into the world that originated with me, like any kind of creation, extremely self critical."}, {"time": 1235, "text": "It's good for productivity, for always striving to improve and so on."}, {"time": 1240, "text": "It might be bad for just appreciating the things you've created."}, {"time": 1246, "text": "I'm a little bit with Marvin Minsky on this where he says the key to a productive life is to hate everything you've ever done in the past."}, {"time": 1257, "text": "I didn't know he said that."}, {"time": 1259, "text": "I must say, I resonate with it a bit."}, {"time": 1261, "text": "And unfortunately, my life currently has me putting a lot of stuff into the world, and I effectively watch almost none of it."}, {"time": 1272, "text": "I can't stand it."}, {"time": 1278, "text": "I just yesterday read Metamorphosis by Kafka, we read Metamorphosis by Kafka where he turns into a giant bug because of the stress that the world puts on him."}, {"time": 1289, "text": "His parents put on him to succeed."}, {"time": 1291, "text": "And I think that you have to find the balance because if you allow the self critical voice to become too heavy, the burden of the world, the pressure that the world puts on you to be the best version of yourself and so on to strive, then you become a bug and that's a big problem."}, {"time": 1311, "text": "And then the world turns against you because you're a bug."}, {"time": 1316, "text": "You become some kind of caricature of yourself."}, {"time": 1319, "text": "I don't know, you become the worst version of yourself and then thereby end up destroying yourself and then the world moves on."}, {"time": 1329, "text": "That's the story."}, {"time": 1330, "text": "That's a lovely story."}, {"time": 1332, "text": "I do think this is one of these places, and frankly, you could map this onto all of modern human experience, but this is one of these places where our ancestral programming does not serve our modern selves."}, {"time": 1345, "text": "So I used to talk to students about the question of dwelling on things."}, {"time": 1350, "text": "Dwelling on things is famously understood to be bad and it can't possibly be bad."}, {"time": 1356, "text": "It wouldn't exist, the tendency toward it wouldn't exist if it was bad."}, {"time": 1360, "text": "So what is bad is dwelling on things past the point of utility."}, {"time": 1392, "text": "This is the point at which it is no longer useful for me to dwell on this error I have made."}, {"time": 1396, "text": "That's what you're looking for."}, {"time": 1397, "text": "And it also gives you license, right?"}, {"time": 1400, "text": "If some part of you feels like it's punishing you rather than searching, then that also has a point at which it's no longer valuable and there's some liberty in realizing, yep, even the part of me that was punishing me knows it's time to stop."}, {"time": 1417, "text": "So if we map that onto compiled code discussion, as a computer science person, I find that very compelling."}, {"time": 1423, "text": "You know, when you compile code, you get warnings sometimes."}, {"time": 1428, "text": "And usually, if you're a good software engineer, you're going to make sure there's no, you know, you treat warnings as errors."}, {"time": 1438, "text": "So you make sure that the compilation produces no warnings."}, {"time": 1442, "text": "But at a certain point, when you have a large enough system, you just let the warnings go."}, {"time": 1447, "text": "Like, I don't know where that warning came from, but, you know, just ultimately you need to compile the code and run with it and hope nothing terrible happens."}, {"time": 1459, "text": "Well, I think what you will find, and believe me, I think what you're talking about with respect to robots and learning is gonna end up having to go to a deep developmental state and a helplessness that evolves into hyper competence and all of that."}, {"time": 1476, "text": "But I live, I noticed that I live by something that I, for lack of a better descriptor, call the theory of close calls."}, {"time": 1487, "text": "And the theory of close calls says that people typically miscategorize the events in their life where something almost went wrong."}, {"time": 1498, "text": "And, you know, for example, if you, I have a friend who, I was walking down the street with my college friends and one of my friends stepped into the street thinking it was clear and was nearly hit by a car going 45 miles an hour, would have been an absolute disaster, might have killed her, certainly would have permanently injured her."}, {"time": 1518, "text": "But she didn't, you know, car didn't touch her, right?"}, {"time": 1521, "text": "Now you could walk away from that and think nothing of it because, well, what is there to think?"}, {"time": 1526, "text": "Nothing happened."}, {"time": 1528, "text": "Or you could think, well, what is the difference between what did happen and my death?"}, {"time": 1533, "text": "The difference is luck."}, {"time": 1535, "text": "I never want that to be true, right?"}, {"time": 1537, "text": "I never want the difference between what did happen and my death to be luck."}, {"time": 1541, "text": "Therefore, I should count this as very close to death and I should prioritize coding so it doesn't happen again at a very high level."}, {"time": 1550, "text": "So anyway, my basic point is the accidents and disasters and misfortune describe a distribution that tells you what's really likely to get you in the end."}, {"time": 1564, "text": "And so personally, you can use them to figure out where the dangers are so that you can afford to take great risks because you have a really good sense of how they're gonna go wrong."}, {"time": 1575, "text": "But I would also point out civilization has this problem."}, {"time": 1579, "text": "Civilization is now producing these events that are major disasters, but they're not existential scale yet, right?"}, {"time": 1587, "text": "They're very serious errors that we can see."}, {"time": 1590, "text": "And I would argue that the pattern is you discover that we are involved in some industrial process at the point it has gone wrong, right?"}, {"time": 1597, "text": "So I'm now always asking the question, okay, in light of the Fukushima triple meltdown, the financial collapse of 2008, the Deepwater Horizon blowout, COVID 19, and its probable origins in the Wuhan lab, what processes do I not know the name of yet that I will discover at the point that some gigantic accident has happened?"}, {"time": 1623, "text": "And can we talk about the wisdom or lack thereof of engaging in that process before the accident, right?"}, {"time": 1629, "text": "That's what a wise civilization would be doing."}, {"time": 1631, "text": "And yet we don't."}, {"time": 1632, "text": "I just wanna mention something that happened a couple of days ago."}, {"time": 1637, "text": "I don't know if you know who JB Straubel is."}, {"time": 1640, "text": "He's the co founder of Tesla, CTO of Tesla for many, many years."}, {"time": 1644, "text": "His wife just died."}, {"time": 1646, "text": "She was riding a bicycle."}, {"time": 1648, "text": "And in the same thin line between death and life that many of us have been in, where you walk into the intersection and there's this close call."}, {"time": 1661, "text": "Every once in a while, you get the short straw."}, {"time": 1670, "text": "I wonder how much of our own individual lives and the entirety of the human civilization rests on this little roll of the dice."}, {"time": 1680, "text": "Well, this is sort of my point about the close calls is that there's a level at which we can't control it, right?"}, {"time": 1686, "text": "The gigantic asteroid that comes from deep space that you don't have time to do anything about."}, {"time": 1693, "text": "There's not a lot we can do to hedge that out, or at least not short term."}, {"time": 1697, "text": "But there are lots of other things."}, {"time": 1700, "text": "Obviously, the financial collapse of 2008 didn't break down the entire world economy."}, {"time": 1707, "text": "It threatened to, but a Herculean effort managed to pull us back from the brink."}, {"time": 1711, "text": "The triple meltdown at Fukushima was awful, but every one of the seven fuel pools held, there wasn't a major fire that made it impossible to manage the disaster going forward."}, {"time": 1721, "text": "We got lucky."}, {"time": 1724, "text": "We could say the same thing about the blowout at the Deepwater Horizon, where a hole in the ocean floor large enough that we couldn't have plugged it, could have opened up."}, {"time": 1734, "text": "All of these things could have been much, much worse, right?"}, {"time": 1737, "text": "And I think we can say the same thing about COVID, as terrible as it is."}, {"time": 1740, "text": "And we cannot say for sure that it came from the Wuhan lab, but there's a strong likelihood that it did."}, {"time": 1746, "text": "And it also could be much, much worse."}, {"time": 1750, "text": "So in each of these cases, something is telling us, we have a process that is unfolding that keeps creating risks where it is luck that is the difference between us and some scale of disaster that is unimaginable."}, {"time": 1762, "text": "And that wisdom, you can be highly intelligent and cause these disasters."}, {"time": 1768, "text": "To be wise is to stop causing them, right?"}, {"time": 1771, "text": "And that would require a process of restraint, a process that I don't see a lot of evidence of yet."}, {"time": 1778, "text": "So I think we have to generate it."}, {"time": 1781, "text": "And somehow, at the moment, we don't have a political structure that would be capable of taking a protective algorithm and actually deploying it, right?"}, {"time": 1795, "text": "Because it would have important economic consequences."}, {"time": 1797, "text": "And so it would almost certainly be shot down."}, {"time": 1800, "text": "But we can obviously also say, we paid a huge price for all of the disasters that I've mentioned."}, {"time": 1809, "text": "And we have to factor that into the equation."}, {"time": 1812, "text": "Something can be very productive short term and very destructive long term."}, {"time": 1817, "text": "Also, the question is how many disasters we avoided because of the ingenuity of humans or just the integrity and character of humans."}, {"time": 1828, "text": "That's sort of an open question."}, {"time": 1830, "text": "We may be more intelligent than lucky."}, {"time": 1836, "text": "Because the optimistic message here that you're getting at is maybe the process that we should be, that maybe we can overcome luck with ingenuity."}, {"time": 1848, "text": "Meaning, I guess you're suggesting the processes we should be listing all the ways that human civilization can destroy itself, assigning likelihood to it, and thinking through how can we avoid that."}, {"time": 1863, "text": "And being very honest with the data out there about the close calls and using those close calls to then create sort of mechanism by which we minimize the probability of those close calls."}, {"time": 1877, "text": "And just being honest and transparent with the data that's out there."}, {"time": 1883, "text": "Well, I think we need to do a couple things for it to work."}, {"time": 1887, "text": "So I've been an advocate for the idea that sustainability is actually, it's difficult to operationalize, but it is an objective that we have to meet if we're to be around long term."}, {"time": 1898, "text": "And I realized that we also need to have reversibility of all of our processes."}, {"time": 1903, "text": "Because processes very frequently when they start do not appear dangerous."}, {"time": 1907, "text": "And then when they scale, they become very dangerous."}, {"time": 1911, "text": "So for example, if you imagine the first internal combustion engine vehicle driving down the street, and you imagine somebody running after them saying, hey, if you do enough of that, you're gonna alter the atmosphere and it's gonna change the temperature of the planet."}, {"time": 1925, "text": "It's preposterous, right?"}, {"time": 1927, "text": "Why would you stop the person who's invented this marvelous new contraption?"}, {"time": 1930, "text": "But of course, eventually you do get to the place where you're doing enough of this that you do start changing the temperature of the planet."}, {"time": 1937, "text": "So if we built the capacity, if we basically said, look, you can't involve yourself in any process that you couldn't reverse if you had to, then progress would be slowed, but our safety would go up dramatically."}, {"time": 1953, "text": "And I think in some sense, if we are to be around long term, we have to begin thinking that way."}, {"time": 1960, "text": "We're just involved in too many very dangerous processes."}, {"time": 1963, "text": "So let's talk about one of the things that if not threatened human civilization certainly hurt it at a deep level, which is COVID 19."}, {"time": 1976, "text": "What percent probability would you currently place on the hypothesis that COVID 19 leaked from the Wuhan Institute of Virology?"}, {"time": 1986, "text": "So I maintain a flow chart of all the possible explanations, and it doesn't break down exactly that way."}, {"time": 1995, "text": "The likelihood that it emerged from a lab is very, very high."}, {"time": 2000, "text": "If it emerged from a lab, the likelihood that the lab was the Wuhan Institute is very, very high."}, {"time": 2007, "text": "There are multiple different kinds of evidence that point to the lab, and there is literally no evidence that points to nature."}, {"time": 2015, "text": "Either the evidence points nowhere or it points to the lab, and the lab could mean any lab, but geographically, obviously, the labs in Wuhan are the most likely, and the lab that was most directly involved with research on viruses that look like COVID, that look like SARS COVID 2, is obviously the place that one would start."}, {"time": 2035, "text": "But I would say the likelihood that this virus came from a lab is well above 95%."}, {"time": 2044, "text": "We can talk about the question of could a virus have been brought into the lab and escaped from there without being modified."}, {"time": 2049, "text": "That's also possible, but it doesn't explain any of the anomalies in the genome of SARS COVID 2."}, {"time": 2057, "text": "Could it have been delivered from another lab?"}, {"time": 2060, "text": "Could Wuhan be a distraction in order that we would connect the dots in the wrong way?"}, {"time": 2066, "text": "That's conceivable."}, {"time": 2067, "text": "I currently have that below 1% on my flowchart, but I think... A very dark thought that somebody would do that almost as a political attack on China."}, {"time": 2079, "text": "I don't even think that's one possibility."}, {"time": 2082, "text": "Sometimes when Eric and I talk about these issues, we will generate a scenario just to prove that something could live in that space, right?"}, {"time": 2091, "text": "It's a placeholder for whatever may actually have happened."}, {"time": 2093, "text": "And so it doesn't have to have been an attack on China."}, {"time": 2097, "text": "That's certainly one possibility."}, {"time": 2099, "text": "But I would point out, if you can predict the future in some unusual way better than others, you can print money, right?"}, {"time": 2110, "text": "That's what markets that allow you to bet for or against virtually any sector allow you to do."}, {"time": 2116, "text": "So you can imagine a simply amoral person or entity generating a pandemic, attempting to cover their tracks because it would allow them to bet against things like cruise ships, air travel, whatever it is, and bet in favor of, I don't know, sanitizing gel and whatever else you would do."}, {"time": 2143, "text": "So am I saying that I think somebody did that?"}, {"time": 2146, "text": "No, I really don't think it happened."}, {"time": 2147, "text": "We've seen zero evidence that this was intentionally released."}, {"time": 2151, "text": "However, were it to have been intentionally released by somebody who did not know, did not want it known where it had come from, releasing it into Wuhan would be one way to cover their tracks."}, {"time": 2161, "text": "So we have to leave the possibility formally open, but acknowledge there's no evidence."}, {"time": 2167, "text": "And the probability therefore is low."}, {"time": 2169, "text": "I tend to believe maybe this is the optimistic nature that I have that people who are competent enough to do the kind of thing we just described are not going to do that because it requires a certain kind of, I don't wanna use the word evil, but whatever word you wanna use to describe the kind of disregard for human life required to do that, that's just not going to be coupled with competence."}, {"time": 2200, "text": "I feel like there's a trade off chart where competence on one axis and evil is on the other."}, {"time": 2205, "text": "And the more evil you become, the crappier you are at doing great engineering, scientific work required to deliver weapons of different kinds, whether it's bioweapons or nuclear weapons, all those kinds of things."}, {"time": 2219, "text": "That seems to be the lessons I take from history, but that doesn't necessarily mean that's what's going to be happening in the future."}, {"time": 2228, "text": "But to stick on the lab leak idea, because the flow chart is probably huge here because there's a lot of fascinating possibilities."}, {"time": 2236, "text": "One question I wanna ask is, what would evidence for natural origins look like?"}, {"time": 2240, "text": "So one piece of evidence for natural origins is that it's happened in the past that viruses have jumped."}, {"time": 2253, "text": "Oh, they do jump."}, {"time": 2255, "text": "So like that's possible to have happened."}, {"time": 2259, "text": "So that's a sort of like a historical evidence, like, okay, well, it's possible that it have..."}, {"time": 2266, "text": "It's not evidence of the kind you think it is."}, {"time": 2268, "text": "It's a justification for a presumption, right?"}, {"time": 2272, "text": "So the presumption upon discovering a new virus circulating is certainly that it came from nature, right?"}, {"time": 2277, "text": "The problem is the presumption evaporates in the face of evidence, or at least it logically should."}, {"time": 2284, "text": "And it didn't in this case."}, {"time": 2285, "text": "It was maintained by people who privately in their emails acknowledged that they had grave doubts about the natural origin of this virus."}, {"time": 2294, "text": "Is there some other piece of evidence that we could look for and see that would say, this increases the probability that it's natural origins?"}, {"time": 2304, "text": "Yeah, in fact, there is evidence."}, {"time": 2307, "text": "I always worry that somebody is going to make up some evidence in order to reverse the flow."}, {"time": 2315, "text": "Well, let's say I am..."}, {"time": 2316, "text": "There's a lot of incentive for that actually."}, {"time": 2318, "text": "There's a huge amount of incentive."}, {"time": 2319, "text": "On the other hand, why didn't the powers that be, the powers that lied to us about weapons of mass destruction in Iraq, why didn't they ever fake weapons of mass destruction in Iraq?"}, {"time": 2329, "text": "Whatever force it is, I hope that force is here too."}, {"time": 2332, "text": "And so whatever evidence we find is real."}, {"time": 2334, "text": "It's the competence thing I'm talking about, but okay, go ahead, sorry."}, {"time": 2338, "text": "Well, we can get back to that."}, {"time": 2340, "text": "But I would say, yeah, the giant piece of evidence that will shift the probabilities in the other direction is the discovery of either a human population in which the virus circulated prior to showing up in Wuhan that would explain where the virus learned all of the tricks that it knew instantly upon spreading from Wuhan."}, {"time": 2360, "text": "So that would do it, or an animal population in which an ancestor epidemic can be found in which the virus learned this before jumping to humans."}, {"time": 2370, "text": "But I point out in that second case, you would certainly expect to see a great deal of evolution in the early epidemic, which we don't see."}, {"time": 2379, "text": "So there almost has to be a human population somewhere else that had the virus circulate or an ancestor of the virus that we first saw in Wuhan circulating."}, {"time": 2388, "text": "And it has to have gotten very sophisticated in that prior epidemic before hitting Wuhan in order to explain the total lack of evolution and extremely effective virus that emerged at the end of 2019."}, {"time": 2401, "text": "So you don't believe in the magic of evolution to spring up with all the tricks already there?"}, {"time": 2405, "text": "Like everybody who doesn't have the tricks, they die quickly."}, {"time": 2409, "text": "And then you just have this beautiful virus that comes in with a spike protein and through mutation and selection, just like the ones that succeed and succeed big are the ones that are going to just spring into life with the tricks."}, {"time": 2426, "text": "Well, no, that's called a hopeful monster."}, {"time": 2430, "text": "And hopeful monsters don't work."}, {"time": 2433, "text": "The job of becoming a new pandemic virus is too difficult."}, {"time": 2437, "text": "It involves two very difficult steps and they both have to work."}, {"time": 2440, "text": "One is the ability to infect a person and spread in their tissues sufficient to make an infection."}, {"time": 2446, "text": "And the other is to jump between individuals at a sufficient rate that it doesn't go extinct for one reason or another."}, {"time": 2453, "text": "Those are both very difficult jobs."}, {"time": 2455, "text": "They require, as you describe, selection."}, {"time": 2458, "text": "And the point is selection would leave a mark."}, {"time": 2460, "text": "We would see evidence that it would stay."}, {"time": 2462, "text": "In animals or humans, we would see."}, {"time": 2465, "text": "And we see this evolutionary trace of the virus gathering the tricks up."}, {"time": 2470, "text": "Yeah, you would see the virus, you would see the clumsy virus get better and better."}, {"time": 2474, "text": "And yes, I am a full believer in the power of that process."}, {"time": 2477, "text": "In fact, I believe it."}, {"time": 2479, "text": "What I know from studying the process is that it is much more powerful than most people imagine."}, {"time": 2485, "text": "That what we teach in the Evolution 101 textbook is too clumsy a process to do what we see it doing and that actually people should increase their expectation of the rapidity with which that process can produce just jaw dropping adaptations."}, {"time": 2502, "text": "That said, we just don't see evidence that it happened here which doesn't mean it doesn't exist, but it means in spite of immense pressure to find it somewhere, there's been no hint which probably means it took place inside of a laboratory."}, {"time": 2515, "text": "So inside the laboratory, gain of function research on viruses."}, {"time": 2520, "text": "And I believe most of that kind of research is doing this exact thing that you're referring to which is accelerated evolution and just watching evolution do its thing and a bunch of viruses and seeing what kind of tricks get developed."}, {"time": 2536, "text": "The other method is engineering viruses."}, {"time": 2541, "text": "So manually adding on the tricks."}, {"time": 2546, "text": "Which do you think we should be thinking about here?"}, {"time": 2550, "text": "So mind you, I learned what I know in the aftermath of this pandemic emerging."}, {"time": 2555, "text": "I started studying the question and I would say based on the content of the genome and other evidence in publications from the various labs that were involved in generating this technology, a couple of things seem likely."}, {"time": 2572, "text": "This SARS CoV2 does not appear to be entirely the result of either a splicing process or serial passaging."}, {"time": 2582, "text": "It appears to have both things in its past or it's at least highly likely that it does."}, {"time": 2589, "text": "So for example, the fern cleavage site looks very much like it was added in to the virus and it was known that that would increase its infectivity in humans and increase its tropism."}, {"time": 2602, "text": "The virus appears to be excellent at spreading in humans and minks and ferrets."}, {"time": 2612, "text": "Now minks and ferrets are very closely related to each other and ferrets are very likely to have been used in a serial passage experiment."}, {"time": 2618, "text": "The reason being that they have an ACE2 receptor that looks very much like the human ACE2 receptor."}, {"time": 2623, "text": "And so were you going to passage the virus or its ancestor through an animal in order to increase its infectivity in humans, which would have been necessary, ferrets would have been very likely."}, {"time": 2635, "text": "It is also quite likely that humanized mice were utilized and it is possible that human airway tissue was utilized."}, {"time": 2645, "text": "I think it is vital that we find out what the protocols were."}, {"time": 2649, "text": "If this came from the Wuhan Institute, we need to know it and we need to know what the protocols were exactly because they will actually give us some tools that would be useful in fighting SARS CoV2 and hopefully driving it to extinction, which ought to be our priority."}, {"time": 2664, "text": "It is a priority that does not, it is not apparent from our behavior, but it really is, it should be our objective."}, {"time": 2671, "text": "If we understood where our interests lie, we would be much more focused on it."}, {"time": 2676, "text": "But those protocols would tell us a great deal."}, {"time": 2679, "text": "If it wasn't the Wuhan Institute, we need to know that."}, {"time": 2682, "text": "If it was nature, we need to know that."}, {"time": 2684, "text": "And if it was some other laboratory, we need to figure out what and where so that we can determine what we can determine about what was done."}, {"time": 2693, "text": "You're opening up my mind about why we should investigate, why we should know the truth of the origins of this virus."}, {"time": 2701, "text": "So for me personally, let me just tell the story of my own kind of journey."}, {"time": 2707, "text": "When I first started looking into the lab leak hypothesis, what became terrifying to me and important to understand and obvious is the sort of like Sam Harris way of thinking, which is it's obvious that a lab leak of a deadly virus will eventually happen."}, {"time": 2729, "text": "My mind was, it doesn't even matter if it happened in this case."}, {"time": 2734, "text": "It's obvious that it's going to happen in the future."}, {"time": 2737, "text": "So why the hell are we not freaking out about this?"}, {"time": 2740, "text": "And COVID 19 is not even that deadly relative to the possible future viruses."}, {"time": 2745, "text": "It's this, the way I disagree with Sam on this, but he thinks about this way about AGI as well, not about artificial intelligence."}, {"time": 2752, "text": "It's a different discussion, I think, but with viruses, it seems like something that could happen on the scale of years, maybe a few decades."}, {"time": 2760, "text": "AGI is a little bit farther out for me, but it seemed, the terrifying thing, it seemed obvious that this will happen very soon for a much deadlier virus as we get better and better at both engineering viruses and doing this kind of evolutionary driven research, gain of function research."}, {"time": 2778, "text": "Okay, but then you started speaking out about this as well, but also started to say, no, no, no, we should hurry up and figure out the origins now because it will help us figure out how to actually respond to this particular virus, how to treat this particular virus."}, {"time": 2797, "text": "What is in terms of vaccines, in terms of antiviral drugs, in terms of just all the number of responses that we should have."}, {"time": 2806, "text": "Okay, I still am much more freaking out about the future."}, {"time": 2813, "text": "Maybe you can break that apart a little bit."}, {"time": 2817, "text": "Which are you most focused on now?"}, {"time": 2823, "text": "Which are you most freaking out about now in terms of the importance of figuring out the origins of this virus?"}, {"time": 2830, "text": "I am most freaking out about both of them because they're both really important and we can put bounds on this."}, {"time": 2838, "text": "Let me say first that this is a perfect test case for the theory of close calls because as much as COVID is a disaster, it is also a close call from which we can learn much."}, {"time": 2848, "text": "You are absolutely right."}, {"time": 2849, "text": "If we keep playing this game in the lab, if we are not, if we are, especially if we do it under pressure and when we are told that a virus is going to leap from nature any day and that the more we know, the better we'll be able to fight it, we're gonna create the disaster, all the sooner."}, {"time": 2866, "text": "So yes, that should be an absolute focus."}, {"time": 2869, "text": "The fact that there were people saying that this was dangerous back in 2015 ought to tell us something."}, {"time": 2875, "text": "The fact that the system bypassed a ban and offshored the work to China ought to tell us this is not a Chinese failure."}, {"time": 2882, "text": "This is a failure of something larger and harder to see."}, {"time": 2887, "text": "But I also think that there's a clock ticking with respect to SARS CoV2 and COVID, the disease that it creates."}, {"time": 2896, "text": "And that has to do with whether or not we are stuck with it permanently."}, {"time": 2900, "text": "So if you think about the cost to humanity of being stuck with influenza, it's an immense cost year after year."}, {"time": 2907, "text": "And we just stop thinking about it because it's there."}, {"time": 2910, "text": "Some years you get the flu, most years you don't."}, {"time": 2912, "text": "Maybe you get the vaccine to prevent it."}, {"time": 2914, "text": "Maybe the vaccine isn't particularly well targeted."}, {"time": 2917, "text": "But imagine just simply doubling that cost."}, {"time": 2920, "text": "Imagine we get stuck with SARS CoV2 and its descendants going forward and that it just settles in and becomes a fact of modern human life."}, {"time": 2931, "text": "That would be a disaster, right?"}, {"time": 2932, "text": "The number of people we will ultimately lose is incalculable."}, {"time": 2935, "text": "The amount of suffering that will be caused is incalculable."}, {"time": 2938, "text": "The loss of wellbeing and wealth, incalculable."}, {"time": 2941, "text": "So that ought to be a very high priority, driving this extinct before it becomes permanent."}, {"time": 2948, "text": "And the ability to drive extinct goes down the longer we delay effective responses."}, {"time": 2955, "text": "To the extent that we let it have this very large canvas, large numbers of people who have the disease in which mutation and selection can result in adaptation that we will not be able to counter the greater its ability to figure out features of our immune system and use them to its advantage."}, {"time": 2973, "text": "So I'm feeling the pressure of driving it extinct."}, {"time": 2977, "text": "I believe we could have driven it extinct six months ago and we didn't do it because of very mundane concerns among a small number of people."}, {"time": 2984, "text": "And I'm not alleging that they were brazen about or that they were callous about deaths that would be caused."}, {"time": 2995, "text": "I have the sense that they were working from a kind of autopilot in which you, let's say you're in some kind of a corporation, a pharmaceutical corporation, you have a portfolio of therapies that in the context of a pandemic might be very lucrative."}, {"time": 3011, "text": "Those therapies have competitors."}, {"time": 3013, "text": "You of course wanna position your product so that it succeeds and the competitors don't."}, {"time": 3018, "text": "And lo and behold, at some point through means that I think those of us on the outside can't really intuit, you end up saying things about competing therapies that work better and much more safely than the ones you're selling that aren't true and do cause people to die in large numbers."}, {"time": 3038, "text": "But it's some kind of autopilot, at least part of it is."}, {"time": 3043, "text": "So there's a complicated coupling of the autopilot of institutions, companies, governments."}, {"time": 3053, "text": "And then there's also the geopolitical game theory thing going on where you wanna keep secrets."}, {"time": 3060, "text": "It's the Chernobyl thing where if you messed up, there's a big incentive, I think, to hide the fact that you messed up."}, {"time": 3070, "text": "So how do we fix this?"}, {"time": 3072, "text": "And what's more important to fix?"}, {"time": 3074, "text": "The autopilot, which is the response that we often criticize about our institutions, especially the leaders in those institutions, Anthony Fauci and so on, some of the members of the scientific community."}, {"time": 3089, "text": "And the second part is the game with China of hiding the information in terms of on the fight between nations."}, {"time": 3100, "text": "Well, in our live streams on Dark Horse, Heather and I have been talking from the beginning about the fact that although, yes, what happens began in China, it very much looks like a failure of the international scientific community."}, {"time": 3114, "text": "That's frightening, but it's also hopeful in the sense that actually if we did the right thing now, we're not navigating a puzzle about Chinese responsibility."}, {"time": 3125, "text": "We're navigating a question of collective responsibility for something that has been terribly costly to all of us."}, {"time": 3134, "text": "So that's not a very happy process."}, {"time": 3137, "text": "But as you point out, what's at stake is in large measure at the very least the strong possibility this will happen again and that at some point it will be far worse."}, {"time": 3147, "text": "So just as a person that does not learn the lessons of their own errors doesn't get smarter and they remain in danger, we collectively, humanity has to say, well, there sure is a lot of evidence that suggests that this is a self inflicted wound."}, {"time": 3166, "text": "When you have done something that has caused a massive self inflicted wound, self inflicted wound, it makes sense to dwell on it exactly to the point that you have learned the lesson that makes it very, very unlikely that something similar will happen again."}, {"time": 3181, "text": "I think this is a good place to kind of ask you to do almost like a thought experiment or to steel man the argument against the lab leak hypothesis."}, {"time": 3195, "text": "So if you were to argue, you said 95% chance that the virus leak from a lab."}, {"time": 3206, "text": "There's a bunch of ways I think you can argue that even talking about it is bad for the world."}, {"time": 3217, "text": "So if I just put something on the table, it's to say that for one, it would be racism versus Chinese people that talking about that it leaked from a lab, there's a kind of immediate kind of blame and it can spiral down into this idea that's somehow the people are responsible for the virus and this kind of thing."}, {"time": 3242, "text": "Is it possible for you to come up with other steel man arguments against talking or against the possibility of the lab leak hypothesis?"}, {"time": 3252, "text": "Well, so I think steel manning is a tool that is extremely valuable, but it's also possible to abuse it."}, {"time": 3262, "text": "I think that you can only steel man a good faith argument."}, {"time": 3266, "text": "And the problem is we now know that we have not been engaged in opponents who were wielding good faith arguments because privately their emails reflect their own doubts."}, {"time": 3276, "text": "And what they were doing publicly was actually a punishment, a public punishment for those of us who spoke up with I think the purpose of either backing us down or more likely warning others not to engage in the same kind of behavior."}, {"time": 3291, "text": "And obviously for people like you and me who regard science as our likely best hope for navigating difficult waters, shutting down people who are using those tools honorably is itself dishonorable."}, {"time": 3307, "text": "So I don't feel that there's anything to steel man."}, {"time": 3339, "text": "And it very definitely involved the claim that what was being avoided was the targeting of Chinese scientists."}, {"time": 3349, "text": "And my point would be, I don't wanna see the targeting of anyone."}, {"time": 3353, "text": "I don't want to see racism of any kind."}, {"time": 3355, "text": "On the other hand, once you create license to lie in order to protect individuals when the world has a stake in knowing what happened, then it is inevitable that that process, that license to lie will be used by the thing that captures institutions for its own purposes."}, {"time": 3375, "text": "So my sense is it may be very unfortunate if the story of what happened here can be used against Chinese people."}, {"time": 3386, "text": "That would be very unfortunate."}, {"time": 3387, "text": "And as I think I mentioned, Heather and I have taken great pains to point out that this doesn't look like a Chinese failure."}, {"time": 3395, "text": "It looks like a failure of the international scientific community."}, {"time": 3398, "text": "So I think it is important to broadcast that message along with the analysis of the evidence."}, {"time": 3403, "text": "But no matter what happened, we have a right to know."}, {"time": 3406, "text": "And I frankly do not take the institutional layer at its word that its motivations are honorable and that it was protecting good hearted scientists at the expense of the world."}, {"time": 3418, "text": "That explanation does not add up."}, {"time": 3420, "text": "Well, this is a very interesting question about whether it's ever okay to lie at the institutional layer to protect the populace."}, {"time": 3432, "text": "I think both you and I are probably on the same, have the same sense that it's a slippery slope."}, {"time": 3441, "text": "Even if it's an effective mechanism in the short term, in the long term, it's going to be destructive."}, {"time": 3447, "text": "This happened with masks."}, {"time": 3450, "text": "This happened with other things."}, {"time": 3452, "text": "If you look at just history pandemics, there's an idea that panic is destructive amongst the populace."}, {"time": 3461, "text": "So you want to construct a narrative, whether it's a lie or not to minimize panic."}, {"time": 3469, "text": "But you're suggesting that almost in all cases, and I think that was the lesson from the pandemic in the early 20th century, that lying creates distrust and distrust in the institutions is ultimately destructive."}, {"time": 3488, "text": "That's your sense that lying is not okay?"}, {"time": 3492, "text": "There are obviously places where complete transparency is not a good idea, right?"}, {"time": 3497, "text": "To the extent that you broadcast a technology that allows one individual to hold the world hostage, obviously you've got something to be navigated."}, {"time": 3507, "text": "But in general, I don't believe that the scientific system should be lying to us."}, {"time": 3516, "text": "In the case of this particular lie, the idea that the wellbeing of Chinese scientists outweighs the wellbeing of the world is preposterous."}, {"time": 3530, "text": "Right, as you point out, one thing that rests on this question is whether we continue to do this kind of research going forward."}, {"time": 3536, "text": "And the scientists in question, all of them, American, Chinese, all of them were pushing the idea that the risk of a zoonotic spillover event causing a major and highly destructive pandemic was so great that we had to risk this."}, {"time": 3552, "text": "Now, if they themselves have caused it, and if they are wrong, as I believe they are, about the likelihood of a major world pandemic spilling out of nature in the way that they wrote into their grant applications, then the danger is the call is coming from inside the house and we have to look at that."}, {"time": 3571, "text": "And yes, whatever we have to do to protect scientists from retribution, we should do, but we cannot protecting them by lying to the world."}, {"time": 3582, "text": "And even worse, by demonizing people like me, like Josh Rogin, like Yuri Dagan, the entire drastic group on Twitter, by demonizing us for simply following the evidence is to set a terrible precedent, right?"}, {"time": 3605, "text": "You're demonizing people for using the scientific method to evaluate evidence that is available to us in the world."}, {"time": 3611, "text": "What a terrible crime it is to teach that lesson, right?"}, {"time": 3616, "text": "Thou shalt not use scientific tools."}, {"time": 3618, "text": "No, I'm sorry."}, {"time": 3619, "text": "Whatever your license to lie is, it doesn't extend to that."}, {"time": 3622, "text": "Yeah, I've seen the attacks on you, the pressure on you has a very important effect on thousands of world class biologists actually."}, {"time": 3636, "text": "At MIT, colleagues of mine, people I know, there's a slight pressure to not be allowed to one, speak publicly and two, actually think."}, {"time": 3651, "text": "Like do you even think about these ideas?"}, {"time": 3653, "text": "It sounds kind of ridiculous, but just in the privacy of your own home, to read things, to think, it's many people, many world class biologists that I know will just avoid looking at the data."}, {"time": 3670, "text": "There's not even that many people that are publicly opposing gain of function research."}, {"time": 3675, "text": "They're also like, it's not worth it."}, {"time": 3678, "text": "It's not worth the battle."}, {"time": 3680, "text": "And there's many people that kind of argue that those battles should be fought in private, with colleagues in the privacy of the scientific community that the public is somehow not maybe intelligent enough to be able to deal with the complexities of this kind of discussion."}, {"time": 3699, "text": "I don't know, but the final result is combined with the bullying of you and all the different pressures in the academic institutions is that it's just people are self censoring and silencing themselves and silencing the most important thing, which is the power of their brains."}, {"time": 3718, "text": "Like these people are brilliant."}, {"time": 3721, "text": "And the fact that they're not utilizing their brain to come up with solutions outside of the conformist line of thinking is tragic."}, {"time": 3731, "text": "Well, it is."}, {"time": 3732, "text": "I also think that we have to look at it and understand it for what it is."}, {"time": 3737, "text": "For one thing, it's kind of a cryptic totalitarianism."}, {"time": 3740, "text": "Somehow people's sense of what they're allowed to think about, talk about, discuss is causing them to self censor."}, {"time": 3747, "text": "And I can tell you it's causing many of them to rationalize, which is even worse."}, {"time": 3751, "text": "They're blinding themselves to what they can see."}, {"time": 3754, "text": "But it is also the case, I believe, that what you're describing about what people said, and a great many people understood that the lab leak hypothesis could not be taken off the table, but they didn't say so publicly."}, {"time": 3768, "text": "And I think that their discussions with each other about why they did not say what they understood, that's what capture sounds like on the inside."}, {"time": 3779, "text": "I don't know exactly what force captured the institutions."}, {"time": 3782, "text": "I don't think anybody knows for sure out here in public."}, {"time": 3787, "text": "I don't even know that it wasn't just simply a process."}, {"time": 3790, "text": "But you have these institutions."}, {"time": 3793, "text": "They are behaving towards a kind of somatic obligation."}, {"time": 3799, "text": "They have lost sight of what they were built to accomplish."}, {"time": 3802, "text": "And on the inside, the way they avoid going back to their original mission is to say things to themselves, like the public can't have this discussion."}, {"time": 3812, "text": "It can't be trusted with it."}, {"time": 3814, "text": "Yes, we need to be able to talk about this, but it has to be private."}, {"time": 3816, "text": "Whatever it is they say to themselves, that is what capture sounds like on the inside."}, {"time": 3820, "text": "It's a institutional rationalization mechanism."}, {"time": 3824, "text": "And it's very, very deadly."}, {"time": 3826, "text": "And at the point you go from lab leak to repurposed drugs, you can see that it's very deadly in a very direct way."}, {"time": 3834, "text": "Yeah, I see this in my field with things like autonomous weapon systems."}, {"time": 3841, "text": "People in AI do not talk about the use of AI in weapon systems."}, {"time": 3845, "text": "They kind of avoid the idea that AI's use them in the military."}, {"time": 3849, "text": "It's kind of funny, there's this like kind of discomfort and they're like, they all hurry, like something scary happens and a bunch of sheep kind of like run away."}, {"time": 3861, "text": "And I don't even know what to do about it."}, {"time": 3863, "text": "And then I feel this natural pull every time I bring up autonomous weapon systems to go along with the sheep."}, {"time": 3870, "text": "There's a natural kind of pull towards that direction because it's like, what can I do as one person?"}, {"time": 3877, "text": "Now there's currently nothing destructive happening with autonomous weapon systems."}, {"time": 3882, "text": "So we're in like in the early days of this race that in 10, 20 years might become a real problem."}, {"time": 3888, "text": "Now where the discussion we're having now, we're now facing the result of that in the space of viruses, like for many years avoiding the conversations here."}, {"time": 3900, "text": "I don't know what to do that in the early days, but I think we have to, I guess, create institutions where people can stand out."}, {"time": 3908, "text": "People can stand out and like basically be individual thinkers and break out into all kinds of spaces of ideas that allow us to think freely, freedom of thought."}, {"time": 3919, "text": "And maybe that requires a decentralization of institutions."}, {"time": 3922, "text": "Well, years ago, I came up with a concept called cultivated insecurity."}, {"time": 3928, "text": "And the idea is, let's just take the example of the average Joe, right?"}, {"time": 3934, "text": "The average Joe has a job somewhere and their mortgage, their medical insurance, their retirement, their connection with the economy is to one degree or another dependent on their relationship with the employer."}, {"time": 3954, "text": "That means that there is a strong incentive, especially in any industry where it's not easy to move from one employer to the next."}, {"time": 3962, "text": "There's a strong incentive to stay in your employer's good graces, right?"}, {"time": 3967, "text": "So it creates a very top down dynamic, not only in terms of who gets to tell other people what to do, but it really comes down to who gets to tell other people how to think."}, {"time": 3978, "text": "So that's extremely dangerous."}, {"time": 3981, "text": "The way out of it is to cultivate security to the extent that somebody is in a position to go against the grain and have it not be a catastrophe for their family and their ability to earn, you will see that behavior a lot more."}, {"time": 3996, "text": "So I would argue that some of what you're talking about is just a simple predictable consequence of the concentration of the sources of wellbeing and that this is a solvable problem."}, {"time": 4011, "text": "You got a chance to talk with Joe Rogan yesterday."}, {"time": 4016, "text": "And I just saw the episode was released and Ivermectin is trending on Twitter."}, {"time": 4024, "text": "Joe told me it was an incredible conversation."}, {"time": 4026, "text": "I look forward to listening to it today."}, {"time": 4027, "text": "Many people have probably, by the time this is released, have already listened to it."}, {"time": 4033, "text": "I think it would be interesting to discuss a postmortem."}, {"time": 4038, "text": "How do you feel how that conversation went?"}, {"time": 4041, "text": "And maybe broadly, how do you see the story as it's unfolding of Ivermectin from the origins from before COVID 19 through 2020 to today?"}, {"time": 4054, "text": "I very much enjoyed talking to Joe and I'm undescribably grateful that he would take the risk of such a discussion, that he would, as he described it, do an emergency podcast on the subject, which I think that was not an exaggeration."}, {"time": 4072, "text": "This needed to happen for various reasons that he took us down the road of talking about the censorship campaign against Ivermectin, which I find utterly shocking and talking about the drug itself."}, {"time": 4087, "text": "And I should say we talked, we had Pierre Corey available."}, {"time": 4090, "text": "He came on the podcast as well."}, {"time": 4092, "text": "He is, of course, the face of the FLCCC, the Frontline COVID 19 Critical Care Alliance."}, {"time": 4100, "text": "These are doctors who have innovated ways of treating COVID patients and they happened on Ivermectin and have been using it."}, {"time": 4109, "text": "And I hesitate to use the word advocating for it because that's not really the role of doctors or scientists, but they are advocating for it in the sense that there is this pressure not to talk about its effectiveness for reasons that we can go into."}, {"time": 4124, "text": "So maybe step back and say, what is Ivermectin and how much studies have been done to show its effectiveness?"}, {"time": 4134, "text": "So Ivermectin is an interesting drug."}, {"time": 4136, "text": "It was discovered in the 70s by a Japanese scientist named Satoshi Omura and he found it in soil near a Japanese golf course."}, {"time": 4148, "text": "So I would just point out in passing that if we were to stop self silencing over the possibility that Asians will be demonized over the possible lab leak in Wuhan and to recognize that actually the natural course of the story has a likely lab leak in China, it has a unlikely hero in Japan, the story is naturally not a simple one."}, {"time": 4176, "text": "But in any case, Omura discovered this molecule."}, {"time": 4180, "text": "He sent it to a friend who was at Merck, scientist named Campbell."}, {"time": 4186, "text": "They won a Nobel Prize for the discovery of the Ivermectin molecule in 2015."}, {"time": 4194, "text": "Its initial use was in treating parasitic infections."}, {"time": 4198, "text": "It's very effective in treating the worm that causes river blindness, the pathogen that causes elephantitis, scabies."}, {"time": 4208, "text": "It's a very effective anti parasite drug."}, {"time": 4210, "text": "It's extremely safe."}, {"time": 4211, "text": "It's on the WHO's list of essential medications."}, {"time": 4214, "text": "It's safe for children."}, {"time": 4216, "text": "It has been administered something like 4 billion times in the last four decades."}, {"time": 4222, "text": "It has been given away in the millions of doses by Merck in Africa."}, {"time": 4227, "text": "People have been on it for long periods of time."}, {"time": 4230, "text": "And in fact, one of the reasons that Africa may have had less severe impacts from COVID 19 is that Ivermectin is widely used there to prevent parasites and the drug appears to have a long lasting impact."}, {"time": 4243, "text": "So it's an interesting molecule."}, {"time": 4245, "text": "It was discovered some time ago apparently that it has antiviral properties."}, {"time": 4250, "text": "And so it was tested early in the COVID 19 pandemic to see if it might work to treat humans with COVID."}, {"time": 4258, "text": "It turned out to have very promising evidence that it did treat humans."}, {"time": 4263, "text": "It was tested in tissues."}, {"time": 4264, "text": "It was tested at a very high dosage, which confuses people."}, {"time": 4268, "text": "They think that those of us who believe that Ivermectin might be useful in confronting this disease are advocating those high doses, which is not the case."}, {"time": 4277, "text": "But in any case, there have been quite a number of studies."}, {"time": 4280, "text": "A wonderful meta analysis was finally released."}, {"time": 4283, "text": "We had seen it in preprint version, but it was finally peer reviewed and published this last week."}, {"time": 4289, "text": "It reveals that the drug, as clinicians have been telling us, those who have been using it, it's highly effective at treating people with the disease, especially if you get to them early."}, {"time": 4299, "text": "And it showed an 86% effectiveness as a prophylactic to prevent people from contracting COVID."}, {"time": 4306, "text": "And that number, 86%, is high enough to drive SARS CoV2 to extinction if we wished to deploy it."}, {"time": 4315, "text": "First of all, the meta analysis, is this the Ivermectin for COVID 19 real time meta analysis of 60 studies?"}, {"time": 4324, "text": "Or there's a bunch of meta analysis there."}, {"time": 4326, "text": "Because I was really impressed by the real time meta analysis that keeps getting updated."}, {"time": 4331, "text": "I don't know if it's the same kind of thing."}, {"time": 4332, "text": "The one at ivmmeta.com?"}, {"time": 4338, "text": "Well, I saw it at c19ivermeta.com."}, {"time": 4341, "text": "No, this is not that meta analysis."}, {"time": 4344, "text": "So that is, as you say, a living meta analysis where you can watch as evidence rolls in."}, {"time": 4347, "text": "Which is super cool, by the way."}, {"time": 4349, "text": "And they've got some really nice graphics that allow you to understand, well, what is the evidence?"}, {"time": 4355, "text": "It's concentrated around this level of effectiveness, et cetera."}, {"time": 4358, "text": "So anyway, it's a great site, well worth paying attention to."}, {"time": 4360, "text": "No, this is a meta analysis."}, {"time": 4363, "text": "I don't know any of the authors but one."}, {"time": 4366, "text": "Second author is Tess Lorry of the BIRD group."}, {"time": 4369, "text": "BIRD being a group of analysts and doctors in Britain that is playing a role similar to the FLCCC here in the US."}, {"time": 4380, "text": "So anyway, this is a meta analysis that Tess Lorry and others did of all of the available evidence."}, {"time": 4388, "text": "And it's quite compelling."}, {"time": 4390, "text": "People can look for it on my Twitter."}, {"time": 4392, "text": "I will put it up and people can find it there."}, {"time": 4395, "text": "So what about dose here?"}, {"time": 4398, "text": "In terms of safety, what do we understand about the kind of dose required to have that level of effectiveness?"}, {"time": 4406, "text": "And what do we understand about the safety of that kind of dose?"}, {"time": 4410, "text": "So let me just say, I'm not a medical doctor."}, {"time": 4412, "text": "I'm a biologist."}, {"time": 4414, "text": "I'm on ivermectin in lieu of vaccination."}, {"time": 4419, "text": "In terms of dosage, there is one reason for concern, which is that the most effective dose for prophylaxis involves something like weekly administration."}, {"time": 4429, "text": "And because that is not a historical pattern of use for the drug, it is possible that there is some longterm implication of being on it weekly for a long period of time."}, {"time": 4442, "text": "There's not a strong indication of that."}, {"time": 4444, "text": "The safety signal that we have over people using the drug over many years and using it in high doses."}, {"time": 4450, "text": "In fact, Dr. Corey told me yesterday that there are cases in which people have made calculation errors and taken a massive overdose of the drug and had no ill effect."}, {"time": 4461, "text": "So anyway, there's lots of reasons to think the drug is comparatively safe, but no drug is perfectly safe."}, {"time": 4467, "text": "And I do worry about the longterm implications of taking it."}, {"time": 4501, "text": "So there's a question about whether or not you could flatten out the intake so that the amount of ivermectin goes down, but the protection remains."}, {"time": 4510, "text": "I have little doubt that that would be discovered if we looked for it."}, {"time": 4515, "text": "But that said, it does seem to be quite safe, highly effective at preventing COVID."}, {"time": 4521, "text": "The 86% number is plenty high enough for us to drive SARS CoV2 to extinction in light of its R0 number of slightly more than two."}, {"time": 4533, "text": "And so why we are not using it is a bit of a mystery."}, {"time": 4536, "text": "So even if everything you said now turns out to be not correct, it is nevertheless obvious that it's sufficiently promising and it always has been in order to merit rigorous scientific exploration, investigation, doing a lot of studies and certainly not censoring the science or the discussion of it."}, {"time": 4560, "text": "So before we talk about the various vaccines for COVID 19, I'd like to talk to you about censorship."}, {"time": 4568, "text": "Given everything you're saying, why did YouTube and other places censor discussion of ivermectin?"}, {"time": 4579, "text": "Well, there's a question about why they say they did it and there's a question about why they actually did it."}, {"time": 4584, "text": "Now, it is worth mentioning that YouTube is part of a consortium."}, {"time": 4591, "text": "It is partnered with Twitter, Facebook, Reuters, AP, Financial Times, Washington Post, some other notable organizations."}, {"time": 4602, "text": "And that this group has appointed itself the arbiter of truth."}, {"time": 4608, "text": "In effect, they have decided to control discussion ostensibly to prevent the distribution of misinformation."}, {"time": 4617, "text": "Now, how have they chosen to do that?"}, {"time": 4619, "text": "In this case, they have chosen to simply utilize the recommendations of the WHO and the CDC and apply them as if they are synonymous with scientific truth."}, {"time": 4631, "text": "Problem, even at their best, the WHO and CDC are not scientific entities."}, {"time": 4637, "text": "They are entities that are about public health."}, {"time": 4640, "text": "And public health has this, whether it's right or not, and I believe I disagree with it, but it has this self assigned right to lie that comes from the fact that there is game theory that works against, for example, a successful vaccination campaign."}, {"time": 4660, "text": "That if everybody else takes a vaccine and therefore the herd becomes immune through vaccination and you decide not to take a vaccine, then you benefit from the immunity of the herd without having taken the risk."}, {"time": 4675, "text": "So people who do best are the people who opt out."}, {"time": 4678, "text": "That's a hazard."}, {"time": 4679, "text": "And the WHO and CDC as public health entities effectively oversimplify stories in order to make sense of oversimplify stories in order that that game theory does not cause a predictable tragedy of the commons."}, {"time": 4695, "text": "With that said, once that right to lie exists, then it turns out to serve the interests of, for example, pharmaceutical companies, which have emergency use authorizations that require that there not be a safe and effective treatment and have immunity from liability for harms caused by their product."}, {"time": 4714, "text": "So that's a recipe for disaster, right?"}, {"time": 4717, "text": "You don't need to be a sophisticated thinker about complex systems to see the hazard of immunizing a company from the harm of its own product at the same time that that product can only exist in the market if some other product that works better somehow fails to be noticed."}, {"time": 4737, "text": "So somehow YouTube is doing the bidding of Merck and others."}, {"time": 4742, "text": "Whether it knows that that's what it's doing, I have no idea."}, {"time": 4745, "text": "I think this may be another case of an autopilot that thinks it's doing the right thing because it's parroting the corrupt wisdom of the WHO and the CDC, but the WHO and the CDC have been wrong again and again in this pandemic."}, {"time": 4758, "text": "And the irony here is that with YouTube coming after me, well, my channel has been right where the WHO and CDC have been wrong consistently over the whole pandemic."}, {"time": 4769, "text": "So how is it that YouTube is censoring us because the WHO and CDC disagree with us when in fact, in past disagreements, we've been right and they've been wrong?"}, {"time": 4778, "text": "There's so much to talk about here."}, {"time": 4781, "text": "So I've heard this many times actually on the inside of YouTube and with colleagues that I've talked with is they kind of in a very casual way say their job is simply to slow or prevent the spread of misinformation."}, {"time": 4803, "text": "And they say like, that's an easy thing to do."}, {"time": 4806, "text": "Like to know what is true or not is an easy thing to do."}, {"time": 4811, "text": "And so from the YouTube perspective, I think they basically outsource of the task of knowing what is true or not to public institutions that on a basic Google search claim to be the arbiters of truth."}, {"time": 4832, "text": "So if you were YouTube who are exceptionally profitable and exceptionally powerful in terms of controlling what people get to see or not, what would you do?"}, {"time": 4846, "text": "Would you take a stand, a public stand against the WHO, CDC?"}, {"time": 4854, "text": "Or would you instead say, you know what?"}, {"time": 4857, "text": "Let's open the dam and let any video on anything fly."}, {"time": 4862, "text": "What do you do here?"}, {"time": 4864, "text": "Say you were put, if Brent Weinstein was put in charge of YouTube for a month in this most critical of times where YouTube actually has incredible amounts of power to educate the populace, to give power of knowledge to the populace such that they can reform institutions."}, {"time": 4884, "text": "What would you do?"}, {"time": 4885, "text": "How would you run YouTube?"}, {"time": 4886, "text": "Well, unfortunately, or fortunately, this is actually quite simple."}, {"time": 4892, "text": "The founders, the American founders, settled on a counterintuitive formulation that people should be free to say anything."}, {"time": 4901, "text": "They should be free from the government blocking them from doing so."}, {"time": 4905, "text": "They did not imagine that in formulating that right, that most of what was said would be of high quality, nor did they imagine it would be free of harmful things."}, {"time": 4914, "text": "What they correctly reasoned was that the benefit of leaving everything so it can be said exceeds the cost, which everyone understands to be substantial."}, {"time": 4925, "text": "What I would say is they could not have anticipated the impact, the centrality of platforms like YouTube, Facebook, Twitter, et cetera."}, {"time": 4936, "text": "If they had, they would not have limited the First Amendment as they did."}, {"time": 4941, "text": "They clearly understood that the power of the federal government was so great that it needed to be limited by granting explicitly the right of citizens to say anything."}, {"time": 4954, "text": "In fact, YouTube, Twitter, Facebook may be more powerful in this moment than the federal government of their worst nightmares could have been."}, {"time": 4964, "text": "The power that these entities have to control thought and to shift civilization is so great that we need to have those same protections."}, {"time": 4972, "text": "It doesn't mean that harmful things won't be said, but it means that nothing has changed about the cost benefit analysis of building the right to censor."}, {"time": 4981, "text": "So if I were running YouTube, the limit of what should be allowed is the limit of the law, right?"}, {"time": 4988, "text": "If what you are doing is legal, then it should not be YouTube's place to limit what gets said or who gets to hear it."}, {"time": 4995, "text": "That is between speakers and audience."}, {"time": 4998, "text": "Will harm come from that?"}, {"time": 4998, "text": "Of course it will."}, {"time": 5000, "text": "But will net harm come from it?"}, {"time": 5002, "text": "No, I don't believe it will."}, {"time": 5004, "text": "I believe that allowing everything to be said does allow a process in which better ideas do come to the fore and win out."}, {"time": 5011, "text": "So you believe that in the end, when there's complete freedom to share ideas, that truth will win out."}, {"time": 5019, "text": "So what I've noticed, just as a brief side comment, that certain things become viral irregardless of their truth."}, {"time": 5031, "text": "I've noticed that things that are dramatic and or funny, like things that become memes are not, don't have to be grounded in truth."}, {"time": 5040, "text": "And so that what worries me there is that we basically maximize for drama versus maximize for truth in a system where everything is free."}, {"time": 5052, "text": "And that is worrying in the time of emergency."}, {"time": 5056, "text": "Well, yes, it's all worrying in time of emergency, to be sure."}, {"time": 5059, "text": "But I want you to notice that what you've happened on is actually an analog for a much deeper and older problem."}, {"time": 5066, "text": "Human beings are the, we are not a blank slate, but we are the blankest slate that nature has ever devised."}, {"time": 5074, "text": "And there's a reason for that, right?"}, {"time": 5075, "text": "It's where our flexibility comes from."}, {"time": 5079, "text": "We have effectively, we are robots in which a large fraction of the cognitive capacity has been, or of the behavioral capacity, has been offloaded to the software layer, which gets written and rewritten over evolutionary time."}, {"time": 5097, "text": "That means effectively that much of what we are, in fact, the important part of what we are is housed in the cultural layer and the conscious layer and not in the hardware hard coding layer."}, {"time": 5108, "text": "So that layer is prone to make errors, right?"}, {"time": 5114, "text": "And anybody who's watched a child grow up knows that children make absurd errors all the time, right?"}, {"time": 5120, "text": "That's part of the process, as we were discussing earlier."}, {"time": 5124, "text": "It is also true that as you look across a field of people discussing things, a lot of what is said is pure nonsense, it's garbage."}, {"time": 5133, "text": "But the tendency of garbage to emerge and even to spread in the short term does not say that over the long term, what sticks is not the valuable ideas."}, {"time": 5145, "text": "So there is a high tendency for novelty to be created in the cultural space, but there's also a high tendency for it to go extinct."}, {"time": 5154, "text": "And you have to keep that in mind."}, {"time": 5155, "text": "It's not like the genome, right?"}, {"time": 5157, "text": "Everything is happening at a much higher rate."}, {"time": 5159, "text": "Things are being created, they're being destroyed."}, {"time": 5161, "text": "And I can't say that, I mean, obviously, we've seen totalitarianism arise many times, and it's very destructive each time it does."}, {"time": 5170, "text": "So it's not like, hey, freedom to come up with any idea you want hasn't produced a whole lot of carnage."}, {"time": 5176, "text": "But the question is, over time, does it produce more open, fairer, more decent societies?"}, {"time": 5183, "text": "And I believe that it does."}, {"time": 5184, "text": "I can't prove it, but that does seem to be the pattern."}, {"time": 5187, "text": "I believe so as well."}, {"time": 5189, "text": "The thing is, in the short term, freedom of speech, absolute freedom of speech can be quite destructive."}, {"time": 5198, "text": "But you nevertheless have to hold on to that, because in the long term, I think you and I, I guess, are optimistic in the sense that good ideas will win out."}, {"time": 5211, "text": "I don't know how strongly I believe that it will work, but I will say I haven't heard a better idea."}, {"time": 5216, "text": "I would also point out that there's something very significant in this question of the hubris involved in imagining that you're going to improve the discussion by censoring, which is the majority of concepts at the fringe are nonsense."}, {"time": 5238, "text": "That's automatic."}, {"time": 5239, "text": "But the heterodoxy at the fringe, which is indistinguishable at the beginning from the nonsense ideas, is the key to progress."}, {"time": 5250, "text": "So if you decide, hey, the fringe is 99% garbage, let's just get rid of it, right?"}, {"time": 5255, "text": "Hey, that's a strong win."}, {"time": 5256, "text": "We're getting rid of 99% garbage for 1% something or other."}, {"time": 5260, "text": "And the point is, yeah, but that 1% something or other is the key."}, {"time": 5263, "text": "You're throwing out the key."}, {"time": 5265, "text": "And so that's what YouTube is doing."}, {"time": 5268, "text": "Frankly, I think at the point that it started censoring my channel, in the immediate aftermath of this major reversal over LabLeak, it should have looked at itself and said, well, what the hell are we doing?"}, {"time": 5279, "text": "Who are we censoring?"}, {"time": 5280, "text": "We're censoring somebody who was just right, right?"}, {"time": 5283, "text": "In a conflict with the very same people on whose behalf we are now censoring, right?"}, {"time": 5287, "text": "That should have caused them to wake up."}, {"time": 5289, "text": "So you said one approach, if you're on YouTube, is this basically let all videos go that do not violate the law."}, {"time": 5296, "text": "Well, I should fix that, okay?"}, {"time": 5298, "text": "I believe that that is the basic principle."}, {"time": 5300, "text": "Eric makes an excellent point about the distinction between ideas and personal attacks, doxxing, these other things."}, {"time": 5308, "text": "So I agree, there's no value in allowing people to destroy each other's lives, even if there's a technical legal defense for it."}, {"time": 5316, "text": "Now, how you draw that line, I don't know."}, {"time": 5319, "text": "But what I'm talking about is, yes, people should be free to traffic in bad ideas, and they should be free to expose that the ideas are bad."}, {"time": 5327, "text": "And hopefully that process results in better ideas winning out."}, {"time": 5330, "text": "Yeah, there's an interesting line between ideas, like the earth is flat, which I believe you should not censor."}, {"time": 5339, "text": "And then you start to encroach on personal attacks."}, {"time": 5344, "text": "So not doxxing, yes, but not even getting to that."}, {"time": 5348, "text": "There's a certain point where it's like, that's no longer ideas, that's more, that's somehow not productive, even if it's wrong."}, {"time": 5358, "text": "It feels like believing the earth is flat is somehow productive, because maybe there's a tiny percent chance it is."}, {"time": 5367, "text": "It just feels like personal attacks, it doesn't, well, I'm torn on this because there's assholes in this world, there's fraudulent people in this world."}, {"time": 5377, "text": "So sometimes personal attacks are useful to reveal that, but there's a line you can cross."}, {"time": 5384, "text": "There's a comedy where people make fun of others."}, {"time": 5388, "text": "I think that's amazing, that's very powerful, and that's very useful, even if it's painful."}, {"time": 5393, "text": "But then there's like, once it gets to be, yeah, there's a certain line, it's a gray area where you cross, where it's no longer in any possible world productive."}, {"time": 5404, "text": "And that's a really weird gray area for YouTube to operate in."}, {"time": 5409, "text": "And that feels like it should be a crowdsource thing, where people vote on it."}, {"time": 5413, "text": "But then again, do you trust the majority to vote on what is crossing the line and not?"}, {"time": 5419, "text": "I mean, this is where, this is really interesting on this particular, like the scientific aspect of this."}, {"time": 5427, "text": "Do you think YouTube should take more of a stance, not censoring, but to actually have scientists within YouTube having these kinds of discussions, and then be able to almost speak out in a transparent way, this is what we're going to let this video stand, but here's all these other opinions."}, {"time": 5447, "text": "Almost like take a more active role in its recommendation system, in trying to present a full picture to you."}, {"time": 5455, "text": "Right now they're not, the recommender systems are not human fine tuned."}, {"time": 5461, "text": "They're all based on how you click, and there's this clustering algorithms."}, {"time": 5465, "text": "They're not taking an active role on giving you the full spectrum of ideas in the space of science."}, {"time": 5471, "text": "They just censor or not."}, {"time": 5472, "text": "Well, at the moment, it's gonna be pretty hard to compel me that these people should be trusted with any sort of curation or comment on matters of evidence, because they have demonstrated that they are incapable of doing it well."}, {"time": 5489, "text": "You could make such an argument, and I guess I'm open to the idea of institutions that would look something like YouTube, that would be capable of offering something valuable."}, {"time": 5499, "text": "I mean, and even just the fact of them literally curating things and putting some videos next to others implies something."}, {"time": 5507, "text": "So yeah, there's a question to be answered, but at the moment, no."}, {"time": 5511, "text": "At the moment, what it is doing is quite literally putting not only individual humans in tremendous jeopardy by censoring discussion of useful tools and making tools that are more hazardous than has been acknowledged seem safe, right?"}, {"time": 5527, "text": "But it is also placing humanity in danger of a permanent relationship with this pathogen."}, {"time": 5533, "text": "I cannot emphasize enough how expensive that is."}, {"time": 5536, "text": "It's effectively incalculable."}, {"time": 5538, "text": "If the relationship becomes permanent, the number of people who will ultimately suffer and die from it is indefinitely large."}, {"time": 5546, "text": "Yeah, currently the algorithm is very rabbit hole driven, meaning if you click on Flat Earth videos, that's all you're going to be presented with and you're not going to be nicely presented with arguments against the Flat Earth."}, {"time": 5562, "text": "And the flip side of that, if you watch like quantum mechanics videos or no, general relativity videos, it's very rare you're going to get a recommendation."}, {"time": 5573, "text": "Have you considered the Earth is flat?"}, {"time": 5574, "text": "And I think you should have both."}, {"time": 5577, "text": "Same with vaccine."}, {"time": 5578, "text": "Videos that present the power and the incredible like biology, genetics, virology about the vaccine, you're rarely going to get videos from well respected scientific minds presenting possible dangers of the vaccine."}, {"time": 5596, "text": "And the vice versa is true as well, which is if you're looking at the dangers of the vaccine on YouTube, you're not going to get the highest quality of videos recommended to you."}, {"time": 5607, "text": "And I'm not talking about like manually inserted CDC videos that are like the most untrustworthy things you can possibly watch about how everybody should take the vaccine, it's the safest thing ever."}, {"time": 5618, "text": "No, it's about incredible, again, MIT colleagues of mine, incredible biologists, virologists that talk about the details of how the mRNA vaccines work and all those kinds of things."}, {"time": 5630, "text": "I think maybe this is me with the AI hat on, is I think the algorithm can fix a lot of this and YouTube should build better algorithms and trust that to a couple of complete freedom of speech to expand what people are able to think about, present always varied views, not balanced in some artificial way, hard coded way, but balanced in a way that's crowdsourced."}, {"time": 5658, "text": "I think that's an algorithm problem that can be solved because then you can delegate it to the algorithm as opposed to this hard code censorship of basically creating artificial boundaries on what can and can't be discussed, instead creating a full spectrum of exploration that can be done and trusting the intelligence of people to do the exploration."}, {"time": 5685, "text": "Well, there's a lot there."}, {"time": 5687, "text": "I would say we have to keep in mind that we're talking about a publicly held company with shareholders and obligations to them and that that may make it impossible."}, {"time": 5697, "text": "And I remember many years ago, back in the early days of Google, I remember a sense of terror at the loss of general search."}, {"time": 5710, "text": "It used to be that Google, if you searched, came up with the same thing for everyone and then it got personalized and for a while it was possible to turn off the personalization, which was still not great because if everybody else is looking at a personalized search and you can tune into one that isn't personalized, that doesn't tell you why the world is sounding the way it is."}, {"time": 5733, "text": "But nonetheless, it was at least an option."}, {"time": 5734, "text": "And then that vanished."}, {"time": 5735, "text": "And the problem is I think this is literally deranging us."}, {"time": 5740, "text": "That in effect, I mean, what you're describing is unthinkable."}, {"time": 5744, "text": "It is unthinkable that in the face of a campaign to vaccinate people in order to reach herd immunity that YouTube would give you videos on hazards of vaccines when this is, how hazardous the vaccines are is an unsettled question."}, {"time": 5764, "text": "Why is it unthinkable?"}, {"time": 5766, "text": "That doesn't make any sense from a company perspective."}, {"time": 5769, "text": "If intelligent people in large amounts are open minded and are thinking through the hazards and the benefits of a vaccine, a company should find the best videos to present what people are thinking about."}, {"time": 5788, "text": "Well, let's come up with a hypothetical."}, {"time": 5790, "text": "Okay, let's come up with a very deadly disease for which there's a vaccine that is very safe, though not perfectly safe."}, {"time": 5800, "text": "And we are then faced with YouTube trying to figure out what to do for somebody searching on vaccine safety."}, {"time": 5807, "text": "Suppose it is necessary in order to drive the pathogen to extinction, something like smallpox, that people get on board with the vaccine."}, {"time": 5817, "text": "But there's a tiny fringe of people who thinks that the vaccine is a mind control agent."}, {"time": 5825, "text": "So should YouTube direct people to the only claims against this vaccine, which is that it's a mind control agent when in fact the vaccine is very safe, whatever that means."}, {"time": 5842, "text": "If that were the actual configuration of the puzzle, then YouTube would be doing active harm, pointing you to this other video potentially."}, {"time": 5853, "text": "Now, yes, I would love to live in a world where people are up to the challenge of sorting that out."}, {"time": 5859, "text": "But my basic point would be, if it's an evidentiary question, and there is essentially no evidence that the vaccine is a mind control agent, and there's plenty of evidence that the vaccine is safe, then while you look for this video, we're gonna give you this one, puts it on a par, right?"}, {"time": 5875, "text": "So for the mind that's tracking how much thought is there behind it's safe versus how much thought is there behind it's a mind control agent will result in artificially elevating this."}, {"time": 5887, "text": "Now in the current case, what we've seen is not this at all."}, {"time": 5891, "text": "We have seen evidence obscured in order to create a false story about safety."}, {"time": 5898, "text": "And we saw the inverse with ivermectin."}, {"time": 5902, "text": "We saw a campaign to portray the drug as more dangerous and less effective than the evidence clearly suggested it was."}, {"time": 5910, "text": "So we're not talking about a comparable thing, but I guess my point is the algorithmic solution that you point to creates a problem of its own, which is that it means that the way to get exposure is to generate something fringy."}, {"time": 5924, "text": "If you're the only thing on some fringe, then suddenly YouTube would be recommending those things, and that's obviously a gameable system at best."}, {"time": 5933, "text": "Yeah, but the solution to that, I know you're creating a thought experiment, maybe playing a little bit of a devil's advocate."}, {"time": 5940, "text": "I think the solution to that is not to limit the algorithm in the case of the super deadly virus."}, {"time": 5945, "text": "It's for the scientists to step up and become better communicators, more charismatic, fight the battle of ideas, sort of create better videos."}, {"time": 5956, "text": "Like if the virus is truly deadly, you have a lot more ammunition, a lot more data, a lot more material to work with in terms of communicating with the public."}, {"time": 5966, "text": "So be better at communicating and stop being, you have to start trusting the intelligence of people and also being transparent and playing the game of the internet, which is like, what is the internet hungry for, I believe?"}, {"time": 5980, "text": "Authenticity, stop looking like you're full of shit."}, {"time": 5986, "text": "The scientific community, if there's any flaw that I currently see, especially the people that are in public office, that like Anthony Fauci, they look like they're full of shit and I know they're brilliant."}, {"time": 5997, "text": "Why don't they look more authentic?"}, {"time": 5999, "text": "So they're losing that game and I think a lot of people observing this entire system now, younger scientists are seeing this and saying, okay, if I want to continue being a scientist in the public eye and I want to be effective at my job, I'm gonna have to be a lot more authentic."}, {"time": 6018, "text": "So they're learning the lesson, this evolutionary system is working."}, {"time": 6022, "text": "So there's just a younger generation of minds coming up that I think will do a much better job in this battle of ideas that when the much more dangerous virus comes along, they'll be able to be better communicators."}, {"time": 6034, "text": "At least that's the hope."}, {"time": 6036, "text": "Using the algorithm to control that is, I feel like is a big problem."}, {"time": 6041, "text": "So you're going to have the same problem with a deadly virus as with the current virus if you let YouTube draw hard lines by the PR and the marketing people versus the broad community of scientists."}, {"time": 6056, "text": "Well, in some sense you're suggesting something that's close kin to what I was saying about freedom of expression ultimately provides an advantage to better ideas."}, {"time": 6067, "text": "So I'm in agreement broadly speaking, but I would also say there's probably some sort of, let's imagine the world that you propose where YouTube shows you the alternative point of view."}, {"time": 6079, "text": "That has the problem that I suggest, but one thing you could do is you could give us the tools to understand what we're looking at, right?"}, {"time": 6087, "text": "You could give us, so first of all, there's something I think myopic, solipsistic, narcissistic about an algorithm that serves shareholders by showing you what you want to see rather than what you need to know, right?"}, {"time": 6102, "text": "That's the distinction is flattering you, playing to your blind spot is something that algorithm will figure out, but it's not healthy for us all to have Google playing to our blind spot."}, {"time": 6113, "text": "It's very, very dangerous."}, {"time": 6114, "text": "So what I really want is analytics that allow me or maybe options and analytics."}, {"time": 6122, "text": "The options should allow me to see what alternative perspectives are being explored, right?"}, {"time": 6129, "text": "So here's the thing I'm searching and it leads me down this road, right?"}, {"time": 6132, "text": "Let's say it's ivermectin, okay?"}, {"time": 6134, "text": "I find all of this evidence that ivermectin works."}, {"time": 6136, "text": "I find all of these discussions and people talk about various protocols and this and that."}, {"time": 6140, "text": "And then I could say, all right, what is the other side?"}, {"time": 6144, "text": "And I could see who is searching, not as individuals, but what demographics are searching alternatives."}, {"time": 6152, "text": "And maybe you could even combine it with something Reddit like where effectively, let's say that there was a position that, I don't know, that a vaccine is a mind control device and you could have a steel man this argument competition effectively and the better answers that steel man and as well as possible would rise to the top."}, {"time": 6173, "text": "And so you could read the top three or four explanations about why this really credibly is a mind control product."}, {"time": 6181, "text": "And you can say, well, that doesn't really add up."}, {"time": 6183, "text": "I can check these three things myself and they can't possibly be right, right?"}, {"time": 6187, "text": "And you could dismiss it."}, {"time": 6188, "text": "And then as an argument that was credible, let's say plate tectonics before that was an accepted concept, you'd say, wait a minute, there is evidence for plate tectonics."}, {"time": 6199, "text": "As crazy as it sounds that the continents are floating around on liquid, actually that's not so implausible."}, {"time": 6206, "text": "We've got these subduction zones, we've got a geology that is compatible, we've got puzzle piece continents that seem to fit together."}, {"time": 6213, "text": "Wow, that's a surprising amount of evidence for that position."}, {"time": 6216, "text": "So I'm gonna file some Bayesian probability with it that's updated for the fact that actually the steel man arguments better than I was expecting, right?"}, {"time": 6223, "text": "So I could imagine something like that where A, I would love the search to be indifferent to who's searching, right?"}, {"time": 6229, "text": "The solipsistic thing is too dangerous."}, {"time": 6231, "text": "So the search could be general, so we would all get a sense for what everybody else was seeing too."}, {"time": 6236, "text": "And then some layer that didn't have anything to do with what YouTube points you to or not, but allowed you to see, you know, the general pattern of adherence to searching for information."}, {"time": 6251, "text": "And again, a layer in which those things could be defended."}, {"time": 6254, "text": "So you could hear what a good argument sounded like rather than just hear a caricatured argument."}, {"time": 6259, "text": "Yeah, and also reward people, creators that have demonstrated like a track record of open mindedness and correctness as much as it could be measured over a long term and sort of, I mean, a lot of this maps to incentivizing good longterm behavior, not immediate kind of dopamine rush kind of signals."}, {"time": 6290, "text": "I think ultimately the algorithm on the individual level should optimize for personal growth, longterm happiness, just growth intellectually, growth in terms of lifestyle personally and so on, as opposed to immediate."}, {"time": 6310, "text": "I think that's going to build a better society, not even just like truth, because I think truth is a complicated thing."}, {"time": 6316, "text": "It's more just you growing as a person, exploring the space of ideas, changing your mind often, increasing the level to which you're open minded, the knowledge base you're operating from, the willingness to empathize with others, all those kinds of things the algorithm should optimize for."}, {"time": 6334, "text": "Like creating a better human at the individual level that you're, I think that's a great business model because the person that's using this tool will then be happier with themselves for having used it and will be a lifelong quote unquote customer."}, {"time": 6350, "text": "I think it's a great business model to make a happy, open minded, knowledgeable, better human being."}, {"time": 6358, "text": "It's a terrible business model under the current system."}, {"time": 6362, "text": "What you want is to build the system in which it is a great business model."}, {"time": 6365, "text": "Why is it a terrible model?"}, {"time": 6367, "text": "Because it will be decimated by those who play to the short term."}, {"time": 6375, "text": "I mean, I think we're living it."}, {"time": 6376, "text": "We're living it."}, {"time": 6377, "text": "Well, no, because if you have the alternative that presents itself, it points out the emperor has no clothes."}, {"time": 6384, "text": "I mean, it points out that YouTube is operating in this way, Twitter is operating in this way, Facebook is operating in this way."}, {"time": 6390, "text": "How long term would you like the wisdom to prove at?"}, {"time": 6395, "text": "Well, even a week is better when it's currently happening."}, {"time": 6400, "text": "Right, but the problem is, if a week loses out to an hour, right?"}, {"time": 6405, "text": "And I don't think it loses out."}, {"time": 6408, "text": "It loses out in the short term."}, {"time": 6410, "text": "At least you're a great communicator and you basically say, look, here's the metrics."}, {"time": 6415, "text": "And a lot of it is like how people actually feel."}, {"time": 6419, "text": "Like this is what people experience with social media."}, {"time": 6422, "text": "They look back at the previous month and say, I felt shitty on a lot of days because of social media."}, {"time": 6431, "text": "If you look back at the previous few weeks and say, wow, I'm a better person because of that month happened."}, {"time": 6438, "text": "That's, they immediately choose the product that's going to lead to that."}, {"time": 6442, "text": "That's what love for products looks like."}, {"time": 6444, "text": "If you love, like a lot of people love their Tesla car, like that's, or iPhone or like beautiful design."}, {"time": 6451, "text": "That's what love looks like."}, {"time": 6453, "text": "You look back, I'm a better person for having used this thing."}, {"time": 6456, "text": "Well, you got to ask yourself the question though, if this is such a great business model, why isn't it devolving?"}, {"time": 6462, "text": "Why don't we see it?"}, {"time": 6464, "text": "Honestly, it's competence."}, {"time": 6466, "text": "It's like people are just, it's not easy to build new, it's not easy to build products, tools, systems on new ideas."}, {"time": 6477, "text": "It's kind of a new idea."}, {"time": 6479, "text": "We've gone through this, everything we're seeing now comes from the ideas of the initial birth of the internet."}, {"time": 6486, "text": "There just needs to be new sets of tools that are incentivizing long term personal growth and happiness."}, {"time": 6494, "text": "Right, but what we have is a market that doesn't favor this, right?"}, {"time": 6498, "text": "I mean, for one thing, we had an alternative to Facebook, right, that looked, you owned your own data, it wasn't exploitative and Facebook bought a huge interest in it and it died."}, {"time": 6512, "text": "I mean, who do you know who's on diaspora?"}, {"time": 6514, "text": "The execution there was not good."}, {"time": 6517, "text": "Right, but it could have gotten better, right?"}, {"time": 6520, "text": "I don't think that the argument that why hasn't somebody done it a good argument for it's not going to completely destroy all of Twitter and Facebook when somebody does it or Twitter will catch up and pivot to the algorithm."}, {"time": 6534, "text": "This is not what I'm saying."}, {"time": 6536, "text": "There's obviously great ideas that remain unexplored because nobody has gotten to the foothill that would allow you to explore them."}, {"time": 6543, "text": "That's true, but you know, an internet that was non predatory is an obvious idea and many of us know that we want it and many of us have seen prototypes of it and we don't move because there's no audience there."}, {"time": 6555, "text": "So the network effects cause you to stay with the predatory internet."}, {"time": 6559, "text": "But let me just, I wasn't kidding about build the system in which your idea is a great business plan."}, {"time": 6568, "text": "So in our upcoming book, Heather and I in our last chapter explore something called the fourth frontier and fourth frontier has to do with sort of a 2.0 version of civilization, which we freely admit we can't tell you very much about."}, {"time": 6582, "text": "It's something that would have to be, we would have to prototype our way there."}, {"time": 6585, "text": "We would have to effectively navigate our way there."}, {"time": 6588, "text": "But the result would be very much like what you're describing."}, {"time": 6591, "text": "It would be something that effectively liberates humans meaningfully and most importantly, it has to feel like growth without depending on growth."}, {"time": 6602, "text": "In other words, human beings are creatures that like every other creature is effectively looking for growth, right?"}, {"time": 6609, "text": "We are looking for underexploited or unexploited opportunities and when we find them, our ancestors for example, they happen into a new valley that was unexplored by people."}, {"time": 6620, "text": "Their population would grow until it hit carrying capacity."}, {"time": 6623, "text": "So there would be this great feeling of there's abundance until you hit carrying capacity, which is inevitable and then zero sum dynamics would set in."}, {"time": 6630, "text": "So in order for human beings to flourish longterm, the way to get there is to satisfy the desire for growth without hooking it to actual growth, which only moves and fits and starts."}, {"time": 6642, "text": "And this is actually, I believe the key to avoiding these spasms of human tragedy when in the absence of growth, people do something that causes their population to experience growth, which is they go and make war on or commit genocide against some other population, which is something we obviously have to stop."}, {"time": 6662, "text": "By the way, this is a hunter gatherers guide to the 21st century coauthored."}, {"time": 6669, "text": "With your wife, Heather, being released in September."}, {"time": 6671, "text": "I believe you said you're going to do a little bit of a preview videos on each chapter leading up to the release."}, {"time": 6677, "text": "So I'm looking forward to the last chapter as well as all the previous ones."}, {"time": 6683, "text": "I have a few questions on that."}, {"time": 6684, "text": "So you generally have faith to clarify that technology could be the thing that empowers this kind of future."}, {"time": 6696, "text": "Well, if you just let technology evolve, it's going to be our undoing, right?"}, {"time": 6703, "text": "One of the things that I fault my libertarian friends for is this faith that the market is going to find solutions without destroying us."}, {"time": 6712, "text": "And my sense is I'm a very strong believer in markets."}, {"time": 6716, "text": "I believe in their power even above some market fundamentalists."}, {"time": 6720, "text": "But what I don't believe is that they should be allowed to plot our course, right?"}, {"time": 6726, "text": "Markets are very good at figuring out how to do things."}, {"time": 6729, "text": "They are not good at all about figuring out what we should do, right?"}, {"time": 6733, "text": "What we should want."}, {"time": 6734, "text": "We have to tell markets what we want and then they can tell us how to do it best."}, {"time": 6739, "text": "And if we adopted that kind of pro market but in a context where it's not steering, where human wellbeing is actually the driver, we can do remarkable things."}, {"time": 6750, "text": "And the technology that emerges would naturally be enhancing of human wellbeing."}, {"time": 6755, "text": "Perfectly so?"}, {"time": 6756, "text": "No, but overwhelmingly so."}, {"time": 6758, "text": "But at the moment, markets are finding our every defective character and exploiting them and making huge profits and making us worse to each other in the process."}, {"time": 6769, "text": "Before we leave COVID 19, let me ask you about a very difficult topic, which is the vaccines."}, {"time": 6780, "text": "So I took the Pfizer vaccine, the two shots."}, {"time": 6785, "text": "You did not."}, {"time": 6787, "text": "You have been taking ivermectin."}, {"time": 6792, "text": "So one of the arguments against the discussion of ivermectin is that it prevents people from being fully willing to get the vaccine."}, {"time": 6804, "text": "How would you compare ivermectin and the vaccine for COVID 19?"}, {"time": 6811, "text": "All right, that's a good question."}, {"time": 6813, "text": "I would say, first of all, there are some hazards with the vaccine that people need to be aware of."}, {"time": 6818, "text": "There are some things that we cannot rule out and for which there is some evidence."}, {"time": 6824, "text": "The two that I think people should be tracking is the possibility, some would say a likelihood, that a vaccine of this nature, that is to say very narrowly focused on a single antigen, is an evolutionary pressure that will drive the emergence of variants that will escape the protection that comes from the vaccine."}, {"time": 6848, "text": "So this is a hazard."}, {"time": 6851, "text": "It is a particular hazard in light of the fact that these vaccines have a substantial number of breakthrough cases."}, {"time": 6858, "text": "So one danger is that a person who has been vaccinated will shed viruses that are specifically less visible or invisible to the immunity created by the vaccines."}, {"time": 6871, "text": "So we may be creating the next pandemic by applying the pressure of vaccines at a point that it doesn't make sense to."}, {"time": 6880, "text": "The other danger has to do with something called antibody dependent enhancement, which is something that we see in certain diseases like dengue fever."}, {"time": 6888, "text": "You may know that dengue, one gets a case, and then their second case is much more devastating."}, {"time": 6894, "text": "So break bone fever is when you get your second case of dengue, and dengue effectively utilizes the immune response that is produced by prior exposure to attack the body in ways that it is incapable of doing before exposure."}, {"time": 6908, "text": "So this is apparently, this pattern has apparently blocked past efforts to make vaccines against coronaviruses."}, {"time": 6917, "text": "Whether it will happen here or not, it is still too early to say."}, {"time": 6920, "text": "But before we even get to the question of harm done to individuals by these vaccines, we have to ask about what the overall impact is going to be."}, {"time": 6929, "text": "And it's not clear in the way people think it is that if we vaccinate enough people, the pandemic will end."}, {"time": 6935, "text": "It could be that we vaccinate people and make the pandemic worse."}, {"time": 6938, "text": "And while nobody can say for sure that that's where we're headed, it is at least something to be aware of."}, {"time": 6943, "text": "So don't vaccines usually create that kind of evolutionary pressure to create deadlier, different strains of the virus?"}, {"time": 6955, "text": "So is there something particular with these mRNA vaccines that's uniquely dangerous in this regard?"}, {"time": 6961, "text": "Well, it's not even just the mRNA vaccines."}, {"time": 6963, "text": "The mRNA vaccines and the adenovector DNA vaccine all share the same vulnerability, which is they are very narrowly focused on one subunit of the spike protein."}, {"time": 6974, "text": "So that is a very concentrated evolutionary signal."}, {"time": 6978, "text": "We are also deploying it in mid pandemic and it takes time for immunity to develop."}, {"time": 6983, "text": "So part of the problem here, if you inoculated a population before encounter with a pathogen, then there might be substantially enough immunity to prevent this phenomenon from happening."}, {"time": 6997, "text": "But in this case, we are inoculating people as they are encountering those who are sick with the disease."}, {"time": 7003, "text": "And what that means is the disease is now faced with a lot of opportunities to effectively evolutionarily practice escape strategies."}, {"time": 7012, "text": "So one thing is the timing, the other thing is the narrow focus."}, {"time": 7016, "text": "Now in a traditional vaccine, you would typically not have one antigen, right?"}, {"time": 7021, "text": "You would have basically a virus full of antigens and the immune system would therefore produce a broader response."}, {"time": 7028, "text": "So that is the case for people who have had COVID, right?"}, {"time": 7031, "text": "They have an immunity that is broader because it wasn't so focused on one part of the spike protein."}, {"time": 7037, "text": "So anyway, there is something unique here."}, {"time": 7039, "text": "So these platforms create that special hazard."}, {"time": 7041, "text": "They also have components that we haven't used before in people."}, {"time": 7046, "text": "So for example, the lipid nanoparticles that coat the RNAs are distributing themselves around the body in a way that will have unknown consequences."}, {"time": 7057, "text": "So anyway, there's reason for concern."}, {"time": 7060, "text": "Is it possible for you to steel man the argument that everybody should get vaccinated?"}, {"time": 7069, "text": "The argument that everybody should get vaccinated is that nothing is perfectly safe."}, {"time": 7074, "text": "Phase three trials showed good safety for the vaccines."}, {"time": 7125, "text": "And with the vaccine as it currently is being deployed, that is a quite a likely scenario that everything, you know, the virus will fade away."}, {"time": 7138, "text": "In the following sense that the probability that a more dangerous strain will be created is nonzero, but it's not 50%, it's something smaller."}, {"time": 7150, "text": "And so the most likely, well, I don't know, maybe you disagree with that, but the scenario we're most likely to see now that the vaccine is here is that the virus, the effects of the virus will fade away."}, {"time": 7161, "text": "First of all, I don't believe that the probability of creating a worse pandemic is low enough to discount."}, {"time": 7167, "text": "I think the probability is fairly high and frankly, we are seeing a wave of variants that we will have to do a careful analysis to figure out what exactly that has to do with campaigns of vaccination, where they have been, where they haven't been, where the variants emerged from."}, {"time": 7183, "text": "But I believe that what we are seeing is a disturbing pattern that reflects that those who were advising caution may well have been right."}, {"time": 7191, "text": "The data here, by the way, and the small tangent is terrible."}, {"time": 7195, "text": "Terrible, right."}, {"time": 7196, "text": "And why is it terrible is another question, right?"}, {"time": 7199, "text": "This is where I started getting angry."}, {"time": 7202, "text": "It's like, there's an obvious opportunity for exceptionally good data, for exceptionally rigorous, like even the self, like the website for self reporting, side effects for, not side effects, but negative effects, right?"}, {"time": 7214, "text": "Adverse events."}, {"time": 7215, "text": "Adverse events, sorry, for the vaccine."}, {"time": 7218, "text": "Like, there's many things I could say from both the study perspective, but mostly, let me just put on my hat of like HTML and like web design."}, {"time": 7229, "text": "Like, it's like the worst website."}, {"time": 7232, "text": "It makes it so unpleasant to report."}, {"time": 7234, "text": "It makes it so unclear what you're reporting."}, {"time": 7237, "text": "If somebody actually has serious effect, like if you have very mild effects, what are the incentives for you to even use that crappy website with many pages and forms that don't make any sense?"}, {"time": 7247, "text": "If you have adverse effects, what are the incentives for you to use that website?"}, {"time": 7253, "text": "What is the trust that you have that this information will be used well?"}, {"time": 7258, "text": "And the data about who's getting vaccinated, anonymized data about who's getting vaccinated, where, when, with what vaccine, coupled with the adverse effects, all of that we should be collecting."}, {"time": 7270, "text": "Instead, we're completely not."}, {"time": 7273, "text": "We're doing it in a crappy way and using that crappy data to make conclusions that you then twist."}, {"time": 7279, "text": "You're basically collecting in a way that can arrive at whatever conclusions you want."}, {"time": 7285, "text": "And the data is being collected by the institutions, by governments, and so therefore, it's obviously they're going to try to construct any kind of narratives they want based on this crappy data."}, {"time": 7296, "text": "Reminds me of much of psychology, the field that I love, but is flawed in many fundamental ways."}, {"time": 7302, "text": "So rant over, but coupled with the dangers that you're speaking to, we don't have even the data to understand the dangers."}, {"time": 7312, "text": "Yeah, I'm gonna pick up on your rant and say, we, estimates of the degree of underreporting in VAERS are that it is 10% of the real to 100%."}, {"time": 7325, "text": "And that's the system for reporting."}, {"time": 7328, "text": "Yeah, the VAERS system is the system for reporting adverse events."}, {"time": 7331, "text": "So in the US, we have above 5,000 unexpected deaths that seem in time to be associated with vaccination."}, {"time": 7342, "text": "That is an undercount, almost certainly, and by a large factor."}, {"time": 7347, "text": "We don't know how large."}, {"time": 7349, "text": "I've seen estimates, 25,000 dead in the US alone."}, {"time": 7354, "text": "Now, you can make the argument that, okay, that's a large number, but the necessity of immunizing the population to drive SARS CoV2 to extinction is such that it's an acceptable number."}, {"time": 7367, "text": "But I would point out that that actually does not make any sense."}, {"time": 7371, "text": "And the reason it doesn't make any sense is actually there are several reasons."}, {"time": 7374, "text": "One, if that was really your point, that yes, many, many people are gonna die, but many more will die if we don't do this."}, {"time": 7382, "text": "Were that your approach, you would not be inoculating people who had had COVID 19, which is a large population."}, {"time": 7390, "text": "There's no reason to expose those people to danger."}, {"time": 7393, "text": "Their risk of adverse events in the case that they have them is greater."}, {"time": 7398, "text": "So there's no reason that we would be allowing those people to face a risk of death if this was really about an acceptable number of deaths arising out of this set of vaccines."}, {"time": 7409, "text": "I would also point out there's something incredibly bizarre."}, {"time": 7412, "text": "And I struggle to find language that is strong enough for the horror of vaccinating children in this case because children suffer a greater risk of longterm effects because they are going to live longer."}, {"time": 7429, "text": "And because this is earlier in their development, therefore it impacts systems that are still forming."}, {"time": 7435, "text": "They tolerate COVID well."}, {"time": 7437, "text": "And so the benefit to them is very small."}, {"time": 7441, "text": "And so the only argument for doing this is that they may cryptically be carrying more COVID than we think, and therefore they may be integral to the way the virus spreads to the population."}, {"time": 7451, "text": "But if that's the reason that we are inoculating children, and there has been some revision in the last day or two about the recommendation on this because of the adverse events that have shown up in children, but to the extent that we were vaccinating children, we were doing it to protect old, infirm people who are the most likely to succumb to COVID 19."}, {"time": 7472, "text": "What society puts children in danger, robs children of life to save old, infirm people?"}, {"time": 7480, "text": "That's upside down."}, {"time": 7483, "text": "So there's something about the way we are going about vaccinating, who we are vaccinating, what dangers we are pretending don't exist that suggests that to some set of people, vaccinating people is a good in and of itself, that that is the objective of the exercise, not herd immunity."}, {"time": 7501, "text": "And the last thing, and I'm sorry, I don't wanna prevent you from jumping in here, but the second reason, in addition to the fact that we're exposing people to danger that we should not be exposing them to."}, {"time": 7511, "text": "By the way, as a tiny tangent, another huge part of this soup that should have been part of it that's an incredible solution is large scale testing."}, {"time": 7522, "text": "But that might be another couple hour conversation, but there's these solutions that are obvious that were available from the very beginning."}, {"time": 7530, "text": "So you could argue that iveractin is not that obvious, but maybe the whole point is you have aggressive, very fast research that leads to a meta analysis and then large scale production and deployment."}, {"time": 7546, "text": "Okay, at least that possibility should be seriously considered, coupled with a serious consideration of large scale deployment of testing, at home testing that could have accelerated the speed at which we reached that herd immunity."}, {"time": 7567, "text": "But I don't even wanna."}, {"time": 7568, "text": "Well, let me just say, I am also completely shocked that we did not get on high quality testing early and that we are still suffering from this even now, because just the simple ability to track where the virus moves between people would tell us a lot about its mode of transmission, which would allow us to protect ourselves better."}, {"time": 7588, "text": "Instead, that information was hard won and for no good reason."}, {"time": 7593, "text": "So I also find this mysterious."}, {"time": 7595, "text": "You've spoken with Eric Weinstein, your brother, on his podcast, The Portal, about the ideas that eventually led to the paper you published titled, The Reserved Capacity Hypothesis."}, {"time": 7610, "text": "I think first, can you explain this paper and the ideas that led up to it?"}, {"time": 7619, "text": "Sure, easier to explain the conclusion of the paper."}, {"time": 7625, "text": "There's a question about why a creature that can replace its cells with new cells grows feeble and inefficient with age."}, {"time": 7634, "text": "We call that process, which is otherwise called aging, we call it senescence."}, {"time": 7640, "text": "And senescence, in this paper, it is hypothesized, is the unavoidable downside of a cancer prevention feature of our bodies."}, {"time": 7656, "text": "That each cell has a limit on the number of times it can divide."}, {"time": 7660, "text": "There are a few cells in the body that are exceptional, but most of our cells can only divide a limited number of times."}, {"time": 7666, "text": "That's called the Hayflick limit."}, {"time": 7667, "text": "And the Hayflick limit reduces the ability of the organism to replace tissues."}, {"time": 7675, "text": "It therefore results in a failure over time of maintenance and repair."}, {"time": 7681, "text": "And that explains why we become decrepit as we grow old."}, {"time": 7686, "text": "The question was why would that be, especially in light of the fact that the mechanism that seems to limit the ability of cells to reproduce is something called a telomere."}, {"time": 7698, "text": "Telomere is a, it's not a gene, but it's a DNA sequence at the ends of our chromosomes that is just simply repetitive."}, {"time": 7706, "text": "And the number of repeats functions like a counter."}, {"time": 7710, "text": "So there's a number of repeats that you have after development is finished."}, {"time": 7714, "text": "And then each time the cell divides a little bit of telomere is lost."}, {"time": 7717, "text": "And at the point that the telomere becomes critically short, the cell stops dividing even though it still has the capacity to do so."}, {"time": 7724, "text": "Stops dividing and it starts transcribing different genes than it did when it had more telomere."}, {"time": 7730, "text": "So what my work did was it looked at the fact that the telomeric shortening was being studied by two different groups."}, {"time": 7737, "text": "It was being studied by people who were interested in counteracting the aging process."}, {"time": 7743, "text": "And it was being studied in exactly the opposite fashion by people who were interested in tumorigenesis and cancer."}, {"time": 7750, "text": "The thought being because it was true that when one looked into tumors, they always had telomerase active."}, {"time": 7756, "text": "That's the enzyme that lengthens our telomeres."}, {"time": 7759, "text": "So those folks were interested in bringing about a halt to the lengthening of telomeres in order to counteract cancer."}, {"time": 7767, "text": "And the folks who were studying the senescence process were interested in lengthening telomeres in order to generate greater repair capacity."}, {"time": 7775, "text": "And my point was evolutionarily speaking, this looks like a pleiotropic effect that the genes which create the tendency of the cells to be limited in their capacity to replace themselves are providing a benefit in youth, which is that we are largely free of tumors and cancer at the inevitable late life cost that we grow feeble and inefficient and eventually die."}, {"time": 7804, "text": "And that matches a very old hypothesis in evolutionary theory by somebody I was fortunate enough to know, George Williams, one of the great 20th century evolutionists who argued that senescence would have to be caused by pleiotropic genes that cause early life benefits at unavoidable late life costs."}, {"time": 7826, "text": "And although this isn't the exact nature of the system, he predicted it matches what he was expecting in many regards to a shocking degree."}, {"time": 7835, "text": "That said, the focus of the paper is about the, well, let me just read the abstract."}, {"time": 7843, "text": "We observed that captive rodent breeding protocols designed, this is the end of the abstract."}, {"time": 7849, "text": "We observed that captive rodent breeding protocols designed to increase reproductive output, simultaneously exert strong selection against reproductive senescence and virtually eliminate selection that would otherwise favor tumor suppression."}, {"time": 7863, "text": "This appears to have greatly elongated the telomeres of laboratory mice."}, {"time": 7867, "text": "With their telomeric failsafe effectively disabled, these animals are unreliable models of normal senescence and tumor formation."}, {"time": 7875, "text": "So basically using these mice is not going to lead to the right kinds of conclusions."}, {"time": 7881, "text": "Safety tests employing these animals likely overestimate cancer risks and underestimate tissue damage and consequent accelerated senescence."}, {"time": 7892, "text": "So I think, especially with your discussion with Eric, the conclusion of this paper has to do with the fact that, like we shouldn't be using these mice to test the safety or to make conclusions about cancer or senescence."}, {"time": 7913, "text": "Is that the basic takeaway?"}, {"time": 7915, "text": "Like basically saying that the length of these telomeres is an important variable to consider."}, {"time": 7921, "text": "I think there was a reason that the world of scientists who was working on telomeres did not spot the pleiotropic relationship that was the key argument in my paper."}, {"time": 7936, "text": "The reason they didn't spot it was that there was a result that everybody knew, which seemed inconsistent."}, {"time": 7942, "text": "The result was that mice have very long telomeres, but they do not have very long lives."}, {"time": 7950, "text": "Now, we can talk about what the actual meaning of don't have very long lives is, but in the end, I was confronted with a hypothesis that would explain a great many features of the way mammals and indeed vertebrates age, but it was inconsistent with one result."}, {"time": 7966, "text": "And at first I thought, maybe there's something wrong with the result."}, {"time": 7970, "text": "Maybe this is one of these cases where the result was achieved once through some bad protocol and everybody else was repeating it, didn't turn out to be the case."}, {"time": 7978, "text": "Many laboratories had established that mice had ultra long telomeres."}, {"time": 7982, "text": "And so I began to wonder whether or not there was something about the breeding protocols that generated these mice."}, {"time": 7991, "text": "And what that would predict is that the mice that have long telomeres would be laboratory mice and that wild mice would not."}, {"time": 7998, "text": "And Carol Greider, who agreed to collaborate with me, tested that hypothesis and showed that it was indeed true, that wild derived mice, or at least mice that had been in captivity for a much shorter period of time did not have ultra long telomeres."}, {"time": 8015, "text": "Now, what this implied though, as you read, is that our breeding protocols generate lengthening of telomeres."}, {"time": 8023, "text": "And the implication of that is that the animals that have these very long telomeres will be hyper prone to create tumors."}, {"time": 8030, "text": "They will be extremely resistant to toxins because they have effectively an infinite capacity to replace any damaged tissue."}, {"time": 8038, "text": "And so ironically, if you give one of these ultra long telomere lab mice a toxin, if the toxin doesn't outright kill it, it may actually increase its lifespan because it functions as a kind of chemotherapy."}, {"time": 8054, "text": "So the reason that chemotherapy works is that dividing cells are more vulnerable than cells that are not dividing."}, {"time": 8061, "text": "And so if this mouse has effectively had its cancer protection turned off, and it has cells dividing too rapidly, and you give it a toxin, you will slow down its tumors faster than you harm its other tissues."}, {"time": 8073, "text": "And so you'll get a paradoxical result that actually some drug that's toxic seems to benefit the mouse."}, {"time": 8080, "text": "Now, I don't think that that was understood before I published my paper."}, {"time": 8084, "text": "Now I'm pretty sure it has to be."}, {"time": 8086, "text": "And the problem is that this actually is a system that serves pharmaceutical companies that have the difficult job of bringing compounds to market, many of which will be toxic."}, {"time": 8099, "text": "Maybe all of them will be toxic."}, {"time": 8101, "text": "And these mice predispose our system to declare these toxic compounds safe."}, {"time": 8107, "text": "And in fact, I believe we've seen the errors that result from using these mice a number of times, most famously with Vioxx, which turned out to do conspicuous heart damage."}, {"time": 8118, "text": "Why do you think this paper and this idea has not gotten significant traction?"}, {"time": 8123, "text": "Well, my collaborator, Carol Greider, said something to me that rings in my ears to this day."}, {"time": 8132, "text": "She initially, after she showed that laboratory mice have anomalously long telomeres and that wild mice don't have long telomeres, I asked her where she was going to publish that result so that I could cite it in my paper."}, {"time": 8144, "text": "And she said that she was going to keep the result in house rather than publish it."}, {"time": 8149, "text": "And at the time, I was a young graduate student."}, {"time": 8154, "text": "I didn't really understand what she was saying."}, {"time": 8156, "text": "But in some sense, the knowledge that a model organism is broken in a way that creates the likelihood that certain results will be reliably generateable, you can publish a paper and make a big splash with such a thing, or you can exploit the fact that you know how those models will misbehave and other people don't."}, {"time": 8177, "text": "So there's a question, if somebody is motivated cynically and what they want to do is appear to have deeper insight into biology because they predict things better than others do, knowing where the flaw is so that your predictions come out true is advantageous."}, {"time": 8194, "text": "At the same time, I can't help but imagine that the pharmaceutical industry, when it figured out that the mice were predisposed to suggest that drugs were safe, didn't leap to fix the problem because in some sense, it was the perfect cover for the difficult job of bringing drugs to market and then discovering their actual toxicity profile, right?"}, {"time": 8217, "text": "This made things look safer than they were and I believe a lot of profits have likely been generated downstream."}, {"time": 8224, "text": "So to kind of play devil's advocate, it's also possible that this particular, the length of the telomeres is not a strong variable for the drug development and for the conclusions that Carol and others have been studying."}, {"time": 8238, "text": "Is it possible for that to be the case?"}, {"time": 8242, "text": "So one reason she and others could be ignoring this is because it's not a strong variable."}, {"time": 8249, "text": "Well, I don't believe so and in fact, at the point that I went to publish my paper, Carol published her result."}, {"time": 8256, "text": "She did so in a way that did not make a huge splash."}, {"time": 8259, "text": "Did she, I apologize if I don't know how, what was the emphasis of her publication of that paper?"}, {"time": 8269, "text": "Was it purely just kind of showing data or is there more, because in your paper, there's a kind of more of a philosophical statement as well."}, {"time": 8277, "text": "Well, my paper was motivated by interest in the evolutionary dynamics around senescence."}, {"time": 8283, "text": "I wasn't pursuing grants or anything like that."}, {"time": 8287, "text": "I was just working on a puzzle I thought was interesting."}, {"time": 8290, "text": "Carol has, of course, gone on to win a Nobel Prize for her co discovery with Elizabeth Greider of telomerase, the enzyme that lengthens telomeres."}, {"time": 8301, "text": "But anyway, she's a heavy hitter in the academic world."}, {"time": 8305, "text": "I don't know exactly what her purpose was."}, {"time": 8307, "text": "I do know that she told me she wasn't planning to publish and I do know that I discovered that she was in the process of publishing very late and when I asked her to send me the paper to see whether or not she had put evidence in it that the hypothesis had come from me, she grudgingly sent it to me and my name was nowhere mentioned and she broke contact at that point."}, {"time": 8330, "text": "What it is that motivated her, I don't know, but I don't think it can possibly be that this result is unimportant."}, {"time": 8337, "text": "The fact is, the reason I called her in the first place, an established contact that generated our collaboration, was that she was a leading light in the field of telomeric studies and because of that, this question about whether the model organisms are distorting the understanding of the functioning of telomeres, it's central."}, {"time": 8360, "text": "Do you feel like you've been, as a young graduate student, do you think Carol or do you think the scientific community broadly screwed you over in some way?"}, {"time": 8371, "text": "I don't think of it in those terms."}, {"time": 8373, "text": "Probably partly because it's not productive but I have a complex relationship with this story."}, {"time": 8382, "text": "On the one hand, I'm livid with Carol Greider for what she did."}, {"time": 8386, "text": "She absolutely pretended that I didn't exist in this story and I don't think I was a threat to her."}, {"time": 8391, "text": "My interest was as an evolutionary biologist, I had made an evolutionary contribution, she had tested a hypothesis and frankly, I think it would have been better for her if she had acknowledged what I had done."}, {"time": 8403, "text": "I think it would have enhanced her work and I was, let's put it this way, when I watched her Nobel lecture, and I should say there's been a lot of confusion about this Nobel stuff."}, {"time": 8415, "text": "I've never said that I should have gotten a Nobel prize."}, {"time": 8417, "text": "People have misportrayed that."}, {"time": 8423, "text": "In listening to her lecture, I had one of the most bizarre emotional experiences of my life because she presented the work that resulted from my hypothesis."}, {"time": 8435, "text": "She presented it as she had in her paper with no acknowledgement of where it had come from and she had in fact portrayed the distortion of the telomeres as if it were a lucky fact because it allowed testing hypotheses that would otherwise not be testable."}, {"time": 8455, "text": "You have to understand as a young scientist to watch work that you have done presented in what's surely the most important lecture of her career, it's thrilling."}, {"time": 8471, "text": "It was thrilling to see her figures projected on the screen there."}, {"time": 8478, "text": "To have been part of work that was important enough for that felt great and of course, to be erased from the story felt absolutely terrible."}, {"time": 8487, "text": "So anyway, that's sort of where I am with it."}, {"time": 8490, "text": "My sense is what I'm really troubled by in this story is the fact that as far as I know, the flaw with the mice has not been addressed."}, {"time": 8505, "text": "And actually, Eric did some looking into this."}, {"time": 8508, "text": "He tried to establish by calling the Jack's lab and trying to ascertain what had happened with the colonies, whether any change in protocol had occurred and he couldn't get anywhere."}, {"time": 8518, "text": "There was seemingly no awareness that it was even an issue."}, {"time": 8522, "text": "So I'm very troubled by the fact that as a father, for example, I'm in no position to protect my family from the hazard that I believe lurks in our medicine cabinets, right?"}, {"time": 8535, "text": "Even though I'm aware of where the hazard comes from, it doesn't tell me anything useful about which of these drugs will turn out to do damage if that is ultimately tested."}, {"time": 8543, "text": "And that's a very frustrating position to be in."}, {"time": 8546, "text": "On the other hand, there's a part of me that's even still grateful to Carol for taking my call."}, {"time": 8551, "text": "She didn't have to take my call and talk to some young graduate student who had some evolutionary idea that wasn't in her wheelhouse specifically, and yet she did."}, {"time": 8561, "text": "And for a while, she was a good collaborator, so."}, {"time": 8564, "text": "Well, can I, I have to proceed carefully here because it's a complicated topic."}, {"time": 8572, "text": "So she took the call."}, {"time": 8575, "text": "And you kind of, you're kind of saying that she basically erased credit, you know, pretending you didn't exist in some kind of, in a certain sense."}, {"time": 8591, "text": "Let me phrase it this way."}, {"time": 8592, "text": "I've, as a research scientist at MIT, I've had, and especially just part of a large set of collaborations, I've had a lot of students come to me and talk to me about ideas, perhaps less interesting than what we're discussing here in the space of AI, that I've been thinking about anyway."}, {"time": 8618, "text": "In general, with everything I'm doing with robotics, people have told me a bunch of ideas that I'm already thinking about."}, {"time": 8629, "text": "The point is taking that idea, see, this is different because the idea has more power in the space that we're talking about here, and robotics is like your idea means shit until you build it."}, {"time": 8640, "text": "Like, so the engineering world is a little different, but there's a kind of sense that I probably forgot a lot of brilliant ideas have been told to me."}, {"time": 8651, "text": "Do you think she pretended you don't exist?"}, {"time": 8654, "text": "Do you think she was so busy that she kind of forgot, you know, that she has like the stream of brilliant people around her, there's a bunch of ideas that are swimming in the air, and you just kind of forget people that are a little bit on the periphery on the idea generation, like, or is it some mix of both?"}, {"time": 8674, "text": "It's not a mix of both."}, {"time": 8676, "text": "I know that because we corresponded."}, {"time": 8679, "text": "She put a graduate student on this work."}, {"time": 8681, "text": "He emailed me excitedly when the results came in."}, {"time": 8686, "text": "So there was no ambiguity about what had happened."}, {"time": 8690, "text": "What's more, when I went to publish my work, I actually sent it to Carol in order to get her feedback because I wanted to be a good collaborator to her, and she absolutely panned it, made many critiques that were not valid, but it was clear at that point that she became an antagonist, and none of this adds up."}, {"time": 8712, "text": "She couldn't possibly have forgotten the conversation."}, {"time": 8716, "text": "I believe I even sent her tissues at some point in part, not related to this project, but as a favor."}, {"time": 8723, "text": "She was doing another project that involved telomeres, and she needed samples that I could get ahold of because of the Museum of Zoology that I was in."}, {"time": 8730, "text": "So this was not a one off conversation."}, {"time": 8734, "text": "I certainly know that those sorts of things can happen, but that's not what happened here."}, {"time": 8737, "text": "This was a relationship that existed and then was suddenly cut short at the point that she published her paper by surprise without saying where the hypothesis had come from and began to be a opposing force to my work."}, {"time": 8754, "text": "Is there, there's a bunch of trajectories you could have taken through life."}, {"time": 8758, "text": "Do you think about the trajectory of being a researcher, of then going to war in the space of ideas, of publishing further papers along this line?"}, {"time": 8773, "text": "I mean, that's often the dynamic of that fascinating space is you have a junior researcher with brilliant ideas and a senior researcher that starts out as a mentor that becomes a competitor."}, {"time": 8786, "text": "I mean, that happens."}, {"time": 8787, "text": "But then the way to, it's almost an opportunity to shine is to publish a bunch more papers in this place to tear it apart, to dig into, like really make it a war of ideas."}, {"time": 8802, "text": "Did you consider that possible trajectory?"}, {"time": 8806, "text": "A couple of things to say about it."}, {"time": 8808, "text": "One, this work was not central for me."}, {"time": 8811, "text": "I took a year on the T. Lemire project because something fascinating occurred to me and I pursued it."}, {"time": 8818, "text": "And the more I pursued it, the clearer it was there was something there."}, {"time": 8821, "text": "But it wasn't the focus of my graduate work."}, {"time": 8823, "text": "And I didn't want to become a T. Lemire researcher."}, {"time": 8828, "text": "What I want to do is to be an evolutionary biologist who upgrades the toolkit of evolutionary concepts so that we can see more clearly how organisms function and why."}, {"time": 8840, "text": "And T. Lemire's was a proof of concept, right?"}, {"time": 8844, "text": "That paper was a proof of concept that the toolkit in question works."}, {"time": 8850, "text": "As for the need to pursue it further, I think it's kind of absurd and you're not the first person to say maybe that was the way to go about it."}, {"time": 8860, "text": "But the basic point is, look, the work was good."}, {"time": 8863, "text": "It turned out to be highly predictive."}, {"time": 8867, "text": "Frankly, the model of senescence that I presented is now widely accepted."}, {"time": 8872, "text": "And I don't feel any misgivings at all about having spent a year on it, said my piece, and moved on to other things which frankly I think are bigger."}, {"time": 8882, "text": "I think there's a lot of good to be done and it would be a waste to get overly narrowly focused."}, {"time": 8888, "text": "There's so many ways through the space of science and the most common ways is just publish a lot."}, {"time": 8896, "text": "Just publish a lot of papers, do these incremental work and exploring the space kind of like ants looking for food."}, {"time": 8904, "text": "You're tossing out a bunch of different ideas."}, {"time": 8906, "text": "Some of them could be brilliant breakthrough ideas, nature."}, {"time": 8909, "text": "Some of them are more confidence kind of publications, all those kinds of things."}, {"time": 8913, "text": "Did you consider that kind of path in science?"}, {"time": 8918, "text": "Of course I considered it, but I must say the experience of having my first encounter with the process of peer review be this story, which was frankly a debacle from one end to the other with respect to the process of publishing."}, {"time": 8935, "text": "It did not, it was not a very good sales pitch for trying to make a difference through publication."}, {"time": 8941, "text": "And I would point out part of what I ran into and I think frankly part of what explains Carol's behavior is that in some parts of science, there is this dynamic where PIs parasitize their underlings and if you're very, very good, you rise to the level where one day instead of being parasitized, you get to parasitize others."}, {"time": 8965, "text": "Now I find that scientifically despicable and it wasn't the culture of the lab I grew up in at all."}, {"time": 9003, "text": "So anyway, my point would be, I wasn't up for being parasitized."}, {"time": 9011, "text": "I don't like the idea that if you are very good, you get parasitized until it's your turn to parasitize others."}, {"time": 9017, "text": "That doesn't make sense to me."}, {"time": 9021, "text": "Crossing over from evolution into cellular biology may have exposed me to that."}, {"time": 9025, "text": "That may have been par for the course, but it doesn't make it acceptable."}, {"time": 9029, "text": "And I would also point out that my work falls in the realm of synthesis."}, {"time": 9036, "text": "My work generally takes evidence accumulated by others and places it together in order to generate hypotheses that explain sets of phenomena that are otherwise intractable."}, {"time": 9051, "text": "And I am not sure that that is best done with narrow publications that are read by few."}, {"time": 9059, "text": "And in fact, I would point to the very conspicuous example of Richard Dawkins, who I must say I've learned a tremendous amount from and I greatly admire."}, {"time": 9067, "text": "Dawkins has almost no publication record in the sense of peer reviewed papers in journals."}, {"time": 9075, "text": "What he's done instead is done synthetic work and he's published it in books, which are not peer reviewed in the same sense."}, {"time": 9082, "text": "And frankly, I think there's no doubting his contribution to the field."}, {"time": 9087, "text": "So my sense is if Richard Dawkins can illustrate that one can make contributions to the field without using journals as the primary mechanism for distributing what you've come to understand, then it's obviously a valid mechanism and it's a far better one from the point of view of accomplishing what I want to accomplish."}, {"time": 9107, "text": "There is of course several levels you can do the kind of synthesis and that does require a lot of both broad and deep thinking is exceptionally valuable."}, {"time": 9116, "text": "You could also, I'm working on something with Andrew Huberman now, you can also publish synthesis."}, {"time": 9122, "text": "That's like review papers that are exceptionally valuable for the communities."}, {"time": 9126, "text": "It brings the community together, tells a history, tells a story of where the community has been."}, {"time": 9131, "text": "It paints a picture of where the path lays for the future."}, {"time": 9134, "text": "I think it's really valuable."}, {"time": 9135, "text": "And Richard Dawkins is a good example of somebody that does that in book form that he kind of walks the line really interestingly."}, {"time": 9143, "text": "You have like somebody who like Neil deGrasse Tyson, who's more like a science communicator."}, {"time": 9148, "text": "Richard Dawkins sometimes is a science communicator, but he gets like close to the technical to where it's a little bit, it's not shying away from being really a contribution to science."}, {"time": 9161, "text": "No, he's made real contributions."}, {"time": 9164, "text": "In book form."}, {"time": 9165, "text": "Yes, he really has."}, {"time": 9167, "text": "I mean, Roger Penrose, I mean, similar kind of idea."}, {"time": 9171, "text": "That's interesting, that's interesting."}, {"time": 9173, "text": "Synthesis does not, especially synthesis work, work that synthesizes ideas does not necessarily need to be peer reviewed."}, {"time": 9183, "text": "It's peer reviewed by peers reading it."}, {"time": 9188, "text": "Well, and reviewing it."}, {"time": 9190, "text": "That's it, it is reviewed by peers, which is not synonymous with peer review."}, {"time": 9193, "text": "And that's the thing is people don't understand that the two things aren't the same, right?"}, {"time": 9197, "text": "Peer review is an anonymous process that happens before publication in a place where there is a power dynamic, right?"}, {"time": 9206, "text": "I mean, the joke of course is that peer review is actually peer preview, right?"}, {"time": 9210, "text": "Your biggest competitors get to see your work before it sees the light of day and decide whether or not it gets published."}, {"time": 9217, "text": "And again, when your formative experience with the publication apparatus is the one I had with the telomere paper, there's no way that that seems like the right way to advance important ideas."}, {"time": 9230, "text": "And what's the harm in publishing them so that your peers have to review them in public where they actually, if they're gonna disagree with you, they actually have to take the risk of saying, I don't think this is right and here's why, right?"}, {"time": 9243, "text": "With their name on it."}, {"time": 9244, "text": "I'd much rather that."}, {"time": 9245, "text": "It's not that I don't want my work reviewed by peers, but I want it done in the open, you know, for the same reason you don't meet with dangerous people in private, you meet at the cafe."}, {"time": 9254, "text": "I want the work reviewed out in public."}, {"time": 9258, "text": "Can I ask you a difficult question?"}, {"time": 9263, "text": "There is popularity in martyrdom."}, {"time": 9266, "text": "There's popularity in pointing out that the emperor has no clothes."}, {"time": 9273, "text": "That can become a drug in itself."}, {"time": 9280, "text": "I've confronted this in scientific work I've done at MIT where there are certain things that are not done well."}, {"time": 9289, "text": "People are not being the best version of themselves."}, {"time": 9292, "text": "And particular aspects of a particular field are in need of a revolution."}, {"time": 9302, "text": "And part of me wanted to point that out versus doing the hard work of publishing papers and doing the revolution."}, {"time": 9313, "text": "Basically just pointing out, look, you guys are doing it wrong and then just walking away."}, {"time": 9319, "text": "Are you aware of the drug of martyrdom, of the ego involved in it, that it can cloud your thinking?"}, {"time": 9332, "text": "Probably one of the best questions I've ever been asked."}, {"time": 9335, "text": "So let me try to sort it out."}, {"time": 9339, "text": "First of all, we are all mysteries to ourself at some level."}, {"time": 9343, "text": "So it's possible there's stuff going on in me that I'm not aware of that's driving."}, {"time": 9348, "text": "But in general, I would say one of my better strengths is that I'm not especially ego driven."}, {"time": 9355, "text": "I have an ego, I clearly think highly of myself, but it is not driving me."}, {"time": 9360, "text": "I do not crave that kind of validation."}, {"time": 9363, "text": "I do crave certain things."}, {"time": 9365, "text": "I do love a good eureka moment."}, {"time": 9367, "text": "There is something great about it."}, {"time": 9369, "text": "And there's something even better about the phone calls you make next when you share it, right?"}, {"time": 9374, "text": "It's pretty fun, right?"}, {"time": 9375, "text": "I really like it."}, {"time": 9377, "text": "I also really like my subject, right?"}, {"time": 9380, "text": "There's something about a walk in the forest when you have a toolkit in which you can actually look at creatures and see something deep, right?"}, {"time": 9390, "text": "I like it, that drives me."}, {"time": 9393, "text": "And I could entertain myself for the rest of my life, right?"}, {"time": 9395, "text": "If I was somehow isolated from the rest of the world, but I was in a place that was biologically interesting, hopefully I would be with people that I love and pets that I love, believe it or not."}, {"time": 9408, "text": "But if I were in that situation and I could just go out every day and look at cool stuff and figure out what it means, I could be all right with that."}, {"time": 9416, "text": "So I'm not heavily driven by the ego thing, as you put it."}, {"time": 9422, "text": "So I am completely the same except instead of the pets, I would put robots."}, {"time": 9428, "text": "But so it's not, it's the eureka, it's the exploration of the subject that brings you joy and fulfillment."}, {"time": 9436, "text": "It's not the ego."}, {"time": 9437, "text": "Well, there's more to say."}, {"time": 9438, "text": "No, I really don't think it's the ego thing."}, {"time": 9441, "text": "I will say I also have kind of a secondary passion for robot stuff."}, {"time": 9445, "text": "I've never made anything useful, but I do believe, I believe I found my calling."}, {"time": 9450, "text": "But if this wasn't my calling, my calling would have been inventing stuff."}, {"time": 9454, "text": "I really enjoy that too."}, {"time": 9456, "text": "So I get what you're saying about the analogy quite well."}, {"time": 9459, "text": "But as far as the martyrdom thing, I understand the drug you're talking about and I've seen it more than I've felt it."}, {"time": 9471, "text": "I do, if I'm just to be completely candid and this question is so good, it deserves a candid answer."}, {"time": 9477, "text": "I do like the fight, right?"}, {"time": 9481, "text": "I like fighting against people I don't respect and I like winning, but I have no interest in martyrdom."}, {"time": 9490, "text": "One of the reasons I have no interest in martyrdom is that I'm having too good a time, right?"}, {"time": 9495, "text": "I very much enjoy my life and."}, {"time": 9497, "text": "It's such a good answer."}, {"time": 9498, "text": "I have a wonderful wife."}, {"time": 9501, "text": "I have amazing children."}, {"time": 9503, "text": "I live in a lovely place."}, {"time": 9506, "text": "I don't wanna exit any quicker than I have to."}, {"time": 9509, "text": "That said, I also believe in things and a willingness to exit if that's the only way is not exactly inviting martyrdom, but it is an acceptance that fighting is dangerous and going up against powerful forces means who knows what will come of it, right?"}, {"time": 9526, "text": "I don't have the sense that the thing is out there that used to kill inconvenient people."}, {"time": 9531, "text": "I don't think that's how it's done anymore."}, {"time": 9532, "text": "It's primarily done through destroying them reputationally, which is not something I relish the possibility of, but there is a difference between a willingness to face the hazard rather than a desire to face it because of the thrill, right?"}, {"time": 9553, "text": "For me, the thrill is in fighting when I'm in the right."}, {"time": 9559, "text": "I think I feel that that is a worthwhile way to take what I see as the kind of brutality that is built into men and to channel it to something useful, right?"}, {"time": 9573, "text": "If it is not channeled into something useful, it will be channeled into something else, so it damn well better be channeled into something useful."}, {"time": 9578, "text": "It's not motivated by fame or popularity, those kinds of things."}, {"time": 9582, "text": "It's, you know what, you're just making me realize that enjoying the fight, fighting the powerful and idea that you believe is right is a kind of optimism for the human spirit."}, {"time": 9601, "text": "It's like, we can win this."}, {"time": 9605, "text": "It's almost like you're turning into action, into personal action, this hope for humanity by saying like, we can win this."}, {"time": 9615, "text": "And that makes you feel good about the rest of humanity, that if there's people like me, then we're going to be okay."}, {"time": 9626, "text": "Even if you're like, your ideas might be wrong or not, but if you believe they're right and you're fighting the powerful against all odds, then we're going to be okay."}, {"time": 9639, "text": "If I were to project, I mean, because I enjoy the fight as well, I think that's the way I, that's what brings me joy, is it's almost like it's optimism in action."}, {"time": 9654, "text": "Well, it's a little different for me."}, {"time": 9655, "text": "And again, I think, you know, I recognize you."}, {"time": 9658, "text": "You're a familiar, your construction is familiar, even if it isn't mine, right?"}, {"time": 9663, "text": "For me, I actually expect us not to be okay."}, {"time": 9668, "text": "And I'm not okay with that."}, {"time": 9670, "text": "But what's really important, if I feel like what I've said is I don't know of any reason that it's not okay, or any reason that it's too late."}, {"time": 9679, "text": "As far as I know, we could still save humanity and we could get to the fourth frontier or something akin to it."}, {"time": 9686, "text": "But I expect us not to, I expect us to fuck it up, right?"}, {"time": 9689, "text": "I don't like that thought, but I've looked into the abyss and I've done my calculations and the number of ways we could not succeed are many and the number of ways that we could manage to get out of this very dangerous phase of history is small."}, {"time": 9704, "text": "The thing I don't have to worry about is that I didn't do enough, right?"}, {"time": 9710, "text": "That I was a coward, that I prioritized other things."}, {"time": 9717, "text": "At the end of the day, I think I will be able to say to myself, and in fact, the thing that allows me to sleep, is that when I saw clearly what needed to be done, I tried to do it to the extent that it was in my power."}, {"time": 9728, "text": "And if we fail, as I expect us to, I can't say, well, geez, that's on me, you know?"}, {"time": 9736, "text": "And frankly, I regard what I just said to you as something like a personality defect, right?"}, {"time": 9742, "text": "I'm trying to free myself from the sense that this is my fault."}, {"time": 9745, "text": "On the other hand, my guess is that personality defect is probably good for humanity, right?"}, {"time": 9751, "text": "It's a good one for me to have the externalities of it are positive, so I don't feel too bad about it."}, {"time": 9758, "text": "Yeah, that's funny, so yeah, our perspective on the world are different, but they rhyme, like you said."}, {"time": 9765, "text": "Because I've also looked into the abyss, and it kind of smiled nervously back."}, {"time": 9771, "text": "So I have a more optimistic sense that we're gonna win more than likely we're going to be okay."}, {"time": 9779, "text": "Right there with you, brother."}, {"time": 9780, "text": "I'm hoping you're right."}, {"time": 9781, "text": "I'm expecting me to be right."}, {"time": 9783, "text": "But back to Eric, you had a wonderful conversation."}, {"time": 9787, "text": "In that conversation, he played the big brother role, and he was very happy about it."}, {"time": 9793, "text": "He was self congratulatory about it."}, {"time": 9797, "text": "Can you talk to the ways in which Eric made you a better man throughout your life?"}, {"time": 9804, "text": "Yeah, hell yeah."}, {"time": 9805, "text": "I mean, for one thing, you know, Eric and I are interestingly similar in some ways and radically different in some other ways, and it's often a matter of fascination to people who know us both because almost always people meet one of us first, and they sort of get used to that thing, and then they meet the other, and it throws the model into chaos."}, {"time": 9824, "text": "But you know, I had a great advantage, which is I came second, right?"}, {"time": 9829, "text": "So although it was kind of a pain in the ass to be born into a world that had Eric in it because he's a force of nature, right?"}, {"time": 9835, "text": "It was also terrifically useful because A, he was a very awesome older brother who made interesting mistakes, learned from them, and conveyed the wisdom of what he had discovered, and that was, you know, I don't know who else ends up so lucky as to have that kind of person blazing the trail."}, {"time": 9858, "text": "It also probably, you know, my hypothesis for what birth order effects are is that they're actually adaptive, right?"}, {"time": 9867, "text": "That the reason that a second born is different than a first born is that they're not born into a world with the same niches in it, right?"}, {"time": 9875, "text": "And so the thing about Eric is he's been completely dominant in the realm of fundamental thinking, right, like what he's fascinated by is the fundamental of fundamentals, and he's excellent at it, which meant that I was born into a world where somebody was becoming excellent in that, and for me to be anywhere near the fundamental of fundamentals was going to be pointless, right?"}, {"time": 9898, "text": "I was going to be playing second fiddle forever, and I think that that actually drove me to the other end of the continuum between fundamental and emergent, and so I became fascinated with biology and have been since I was three years old, right?"}, {"time": 9913, "text": "I think Eric drove that, and I have to thank him for it because, you know, I mean."}, {"time": 9919, "text": "I never thought of, so Eric drives towards the fundamental, and you drive towards the emergent, the physics and the biology."}, {"time": 9928, "text": "Right, opposite ends of the continuum, and as Eric would be quick to point out if he was sitting here, I treat the emergent layer, I seek the fundamentals in it, which is sort of an echo of Eric's style of thinking but applied to the very far complexity."}, {"time": 9943, "text": "He's overpoweringly argues for the importance of physics, the fundamental of the fundamental."}, {"time": 9955, "text": "He's not here to defend himself."}, {"time": 9957, "text": "Is there an argument to be made against that?"}, {"time": 9960, "text": "Or biology, the emergent, the study of the thing that emerged when the fundamental acts at the cosmic scale and then builds the beautiful thing that is us is much more important."}, {"time": 9976, "text": "Psychology, biology, the systems that we're actually interacting with in this human world are much more important to understand than the low level theories of quantum mechanics and general relativity."}, {"time": 9993, "text": "Yeah, I can't say that one is more important."}, {"time": 9995, "text": "I think there's probably a different time scale."}, {"time": 9998, "text": "I think understanding the emergent layer is more often useful, but the bang for the buck at the far fundamental layer may be much greater."}, {"time": 10008, "text": "So for example, the fourth frontier, I'm pretty sure it's gonna have to be fusion powered."}, {"time": 10015, "text": "I don't think anything else will do it, but once you had fusion power, assuming we didn't just dump fusion power on the market the way we would be likely to if it was invented usefully tomorrow, but if we had fusion power and we had a little bit more wisdom than we have, you could do an awful lot."}, {"time": 10032, "text": "And that's not gonna come from people like me who look at the dynamics of it."}, {"time": 10037, "text": "Can I argue against that?"}, {"time": 10041, "text": "I think the way to unlock fusion power is through artificial intelligence."}, {"time": 10048, "text": "So I think most of the breakthrough ideas in the futures of science will be developed by AI systems."}, {"time": 10055, "text": "And I think in order to build intelligent AI systems, you have to be a scholar of the fundamental of the emergent, of biology, of the neuroscience, of the way the brain works, of intelligence, of consciousness."}, {"time": 10070, "text": "And those things, at least directly, don't have anything to do with physics."}, {"time": 10076, "text": "You're making me a little bit sad because my addiction to the aha moment thing is incompatible with outsourcing that job."}, {"time": 10086, "text": "Like the outsource thing."}, {"time": 10087, "text": "I don't wanna outsource that thing to the AI."}, {"time": 10089, "text": "You reap the moment."}, {"time": 10091, "text": "And actually, I've seen this happen before because some of the people who trained Heather and me were phylogenetic systematists, Arnold Kluge in particular."}, {"time": 10101, "text": "And the problem with systematics is that to do it right when your technology is primitive, you have to be deeply embedded in the philosophical and the logical, right?"}, {"time": 10113, "text": "Your method has to be based in the highest level of rigor."}, {"time": 10120, "text": "Once you can sequence genes, genes can spit so much data at you that you can overwhelm high quality work with just lots and lots and lots of automated work."}, {"time": 10129, "text": "And so in some sense, there's like a generation of phylogenetic systematists who are the last of the greats because what's replacing them is sequencers."}, {"time": 10139, "text": "So anyway, maybe you're right about the AI."}, {"time": 10143, "text": "And I guess I'm... What makes you sad?"}, {"time": 10146, "text": "I like figuring stuff out."}, {"time": 10147, "text": "Is there something that you disagree with the error con, even trying to convince them you failed so far, but you will eventually succeed?"}, {"time": 10158, "text": "You know, that is a very long list."}, {"time": 10160, "text": "Eric and I have tensions over certain things that recur all the time."}, {"time": 10166, "text": "And I'm trying to think what would be the ideal... Is it in the space of science, in the space of philosophy, politics, family, love, robots?"}, {"time": 10175, "text": "Well, all right, let me..."}, {"time": 10179, "text": "I'm just gonna use your podcast to make a bit of a cryptic war and just say there are many places in which I believe that I have butted heads with Eric over the course of decades and I have seen him move in my direction substantially over time."}, {"time": 10196, "text": "So you've been winning."}, {"time": 10197, "text": "He might win a battle here or there, but you've been winning the war."}, {"time": 10200, "text": "I would not say that."}, {"time": 10201, "text": "It's quite possible he could say the same thing about me."}, {"time": 10204, "text": "And in fact, I know that it's true."}, {"time": 10206, "text": "There are places where he's absolutely convinced me."}, {"time": 10208, "text": "But in any case, I do believe it's at least..."}, {"time": 10211, "text": "It may not be a totally even fight, but it's more even than some will imagine."}, {"time": 10216, "text": "But yeah, we have..."}, {"time": 10218, "text": "There are things I say that drive him nuts, right?"}, {"time": 10222, "text": "Like when something, like you heard me talk about the... What was it?"}, {"time": 10229, "text": "It was the autopilot that seems to be putting a great many humans in needless medical jeopardy over the COVID 19 pandemic."}, {"time": 10240, "text": "And my feeling is we can say this almost for sure."}, {"time": 10245, "text": "Anytime you have the appearance of some captured gigantic entity that is censoring you on YouTube and handing down dictates from the who and all of that, it is sure that there will be a certain amount of collusion, right?"}, {"time": 10261, "text": "There's gonna be some embarrassing emails in some places that are gonna reveal some shocking connections."}, {"time": 10265, "text": "And then there's gonna be an awful lot of emergence that didn't involve collusion, right?"}, {"time": 10271, "text": "In which people were doing their little part of a job and something was emerging."}, {"time": 10274, "text": "And you never know what the admixture is."}, {"time": 10276, "text": "How much are we looking at actual collusion and how much are we looking at an emergent process?"}, {"time": 10281, "text": "But you should always walk in with the sense that it's gonna be a ratio."}, {"time": 10284, "text": "And the question is, what is the ratio in this case?"}, {"time": 10287, "text": "I think this drives Eric nuts because he is very focused on the people."}, {"time": 10292, "text": "I think he's focused on the people who have a choice and make the wrong one."}, {"time": 10296, "text": "And anyway, he may."}, {"time": 10298, "text": "Discussion of the ratio is a distraction to that."}, {"time": 10301, "text": "I think he takes it almost as an offense because it grants cover to people who are harming others."}, {"time": 10311, "text": "And I think it offends him morally."}, {"time": 10316, "text": "And if I had to say, I would say it alters his judgment on the matter."}, {"time": 10322, "text": "But anyway, certainly useful just to leave open the two possibilities and say it's a ratio, but we don't know which one."}, {"time": 10330, "text": "Brother to brother, do you love the guy?"}, {"time": 10333, "text": "Hmm, hell yeah, hell yeah."}, {"time": 10335, "text": "And I'd love him if he was just my brother, but he's also awesome."}, {"time": 10339, "text": "So I love him and I love him for who he is."}, {"time": 10341, "text": "So let me ask you about back to your book, Hunter Gatherer's Guide to the 21st Century."}, {"time": 10349, "text": "I can't wait both for the book and the videos you do on the book."}, {"time": 10353, "text": "That's really exciting that there's like a structured, organized way to present this."}, {"time": 10359, "text": "A kind of from an evolutionary biology perspective, a guide for the future, using our past as the fundamental, the emergent way to present a picture of the future."}, {"time": 10376, "text": "Let me ask you about something that, I think about a little bit in this modern world, which is monogamy."}, {"time": 10387, "text": "So I personally value monogamy."}, {"time": 10390, "text": "One girl, ride or die."}, {"time": 10393, "text": "Ride or, no, that's exactly it now."}, {"time": 10395, "text": "But that said, I don't know what's the right way to approach this, but from an evolutionary biology perspective or from just looking at modern society, that seems to be an idea that's not, what's the right way to put it, flourishing?"}, {"time": 10417, "text": "It is waning."}, {"time": 10418, "text": "It's waning."}, {"time": 10421, "text": "So I suppose based on your reaction, you're also a supporter of monogamy or you value monogamy."}, {"time": 10427, "text": "Are you and I just delusional?"}, {"time": 10433, "text": "What can you say about monogamy from the context of your book, from the context of evolutionary biology, from the context of being human?"}, {"time": 10442, "text": "Yeah, I can say that I fully believe that we are actually enlightened and that although monogamy is waning, that it is not waning because there is a superior system."}, {"time": 10452, "text": "It is waning for predictable other reasons."}, {"time": 10455, "text": "So let us just say it is, there is a lot of pre trans fallacy here where people go through a phase where they recognize that actually we know a lot about the evolution of monogamy and we can tell from the fact that humans are somewhat sexually dimorphic that there has been a lot of polygyny in human history."}, {"time": 10479, "text": "And in fact, most of human history was largely polygynous."}, {"time": 10485, "text": "But it is also the case that most of the people on earth today belong to civilizations that are at least nominally monogamous and have practiced monogamy."}, {"time": 10494, "text": "And that's not anti evolutionary."}, {"time": 10498, "text": "What that is is part of what I mentioned before where human beings can swap out their software program and different mating patterns are favored in different periods of history."}, {"time": 10511, "text": "So I would argue that the benefit of monogamy, the primary one that drives the evolution of monogamous patterns in humans is that it brings all adults into child rearing."}, {"time": 10524, "text": "Now the reason that that matters is because human babies are very labor intensive."}, {"time": 10529, "text": "In order to raise them properly, having two parents is a huge asset and having more than two parents, having an extended family also very important."}, {"time": 10539, "text": "But what that means is that for a population that is expanding, a monogamous mating system makes sense."}, {"time": 10548, "text": "It makes sense because it means that the number of offspring that can be raised is elevated."}, {"time": 10552, "text": "It's elevated because all potential parents are involved in parenting."}, {"time": 10558, "text": "Whereas if you sideline a bunch of males by having a polygynous system in which one male has many females, which is typically the way that works, what you do is you sideline all those males, which means the total amount of parental effort is lower and the population can't grow."}, {"time": 10572, "text": "So what I'm arguing is that you should expect to see populations that face the possibility of expansion endorse monogamy."}, {"time": 10581, "text": "And at the point that they have reached carrying capacity, you should expect to see polygyny break back out."}, {"time": 10586, "text": "And what we are seeing is a kind of false sophistication around polyamory, which will end up breaking down into polygyny, which will not be in the interest of most people."}, {"time": 10597, "text": "Really the only people whose interest it could be argued to be in would be the very small number of males at the top who have many partners and everybody else suffers."}, {"time": 10608, "text": "Is it possible to make the argument if we focus in on those males at the quote unquote top with many female partners, is it possible to say that that's a suboptimal life, that a single partner is the optimal life?"}, {"time": 10626, "text": "I have a feeling that you and I wouldn't have to go very far to figure out that what might be evolutionarily optimal doesn't match my values as a person and I'm sure it doesn't match yours either."}, {"time": 10640, "text": "Can we try to dig into that gap between those two?"}, {"time": 10644, "text": "I mean, we can do it very simply."}, {"time": 10649, "text": "Selection might favor your engaging in war against a defenseless enemy or genocide, right?"}, {"time": 10658, "text": "It's not hard to figure out how that might put your genes at advantage."}, {"time": 10663, "text": "I don't know about you, Lex."}, {"time": 10664, "text": "I'm not getting involved in no genocide."}, {"time": 10667, "text": "I won't do it."}, {"time": 10668, "text": "I will do anything to avoid it."}, {"time": 10694, "text": "You don't wanna be some robot on a mission that involves genocide when necessary."}, {"time": 10699, "text": "You wanna be your own person and accomplish things that you think are valuable."}, {"time": 10704, "text": "And so among those are not advocating, let's suppose you were in a position to be one of those males at the top of a polygynous system."}, {"time": 10715, "text": "We both know why that would be rewarding, right?"}, {"time": 10718, "text": "But we also both recognize."}, {"time": 10719, "text": "Do we?"}, {"time": 10721, "text": "Lots of sex?"}, {"time": 10723, "text": "Okay, what else?"}, {"time": 10723, "text": "Lots of sex and lots of variety, right?"}, {"time": 10725, "text": "So look, every red blooded American slash Russian male can understand why that's appealing, right?"}, {"time": 10733, "text": "On the other hand, it is up against an alternative which is having a partner with whom one is bonded especially closely, right?"}, {"time": 10747, "text": "A love."}, {"time": 10749, "text": "Well, I don't wanna straw man the polygyny position."}, {"time": 10754, "text": "Obviously polygyny is complex and there's nothing that stops a man presumably from loving multiple partners and from them loving him back."}, {"time": 10763, "text": "But in terms of, if love is your thing, there's a question about, okay, what is the quality of love if it is divided over multiple partners, right?"}, {"time": 10771, "text": "And what is the net consequence for love in a society when multiple people will be frozen out for every individual male in this case who has it?"}, {"time": 10781, "text": "And what I would argue is, and you know, this is weird to even talk about, but this is partially me just talking from personal experience."}, {"time": 10791, "text": "I think there actually is a monogamy program in us and it's not automatic."}, {"time": 10795, "text": "But if you take it seriously, you can find it and frankly, marriage, and it doesn't have to be marriage, but whatever it is that results in a lifelong bond with a partner has gotten a very bad rap."}, {"time": 10810, "text": "You know, it's the butt of too many jokes."}, {"time": 10812, "text": "But the truth is, it's hugely rewarding, it's not easy."}, {"time": 10818, "text": "But if you know that you're looking for something, right?"}, {"time": 10820, "text": "If you know that the objective actually exists and it's not some utopian fantasy that can't be found, if you know that there's some real world, you know, warts and all version of it, then you might actually think, hey, that is something I want and you might pursue it and my guess is you'd be very happy when you find it."}, {"time": 10836, "text": "Yeah, I think there is, getting to the fundamental and the emergent, I feel like there is some kind of physics of love."}, {"time": 10844, "text": "So one, there's a conservation thing going on."}, {"time": 10847, "text": "So if you have like many partners, yeah, in theory, you should be able to love all of them deeply."}, {"time": 10854, "text": "But it seems like in reality that love gets split."}, {"time": 10858, "text": "Now, there's another law that's interesting in terms of monogamy."}, {"time": 10862, "text": "I don't know if it's at the physics level, but if you are in a monogamous relationship by choice and almost as in slight rebellion to social norms, that's much more powerful."}, {"time": 10877, "text": "Like if you choose that one partnership, that's also more powerful."}, {"time": 10882, "text": "If like everybody's in a monogamous, this pressure to be married and this pressure of society, that's different because that's almost like a constraint on your freedom that is enforced by something other than your own ideals."}, {"time": 10895, "text": "It's by somebody else."}, {"time": 10897, "text": "When you yourself choose to, I guess, create these constraints, that enriches that love."}, {"time": 10905, "text": "So there's some kind of love function, like E equals MC squared, but for love, that I feel like if you have less partners and it's done by choice, that can maximize that."}, {"time": 10916, "text": "And that love can transcend the biology, transcend the evolutionary biology forces that have to do much more with survival and all those kinds of things."}, {"time": 10927, "text": "It can transcend to take us to a richer experience, which we have the luxury of having, exploring of happiness, of joy, of fulfillment, all those kinds of things."}, {"time": 10939, "text": "Totally agree with this."}, {"time": 10941, "text": "And there's no question that by choice, when there are other choices, imbues it with meaning that it might not otherwise have."}, {"time": 10950, "text": "I would also say, I'm really struck by, and I have a hard time not feeling terrible sadness over what younger people are coming to think about this topic."}, {"time": 10966, "text": "I think they're missing something so important and so hard to phrase that, and they don't even know that they're missing it."}, {"time": 10974, "text": "They might know that they're unhappy, but they don't understand what it is they're even looking for, because nobody's really been honest with them about what their choices are."}, {"time": 10982, "text": "And I have to say, if I was a young person, or if I was advising a young person, which I used to do, again, a million years ago when I was a college professor four years ago, but I used to talk to students."}, {"time": 10993, "text": "I knew my students really well, and they would ask questions about this, and they were always curious because Heather and I seemed to have a good relationship, and many of them knew both of us."}, {"time": 11002, "text": "So they would talk to us about this."}, {"time": 11004, "text": "If I was advising somebody, I would say, do not bypass the possibility that what you are supposed to do is find somebody worthy, somebody who can handle it, somebody who you are compatible with, and that you don't have to be perfectly compatible."}, {"time": 11021, "text": "It's not about dating until you find the one."}, {"time": 11024, "text": "It's about finding somebody whose underlying values and viewpoint are complimentary to yours, sufficient that you fall in love."}, {"time": 11033, "text": "If you find that person, opt out together."}, {"time": 11038, "text": "Get out of this damn system that's telling you what's sophisticated to think about love and romance and sex."}, {"time": 11044, "text": "Ignore it together, all right?"}, {"time": 11046, "text": "That's the key, and I believe you'll end up laughing in the end if you do it."}, {"time": 11052, "text": "You'll discover, wow, that's a hellscape that I opted out of, and this thing I opted into?"}, {"time": 11059, "text": "Complicated, difficult, worth it."}, {"time": 11062, "text": "Nothing that's worth it is ever not difficult, so we should even just skip the whole statement about difficult."}, {"time": 11070, "text": "I just, I wanna be honest."}, {"time": 11072, "text": "It's not like, oh, it's nonstop joy."}, {"time": 11075, "text": "No, it's fricking complex, but worth it?"}, {"time": 11078, "text": "No question in my mind."}, {"time": 11081, "text": "Is there advice outside of love that you can give to young people?"}, {"time": 11085, "text": "You were a million years ago a professor."}, {"time": 11089, "text": "Is there advice you can give to young people, high schoolers, college students about career, about life?"}, {"time": 11096, "text": "Yeah, but it's not, they're not gonna like it because it's not easy to operationalize, and this was a problem when I was a college professor, too."}, {"time": 11103, "text": "People would ask me what they should do."}, {"time": 11104, "text": "Should they go to graduate school?"}, {"time": 11106, "text": "I had almost nothing useful to say because the job market and the market of prejob training and all of that, these things are all so distorted and corrupt that I didn't wanna point anybody to anything because it's all broken, and I would tell them that, but I would say that results in a kind of meta level advice that I do think is useful."}, {"time": 11133, "text": "You don't know what's coming."}, {"time": 11135, "text": "You don't know where the opportunities will be."}, {"time": 11138, "text": "You should invest in tools rather than knowledge."}, {"time": 11142, "text": "To the extent that you can do things, you can repurpose that no matter what the future brings to the extent that if you, as a robot guy, you've got the skills of a robot guy."}, {"time": 11153, "text": "Now, if civilization failed and the stuff of robot building disappeared with it, you'd still have the mind of a robot guy, and the mind of a robot guy can retool around all kinds of things, whether you're forced to work with fibers that are made into ropes."}, {"time": 11172, "text": "Your mechanical mind would be useful in all kinds of places, so invest in tools like that that can be easily repurposed, and invest in combinations of tools, right?"}, {"time": 11183, "text": "If civilization keeps limping along, you're gonna be up against all sorts of people who have studied the things that you studied, right?"}, {"time": 11193, "text": "If you think, hey, computer programming is really, really cool, and you pick up computer programming, guess what, you just entered a large group of people who have that skill, and many of them will be better than you, almost certainly."}, {"time": 11244, "text": "And so anyway, that isn't useful advice."}, {"time": 11246, "text": "It doesn't tell you whether you should go to graduate school or not, but it does tell you the one thing we can say for certain about the future is that it's uncertain, and so prepare for it."}, {"time": 11256, "text": "And like you said, there's cool things to be discovered in the intersection of fields and ideas."}, {"time": 11262, "text": "And I would look at grad school that way, actually, if you do go, or I see, I mean, this is such a, like every course in grad school, undergrad too, was like this little journey that you're on that explores a particular field."}, {"time": 11280, "text": "And it's not immediately obvious how useful it is, but it allows you to discover intersections between that thing and some other thing."}, {"time": 11291, "text": "So you're bringing to the table these pieces of knowledge, some of which when intersected might create a niche that's completely novel, unique, and will bring you joy."}, {"time": 11303, "text": "I mean, I took a huge number of courses in theoretical computer science."}, {"time": 11308, "text": "Most of them seem useless, but they totally changed the way I see the world in ways that I'm not prepared or is a little bit difficult to kind of make explicit, but taken together, they've allowed me to see, for example, the world of robotics totally different and different from many of my colleagues and friends and so on."}, {"time": 11331, "text": "And I think that's a good way to see if you go to grad school was as a opportunity to explore intersections of fields, even if the individual fields seem useless."}, {"time": 11344, "text": "Yeah, and useless doesn't mean useless, right?"}, {"time": 11347, "text": "Useless means not directly applicable, but a good, useless course can be the best one you ever took."}, {"time": 11354, "text": "Yeah, I took James Joyce, a course on James Joyce, and that was truly useless."}, {"time": 11361, "text": "Well, I took immunobiology in the medical school when I was at Penn as, I guess I would have been a freshman or a sophomore."}, {"time": 11370, "text": "I wasn't supposed to be in this class."}, {"time": 11373, "text": "It blew my goddamn mind, and it still does, right?"}, {"time": 11377, "text": "I mean, we had this, I don't even know who it was, but we had this great professor who was highly placed in the world of immunobiology."}, {"time": 11384, "text": "The course is called Immunobiology, not immunology."}, {"time": 11387, "text": "Immunobiology, it had the right focus, and as I recall it, the professor stood sideways to the chalkboard, staring off into space, literally stroking his beard with this bemused look on his face through the entire lecture."}, {"time": 11404, "text": "And you had all these medical students who were so furiously writing notes that I don't even think they were noticing the person delivering this thing, but I got what this guy was smiling about."}, {"time": 11413, "text": "It was like so, what he was describing, adaptive immunity is so marvelous, right?"}, {"time": 11418, "text": "That it was like almost a privilege to even be saying it to a room full of people who were listening, you know?"}, {"time": 11423, "text": "But anyway, yeah, I took that course, and lo and behold, COVID."}, {"time": 11427, "text": "That's gonna be useful."}, {"time": 11428, "text": "Well, yeah, suddenly it's front and center, and wow, am I glad I took it."}, {"time": 11433, "text": "But anyway, yeah, useless courses are great."}, {"time": 11437, "text": "And actually, Eric gave me one of the greater pieces of advice, at least for college, that anyone's ever given, which was don't worry about the prereqs."}, {"time": 11446, "text": "Take it anyway, right?"}, {"time": 11448, "text": "But now, I don't even know if kids can do this now because the prereqs are now enforced by a computer."}, {"time": 11453, "text": "But back in the day, if you didn't mention that you didn't have the prereqs, nobody stopped you from taking the course."}, {"time": 11459, "text": "And what he told me, which I didn't know, was that often the advanced courses are easier in some way."}, {"time": 11466, "text": "The material's complex, but it's not like intro bio where you're learning a thousand things at once, right?"}, {"time": 11474, "text": "It's like focused on something."}, {"time": 11476, "text": "So if you dedicate yourself, you can pull it off."}, {"time": 11478, "text": "Yeah, stay with an idea for many weeks at a time, and it's ultimately rewarding, and not as difficult as it looks."}, {"time": 11494, "text": "Well, I feel terrible having to give you the answer."}, {"time": 11498, "text": "I realize you asked the question, but if I tell you, you're gonna again feel bad."}, {"time": 11503, "text": "I don't wanna do that."}, {"time": 11504, "text": "But look, there's two."}, {"time": 11506, "text": "There can be a disappointment."}, {"time": 11507, "text": "No, it's gonna be a horror, right?"}, {"time": 11510, "text": "Because we actually know the answer to the question."}, {"time": 11513, "text": "It's completely meaningless."}, {"time": 11516, "text": "There is nothing that we can do that escapes the heat death of the universe or whatever it is that happens at the end."}, {"time": 11522, "text": "And we're not gonna make it there anyway."}, {"time": 11524, "text": "But even if you were optimistic about our ability to escape every existential hazard indefinitely, ultimately it's all for naught and we know it, right?"}, {"time": 11537, "text": "That said, once you stare into that abyss, and then it stares back and laughs or whatever happens, then the question is, okay, given that, can I relax a little bit, right?"}, {"time": 11549, "text": "And figure out, well, what would make sense if that were true, right?"}, {"time": 11554, "text": "And I think there's something very clear to me."}, {"time": 11557, "text": "I think if you do all of the, if I just take the values that I'm sure we share and extrapolate from them, I think the following thing is actually a moral imperative."}, {"time": 11568, "text": "Being a human and having opportunity is absolutely fucking awesome, right?"}, {"time": 11574, "text": "A lot of people don't make use of the opportunity and a lot of people don't have opportunity, right?"}]}, {"title": "Rodney Brooks: Robotics | Lex Fridman Podcast #217", "id": "nre0QT9LN6w", "quotes": [{"time": 291, "text": "I was born in the end of 1954, and I grew up in Adelaide, South Australia, and I have these two books that are dated 1961, so I'm guessing my mother found them in a store in 62 or 63, How and Why Wonder Books."}, {"time": 309, "text": "How and Why Wonder Book of Electricity, and a How and Why Wonder Book of Giant Brains and Robots."}, {"time": 315, "text": "And I learned how to build circuits, you know, when I was eight or nine, simple circuits, and I read, you know, learned the binary system, and saw all these drawings, mostly, of robots, and then I tried to build them for the rest of my childhood."}, {"time": 336, "text": "Wait, 61, you said?"}, {"time": 338, "text": "This was when the two books, I've still got them at home."}, {"time": 341, "text": "What does the robot mean in that context?"}, {"time": 343, "text": "Some of the robots that they had were arms, you know, big arms to move nuclear material around, but they had pictures of welding robots that looked like humans under the sea, welding stuff underwater."}, {"time": 359, "text": "So they weren't real robots, but they were, you know, what people were thinking about for robots."}, {"time": 366, "text": "Were you thinking about humanoids?"}, {"time": 367, "text": "Were you thinking about arms with fingers?"}, {"time": 369, "text": "Were you thinking about faces or colors?"}, {"time": 372, "text": "Were you thinking about faces or cars?"}, {"time": 374, "text": "No, actually, to be honest, I realized my limitation on building mechanical stuff."}, {"time": 379, "text": "So I just built the brains, mostly, out of different technologies as I got older."}, {"time": 388, "text": "I built a learning system which was chemical based, and I had this ice cube tray."}, {"time": 395, "text": "Each well was a cell, and by applying voltage to the two electrodes, it would build up a copper bridge."}, {"time": 403, "text": "So over time, it would learn a simple network so I could teach it stuff."}, {"time": 410, "text": "And mostly, things were driven by my budget, and nails as electrodes and an ice cube tray was about my budget at that stage."}, {"time": 422, "text": "Later, I managed to buy transistors, and I could build gates and flip flops and stuff."}, {"time": 427, "text": "So one of your first robots was an ice cube tray?"}, {"time": 431, "text": "Yeah, it was very cerebral because it learned to add."}, {"time": 437, "text": "Well, just a decade or so before, in 1950, Alan Turing wrote a paper that formulated the Turing Test, and he opened that paper with the question, can machines think?"}, {"time": 456, "text": "Can your ice cube tray one day think?"}, {"time": 460, "text": "Certainly, machines can think because I believe you're a machine, and I'm a machine, and I believe we both think."}, {"time": 466, "text": "I think any other philosophical position is sort of a little ludicrous."}, {"time": 471, "text": "What does think mean if it's not something that we do?"}, {"time": 473, "text": "And we are machines."}, {"time": 476, "text": "So yes, machines can, but do we have a clue how to build such machines?"}, {"time": 480, "text": "That's a very different question."}, {"time": 482, "text": "Are we capable of building such machines?"}, {"time": 485, "text": "Are we smart enough?"}, {"time": 486, "text": "We think we're smart enough to do anything, but maybe we're not."}, {"time": 490, "text": "Maybe we're just not smart enough to build stuff like us."}, {"time": 494, "text": "The kind of computer that Alan Turing was thinking about, do you think there is something fundamentally or significantly different between the computer between our ears, the biological computer that humans use, and the computer that he was thinking about from a sort of high level philosophical?"}, {"time": 513, "text": "Yeah, I believe that it's very wrong."}, {"time": 516, "text": "In fact, I'm halfway through a, I think it'll be about a 480 page book, the working title is Not Even Wrong."}, {"time": 525, "text": "And if I may, I'll tell you a bit about that book."}, {"time": 528, "text": "So there's two, well, three thrusts to it."}, {"time": 532, "text": "One is the history of computation, what we call computation."}, {"time": 536, "text": "It goes all the way back to some manuscripts in Latin from 1614 and 1620 by Napier and Kepler through Babbage and Lovelace."}, {"time": 546, "text": "And then Turing's 1936 paper is what we think of as the invention of modern computation."}, {"time": 557, "text": "And that paper, by the way, did not set out to invent computation."}, {"time": 563, "text": "It set out to negatively answer one of Hilbert's three later set of problems."}, {"time": 569, "text": "He called it an effective way of getting answers."}, {"time": 578, "text": "And Hilbert really worked with rewriting rules, as did Church, who also, at the same time, a month earlier than Turing, disproved Hilbert's one of these three hypotheses."}, {"time": 597, "text": "Turing set out to disprove it, because it's always easier to disprove these things than to prove that there is an answer."}, {"time": 604, "text": "And so he needed, and it really came from his professor while I was an undergrad at Cambridge, who turned it into, is there a mechanical process?"}, {"time": 616, "text": "So he wanted to show a mechanical process that could calculate numbers, because that was a mechanical process that people used to generate tables."}, {"time": 627, "text": "They were called computers, the people at the time."}, {"time": 630, "text": "And they followed a set of rules where they had paper, and they would write numbers down, and based on the numbers, they'd keep writing other numbers."}, {"time": 639, "text": "And they would produce numbers for these tables, engineering tables, that the more iterations they did, the more significant digits came out."}, {"time": 648, "text": "And so Turing, in that paper, set out to define what sort of machine could do that, mechanical machine, where it could produce an arbitrary number of digits in the same way a human computer did."}, {"time": 666, "text": "And he came up with a very simple set of constraints where there was an infinite supply of paper."}, {"time": 674, "text": "This is the tape of the Turing machine, and each Turing machine came with a set of instructions that, as a person, could do with pencil and paper, write down things on the tape and erase them and put new things there."}, {"time": 690, "text": "And he was able to show that that system was not able to do something that Hilbert had hypothesized, so he disproved it."}, {"time": 698, "text": "But he had to show that this system was good enough to do whatever could be done, but couldn't do this other thing."}, {"time": 708, "text": "And there he said, and he says in the paper, I don't have any real arguments for this, but based on intuition."}, {"time": 715, "text": "So that's how he defined computation."}, {"time": 718, "text": "And then if you look over the next, from 1936 up until really around 1975, you see people struggling with, is this really what computation is?"}, {"time": 730, "text": "And so Marvin Minsky, very well known in AI, but also a fantastic mathematician, in his book Finite and Infant Machines from the mid-'60s, which is a beautiful, beautiful mathematical book, says at the start of the book, well, what is computation?"}, {"time": 746, "text": "Turing says it's this, and yeah, I sort of think it's that."}, {"time": 749, "text": "It doesn't really matter whether the stuff's made of wood or plastic."}, {"time": 752, "text": "It's just that relatively cheap stuff can do this stuff."}, {"time": 756, "text": "And so yeah, seems like computation."}, {"time": 760, "text": "And Donald Knuth, in his first volume of his Art of Computer Programming in around 1968, says, well, what's computation?"}, {"time": 772, "text": "It's this stuff, like Turing says, that a person could do each step without too much trouble."}, {"time": 777, "text": "And so one of his examples of what would be too much trouble was a step which required knowing whether Fermat's Last Theorem was true or not, because it was not known at the time."}, {"time": 788, "text": "And that's too much trouble for a person to do as a step."}, {"time": 792, "text": "And Hopcroft and Ullman sort of said a similar thing later that year."}, {"time": 798, "text": "And by 1975, in the A.H.O."}, {"time": 800, "text": "Hopcroft and Ullman book, they're saying, well, you know, we don't really know what computation is, but intuition says this is sort of about right, and this is what it is."}, {"time": 812, "text": "It's a sort of agreed upon thing which happens to be really easy to implement in silicon."}, {"time": 819, "text": "And then we had Moore's Law, which took off, and it's been an incredibly powerful tool."}, {"time": 824, "text": "I certainly wouldn't argue with that."}, {"time": 826, "text": "The version we have of computation, incredibly powerful."}, {"time": 829, "text": "Can we just take a pause?"}, {"time": 831, "text": "So what we're talking about is there's an infinite tape with some simple rules of how to write on that tape, and that's what we're kind of thinking about."}, {"time": 839, "text": "This is computation."}, {"time": 840, "text": "Yeah, and it's modeled after humans, how humans do stuff."}, {"time": 843, "text": "And I think it's, Turing says in the 36th paper, one of the critical facts here is that a human has a limited amount of memory."}, {"time": 851, "text": "So that's what we're going to put onto our mechanical computers."}, {"time": 855, "text": "So, you know, I'm like mass."}, {"time": 859, "text": "I'm like mass or charge or, you know, it's not given by the universe."}, {"time": 866, "text": "It was, this is what we're going to call computation."}, {"time": 869, "text": "And then it has this really, you know, it had this really good implementation, which has completely changed our technological world."}, {"time": 880, "text": "Second part of the book, or argument in the book, I have this two by two matrix with science."}, {"time": 888, "text": "In the top row, engineering in the bottom row, left column is intelligence, right column is life."}, {"time": 898, "text": "So in the bottom row, the engineering, there's artificial intelligence and artificial life."}, {"time": 903, "text": "In the top row, there's neuroscience and abiogenesis."}, {"time": 907, "text": "How does living matter turn in?"}, {"time": 909, "text": "How does nonliving matter become living matter?"}, {"time": 912, "text": "Four disciplines."}, {"time": 914, "text": "These four disciplines all came into the current form in the period 1945 to 1965."}, {"time": 924, "text": "There was neuroscience before, but it wasn't effective neuroscience."}, {"time": 928, "text": "It was, you know, there were these ganglia and there's electrical charges, but no one knows what to do with it."}, {"time": 933, "text": "And furthermore, there are a lot of players who are common across them."}, {"time": 938, "text": "I've identified common players except for artificial intelligence and abiogenesis."}, {"time": 943, "text": "I don't have, but for any other pair, I can point to people who work them."}, {"time": 947, "text": "And a whole bunch of them, by the way, were at the research lab for electronics at MIT where Warren McCulloch held forth."}, {"time": 958, "text": "In fact, McCulloch, Pitts, Letvin, and Maturana wrote the first paper on functional neuroscience called What the Frog's Eye Tells the Frog's Brain, where instead of it just being this bunch of nerves, they sort of showed what different anatomical components were doing and telling other anatomical components and, you know, generating behavior in the frog."}, {"time": 983, "text": "Would you put them as basically the fathers or one of the early pioneers of what are now called artificial neural networks?"}, {"time": 993, "text": "Yeah, I mean, McCulloch and Pitts."}, {"time": 996, "text": "Pitts was a much younger than him."}, {"time": 1038, "text": "It was picked up by John von Neumann when he was designing the Edbeck computer in 1945."}, {"time": 1046, "text": "He talked about its components being neurons based on, and in references, he's only got three references and one of them is the McCulloch Pitts paper."}, {"time": 1055, "text": "So all these people and then the AI people and the artificial life people, which was John von Neumann originally, there's like overlap between all, they're all going around the same time."}, {"time": 1065, "text": "And three of these four disciplines turned to computation as their primary metaphor."}, {"time": 1071, "text": "So I've got a couple of chapters in the book."}, {"time": 1074, "text": "One is titled, wait, computers are people?"}, {"time": 1078, "text": "Because that's where our computers came from."}, {"time": 1081, "text": "And, you know, from people who were computing stuff."}, {"time": 1085, "text": "And then I've got another chapter, wait, people are computers?"}, {"time": 1088, "text": "Which is about computational neuroscience."}, {"time": 1091, "text": "So there's this whole circle here."}, {"time": 1094, "text": "And that computation is it."}, {"time": 1096, "text": "And, you know, I have talked to people about, well, maybe it's not computation that goes on in the head."}, {"time": 1104, "text": "Okay, well, when Elon Musk's rocket goes up, is it computing?"}, {"time": 1111, "text": "Is that how it gets into orbit?"}, {"time": 1112, "text": "By computing?"}, {"time": 1114, "text": "But we've got this idea, if you want to build an AI system, you write a computer program."}, {"time": 1119, "text": "Yeah, so the word computation very quickly starts doing a lot of work that it was not initially intended to do."}, {"time": 1128, "text": "It's the second and same if you talk about the universe as essentially performing a computation."}, {"time": 1134, "text": "Wolfram does this."}, {"time": 1135, "text": "He turns it into computation."}, {"time": 1137, "text": "You don't turn rockets into computation."}, {"time": 1139, "text": "By the way, when you say computation in our conversation, do you tend to think of computation narrowly in the way Turing thought of computation?"}, {"time": 1148, "text": "It's gotten very, you know, squishy."}, {"time": 1154, "text": "Squishy."}, {"time": 1157, "text": "But computation in the way Turing thinks about it and the way most people think about it actually fits very well with thinking like a hunter gatherer."}, {"time": 1169, "text": "There are places and there can be stuff in places and the stuff in places can change and it stays there until someone changes it."}, {"time": 1177, "text": "And it's this metaphor of place and container, which, you know, is a combination of our place cells in our hippocampus and our cortex."}, {"time": 1188, "text": "But this is how we use metaphors for mostly to think about."}, {"time": 1192, "text": "And when we get outside of our metaphor range, we have to invent tools which we can sort of switch on to use."}, {"time": 1198, "text": "So calculus is an example of a tool."}, {"time": 1201, "text": "It can do stuff that our raw reasoning can't do, and we've got conventions of when you can use it or not."}, {"time": 1208, "text": "But sometimes, you know, people try to all the time, we always try to get physical metaphors for things, which is why quantum mechanics has been such a problem for a hundred years."}, {"time": 1221, "text": "Because it's a particle."}, {"time": 1222, "text": "No, it's a wave."}, {"time": 1222, "text": "It's got to be something we understand."}, {"time": 1224, "text": "And I say, no, it's some weird mathematical logic that's different from those, but we want that metaphor."}, {"time": 1230, "text": "Well, you know, I suspect that, you know, a hundred years or 200 years from now, neither quantum mechanics nor dark matter will be talked about in the same terms, you know, in the same way that Flogerson's theory eventually went away."}, {"time": 1244, "text": "Because it just wasn't an adequate explanatory metaphor, you know."}, {"time": 1249, "text": "That metaphor was the stuff, there is stuff in the burning, the burning is in the matter."}, {"time": 1256, "text": "As it turns out, the burning was outside the matter, it was the oxygen."}, {"time": 1259, "text": "So our desire for metaphor and combined with our limited cognitive capabilities gets us into trouble."}, {"time": 1266, "text": "That's my argument in this book."}, {"time": 1268, "text": "Now, and people say, well, what is it then?"}, {"time": 1270, "text": "And I say, well, I wish I knew that, right, the book about that."}, {"time": 1272, "text": "But I, you know, I give some ideas."}, {"time": 1274, "text": "But so there's the three things."}, {"time": 1277, "text": "Computation is sort of a particular thing we use."}, {"time": 1282, "text": "Oh, can I tell you one beautiful thing, one beautiful thing I found?"}, {"time": 1286, "text": "So, you know, I used an example of a thing that's different from computation."}, {"time": 1290, "text": "You hit a drum and it vibrates, and there are some stationary points on the drum surface, you know, because the waves are going up and down the stationary points."}, {"time": 1297, "text": "Now, you could compute them to arbitrary precision, but the drum just knows them."}, {"time": 1305, "text": "The drum doesn't have to compute."}, {"time": 1307, "text": "What was the very first computer program ever written by Ada Lovelace?"}, {"time": 1311, "text": "To compute Bernoulli numbers, and the Bernoulli numbers are exactly what you need to find those stable points in the drum surface."}, {"time": 1319, "text": "And there was a bug in the program."}, {"time": 1323, "text": "The arguments to divide were, I don't know, I don't know."}, {"time": 1326, "text": "The arguments to divide were reversed in one place."}, {"time": 1330, "text": "And it still worked?"}, {"time": 1331, "text": "Well, no, she's never got to run it."}, {"time": 1332, "text": "They never built the analytical engine."}, {"time": 1334, "text": "She wrote the program without it, you know."}, {"time": 1339, "text": "So the computation?"}, {"time": 1341, "text": "Computation is sort of, you know, a thing that's become dominant as a metaphor, but is it the right metaphor?"}, {"time": 1349, "text": "All three of these four fields adopted computation."}, {"time": 1353, "text": "And, you know, a lot of it swirls around Warren McCulloch and all his students, and he funded a lot of people."}, {"time": 1365, "text": "And our human metaphors, our limitations to human thinking, all play into this."}, {"time": 1370, "text": "Those are the three themes of the book."}, {"time": 1372, "text": "So I have a little to say about computation."}, {"time": 1374, "text": "So you're saying that there is a gap between the computer or the machine that performs computation and this machine that appears to have consciousness and intelligence."}, {"time": 1393, "text": "Yeah, that piece of meat in your head."}, {"time": 1396, "text": "Piece of meat."}, {"time": 1396, "text": "And maybe it's not just the meat in your head, it's the rest of you too."}, {"time": 1400, "text": "I mean, you actually have a neural system in your gut."}, {"time": 1404, "text": "I tend to also believe, not believe, but we're now dancing around things we don't know, but I tend to believe other humans are important."}, {"time": 1416, "text": "Like, so we're almost like, I just don't think we would ever have achieved the level of intelligence we have with other humans."}, {"time": 1424, "text": "I'm not saying so confidently, but I have an intuition that some of the intelligence is in the interaction."}, {"time": 1431, "text": "Yeah, and I think it seems to be very likely, again, this is speculation, but we, our species, and probably neanderthals to some extent, because you can find old bones where they seem to be counting on them by putting notches that were neanderthals, we are able to put some of our stuff outside our body into the world."}, {"time": 1458, "text": "And then other people can share it."}, {"time": 1460, "text": "And then we get these tools that become shared tools."}, {"time": 1462, "text": "And so there's a whole coupling that would not occur in the single deep learning network, which was fed all of literature or something."}, {"time": 1473, "text": "Yeah, the neural network can't step outside of itself."}, {"time": 1478, "text": "But is there some, can we explore this dark room a little bit and try to get at something?"}, {"time": 1486, "text": "What is the magic?"}, {"time": 1487, "text": "Where does the magic come from in the human brain that creates the mind?"}, {"time": 1492, "text": "What's your sense as scientists that try to understand it and try to build it?"}, {"time": 1498, "text": "What are the directions it followed might be productive?"}, {"time": 1504, "text": "Is it creative, interactive robots?"}, {"time": 1507, "text": "Is it creating large deep neural networks that do like self supervised learning and just like we'll discover that when you make something large enough, some interesting things will emerge?"}, {"time": 1519, "text": "Is it through physics and chemistry, biology, like artificial life angle?"}, {"time": 1523, "text": "Like we'll sneak up in this four quadrant matrix that you mentioned."}, {"time": 1528, "text": "Is there anything you're most, if you had to bet all your money, financial?"}, {"time": 1533, "text": "I wouldn't."}, {"time": 1535, "text": "So every intelligence we know, animal intelligence, dog intelligence, octopus intelligence, which is a very different sort of architecture from us."}, {"time": 1549, "text": "All the intelligences we know perceive the world in some way and then have action in the world, but they're able to perceive objects in a way which is actually pretty damn phenomenal and surprising."}, {"time": 1573, "text": "We tend to think that the box over here between us, which is a sound box, I think is a blue box, but blueness is something that we construct with color constancy."}, {"time": 1592, "text": "The blueness is not a direct function of the photons we're receiving."}, {"time": 1597, "text": "It's actually context, which is why you can turn, maybe seeing the examples where someone turns a stop sign into some other sort of sign by just putting a couple of marks on them and the deep learning system gets it wrong."}, {"time": 1615, "text": "And everyone says, but the stop sign's red."}, {"time": 1618, "text": "Why is it thinking it's the other sort of sign?"}, {"time": 1619, "text": "Because redness is not intrinsic in just the photons."}, {"time": 1622, "text": "It's actually a construction of an understanding of the whole world and the relationship between objects to get color constancy."}, {"time": 1631, "text": "But our tendency, in order that we get an archive paper really quickly, is you just show a lot of data and give the labels and hope it figures it out."}, {"time": 1638, "text": "But it's not figuring it out in the same way we do."}, {"time": 1641, "text": "We have a very complex perceptual understanding of the world."}, {"time": 1644, "text": "Dogs have a very different perceptual understanding based on smell."}, {"time": 1648, "text": "They go smell a post, they can tell how many different dogs have visited it in the last 10 hours and how long ago."}, {"time": 1656, "text": "There's all sorts of stuff that we just don't perceive about the world."}, {"time": 1659, "text": "And just taking a single snapshot is not perceiving about the world."}, {"time": 1662, "text": "It's not seeing the registration between us and the object."}, {"time": 1668, "text": "And registration is a philosophical concept."}, {"time": 1672, "text": "Brian Cantwell Smith talks about it a lot."}, {"time": 1674, "text": "Very difficult, squirmy thing to understand."}, {"time": 1679, "text": "But I think none of our systems do that."}, {"time": 1682, "text": "We've always talked in AI about the symbol grounding problem, how our symbols that we talk about are grounded in the world."}, {"time": 1688, "text": "And when deep learning came along and started labeling images, people said, ah, the grounding problem has been solved."}, {"time": 1693, "text": "No, the labeling problem was solved with some percentage accuracy, which is different from the grounding problem."}, {"time": 1700, "text": "So you agree with Hans Marvick and what's called the Marvick's paradox that highlights this counterintuitive notion that reasoning is easy, but perception and mobility are hard."}, {"time": 1719, "text": "We shared an office when I was working on computer vision and he was working on his first mobile robot."}, {"time": 1726, "text": "What were those conversations like?"}, {"time": 1730, "text": "So do you still kind of, maybe you can elaborate, do you still believe this kind of notion that perception is really hard?"}, {"time": 1739, "text": "Like, can you make sense of why we humans have this poor intuition about what's hard and not?"}, {"time": 1744, "text": "Well, let me give us sort of another story."}, {"time": 1751, "text": "If you go back to the original teams working on AI from the late 50s into the 60s, and you go to the AI lab at MIT, who was it that was doing that?"}, {"time": 1767, "text": "It was a bunch of really smart kids who got into MIT and they were intelligent."}, {"time": 1772, "text": "So what's intelligence about?"}, {"time": 1774, "text": "Well, the stuff they were good at, playing chess, doing integrals, that was hard stuff."}, {"time": 1780, "text": "But, you know, a baby could see stuff, that wasn't intelligent, anyone could do that, that's not intelligence."}, {"time": 1787, "text": "And so, you know, there was this intuition that the hard stuff is the things they were good at and the easy stuff was the stuff that everyone could do."}, {"time": 1797, "text": "And maybe I'm overplaying it a little bit, but I think there's an element of that."}, {"time": 1800, "text": "Yeah, I mean, I don't know how much truth there is to, like chess, for example, was for the longest time seen as the highest level of intellect, right?"}, {"time": 1814, "text": "Until we got computers that were better at it than people."}, {"time": 1817, "text": "And then we realized, you know, if you go back to the 90s, you'll see, you know, the stories in the press around when Kasparov was beaten by Deep Blue."}, {"time": 1826, "text": "Oh, this is the end of all sorts of things."}, {"time": 1828, "text": "Computers are going to be able to do anything from now on."}, {"time": 1830, "text": "And we saw exactly the same stories with Alpha Zero, the Go Playing program."}, {"time": 1837, "text": "But still, to me, reasoning is a special thing."}, {"time": 1841, "text": "And perhaps... No, actually, we're really bad at reasoning."}, {"time": 1844, "text": "We just use these analogies based on our hunter gatherer intuitions."}, {"time": 1848, "text": "But why is that not, don't you think the ability to construct metaphor is a really powerful thing?"}, {"time": 1853, "text": "Oh, yeah, it is."}, {"time": 1854, "text": "Tell stories."}, {"time": 1855, "text": "It's the constructing the metaphor and registering that something constant in our brains."}, {"time": 1860, "text": "Like, isn't that what we're doing with vision too?"}, {"time": 1864, "text": "And we're telling our stories."}, {"time": 1866, "text": "We're constructing good models of the world."}, {"time": 1869, "text": "But I think we jumped between what we're capable of and how we're doing it right there."}, {"time": 1876, "text": "It was a little confusion that went on as we were telling each other stories."}, {"time": 1883, "text": "Trying to delude each other."}, {"time": 1884, "text": "No, I just think I'm not exactly so."}, {"time": 1887, "text": "I'm trying to pull apart this Moravec's paradox."}, {"time": 1890, "text": "I don't view it as a paradox."}, {"time": 1893, "text": "What did evolution spend its time on?"}, {"time": 1896, "text": "It spent its time on getting us to perceive and move in the world."}, {"time": 1899, "text": "That was 600 million years as multi cell creatures doing that."}, {"time": 1903, "text": "And then it was relatively recent that we were able to hunt or gather or even animals hunting."}, {"time": 1913, "text": "That's much more recent."}, {"time": 1914, "text": "And then anything that we, speech, language, those things are a couple of hundred thousand years probably, if that long."}, {"time": 1925, "text": "And then agriculture, 10,000 years."}, {"time": 1929, "text": "All that stuff was built on top of those earlier things, which took a long time to develop."}, {"time": 1934, "text": "So if you then look at the engineering of these things, so building it into robots, what's the hardest part of robotics?"}, {"time": 1942, "text": "Do you think as the decades that you worked on robots in the context of what we're talking about, vision, perception, the actual sort of the biomechanics of movement, I'm kind of drawing parallels here between humans and machines always."}, {"time": 1960, "text": "Like what do you think is the hardest part of robotics?"}, {"time": 1964, "text": "I just want to think all of them."}, {"time": 1969, "text": "There are no easy parts to do well."}, {"time": 1973, "text": "We sort of go reductionist and we reduce it."}, {"time": 1975, "text": "If only we had all the location of all the points in 3D, things would be great."}, {"time": 1982, "text": "If only we had labels on the images, things would be great."}, {"time": 1987, "text": "But as we see, that's not good enough."}, {"time": 1990, "text": "Some deeper understanding."}, {"time": 1993, "text": "But if I came to you and I could solve one category of problems in robotics instantly, what would give you the greatest pleasure?"}, {"time": 2008, "text": "I mean, you look at robots that manipulate objects, what's hard about that?"}, {"time": 2016, "text": "You know, is it the perception, is it the reasoning about the world, that common sense reasoning, is it the actual building a robot that's able to interact with the world?"}, {"time": 2029, "text": "Is it like human aspects of a robot that's interacting with humans in that game theory of how they work well together?"}, {"time": 2036, "text": "Well, let's talk about manipulation for a second because I had this really blinding moment, you know, I'm a grandfather, so grandfathers have blinding moments."}, {"time": 2045, "text": "Just three or four miles from here, last year, my 16 month old grandson was in his new house for the first time, right?"}, {"time": 2058, "text": "First time in this house."}, {"time": 2059, "text": "And he'd never been able to get to a window before, but this had some low windows."}, {"time": 2065, "text": "And he goes up to this window with a handle on it that he's never seen before."}, {"time": 2069, "text": "And he's got one hand pushing the window and the other hand turning the handle to open the window."}, {"time": 2076, "text": "He knew two different hands, two different things he knew how to put together."}, {"time": 2084, "text": "And he's 16 months old."}, {"time": 2085, "text": "And there you are watching in awe."}, {"time": 2091, "text": "In an environment he'd never seen before, a mechanism he'd never seen."}, {"time": 2095, "text": "How did he do that?"}, {"time": 2096, "text": "Yes, that's a good question."}, {"time": 2099, "text": "It's like, okay, like you could see the leap of genius from using one hand to perform a task to combining, doing, I mean, first of all, in manipulation, that's really difficult."}, {"time": 2111, "text": "It's like two hands, both necessary to complete the action."}, {"time": 2115, "text": "And completely different."}, {"time": 2116, "text": "And he'd never seen a window open before, but he inferred somehow handle open something."}, {"time": 2125, "text": "Yeah, there may have been a lot of slightly different failure cases that you didn't see."}, {"time": 2132, "text": "Not with a window, but with other objects of turning and twisting and handles."}, {"time": 2137, "text": "There's a great counter to reinforcement learning."}, {"time": 2142, "text": "We'll just give the robot plenty of time to try everything."}, {"time": 2150, "text": "Can I tell a little side story here?"}, {"time": 2152, "text": "Yeah, so I'm in DeepMind in London, this is three, four years ago, where there's a big Google building, and then you go inside and you go through this more security, and then you get to DeepMind where the other Google employees can't go."}, {"time": 2169, "text": "And I'm in a conference room, a conference room with some of the people, and they tell me about their reinforcement learning experiment with robots, which are just trying stuff out."}, {"time": 2183, "text": "And they're my robots."}, {"time": 2185, "text": "They're Sawyer's."}, {"time": 2186, "text": "We sold them."}, {"time": 2189, "text": "And they really like them because Sawyer's are compliant and can sense forces, so they don't break when they're bashing into walls."}, {"time": 2196, "text": "They stop and they do all this stuff."}, {"time": 2198, "text": "So you just let the robot do stuff, and eventually it figures stuff out."}, {"time": 2202, "text": "By the way, Sawyer, we're talking about robot manipulation, so robot arms and so on."}, {"time": 2207, "text": "Yeah, Sawyer's a robot."}, {"time": 2210, "text": "What's Sawyer?"}, {"time": 2211, "text": "Sawyer's a robot arm that my company Rethink Robotics built."}, {"time": 2215, "text": "Thank you for the context."}, {"time": 2217, "text": "So we're in DeepMind."}, {"time": 2219, "text": "And it's in the next room, these robots are just bashing around to try and use reinforcement learning to learn how to act."}, {"time": 2225, "text": "Can I go see them?"}, {"time": 2226, "text": "Oh no, they're secret."}, {"time": 2228, "text": "They were my robots."}, {"time": 2229, "text": "They were secret."}, {"time": 2232, "text": "Anyway, the point is, you know, this idea that you just let reinforcement learning figure everything out is so counter to how a kid does stuff."}, {"time": 2241, "text": "So again, story about my grandson."}, {"time": 2244, "text": "I gave him this box that had lots of different lock mechanisms."}, {"time": 2249, "text": "He didn't randomly, you know, and he was 18 months old, he didn't randomly try to touch every surface or push everything."}, {"time": 2255, "text": "He found he could see where the mechanism was, and he started exploring the mechanism for each of these different lock mechanisms."}, {"time": 2264, "text": "And there was reinforcement, no doubt, of some sort going on there."}, {"time": 2268, "text": "But he applied a pre filter, which cut down the search space dramatically."}, {"time": 2275, "text": "I wonder to what level we're able to introspect what's going on."}, {"time": 2279, "text": "Because what's also possible is you have something like reinforcement learning going on in the mind in the space of imagination."}, {"time": 2285, "text": "So like you have a good model of the world you're predicting and you may be running those tens of thousands of like loops, but you're like, as a human, you're just looking at yourself trying to tell a story of what happened."}, {"time": 2298, "text": "And it might seem simple, but maybe there's a lot of computation going on."}, {"time": 2304, "text": "Whatever it is, but there's also a mechanism that's being built up."}, {"time": 2308, "text": "It's not just random search."}, {"time": 2310, "text": "Yeah, that mechanism prunes it dramatically."}, {"time": 2313, "text": "Yeah, that pruning, that pruning stuff, but it doesn't, it's possible that that's, so you don't think that's akin to a neural network inside a reinforcement learning algorithm."}, {"time": 2329, "text": "It's, yeah, until it's possible."}, {"time": 2332, "text": "It's possible, but I'll be incredibly surprised if that happens."}, {"time": 2341, "text": "I'll also be incredibly surprised that after all the decades that I've been doing this, where every few years someone thinks, now we've got it."}, {"time": 2350, "text": "Now we've got it."}, {"time": 2352, "text": "Four or five years ago, I was saying, I don't think we've got it yet."}, {"time": 2355, "text": "And everyone was saying, you don't understand how powerful AI is."}, {"time": 2358, "text": "I had people tell me, you don't understand how powerful it is."}, {"time": 2362, "text": "I sort of had a track record of what the world had done to think, well, this is no different from before."}, {"time": 2371, "text": "Or we have bigger computers."}, {"time": 2373, "text": "We had bigger computers in the 90s and we could do more stuff."}, {"time": 2377, "text": "But okay, so let me push back because I'm generally sort of optimistic and try to find the beauty in things."}, {"time": 2384, "text": "I think there's a lot of surprising and beautiful things that neural networks, this new generation of deep learning revolution has revealed to me, has continually been very surprising the kind of things it's able to do."}, {"time": 2399, "text": "Now, generalizing that over saying like this, we've solved intelligence."}, {"time": 2403, "text": "That's another big leap."}, {"time": 2405, "text": "But is there something surprising and beautiful to you about neural networks that were actually you said back and said, I did not expect this?"}, {"time": 2416, "text": "Oh, I think their performance on ImageNet was shocking."}, {"time": 2422, "text": "The computer vision in those early days was just very like, wow, okay."}, {"time": 2426, "text": "That doesn't mean that they're solving everything in computer vision we need to solve or in vision for robots."}, {"time": 2433, "text": "What about AlphaZero and self play mechanisms and reinforcement learning?"}, {"time": 2437, "text": "Yeah, that was all in the 90s."}, {"time": 2439, "text": "Yeah, that was all in Donald Mickey's 1961 paper."}, {"time": 2444, "text": "Everything that was there, which introduced reinforcement learning."}, {"time": 2448, "text": "No, but come on."}, {"time": 2449, "text": "So no, you're talking about the actual techniques."}, {"time": 2452, "text": "But isn't it surprising to you the level it's able to achieve with no human supervision of chess play?"}, {"time": 2459, "text": "Like, to me, there's a big, big difference between Deep Blue and... Maybe what that's saying is how overblown our view of ourselves is."}, {"time": 2473, "text": "You know, the chess is easy."}, {"time": 2476, "text": "Yeah, I mean, I came across this 1946 report that, and I'd seen this as a kid in one of those books that my mother had given me actually."}, {"time": 2490, "text": "The 1946 report, which pitted someone with an abacus against an electronic calculator, and he beat the electronic calculator."}, {"time": 2502, "text": "You know, so there at that point was, well, humans are still better than machines at calculating."}, {"time": 2508, "text": "Are you surprised today that a machine can, you know, do a billion floating point operations a second and, you know, you're puzzling for minutes through one?"}, {"time": 2518, "text": "I mean, I don't know, but I am certainly surprised there's something, to me, different about learning, so a system that's able to learn."}, {"time": 2530, "text": "Learning."}, {"time": 2530, "text": "See, now you're getting into one of the deadly sins."}, {"time": 2535, "text": "Because of using terms overly broadly."}, {"time": 2539, "text": "Yeah, I mean, there's so many different forms of learning."}, {"time": 2542, "text": "So many different forms."}, {"time": 2543, "text": "You know, I learned my way around the city."}, {"time": 2544, "text": "I learned to play chess."}, {"time": 2546, "text": "I learned Latin."}, {"time": 2548, "text": "I learned to ride a bicycle."}, {"time": 2550, "text": "All of those are, you know, very different capabilities."}, {"time": 2554, "text": "And if someone, you know, has a, you know, in the old days, people would write a paper about learning something."}, {"time": 2563, "text": "Now the corporate press office puts out a press release about how Company X is leading the world because they have a system that can... Yeah, but here's the thing."}, {"time": 2578, "text": "So what is learning?"}, {"time": 2580, "text": "When I refer to... Learning is many things."}, {"time": 2582, "text": "It's a suitcase word."}, {"time": 2584, "text": "It's a suitcase word, but loosely, there's a dumb system, and over time, it becomes smart."}, {"time": 2593, "text": "Well, it becomes less dumb at the thing that it's doing."}, {"time": 2596, "text": "Smart is a loaded word."}, {"time": 2599, "text": "Yes, less dumb at the thing it's doing."}, {"time": 2601, "text": "It gets better performance under some measure, under some set of conditions at that thing."}, {"time": 2607, "text": "And most of these learning algorithms, learning systems, fail when you change the conditions just a little bit in a way that humans don't."}, {"time": 2617, "text": "So I was at DeepMind, the AlphaGo had just come out, and I said, what would have happened if you'd given it a 21 by 21 board instead of a 19 by 19 board?"}, {"time": 2629, "text": "They said, fail totally."}, {"time": 2631, "text": "But a human player would actually be able to play."}, {"time": 2635, "text": "And actually, funny enough, if you look at DeepMind's work since then, they're presenting a lot of algorithms that would do well at the bigger board."}, {"time": 2647, "text": "So they're slowly expanding this generalization."}, {"time": 2650, "text": "I mean, to me, there's a core element there."}, {"time": 2652, "text": "I think it is very surprising to me that even in a constrained game of chess or Go, that through self play, by a system playing itself, that it can achieve superhuman level performance through learning alone."}, {"time": 2669, "text": "Okay, so you didn't like it when I referred to Donald Mickey's 1961 paper."}, {"time": 2678, "text": "There, in the second part of it, which came a year later, they had self play on an electronic computer at tic tac toe, okay, but it learned to play tic tac toe through self play."}, {"time": 2692, "text": "And it learned to play optimally."}, {"time": 2694, "text": "What I'm saying is, okay, I have a little bit of a bias, but I find ideas beautiful, but only when they actually realize the promise."}, {"time": 2706, "text": "That's another level of beauty."}, {"time": 2708, "text": "For example, what Bezos and Elon Musk are doing with rockets."}, {"time": 2713, "text": "We had rockets for a long time, but doing reusable cheap rockets, it's very impressive."}, {"time": 2718, "text": "In the same way, I would have not predicted."}, {"time": 2722, "text": "First of all, when I started and fell in love with AI, the game of Go was seen to be impossible to solve."}, {"time": 2731, "text": "Okay, so I thought maybe, you know, maybe it'd be possible to maybe have big leaps in a Moore's law style of way, in computation, I'll be able to solve it."}, {"time": 2742, "text": "But I would never have guessed that you can learn your way, however, I mean, in the narrow sense of learning, learn your way to beat the best people in the world at the game of Go without human supervision, not studying the game of experts."}, {"time": 2759, "text": "Okay, so using a different learning technique, Arthur Samuel in the early 60s, and he was the first person to use machine learning, had a program that could beat the world champion at checkers."}, {"time": 2776, "text": "And that at the time was considered amazing."}, {"time": 2779, "text": "By the way, Arthur Samuel had some fantastic advantages."}, {"time": 2783, "text": "Do you want to hear Arthur Samuel's advantages?"}, {"time": 2786, "text": "One, he was at the 1956 AI conference."}, {"time": 2790, "text": "I knew Arthur later in life."}, {"time": 2792, "text": "He was at Stanford when I was a graduate student there."}, {"time": 2794, "text": "He wore a tie and a jacket every day, the rest of us didn't."}, {"time": 2798, "text": "Delightful man, delightful man."}, {"time": 2802, "text": "It turns out Claude Shannon, in a 1950 Scientific American article, on chess playing, outlined the learning mechanism that Arthur Samuel used, and they had met in 1956."}, {"time": 2817, "text": "I assume there was some communication, but I don't know that for sure."}, {"time": 2820, "text": "But Arthur Samuel had been a vacuum tube engineer, getting reliability of vacuum tubes, and then had overseen the first transistorized computers at IBM."}, {"time": 2831, "text": "And in those days, before you shipped a computer, you ran it for a week to get early failures."}, {"time": 2838, "text": "So he had this whole farm of computers running random code for hours and hours for each computer."}, {"time": 2848, "text": "He had a whole bunch of them."}, {"time": 2849, "text": "So he ran his chess learning program with self play on IBM's production line."}, {"time": 2858, "text": "He had more computation available to him than anyone else in the world, and then he was able to produce a chess playing program, I mean a checkers playing program, that could beat the world champion."}, {"time": 2871, "text": "The question is, what I mean surprised, I don't just mean it's nice to have that accomplishment, is there is a stepping towards something that feels more intelligent than before."}, {"time": 2886, "text": "Yeah, but that's in your view of the world."}, {"time": 2888, "text": "Okay, well let me then, it doesn't mean I'm wrong."}, {"time": 2891, "text": "No, no it doesn't."}, {"time": 2893, "text": "So the question is, if we keep taking steps like that, how far that takes us?"}, {"time": 2898, "text": "Are we going to build a better recommender systems?"}, {"time": 2901, "text": "Are we going to build a better robot?"}, {"time": 2903, "text": "Or will we solve intelligence?"}, {"time": 2905, "text": "So, you know, I'm putting my bet on, but still missing a whole lot."}, {"time": 2914, "text": "And why would I say that?"}, {"time": 2916, "text": "Well, in these games, they're all, you know, 100% information games, but again, but each of these systems is a very short description of the current state, which is different from registering and perception in the world, which gets back to Marovec's paradox."}, {"time": 2935, "text": "I'm definitely not saying that chess is somehow harder than perception or any kind of, even any kind of robotics in the physical world, I definitely think is way harder than the game of chess."}, {"time": 2950, "text": "So I was always much more impressed by the workings of the human mind."}, {"time": 2955, "text": "The human mind is incredible."}, {"time": 2957, "text": "I believe that from the very beginning, I wanted to be a psychiatrist for the longest time."}, {"time": 2960, "text": "I always thought that's way more incredible in the game of chess."}, {"time": 2963, "text": "I think the game of chess is, I love the Olympics."}, {"time": 2966, "text": "It's just another example of us humans picking a task and then agreeing that a million humans will dedicate their whole life to that task."}, {"time": 2973, "text": "And that's the cool thing that the human mind is able to focus on one task and then compete against each other and achieve like weirdly incredible levels of performance."}, {"time": 2984, "text": "That's the aspect of chess that's super cool."}, {"time": 2986, "text": "Not that chess in itself is really difficult."}, {"time": 2989, "text": "It's like the Fermat's last theorem is not in itself to me that interesting."}, {"time": 2993, "text": "The fact that thousands of people have been struggling to solve that particular problem is fascinating."}, {"time": 2998, "text": "So can I tell you my disease in this way?"}, {"time": 3001, "text": "Which actually is closer to what you're saying."}, {"time": 3003, "text": "So as a child, I was building various, I called them computers."}, {"time": 3007, "text": "They weren't general purpose computers."}, {"time": 3009, "text": "Ice cube tray."}, {"time": 3010, "text": "The ice cube tray was one."}, {"time": 3011, "text": "But I built other machines."}, {"time": 3012, "text": "And what I liked to build was machines that could beat adults at a game and the adults couldn't beat my machine."}, {"time": 3019, "text": "So you were like, that's powerful."}, {"time": 3022, "text": "That's a way to rebel."}, {"time": 3024, "text": "Oh, by the way, when was the first time you built something that outperformed you?"}, {"time": 3034, "text": "Well, I knew how it worked."}, {"time": 3036, "text": "I was probably nine years old and I built a thing that was a game where you take turns in taking matches from a pile and either the one who takes the last one or the one who doesn't take the last one wins."}, {"time": 3049, "text": "And so it was pretty easy to build that out of wires and nails and little coils that were like plugging in the number and a few light bulbs."}, {"time": 3059, "text": "The one I was proud of, I was 12 when I built a thing out of old telephone switchboard switches that could always win at tic tac toe."}, {"time": 3071, "text": "And that was a much harder circuit to design."}, {"time": 3074, "text": "But again, it was no active components."}, {"time": 3077, "text": "It was just three position switches, empty, X, zero, O."}, {"time": 3083, "text": "And nine of them and a light bulb on which move it wanted next."}, {"time": 3089, "text": "And then the human would go and move that."}, {"time": 3091, "text": "See, there's magic in that creation."}, {"time": 3094, "text": "I tend to see magic in robots that like I also think that intelligence is a little bit overrated."}, {"time": 3104, "text": "I think we can have deep connections with robots very soon."}, {"time": 3109, "text": "And well, we'll come back to connections for sure."}, {"time": 3112, "text": "But I do want to say, I think too many people make the mistake of seeing that magic and thinking, well, we'll just continue."}, {"time": 3122, "text": "But each one of those is a hard fought battle for the next step, the next step."}, {"time": 3128, "text": "The open question here is, and this is why I'm playing devil's advocate, but I often do when I read your blog post in my mind because I have like this eternal optimism, is it's not clear to me."}, {"time": 3139, "text": "So I don't do what obviously the journalists do or they give into the hype, but it's not obvious to me how many steps away we are from a truly transformational understanding of what it means to build intelligent systems or how to build intelligent systems."}, {"time": 3160, "text": "I'm also aware of the whole history of artificial intelligence, which is where your deep grounding of this is, is there has been an optimism for decades and that optimism, just like reading old optimism is absurd because people were like, this is, they were saying things are trivial for decades since the sixties, they're saying everything is true."}, {"time": 3180, "text": "Computer vision is trivial, but I think my mind is working crisply enough to where, I mean, we can dig into if you want."}, {"time": 3189, "text": "I'm really surprised by the things DeepMind has done."}, {"time": 3192, "text": "I don't think they're so, they're yet close to solving intelligence, but I'm not sure it's not 10 to 10 years away."}, {"time": 3202, "text": "What I'm referring to is interesting to see when the engineering, it takes that idea to scale and the idea works."}, {"time": 3212, "text": "And no, it fools people."}, {"time": 3215, "text": "Honestly, Rodney, if it was you, me and Demis inside a room, forget the press, forget all those things, just as a scientist, as a roboticist, that wasn't surprising to you that at scale."}, {"time": 3227, "text": "So we're talking about very large now, okay, let's pick one."}, {"time": 3230, "text": "That's the most surprising to you."}, {"time": 3232, "text": "Please don't yell at me."}, {"time": 3233, "text": "GPT three, okay."}, {"time": 3236, "text": "Hold on, hold on, I was going to say, okay, alpha zero, alpha go, alpha go, zero, alpha zero, and then alpha fold one and two."}, {"time": 3246, "text": "So do any of these kind of have this core of, forget usefulness or application and so on, which you could argue for alpha fold, like, as a scientist, was those surprising to you that it worked as well as it did?"}, {"time": 3263, "text": "Okay, so if we're going to make the distinction between surprise and usefulness, and I have to explain this, I would say alpha fold, and one of the problems at the moment with alpha fold is, you know, it gets a lot of them right, which is a surprise to me, because they're a really complex thing, but you don't know which ones it gets right, which then is a bit of a problem."}, {"time": 3292, "text": "Now they've come out with a recent... You mean the structure of the proteins, it gets a lot of those right."}, {"time": 3296, "text": "Yeah, it's a surprising number of them right, it's been a really hard problem."}, {"time": 3300, "text": "So that was a surprise how many it gets right."}, {"time": 3303, "text": "So far, the usefulness is limited, because you don't know which ones are right or not, and now they've come out with a thing in the last few weeks, which is trying to get a useful tool out of it, and they may well do it."}, {"time": 3315, "text": "In that sense, at least alpha fold is different, because your alpha fold tool is different, because now it's producing data sets that are actually, you know, potentially revolutionizing competition biology, like they will actually help a lot of people, but... You would say potentially revolutionizing, we don't know yet, but yeah."}, {"time": 3336, "text": "That's true, yeah."}, {"time": 3336, "text": "But they're, you know, but I got you."}, {"time": 3339, "text": "I mean, this is..."}, {"time": 3340, "text": "Okay, so you know what, this is gonna be so fun, so let's go right into it."}, {"time": 3345, "text": "Speaking of robots that operate in the real world, let's talk about self driving cars."}, {"time": 3354, "text": "Okay, because you have built robotics companies, you're one of the greatest roboticists in history, and that's not just in the space of ideas, we'll also probably talk about that, but in the actual building and execution of businesses that make robots that are useful for people and that actually work in the real world and make money."}, {"time": 3378, "text": "You also sometimes are critical of Mr. Elon Musk, or let's more specifically focus on this particular technology, which is autopilot inside Teslas."}, {"time": 3389, "text": "What are your thoughts about Tesla autopilot, or more generally vision based machine learning approach to semi autonomous driving?"}, {"time": 3398, "text": "These are robots, they're being used in the real world by hundreds of thousands of people, and if you want to go there, I can go there, but that's not too much, which they're... Let's say they're on par safety wise as humans currently, meaning human alone versus human plus robot."}, {"time": 3418, "text": "Okay, so first let me say I really like the car I came in here today."}, {"time": 3426, "text": "2021 model, Mercedes E450."}, {"time": 3432, "text": "I am impressed by the machine vision, sonar, other things."}, {"time": 3439, "text": "I'm impressed by what it can do."}, {"time": 3441, "text": "I'm really impressed with many aspects of it."}, {"time": 3449, "text": "It's able to stay in lane, is it?"}, {"time": 3451, "text": "Oh yeah, it does the lane stuff."}, {"time": 3455, "text": "It's looking on either side of me, it's telling me about nearby cars."}, {"time": 3460, "text": "For blind spots and so on."}, {"time": 3461, "text": "Yeah, when I'm going in close to something in the park, I get this beautiful, gorgeous, top down view of the world."}, {"time": 3469, "text": "I am impressed up the wazoo of how registered and metrical that is."}, {"time": 3476, "text": "So it's like multiple cameras and it's all ready to go to produce the 360 view kind of thing?"}, {"time": 3480, "text": "360 view, it's synthesized so it's above the car, and it is unbelievable."}, {"time": 3486, "text": "I got this car in January, it's the longest I've ever owned a car without digging it."}, {"time": 3491, "text": "So it's better than me."}, {"time": 3493, "text": "Me and it together are better."}, {"time": 3495, "text": "So I'm not saying technology's bad or not useful, but here's my point."}, {"time": 3504, "text": "Yes, it's a replay of the same movie."}, {"time": 3511, "text": "Okay, so maybe you've seen me ask this question before."}, {"time": 3514, "text": "But when did the first car go over 55 miles an hour for over 10 miles on a public freeway with other traffic around driving completely autonomously?"}, {"time": 3536, "text": "When did that happen?"}, {"time": 3539, "text": "Was it CMU in the 80s or something?"}, {"time": 3541, "text": "It was a long time ago."}, {"time": 3542, "text": "It was actually in 1987 in Munich at the Bundeswehr."}, {"time": 3549, "text": "So they had it running in 1987."}, {"time": 3552, "text": "When do you think, and Elon has said he's going to do this, when do you think we'll have the first car drive coast to coast in the US, hands off the wheel, feet off the pedals, coast to coast?"}, {"time": 3565, "text": "As far as I know, a few people have claimed to do it."}, {"time": 3568, "text": "1995, that was Carnegie Mellon."}, {"time": 3570, "text": "I didn't know, but oh, that was the, they didn't claim, did they claim 100%?"}, {"time": 3575, "text": "Not 100%, not 100%."}, {"time": 3577, "text": "And then there's a few marketing people who have claimed 100% since then."}, {"time": 3581, "text": "My point is that, you know, what I see happening again is someone sees a demo and they overgeneralize and say, we must be almost there."}, {"time": 3592, "text": "But we've been working on it for 35 years."}, {"time": 3594, "text": "So that's demos."}, {"time": 3596, "text": "But this is going to take us back to the same conversation with AlphaZero."}, {"time": 3599, "text": "Are you not, okay, I'll just say what I am because I thought, okay, when I first started interacting with the Mobileye implementation of Tesla Autopilot, I've driven a lot of car, you know, I've been in Google self driving car since the beginning."}, {"time": 3618, "text": "I thought there was no way before I sat and used Mobileye, I thought they're just knowing computer vision."}, {"time": 3624, "text": "I thought there's no way it could work as well as it was working."}, {"time": 3626, "text": "So my model of the limits of computer vision was way more limited than the actual implementation of Mobileye."}, {"time": 3635, "text": "I was so that's one example."}, {"time": 3637, "text": "I was really surprised."}, {"time": 3639, "text": "It's like, wow, that was that was incredible."}, {"time": 3641, "text": "The second surprise came when Tesla threw away Mobileye and started from scratch."}, {"time": 3650, "text": "I thought there's no way they can catch up to Mobileye."}, {"time": 3652, "text": "I thought what Mobileye was doing was kind of incredible, like the amount of work and the annotation."}, {"time": 3656, "text": "Yeah, well, Mobileye was started by Amnon Shashua and used a lot of traditional, you know, hard fought computer vision techniques."}, {"time": 3664, "text": "But they also did a lot of good sort of like non research stuff, like actual like just good, like what you do to make a successful product, right?"}, {"time": 3674, "text": "Scale, all that kind of stuff."}, {"time": 3676, "text": "And so I was very surprised when they from scratch were able to catch up to that."}, {"time": 3680, "text": "That's very impressive."}, {"time": 3681, "text": "And I've talked to a lot of engineers that was involved."}, {"time": 3683, "text": "This is that was impressive."}, {"time": 3685, "text": "That was impressive."}, {"time": 3687, "text": "And the recent progress, especially under the involvement of Andrej Karpathy, what they were what they're doing with the data engine, which is converting into the driving task into these multiple tasks and then doing this edge case discovery when they're pulling back like the level of engineering made me rethink what's possible."}, {"time": 3709, "text": "I don't I still, you know, I don't know to that intensity, but I always thought it was very difficult to solve autonomous driving with all the sensors, with all the computation."}, {"time": 3720, "text": "I just thought it's a very difficult problem."}, {"time": 3722, "text": "But I've been continuously surprised how much you can engineer."}, {"time": 3727, "text": "First of all, the data acquisition problem, because I thought, you know, just because I worked with a lot of car companies and they're they're so a little a little bit old school to where I didn't think they could do this at scale like AWS style data collection."}, {"time": 3745, "text": "So when Tesla was able to do that, I started to think, OK, so what are the limits of this?"}, {"time": 3753, "text": "I still believe that driver like sensing and the interaction with the driver and like studying the human factor psychology problem is essential."}, {"time": 3763, "text": "It's it's always going to be there."}, {"time": 3765, "text": "It's always going to be there, even with fully autonomous driving."}, {"time": 3768, "text": "But I've been surprised what is the limit, especially a vision based alone, how far that can take us."}, {"time": 3777, "text": "So that's my levels of surprise now."}, {"time": 3780, "text": "OK, can you explain in the same way you said, like Alpha Zero, that's a homework problem that's scaled large in its chest, like who cares?"}, {"time": 3790, "text": "Go with here's actual people using an actual car and driving."}, {"time": 3795, "text": "Many of them drive more than half their miles using the system."}, {"time": 3800, "text": "So, yeah, they're doing well with with pure vision for your vision."}, {"time": 3805, "text": "And, you know, and now no radar, which is I suspect that can't go all the way."}, {"time": 3810, "text": "And one reason is without without new cameras that have a dynamic range closer to the human eye, because human eye has incredible dynamic range."}, {"time": 3819, "text": "And we make use of that dynamic range in its 11 orders of magnitude or some crazy number like that."}, {"time": 3827, "text": "The cameras don't have that, which is why you see the the the bad cases where the sun on a white thing and it blinds it in a way it wouldn't blind the person."}, {"time": 3839, "text": "I think there's a bunch of things to think about before you say this is so good, it's just going to work."}, {"time": 3846, "text": "OK, and I'll come at it from multiple angles."}, {"time": 3852, "text": "And I know you've got a lot of time."}, {"time": 3854, "text": "OK, let's let's I have thought about these things."}, {"time": 3858, "text": "You've been writing a lot of great blog posts about it for a while before Tesla had autopilot."}, {"time": 3865, "text": "So you've been thinking about autonomous driving for a while from every angle."}, {"time": 3869, "text": "So so a few things, you know, in the US, I think that the death rate for autonomous driving death rate from motor vehicle accidents is about thirty five thousand a year, which is an outrageous number, not outrageous compared to covid deaths."}, {"time": 3889, "text": "But, you know, there is no rationality."}, {"time": 3892, "text": "And that's part of the thing people have said."}, {"time": 3894, "text": "Engineers say to me, well, if we cut down the number of deaths by 10 percent by having autonomous driving, that's going to be great."}, {"time": 3901, "text": "Everyone will love it."}, {"time": 3902, "text": "And my prediction is that if autonomous vehicles kill more than 10 people a year, they'll be screaming and hollering, even though thirty five thousand people a year have been killed by human drivers."}, {"time": 3916, "text": "It's not rational."}, {"time": 3917, "text": "It's a different set of expectations."}, {"time": 3920, "text": "And that will probably continue."}, {"time": 3923, "text": "So there's that aspect of it."}, {"time": 3925, "text": "The other aspect of it is that when we introduce new technology, we often change the rules of the game."}, {"time": 3936, "text": "So when we introduced cars first into our daily lives, we completely rebuilt our cities and we changed all the laws."}, {"time": 3946, "text": "Yeah, jaywalking was not an offense that was pushed by the car companies so that people would stay off the road so there wouldn't be deaths from pedestrians getting hit."}, {"time": 3957, "text": "We completely changed the structure of our cities and had these foul smelling things everywhere around us."}, {"time": 3964, "text": "And now you see pushback in cities like Barcelona is really trying to exclude cars, et cetera."}, {"time": 3971, "text": "So I think that to get to self driving, we will, large adoption, it's not going to be just take the current situation, take out the driver and put the same car doing the same stuff because the end case is too many."}, {"time": 3991, "text": "Here's an interesting question."}, {"time": 3993, "text": "How many fully autonomous train systems do we have in the U.S.?"}, {"time": 4001, "text": "I mean, do you count them as fully autonomous?"}, {"time": 4003, "text": "I don't know because they're usually as a driver, but they're kind of autonomous, right?"}, {"time": 4007, "text": "No, let's get rid of the driver."}, {"time": 4012, "text": "It's either 15 or 16."}, {"time": 4014, "text": "Most of them are in airports."}, {"time": 4016, "text": "There's a few that are fully autonomous."}, {"time": 4019, "text": "Seven are in airports, there's a few that go about five, two that go about five kilometers out of airports."}, {"time": 4031, "text": "When is the first fully autonomous train system for mass transit expected to operate fully autonomously with no driver in a U.S. City?"}, {"time": 4043, "text": "It's expected to operate in 2017 in Honolulu."}, {"time": 4049, "text": "It's delayed, but they will get there."}, {"time": 4052, "text": "BART, by the way, was originally going to be autonomous here in the Bay Area."}, {"time": 4055, "text": "I mean, they're all very close to fully autonomous, right?"}, {"time": 4058, "text": "Yeah, but getting that close is the thing."}, {"time": 4061, "text": "And I've often gone on a fully autonomous train in Japan, one that goes out to that fake island in the middle of Tokyo Bay."}, {"time": 4070, "text": "I forget the name of that."}, {"time": 4073, "text": "And what do you see when you look at that?"}, {"time": 4075, "text": "What do you see when you go to a fully autonomous train in an airport?"}, {"time": 4083, "text": "It's not like regular trains."}, {"time": 4087, "text": "At every station, there's a double set of doors so that there's a door of the train and there's a door off the platform."}, {"time": 4098, "text": "And this is really visible in this Japanese one because it goes out in amongst buildings."}, {"time": 4103, "text": "The whole track is built so that people can't climb onto it."}, {"time": 4107, "text": "So there's an engineering that then makes the system safe and makes them acceptable."}, {"time": 4112, "text": "I think we'll see similar sorts of things happen in the U.S. What surprised me, I thought, wrongly, that we would have special purpose lanes on 101 in the Bay Area, the leftmost lane, so that it would be normal for Teslas or other cars to move into that lane and then say, okay, now it's autonomous and have that dedicated lane."}, {"time": 4140, "text": "I was expecting movement to that."}, {"time": 4143, "text": "Five years ago, I was expecting we'd have a lot more movement towards that."}, {"time": 4147, "text": "And it may be because Tesla's been overpromising by saying this, calling their system fully self driving, I think they may have been gotten there quicker by collaborating to change the infrastructure."}, {"time": 4163, "text": "This is one of the problems with long haul trucking being autonomous."}, {"time": 4170, "text": "I think it makes sense on freeways at night for the trucks to go autonomously, but then is that how do you get onto and off of the freeway?"}, {"time": 4180, "text": "What sort of infrastructure do you need for that?"}, {"time": 4183, "text": "Do you need to have the human in there to do that or can you get rid of the human?"}, {"time": 4188, "text": "So I think there's ways to get there, but it's an infrastructure argument because the long tail of cases is very long and the acceptance of it will not be at the same level as human drivers."}, {"time": 4202, "text": "So I'm with you still, and I was with you for a long time, but I am surprised how well how many edge cases of machine learning and vision based methods can cover."}, {"time": 4215, "text": "This is what I'm trying to get at is I think there's something fundamentally different with vision based methods and Tesla Autopilot and any company that's trying to do the same."}, {"time": 4227, "text": "Okay, well, I'm not going to argue with you because, you know, we're speculating."}, {"time": 4234, "text": "Yes, but, you know, my gut feeling tells me it's going to be things will speed up when there is engineering of the environment because that's what happened with every other technology."}, {"time": 4248, "text": "I'm a bit, I don't know about you, but I'm a bit cynical that infrastructure is going to rely on government to help out in these cases."}, {"time": 4260, "text": "If you just look at infrastructure in all domains, it's just a government always drags behind on infrastructure."}, {"time": 4267, "text": "There's like there's so many just well in this country in the future."}, {"time": 4272, "text": "Yes, in this country."}, {"time": 4273, "text": "And of course, there's many, many countries that are actually much worse on infrastructure."}, {"time": 4277, "text": "Oh, yes, many of the much worse and there's some that are much worse."}, {"time": 4281, "text": "You know, like high speed rail, the other countries are much better."}, {"time": 4285, "text": "I guess my question is, like, which is at the core of what I was trying to think through here and ask is like, how hard is the driving problem as it currently stands?"}, {"time": 4297, "text": "So you mentioned, like, we don't want to just take the human out and duplicate whatever the human was doing."}, {"time": 4302, "text": "But if we were to try to do that, what, how hard is that problem?"}, {"time": 4308, "text": "Because I used to think is way harder."}, {"time": 4312, "text": "Like, I used to think it's with vision alone, it would be three decades, four decades."}, {"time": 4319, "text": "Okay, so I don't know the answer to this thing I'm about to pose, but I do notice that on Highway 280 here in the Bay Area, which largely has concrete surface rather than blacktop surface, the white lines that are painted there now have black boundaries around them."}, {"time": 4340, "text": "And my lane drift system in my car would not work without those black boundaries."}, {"time": 4348, "text": "So I don't know whether they started doing it to help the lane drift, whether it is an instance of infrastructure following the technology, but my car would not perform as well as the lane, my car would not perform as well without that change in the way they paint the line."}, {"time": 4365, "text": "Unfortunately, really good lane keeping is not as valuable."}, {"time": 4370, "text": "Like, it's orders of magnitude more valuable to have a fully autonomous system."}, {"time": 4374, "text": "Like, yeah, but for me, lane keeping is really helpful because I'm more healthy at it."}, {"time": 4380, "text": "But you wouldn't pay 10 times."}, {"time": 4383, "text": "Like, the problem is there's not financial, like, it doesn't make sense to revamp the infrastructure to make lane keeping easier."}, {"time": 4394, "text": "It does make sense to revamp the infrastructure."}, {"time": 4397, "text": "If you have a large fleet of autonomous vehicles, now you change what it means to own cars, you change the nature of transportation."}, {"time": 4404, "text": "But for that, you need autonomous vehicles."}, {"time": 4409, "text": "Let me ask you about Waymo then."}, {"time": 4411, "text": "I've gotten a bunch of chances to ride in a Waymo self driving car."}, {"time": 4417, "text": "And they're, I don't know if you'd call them self driving, but."}, {"time": 4420, "text": "Well, I mean, I rode in one before they were called Waymo when I was still at X."}, {"time": 4425, "text": "So there's currently, there's a big leap, another surprising leap I didn't think would happen, which is they have no driver currently."}, {"time": 4433, "text": "Yeah, in Chandler."}, {"time": 4435, "text": "In Chandler, Arizona."}, {"time": 4436, "text": "And I think they're thinking of doing that in Austin as well."}, {"time": 4438, "text": "But they're expanding."}, {"time": 4441, "text": "Although, you know, and I do an annual checkup on this."}, {"time": 4446, "text": "So as of late last year, they were aiming for hundreds of rides a week, not thousands."}, {"time": 4454, "text": "And there is no one in the car, but there's certainly safety people in the loop."}, {"time": 4462, "text": "And it's not clear how many, you know, what the ratio of cars to safety people is."}, {"time": 4466, "text": "It wasn't, obviously, they're not 100% transparent about this."}, {"time": 4471, "text": "None of them are 100% transparent."}, {"time": 4473, "text": "They're very untransparent."}, {"time": 4474, "text": "But at least the way they're, I don't want to make definitively, but they're saying there's no teleoperation."}, {"time": 4482, "text": "So like, they're, I mean, okay."}, {"time": 4485, "text": "And that sort of fits with YouTube videos I've seen of people being trapped in the car by a red cone on the street."}, {"time": 4495, "text": "And they do have rescue vehicles that come, and then a person gets in and drives it."}, {"time": 4502, "text": "But isn't it incredible to you, it was to me, to get in a car with no driver and watch the steering wheel turn, like for somebody who has been studying, at least certainly the human side of autonomous vehicles for many years, and you've been doing it for way longer, like it was incredible to me that this was actually could happen."}, {"time": 4522, "text": "I don't care if that scale is 100 cars."}, {"time": 4524, "text": "This is not a demo."}, {"time": 4525, "text": "This is not, this is me as a regular human."}, {"time": 4528, "text": "The argument I have is that people make interpolations from that."}, {"time": 4533, "text": "Interpolations."}, {"time": 4533, "text": "That, you know, it's here, it's done."}, {"time": 4537, "text": "You know, it's just, you know, we've solved it."}, {"time": 4539, "text": "No, we haven't yet."}, {"time": 4540, "text": "And that's my argument."}, {"time": 4542, "text": "So I'd like to go to, you keep a list of predictions on your amazing blog post."}, {"time": 4548, "text": "It'd be fun to go through them."}, {"time": 4549, "text": "But before then, let me ask you about this."}, {"time": 4551, "text": "You have a harshness to you sometimes in your criticisms of what is perceived as hype."}, {"time": 4565, "text": "And so like, because people extrapolate, like you said, and they kind of buy into the hype and then they kind of start to think that the technology is way better than it is."}, {"time": 4578, "text": "But let me ask you maybe a difficult question."}, {"time": 4583, "text": "Do you think if you look at history of progress, don't you think to achieve the quote impossible, you have to believe that it's possible?"}, {"time": 4594, "text": "Look, his two great runs, great, unbelievable, 1903, first human power, human, you know, human, you know, heavier than their flight."}, {"time": 4610, "text": "1969, we land on the moon."}, {"time": 4612, "text": "That's 66 years."}, {"time": 4613, "text": "I'm 66 years old in my lifetime, that span of my lifetime, barely, you know, flying, I don't know what it was, 50 feet, the length of the first flight or something to landing on the moon."}, {"time": 4628, "text": "But that requires, by the way, one of the Wright brothers, both of them, but one of them didn't believe it's even possible like a year before."}, {"time": 4636, "text": "So, like, not just possible soon, but like ever."}, {"time": 4641, "text": "How important is it to believe and be optimistic is what I guess."}, {"time": 4644, "text": "Oh, yeah, it is important."}, {"time": 4646, "text": "It's when it goes crazy, when I, you know, you said that, what was the word you used for my bad?"}, {"time": 4660, "text": "I just get so frustrated."}, {"time": 4662, "text": "When people make these leaps and tell me that I'm, that I don't understand, you know, yeah."}, {"time": 4673, "text": "There's just from iRobot, which I was co founder of."}, {"time": 4677, "text": "I don't know the exact numbers now because I haven't, it's 10 years since I stepped off the board, but I believe it's well over 30 million robots cleaning houses from that one company."}, {"time": 4686, "text": "And now there's lots of other companies."}, {"time": 4688, "text": "Was that a crazy idea that we had to believe in 2002 when we released it?"}, {"time": 4694, "text": "Yeah, that was, we had, we had to, you know, believe that it could be done."}, {"time": 4700, "text": "Let me ask you about this."}, {"time": 4701, "text": "So iRobot, one of the greatest robotics companies ever in terms of creating a robot that actually works in the real world, probably the greatest robotics company ever."}, {"time": 4711, "text": "You were the co founder of it."}, {"time": 4713, "text": "If, if the Rodney Brooks of today talked to the Rodney of back then, what would you tell him?"}, {"time": 4721, "text": "Cause I have a sense that would you pat him on the back and say, well, you're doing is going to fail, but go at it anyway."}, {"time": 4730, "text": "That's what I'm referring to with the harshness."}, {"time": 4734, "text": "You've accomplished an incredible thing there."}, {"time": 4736, "text": "One of the several things we'll talk about was, you know, you know, you know, you've done several things we'll talk about."}, {"time": 4743, "text": "Well, like that's what I'm trying to get at that line."}, {"time": 4746, "text": "No, it's, it's when my harshness is reserved for people who are not doing it, who claim it's just, well, this shows that it's just going to happen."}, {"time": 4756, "text": "But here, here's the thing."}, {"time": 4758, "text": "This shows."}, {"time": 4759, "text": "But you have that harshness for Elon too."}, {"time": 4764, "text": "And no, no, it's a different harshness."}, {"time": 4766, "text": "No, it's, it's a different argument with Elon."}, {"time": 4770, "text": "I think SpaceX is an amazing company."}, {"time": 4774, "text": "On the other hand, you know, I, in one of my blog posts, I said, what's easy and what's hard."}, {"time": 4780, "text": "I said, yeah, space X vertical landing rockets."}, {"time": 4784, "text": "It had been done before."}, {"time": 4786, "text": "Grid fins had been done since the sixties."}, {"time": 4788, "text": "Every Soyuz has them."}, {"time": 4792, "text": "Reusable space DCX reuse those rockets that landed vertically."}, {"time": 4798, "text": "There's a whole insurance industry in place for rocket launches."}, {"time": 4802, "text": "There are all sorts of infrastructure that was doable."}, {"time": 4807, "text": "It took a great entrepreneur, a great personal expense."}, {"time": 4811, "text": "He almost drove himself, you know, bankrupt doing it, a great belief to do it."}, {"time": 4818, "text": "Whereas Hyperloop, there's a whole bunch more stuff that's never been thought about and never been demonstrated."}, {"time": 4828, "text": "So my estimation is Hyperloop is a long, long, long, a lot further off."}, {"time": 4833, "text": "But, and if I've got a criticism of, of, of Elon, it's that he doesn't make distinctions between when the technology's coming along and ready."}, {"time": 4844, "text": "And then he'll go off and mouth off about other things, which then people go and compete about and try and do."}, {"time": 4851, "text": "And so this is where I, I, I, I understand what you're saying."}, {"time": 4857, "text": "I tend to draw a different distinction."}, {"time": 4860, "text": "I, I have a similar kind of harshness towards people who are not telling the truth, who are basically fabricating stuff to make money or to, well, he believes what he says."}, {"time": 4871, "text": "I just think that's a very important difference because I think in order to fly, in order to get to the moon, you have to believe even when most people tell you you're wrong and most likely you're wrong, but sometimes you're right."}, {"time": 4886, "text": "I mean, that's the same thing I have with Tesla autopilot."}, {"time": 4889, "text": "I think that's an interesting one."}, {"time": 4891, "text": "I was, especially when I was at MIT and just the entire human factors in the robotics community were very negative towards Elon."}, {"time": 4900, "text": "It was very interesting for me to observe colleagues at MIT."}, {"time": 4905, "text": "I wasn't sure what to make of that."}, {"time": 4906, "text": "That was very upsetting to me because I understood where that, where that's coming from."}, {"time": 4911, "text": "And I agreed with them and I kind of almost felt the same thing in the beginning until I kind of opened my eyes and realized there's a lot of interesting ideas here that might be over hype."}, {"time": 4922, "text": "You know, if you focus yourself on the idea that you shouldn't call a system full self driving when it's obviously not autonomous, fully autonomous, you're going to miss the magic."}, {"time": 4936, "text": "Oh, yeah, you are going to miss the magic."}, {"time": 4938, "text": "But at the same time, there are people who buy it, literally pay money for it and take those words as given."}, {"time": 4947, "text": "So it's, but I haven't."}, {"time": 4950, "text": "So that I take words as given is one thing."}, {"time": 4953, "text": "I haven't actually seen people that use autopilot that believe that the behavior is really important, like the actual action."}, {"time": 4960, "text": "So like, this is to push back on the very thing that you're frustrated about, which is like journalists and general people buying all the hype and going out in the same way."}, {"time": 4972, "text": "I think there's a lot of hype about the negatives of this, too, that people are buying without using people use the way this is what this was."}, {"time": 4981, "text": "This opened my eyes."}, {"time": 4982, "text": "Actually, the way people use a product is very different than the way they talk about it."}, {"time": 4987, "text": "This is true with robotics, with everything."}, {"time": 4989, "text": "Everybody has dreams of how a particular product might be used or so on."}, {"time": 4993, "text": "And then when it meets reality, there's a lot of fear of robotics, for example, that robots are somehow dangerous and all those kinds of things."}, {"time": 5000, "text": "But when you actually have robots in your life, whether it's in the factory or in the home, making your life better, that's going to be that's way different."}, {"time": 5008, "text": "Your perceptions of it are going to be way different."}, {"time": 5010, "text": "And so my just tension was like, here's an innovator."}, {"time": 5014, "text": "Supercruise from Cadillac was super interesting, too."}, {"time": 5021, "text": "That's a really interesting system."}, {"time": 5023, "text": "We should be excited by those innovations."}, {"time": 5025, "text": "OK, so can I tell you something that's really annoyed me recently?"}, {"time": 5029, "text": "It's really annoyed me that the press and friends of mine on Facebook are going, these billionaires and their space games, why are they doing that?"}, {"time": 5039, "text": "And that really, really pisses me off."}, {"time": 5042, "text": "I must say, I applaud that."}, {"time": 5045, "text": "I applaud it."}, {"time": 5046, "text": "It's the taking and not necessarily the people who are doing the things, but, you know, that I keep having to push back against unrealistic expectations when these things can become real."}, {"time": 5060, "text": "Yeah, I this was interesting on because there's been a particular focus for me is autonomous driving, Elon's prediction of when certain milestones will be hit."}, {"time": 5070, "text": "There's several things to be said there that I always I thought about, because whenever you said them, it was obvious that's not going to me as a person that kind of not inside the system is obvious."}, {"time": 5086, "text": "It's unlikely to hit those."}, {"time": 5088, "text": "There's two comments I want to make."}, {"time": 5090, "text": "One, he legitimately believes it."}, {"time": 5094, "text": "And two, much more importantly, I think that having ambitious deadlines drives people to do the best work of their life, even when the odds of those deadlines are very low."}, {"time": 5109, "text": "To a point, and I'm not talking about anyone here, I'm just saying."}, {"time": 5112, "text": "So there's a line there, right?"}, {"time": 5114, "text": "You have to have a line because you overextend and it's demoralizing."}, {"time": 5120, "text": "It's demoralizing, but I will say that there's an additional thing here that those words also drive the stock market."}, {"time": 5134, "text": "And we have because of the way that rich people in the past have manipulated the rubes through investment, we have developed laws about what you're allowed to say."}, {"time": 5149, "text": "And you know, there's an area here which is I tend to be maybe I'm naive, but I tend to believe that like engineers, innovators, people like that, they're not they're my they don't think like that, like manipulating the price of the stock price."}, {"time": 5169, "text": "But it's possible that I'm I'm certain it's possible that I'm wrong."}, {"time": 5173, "text": "It's a very cynical view of the world because I think most people that run companies, especially original founders, they yeah, I'm not saying that's the intent."}, {"time": 5187, "text": "I'm saying it's eventually it's kind of you you you you fall into that kind of behavior pattern."}, {"time": 5193, "text": "I tend to I wasn't saying I wasn't saying it's falling into that intent."}, {"time": 5197, "text": "It's just you also have to protect investors in this environment."}, {"time": 5203, "text": "In this market."}, {"time": 5205, "text": "OK, so you have first of all, you have an amazing blog that people should check out."}, {"time": 5210, "text": "But you also have this in that blog, a set of predictions."}, {"time": 5214, "text": "Such a cool idea."}, {"time": 5215, "text": "I don't know how long ago you started, like three, four years ago."}, {"time": 5218, "text": "It was January 1st, 2018."}, {"time": 5221, "text": "18."}, {"time": 5222, "text": "And I made these predictions and I said that every January 1st, I was going to check back on how my predictions."}, {"time": 5229, "text": "That's such a great thought experiment."}, {"time": 5230, "text": "For 32 years."}, {"time": 5231, "text": "Oh, you said 32 years."}, {"time": 5233, "text": "I said 32 years because it's still that'll be January 1st, 2050."}, {"time": 5236, "text": "I'll be I will just turn ninety."}, {"time": 5241, "text": "Five, you know, and so people know that your predictions, at least for now, are in the space of artificial intelligence."}, {"time": 5253, "text": "Yeah, I didn't say I was going to make new predictions."}, {"time": 5254, "text": "I was just going to measure this set of predictions that I made because I was sort of I was sort of annoyed that everyone could make predictions."}, {"time": 5260, "text": "They didn't come true and everyone forgot."}, {"time": 5262, "text": "So I should hold myself to a high standard."}, {"time": 5264, "text": "Yeah, but also just putting years and like date ranges on things."}, {"time": 5268, "text": "It's a good thought exercise."}, {"time": 5270, "text": "Yeah, like and like reasoning your thoughts out."}, {"time": 5272, "text": "And so the topics are artificial intelligence, autonomous vehicles and space."}, {"time": 5280, "text": "I was wondering if we could just go through some that stand out maybe from memory."}, {"time": 5284, "text": "I can just mention to you some."}, {"time": 5286, "text": "Let's talk about self driving cars, like some predictions that you're particularly proud of or are particularly interesting from flying cars to the other element here is like how widespread the location where the deployment of the autonomous vehicles is."}, {"time": 5305, "text": "And there's also just a few fun ones."}, {"time": 5307, "text": "Is there something that jumps to mind that you remember from the predictions?"}, {"time": 5311, "text": "Well, I think I did put in there that there would be a dedicated self driving lane on 101 by some year, and I think I was over optimistic on that one."}, {"time": 5322, "text": "Yeah, I actually do remember that."}, {"time": 5324, "text": "But you I think you were mentioning like difficulties at different cities."}, {"time": 5330, "text": "Cambridge, Massachusetts, I think was an example."}, {"time": 5332, "text": "Yeah, like in Cambridge Port, you know, I lived in Cambridge Port for a number of years and you know, the roads are narrow and getting getting anywhere as a human driver is incredibly frustrating when you start to put and people drive the wrong way on one way streets there."}, {"time": 5347, "text": "It's just your prediction was driverless taxi services operating on all streets in Cambridge Port, Massachusetts in 2035."}, {"time": 5361, "text": "And that may have been too optimistic."}, {"time": 5366, "text": "You know, I've gotten a little more pessimistic since I made these internally on some of these things."}, {"time": 5371, "text": "So what can you put a year to a major milestone of deployment of a taxi service in in a few major cities like something where you feel like autonomous vehicles are here."}, {"time": 5387, "text": "So let's let's take the grid streets of San Francisco north of market."}, {"time": 5397, "text": "Relatively benign environment, the streets are wide, the major problem is delivery trucks stopping everywhere, which made things more complicated."}, {"time": 5412, "text": "Taxi system there with somewhat designated pickup and drop offs, unlike with Uber and Lyft, where you can sort of get to any place and the drivers will figure out how to get in there."}, {"time": 5430, "text": "We're still a few years away."}, {"time": 5432, "text": "I, you know, I live in that area."}, {"time": 5435, "text": "So I see, you know, the self driving car companies cars, multiple multiple ones every day."}, {"time": 5442, "text": "Now if they're cruise, Zooks less often, Waymo all the time, different and different ones come and go."}, {"time": 5453, "text": "And there's always a driver."}, {"time": 5455, "text": "There's always a driver at the moment, although I have noticed that sometimes the driver does not have the authority to take over without talking to the home office, because they will sit there waiting for a long time, and clearly something's going on where the home office is making a decision."}, {"time": 5476, "text": "So they're, you know, and, and so you can see whether they've got their hands on the wheel or not."}, {"time": 5482, "text": "And, and it's the incident resolution time that tells you, gives you some clues."}, {"time": 5488, "text": "So what year do you think, what's your intuition?"}, {"time": 5490, "text": "What date range are you currently thinking San Francisco would be?"}, {"time": 5494, "text": "Are you currently thinking San Francisco would be autonomous taxi service from any point A to any point B without a driver?"}, {"time": 5507, "text": "Are you still, are you thinking 10 years from now, 20 years from now, 30 years from now?"}, {"time": 5513, "text": "Certainly not 10 years from now."}, {"time": 5515, "text": "It's going to be longer."}, {"time": 5516, "text": "If you're allowed to go south of market way longer."}, {"time": 5519, "text": "And unless it's reengineering of roads."}, {"time": 5523, "text": "By the way, what's the biggest challenge?"}, {"time": 5525, "text": "You mentioned a few."}, {"time": 5526, "text": "Is it, is it the delivery trucks?"}, {"time": 5529, "text": "Is it the edge cases, the computer perception, well, here's a case that I saw outside my house a few weeks ago, about 8pm on a Friday night, it was getting dark, it was before the solstice."}, {"time": 5543, "text": "It was a cruise vehicle come down the hill, turned right and stopped dead, covering the crosswalk."}, {"time": 5553, "text": "Why did it stop dead?"}, {"time": 5555, "text": "Because there was a human just two feet from it."}, {"time": 5558, "text": "Now, I just glanced, I knew what was happening."}, {"time": 5561, "text": "The human was a woman was at the door of her car trying to unlock it with one of those things that, you know, when you don't have a key."}, {"time": 5570, "text": "That car thought, oh, she could jump out in front of me any second."}, {"time": 5575, "text": "As a human, I could tell, no, she's not going to jump out."}, {"time": 5577, "text": "She's busy trying to unlock her."}, {"time": 5579, "text": "She's lost her keys."}, {"time": 5580, "text": "She's trying to get in the car."}, {"time": 5581, "text": "And it stayed there for, until I got bored."}, {"time": 5585, "text": "And so the human driver in there did not take over."}, {"time": 5591, "text": "But here's the kicker to me."}, {"time": 5594, "text": "A guy comes down the hill with a stroller, I assume there's a baby in there, and now the crosswalk's blocked by this cruise vehicle."}, {"time": 5605, "text": "What's he going to do?"}, {"time": 5607, "text": "Cleverly, I think, he decided not to go in front of the car."}, {"time": 5610, "text": "But he had to go behind it."}, {"time": 5614, "text": "He had to get off the crosswalk, out into the intersection, to push his baby around this car, which was stopped there."}, {"time": 5621, "text": "And no human driver would have stopped there for that length of time."}, {"time": 5624, "text": "They would have got out and out of the way."}, {"time": 5626, "text": "And that's another one of my pet peeves, that safety is being compromised for individuals who didn't sign up for having this happen in their neighborhood."}, {"time": 5639, "text": "Now you can say that's an edge case, but... Yeah, well, I'm in general not a fan of anecdotal evidence for stuff like this is one of my biggest problems with the discussion of autonomous vehicles in general, people that criticize them or support them are using edge cases, are using anecdotal evidence, but I got you."}, {"time": 5664, "text": "Your question is, when is it going to happen in San Francisco?"}, {"time": 5666, "text": "I say not soon, but it's going to be one of them."}, {"time": 5669, "text": "But where it is going to happen is in limited domains, campuses of various sorts, gated communities where the other drivers are not arbitrary people."}, {"time": 5686, "text": "They're people who know about these things, they've been warned about them, and at velocities where it's always safe to stop dead."}, {"time": 5697, "text": "You can't do that on the freeway."}, {"time": 5698, "text": "That I think we're going to start to see, and they may not be shaped like current cars, they may be things like May Mobility has those things and various companies have these."}, {"time": 5712, "text": "Yeah, I wonder if that's a compelling experience."}, {"time": 5714, "text": "To me, it's not just about automation, it's about creating a product that makes your..."}, {"time": 5720, "text": "It's not just cheaper, but it's fun to ride."}, {"time": 5723, "text": "One of the least fun things is for a car that stops and waits."}, {"time": 5729, "text": "There's something deeply frustrating for us humans for the rest of the world to take advantage of us as we wait."}, {"time": 5735, "text": "But think about not you as the customer, but someone who's in their 80s in a retirement village whose kids have said, you're not driving anymore, and this gives you the freedom to go to the market."}, {"time": 5754, "text": "That's a hugely beneficial thing, but it's a very few orders of magnitude less impact on the world."}, {"time": 5760, "text": "It's just a few people in a small community using cars as opposed to the entirety of the world."}, {"time": 5767, "text": "I like that the first time that a car equipped with some version of a solution to the trolley problem is... What's NIML stand for?"}, {"time": 5776, "text": "Not in my life."}, {"time": 5777, "text": "I define my lifetime as up to 2050."}, {"time": 5780, "text": "You know, I ask you, when have you had to decide which person shall I kill?"}, {"time": 5789, "text": "No, you put the brakes on and you break as hard as you can."}, {"time": 5791, "text": "You're not making that decision."}, {"time": 5795, "text": "I do think autonomous vehicles or semi autonomous vehicles do need to solve the whole pedestrian problem that has elements of the trolley problem within it, but it's not... Yeah, well, and I talk about it in one of the articles or blog posts that I wrote, and people have told me, one of my coworkers has told me he does this."}, {"time": 5816, "text": "He tortures autonomously driven vehicles and pedestrians will torture them."}, {"time": 5821, "text": "Now, once they realize that putting one foot off the curb makes the car think that they might walk into the road, teenagers will be doing that all the time."}, {"time": 5830, "text": "I, by the way, one of my, and this is a whole nother discussion, because my main interest with robotics is HRI, human robot interaction."}, {"time": 5839, "text": "I believe that robots that interact with humans will have to push back."}, {"time": 5845, "text": "Like they can't just be bullied because that creates a very uncompelling experience for the humans."}, {"time": 5851, "text": "Yeah, well, you know, Waymo, before it was called Waymo, discovered that, you know, they had to do that at four way intersections."}, {"time": 5858, "text": "They had to nudge forward to give the cue that they were going to go, because otherwise the other drivers would just beat them all the time."}, {"time": 5866, "text": "So you cofounded iRobot, as we mentioned, one of the most successful robotics companies ever."}, {"time": 5873, "text": "What are you most proud of with that company and the approach you took to robotics?"}, {"time": 5880, "text": "Well, there's something I'm quite proud of there, which may be a surprise, but, you know, I was still on the board when this happened, it was March 2011, and we sent robots to Japan and they were used to help shut down the Fukushima Daiichi nuclear power plant, which was, everything was, I've been there since, I was there in 2014, and the robots, some of the robots were still there."}, {"time": 5913, "text": "I was proud that we were able to do that."}, {"time": 5915, "text": "Why were we able to do that?"}, {"time": 5918, "text": "And, you know, people have said, well, you know, Japan is so good at robotics."}, {"time": 5922, "text": "It was because we had had about 6,500 robots deployed in Iraq and Afghanistan, teleopt, but with intelligence, dealing with roadside bombs."}, {"time": 5970, "text": "What about just the simple, and for people who don't know, one of the things that iRobot has created is the Roomba vacuum cleaner."}, {"time": 5982, "text": "What about the simple robot that, that is the Roomba, quote unquote, simple, that's deployed in tens of millions of, in tens of millions of homes?"}, {"time": 6034, "text": "What was I doing at the time we were building, building the Roomba?"}, {"time": 6041, "text": "One of the things was we had this, you know, incredibly tight budget because we wanted to put it on the shelves at $200."}, {"time": 6050, "text": "There was another home cleaning robot at the time, it was the Electrolux Trilobite, which sold for 2,000 euros, and to us that was not going to be a consumer product, so we had reason to believe that $200 was a, was a thing that people would buy at."}, {"time": 6070, "text": "That was our aim, but that meant we had, you know, that's on the shelf making profit."}, {"time": 6079, "text": "That means the cost of goods has to be minimal, so I find all these emails of me going, you know, I'd be in Taipei for a MIT meeting, and I'd stay a few extra days and go down to Hsinchu and talk to these little tiny companies, lots of little tiny companies outside of TSMC, Taiwan Semiconductor Manufacturing Corporation, which let all these little companies be fabulous."}, {"time": 6174, "text": "Yeah, and you were excited."}, {"time": 6177, "text": "Yeah, and I was reading all these emails, Colin, I found this, so."}, {"time": 6182, "text": "Did you think, did you ever think that you guys could be so successful?"}, {"time": 6187, "text": "Like, eventually this company would be so successful, could you possibly have imagined?"}, {"time": 6192, "text": "No, we never did think that."}, {"time": 6193, "text": "We'd had 14 failed business models up to 2002, and then we had two winners the same year."}, {"time": 6199, "text": "No, and then, you know, we, I remember the board, because by this time we had some venture capital in, the board went along with us building some robots for, you know, aiming at the Christmas 2002 market, and we went three times over what they authorized and built 70,000 of them, and sold them all in that first, because we released on September 18th, and they were all sold by Christmas."}, {"time": 6232, "text": "So it was, so we were gutsy, but."}, {"time": 6237, "text": "But yeah, you didn't think this will take over the world."}, {"time": 6240, "text": "Well, this is, so a lot of amazing robotics companies have gone under over the past few decades."}, {"time": 6250, "text": "Why do you think it's so damn hard to run a successful robotics company?"}, {"time": 6257, "text": "There's a few things."}, {"time": 6260, "text": "One is expectations of capabilities by the founders that are off base."}, {"time": 6269, "text": "The founders, not the consumer, the founders."}, {"time": 6271, "text": "Yeah, expectations of what can be delivered."}, {"time": 6274, "text": "Mispricing, and what a customer thinks is a valid price, is not rational, necessarily."}, {"time": 6283, "text": "And expectations of customers, and just the sheer hardness of getting people to adopt a new technology."}, {"time": 6297, "text": "And I've suffered from all three of these, you know."}, {"time": 6299, "text": "I've had more failures than successes, in terms of companies."}, {"time": 6304, "text": "I've suffered from all three."}, {"time": 6307, "text": "So, do you think one day there will be a robotics company, and by robotics company, I mean, where your primary source of income is from robots, that will be a trillion plus dollar company?"}, {"time": 6324, "text": "And if so, what would that company do?"}, {"time": 6331, "text": "I can't, you know, because I'm still starting robot companies."}, {"time": 6338, "text": "I'm not making any such predictions in my own mind."}, {"time": 6341, "text": "I'm not thinking about a trillion dollar company."}, {"time": 6343, "text": "And by the way, I don't think, you know, in the 90s, anyone was thinking that Apple would ever be a trillion dollar company."}, {"time": 6348, "text": "So, these are, these are, you know, these are, you know, these are, you know, these would be a trillion dollar company, so these are, these are very hard to predict."}, {"time": 6357, "text": "But, sorry to interrupt, but don't you, because I kind of have a vision in a small way, and it's a big vision in a small way, that I see that there would be robots in the home, at scale, like Roomba, but more."}, {"time": 6373, "text": "And that's trillion dollar."}, {"time": 6376, "text": "And I think there's a real market pull for them because of the demographic inversion, you know, who's going to do all the stuff for the older people?"}, {"time": 6386, "text": "There's too many, you know, I'm leading here."}, {"time": 6391, "text": "There's going to be too many of us."}, {"time": 6396, "text": "But we don't have capable enough robots to make that economic argument at this point."}, {"time": 6402, "text": "Do I expect that that will happen?"}, {"time": 6404, "text": "Yes, I expect it will happen."}, {"time": 6405, "text": "But I got to tell you, we introduced the Roomba in 2002, and I stayed another nine years."}, {"time": 6411, "text": "We were always trying to find what the next home robot would be, and still today, the primary product of 20 years late, almost 20 years later, 19 years later, the primary product is still the Roomba."}, {"time": 6423, "text": "So iRobot hasn't found the next one."}, {"time": 6427, "text": "Do you think it's possible for one person in the garage to build it versus, like, Google launching Google self driving car that turns into Waymo?"}, {"time": 6436, "text": "Do you think this is almost like what it takes to build a successful robotics company?"}, {"time": 6440, "text": "Do you think it's possible to go from the ground up, or is it just too much capital investment?"}, {"time": 6445, "text": "Yeah, so it's very hard to get there without a lot of capital."}, {"time": 6451, "text": "And we're starting to see, you know, fair chunks of capital for some robotics companies."}, {"time": 6458, "text": "You know, Series B's, I saw one yesterday for $80 million, I think it was, for Covariant."}, {"time": 6465, "text": "But it can take real money to get into these things, and you may fail along the way."}, {"time": 6474, "text": "I've certainly failed at Rethink Robotics, and we lost $150 million in capital there."}, {"time": 6480, "text": "So, okay, so Rethink Robotics is another amazing robotics company you cofounded."}, {"time": 6486, "text": "So what was the vision there?"}, {"time": 6489, "text": "What was the dream?"}, {"time": 6491, "text": "And what are you most proud of with Rethink Robotics?"}, {"time": 6495, "text": "I'm most proud of the fact that we got robots out of the cage in factories that were safe, absolutely safe, for people and robots to be next to each other."}, {"time": 6506, "text": "So these are robotic arms."}, {"time": 6507, "text": "Robotic arms."}, {"time": 6508, "text": "Able to pick up stuff and interact with humans."}, {"time": 6511, "text": "Yeah, and that humans could retask them without writing code."}, {"time": 6515, "text": "And now that's sort of become an expectation for a lot of other little companies and big companies, our advertising they're doing."}, {"time": 6522, "text": "That's both an interface problem and also a safety problem."}, {"time": 6527, "text": "So I'm most proud of that."}, {"time": 6531, "text": "I completely, I let myself be talked out of what I wanted to do."}, {"time": 6539, "text": "And, you know, you always got, you know, I can't replay the tape."}, {"time": 6542, "text": "I can't replay it."}, {"time": 6545, "text": "Maybe, you know, if I'd been stronger on, and I remember the day, I remember the exact meeting."}, {"time": 6553, "text": "Can you take me through that meeting?"}, {"time": 6558, "text": "So I'd said that I'd set as a target for the company that we were going to build $3,000 robots with force feedback that was safe for people to be around."}, {"time": 6570, "text": "That was my goal."}, {"time": 6571, "text": "And we built, so we started in 2008, and we had prototypes built of plastic, plastic gearboxes, and at a $3,000, you know, lifetime, or $3,000, I was saying, we're going to go after not the people who already have robot arms in factories, the people who would never have a robot arm."}, {"time": 6593, "text": "We're going to go after a different market."}, {"time": 6595, "text": "So we don't have to meet their expectations."}, {"time": 6597, "text": "And so we're going to build it out of plastic."}, {"time": 6599, "text": "It doesn't have to have a $35,000 lifetime."}, {"time": 6602, "text": "It's going to be so cheap that it's OpEx, not CapEx."}, {"time": 6609, "text": "And so we had a prototype that worked reasonably well, but the control engineers were complaining about these plastic gearboxes with a beautiful little planetary gearbox that we could use something called series elastic actuators."}, {"time": 6629, "text": "We embedded them in there."}, {"time": 6630, "text": "We could measure forces."}, {"time": 6632, "text": "We knew when we hit something, et cetera."}, {"time": 6635, "text": "The control engineers were saying, yeah, but there's this torque ripple because these plastic gears, they're not great gears, and there's this ripple, and trying to do force control around this ripple is so hard."}, {"time": 6647, "text": "And I'm not going to name names, but I remember one of the mechanical engineers saying, we'll just build a metal gearbox with spur gears, and it'll take six weeks."}, {"time": 6659, "text": "We'll be done."}, {"time": 6663, "text": "Two years later, we got the spur gearbox working."}, {"time": 6668, "text": "We cost reduced it every possible way we could, but now the price went up too."}, {"time": 6675, "text": "And then the CEO at the time said, well, we have to have two arms, not one arm."}, {"time": 6679, "text": "So our first robot product, Baxter, now cost $25,000, and the only people who were going to look at that were people who had arms in factories because that was somewhat cheaper for two arms than arms in factories."}, {"time": 6694, "text": "But they were used to 0.1 millimeter reproducibility of motion and certain velocities, and I kept thinking, but that's not what we're giving you."}, {"time": 6705, "text": "You don't need position repeatability."}, {"time": 6707, "text": "Use force control like a human does."}, {"time": 6709, "text": "No, no, but we want that repeatability."}, {"time": 6713, "text": "We want that repeatability."}, {"time": 6714, "text": "All the other robots have that repeatability."}, {"time": 6716, "text": "Why don't you have that repeatability?"}, {"time": 6718, "text": "So can you clarify?"}, {"time": 6719, "text": "Force control is you can grab the arm and you can move it."}, {"time": 6722, "text": "You can move it around, but suppose you... Can you see that?"}, {"time": 6727, "text": "Suppose you want to..."}, {"time": 6730, "text": "Suppose this thing is a precise thing that's got to fit here in this right angle."}, {"time": 6736, "text": "Under position control, you have fixtured where this is."}, {"time": 6740, "text": "You know where this is precisely, and you just move it, and it goes there."}, {"time": 6745, "text": "In force control, you would do something like slide over here till we feel that and slide it in there, and that's how a human gets precision."}, {"time": 6754, "text": "They use force feedback and get the things to mate rather than just go straight to it."}, {"time": 6762, "text": "Couldn't convince our customers who were in factories and were used to thinking about things a certain way, and they wanted it, wanted it, wanted it."}, {"time": 6771, "text": "So then we said, okay, we're going to build an arm that gives you that."}, {"time": 6776, "text": "So now we ended up building a $35,000 robot with one arm with... Oh, what are they called?"}, {"time": 6784, "text": "A certain sort of gearbox made by a company whose name I can't remember right now, but it's the name of the gearbox."}, {"time": 6791, "text": "But it's got torque ripple in it."}, {"time": 6795, "text": "So now there was an extra two years of solving the problem of doing the force with the torque ripple."}, {"time": 6800, "text": "So we had to do the thing we had avoided for the plastic gearboxes, which is a little bit for the plastic gearboxes we ended up having to do."}, {"time": 6811, "text": "The robot was now overpriced and they... And that was your intuition from the very beginning kind of that this is not... You're opening a door to solve a lot of problems that you're eventually going to have to solve this problem anyway."}, {"time": 6826, "text": "And also I was aiming at a low price to go into a different market."}, {"time": 6829, "text": "Low price."}, {"time": 6830, "text": "That didn't have robots."}, {"time": 6831, "text": "$3,000 would be amazing."}, {"time": 6832, "text": "I think we could have done it for five."}, {"time": 6834, "text": "But, you know, you talked about setting the goal a little too far for the engineers."}, {"time": 6842, "text": "So why would you say that company not failed, but went under?"}, {"time": 6849, "text": "We had buyers and there's this thing called the Committee on Foreign Investment in the U.S., CFIUS."}, {"time": 6858, "text": "And that had previously been invoked twice."}, {"time": 6861, "text": "Around where the government could stop foreign money coming into a U.S. company based on defense requirements."}, {"time": 6872, "text": "We went through due diligence multiple times."}, {"time": 6874, "text": "We were going to get acquired, but every consortium had Chinese money in it, and all the bankers would say at the last minute, you know, this isn't going to get past CFIUS, and the investors would go away."}, {"time": 6887, "text": "And then we had two buyers, once we were about to run out of money, two buyers, and one used heavy handed legal stuff with the other one, said they were going to take it and pay more, dropped out when we were out of cash, and then bought the assets at 1 30th of the price they had offered a week before."}, {"time": 6910, "text": "It was a tough week."}, {"time": 6912, "text": "Do you, does it hurt to think about like an amazing company that didn't, you know, like iRobot didn't find a way?"}, {"time": 6924, "text": "Yeah, it was tough."}, {"time": 6925, "text": "I said I was never going to start another company."}, {"time": 6927, "text": "I was pleased that everyone liked what we did so much that the team was hired by three companies, and I was very happy that we were able to do that."}, {"time": 6940, "text": "Three companies within a week."}, {"time": 6942, "text": "Everyone had a job in one of these three companies."}, {"time": 6944, "text": "Some stayed in their same desks because another company came in and rented the space."}, {"time": 6950, "text": "So I felt good about people not being out on the street."}, {"time": 6955, "text": "So Baxter has a screen with a face."}, {"time": 6959, "text": "What, that's a revolutionary idea for a robot manipulation, like for a robotic arm."}, {"time": 6967, "text": "How much opposition did you get?"}, {"time": 6968, "text": "Well, first the screen was also used during codeless programming."}, {"time": 6972, "text": "We taught by demonstration."}, {"time": 6974, "text": "It showed you what its understanding of the task was."}, {"time": 6977, "text": "So it had two roles."}, {"time": 6981, "text": "Some customers hated it, and so we made it so that when the robot was running it could be showing graphs of what was happening and not show the eyes."}, {"time": 6990, "text": "Other people, and some of them surprised me who they were, saying well this one doesn't look as human as the old one."}, {"time": 6997, "text": "We liked the human looking."}, {"time": 7000, "text": "So there was a mixed bag."}, {"time": 7003, "text": "But do you think that's, I don't know, I'm kind of disappointed whenever I talk to roboticists, like the best robotics people in the world, they seem to not want to do the eyes type of thing."}, {"time": 7016, "text": "Like they seem to see it as a machine as opposed to a machine that can also have a human connection."}, {"time": 7023, "text": "It seems like a lost opportunity."}, {"time": 7025, "text": "I think the trillion dollar company will have to do the human connection very well no matter what it does."}, {"time": 7037, "text": "I might give a ridiculous answer."}, {"time": 7039, "text": "Do you think, well maybe by way of asking the question, let me first mention that you're kind of critical of the idea of the Turing test as a test of intelligence."}, {"time": 7052, "text": "Let me first ask this question."}, {"time": 7053, "text": "Do you think we'll be able to build an AI system that humans fall in love with and it falls in love with the human, like romantic love?"}, {"time": 7066, "text": "Well, we've had that with humans falling in love with cars even back in the 50s."}, {"time": 7071, "text": "It's a different love, right?"}, {"time": 7073, "text": "I think there's a lifelong partnership where you can communicate and grow like..."}, {"time": 7079, "text": "I think we're a long way from that."}, {"time": 7081, "text": "I think we're a long, long way."}, {"time": 7083, "text": "I think Blade Runner had the time scale totally wrong."}, {"time": 7090, "text": "Yeah, but so to me, honestly, the most difficult part is the thing that you said with the Marvex Paradox is to create a human form that interacts and perceives the world."}, {"time": 7101, "text": "But if we just look at a voice, like the movie Her or just like an Alexa type voice, I tend to think we're not that far away."}, {"time": 7109, "text": "Well, for some people, maybe not, but as humans, as we think about the future, we always try to... And this is the premise of most science fiction movies."}, {"time": 7126, "text": "You've got the world just as it is today and you change one thing."}, {"time": 7130, "text": "But that's not how... And it's the same with a self driving car."}, {"time": 7133, "text": "You change one thing."}, {"time": 7135, "text": "No, everything changes."}, {"time": 7136, "text": "Everything grows together."}, {"time": 7139, "text": "So surprisingly, it might be surprising to you or might not, I think the best movie about this stuff was Bicentennial Man."}, {"time": 7149, "text": "And what was happening there?"}, {"time": 7151, "text": "It was schmaltzy and, you know, but what was happening there?"}, {"time": 7155, "text": "As the robot was trying to become more human, the humans were adopting the technology of the robot and changing their bodies."}, {"time": 7163, "text": "So there was a convergence happening in a sense."}, {"time": 7167, "text": "So we will not be the same."}, {"time": 7168, "text": "You know, we're already talking about genetically modifying our babies."}, {"time": 7172, "text": "You know, there's more and more stuff happening around that."}, {"time": 7176, "text": "We will want to modify ourselves even more for all sorts of things."}, {"time": 7183, "text": "We put all sorts of technology in our bodies to improve it."}, {"time": 7188, "text": "You know, I've got things in my ears so that I can sort of hear you."}, {"time": 7196, "text": "So we're always modifying our bodies."}, {"time": 7197, "text": "So, you know, I think it's hard to imagine exactly what it will be like in the future."}, {"time": 7203, "text": "But on the Turing test side, do you think, so forget about love for a second, let's talk about just like the Alexa Prize."}, {"time": 7212, "text": "Actually, I was invited to be a part of the Alexa Prize."}, {"time": 7216, "text": "Actually, I was invited to be a, what is the interviewer for the Alexa Prize or whatever that's in two days."}, {"time": 7225, "text": "Their idea is success looks like a person wanting to talk to an AI system for a prolonged period of time, like 20 minutes."}, {"time": 7235, "text": "How far away are we and why is it difficult to build an AI system with which you'd want to have a beer and talk for an hour or two hours?"}, {"time": 7245, "text": "Like not for to check the weather or to check music, but just like to talk as friends."}, {"time": 7253, "text": "Yeah, well, you know, we saw Weizenbaum back in the 60s with his programmer, Elisa, being shocked at how much people would talk to Elisa."}, {"time": 7263, "text": "And I remember, you know, in the 70s typing, you know, stuff to Elisa to see what it would come back with."}, {"time": 7269, "text": "You know, I think right now, and this is a thing that Amazon's been trying to improve with Alexa, there is no continuity of topic."}, {"time": 7282, "text": "There's not, you can't refer to what we talked about yesterday."}, {"time": 7287, "text": "It's not the same as talking to a person where there seems to be an ongoing existence, which changes."}, {"time": 7293, "text": "We share moments together and they last in our memory together."}, {"time": 7297, "text": "Yeah, there's none of that."}, {"time": 7299, "text": "And there's no sort of intention of these systems that they have any goal in life, even if it's to be happy, you know, they don't even have a semblance of that."}, {"time": 7311, "text": "Now, I'm not saying this can't be done."}, {"time": 7313, "text": "I'm just saying, I think this is why we don't feel that way about them."}, {"time": 7317, "text": "That's a sort of a minimal requirement."}, {"time": 7321, "text": "If you want the sort of interaction you're talking about, it's a minimal requirement."}, {"time": 7326, "text": "Whether it's going to be sufficient, I don't know."}, {"time": 7330, "text": "We haven't seen it yet."}, {"time": 7331, "text": "We don't know what it feels like."}, {"time": 7334, "text": "I tend to think it's not as difficult as solving intelligence, for example, and I think it's achievable in the near term."}, {"time": 7346, "text": "But on the Turing test, why don't you think the Turing test is a good test of intelligence?"}, {"time": 7352, "text": "Oh, because, you know, again, the Turing, if you read the paper, Turing wasn't saying this is a good test."}, {"time": 7360, "text": "He was using it as a rhetorical device to argue that if you can't tell the difference between a computer and a person, you must say that the computer's thinking because you can't tell the difference, you know, when it's thinking."}, {"time": 7376, "text": "You can't say something different."}, {"time": 7378, "text": "What it has become as this sort of weird game of fooling people, so back at the AI Lab in the late 80s, we had this thing that still goes on called the AI Olympics, and one of the events we had one year was the original imitation game, as Turing talked about, because he starts by saying, can you tell whether it's a man or a woman?"}, {"time": 7405, "text": "So we did that at the Lab."}, {"time": 7408, "text": "You'd go and type, and the thing would come back, and you had to tell whether it was a man or a woman, and one man came up with a question that he could ask, which was always a dead giveaway of whether the other person was really a man or a woman."}, {"time": 7436, "text": "He would ask them, did you have green plastic toy soldiers as a kid?"}, {"time": 7441, "text": "What did you do with them?"}, {"time": 7443, "text": "And a woman trying to be a man would say, oh, I lined them up."}, {"time": 7447, "text": "We had wars."}, {"time": 7447, "text": "We had battles."}, {"time": 7448, "text": "And the man, just being a man, would say, I stomped on them."}, {"time": 7451, "text": "I burned them."}, {"time": 7451, "text": "So that's what the Turing test with computers has become."}, {"time": 7461, "text": "What's the trick question?"}, {"time": 7463, "text": "That's why I say it's sort of devolved into this weirdness."}, {"time": 7469, "text": "Nevertheless, conversation not formulated as a test is a fascinatingly challenging dance."}, {"time": 7476, "text": "That's a really hard problem."}, {"time": 7478, "text": "To me, conversation, when non poses a test, is a more intuitive illustration how far away we are from solving intelligence than computer vision."}, {"time": 7489, "text": "Computer vision is harder for me to pull apart."}, {"time": 7493, "text": "But with language, with conversation, you could see."}, {"time": 7495, "text": "Because language is so human."}, {"time": 7496, "text": "It's so human."}, {"time": 7498, "text": "We can so clearly see it."}, {"time": 7504, "text": "Shit, you mentioned something I was going to go off on."}, {"time": 7508, "text": "I mean, I have to ask you, because you were the head of CSAIL, AI Lab, for a long time."}, {"time": 7518, "text": "To me, when I came to MIT, you were one of the greats at MIT."}, {"time": 7522, "text": "So what was that time like?"}, {"time": 7525, "text": "And plus, you're friends with, but you knew Minsky and all the folks there, all the legendary AI people of which you're one."}, {"time": 7539, "text": "What are memories that stand out to you from that time, from your time at MIT, from the AI Lab, from the dreams that the AI Lab represented, to the actual revolutionary work?"}, {"time": 7553, "text": "Well, let me tell you first the disappointment in myself."}, {"time": 7556, "text": "As I've been researching this book, and so many of the players were active in the 50s and 60s, I knew many of them when they were older, and I didn't ask them all the questions now I wish I had asked."}, {"time": 7571, "text": "I'd sit with them at our Thursday lunches, which we had a faculty lunch, and I didn't ask them so many questions that now I wish I had."}, {"time": 7579, "text": "Can I ask you that question?"}, {"time": 7580, "text": "Because you wrote that."}, {"time": 7582, "text": "You wrote that you were fortunate to know and rub shoulders with many of the greats, those who founded AI, robotics, and computer science, and the World Wide Web."}, {"time": 7590, "text": "And you wrote that your big regret nowadays is that often I have questions for those who have passed on, and I didn't think to ask them any of these questions, even as I saw them and said hello to them on a daily basis."}, {"time": 7604, "text": "So maybe also another question I want to ask, if you could talk to them today, what question would you ask?"}, {"time": 7611, "text": "What questions would you ask?"}, {"time": 7613, "text": "Well, Licklider, I would ask him."}, {"time": 7616, "text": "You know, he had the vision for humans and computers working together, and he really founded that at DARPA, and he gave the money to MIT, which started Project MAC in 1963."}, {"time": 7632, "text": "And I would have talked to him about what the successes were, what the failures were, what he saw as progress, etc."}, {"time": 7638, "text": "I would have asked him more questions about that, because now I could use it in my book, you know, but I think it's lost."}, {"time": 7645, "text": "It's lost forever."}, {"time": 7646, "text": "A lot of the motivations are lost."}, {"time": 7653, "text": "I should have asked Marvin why he and Seymour Pappert came down so hard on neural networks in 1968 in their book Perceptrons, because Marvin's PhD thesis was all about neural networks."}, {"time": 7668, "text": "And how do you make sense of that?"}, {"time": 7670, "text": "That book destroyed the field."}, {"time": 7672, "text": "He probably, do you think he knew the effect that book would have?"}, {"time": 7679, "text": "All the theorems are negative theorems."}, {"time": 7685, "text": "That's just the way of, that's the way of life."}, {"time": 7690, "text": "But still, it's kind of tragic that he was both the proponent and the destroyer of neural networks."}, {"time": 7699, "text": "Is there other memories stand out from the robotics and the AI work at MIT?"}, {"time": 7708, "text": "Well, yeah, but you gotta be more specific."}, {"time": 7711, "text": "Well, I mean, like, it's such a magical place."}, {"time": 7713, "text": "I mean, to me, it's a little bit also heartbreaking that, you know, with Google and Facebook, like DeepMind and so on, so much of the talent, you know, it doesn't stay necessarily for prolonged periods of time in these universities."}, {"time": 7730, "text": "I mean, some of the companies are more guilty than others of paying fabulous salaries to some of the highest, you know, producers."}, {"time": 7740, "text": "And then just, you never hear from them again."}, {"time": 7742, "text": "They're not allowed to give public talks."}, {"time": 7744, "text": "They're sort of locked away."}, {"time": 7746, "text": "And it's sort of like collecting, you know, Hollywood stars or something."}, {"time": 7752, "text": "And they're not allowed to make movies anymore."}, {"time": 7753, "text": "I own them."}, {"time": 7755, "text": "That's tragic because, I mean, there's an openness to the university setting where you do research to both in the space of ideas and like publication, all those kinds of things."}, {"time": 7765, "text": "Yeah, you know, and, you know, there's the publication and all that."}, {"time": 7768, "text": "And often, you know, although these places say they publish."}, {"time": 7772, "text": "There's pressure."}, {"time": 7773, "text": "But I think, for instance, you know, on net net, I think Google buying those eight or nine robotics company was bad for the field because it locked those people away."}, {"time": 7786, "text": "They didn't have to make the company succeed anymore, locked them away for years, and then sort of all frid it away."}, {"time": 7796, "text": "So do you have hope for MIT, for MIT?"}, {"time": 7803, "text": "Why shouldn't I?"}, {"time": 7804, "text": "Well, I could be harsh and say that I'm not sure I would say MIT is leading the world in AI or even Stanford or Berkeley."}, {"time": 7815, "text": "I would say, I would say DeepMind, Google AI, Facebook AI, all of those things."}, {"time": 7823, "text": "I would take a slightly different approach, a different answer."}, {"time": 7830, "text": "I'll come back to Facebook in a minute."}, {"time": 7832, "text": "But I think those other places are following a dream of one of the founders."}, {"time": 7842, "text": "And I'm not sure that it's well founded, the dream."}, {"time": 7846, "text": "And I'm not sure that it's going to have the impact that he believes it is."}, {"time": 7854, "text": "You're talking about Facebook and Google and so on."}, {"time": 7856, "text": "I'm talking about Google."}, {"time": 7857, "text": "Google."}, {"time": 7858, "text": "But the thing is, those research labs aren't, there's the big dream."}, {"time": 7863, "text": "And I'm usually a fan of no matter what the dream is, a big dream is a unifier."}, {"time": 7868, "text": "Because what happens is you have a lot of bright minds working together on a dream."}, {"time": 7875, "text": "What results is a lot of adjacent ideas and how so much progress is made."}, {"time": 7881, "text": "So I'm not saying they're actually leading."}, {"time": 7882, "text": "I'm not saying that the universities are leading."}, {"time": 7885, "text": "But I don't think those companies are leading in general because they're, we saw this incredible spike in attendees at NeurIPS."}, {"time": 7896, "text": "And as I said in my January 1st review this year for 2020, 2020 will not be remembered as a watershed year for machine learning or AI."}, {"time": 7908, "text": "There was nothing surprising happened anyway."}, {"time": 7912, "text": "Unlike when deep learning hit ImageNet."}, {"time": 7917, "text": "That was a shake."}, {"time": 7922, "text": "And there's a lot more people writing papers, but the papers are fundamentally boring and uninteresting."}, {"time": 7928, "text": "Incremental work."}, {"time": 7930, "text": "Is there a particular memories you have with Minsky or somebody else at MIT that stand out, funny stories?"}, {"time": 7936, "text": "I mean, unfortunately, he's another one that's passed away."}, {"time": 7941, "text": "You've known some of the biggest minds in AI."}, {"time": 7945, "text": "And you know, they, they did amazing things and sometimes they were grumpy."}, {"time": 7951, "text": "Well, he was, uh, he was interesting cause he was very grumpy, but that, that was his, uh, I remember him saying in an interview that the key to success or being to keep being productive is to hate everything you've ever done in the past."}, {"time": 7965, "text": "Maybe that, maybe that explains the Perceptron book."}, {"time": 7969, "text": "There it was."}, {"time": 7970, "text": "He told you exactly."}, {"time": 7973, "text": "But he, meaning like, just like, I mean, maybe that's the way to not treat yourself too seriously."}, {"time": 7979, "text": "Just, uh, you know, you're not, you're not, you're not, you're not, you're not, you're not treating yourself too seriously."}, {"time": 7985, "text": "Just, uh, always be moving forward."}, {"time": 7989, "text": "Uh, that was the idea."}, {"time": 7990, "text": "I mean, that, that crankiness, I mean, there's a, uh, that's the scary."}, {"time": 7994, "text": "So let me, let me, let me tell you, uh, you know, what really, um, you know, the joy memories are about having access to technology before anyone else has seen it."}, {"time": 8007, "text": "You know, I got to Stanford in 1977 and we had, um, you know, we had terminals that could show live video on them."}, {"time": 8017, "text": "Um, digital, digital sound system."}, {"time": 8020, "text": "We had a Xerox graphics printer."}, {"time": 8025, "text": "We could print, um, uh, it wasn't, you know, it wasn't like a typewriter ball hitting in characters."}, {"time": 8031, "text": "It could print arbitrary things."}, {"time": 8033, "text": "I mean, you know, one bit, you know, black or white, but you get arbitrary pictures."}, {"time": 8038, "text": "This was science fiction sort of stuff."}, {"time": 8040, "text": "Um, um, at, at MIT, the, uh, the list machines, which, you know, they were the first personal computers and, you know, cost a hundred thousand dollars each."}, {"time": 8052, "text": "And I could, you know, I got there early enough in the day."}, {"time": 8054, "text": "I got one for the day."}, {"time": 8055, "text": "Couldn't, couldn't stand up."}, {"time": 8057, "text": "I had to keep working."}, {"time": 8058, "text": "Um, um, so they're having that like direct glimpse into the future."}, {"time": 8065, "text": "And, and, you know, I've had email every day since 1977."}, {"time": 8069, "text": "Um, and, uh, you know, the, the host field was only eight bits, you know, that many places, but I could send the email to other people at a few places."}, {"time": 8079, "text": "So that was, that was pretty exciting to be in that world so different from what the rest of the world knew."}, {"time": 8086, "text": "Um, uh, uh, let me ask you probably edit this out, but just in case you have a story, uh, I'm hanging out with Don Knuth, uh, for a while tomorrow."}, {"time": 8100, "text": "Did you ever get a chance to such a different world than yours?"}, {"time": 8103, "text": "He's a very kind of theoretical computer science, the puzzle of, uh, of, uh, computer science and mathematics."}, {"time": 8109, "text": "And you're so much about the magic of robotics, like the practice of it."}, {"time": 8113, "text": "You mentioned him earlier for like, not, you know, about computation."}, {"time": 8117, "text": "Did your worlds cross?"}, {"time": 8119, "text": "They did enough."}, {"time": 8120, "text": "You know, I, I know him now we talk, you know, but let me tell you my, my Donald Knuth story."}, {"time": 8126, "text": "So, um, you know, besides, you know, analysis of algorithms, he's well known for writing tech, which is in LaTeX, which is the academic publishing system."}, {"time": 8137, "text": "So he did that at the AI lab and he would do it."}, {"time": 8141, "text": "He would work overnight at the AI lab."}, {"time": 8145, "text": "And one, one day, one night, the, uh, the mainframe computer went down and, um, uh, a guy named Robert Pore was there."}, {"time": 8157, "text": "He did his PhD at the Media Lab at MIT and he was, um, you know, an engineer."}, {"time": 8164, "text": "And so I, he and I, you know, tracked down what were the problem was."}, {"time": 8168, "text": "It was one of this big refrigerator size or washing machine size disk drives had failed."}, {"time": 8173, "text": "And that's what brought the whole system down."}, {"time": 8175, "text": "So we've got panels pulled off and we're pulling, you know, circuit cards out."}, {"time": 8180, "text": "And Donald Knuth, who's a really tall guy walks in and he's looking down and says, when will it be fixed?"}, {"time": 8186, "text": "You know, cause he wanted to get back to writing his tech system."}, {"time": 8191, "text": "And so we, we figured out, you know, it was a particular chip, 7,400 series chip, which was socketed."}, {"time": 8198, "text": "We popped it out."}, {"time": 8200, "text": "We put a replacement in, put it back in."}, {"time": 8203, "text": "Smoke comes out cause we put it in backwards."}, {"time": 8205, "text": "Cause we were so nervous that Donald Knuth was standing over us."}, {"time": 8209, "text": "Anyway, we eventually got it fixed and got the mainframe running again."}, {"time": 8213, "text": "So that was your little, when was that again?"}, {"time": 8216, "text": "Well, that must have been before October 79."}, {"time": 8218, "text": "Cause we moved out of that building then."}, {"time": 8220, "text": "So sometime probably 78 sometime early 79."}, {"time": 8223, "text": "Yeah, those, all those figures is just fascinating."}, {"time": 8226, "text": "All the people with pass, pass through MIT is really fascinating."}, {"time": 8230, "text": "Is there, let me ask you to put on your big wise man hat."}, {"time": 8238, "text": "Is there advice that you can give to young people today, whether in high school or college who are thinking about their career or thinking about life, how to live a life they're proud of, a successful life?"}, {"time": 8252, "text": "So, so many people ask me for advice and have asked for, and I give, I talk to a lot of people all the time and there is no one way."}, {"time": 8264, "text": "You know, there's a lot of pressure to produce papers that will be acceptable and be published."}, {"time": 8276, "text": "Maybe I was, maybe I can't do it."}, {"time": 8278, "text": "Maybe I was, maybe I come from an age where I would, I could be a rebel against that and still succeed."}, {"time": 8287, "text": "Maybe it's harder today, but I think it's important not to get too caught up with what everyone else is doing."}, {"time": 8298, "text": "And if you, if, well, it depends on what you want of life."}, {"time": 8302, "text": "If you want to have real impact, you have to be ready to fail a lot of times."}, {"time": 8311, "text": "So you have to make a lot of unsafe decisions."}, {"time": 8314, "text": "And the only way to make that work is to make, keep doing it for a long time."}, {"time": 8318, "text": "And then one of them will be work out."}, {"time": 8320, "text": "And so that, that, that will make something successful."}, {"time": 8325, "text": "Or yeah, or you may, or you just may, you know, end up, you know, not having a, you know, having a lousy career."}, {"time": 8330, "text": "I mean, it's certainly possible."}, {"time": 8332, "text": "Taking the risk is the thing."}, {"time": 8336, "text": "But there's no way to, to make all safe decisions and actually really contribute."}, {"time": 8346, "text": "Do you think about your death, about your mortality?"}, {"time": 8352, "text": "I got to say when COVID hit, I did."}, {"time": 8355, "text": "Because we did, you know, in the early days, we didn't know how bad it was going to be."}, {"time": 8358, "text": "And I, that, that made me work on my book harder for a while, but then I'd started this company and now I'm doing full time, more than full time of the company."}, {"time": 8367, "text": "So the book's on hold, but I do want to finish this book."}, {"time": 8370, "text": "When you think about it, are you afraid of it?"}, {"time": 8375, "text": "I'm afraid of dribbling, you know, of losing it."}, {"time": 8382, "text": "The details of, okay."}, {"time": 8385, "text": "But the fact that the ride ends, I've known that for a long time."}, {"time": 8391, "text": "So it's, yeah, but there's knowing and knowing."}, {"time": 8395, "text": "It's such a, yeah."}, {"time": 8397, "text": "And it really sucks."}, {"time": 8398, "text": "It feels, it feels a lot closer."}, {"time": 8401, "text": "So my, in, in my, my blog with my predictions, my sort of push back against that was that I said, I'm going to review these every year for 32 years and that puts me into my mid nineties."}, {"time": 8414, "text": "So, you know, it's my whole every, every time you write the blog posts, you're getting closer and closer to your own prediction of your death."}, {"time": 8424, "text": "What do you hope your legacy is?"}, {"time": 8428, "text": "You're one of the greatest roboticist AI researchers of all time."}, {"time": 8434, "text": "What I hope is that I actually finished writing this book and that there's one person who reads it and see something about changing the way they're thinking."}, {"time": 8448, "text": "And that leads to the next big."}, {"time": 8454, "text": "And then there'll be on a podcast a hundred years from now saying I once read that book and that changed everything."}, {"time": 8466, "text": "This whole thing, the existence, the, the, the, all the hurried things we do on this planet, what do you think is the meaning of it all?"}, {"time": 8473, "text": "Well, you know, I think we're all really bad at it."}, {"time": 8477, "text": "Life or finding meaning or both."}, {"time": 8479, "text": "We get caught up in, in, in the, it's easy to get easier to do the stuff that's immediate and not through the stuff."}, {"time": 8484, "text": "It's not immediate."}, {"time": 8487, "text": "So the big picture we're bad at."}, {"time": 8491, "text": "Do you have a sense of what that big picture is?"}]}, {"title": "Peter Woit: Theories of Everything & Why String Theory is Not Even Wrong | Lex Fridman Podcast #246", "id": "nDDJFvuFXdc", "quotes": [{"time": 342, "text": "We grow up in this three spatial dimensional world and we have intimate understanding of certain kinds of geometry and certain kinds of things."}, {"time": 350, "text": "But these things that we've discovered in both math and physics are, that they're not at all close, have any obvious connection to kind of human everyday experience."}, {"time": 362, "text": "They're really quite different."}, {"time": 363, "text": "And I can say some of my initial fascination with this when I was young and starting to learn about it was actually exactly this kind of arcane nature of these things."}, {"time": 375, "text": "It was a little bit like being told, well, there are these kind of semi mystical experience that you can acquire by a long study and whatever, except that it was actually true."}, {"time": 387, "text": "There's actually evidence that this actually works."}, {"time": 389, "text": "So I'm a little bit wary of trying to give people that kind of thing, because I think it's mostly misleading."}, {"time": 395, "text": "But one thing to say is that geometry is a large part of it."}, {"time": 399, "text": "And maybe one interesting thing to say very, that's about more recent, some of the most recent ideas is that when we think about the geometry of our space and time, it's kind of three spatial and one time dimension."}, {"time": 413, "text": "It's a physics is in some sense about something that's kind of four dimensional in a way."}, {"time": 420, "text": "And a really interesting thing about some of the recent developments and number theory have been to realize that these ideas that we were looking at naturally fit into a context where your theory is kind of four dimensional."}, {"time": 435, "text": "So, geometry is a big part of this and we know a lot and feel a lot about two, one, two, three dimensional geometry."}, {"time": 444, "text": "So wait a minute, so we can at least rely on the four dimensions of space and time and say that we can get pretty far by working in those four dimensions."}, {"time": 455, "text": "I thought you were gonna scare me that we're gonna have to go to many, many, many, many more dimensions than that."}, {"time": 507, "text": "That kind of thing leaves us astray, you think?"}, {"time": 509, "text": "So creating all these extra dimensions just to give yourself extra degrees of freedom."}, {"time": 515, "text": "Isn't that the process of mathematics is to create all of these trajectories for yourself but eventually you have to end up at the final place but it's okay to sort of create abstract objects on your path to proving something."}, {"time": 535, "text": "Yeah, certainly and from a mathematician's point of view, I mean, the kinds of, mathematicians also are very different than physicists in that we like to develop very general theories."}, {"time": 546, "text": "We like to, if we have an idea, we want to see what's the greatest generality in which you can talk about it."}, {"time": 551, "text": "So from the point of view of most of the ways geometry is formulated by mathematicians, it really doesn't matter, it works in any dimension."}, {"time": 559, "text": "We can do one, two, three, four, any number."}, {"time": 562, "text": "There's no particular, for most of geometry, there's no particular special thing about four."}, {"time": 568, "text": "But anyway, but what physicists have been trying to do over the years is try to understand these fundamental theories in a geometrical way and it's very tempting to kind of just start bringing in extra dimensions and using them to explain the structure."}, {"time": 586, "text": "But typically this attempt kind of founders because you just don't know, you end up not being able to explain why we only see four."}, {"time": 599, "text": "It is nice in the space of physics that like if you look at Fermat's last theorem, it's much easier to prove that there's no solution for n equals three than it is for the general case."}, {"time": 612, "text": "And so I guess that's the nice benefit of being a physicist is you don't have to worry about the general case because we live in a universe with n equals four in this case."}, {"time": 655, "text": "And I'm less interested in kind of proving a precise theorem about exactly when it's gonna work and when it's not gonna work."}, {"time": 662, "text": "Do you usually think about really simple examples, like both for teaching and when you try to solve a difficult problem, do you construct the simplest possible examples that captures the fundamentals of the problem and try to solve it?"}, {"time": 675, "text": "Yeah, exactly, that's often a really fruitful way to if you've got some idea to just kind of try to boil it down to what's the simplest situation in which this kind of thing is gonna happen and then try to really understand that and understand that and that is almost always a really good way to get insight into it."}, {"time": 694, "text": "Do you work with paper and pen or like, for example, for me coming from the programming side, if I look at a model, if I look at some kind of mathematical object, I like to mess around with it sort of numerically."}, {"time": 744, "text": "Well, the problem with this kind of stuff I'm interested in is you rarely can kind of, it's rarely something that is really kind of, or even the simplest example, you can kind of see what's going on by looking at something happening in three dimensions."}, {"time": 762, "text": "There's generally the structures involved are either they're more abstract or if you try to kind of embed them in some kind of space and where you could manipulate them in some kind of geometrical way, it's gonna be a much higher dimensional space."}, {"time": 777, "text": "So even simple examples, the embedding them into three dimensional space, you're losing a lot."}, {"time": 783, "text": "Yeah, but to capture what you're trying to understand about them, you have to go to four or more dimensions."}, {"time": 819, "text": "Are we supposed to be sad or excited by the fact that our human minds can't fully comprehend the kind of mathematics you're talking about?"}, {"time": 826, "text": "I mean, what do we make of that?"}, {"time": 828, "text": "I mean, to me, that makes you quite sad."}, {"time": 830, "text": "It makes it seem like there's a giant mystery out there that we'll never truly get to experience directly."}, {"time": 838, "text": "It is kind of sad how difficult this is."}, {"time": 841, "text": "I mean, or I would put it a different way that most questions that people have about this kind of thing, you can give them a really true answer and really understand it but the problem is one more of time."}, {"time": 889, "text": "Speaking of a limited amount of time, we only have a few hours, maybe a few days together here on this podcast."}, {"time": 897, "text": "Let me ask you the question of amongst many of the ideas that you work on in mathematics and physics, which is the most beautiful idea or one of the most beautiful ideas, maybe a surprising idea and once again, unfortunately, the way life works, we only have a limited time together to try to convey such an idea."}, {"time": 918, "text": "Okay, well, actually, let me just tell you something which I'm tempted to kind of start trying to explain what I think is this most powerful idea that brings together math and physics, ideas about groups and representations and how it fits in quantum mechanics but in some sense, I wrote a whole textbook about that and I don't think we really have time to get very far into it so."}, {"time": 939, "text": "Well, can I actually, on a small tangent, you did write a paper towards a grant unified theory mathematics and physics, maybe you could step there first, what is the key idea in that paper?"}, {"time": 949, "text": "Well, I think we've kind of gone over that."}, {"time": 997, "text": "Could you put words to sort of the disciplines we're trying to unify?"}, {"time": 1000, "text": "So you said number theory, are we literally talking about all the major fields of mathematics?"}, {"time": 1005, "text": "So it's like the number theory, geometry, so the differential geometry, topology."}, {"time": 1011, "text": "Yeah, so the, I mean, one name for this that this is acquired in mathematics is the so called Langlands program and so this started out in mathematics."}, {"time": 1116, "text": "One of the things that makes me sad is I'm a pretty knowledgeable person and then, what is it?"}, {"time": 1126, "text": "At least I'm in the neighborhood like theoretical computer science, right?"}, {"time": 1130, "text": "And it's still way out of my reach and so many people talk about like Langlands, for example, is one of the most brilliant people in mathematics and just really admire his work and I can't, it's like almost I can't hear the music that he composed and it makes me sad."}, {"time": 1145, "text": "Yeah, well, I mean, I think unfortunately, it's not just you, it's I think even most mathematicians have no, really don't actually understand what this is about."}, {"time": 1189, "text": "Well, if we can step into the back to the question of beauty, is there an idea that maybe is a little bit smaller that you find beautiful in the space of mathematics or physics?"}, {"time": 1202, "text": "There's an idea that I kind of went, got a physics PhD and spent a lot of time learning about mathematics and I guess it was embarrassing that I hadn't really actually understand this very simple idea until I kind of learned it when I actually started teaching math classes, which is maybe that there's a simple way to explain kind of the fundamental way in which algebra and geometry are connected."}, {"time": 1270, "text": "So one of the most surprising examples of this, for instance, is a standard kind of thing that seems to have nothing to do with geometry is the integers."}, {"time": 1281, "text": "So you can multiply them and add them, it's an algebra but it seems to have nothing to do with geometry but what you can, it turns out, but if you ask yourself this question and ask, you know, are integers, can you think, if somebody gives you an integer, can you think of it as a function on some space, on some geometry?"}, {"time": 1302, "text": "And it turns out that yes, you can and the space is the space of prime numbers and so what you do is you just, if somebody gives you an integer, you can make a function on the prime numbers by just, you know, at each prime number taking that, that integer modulo that prime."}, {"time": 1318, "text": "So if you say, I don't know, if you're given 10, you know, 10 and you ask, what is its value at two?"}, {"time": 1325, "text": "Well, it's five times two, so mod two, it's zero, so it's zero one."}, {"time": 1330, "text": "What is its value at three?"}, {"time": 1333, "text": "Well, it's nine plus one, so it's one mod three."}, {"time": 1337, "text": "So it's zero at two, it's one at three and you can kind of keep going."}, {"time": 1341, "text": "And so this is really kind of a truly fundamental idea."}, {"time": 1346, "text": "It's at the basis of what's called algebraic geometry and it just links these two parts of mathematics that look completely different and it's just an incredibly powerful idea and so much of mathematics emerges from this kind of simple relation."}, {"time": 1359, "text": "So you're talking about mapping from one discrete space to another."}, {"time": 1364, "text": "So for a second, I thought perhaps mapping like a continuous space to a discrete space, like functions over a continuous space, because yeah."}, {"time": 1376, "text": "Well, I mean, you can take, if somebody gives you a space, you can ask, you can say, well, let's, and this is also, this is part of the same idea."}, {"time": 1385, "text": "The part of the same idea is that if you try and do geometry and somebody tells you, here's a space, that what you should do is you should wait, so say, wait a minute, maybe I should be trying to solve this using algebra."}, {"time": 1395, "text": "And so if I do that, the way to start is, you give me the space, I start to think about the functions of the space, okay?"}, {"time": 1402, "text": "So for each point in the space, I associate a number."}, {"time": 1406, "text": "I can take different kinds of functions and different kinds of values, but basically functions on a space."}, {"time": 1411, "text": "So what this insight is telling you is that if you're a geometer, often the way to work is to change your problem into algebra by changing your space, stop thinking about your space and the points in it and think about the functions on it."}, {"time": 1427, "text": "And if you're an algebraist and you've got these abstract algebraic gadgets that you're multiplying and adding, say, wait a minute, are those gadgets, can I think of them in some way as a function on a space?"}, {"time": 1439, "text": "What would that space be and what kind of functions would they be?"}, {"time": 1442, "text": "And that going back and forth really brings these two completely different looking areas of mathematics together."}, {"time": 1449, "text": "Do you have particular examples where it allowed to prove some difficult things by jumping from one to the other?"}, {"time": 1456, "text": "Is that something that's a part of modern mathematics where such jumps are made?"}, {"time": 1461, "text": "Oh yeah, this is kind of all the time."}, {"time": 1463, "text": "Much of modern number theory is kind of based on this idea."}, {"time": 1467, "text": "But, and when you start doing this, you start to realize that you need, what simple things on one side of the algebra start to require you to think about the other side, about geometry in a new way."}, {"time": 1482, "text": "You have to kind of get a more sophisticated idea about geometry, or if you start thinking about the functions on a space, you may need a more sophisticated kind of algebra."}, {"time": 1492, "text": "But in some sense, I mean, much or most of modern number theory is based upon this move to geometry."}, {"time": 1498, "text": "And there's also a lot of geometry and topology is also based upon, yeah, change."}, {"time": 1505, "text": "If you want to understand the topology of something, you look at the functions, you do drum comology and you get the topology."}, {"time": 1513, "text": "Well, let me ask you then the ridiculous question."}, {"time": 1516, "text": "You said that this idea is beautiful."}, {"time": 1518, "text": "Can you formalize the definition of the word beautiful?"}, {"time": 1522, "text": "And why is this beautiful?"}, {"time": 1524, "text": "First, why is this beautiful?"}, {"time": 1526, "text": "And second, what is beautiful?"}, {"time": 1529, "text": "Yeah, well, and I think there are many different things you can find beautiful for different reasons."}, {"time": 1534, "text": "I mean, I think in this context, the notion of beauty, I think really is just kind of an idea is beautiful if it's packages a huge amount of kind of power and information into something very simple."}, {"time": 1548, "text": "So in some sense, you can almost kind of try and measure it in the sense of what are the implications of this idea?"}, {"time": 1558, "text": "What non trivial things does it tell you versus how simply can you express the idea?"}, {"time": 1567, "text": "So the level of compression, what is it correlates with beauty?"}, {"time": 1572, "text": "Yeah, that's one aspect of it."}, {"time": 1575, "text": "And so you can start to tell that an idea is becoming uglier and uglier as you start kind of having to, it doesn't quite do what you want."}, {"time": 1582, "text": "So you throw in something else to the idea and you keep doing that until you get what you want."}, {"time": 1587, "text": "But that's how you know you're doing something uglier and uglier when you have to kind of keep adding and more into what was originally a fairly simple idea and making it more and more complicated to get what you want."}, {"time": 1601, "text": "Okay, so let's put some philosophical words on the table and try to make some sense of them."}, {"time": 1607, "text": "One word is beauty, another one is simplicity as you mentioned, another one is truth."}, {"time": 1613, "text": "So do you have a sense if I give you two theories, one is simpler, one is more complicated."}, {"time": 1622, "text": "Do you have a sense of which one is more likely to be true to capture deeply the fabric of reality, the simple one or the more complicated one?"}, {"time": 1635, "text": "Yeah, I think all of our evidence, what we see in the history of the subject is the simpler one though."}, {"time": 1642, "text": "Often it's a surprise, it's simpler in a surprising way."}, {"time": 1646, "text": "But yeah, that we just don't, we just, anyway, the kind of best theories we've been coming up with are ultimately when properly understood, relatively simple and much, much simpler than you would expect them to be."}, {"time": 1661, "text": "Do you have a good explanation why that is?"}, {"time": 1663, "text": "Is it just because humans want it to be that way?"}, {"time": 1666, "text": "Are we just like ultra biased and we just kind of convince ourselves that simple is better because we find simplicity beautiful?"}, {"time": 1673, "text": "Or is there something about our actual universe that at the core is simple?"}, {"time": 1680, "text": "My own belief is that there is something about a universe that's simple and as I was trying to say that, there is some kind of fundamental thing about math, physics and all this picture, which is in some sense simple."}, {"time": 1694, "text": "It's true that, it's of course true that our minds have certain, are very limited and can certainly do certain things and not others."}, {"time": 1703, "text": "So it's in principle possible that there's some great insight in, there are a lot of insights into the way the world works, which just aren't accessible to us because that's not the way our minds work, we don't."}, {"time": 1715, "text": "And that what we're seeing, this kind of simplicity is just because that's all we ever have any hope of seeing."}, {"time": 1722, "text": "So there's a brilliant physicist by the name of Sabine Hassenfelder who both agrees and disagrees with you."}, {"time": 1731, "text": "I suppose agrees that the final answer will be simple."}, {"time": 1738, "text": "But simplicity and beauty leads us astray in the local pockets of scientific progress."}, {"time": 1745, "text": "Do you agree with her disagreement and do you disagree with her agreement?"}, {"time": 1751, "text": "And agree with the agreement and so on."}, {"time": 1754, "text": "Anyway, yes, I found it was really fascinating reading her book and anyway, I was finding disagreeing with a lot, but then at the end when she says yes, when we find, when we actually figure this out, it will be simple and okay, so we agree in the end."}, {"time": 1771, "text": "But does beauty lead us astray, which is the core thesis of her work in that book."}, {"time": 1777, "text": "I actually, I guess I do disagree with her on that so much."}, {"time": 1781, "text": "I don't think, and especially, and I actually fairly strongly disagree with her about sometimes the way she'll refer to math."}, {"time": 1787, "text": "And so the problem is, physicists and people in general just refer to it as math and they're often meaning not what I would call math, which is the interesting ideas of math, but just some complicated calculation."}, {"time": 1803, "text": "And so I guess my feeling about it is more that it's very, the problem with talking about simplicity and using simplicity as a guide is that it's very, it's very easy to fool yourself and it's very easy to decide to fall in love with an idea."}, {"time": 1823, "text": "You have an idea, you think, oh, this is great and you fall in love with it."}, {"time": 1826, "text": "And it's like any kind of love affair, it's very easy to believe that the object of your affections is much more beautiful than the others might think and that they really are."}, {"time": 1836, "text": "And that's very, very easy to do."}, {"time": 1839, "text": "So if you say, I'm just gonna pursue ideas about beauty and this and mathematics and this, it's extremely easy to just fool yourself, I think."}, {"time": 1878, "text": "I see, so it's not that the simplicity of beauty leads us astray, it's just people are people and they fall in love with whatever idea they have and then they weave narratives around that idea or they present it in such a way that emphasizes the simplicity and the beauty."}, {"time": 1896, "text": "Yeah, that's part of it."}, {"time": 1930, "text": "I think her emphasis is more, that I don't really disagree with, is that people should be concentrating on when they're trying to develop better theories on more on self consistency, not so much on beauty, but not is this idea beautiful, but is there something about the theory which is not quite consistent and use that as a guide that there's something wrong there which needs fixing."}, {"time": 1957, "text": "And so I think that part of her argument, I think we're on the same page about."}, {"time": 1963, "text": "What is consistency and inconsistencies?"}, {"time": 1968, "text": "What exactly, do you have examples in mind?"}, {"time": 1973, "text": "Well, it can be just simple inconsistency between theory and an experiment that if you, so we have this great fundamental theory, but there are some things that we see out there which don't seem to fit in it, like dark energy and dark matter, for instance."}, {"time": 1987, "text": "But if there's something which you can't test experimentally, I think she would argue and I would agree that, for instance, if you're trying to think about gravity and how are you gonna have a quantum theory of gravity, you should kind of test any of your ideas with kind of a thought experiment."}, {"time": 2004, "text": "Does this actually give a consistent picture of what's gonna happen, of what happens in this particular situation or not?"}, {"time": 2013, "text": "You've written about this."}, {"time": 2016, "text": "Since quantum gravitational effects are really small, super small, arguably unobservably small, should we have hope to arrive at a theory of quantum gravity somehow?"}, {"time": 2029, "text": "What are the different ways we can get there?"}, {"time": 2031, "text": "You've mentioned that you're not as interested in that effort because basically, yes, you cannot have ways to scientifically validate it given the tools of today."}, {"time": 2044, "text": "Yeah, I've actually, you know, I've over the years certainly spent a lot of time learning about gravity and about attempts to quantize it, but it hasn't been that much in the past the focus of what I've been thinking about."}, {"time": 2056, "text": "But I mean, my feeling was always, you know, as I think Sabina would agree that the, you know, one way you can pursue this if you can't do experiments is just this kind of search for consistency."}, {"time": 2069, "text": "You know, it can be remarkably hard to come up with a completely consistent model of this in a way that brings together quantum mechanics and general relativity."}, {"time": 2079, "text": "And that's, I think, kind of been the traditional way that people who have pursued quantum gravity have often pursued, you know, we have the best route to finding a consistent theory of quantum gravity and string theorists will tell you this, other people will tell you it, it's kind of what people argue about."}, {"time": 2100, "text": "But the problem with all of that is that you end up, you know, the danger is that you end up with, that everybody could be successful."}, {"time": 2110, "text": "Everybody's program for how to find a theory of quantum gravity, you know, ends up with something that is consistent."}, {"time": 2118, "text": "And so, and in some sense you could argue this is what happened to the string theorists."}, {"time": 2123, "text": "They solved their problem of finding a consistent theory of quantum gravity and they ended up, but they found 10 to the 500 solutions."}, {"time": 2130, "text": "So you, you know, if you believe that everything that they would like to be true is true, well, okay, you've got a theory, but it ends up being kind of useless because it's just one of an infinite, essentially infinite number of things which you have no way to experimentally distinguish."}, {"time": 2148, "text": "And so this is just a depressing situation."}, {"time": 2152, "text": "But I do think that there is a, so again, I think pursuing ideas about what, more about beauty and how can you integrate and unify these issues about gravity with other things we know about physics."}, {"time": 2166, "text": "And can you find a theory where these fit together in a way that makes sense and hopefully predict something."}, {"time": 2172, "text": "That's much more promising."}, {"time": 2174, "text": "Well, it makes sense and hopefully, I mean, we'll sneak up onto this question a bunch of times because you kind of said a few slightly contradictory things which is like, it's nice to have a theory that's consistent, but then if the theory is consistent, it doesn't necessarily mean anything."}, {"time": 2193, "text": "It's not enough, it's not enough."}, {"time": 2195, "text": "It's not enough and that's the problem."}, {"time": 2196, "text": "So it's like, it keeps coming back to, okay, there should be some experimental validation."}, {"time": 2203, "text": "So, okay, let's talk a little bit about strength theory."}, {"time": 2207, "text": "You've been a bit of an outspoken critic of strength theory."}, {"time": 2212, "text": "Maybe one question first to ask is what is strength theory?"}, {"time": 2216, "text": "And beyond that, why is it wrong?"}, {"time": 2221, "text": "Or rather as the title of your blog says, not even wrong."}, {"time": 2227, "text": "Well, one interesting thing about the current state of strength theory is that, I think it, I'd argue it's actually very, very difficult to at this point to say what strength theory means."}, {"time": 2235, "text": "If people say they're a strength theorist, what they mean and what they're doing is kind of hard to pin down the meaning of the term."}, {"time": 2244, "text": "But the initial meaning I think goes back to, there was kind of a series of developments starting in 1984 in which people felt that they had found a unified theory of our so called standard model of all the standard, well known kind of particle interactions and gravity and it all fit together in a quantum theory."}, {"time": 2266, "text": "And that you could do this in a very specific way by instead of thinking about having a quantum theory of particles moving around in space time, think about a quantum theory of kind of one dimensional loops moving around in space time, so called strings."}, {"time": 2283, "text": "And so instead of one degree of freedom, these have an infinite number of degrees of freedom."}, {"time": 2288, "text": "It's a much more complicated theory, but you can imagine, okay, we're gonna quantize this theory of loops moving around in space time."}, {"time": 2296, "text": "And what they found is that you could do this and you could fairly, relatively straightforwardly make sense of such a quantum theory, but only if space and time together were 10 dimensional."}, {"time": 2311, "text": "And so then you had this problem, again, the problem I referred to at the beginning of, okay, now once you make that move, you gotta get rid of six dimensions."}, {"time": 2319, "text": "And so the hope was that you could get rid of the six dimensions by making them very small and that consistency of the theory would require that these six dimensions satisfy a very specific condition called being a Calabi out manifold."}, {"time": 2335, "text": "And that we knew very, very few examples of this."}, {"time": 2338, "text": "So what got a lot of people very excited back in 84, 85 was the hope that you could just take this 10 dimensional string theory and find one of a limited number of possible ways of getting rid of six dimensions by making them small and then you would end up with an effective four dimensional theory, which looked like the real world."}, {"time": 2358, "text": "This was the hope."}, {"time": 2360, "text": "So then there's then a very long story about what happened to that hope over the years."}, {"time": 2395, "text": "But it was kind of in the realm of ideas which initially looked good, but the more you look at them, they just, they don't work out the way you want and they don't actually end up carrying the power or that you originally had this vision of."}, {"time": 2410, "text": "And yes, the book title is not even wrong."}, {"time": 2414, "text": "Your blog, your excellent blog title is not even wrong."}, {"time": 2417, "text": "Okay, but there's nevertheless been a lot of excitement about string theory through the decades, as you mentioned."}, {"time": 2424, "text": "What are the different flavors of ideas that came, like that branched out?"}, {"time": 2431, "text": "You mentioned 10 dimensions."}, {"time": 2432, "text": "You mentioned loops with infinite degrees of freedom."}, {"time": 2436, "text": "What other interesting ideas to you that kind of emerged from this world?"}, {"time": 2441, "text": "Well, yeah, I mean, the problem with talking about the whole subject and part of the reason I wrote the book is that it gets very, very complicated."}, {"time": 2448, "text": "I mean, there's a huge amount, a lot of people got very interested in this, a lot of people worked on it."}, {"time": 2455, "text": "And in some sense, I think what happened is exactly because the idea didn't really work that this caused people to, instead of focusing on this one idea and digging in and working on that, they just kind of kept trying new things."}, {"time": 2471, "text": "And so people, I think, ended up wandering around in a very, very rich space of ideas about mathematics and physics and discovering all sorts of really interesting things."}, {"time": 2479, "text": "It's just the problem is there tended to be an inverse relationship between how interesting and beautiful and fruitful this new idea that they were trying to pursue was and how much it looked like the real world."}, {"time": 2491, "text": "So there's a lot of beautiful mathematics came out of it."}, {"time": 2494, "text": "I think one of the most spectacular is what the physicists call two dimensional conformal field theory."}, {"time": 2500, "text": "And so these are basically quantum field theories and kind of think of it as one space and one time dimension, which have just this huge amount of symmetry and a huge amount of structure, which there's some totally fantastic mathematics behind it."}, {"time": 2517, "text": "And again, and some of that mathematics is exactly also what appears in the Langlands program."}, {"time": 2523, "text": "So a lot of the first interaction between math and physics around the Langlands program has been around these two dimensional conformal field theories."}, {"time": 2532, "text": "Is there something you could say about what are the major problems are with string theory?"}, {"time": 2538, "text": "So like, besides that there's no experimental validation, you've written that a big hole in string theory has been its perturbative definition."}, {"time": 2554, "text": "Perhaps that's one, can you explain what that means?"}, {"time": 2556, "text": "Well, maybe to begin with, I think the simplest thing to say is, the initial idea really was that, okay, we have this, instead of what's great is we have this thing that only works, it's very structured and has to work in a certain way for it to make sense."}, {"time": 2575, "text": "But then you ended up in 10 space time dimensions."}, {"time": 2581, "text": "And so to get back to physics, you had to get rid of five of the dimensions, six of the dimensions."}, {"time": 2586, "text": "And the bottom line I would say in some sense is very simple that what people just discovered is just, there's kind of no particularly nice way of doing this, there's an infinite number of ways of doing it and you can get whatever you want depending on how you do it."}, {"time": 2600, "text": "So you end up the whole program of starting at 10 dimensions and getting to four just kind of collapses out of a lack of any way to kind of get to where you want because you can get anything."}, {"time": 2611, "text": "The hope around that problem has always been that the standard formulation that we have of string theory, which is, you can go by the name perturbative, but it's kind of, there's a standard way we know of given a classical theory of constructing a quantum theory and working with it, which is the so called perturbation theory that we know how to do."}, {"time": 2639, "text": "And that by itself just doesn't give you any hint as to what to do about the six dimensions."}, {"time": 2646, "text": "So actual perturbed string theory by itself really only works in 10 dimensions."}, {"time": 2651, "text": "So you have to start making some kinds of assumptions about how I'm gonna go beyond this formulation that we really understand of string theory and get rid of these six dimensions."}, {"time": 2664, "text": "So kind of the simplest one was the Klabiau postulate, but when that didn't really work out, people have tried more and more different things."}, {"time": 2673, "text": "And the hope has always been that the solution, this problem would be that you would find a deeper and better understanding of what string theory is that would actually go beyond this perturbative expansion and which would generalize this."}, {"time": 2691, "text": "And that once you had that, it would solve this problem of, it would pick out what to do with the six dimensions."}, {"time": 2701, "text": "So if I could restate the problem, it seems like there's a very consistent physical world operating in four dimensions."}, {"time": 2713, "text": "And how do you map a consistent physical world in 10 dimensions to a consistent physical world in four dimensions?"}, {"time": 2721, "text": "And how difficult is this problem?"}, {"time": 2723, "text": "Is that something you can even answer?"}, {"time": 2727, "text": "Just in terms of physics intuition, in terms of mathematics, mapping from 10 dimensions to four dimensions."}, {"time": 2735, "text": "Well, basically, I mean, you have to get rid of the six of the dimensions."}, {"time": 2738, "text": "So there's kind of two ways of doing it."}, {"time": 2741, "text": "One is what we called compactification."}, {"time": 2744, "text": "You say that there really are 10 dimensions, but for whatever reason, six of them are so, so small, we can't see them."}, {"time": 2751, "text": "So you basically start out with 10 dimensions and what we call, make six of them not go out to infinity, but just kind of a finite extent and then make that size go down so small, it's unobservable."}, {"time": 2765, "text": "But that's like, that's a math trick."}, {"time": 2768, "text": "So can you also help me build an intuition about how rich and interesting the world in those six dimensions is?"}, {"time": 2777, "text": "So compactification seems to imply... Well, it's not very interesting."}, {"time": 2782, "text": "Well, no, but the problem is that what you learn if you start doing mathematics and looking at geometry and topology and more and more dimensions is that, I mean, asking the question like, what are all possible six dimensional spaces?"}, {"time": 2796, "text": "It's just, it's kind of an unnatural question."}, {"time": 2798, "text": "It's just, I mean, it's even kind of technically undecidable in some way."}, {"time": 2802, "text": "There are too many things you can do with all these, if you start trying to make, if you start trying to make one dimensional spaces, it's like, well, you got a line, you can make a circle, you can make graphs, you can kind of see what you can do."}, {"time": 2815, "text": "But as you go to higher and higher dimensions, there are just so many ways you can put things together of and get something of that dimensionality."}, {"time": 2825, "text": "And so unless you have some very, very strong principle, we're just gonna pick out some very specific ones of these six dimensional spaces."}, {"time": 2835, "text": "And there are just too many of them and you can get anything you want."}, {"time": 2839, "text": "So if you have 10 dimensions, the kind of things that happen, say that's actually the way, that's actually the fabric of our reality is 10 dimensions."}, {"time": 2849, "text": "There's a limited set of behaviors of objects."}, {"time": 2853, "text": "I don't know even know what the right terminology to use that can occur within those dimensions, like in reality."}, {"time": 2861, "text": "And so like what I'm getting at is like, is there some consistent constraints?"}, {"time": 2867, "text": "So if you have some constraints that map to reality, then you can start saying like, dimension number seven is kind of boring."}, {"time": 2876, "text": "All the excitement happens in the spatial dimensions, one, two, three."}, {"time": 2880, "text": "And time is also kind of boring."}, {"time": 2882, "text": "And like some are more exciting than others, or we can use our metric of beauty."}, {"time": 2888, "text": "Some dimensions are more beautiful than others."}, {"time": 2890, "text": "Once you have an actual understanding of what actually happens in those dimensions in our physical world, as opposed to sort of all the possible things that could happen."}, {"time": 2899, "text": "In some sense, I mean, just the basic fact is you need to get rid of them."}, {"time": 2902, "text": "We don't see them."}, {"time": 2903, "text": "So you need to somehow explain them."}, {"time": 2905, "text": "The main thing you're trying to do is to explain why we're not seeing them."}, {"time": 2908, "text": "And so you have to come up with some theory of these extra dimensions and how they're gonna behave."}, {"time": 2915, "text": "And string theory gives you some ideas about how to do that."}, {"time": 2919, "text": "But the bottom line is where you're trying to go with this whole theory you're creating is to just make all of its effects essentially unobservable."}, {"time": 2929, "text": "So it's not a really, it's an inherently kind of dubious and worrisome thing that you're trying to do there."}, {"time": 2938, "text": "Why are you just adding in all this stuff and then trying to explain why we don't see it?"}, {"time": 2943, "text": "This may be a dumb question, but is this an obvious thing to state that those six dimensions are unobservable or anything beyond four dimensions is unobservable?"}, {"time": 2956, "text": "Or do you leave a little door open to saying the current tools of physics, and obviously our brains aren't unable to observe them, but we may need to come up with methodologies for observing them."}, {"time": 2970, "text": "So as opposed to collapsing your mathematical theory into four dimensions, leaving the door open a little bit too, maybe we need to come up with tools that actually allow us to directly measure those dimensions."}, {"time": 2982, "text": "Yes, I mean, you can certainly ask, assume that we've got model, look at models with more dimensions and ask, what would the observable effects, how would we know this?"}, {"time": 2994, "text": "And you go out and do experiments."}, {"time": 2995, "text": "So for instance, you have a, like gravitationally you have an inverse square law of forces."}, {"time": 3002, "text": "If you had more dimensions, that inverse square law would change to something else."}, {"time": 3006, "text": "So you can go and start measuring the inverse square law and say, okay, inverse square law is working, but maybe if I get, and it turns out to be actually kind of very, very hard to measure gravitational effects and even kind of somewhat macroscopic distances because they're so small."}, {"time": 3023, "text": "So you can start looking at the inverse square law and say, start trying to measure it at shorter and shorter distances and see if there were extra dimensions at those distance scales, you would start to see the inverse square law fail."}, {"time": 3036, "text": "And so people look for that and again, you don't see it, but you can, I mean, there's all sorts of experiments of this kind you can imagine which test for effects of extra dimensions at different distance scales, but none of them, I mean, they all just don't work."}, {"time": 3055, "text": "Nothing yet."}, {"time": 3058, "text": "Nothing yet, but you could say, ah, but it's just much, much smaller, you can say that."}, {"time": 3065, "text": "Which by the way makes LIGO and the detection of gravitational waves quite an incredible project."}, {"time": 3073, "text": "Ed Witten is often brought up as one of the most brilliant mathematicians and physicists ever."}, {"time": 3081, "text": "What do you make of him and his work on string theory?"}, {"time": 3084, "text": "Well, I think he's a truly remarkable figure."}, {"time": 3086, "text": "I've had the pleasure of meeting him first when he was a postdoc."}, {"time": 3091, "text": "And I mean, he's just completely amazing mathematician and physicist."}, {"time": 3098, "text": "And he's quite a bit smarter than just about any of the rest of us and also more hardworking."}, {"time": 3104, "text": "It's a kind of frightening combination to see how much he's been able to do."}, {"time": 3110, "text": "But I would actually argue that his greatest work, the things that he's done that have been of just this mind blowing significance of giving us, I mean, he's completely revolutionized some areas of mathematics."}, {"time": 3122, "text": "He's totally revolutionized the way we understand the relations between mathematics and physics."}, {"time": 3127, "text": "And most of those, his greatest work is stuff that has little or nothing to do with string theory."}, {"time": 3135, "text": "I mean, for instance, so he was actually one of Fields."}, {"time": 3139, "text": "The very strange thing about him in some sense is that he doesn't have a Nobel Prize."}, {"time": 3143, "text": "So there's a very large number of people who are nowhere near as smart as he is and don't work anywhere near as hard who have Nobel Prizes."}, {"time": 3151, "text": "I think he just had the misfortune of coming into the field at a time when things had gotten much, much, much tougher and nobody really had, no matter how smart you were, it was very hard to come up with a new idea that was gonna work physically and get you a Nobel Prize."}, {"time": 3167, "text": "But he got a Fields Medal for a certain work he did in mathematics, and that's just completely unheard of."}, {"time": 3176, "text": "For mathematicians to give a Fields Medal to someone outside their field in physics is really, you wouldn't have, before he came around, I don't think anybody would have thought that was even conceivable."}, {"time": 3188, "text": "So you're saying he came into the field of theoretical physics at a time when, and still to today, is you can't get a Nobel Prize for purely theoretical work."}, {"time": 3200, "text": "The specific problem of trying to do better than the standard, the standard model is just this insanely successful thing, and it kind of came together in 1973, pretty much."}, {"time": 3210, "text": "And all of the people who kind of were involved in that coming together, many of them ended up with Nobel Prizes for that."}, {"time": 3218, "text": "But if you look post 1973, pretty much, it's a little bit more, there's some edge cases, if you like, but if you look post 1973 at what people have done to try to do better than the standard model and to get a better idea, it really hasn't, it's been too hard a problem."}, {"time": 3238, "text": "It hasn't worked."}, {"time": 3239, "text": "The theory's too good."}, {"time": 3240, "text": "And so it's not that other people went out there and did it, and not him, and that they got Nobel Prizes for doing it, it's just that no one really, the kind of thing he's been trying to do with string theory is not, no one has been able to do since 1973."}, {"time": 3255, "text": "Is there something you can say about the standard model, so the four laws of physics that seems to work very well, and yet people are striving to do more?"}, {"time": 3264, "text": "Talking about unification, so on, why?"}, {"time": 3267, "text": "What's wrong, what's broken about the standard model?"}, {"time": 3270, "text": "Why does it need to be improved?"}, {"time": 3273, "text": "I mean, the thing that's gets most attention is gravity, that we have trouble."}, {"time": 3279, "text": "So you want to, in some sense, integrate what we know about the gravitational force with it and have a unified quantum field theory that has gravitational interactions also."}, {"time": 3290, "text": "So that's the big problem everybody talks about."}, {"time": 3293, "text": "I mean, but it's also true that if you look at the standard model, it has these very, very deep, beautiful ideas, but there's certain aspects of it that are very, let's just say that they're not beautiful."}, {"time": 3336, "text": "There's very small number of parameters and a few integers which tell you what the theory is."}, {"time": 3340, "text": "To make this work as a theory of the real world, you need a Higgs field and you need to, it needs to do something."}, {"time": 3348, "text": "And once you introduce that Higgs field, all sorts of parameters make an appearance."}, {"time": 3354, "text": "So now we've got 20 or 30 or whatever parameters that are gonna tell you what all the masses of things are and what's gonna happen."}, {"time": 3362, "text": "So you've gone from a very tightly constrained thing with a couple of parameters to this thing, which the minute you put it in, you had to add all this extra, all these extra parameters to make things work."}, {"time": 3375, "text": "And so that, it may be one argument as well, that's just the way the world is, and the fact that you don't find that aesthetically pleasing is just your problem, or maybe we live in a multiverse and those numbers are just different in every universe."}, {"time": 3390, "text": "But another reasonable conjecture is just that, well, this is just telling us that there's something we don't understand about what's going on in a deeper way, which would explain those numbers."}, {"time": 3401, "text": "And there's some kind of deeper idea about where the Higgs field comes from and what's going on, which we haven't figured out yet."}, {"time": 3409, "text": "And that's what we should look for."}, {"time": 3412, "text": "But to stick on string theory a little bit longer, could you play devil's advocate and try to argue for string theory, why it is something that deserved the effort that it got, and still, like if you think of it as a flame, still should be a little flame that keeps burning?"}, {"time": 3434, "text": "Well, I think the, I mean, the most positive argument for it is all sorts of new ideas about mathematics and about parts of physics really emerge from it."}, {"time": 3444, "text": "That was very a fruitful source of ideas."}, {"time": 3448, "text": "And I think this is actually one argument you'll definitely, which I kind of agree with, I'll hear from Whitten and from other string theorists, say that this is just such a fruitful and inspiring idea and it's led to so many other different things coming out of it that there must be something right about this."}, {"time": 3465, "text": "And that's, okay, anyway, I think that's probably the strongest thing that they've got."}, {"time": 3472, "text": "But you don't think there's aspects to it that could be neighboring to a theory that does unify everything, to a theory of everything."}, {"time": 3483, "text": "Like it could, it may not be exactly, exactly the theory, but sticking on it longer might get us closer to the theory of everything."}, {"time": 3494, "text": "Well, the problem with it now really is that you really don't know what it is now."}, {"time": 3497, "text": "You've never, nobody has ever kind of come up with this nonperturbative theory."}, {"time": 3503, "text": "So it's become more and more frustrating and an odd activity to try to argue with a string theorist about string theory because it's become less and less well defined what it is."}, {"time": 3517, "text": "And it's become actually more and more kind of a, whether you have this weird phenomenon of people calling themselves string theorists when they've never actually worked on any theory where there are any strings anywhere."}, {"time": 3529, "text": "So what has actually happened kind of sociologically is that you started out with this fairly well defined proposal."}, {"time": 3536, "text": "And then I would argue because that didn't work, people branched out in all sorts of directions doing all sorts of things."}, {"time": 3542, "text": "It became farther and farther removed from that."}, {"time": 3545, "text": "And for sociological reasons, the ones who kind of started out or now or were trained by the people who worked on that have now become this string theorists."}, {"time": 3558, "text": "And, but it's becoming almost more kind of a tribal denominator than a, I think so it's very hard to know what you're arguing about when you're arguing about string theory these days."}, {"time": 3570, "text": "Well, to push back on that a little bit, I mean, string theory is just a term, right?"}, {"time": 3574, "text": "It doesn't, like you could, like this is the way language evolves is it could start to represent something more than just the theory that involves strings."}, {"time": 3583, "text": "It could represent the effort to unify the laws of physics."}, {"time": 3590, "text": "At high dimensions with these super tiny objects, right?"}, {"time": 3594, "text": "Or something like that."}, {"time": 3596, "text": "I mean, we can sort of put string theory aside."}, {"time": 3599, "text": "So for example, neural networks in the space of machine learning, there was a time when they were extremely popular."}, {"time": 3605, "text": "They became much, much less popular to a point where if you mentioned neural networks, you're getting no funding and you're not going to be respected at conferences."}, {"time": 3613, "text": "And then once again, neural networks became all the rage about 10, 15 years ago."}, {"time": 3620, "text": "And as it goes up and down and a lot of people would argue that using terminology like machine learning and deep learning is often misused over general, everything that works is deep learning, everything that doesn't, isn't something like that."}, {"time": 3638, "text": "That's just the way, again, we're back to sociological things, but I guess what I'm trying to get at is if we leave the sociological mess aside, do we throw out the baby with the bathwater?"}, {"time": 3653, "text": "Is there some, besides the side effects of nice ideas from the Ed Wittons of the world, is there some core truths there that we should stick by in the full beautiful mess of a space that we call string theory, that people call string theory?"}, {"time": 3671, "text": "You're right, it is kind of a common problem that how what you call some field changes and evolves and in interesting ways as the field changes."}, {"time": 3682, "text": "But I mean, I guess what I would argue is the initial understanding of string theory that was quite specific, we're talking about a specific idea, 10 dimensional super strings compactified to six dimensions."}, {"time": 3696, "text": "That to my mind, the really bad thing has happened to the subject is that it's hard to get people to admit, at least publicly, that that was a failure, that this really didn't work."}, {"time": 3709, "text": "And so de facto, what people do is people stop doing that and they start doing more interesting things, but they keep talking to the public about string theory and referring back to that idea and using that as kind of the starting point and as kind of the place where the whole tribe starts and everything else comes from."}, {"time": 3761, "text": "So you're continually pointing back to this idea which never worked out as your guiding inspiration."}, {"time": 3768, "text": "And it really kind of deforms your whole way of your hopes of making progress."}, {"time": 3774, "text": "And that's, to me, I think the kind of worst thing that's happened in this field."}, {"time": 3779, "text": "Okay, sure, so there's a lack of transparency, sort of authenticity about communicating the things that failed in the past."}, {"time": 3787, "text": "And so you don't have a clear picture of like firm ground that you're standing on."}, {"time": 3792, "text": "But again, those are sociological things."}, {"time": 3793, "text": "And there's a bunch of questions I want to ask you."}, {"time": 3798, "text": "So one, what's your intuition about why the original idea failed?"}, {"time": 3806, "text": "So what can you say about why you're pretty sure it has failed?"}, {"time": 3812, "text": "I mean, the initial idea was, as I try to explain it, it was quite seductive in that you could see why Whitten and others got excited by it."}, {"time": 3820, "text": "It was, you know, at the time it looked like there were only a few of these possible clobby owls that would work."}, {"time": 3827, "text": "And it looked like, okay, we just have to understand this very specific model and these very specific six dimensional spaces, and we're going to get everything."}, {"time": 3835, "text": "And so it was a very seductive idea, but it just, you know, as people learned, worked more and more about it, it just didn't, they just kind of realized that there are just more and more things you can do with these six dimensions and you can't, and this is just not going to work."}, {"time": 3852, "text": "Meaning like, it's, I mean, what was the failure mode here?"}, {"time": 3861, "text": "Is it, you could just have an infinite number of possibilities that you could do so you can come up with any theory you want, you can fit quantum mechanics, you can explain gravity, you can explain anything you want with it."}, {"time": 3872, "text": "Is that the basic failure mode?"}, {"time": 3874, "text": "Yeah, so it's a failure mode of kind of that this idea ended up being kind of being essentially empty, that it just doesn't, ends up not telling you anything because it's consistent with just about anything."}, {"time": 3887, "text": "And so, I mean, there's a complex, if you try and talk with string theorists about this now, I mean, there's an argument, there's a long argument over this about whether, oh no, no, no, maybe there still are constraints coming out of this idea or not."}, {"time": 3901, "text": "Or maybe we live in a multiverse and everything is true anyway, so you can, there are various ways you can kind of, that string theorists have kind of react to this kind of argument that I'm making, but I try to hold onto it."}, {"time": 3917, "text": "What about experimental validation?"}, {"time": 3918, "text": "Is that a fair standard to hold before a theory of everything that's trying to unify quantum mechanics and gravity?"}, {"time": 3928, "text": "Yeah, I mean, ultimately, to be really convinced that some new idea about unification really works, you need some kind of, you need to look at the real world and see that this is telling you something true about it."}, {"time": 3944, "text": "I mean, either telling you that if you do some experiment and go out and do it, you'll get some unexpected result and that's the kind of gold standard, or it may be just that like all those numbers that are, we don't know how to explain, it will show you how to calculate them."}, {"time": 3962, "text": "I mean, it can be various kinds of experimental validation, but that's certainly ideally what you're looking for."}, {"time": 3968, "text": "How tough is this, do you think, for a theory of everything, not just string theory, for something that unifies gravity and quantum mechanics, so the very big and the very small?"}, {"time": 3977, "text": "Is this, let me ask you one way, is it a physics problem, a math problem, or an engineering problem?"}, {"time": 3987, "text": "My guess is it's a combination of a physics and a math problem that you really need."}, {"time": 3993, "text": "It's not really engineering, it's not like there's some kind of well defined thing you can write down and we just don't have enough computer power to do the calculation."}, {"time": 4003, "text": "That's not the kind of problem it is at all."}, {"time": 4006, "text": "But the question is, what mathematical tools you need to properly formulate the problem is unclear."}, {"time": 4013, "text": "So one reasonable conjecture is the way, the reason that we haven't had any success yet is just that we're missing, either we're missing certain physical ideas or we're missing certain mathematical tools, which there are some combination of them, which we need to kind of properly formulate the problem and see that it has a solution that looks like the real world."}, {"time": 4037, "text": "But those you need, I guess you don't, but there's a sense that you need both gravity, like all the laws of physics to be operating on the same level."}, {"time": 4048, "text": "So it feels like you need an object like a black hole or something like that in order to make predictions about."}, {"time": 4058, "text": "Otherwise, you're always making predictions about this joint phenomena or can you do that as long as the theory is consistent and doesn't have special cases for each of the phenomena?"}, {"time": 4068, "text": "Well, your theory should, I mean, if your theory is gonna include gravity, our current understanding of gravity is that you should have, there should be black hole states in it."}, {"time": 4077, "text": "You should be able to describe black holes in this theory."}, {"time": 4080, "text": "And just one aspect that people have concentrated a lot on is just this kind of questions about if your theory includes black holes like it's supposed to and it includes quantum mechanics, then there's certain kinds of paradoxes which come up."}, {"time": 4093, "text": "And so that's been a huge focus of kind of quantum gravity work has been just those paradoxes."}, {"time": 4100, "text": "So stepping outside of string theory, can you just say first at a high level, what is the theory of everything?"}, {"time": 4108, "text": "What is the theory of everything seek to accomplish?"}, {"time": 4112, "text": "Well, I mean, this is very much a kind of reductionist point of view in the sense that, so it's not a theory."}, {"time": 4118, "text": "This is not gonna explain to you anything."}, {"time": 4122, "text": "It doesn't really, this kind of theory, this kind of theory of everything we're talking about doesn't say anything interesting, particularly about like macroscopic objects, about what the weather is gonna be tomorrow, or things are happening at this scale."}, {"time": 4134, "text": "But just what we've discovered is that as you look at the universe that kind of, if you kind of start, you can start breaking it apart into, and you end up with some fairly simple pieces, quanta, if you like, and which are doing, which are interacting in some fairly simple way."}, {"time": 4154, "text": "And it's, so what we mean by theory of everything is a theory that describes all the object, all the correct objects you need to describe what's happening in the world and describes how they're interacting with each other at our most fundamental level."}, {"time": 4171, "text": "How you get from that theory to describing some macroscopic, incredibly complicated thing is, there that becomes, again, more of an engineering problem and you may need machine learning, or you may, you know, a lot of very different things to do it, but."}, {"time": 4185, "text": "Well, I don't even think it's just engineering."}, {"time": 4188, "text": "It's also science."}, {"time": 4190, "text": "One thing that I find kind of interesting talking to physicists is a little bit, there's a, a little bit of hubris."}, {"time": 4207, "text": "Some of the most brilliant people I know are physicists, both philosophy and just in terms of mathematics, in terms of understanding the world."}, {"time": 4214, "text": "But there's a kind of either hubris or what would I call it?"}, {"time": 4219, "text": "Like a confidence that if we have a theory of everything, we will understand everything."}, {"time": 4224, "text": "Like this is the deepest thing to understand."}, {"time": 4226, "text": "And I would say, and like the rest is details, right?"}, {"time": 4229, "text": "That's the old Rutherford thing."}, {"time": 4233, "text": "But to me, there's like, this is like a cake or something."}, {"time": 4237, "text": "There's layers to this thing and each one has a theory of everything."}, {"time": 4242, "text": "Like at every level from biology, like how life originates, that itself, like complex systems."}, {"time": 4252, "text": "Like that in itself is like this gigantic thing that requires a theory of everything."}, {"time": 4258, "text": "And then there's the, in the space of humans, psychology, like intelligence, collective intelligence, the way it emerges among species, that feels like a complex system that requires its own theory of everything."}, {"time": 4271, "text": "On top of that is things like in the computing space, artificial intelligence systems, like that feels like it needs a theory of everything."}, {"time": 4279, "text": "And it's almost like once we solve, once we come up with a theory of everything that explains the basic laws of physics that gave us the universe, even stuff that's super complex, like how the universe might be able to originate, even explaining something that you're not a big fan of, like multiverses or stuff that we don't have any evidence of yet."}, {"time": 4302, "text": "Still, we won't be able to have a strong explanation of why food tastes delicious."}, {"time": 4313, "text": "No, anyway, yeah, I agree completely."}, {"time": 4315, "text": "I mean, there is something kind of completely wrong with this terminology of theory of everything."}, {"time": 4360, "text": "And as you go to different levels of explanation, you're gonna need to develop new, different, completely different ideas, completely different ways of thinking."}, {"time": 4367, "text": "And I guess there's a famous kind of Phil Anderson's slogan is that, you know, more is different."}, {"time": 4374, "text": "And so it's just, even once you understand how, what a couple of things, if you have a collection of stuff and you understand perfectly well how each thing is interacting with the others, what the whole thing is gonna do is just a completely different problem."}, {"time": 4390, "text": "It's just not, and you need completely different ways of thinking about it."}, {"time": 4395, "text": "I got to ask you at a few different attempts that a theory of everything, especially recently."}, {"time": 4400, "text": "So I've been for many years, a big fan of cellular automata of complex systems."}, {"time": 4405, "text": "And obviously because of that, a fan of Stephen Wolfram's work in that space, but he's recently been talking about a theory of everything through his physics project, essentially."}, {"time": 4418, "text": "What do you think about this kind of discreet theory of everything like from simple rules and simple objects on the hypergraphs emerges all of our reality where time and space are emergent."}, {"time": 4431, "text": "Basically everything we see around us is emergent."}, {"time": 4433, "text": "Yeah, I have to say, unfortunately, I've kind of pretty much zero sympathy for that."}, {"time": 4438, "text": "I mean, I don't, I spent a little time looking at it and I just don't see, it doesn't seem to me to get anywhere."}, {"time": 4444, "text": "And it really is just really, really doesn't agree at all with what I'm seeing, this kind of unification of math and physics that I'm kind of talking about around certain kinds of very deep ideas about geometry and stuff."}, {"time": 4457, "text": "This, if you want to believe that your things are really coming out of cellular automata at the most fundamental level, you have to believe that everything that I've seen my whole career and as beautiful, powerful ideas, that that's all just kind of a mirage, which just kind of randomly is emerging from these more basic, very, very simple minded things."}, {"time": 4481, "text": "And you have to give me some serious evidence for that and I'm seeing nothing."}, {"time": 4486, "text": "So Mirage, you don't think there could be a consistency where things like quantum mechanics could emerge from much, much, much smaller, discreet, like computational type systems."}, {"time": 4500, "text": "I think from the point of view of certain mathematical point of view, quantum mechanics is already mathematically as simple as it gets."}, {"time": 4507, "text": "It really is a story about really the fundamental objects that you work within when you write down a quantum theory are in some form point of view, precisely the fundamental objects at these deepest levels of mathematics that you're working with, they're exactly the same."}, {"time": 4525, "text": "So, and cellular automata are something completely different which don't fit into these structures."}, {"time": 4530, "text": "And so I just don't see why, anyway, I don't see it as a promising thing to do."}, {"time": 4537, "text": "And then just looking at it and saying, does this go anywhere?"}, {"time": 4539, "text": "Does this solve any problem that I've ever, that I didn't, does this solve any problem of any kind?"}, {"time": 4546, "text": "Yeah, to me, cellular automata and these hypergraphs, I'm not sure solving a problem is even the standard to apply here at this moment."}, {"time": 4557, "text": "To me, the fascinating thing is that the question it asks have no good answers."}, {"time": 4562, "text": "So there's not good math explaining, forget the physics of it, math explaining the behavior of complex systems."}, {"time": 4569, "text": "And that to me is both exciting and paralyzing."}, {"time": 4572, "text": "Like we're at the very early days of understanding how complicated and fascinating things emerge from simple rules."}, {"time": 4581, "text": "Yeah, and I agree."}, {"time": 4582, "text": "I think that is a truly great problem."}, {"time": 4585, "text": "And depending where it goes, it may be, it may start to develop some kind of connections to the things that I've kind of found more fruitful and hard to know."}, {"time": 4598, "text": "It just, I think a lot of that area, I kind of strongly feel I best not say too much about it because I just, I don't know too much about it."}, {"time": 4608, "text": "And again, we're back to this original problem that your time in life is limited."}, {"time": 4614, "text": "You have to figure out what you're gonna spend your time thinking about."}, {"time": 4616, "text": "And that's something I've just never seen enough to convince me to spend more time thinking about."}, {"time": 4621, "text": "Well, also timing, it's not just that our time is limited, but the timing of the kind of things you think about."}, {"time": 4627, "text": "There's some aspect to cellular automata, these kinds of objects that it feels like we're very many years away from having big breakthroughs on."}, {"time": 4638, "text": "And so it's like, you have to pick the problems that are solvable today."}, {"time": 4641, "text": "In fact, my intuition, again, perhaps biased, is it feels like the kind of systems that, complex systems that cellular automata are, would not be solved by human brains."}, {"time": 4656, "text": "It feels like something post human that will solve that problem."}, {"time": 4661, "text": "Or like significantly enhanced humans, meaning like using computational tools, very powerful computational tools to crack these problems open."}, {"time": 4674, "text": "That's if our approach to science, our ability to understand science, our ability to understand physics will become more and more computational, or there'll be a whole field that's computational in nature, which currently is not the case."}, {"time": 4687, "text": "Currently, computation is the thing that sort of assists us in understanding science the way we've been doing it all along, but if there's a whole new, I mean, we're from a new kind of science, right?"}, {"time": 4700, "text": "It's a little bit dramatic, but you know, if computers could do science on their own, computational systems, perhaps that's the way they would do the science."}, {"time": 4715, "text": "They would try to understand the cellular automata, and that feels like we're decades away."}, {"time": 4719, "text": "So perhaps it'll crack open some interesting facets of this physics problem, but it's very far away."}, {"time": 4726, "text": "So timing is everything."}, {"time": 4728, "text": "That's perfectly possible, yeah."}, {"time": 4731, "text": "Well, let me ask you then, in the space of geometry, I don't know how well you know Eric Weinstein."}, {"time": 4737, "text": "Oh, quite well, yeah."}, {"time": 4740, "text": "What are your thoughts about his geometric community and the space of ideas that he's playing with in his proposal for theory of everything?"}, {"time": 4749, "text": "Well, I think that he has, he fundamentally has, I think, the same problems that everybody has had trying to do this, and there are really versions of the same problem that you try to get unity by putting everything into some bigger structure."}, {"time": 4806, "text": "So I just, anyway, it's the same, and there's another interesting example of a similar kind of thing is Garrett Leasy's theory of everything."}, {"time": 4845, "text": "And, because we don't see those symmetries in the real world, and so ultimately, there would need to be a simple process for collapsing it to four dimensions."}, {"time": 4918, "text": "Are there lessons, ideas to be learned from theories like that, from Garrett Leacy's, from Eric's?"}, {"time": 4925, "text": "I don't know, it depends, I have to confess, I haven't looked that closely at Eric's, I mean, he explained this to me personally a few times, and I've looked a bit at his paper, but it's, again, we're back to the problem of a limited amount of time in life."}, {"time": 4942, "text": "Yeah, I mean, it's an interesting effect, right?"}, {"time": 4946, "text": "Why don't more physicists look at it?"}, {"time": 5073, "text": "Yeah, it takes a long time, which is the nice thing about AI is unlike the kind of physics we're talking about, if your idea is good, that should quite naturally lead to you being able to build a system that's intelligent."}, {"time": 5089, "text": "So you don't need to get approval from somebody that's saying you have a good idea here."}, {"time": 5094, "text": "You can just utilize that idea in an engineer system, like naturally leads to engineering."}, {"time": 5098, "text": "With physics here, if you have a perfect theory that explains everything, that still doesn't obviously lead one, to scientific experiments that can validate that theory, and two, to like trinkets you can build and sell at a store for $5."}, {"time": 5118, "text": "You can't make money off of it."}, {"time": 5121, "text": "So that makes it much more challenging."}, {"time": 5125, "text": "Well, let me also ask you about something that you found, especially recently appealing, which is Roger Penrose's Twister theory."}, {"time": 5135, "text": "What kind of questions might it allow us to answer?"}, {"time": 5137, "text": "What will the answers look like?"}, {"time": 5139, "text": "It's only in the last couple of years that I really, really kind of come to really, I think, to appreciate it and to see how to really, I believe to see how to really do something with it."}, {"time": 5148, "text": "And I've gotten very excited about that the last year or two."}, {"time": 5151, "text": "I mean, one way of saying one idea of Twister theory is that it's a different way of thinking about what space and time are and about what points in space and time are, which is very interesting that it only really works in four dimensions."}, {"time": 5167, "text": "So four dimensions behaves very, very specially unlike other dimensions."}, {"time": 5171, "text": "And in four dimensions, there is a way of thinking about space and time geometry, as well as just thinking about points in space and time."}, {"time": 5181, "text": "You can also think about different objects, these so called twisters."}, {"time": 5186, "text": "And then when you do that, you end up with a kind of a really interesting insight that you can formulate a theory, and you can formulate a very, take a standard theory that we formulate in terms of points of space and time, and you can reformulate in this Twister language."}, {"time": 5204, "text": "And in this Twister language, it's the fundamental objects actually are more kind of the, are actually spheres in some sense, kind of the light cone."}, {"time": 5214, "text": "So maybe one way to say it, which actually I think is really, is quite amazing."}, {"time": 5222, "text": "If you ask yourself, what do we know about the world?"}, {"time": 5225, "text": "We have this idea that the world out there is all these different points and these points of time."}, {"time": 5231, "text": "Well, that's kind of a derived quantity."}, {"time": 5233, "text": "What we really know about the world is when we open our eyes, what do you see?"}, {"time": 5237, "text": "You see a sphere."}, {"time": 5239, "text": "And that what you're looking at is you're looking at, a sphere is worth of light rays coming into your eyes."}, {"time": 5246, "text": "And what Penrose says is that, well, what a point in space time is, is that sphere, that sphere of all the light rays coming in."}, {"time": 5256, "text": "And he says, and you should formulate your, instead of thinking about points, you should think about the space of those spheres, if you like, and formulate the degrees of freedom as physics as living on those spheres, living on, so you're kind of living on, your degrees of freedom are living on light rays, not on points."}, {"time": 5275, "text": "And it's a very different way of thinking about physics."}, {"time": 5280, "text": "And he and others working with him developed a beautiful mathematical formulas and a way to go back from forth between some aspects of our standard way we write these things down and work in the so called twister space."}, {"time": 5323, "text": "And my own, I mean, what's kind of gotten me excited really is what I think I have an idea about that I think does actually work, that goes more in that direction."}, {"time": 5334, "text": "And I can go on about that endlessly or talk a little bit about it, but that's the, I think that's the one kind of easy to explain insight about twister theory."}, {"time": 5345, "text": "There are some more technical ones."}, {"time": 5346, "text": "I should mean, I think it's also very convincing what it tells you about spinners, for instance, but that's a more technical."}, {"time": 5352, "text": "Well, first let's like linger on the spheres and the light cones."}, {"time": 5357, "text": "You're saying twisted theory allows you to make that the fundamental object with which you're operating."}, {"time": 5364, "text": "How that, I mean, first of all, like philosophically that's weird and beautiful, maybe because it maps, it feels like it moves us so much closer to the way human brains perceive reality."}, {"time": 5381, "text": "So it's almost like our perception is like the content of our perception is the fundamental object of reality."}, {"time": 5394, "text": "That's very appealing."}, {"time": 5397, "text": "Is it mathematically powerful?"}, {"time": 5401, "text": "Is there something you can say, can you say a little bit more about what the heck that even means for, because it's much easier to think about mathematically like a point in space time."}, {"time": 5413, "text": "What does it mean to be operating on the light cone?"}, {"time": 5416, "text": "It uses a kind of mathematics that's relative, that kind of goes back to the 19th century among mathematicians."}, {"time": 5423, "text": "It's not, anyway, it's a bit of a long story, but one problem is that you have to start, it's crucial that you think in terms of complex numbers and not just real numbers."}, {"time": 5432, "text": "And this, for most people, that makes it harder to, for mathematicians, that's fine."}, {"time": 5437, "text": "We love doing that."}, {"time": 5438, "text": "But for most people, that makes it harder to think about."}, {"time": 5441, "text": "I think perhaps the most, the way that there is something you can say very specifically about it in terms of spinners, which I don't know if you want to, I think at some point you want to talk, so maybe you can."}, {"time": 5452, "text": "What are spinners?"}, {"time": 5453, "text": "Let's start with spinners, because I think that if we can introduce that, then I can say it."}, {"time": 5457, "text": "By the way, twister is spelled with an O and spinner is spelled with an O as well."}, {"time": 5465, "text": "In case you want to Google it and look it up, there's very nice Wikipedia pages as a starting point."}, {"time": 5470, "text": "I don't know what is a good starting point for twister theory."}, {"time": 5473, "text": "Well, one thing you say about Penrose, I mean, Penrose is actually a very good writer and also a very good draftsman."}, {"time": 5479, "text": "He's a draftsman, to the extent this is visualizable, he actually has done some very nice drawings."}, {"time": 5483, "text": "So, I mean, almost any kind of expository thing you can find him writing is a very good place to start."}, {"time": 5489, "text": "He's a remarkable person."}, {"time": 5492, "text": "But the, so spinners are something that independently came out of mathematics and out of physics."}, {"time": 5500, "text": "And to say where they came out of physics, I mean, what people realized when they started looking at elementary particles like electrons or whatever, that there seem to be some kind of doubling of the degrees of freedom going on."}, {"time": 5513, "text": "If you counted what was there in some sense in the way you would expect it and when you started doing quantum mechanics and started looking at elementary particles, there were seen to be two degrees of freedom, they're not one."}, {"time": 5524, "text": "And one way of seeing it was that if you put your electron in a strong magnetic field and asked what was the energy of it, instead of it having one energy, it would have two energies, there'd be two energy levels."}, {"time": 5537, "text": "And as you increase magnetic field, the splitting would increase."}, {"time": 5542, "text": "So physicists kind of realized that, wait a minute."}, {"time": 5544, "text": "So we thought when we were doing, first started doing quantum mechanics, that the way to describe particles was in terms of wave functions and these wave functions were complex to complex values."}, {"time": 5555, "text": "Well, if we actually look at particles, that that's not right."}, {"time": 5558, "text": "They're pairs of complex numbers."}, {"time": 5564, "text": "So one of the kind of fundamental, from the physics point of view, the fundamental question is why are all our kind of fundamental particles described by pairs of complex numbers?"}, {"time": 5575, "text": "Just weird."}, {"time": 5576, "text": "And then you can ask, well, what happens if you like take an electron and rotate it?"}, {"time": 5583, "text": "So how do things move in this pair of complex numbers?"}, {"time": 5588, "text": "Well, now, if you go back to mathematics, what had been understood in mathematics, some years earlier, not that many years earlier, was that if you ask very, very generally, think about geometry of three dimensions and ask, and if you think about things that are happening in three dimensions in the standard way, everything, the standard way of doing geometry, everything is about vectors, right?"}, {"time": 5612, "text": "So if you've taken any mathematics classes, you probably see vectors at some point."}, {"time": 5616, "text": "They're just triplets of numbers tell you what a direction is or how far you're going in three dimensional space."}, {"time": 5622, "text": "And most of everything we teach in most standard courses in mathematics is about vectors and things you build out of vectors."}, {"time": 5631, "text": "So you express everything about geometry in terms of vectors or how they're changing or how you put two of them together and get planes and whatever."}, {"time": 5640, "text": "But what had been realized that, Rianna, is that if you ask very, very generally, what are the, if you have, what are the things that you can kind of consistently think about rotating?"}, {"time": 5653, "text": "And so you ask a technical question, what are the representations of the rotation group?"}, {"time": 5658, "text": "Well, you find that one answer is they're vectors and everything you build out of vectors, but then people found, but wait a minute, there's also these other things, which you can build out of vectors, but which you can consistently rotate."}, {"time": 5674, "text": "And they're described by pairs of complex numbers, by two complex numbers."}, {"time": 5678, "text": "And they're the spinners also."}, {"time": 5680, "text": "And to make a lot, and to make, and you can think of spinners in some sense as more fundamental than vectors because you can build vectors out of spinners."}, {"time": 5688, "text": "You can take two spinners and make a vector, but you can't, if you only have vectors, you can't get spinners."}, {"time": 5696, "text": "So they're in some sense, there's some kind of level of lower level of geometry beyond what we thought it was, which was kind of spinner geometry."}, {"time": 5704, "text": "And this is something which even to this day, when we teach graduate courses in geometry, we mostly don't talk about this because it's a bit hard to do correctly."}, {"time": 5715, "text": "If you start with your whole setup is in terms of vectors, describing things in terms of spinners is a whole different ball game."}, {"time": 5724, "text": "But anyway, it was just this amazing fact that this kind of more fundamental piece of geometry, spinners, and what we were actually seeing, if you look at electron, are one and the same."}, {"time": 5737, "text": "So it's, I think it's kind of a mind blowing thing, but it's very counterintuitive."}, {"time": 5744, "text": "What are some weird properties of spinners that are counterintuitive?"}, {"time": 5750, "text": "That there are some things that they do, for instance, if you rotate a spinner around 360 degrees, it doesn't come back towards, it becomes minus what it was."}, {"time": 5760, "text": "Or, so it's, anyway, so the way rotations work, there's a kind of a funny sign you have to keep track of in some sense."}, {"time": 5768, "text": "So they're kind of too valued in another weird way."}, {"time": 5771, "text": "But the fundamental problem is that it's just not, if you're used to visualizing vectors, you just, there's nothing you can do visualizing in terms of vectors that will ever give you a spinner."}, {"time": 5781, "text": "It just is not gonna ever work."}, {"time": 5783, "text": "As you were saying that I was visualizing a vector walking along a Mobius strip, and it ends up being upside down."}, {"time": 5792, "text": "But you're saying that doesn't really capture."}, {"time": 5794, "text": "So, I mean, what really captures it?"}, {"time": 5796, "text": "The problem is that it's really, the simplest way to describe it is in terms of two complex numbers."}, {"time": 5803, "text": "And your problem with two complex numbers is that's four real numbers."}, {"time": 5806, "text": "So your spinner kind of lies in a four dimensional space."}, {"time": 5810, "text": "So you, that makes it hard to visualize."}, {"time": 5813, "text": "And it's crucial that it's not just any four dimensions."}, {"time": 5817, "text": "It's just, it's actually complex numbers."}, {"time": 5819, "text": "You're really gonna use the fact that these are two complex numbers."}, {"time": 5823, "text": "So it's very hard to visualize."}, {"time": 5826, "text": "But to get back to what I think is mind blowing about twisters is that the, another way of saying this idea about talking about spheres, another way of saying the fundamental idea of twister theory is in some sense, the fundamental idea of twister theory is that a point is a two complex dimensional space."}, {"time": 5848, "text": "So that every, and that it lives inside, the space that it lies inside is twister space."}, {"time": 5854, "text": "So in the simplest case, it's four, twister space is four dimensional and a point in space time is a two complex dimensional subspace of all the four complex dimensions."}, {"time": 5867, "text": "And as you move around in space time, you're just moving, your planes are just moving around."}, {"time": 5872, "text": "And that, but then the."}, {"time": 5874, "text": "So it's a plane in a four dimensional space."}, {"time": 5876, "text": "It's a plane."}, {"time": 5878, "text": "Complex."}, {"time": 5879, "text": "Complex plane."}, {"time": 5880, "text": "So it's two complex dimensions in four complex."}, {"time": 5883, "text": "But then to me, the mind blowing thing about this is this then kind of tautologically answers the question is what is a spinner?"}, {"time": 5890, "text": "Well, a spinner is a point."}, {"time": 5894, "text": "I mean, the space of spinners at a point is the point."}, {"time": 5897, "text": "In twister theory, the points are the complex two planes."}, {"time": 5901, "text": "And you want me to, and you're asking what a spinner is."}, {"time": 5904, "text": "Well, a spinner, the space of spinners is that two plane."}, {"time": 5908, "text": "So it's, you know, just your whole definition of what a point in space time was just told you what a spinner was."}, {"time": 5915, "text": "It's, they're just, it's the same thing."}, {"time": 5917, "text": "Yeah, but we're trying to project that into a three dimensional space and trying to intuit, but you can't."}, {"time": 5922, "text": "Yeah, so the intuition becomes very difficult, but from, if you don't, not using twister theory, you have to kind of go through a certain fairly complicated rigmarole to even describe spinners to describe electrons."}, {"time": 5935, "text": "Whereas using twister theory, it's just completely tautological."}, {"time": 5938, "text": "They're just what you want to describe."}, {"time": 5943, "text": "The electron is fundamentally the way that you're describing the point in space time already."}, {"time": 5948, "text": "It's just there, so."}, {"time": 5951, "text": "You mentioned that you found it appealing recently."}, {"time": 5954, "text": "Is it just because of certain aspects of its mathematical beauty, or do you actually have a hope that this might lead to a theory of everything?"}, {"time": 5962, "text": "Yeah, I mean, I certainly do have such a hope because what I've found, I think the thing which I've done, which I don't think, as far as I can tell, no one had really looked at from this point of view before is, has to do with this question of how do you treat time in your quantum theory?"}, {"time": 5980, "text": "And so there's another long story about how we do quantum theories and about how we treat time in quantum theories, which is a long story."}, {"time": 5991, "text": "But the short version of it is that what people have found when you try and write down a quantum theory, that it's often a good idea to take your time coordinate, whatever you're using to your time coordinate, and multiply it by the square root of minus one and to make it purely imaginary."}, {"time": 6011, "text": "And so all these formulas, which you have in your standard theory, if you do that to those, I mean, those formulas have some very strange behavior and they're kind of singular."}, {"time": 6025, "text": "If you ask even some simple questions, you have to take very delicate singular limits in order to get the correct answer, and you have to take them from the right direction, otherwise it doesn't work."}, {"time": 6036, "text": "Whereas if you just take time, and if you just put a factor of square root of minus one, wherever you see the time coordinate, you end up with much simpler formulas, which are much better behaved mathematically."}, {"time": 6049, "text": "And what I hadn't really appreciated until fairly recently is also how dramatically that changes the whole structure of the theory."}, {"time": 6057, "text": "You end up with a consistent way of talking about these quantum theories, but it has some very different flavor and very different aspects that I hadn't really appreciated."}, {"time": 6067, "text": "And in particular, the way symmetries act on it is not at all what I originally had expected."}, {"time": 6075, "text": "And so that's the new thing that I have, or I think gives you something, is to do this move, which people often think of as just kind of a mathematical trick that you're doing to make some formulas work out nicely, but to take that mathematical trick as really fundamental."}, {"time": 6093, "text": "And it turns out in Twister theory allows you to simultaneously talk about your usual time and the time times the square root of minus one, they both fit very nicely into Twister theory."}, {"time": 6105, "text": "And you end up with some structures which look a lot like the standard models."}, {"time": 6111, "text": "Well, let me ask you about some Nobel prizes."}, {"time": 6115, "text": "Do you think there will be, there was a bet between Michio Kaku and somebody else about."}, {"time": 6124, "text": "John Horgan."}, {"time": 6125, "text": "John Horgan about, by the way, maybe discover a cool website, longbets.com or.org."}, {"time": 6131, "text": "Better, yeah, yeah."}, {"time": 6131, "text": "Yeah, it's cool."}, {"time": 6132, "text": "It's cool that you can make a bet with people and then check in 20 years later."}, {"time": 6138, "text": "I really love it."}, {"time": 6139, "text": "There's a lot of interesting bets on there."}, {"time": 6141, "text": "I would love to participate, but it's interesting to see, time flies and you make a bet about what's going to happen in 20 years."}, {"time": 6148, "text": "You don't realize 20 years just goes like this."}, {"time": 6151, "text": "And then you get to face out and you get to wonder what was that person?"}, {"time": 6159, "text": "What was I thinking?"}, {"time": 6161, "text": "That person 20 years ago was almost like a different person."}, {"time": 6163, "text": "What was I thinking back then to think that?"}, {"time": 6167, "text": "So let me ask you this on record, 20 years from now or some number of years from now, do you think there will be a Nobel Prize given for something directly connected to a first broadly theory of everything?"}, {"time": 6181, "text": "And second, of course, one of the possibilities, one of them, string theory?"}, {"time": 6190, "text": "String theory, definitely not."}, {"time": 6193, "text": "Things have gone, yeah."}, {"time": 6196, "text": "So if you were giving financial advice, you would say not to bet on that?"}, {"time": 6199, "text": "No, do not."}, {"time": 6200, "text": "And even, I actually suspect if you ask string theorists that question, you're gonna get a few of them saying, I mean, if you'd asked them that question 20 years ago, again, when Kaku was making this bet or whatever, I think some of them would have taken you up on it."}, {"time": 6215, "text": "And certainly back in 1984, a bunch of them would have said, oh, sure, yeah."}, {"time": 6219, "text": "But now I get the impression that even they realize that things are not looking good for that particular idea."}, {"time": 6226, "text": "Again, it depends what you mean by string theory, whether maybe the term will evolve to mean something else, which will work out."}, {"time": 6233, "text": "But I don't think that's not gonna like it to work out, whether something else."}, {"time": 6239, "text": "I mean, I still think it's relatively unlikely that you'll have any really successful theory of everything."}, {"time": 6244, "text": "And the main problem is just the, it's become so difficult to do experiments at higher energy that we've really lost this ability to kind of get unexpected input from experiment."}, {"time": 6259, "text": "And you can, while it's maybe hard to figure out what people's thinking is gonna be 20 years from now, looking at high energy particle, high energy colliders and their technology, it's actually pretty easy to make a pretty accurate guess what you're gonna be doing 20 years from now."}, {"time": 6277, "text": "And I think actually, I would actually claim that it's pretty clear where you're gonna be 20 years from now."}, {"time": 6284, "text": "And what it's gonna be is you're gonna have the LHC, you're gonna have a lot more data, an order of magnitude or more data from the LHC, but at the same energy."}, {"time": 6297, "text": "You're not gonna see a higher energy accelerator operating successfully in the next 20 years."}, {"time": 6305, "text": "And like maybe machine learning or great sort of data science methodologies that process that data will not reveal any major shifts in our understanding of the underlying physics, you think?"}, {"time": 6320, "text": "I mean, I think that field, my understanding is they're starting to make a great use of those techniques, but it seems to look like it will help them solve certain technical problems and be able to do things somewhat better, but not completely change the way they're looking at things."}, {"time": 6336, "text": "What do you think about the potential quantum computers simulating quantum mechanical systems and through that sneak up to sort of through simulation, sneak up to a deep understanding of the fundamental physics?"}, {"time": 6351, "text": "The problem there is that that's promising more for this, for Phil Anderson's problem, that if you wanna, there's lots and lots of, you start putting together lots and lots of things and we think we know they're pair by pair interactions, but what this thing is gonna do, we don't have any good calculational techniques."}, {"time": 6376, "text": "Quantum computers may very well give you those."}, {"time": 6379, "text": "And so they may, what we think of is kind of a strong coupling behavior."}, {"time": 6383, "text": "We have no good way to calculate."}, {"time": 6386, "text": "Even though we can write down the theory, we don't know how to calculate anything with any accuracy and the quantum computer may solve that problem."}, {"time": 6394, "text": "But the problem is that I don't think that they're gonna solve the problem that they help you with the problem of not having the, of knowing what the right underlying theory is."}, {"time": 6404, "text": "As somebody who likes experimental validation, let me ask you the perhaps ridiculous sounding, but I don't think it's actually a ridiculous question of do you think we live in a simulation?"}, {"time": 6416, "text": "Do you find that thought experiment at all useful or interesting?"}, {"time": 6420, "text": "Not really, I don't, it just doesn't."}, {"time": 6423, "text": "Yeah, anyway, to me, it doesn't actually lead to any kind of interesting, lead anywhere interesting."}, {"time": 6431, "text": "Yeah, to me, so maybe I'll throw a wrench into your thing."}, {"time": 6436, "text": "To me, it's super interesting from an engineering perspective."}, {"time": 6439, "text": "So if you look at virtual reality systems, the actual question is how much computation and how difficult is it to construct a world that like there are several levels here."}, {"time": 6456, "text": "One is you won't know the difference, our human perception systems and maybe even the tools of physics won't know the difference between the simulated world and the real world."}, {"time": 6467, "text": "That's sort of more of a physics question."}, {"time": 6471, "text": "The most interesting question to me has more to do with why food tastes delicious, which is create how difficult and how much computation is required to construct a simulation where you kind of know it's a simulation at first, but you want to stay there anyway."}, {"time": 6487, "text": "And over time, you don't even remember."}, {"time": 6493, "text": "Yeah, well, anyway, I agree, these are kind of fascinating questions and they may be very, very relevant to our future as a species, but yeah, they're just very far from anything I think."}, {"time": 6506, "text": "Well, so from a physics perspective, it's not useful to you to think, taking a computational perspective to our universe, thinking of it as an information processing system and then they give it as doing computation and then you think about the resources required to do that kind of computation and all that kind of stuff."}, {"time": 6522, "text": "You could just look at the basic physics and who cares what the computer it's running on is."}, {"time": 6526, "text": "Yeah, it just, I mean, the kinds of, I mean, I'm willing to agree that you can get into interesting kinds of questions going down that road, but they're just so different from anything from what I've found interesting and I just, again, I just have to kind of go back to life is too short and I'm very glad other people are thinking about this, but I just don't see anything I can do with it."}, {"time": 6548, "text": "What about space itself?"}, {"time": 6551, "text": "So I have to ask you about aliens."}, {"time": 6554, "text": "Again, something, since you emphasize evidence, do you think there is, how many, do you think there are and how many intelligent alien civilizations are out there?"}, {"time": 6565, "text": "Yeah, I have no idea, but I have certainly, as far as I know, unless the government's covering it up or something, we haven't heard from, we don't have any evidence for such things yet, but there seems to be no, there's no particular obstruction why there shouldn't be, so."}, {"time": 6583, "text": "I mean, do you, you work on some fundamental questions about the physics of reality."}, {"time": 6589, "text": "When you look up to the stars, do you think about whether somebody's looking back at us?"}, {"time": 6595, "text": "Yes, yeah, well, actually, I originally got interested in physics."}, {"time": 6598, "text": "I actually started out as a kid interested in astronomy, exactly that, and a telescope and whatever that, and certainly read a lot of science fiction and thought about that."}, {"time": 6608, "text": "I find over the years, I find myself kind of less, anyway, less and less interested in that one, just because I don't really know what to do with them."}, {"time": 6619, "text": "I also kind of, at some point, kind of stopped reading science fiction that much, kind of feeling that there was just too, that the actual science I was kind of learning about was perfectly kind of weird and fascinating, and unusual enough, and better than any of the stuff that Isaac Asimov, so why should I?"}, {"time": 6636, "text": "Yeah, and you can mess with the science much more than the distant science fiction, the one that exists in our imagination or the one that exists out there among the stars."}, {"time": 6649, "text": "Well, you mentioned science fiction."}, {"time": 6651, "text": "You've written quite a few book reviews."}, {"time": 6654, "text": "I gotta ask you about some books, perhaps, if you don't mind."}, {"time": 6657, "text": "Is there one or two books that you would recommend to others and maybe if you can, what ideas you drew from them?"}, {"time": 6669, "text": "Either negative recommendations or positive recommendations."}, {"time": 6672, "text": "Do not read this book for sure."}, {"time": 6675, "text": "Well, I must say, I mean, unfortunately, yeah, you can go to my website and you can click on book reviews and you can see I've written, read a lot of, a lot of, I mean, as you can tell from my views about string theory, I'm not a fan of a lot of the kind of popular books about, oh, isn't string theory great?"}, {"time": 6692, "text": "And yes, I'm not a fan of a lot of things of that kind."}, {"time": 6697, "text": "Can I ask you a quick question on this, a small tangent?"}, {"time": 6701, "text": "Are you a fan, can you explore the pros and cons of, if I get string theory, sort of science communication, sort of Cosmos style communication of concepts to people that are outside of physics, outside of mathematics, outside of even the sciences and helping people to sort of dream and fill them with awe about the full range of mysteries in our universe?"}, {"time": 6730, "text": "That's a complicated issue."}, {"time": 6731, "text": "You know, I think, you know, I certainly go back and go back to like what inspired me and maybe to connect it a little bit to this question about books."}, {"time": 6739, "text": "I mean, certainly when the books, some books that I remember reading when I was a kid were about the early history of quantum mechanics, like Heisenberg's books that he wrote about, you know, kind of looking back at telling the history of what happened when he developed quantum mechanics."}, {"time": 6752, "text": "It's just kind of a totally fascinating, romantic, great story, and those were very inspirational to me."}, {"time": 6760, "text": "And I would think maybe other people might also find them that, but the... And that's almost like the human story of the development of the ideas."}, {"time": 6769, "text": "Yeah, the human story, but yeah, just also how, you know, there are these very, very weird ideas that didn't seem to make sense, and how they were struggling with them and how, you know, they actually..."}, {"time": 6778, "text": "Anyway, it's, I think it's the period of physics kind of beginning, you know, 1905 with Planck and Einstein and ending up with the war when these things get used to, you know, make massively destructive weapons."}, {"time": 6794, "text": "It's just the truly amazing... And so many, so many new ideas."}, {"time": 6797, "text": "Let me, on another, a tangent on top of a tangent on top of a tangent, ask, if we didn't have Einstein, so how does science progress?"}, {"time": 6806, "text": "Is it the lone geniuses?"}, {"time": 6808, "text": "Or is it some kind of weird network of ideas swimming in the air and just kind of the geniuses pop up to catch them and others would anyway?"}, {"time": 6819, "text": "Without Einstein, would we have special relativity, general relativity?"}, {"time": 6824, "text": "I mean, it's an interesting case to case basis."}, {"time": 6827, "text": "I mean, special relativity, I think we would have had, I mean, there are other people."}, {"time": 6833, "text": "Anyway, you could even argue that it was already there in some form in some ways, but I think special relativity you would have had without Einstein fairly quickly."}, {"time": 6843, "text": "General relativity, that was a much, much harder thing to do and required a much more effort, much more sophisticated."}, {"time": 6851, "text": "That I think you would have had sooner or later, but it would have taken quite a bit longer."}, {"time": 6856, "text": "That took a bunch of years to validate scientifically, the general relativity."}, {"time": 6861, "text": "But even for Einstein, from the point where he had kind of a general idea of what he was trying to do to the point where he actually had a well defined theory that you could actually compare to the real world, that was, I forget the number of the order of magnitude, 10 years of very serious work."}, {"time": 6876, "text": "And if he hadn't been around to do that, it would have taken a while before anyone else got around to it."}, {"time": 6883, "text": "On the other hand, there are things like, with quantum mechanics, you have Heisenberg and Schrodinger came up with two, which ultimately equivalent, but two different approaches to it within months of each other."}, {"time": 6899, "text": "And so if Heisenberg hadn't been there, you already would have had Schrodinger or whatever."}, {"time": 6904, "text": "And if neither of them had been there, it would have been somebody else a few months later."}, {"time": 6907, "text": "So there are times when the, just the, a lot often is the combination of the right ideas are in place and the right experimental data is in place to point in the right direction."}, {"time": 6920, "text": "And it's just waiting for somebody who's gonna find it."}, {"time": 6925, "text": "Maybe to go back to your aliens, I guess the one thing that I often wonder about aliens is, would they have the same fundamental physics ideas as we have in mathematics?"}, {"time": 6935, "text": "Would their math, you know, would they, you know, how much is this really intrinsic to our minds?"}, {"time": 6942, "text": "If you start out with a different kind of mind when you end up with a different ideas of what fundamental physics is or what the structure of mathematics is."}, {"time": 6949, "text": "So this is why, like if I was, you know, I like video games, the way I would do it as a curious being, so first experiment I'd like to do is run Earth over many thousands of times and see if our particular, no, you know what?"}, {"time": 6966, "text": "I wouldn't do the full evolution."}, {"time": 6968, "text": "I would start at Homo sapiens first and then see the evolution of Homo sapiens millions of times and see how the ideas of science would evolve."}, {"time": 6976, "text": "Like, would you get, like how would physics evolve?"}, {"time": 6979, "text": "How would math evolves?"}, {"time": 6981, "text": "I would particularly just be curious about the notation they come up with."}, {"time": 6985, "text": "Every once in a while I would like throw miracles at them to like, to mess with them and stuff."}, {"time": 6991, "text": "And then I would also like to run Earth from the very beginning to see if evolution will produce different kinds of brains that would then produce different kinds of mathematics and physics."}, {"time": 7000, "text": "And then finally, I would probably millions of times run the universe over to see what kind of, what kind of environments and what kind of life would be created to then lead to intelligent life, to then lead to theories of mathematics and physics and to see the full range."}, {"time": 7020, "text": "And like, sort of like Darwin kind of mark, okay."}, {"time": 7024, "text": "It took them, what is it, several hundred million years to come up with calculus."}, {"time": 7033, "text": "I would just like keep noting how long it took and get an average and see which ideas are difficult, which are not and then conclusively sort of figure out if it's more collective intelligence or singular intelligence that's responsible for shifts and for big phase shifts and breakthroughs in science."}, {"time": 7053, "text": "If I was playing a video game and ran, I got a chance to run this whole thing."}, {"time": 7058, "text": "Yeah, but we're talking about books before I distracted us horribly."}, {"time": 7062, "text": "About books, okay, so books, yeah, go back, books."}, {"time": 7064, "text": "Yeah, so and then, yeah, so that's one thing I'd recommend is the books about the, from the original people, especially Heisenberg about the, how that happened."}, {"time": 7073, "text": "And there's also a very, very good kind of history of the kind of what happened during this 20th century in physics and up to the time of the Standard Model in 1973."}, {"time": 7085, "text": "It's called The Second Creation by Bob Kreis and Mann."}, {"time": 7090, "text": "That's one of the best ones."}, {"time": 7091, "text": "I know that's, but the one thing that I can say is that, so that book, I think, I forget when it was, late 80s, 90s."}, {"time": 7100, "text": "The problem is that there just hasn't been much that's actually worked out since then."}, {"time": 7104, "text": "So most of the books that are kind of trying to tell you about all the glorious things that have happened since 1973 are, they're mostly telling you about how glorious things are, which actually don't really work."}, {"time": 7115, "text": "And it's really, the argument people sometimes make in favor of these books as well, oh, they're really great because you want to do something that will get kids excited."}, {"time": 7123, "text": "And then, so they're getting excited about things, something that's not really quite working."}, {"time": 7127, "text": "It doesn't really matter, the main thing is get them excited."}, {"time": 7130, "text": "The other argument is, wait a minute, if you're getting people excited about ideas that are wrong, you're really kind of, you're actually kind of discrediting the whole scientific enterprise in a not really good way."}, {"time": 7142, "text": "So there's this problem."}, {"time": 7144, "text": "So my general feeling about expository stuff is, yeah, it's to the extent you can do it kind of honestly and, well, that's great."}, {"time": 7152, "text": "There are a lot of people doing that now, but to the extent that you're just trying to get people excited and enthusiastic by kind of telling them stuff, which isn't really true, you really shouldn't be doing that."}, {"time": 7166, "text": "You obviously have a much better intuition about physics."}, {"time": 7168, "text": "I tend to, in the space of AI, for example, you could use certain kinds of language, like calling things intelligent that could rub people the wrong way."}, {"time": 7183, "text": "But I never had a problem with that kind of thing, saying that a program can learn its way without any human supervision as AlphaZero does to play chess."}, {"time": 7193, "text": "To me, that may not be intelligence, but it sure as heck seems like a few steps down the path towards intelligence."}, {"time": 7204, "text": "And so I think that's a very peculiar property of systems that can be engineered."}, {"time": 7210, "text": "So even if the idea is fuzzy, even if you're not really sure what intelligence is, or if you don't have a deep fundamental understanding or even a model what intelligence is, if you build a system that sure as heck is impressive and showing some of the signs of what previously thought impossible for a nonintelligent system, then that's impressive and that's inspiring and that's okay to celebrate."}, {"time": 7236, "text": "In physics, because you're not engineering anything, you're just now swimming in the space, directly when you do theoretical physics, that it could be more dangerous."}, {"time": 7245, "text": "You could be out too far away from shore."}, {"time": 7248, "text": "Yeah, well, the problem, I think physics is, I think it's actually hard for people even to believe or really understand how that this particular kind of physics has gotten itself into a really unusual and strange and historically unusual state, which is not really."}, {"time": 7266, "text": "I mean, I spent half my life among mathematicians and half of the physicists, and mathematics is kind of doing fine."}, {"time": 7272, "text": "People are making progress and it has all the usual problems, but also, so you could have a, but I just, I don't know, I've never seen anything at all happening in mathematics like what's happened in this specific area in physics."}, {"time": 7286, "text": "It's just the kind of sociology of this, the way this field works banging up against this harder problem without anything from experiment to help it."}, {"time": 7298, "text": "It's really, it's led to some really kind of problematic things."}, {"time": 7303, "text": "And those, so it's one thing to kind of oversimplify or to slightly misrepresent, to try to explain things in a way that's not quite right, but it's another thing to start promoting to people as a success as ideas, which really completely failed."}, {"time": 7320, "text": "And so, I mean, I've kind of a very, very specific, if you used to have people, I won't name any names, for instance, coming on certain podcasts like yours, telling the world, this is a huge success and this is really wonderful."}, {"time": 7336, "text": "And this is really problematic and it carries a serious danger of once, when people realize that this is what's going on, that the loss of credibility of science is a real, real problem for our society."}, {"time": 7354, "text": "And you don't want people to have an all too good reason to think that what they're being told by kind of some of the best institutions or a country or authorities is not true."}, {"time": 7369, "text": "You know, it's not true, it's a problem."}, {"time": 7372, "text": "That's obviously characteristic of not just physics, it's sociology."}, {"time": 7380, "text": "And it's, I mean, obviously in the space of politics, it's the history of politics is you sell ideas to people, even when you don't have any proof that those ideas actually work in the US because if they've worked in that, that seems to be the case throughout history."}, {"time": 7403, "text": "And just like you said, it's human beings running up against a really hard problem."}, {"time": 7408, "text": "I'm not sure if this is like a particular like trajectory through the progress of physics that we're dealing with now or it's just a natural progress of science."}, {"time": 7420, "text": "You run up against a really difficult stage of a field and different people behave differently in the face of that."}, {"time": 7433, "text": "Some sell books and sort of tell narratives that are beautiful and so on."}, {"time": 7437, "text": "They're not necessarily grounded in solutions that have proven themselves."}, {"time": 7442, "text": "Others kind of put their head down quietly, keep doing the work."}, {"time": 7446, "text": "Others sort of pivot to different fields and that's kind of like, yeah, ants scattering."}, {"time": 7451, "text": "And then you have fields like machine learning, which there was a few folks mostly scattered away from machine learning in the 90s, in the winter of AI, AI winter, as they call it."}, {"time": 7462, "text": "But a few people kept their head down and now they're called the fathers of deep learning."}, {"time": 7467, "text": "And they didn't think of it that way."}, {"time": 7471, "text": "And in fact, if there's another AI winter, they'll just probably keep working on it anyway, sort of like loyal ants sticking to a particular thing."}, {"time": 7480, "text": "So it's interesting, but you're sort of saying that we should be careful over hyping things that have not proven themselves because people will lose trust in the scientific process."}, {"time": 7493, "text": "But unfortunately, there's been other ways in which people have lost trust in the scientific process."}, {"time": 7499, "text": "That ultimately has to do actually with all the same kind of behavior as you're highlighting, which is not being honest and transparent about the flaws of mistakes of the past."}, {"time": 7510, "text": "Yeah, I mean, that's always a problem."}, {"time": 7512, "text": "But this particular field is kind of fun."}, {"time": 7514, "text": "It's always a strange one."}, {"time": 7517, "text": "I mean, I think in the sense that there's a lot of public fascination with it that it seems to speak to kind of our deepest questions about what is this physical reality?"}, {"time": 7527, "text": "Where do we come from?"}, {"time": 7528, "text": "And these kind of deep issues."}, {"time": 7530, "text": "So there's this unusual fascination with it."}, {"time": 7533, "text": "Mathematics is very different."}, {"time": 7534, "text": "Nobody's that interested in mathematics."}, {"time": 7536, "text": "Nobody really kind of expects to learn really great, deep things about the world from mathematics that much."}, {"time": 7542, "text": "They don't ask mathematicians that."}, {"time": 7544, "text": "So it's a very unusual, it draws this kind of unusual amount of attention."}, {"time": 7550, "text": "And it really is historically in a really unusual state."}, {"time": 7554, "text": "It's gotten itself way kind of down a blind alley in a way which it's hard to find other historical parallels to."}, {"time": 7566, "text": "But sort of to push back a little bit, there's power to inspiring people."}, {"time": 7570, "text": "And if I just empirically look, physicists are really good at combining science and philosophy and communicating it."}, {"time": 7584, "text": "Like there's something about physics often that forces you to build a strong intuition about the way reality works, right?"}, {"time": 7591, "text": "And that allows you to think through sort of and communicate about all kinds of questions."}, {"time": 7597, "text": "Like if you see physicists, it's always fascinating to take on problems that have nothing to do with their particular discipline."}, {"time": 7603, "text": "They think in interesting ways and they're able to communicate their thinking in interesting ways."}, {"time": 7608, "text": "And so in some sense, they have a responsibility not just to do science, but to inspire."}, {"time": 7615, "text": "And not responsibility, but the opportunity."}, {"time": 7618, "text": "And thereby, I would say a little bit of a responsibility."}, {"time": 7623, "text": "But I don't know, anyway, it's hard to say because there's many, many people doing this kind of thing with different degrees of success and whatever."}, {"time": 7709, "text": "Well, in general, for graduate students, for people who seek to be experts in the field, diversity of ideas is really powerful and is getting into this local pocket of ideas that people hold on to for several decades is not good, no matter what the idea."}, {"time": 7724, "text": "I would say no matter if the idea is right or wrong, because there's no such thing as right in the long term, like it's right for now until somebody builds on something much bigger on top of it."}, {"time": 7738, "text": "It might end up being right, but being a tiny subset of a much bigger thing."}, {"time": 7743, "text": "So you always should question sort of the ways of the past."}, {"time": 7747, "text": "Yeah, so how to kind of achieve that kind of diversity of thought and within kind of the sociology of how we organize scientific researches."}, {"time": 7757, "text": "I know this is one thing that I think it's very interesting that Sabina Hassenfelder has very interesting things to say about it."}, {"time": 7763, "text": "And I think also Lee Smolin in his book, which is also about that very much in agreement with them that there's a really kind of important questions about how research in this field is organized and what can you do to kind of get more diversity of thought and get people thinking about a wider range of ideas."}, {"time": 7793, "text": "At the bottom, I think humility always helps."}, {"time": 7795, "text": "Well, the problem is that it's also, it's a combination of humility to know when you're wrong and also, but also you have to have a certain very serious lack of humility to believe that you're gonna make progress on some of these problems."}, {"time": 7811, "text": "I think you have to have like both modes and switch between them when needed."}, {"time": 7818, "text": "Let me ask you a question you're probably not gonna wanna answer because you're focused on the mathematics of things and mathematics can't answer the why questions, but let me ask you anyway."}, {"time": 7830, "text": "Do you think there's meaning to this whole thing?"}]}, {"title": "Ray Dalio: Money, Power, and the Collapse of Empires | Lex Fridman Podcast #251", "id": "TISMidxdZoc", "quotes": [{"time": 556, "text": "25% of the world's new inventions came from the Dutch, and so as they went around the world, they also brought their currency, and they brought their military."}, {"time": 568, "text": "They needed the currency, they paid for things, and that currency, and then the more that happens, the more that becomes a reserve currency, and then they have their military, so they need their military strength, and so you see it evolve in all of those ways."}, {"time": 585, "text": "But over a period of time, as they become more successful and more expensive, they become more expensive, and newer countries come along, like the UK, then learn to build ships from a lot the Dutch and could do that less expensively, and also when they become more expensive, so less competitive, and also the work ethic begins to change."}, {"time": 619, "text": "They believe that since they're richer, they can enjoy life more."}, {"time": 622, "text": "They don't have to work quite as hard, and so you start to see the tilt."}, {"time": 628, "text": "Now you start to see the development of the top, and when you have a world reserve currency, that allows you to borrow a lot of money because those who want to save want to hold your money, and that means that they'll lend you money, and so those countries get deeper into debt."}, {"time": 647, "text": "So you see that they gradually lose their competitiveness, and they get themselves into financial circumstances, which are not good, and they have large wealth gaps, which set the stage for downturns."}, {"time": 664, "text": "And when they have downturns, the first question is do they have enough money?"}, {"time": 670, "text": "And traditionally, money is resources."}, {"time": 675, "text": "So you classically see that the coffers are bare, that they're spending more money than they are earning, and they run out of money in the coffers, and their granaries are empty rather than stocked so that they give them the buffer."}, {"time": 695, "text": "And as that deteriorates, that worsens conditions."}, {"time": 700, "text": "And if they have a rival power that's also challenging them, they see greater internal conflict over wealth, and then they have the problems internally and the problems externally, which usually results in an internal war or an external war that leads to the change to the new world order."}, {"time": 723, "text": "And to you, the Dutch Empire is a good example of that."}, {"time": 727, "text": "The British, what are some of the key examples that you think about in the book of this process that followed the big cycle?"}, {"time": 736, "text": "Well, the leading reserve currency empires, but it applies to all the empires, were the Dutch, the British, the American, and the Chinese."}, {"time": 748, "text": "But you could follow the same pattern."}, {"time": 752, "text": "In the book, it was very important for me to not just use words and concepts because that's subjective."}, {"time": 761, "text": "It was very important for me to use actual measurements."}, {"time": 765, "text": "So as you see in the book, you can see every level of this."}, {"time": 769, "text": "You can see where's the education level, what is the military power, each one of those, and you could see them back going over the 500 years."}, {"time": 779, "text": "And so you could see the arcs and the composition of those arcs, and what you see is really, in most countries and most dynasties, you could see that."}, {"time": 790, "text": "But you also can see through those numbers the health of those countries."}, {"time": 795, "text": "Today, there are statistics that are in the book that show what is the level of education, what is the level of economic output, what is the level of military strength, what is the level of a number of different measures of strength, so that you can then compare that."}, {"time": 818, "text": "And I think that because they're objective measures of strength that you could see change, that shows the picture of where we are today."}, {"time": 828, "text": "And I think one of the most important things about the book is that it allows people to monitor how those things are transpiring."}, {"time": 836, "text": "I think for policymakers, are your policymakers doing a good job?"}, {"time": 843, "text": "And there's so much subjectivity in that."}, {"time": 846, "text": "But I think it's very simple."}, {"time": 848, "text": "If those lines on the chart are improving, if your health index is improving, then you're moving toward a better life."}, {"time": 857, "text": "So that's what the book works like."}, {"time": 859, "text": "Also, it was used to create a model for the future."}, {"time": 864, "text": "In other words, there are cause effect relationships."}, {"time": 868, "text": "Everything that happens has reasons, causes, that preceded it, that made it happen."}, {"time": 874, "text": "And so by having all those in numbers, one can see the probabilities of certain things happening."}, {"time": 882, "text": "So that's what you see in the book."}, {"time": 886, "text": "It's not just Ray's interpretation."}, {"time": 889, "text": "I didn't wanna make it Ray's interpretation because I don't know if I'm right."}, {"time": 893, "text": "Yeah, so one of the fascinating things in the book, so you have list these 18 measures, and there's like a little scorecard for the countries of the world today."}, {"time": 904, "text": "So let's say US, China, and Europe, and what it was 20 years ago, and looking at the change from 20 years ago, and that's another indicator, the change itself, to see where things are headed."}, {"time": 917, "text": "Maybe can you comment on, from a score perspective, how is US and China doing?"}, {"time": 924, "text": "And in the 18 measures, what are some measures that stand out to you as particularly important to think about today for the United States, for China?"}, {"time": 933, "text": "Well, there are a number."}, {"time": 935, "text": "Financially, what you see in the United States is that we're borrowing a lot more money, creating a lot of debt, and we're printing a lot of money."}, {"time": 949, "text": "And our capacity to do that is very much, is limited, first of all, because when there's a sale of a bond, when the government borrows more than it borrows money, because it spends more than it takes in, you have to sell a bond."}, {"time": 970, "text": "And the world right now has a lot of US dollar denominated bonds, because as the world's reserve currency, they sell, sold on them."}, {"time": 978, "text": "And they have very bad returns, negative real returns, negative real returns significantly, and so on."}, {"time": 987, "text": "So that means that more bonds has to be sold than are bought."}, {"time": 996, "text": "And that means that the Federal Reserve is faced with the choice of having to raise the interest rate to curtail borrowing, which slows the economy and hurts the markets, or by filling that difference and producing money, the debt monetization, which produces an inflation in goods, services, and financial assets."}, {"time": 1023, "text": "So in that regard, that's the United States's position."}, {"time": 1028, "text": "In China's case, its balance of payments is better."}, {"time": 1033, "text": "China has displaced the United States as the world's largest trading country."}, {"time": 1040, "text": "In other words, more exports to other countries."}, {"time": 1043, "text": "And as a result, it's economically competitive, but it doesn't have the world's reserve currency."}, {"time": 1051, "text": "It's a real blessing."}, {"time": 1052, "text": "So the United States, it has the world's reserve currency, but it is risking it because of this imbalance."}, {"time": 1060, "text": "So if you look at history, you see that those go slowly, but when they go eventually, they go quickly."}, {"time": 1070, "text": "So there's a risk of that financially."}, {"time": 1074, "text": "Then there's the issue of internal order."}, {"time": 1078, "text": "So I'm just giving you the major ones, but I'll get into some of the other ones too."}, {"time": 1082, "text": "Right now, there's a lot of internal conflict in the United States, which affects how well it works."}, {"time": 1094, "text": "In China, there's less internal conflict because it's a more autocratic state, but also they've created this bifurcation of what is political and what is economic in terms of producing that prosperity."}, {"time": 1112, "text": "So if you stay out of the politics pretty much, and then you're seeing entrepreneurship, you're seeing the finances of new businesses and so on."}, {"time": 1124, "text": "And so that internal working, that's subject to different people's interpretations whether they like it or not, but the internal conflict in terms of those kinds of measures is less."}, {"time": 1137, "text": "Sorry to pause on that for a second."}, {"time": 1140, "text": "So these measures, I guess you don't want to sort of romanticize any one measure or something like that, overinterpret any one measure, but is internal conflict always a bad thing?"}, {"time": 1153, "text": "Is it a complicated calculation?"}, {"time": 1158, "text": "Or do you kind of, the way we think about these measures that you've presented, we should be thinking like the higher, the better, the lower, the worse, I mean, of course, depending on the measure."}, {"time": 1167, "text": "Well, in many cases, the conflict that produces the revolution produces revolutionary changes that lead to resolutions and lead to new starts."}, {"time": 1184, "text": "And so a short term civil war is a hellacious experience."}, {"time": 1192, "text": "And at the same time, it can be the transition to a new beginning."}, {"time": 1198, "text": "Also, there are different types of conflict."}, {"time": 1203, "text": "Competition, which makes things, makes everything better, is a productive conflict, whereas destructive conflicts are not good over the short time."}, {"time": 1220, "text": "So that's how those go."}, {"time": 1223, "text": "So within each measure, the story is complicated."}, {"time": 1229, "text": "Yeah, but my measures are sort of clear, meaning how much political conflict, how much social conflict."}, {"time": 1238, "text": "In other words, you can measure conflict, you can measure fighting, you can measure crime rates, you can measure lots of different ways of conflict."}, {"time": 1249, "text": "So the measures are a composite of different types of internal conflict."}, {"time": 1255, "text": "What are some other interesting measures, maybe if you can also mention that, for me in particular, interest is education and innovation."}, {"time": 1263, "text": "Yes, the classic cycle, the most important leading indicator is the quality of education."}, {"time": 1271, "text": "Most importantly, broad based education drawn from the largest population because you can never tell who the talent is going to be."}, {"time": 1283, "text": "So where are they gonna come from?"}, {"time": 1285, "text": "So for example, if you look at the Chinese dynasties, the great Chinese dynasties and the Confucian approach, it was meritocratic of everybody could sit for exams and so on broad base of drawing in the populations."}, {"time": 1301, "text": "And you see that if you go across societies because that draws on the largest number of population to get education."}, {"time": 1310, "text": "And it also, that creates a reality and a perception that the system is fair, equal opportunity, not just one of privilege."}, {"time": 1323, "text": "And that helps to create social stability."}, {"time": 1326, "text": "But education is not just education in understanding facts and so on, it is education in civility of how to behave together."}, {"time": 1339, "text": "And so if they're smart, they understand how to be productive because they work well together and they're productive."}, {"time": 1347, "text": "And then that leads to the next stage."}, {"time": 1350, "text": "You could see in the lines in the charts, I plotted these so that you could see in a typical cycle, you could see that education is the long leading indicator."}, {"time": 1362, "text": "And then you could see, as you mentioned, that what you see is inventiveness and technology measures then follow and you see then also competitiveness and world markets follows."}, {"time": 1375, "text": "For example, in the early stages of a cycle, the industries that they go into tend to be very basic industry because they have cheap labor, something like textiles and simple manufactured goods and so on."}, {"time": 1391, "text": "But as the education rises, then they move up the value chain to greater technologies and so on, which raises incomes and raises productivity."}, {"time": 1403, "text": "So yes, those and as you say, there are 18 different measures like that, but education and then civility and the inventiveness."}, {"time": 1412, "text": "So you see it reflected in who's inventing what."}, {"time": 1418, "text": "And that corresponds then who's trading with, who's a big trading country and where's the value of economic output and what are per capita incomes."}, {"time": 1427, "text": "They all follow those arcs."}, {"time": 1431, "text": "Yeah, like you said, the fascinating thing about your book, so there's philosophy, there's wisdom, but there's plots."}, {"time": 1438, "text": "Yeah, you can see it."}, {"time": 1441, "text": "So it's not just your opinion."}, {"time": 1442, "text": "It's kind of like you can interpret it in any way you like, but you're just giving a lot of your own insights along with the numbers."}, {"time": 1452, "text": "If you were to look at the American nation, the American empire and the trajectories looking into the future given these measures, what is the trajectory that leads to the collapse of the American empire based on these measures?"}, {"time": 1468, "text": "What are the concerning indicators and if those break down further, what does that look like?"}, {"time": 1474, "text": "Well, all of those indicators are concerning, maybe except for one, which is technology, the technology niche, although even in that area, the United States is improving at a slower rate than is China for various advantages that they have there."}, {"time": 1500, "text": "They put out about eight times as many computer engineers they have free data and so on, but if you look at them, so the financial is a concern."}, {"time": 1512, "text": "The internal order, disorder is a concern."}, {"time": 1517, "text": "Then if you look at education levels, the United States is in many ways is losing its educational advantage."}, {"time": 1527, "text": "If you were to look at, compare it with China, if you take general public education in the United States, it's deteriorated tremendously even in comparison to developed countries."}, {"time": 1540, "text": "There are scores, PISA scores and so on, and it's something like 38th in the world or something and that was a big plunge, average public education."}, {"time": 1548, "text": "If you look at the best universities in the world, the United States is unique in having the best universities in the world, so there are these privileged universities in the world, so there are these privileged spots that are, you know, excellent, uniquely excellent."}, {"time": 1566, "text": "So when you look at the comparison, education in China is improving rapidly and the quantity is a quantity of educated people in the areas that they're moving in is greater and the resources that they're putting behind it is greater and so you see the results are greater, but it's sort of along the lines that I'm dealing with."}, {"time": 1594, "text": "If you were to follow through in terms of actual productions, I think you know in terms of technologies, there are some areas that the United States is in a lead at the moment, there's some areas that China's in a lead, but China's gaining very quickly."}, {"time": 1614, "text": "When I first went to China, 1984, I would bring $10 calculators and I gave them away as gifts to high ranking people and they thought they were miracle devices."}, {"time": 1628, "text": "Right now, in terms of areas like quantum computing and AI and you know, many areas, you have a race going on and so if you take the trajectory of the competitiveness, not just look at the current level, you have a situation where they're improving at a much faster rate."}, {"time": 1651, "text": "This is all good for the world if the world can get along."}, {"time": 1656, "text": "And the main thing I think is, how do you have a healthy world and how do you have a strong economy and how do you have a strong situation is be strong."}, {"time": 1669, "text": "The United States is war is with itself."}, {"time": 1673, "text": "That's the main war."}, {"time": 1675, "text": "You know, it's very simple in history."}, {"time": 1679, "text": "Be financially sound, earn more than you spend and be strong in these ways and pretty much everything will take care of itself."}, {"time": 1693, "text": "But you make it sound simple of course because there's a momentum when things degrade, when the education system degrades, when you start borrowing, when I mean, all of these indicators, once they're going down, there's a momentum to it, right?"}, {"time": 1708, "text": "So it's hard to reverse it."}, {"time": 1710, "text": "Right and there are circumstances that you're then in."}, {"time": 1713, "text": "For example, indebtedness."}, {"time": 1716, "text": "You know, it's politically desirable for those to borrow money and spend because their constituencies only look at what they get and when they get a lot, they don't pay attention to the balance sheet and how much debt is on the books."}, {"time": 1735, "text": "So it's always better to borrow, spend and then leave the cleanup to the next guy."}, {"time": 1741, "text": "And so you inherit a lot."}, {"time": 1744, "text": "You inherit it as a new president enters in or new legislators, they have a lot of debt, they have a broken down infrastructure, they don't have enough money to fix that."}, {"time": 1759, "text": "And so that's the lay of the land that the prior generations put you in and there you are."}, {"time": 1770, "text": "It's difficult because when you start to think, okay, what's healthy?"}, {"time": 1774, "text": "Well, earn more than you spend."}, {"time": 1777, "text": "Well, that's not so easy because you know, what does that mean?"}, {"time": 1781, "text": "Go earn more?"}, {"time": 1782, "text": "I mean, okay, that's not so easy."}, {"time": 1784, "text": "Spend less?"}, {"time": 1787, "text": "That isn't gonna work."}, {"time": 1789, "text": "So now what do you do?"}, {"time": 1790, "text": "Okay, you have this debt that you then monetize and that's why it's classic."}, {"time": 1795, "text": "So yes, that's why these cycles occur because what has created before, what happened before created the lay of the land that is then increasingly difficult to deal with."}, {"time": 1806, "text": "So what can great leaders do in this moment?"}, {"time": 1808, "text": "I mean, maybe my sense is leadership is crucial here."}, {"time": 1813, "text": "So for example, to do very large projects and invest in the education system that sort of try to fix the fundamentals or maybe invest more and more into the innovation and the development of new technologies and so on."}, {"time": 1829, "text": "It feels like that just doesn't happen organically."}, {"time": 1833, "text": "So you have to have strong leaders that convince the populace of the importance of these ideas."}, {"time": 1843, "text": "Well, I completely agree with your list."}, {"time": 1846, "text": "What we have is a situation where everybody has their opinions and they have to sort of get them exactly right and they all fight with each other about whether their opinions."}, {"time": 1858, "text": "So the most important thing is that we become bipartisan so that we don't and we get over our differences."}, {"time": 1867, "text": "I would have a bipartisan cabinet."}, {"time": 1870, "text": "I would draw upon both members of both parties, the moderates who are going to be able to work together."}, {"time": 1880, "text": "So as then we have one country and then we deal with those in a means that works for the majority of the people in the middle rather than the polarity."}, {"time": 1892, "text": "I think our greatest risk is in not being able to do that."}, {"time": 1897, "text": "So I would say that's a paramount importance because we have the resources, wealth, real wealth and science and everything has never been better than it is."}, {"time": 1911, "text": "But the notion is that it has to work for the majority of people and we have to keep it being productive."}, {"time": 1919, "text": "So that group has got to calmly and knowledgeably work together so that they increase the size of the pie and they create broad based prosperity."}, {"time": 1932, "text": "So that is a paramount importance."}, {"time": 1935, "text": "Whatever they do, if they do it that way, I can say I'm happy about because that other alternative is the really scary alternative."}, {"time": 1948, "text": "The scary alternative, the different ways it has evolved throughout history, some of it has led to wars."}, {"time": 1959, "text": "What are the future trajectories that lead to a potential war with China?"}, {"time": 1964, "text": "Cold war or hot war?"}, {"time": 1968, "text": "Is this something you're worried about?"}, {"time": 1970, "text": "Yeah, I'd like to talk about both wars."}, {"time": 1972, "text": "So the war with China, as I say, there are five kinds of wars."}, {"time": 1976, "text": "There's a trade war, technology war, geopolitical influence war, capital war, and military war."}, {"time": 1988, "text": "As far as military war goes, I think it's only a Taiwan issue, but that's a big issue."}, {"time": 1996, "text": "And we could talk about that for a minute, but those others, they'll be rough competitions and we'll have that type of evolution over a period of time."}, {"time": 2007, "text": "That's what that war looks like."}, {"time": 2010, "text": "Taiwan has been, for a long time, a sovereignty issue to China."}, {"time": 2020, "text": "And it has its roots in what's called the 100 years of humiliation."}, {"time": 2027, "text": "From the 1840s to 1949, foreign powers came in, took advantage of China, they had the opium wars and such times, and that represented the 100 years of humiliation."}, {"time": 2043, "text": "And Taiwan represents their sovereignty and their important thing."}, {"time": 2051, "text": "And 50 years ago, starting 50 years ago, there was an agreement that there is one China and Taiwan is part of China."}, {"time": 2061, "text": "And that there would be peaceful reunification."}, {"time": 2066, "text": "The peaceful reunification hasn't happened."}, {"time": 2071, "text": "And in their view, that's a very big issue."}, {"time": 2074, "text": "And so it's a big contentious issue."}, {"time": 2077, "text": "And that could produce a military war, could produce a military accident, could produce, it's a very tense situation."}, {"time": 2086, "text": "And if we had a military war, God help us because of the capacity in all different new ways to inflict harm on each other."}, {"time": 2096, "text": "But anyway, that's that."}, {"time": 2098, "text": "If you don't have that military war, you'll have the competition between those other kinds of wars and whoever is strongest in those areas will win."}, {"time": 2111, "text": "Where do you put cyber war within the five?"}, {"time": 2114, "text": "Well, cyber war is a military war."}, {"time": 2117, "text": "I'm assuming the type of cyber war that you're referring to is that which is used to inflict pain on the other party through cyber."}, {"time": 2126, "text": "So cyber wars, you'll see cyber war."}, {"time": 2129, "text": "You could see space war."}, {"time": 2131, "text": "You can see drone warfare."}, {"time": 2135, "text": "New types of warfare, not just the traditional and nuclear type of warfare."}, {"time": 2142, "text": "But you could see any of the above."}, {"time": 2144, "text": "What are the defining characteristics?"}, {"time": 2148, "text": "What are the interesting things about Xi Jinping, the president of China, as a leader on the world stage?"}, {"time": 2155, "text": "His father was a early leader."}, {"time": 2161, "text": "He was himself in the Cultural Revolution in times, treated brutally."}, {"time": 2172, "text": "And during that period of time, it was very, very difficult."}, {"time": 2177, "text": "And he came up through the ranks and he's a very intelligent man."}, {"time": 2186, "text": "When he first came to power, as you know, they have two five year terms, and we're now coming to the end of the second of those five year terms."}, {"time": 2196, "text": "When he first came to power, he felt that there should be a lot of reform."}, {"time": 2202, "text": "And reform meant moving to much more of a market and open economy."}, {"time": 2209, "text": "When that happened, him coming in, I had some contact with economic policymakers, but in the circumstances then, were that five major banks lent to state owned enterprises and local governments with implied government guarantees."}, {"time": 2227, "text": "And so there was not control of that and the movement to aim more of a market economy."}, {"time": 2234, "text": "And the development of markets was a primary and also the dealing with the corruption issue."}, {"time": 2240, "text": "There was a lot of corruption prior to that, and that was viewed as an existential threat to the system."}, {"time": 2248, "text": "So that became the primary objective."}, {"time": 2251, "text": "And then as time progressed over those 10 years, there was a lot of changing in the world, their financial circumstances, opening many, many other markets."}, {"time": 2266, "text": "They particularly getting money to small and medium sized enterprises and developing a lending system and then establishing controls on it."}, {"time": 2275, "text": "So right now there's a vibrant capital markets."}, {"time": 2280, "text": "You can raise capital, you can be an entrepreneur, you can become a billionaire in the capital markets."}, {"time": 2287, "text": "And they developed the markets to be the second largest capital markets."}, {"time": 2291, "text": "At the same time, they had to deal with their rising debt issue, which they began to deal with really about four years ago, when the second largest capital markets were about four years ago, when the second term began."}, {"time": 2313, "text": "And then Lu He became the vice premier responsible for that and to deal with those issues."}, {"time": 2326, "text": "So you see right now that what's happening is the dealing with the real estate bubble."}, {"time": 2333, "text": "There was a development in real estate, a bubble, which produced a lot of unproductive lending."}, {"time": 2339, "text": "And Xi Jinping said, houses are meant to live in, not to speculate on."}, {"time": 2348, "text": "And so that was wasteful."}, {"time": 2349, "text": "So they established what they call three red lines, which are financial ratios, that the property developers had to live within."}, {"time": 2358, "text": "And that is then causing the adjustments that are going on now, which in my view are very healthy because whenever there's bankruptcies and so on, most in the public think, okay, that's a problem."}, {"time": 2373, "text": "It's in many cases really a cleaning up of bad debts and bad practices."}, {"time": 2377, "text": "And so that's what's going on."}, {"time": 2380, "text": "So that's, let's say economically."}, {"time": 2382, "text": "At the same time, there is the changing relationships, the changing world order, the changing relationships with the United States and other countries, which is becoming much less cooperative and much more warlike, much more confrontational."}, {"time": 2402, "text": "Those two things, the domestic debt problem and the domestic, has led to what's called core, what they call core leadership, which means a leadership more around him that is less challenging because they believe in history that during very difficult times, a more centrally controlled decision making process lends itself better than to a more fragmented political contentious project."}, {"time": 2435, "text": "And that's basically what's going on now."}, {"time": 2439, "text": "You said it very eloquently, but you mean the leadership is surrounded by yes men and there's a lot of centralized control."}, {"time": 2450, "text": "That characterization is much more black and white than it really is."}, {"time": 2457, "text": "But it leans towards that direction."}, {"time": 2460, "text": "Like for example, of the standing members of the Politburo, four are more allotted, three are less so."}, {"time": 2469, "text": "You have to understand that it's kind of a collective leadership at the top."}, {"time": 2474, "text": "And then of course, there's just jockeying for power in a highly political sense at the top."}, {"time": 2482, "text": "But no one leader can be successful against all those powers at the top."}, {"time": 2490, "text": "So it's very politically negotiating."}, {"time": 2492, "text": "It's very much more like if you put in the United States the Democrats and the Republicans and they had to be in the same government and they work it out."}, {"time": 2503, "text": "It's kind of something like that."}, {"time": 2505, "text": "And so that's that struggle, but it's an internal struggle."}, {"time": 2509, "text": "Where do you put the importance of some of these ideas at the founding of the United States when now we're talking about that at the context of China, the freedom of speech, freedoms?"}, {"time": 2522, "text": "What China is doing with the central management of a lot of things, it's enabling a lot of growth, but it's also limiting people on the very basic level in terms of freedom."}, {"time": 2533, "text": "The kind of freedom that I think can lead to entrepreneurship, to starting new businesses, to having big dreams and chasing those dreams and then creating totally new things in whatever the space, maybe in technology, in business and whatever."}, {"time": 2550, "text": "How important is that as a metric for society?"}, {"time": 2553, "text": "Well, they have a view, which is the idea of a dialectic, which means that two things are at obvious, that everything comes with pros and cons and two opposites exist."}, {"time": 2566, "text": "And you want the benefits of those two opposites and how do you deal with the benefits of those two opposites?"}, {"time": 2574, "text": "So let's say you want the capital markets because it gets money into the hands of the entrepreneurs who are motivated, they build fortunes, and that drives an economy to do very well."}, {"time": 2587, "text": "And at the same time, it produces the other problems, the wealth gaps, the other problems, the debt cycle that we're talking about and so on."}, {"time": 2598, "text": "And Deng Xiaoping, how do you reconcile communism and the market economy and the capital markets?"}, {"time": 2607, "text": "And he famously said, it doesn't matter if it's a white cat or a black cat, just as long as it catches mice."}, {"time": 2616, "text": "In other words, if it works in making the country richer, then that becomes the objective and then they move that along."}, {"time": 2623, "text": "So there are these conflicts."}, {"time": 2626, "text": "And one of the leaders described it to me as follows, because it's confusion and it goes back over a period of time."}, {"time": 2635, "text": "There's a hierarchy and it's an extension of the family, he described it."}, {"time": 2641, "text": "And he said, the United States is a country of individuals and individualism, and that is its vibrancy that we see the individual rights to speak up, the individual protection of the individual, individual property rights and all of those things is of paramount importance."}, {"time": 2668, "text": "And we build our organization."}, {"time": 2669, "text": "That's why democracy is from the bottom up or even a company, we'll get together and we'll be partners to prosper together."}, {"time": 2677, "text": "That is the American approach."}, {"time": 2679, "text": "He was describing that in China, it's an extension of the Confucian family, essentially."}, {"time": 2687, "text": "And so it's almost like there's a hierarchy."}, {"time": 2692, "text": "And so what they think about is the common good, not the individualism."}, {"time": 2699, "text": "So for example, if they want a high speed rail to go from one place to another, and that's best in the common good, then the individual protections that would stand in the way of doing that would be of secondary concern."}, {"time": 2713, "text": "So that notion of controlling."}, {"time": 2717, "text": "So for example, what they're doing with video games, they control what type of video games and how many hours a day kids can be on video games operating in that way, because they believe that that's good for the society and that's very controlling."}, {"time": 2740, "text": "In the United States, I think probably most parents would say, leave it to me."}, {"time": 2745, "text": "And it's a matter between me and my kids."}, {"time": 2748, "text": "The same thing has to do with data."}, {"time": 2750, "text": "In other words, in the United States, who controls the data?"}, {"time": 2755, "text": "Does the company control the data?"}, {"time": 2757, "text": "Do you individually control the data?"}, {"time": 2760, "text": "And so the inclination would be to figure that out, but nobody would say that the government is going to control the data because of our inclination of really anti government control."}, {"time": 2771, "text": "In China, it would be that the government will control the data because that's going to be best for the society."}, {"time": 2778, "text": "And it depends who you trust."}, {"time": 2780, "text": "But that's, so that difference in philosophy is very much at the heart of that."}, {"time": 2788, "text": "As far as your question in terms of effectiveness, it really is, in China's case, it's how you balance the things, right?"}, {"time": 2798, "text": "So what they're attempting to do is to create a lot of freedom and creativity in areas that are not political, let's say."}, {"time": 2810, "text": "And so you see a lot of entrepreneurship, you see a lot of product development, you see a lot of creativity happening in that way."}, {"time": 2820, "text": "So the stereotype that you don't see creativity happening is an old stereotype, whereas a lot of creativity is certainly happening."}, {"time": 2829, "text": "And the system can work well if they can achieve that kind of balance."}, {"time": 2833, "text": "It's proven to have worked well."}, {"time": 2835, "text": "Since I started going there in 1984, per capita income, real per capita income, has increased by 26 times."}, {"time": 2844, "text": "The longevity rate has increased by 10 years."}, {"time": 2848, "text": "The poverty rate has fallen from 88% to less than 1% in terms of basics like starvation and things."}, {"time": 2857, "text": "And if you read history, Plato's Republic, he talks about the cycles, democracy and autocratic and the benevolent despot and all of that, each has their own vulnerability."}, {"time": 2873, "text": "The vulnerability of democracy, which has been a remarkable, remarkable system and I don't have to extol the benefits of it, but the vulnerability of it has always been the internal conflict that produces itself as anarchy."}, {"time": 2893, "text": "In World War II, four democracies chose to be autocracies because there was internal disorder and there was the belief, will somebody bring about order and get control of the situation?"}, {"time": 2912, "text": "That was in Germany, Italy, Japan and Spain."}, {"time": 2918, "text": "They were parliamentary systems that turned themselves over to that."}, {"time": 2923, "text": "So both systems have vulnerabilities."}, {"time": 2929, "text": "I think the main thing that we need to think about is those vulnerabilities."}, {"time": 2934, "text": "Democracy is an amazing system because the adherence to the rules and the system and the checks and balances is quite amazing and it gives it a flexibility to change without civil wars."}, {"time": 2952, "text": "But there has to be the respect of the rules."}, {"time": 2955, "text": "And when you see something like they will not accept elections or they will not accept rules, history has shown, when the causes that people are behind are more important to them than the system, the system is in jeopardy."}, {"time": 2974, "text": "So we have a situation that's very much like that in terms of, let's say, the 2024 elections."}, {"time": 2982, "text": "I believe that there's a very high chance that neither side will accept losing, for example."}, {"time": 2991, "text": "And so we have that kind of a situation."}, {"time": 2996, "text": "So one would hope that one could rise above the disagreements and rely on the system for resolving disagreements."}, {"time": 3006, "text": "Because if that doesn't happen, then we have our own chaos."}, {"time": 3013, "text": "So the kind of the trend that started in 2020, or I mean, I suppose it's been there, it's been growing."}, {"time": 3022, "text": "One representation of this internal disorder has been the growing trend of being skeptical about the results of the election."}, {"time": 3029, "text": "Well, it started before that."}, {"time": 3031, "text": "There was the emergence of population before President Trump was elected."}, {"time": 3040, "text": "He was basically elected as a populist because there was a large percentage of the population that felt that the system didn't work for them."}, {"time": 3050, "text": "And he tapped into that."}, {"time": 3052, "text": "And he was largely elected as a populist leader, first populist leader in a developed country."}, {"time": 3060, "text": "And so populism began then."}, {"time": 3064, "text": "And that was a battle of one group against the other group."}, {"time": 3068, "text": "And so since then, it's been like that and it continued to grow."}, {"time": 3077, "text": "You've mentioned the vulnerability of democracy, that internal disorder is the vulnerability of democracy."}, {"time": 3086, "text": "What's the vulnerability of a system like China?"}, {"time": 3089, "text": "Maybe one way to say is put China aside and look at history, look at Soviet Union."}, {"time": 3094, "text": "What's the vulnerability of a communist type system?"}, {"time": 3099, "text": "Well, I'll call it both communist and autocratic, depending on how much autocracy, is that it lacks flexibility."}, {"time": 3112, "text": "It lacks the ability, but I should deal with them differently."}, {"time": 3119, "text": "In other words, there's the economic system."}, {"time": 3122, "text": "The economic system threatens motivation and productivity."}, {"time": 3127, "text": "So communism or socialism has to be done in a way where you can threaten productivity."}, {"time": 3136, "text": "Capitalism has, and what I mean by that, I mean free markets and capital markets have been an effective way of allocating resources and also creating the incentives and the resources, providing the resources for the inventiveness of new ideas."}, {"time": 3157, "text": "And so if I compare that, what the Chinese have done to a large extent is to recognize that and have made a move."}, {"time": 3167, "text": "That's why the seeming dialectic or the conflict between those two things exists."}, {"time": 3173, "text": "But anyway, that's it."}, {"time": 3175, "text": "As far as an autocratic system, rather than one man, one vote from the population up, the risks of the autocratic system is that there's enough discontent that arises that the system doesn't have the flexibility and that rather than bending, it breaks."}, {"time": 3201, "text": "That's the big risk."}, {"time": 3204, "text": "The notion of trying to control a population if there's that, rather than giving it the flexibility."}, {"time": 3212, "text": "So that would be the big risk of the autocratic system."}, {"time": 3216, "text": "What's the human, because you mentioned like the top gets bigger with the empires and you start to get things for granted."}, {"time": 3225, "text": "Is some of this just human nature?"}, {"time": 3228, "text": "So the concern with China, with autocratic nations, the concern with the Third Reich, the Soviet Union, was that fundamentally at the individual level, the humans involved at the top, they start becoming, they're starting to lose touch with reality in a way that no longer makes them."}, {"time": 3253, "text": "I guess that's the representation, the flexibility that you're referring to."}, {"time": 3256, "text": "Well, I mean, in a democracy, you could change."}, {"time": 3261, "text": "You can go as far left or as far right."}, {"time": 3263, "text": "You can change the leaders easily."}, {"time": 3265, "text": "And so the people don't become, they pretty much only have themselves to blame."}, {"time": 3272, "text": "And one of the problems of that is they may not choose the best leaders, but they have that flexibility."}, {"time": 3282, "text": "So vote and you get what you wanted."}, {"time": 3286, "text": "In the case of the autocratic, let's say leaders, and then the movement from democracies to autocracies, what you see normally that movement is that one of the systems is not working."}, {"time": 3300, "text": "Let's say the democracy is not effectively, everybody's arguing with each other and nobody's getting anything done."}, {"time": 3306, "text": "You know, like Mussolini, the trains are not running on time."}, {"time": 3310, "text": "And that would be the example, geez, this place has gotten chaotic."}, {"time": 3314, "text": "Will somebody get to control?"}, {"time": 3316, "text": "And then you get the autocratic and then he's autocratic enough to boss people around."}, {"time": 3324, "text": "And then you follow those kinds of orders."}, {"time": 3329, "text": "And it's like maybe a CEO in a powerful company going around and that could work well or it could work badly."}, {"time": 3336, "text": "Most companies are run as like autocracies in a sense."}, {"time": 3341, "text": "You know, there's the hierarchy and the command economy and that kind of thing."}, {"time": 3346, "text": "And that can work well or not."}, {"time": 3351, "text": "But then quite often when you get the populist autocratic, their personality is something that they want to fight and they become more nationalistic and they tend to become more militaristic."}, {"time": 3367, "text": "And human nature at that stage lends itself to fighting."}, {"time": 3373, "text": "There's an arc here that when we think of a country and we say we, and we think of a country, it's not true, it's not like that."}, {"time": 3384, "text": "There are individuals who change."}, {"time": 3386, "text": "One generation dies and another generation comes along."}, {"time": 3390, "text": "And one of those arcs is that the one generation of the ones who have been through war don't wanna go to war and are more happily willing to abide by whatever the rules are."}, {"time": 3407, "text": "As you get farther along into that cycle and you get a new generation and they forget about wars and the horrors of wars, then they want to fight."}, {"time": 3419, "text": "And so you're seeing right now the emerging of fight for right and what that means is you see it internally, fight where are you and fight for that thing and they mean fight."}, {"time": 3434, "text": "And then externally, fight, are you going to be the strong one who will fight and win?"}, {"time": 3441, "text": "And that develops on both sides, this fight and win and each side is cheering each other on into a war."}, {"time": 3450, "text": "But that comes by those who really have not experienced war because it comes in their part of their lifetime."}, {"time": 3458, "text": "Humans are fascinating."}, {"time": 3461, "text": "And by the way, human nature has not changed over the thousands of years."}, {"time": 3468, "text": "So it's so interesting because like in doing this study and it comes across in the study, it's like watching the same movie over and over again."}, {"time": 3476, "text": "You know, you see the arc and you see it happen over and over again."}, {"time": 3482, "text": "The only things that seem to change are the clothes people wear and the technologies they use."}, {"time": 3487, "text": "Yeah, and then somebody probably would disagree with you about the clothes."}, {"time": 3493, "text": "Maybe there's also cycles within fashions."}, {"time": 3496, "text": "Maybe we're not even creative there."}, {"time": 3498, "text": "What do you make of Russia and Vladimir Putin?"}, {"time": 3503, "text": "What do you think about Putin as a leader, as a human being on this world stage within the context of the cycles of empires that you think about?"}, {"time": 3513, "text": "Well, Putin came to power at the failure of Russia's last order."}, {"time": 3521, "text": "So there was the end of communism and there was the development of the market economy, the collapse of the Soviet Union."}, {"time": 3530, "text": "And at that time, he was appointed by Yeltsin who was an alcoholic and had problems managing and was put into power."}, {"time": 3545, "text": "And the conditions in the Russia were, there was anarchy, there was no money."}, {"time": 3552, "text": "It had the classic end of cycle ingredients."}, {"time": 3555, "text": "It was broke."}, {"time": 3556, "text": "It was people were fighting with each other."}, {"time": 3558, "text": "It was in the anarchy."}, {"time": 3560, "text": "And that's when he came to power."}, {"time": 3563, "text": "And there were not institutions."}, {"time": 3567, "text": "The whole thing had collapsed and it was not effective ministry of education, ministry of anything."}, {"time": 3574, "text": "And so the idea was that they needed 25 years of stability and they needed a democracy and they needed the improvement of capital markets."}, {"time": 3587, "text": "So he's been in that position as I guess I would call him a semi autocratic leader in that from all indications, he would respect the democracy and he's very popular."}, {"time": 3607, "text": "He's won democratic elections because he's been a strong leader and he's brought peace and stability to Russia after the breakup of the Soviet Union."}, {"time": 3621, "text": "And he's a strong leader in pursuit of the country's interest in a way where Russia is not a significant economic power but it is a significant military power."}, {"time": 3643, "text": "So the issues, and then there's a strong alliance between Russia and China now."}, {"time": 3651, "text": "So that's kind of the lay of the land."}, {"time": 3655, "text": "And then there are sensitivities."}, {"time": 3658, "text": "The Ukraine issue is a sensitivity because of there are a lot of Russians who live in the Ukraine and there's also the issue of NATO on their border."}, {"time": 3671, "text": "So there are those kinds of things and he has military power and he has a strong alliance with China."}, {"time": 3678, "text": "And I guess that's my best summary of what his position is."}, {"time": 3684, "text": "He's a strong leader, popular."}, {"time": 3690, "text": "These are not subjective interpretations."}, {"time": 3693, "text": "These are objective interpretations."}, {"time": 3695, "text": "Yeah, it's interesting just in this conversation, you're not sort of doing the usual criticism of any one particular system."}, {"time": 3705, "text": "You're looking at these systems from the perspective of history."}, {"time": 3708, "text": "You're just describing how they work."}, {"time": 3710, "text": "It's often times when you talk about what Russia is today or what the Soviet Union was or what China is today is you start to criticize."}, {"time": 3718, "text": "Well, they do this kind of censorship or they do this kind of, they limit freedoms in this kind of way."}, {"time": 3725, "text": "But you're just kind of describing this as a nation with ideas, what they think is right."}, {"time": 3731, "text": "This is how they hope to get it to work."}, {"time": 3733, "text": "This is why it's working."}, {"time": 3734, "text": "This is what's not working."}, {"time": 3736, "text": "Here's metrics that show that it's not working."}, {"time": 3739, "text": "I think that's a refreshing way to think about it."}, {"time": 3741, "text": "It's easy though, I mean, you got some criticism saying that I think China is a strict parent."}, {"time": 3750, "text": "Some people criticize these countries for doing, for violating human rights."}, {"time": 3755, "text": "I suppose there's some people that criticize the United States for violating human rights."}, {"time": 3761, "text": "But what are your thoughts on the world stage today about some of the behaviors it has governed in terms of respecting the rights, the basic rights of human beings?"}, {"time": 3775, "text": "You described accurately how I just tried to look at this and how I just tried to look at things in a non, I don't want to impute my values on anybody."}, {"time": 3792, "text": "I mean, there are intolerable things."}, {"time": 3794, "text": "So I'm not saying there aren't intolerable things."}, {"time": 3796, "text": "But one of the great things of being an American here is that I grew up with all different nationalities, having all different points of view and all different religions and all different ways of operating."}, {"time": 3810, "text": "And I've come to treasure the fact that that is, what's their business is their business."}, {"time": 3817, "text": "And then the question is, where do you cross the line under what circumstances that others have got to do it my way."}, {"time": 3825, "text": "And then when you do it internationally, the issue of what is a sovereign state, which as I say in the piece of Westphalia and you have borders and then when do you cross the line that my way of doing things has got to be their way of doing things or what are the various rights."}, {"time": 3846, "text": "And so that's a very delicate question or a very difficult question."}, {"time": 3851, "text": "And we all have responsibilities to different parties and we all have different levels of knowledge about those particular things."}, {"time": 3861, "text": "So for example, as an international investor, I have a responsibility to my investors."}, {"time": 3869, "text": "Those who run companies have a responsibility to theirs of how do they run that."}, {"time": 3874, "text": "So if you're taking Nike or Snickers and so on and Americans can decide whether they wanna buy Chinese products or not buy Chinese products, we are all faced with those types of choices."}, {"time": 3889, "text": "So you have what do you wanna do in your constituency and you have your choices."}, {"time": 3893, "text": "And then beyond that, in many cases, the issues are quite complex, like there are geopolitical questions that enter into it."}, {"time": 3902, "text": "So, and then I believe that if you disconnected, if all those entities like myself, the businesses doing business with China disconnected, I think that that would be disastrous, economically disastrous."}, {"time": 3922, "text": "And it would also be reduce the understanding that comes from working together that helps to reduce wars."}, {"time": 3931, "text": "And so these are all complicated."}, {"time": 3933, "text": "So what we do is, and who makes it my opinion matters the most?"}, {"time": 3939, "text": "Why should it be my opinion that matters the most in making that decision?"}, {"time": 3943, "text": "So I largely look at the government guidance that I get not only from my own government, but from the other governments and I follow the rules."}, {"time": 3952, "text": "I'm in 40, we invest in 40 countries."}, {"time": 3955, "text": "And we wanna do that in the best way to provide the diversified portfolio."}, {"time": 3959, "text": "And we sort of need that."}, {"time": 3961, "text": "Every one of those countries has similar complexities."}, {"time": 3966, "text": "There are always one issue or another, and there's only so much that we really understand about all of those issues."}, {"time": 3973, "text": "So we rely largely on the guidance that we get."}, {"time": 3977, "text": "Yeah, you have to empathize and show respect to the culture of the place, the way things are done."}, {"time": 3983, "text": "You don't necessarily, the way you heal relationships between nations is like you said, you work together."}, {"time": 3992, "text": "And that requires kind of to listen maybe more than you talk."}, {"time": 4000, "text": "And I think people in the public sphere talk a lot about China without really listening, without understanding much about China, though one of the things that makes me really sad because I know how to speak Russian and I know how much is lost in translation."}, {"time": 4017, "text": "It makes me sad that I'll never really get to know the Chinese culture because like, I'll never really get to know the language, the literature, just talk to regular people."}, {"time": 4028, "text": "It's not just the government or officials or scientists, just regular folks, get the culture."}, {"time": 4032, "text": "I think if you don't understand the culture, just the basics of the human nature, what people love about their country, about their family or the kind of hopes they have, what kind of values they have, without that you're not gonna be able to fully connect with them."}, {"time": 4054, "text": "And you have to do that first to have a chance of building a good world."}, {"time": 4059, "text": "I was very lucky because as I say, since 1984, so for more than half of my life, I've been going there and the common people and all sorts of people, and I've got to meet them."}, {"time": 4073, "text": "I don't speak the language, but a combination of through translators or them speaking English and being in situations."}, {"time": 4082, "text": "I had my son go to school, a local school, and we developed those kinds of understandings."}, {"time": 4090, "text": "I think that, but the not wanting to know the other perspective is the thing that's most scary."}, {"time": 4102, "text": "Like I'm right now in the middle and all I want to try to do is to help mutual understanding."}, {"time": 4111, "text": "You're right, if there were questions probing me, asking me, what is it?"}, {"time": 4116, "text": "I'm not on one side or another."}, {"time": 4119, "text": "I don't want to be on one side or another."}, {"time": 4121, "text": "I believe that each has their right within there to approach their different culture in their own way."}, {"time": 4126, "text": "So many ways you gave an example."}, {"time": 4130, "text": "If they're not doing harm to others, I mean, but that issue of trying to understand is so much better."}, {"time": 4143, "text": "That doesn't mean agree with."}, {"time": 4145, "text": "If you are wanting to out clever and out compete somebody, it still pays to understand what they're thinking."}, {"time": 4156, "text": "So to achieve understanding of what they're thinking, even if you want to go to war with them, that understanding is the best thing to have."}, {"time": 4165, "text": "What we have now is a situation in which there's an enemy mentality."}, {"time": 4171, "text": "And that means that anything that serves, seems to be like understanding or conveying understanding, seems to mistakenly create the notion of I'm on their side in a war."}, {"time": 4185, "text": "And that's kind of a dangerous thing because there's a momentum here to fight."}, {"time": 4191, "text": "Henry Kissinger praises your new book and you thank him in it in the dedication."}, {"time": 4199, "text": "What makes him interesting?"}, {"time": 4201, "text": "Maybe what makes him controversial?"}, {"time": 4203, "text": "What makes him such a central figure in history?"}, {"time": 4205, "text": "First, most importantly, he's unique about seeing things through all the others eyes."}, {"time": 4214, "text": "So if you were, it's like there's a chess game."}, {"time": 4218, "text": "I mean, I think geopolitics is like a chess game, but with multiple chess players playing the same game."}, {"time": 4226, "text": "So imagine there are six people around playing the chess game and he could sit in each seat and he could know how they see it, okay?"}, {"time": 4238, "text": "And see it in a calm way of how they see it."}, {"time": 4242, "text": "He's unique in that way."}, {"time": 4243, "text": "He's 98 years old and he's equally able to do that."}, {"time": 4248, "text": "And he has a background in which he's a historian."}, {"time": 4252, "text": "So he really understands history super terrifically."}, {"time": 4258, "text": "He doesn't understand economic history as much."}, {"time": 4262, "text": "So that's why to some extent we enjoy having a conversation because he's interested in the economic piece he doesn't know and I'm so interested in the geopolitical piece that I don't know as well."}, {"time": 4275, "text": "But anyway, he's able to do that, but not only a historian, but a practitioner."}, {"time": 4281, "text": "So when you go from an academic to a practitioner who has that talent to see things through others eyes in an objective way and to be strategic rather than just tactical, that's a very special person and that's why Henry is, to me, a very special person."}, {"time": 4303, "text": "Yeah, he's lived a fascinating life."}, {"time": 4305, "text": "Just all of the world events he's been involved in is fascinating and like you said, that's such an interesting skill to have to consider what are the concerns, the hope, the dreams, the fears of all the people at the table."}, {"time": 4319, "text": "What are they thinking?"}, {"time": 4321, "text": "I find that people don't, once again, don't do that enough when it's the obvious thing you should be doing, whether it's business deals or political negotiation or geopolitical negotiation."}, {"time": 4335, "text": "I'm often surprised, again, sorry to go to the Russian thing because I hear Putin talk in Russian and you start to infer certain intentions, like not the trivial stuff, like the human being."}, {"time": 4350, "text": "What is that human being hoping for himself, for his country, for his close inner circle, for the bigger, and I just see that that's often just lost in translation."}, {"time": 4361, "text": "I just see American leaders talking to Putin and it's just not, there's not a connection."}, {"time": 4368, "text": "Absolutely, I know exactly what you're talking about."}, {"time": 4373, "text": "It has never failed that in my listening to a conversation or even reading a speech and you see then it reported, inevitably, the reporter picks some headline characterization that has very little to do with what was really happening but might be a headline grabber that's at some kind of distortion and there's a lack of understanding of really what's going on."}, {"time": 4405, "text": "If it's okay, let me ask you a couple questions about cryptocurrency."}, {"time": 4409, "text": "You've had a few opinions about Bitcoin over the years."}, {"time": 4412, "text": "What are your thoughts about Bitcoin today, its role in the global financial system and just in human society in general?"}, {"time": 4421, "text": "Well, the evolution of Bitcoin over the years is one of the things that has influenced changes in my view."}, {"time": 4431, "text": "It has proven itself something like 10, 11 years ago."}, {"time": 4437, "text": "Imagine the programming of this and you throw it out and that's the idea."}, {"time": 4442, "text": "It has not been hacked."}, {"time": 4444, "text": "It has operated, it has built, it has come an amazing way over that 11 years to be maybe probably the most excited topic among a lot of people and has been used and is now has obtained the status of having imputed value."}, {"time": 4468, "text": "At the same time, it is one of those assets that is an alternative money."}, {"time": 4475, "text": "I think we're entering an era where there's going to be a competition of monies."}, {"time": 4483, "text": "Because of the printing of fiat money and the depreciated value, there will be a competition of monies and Bitcoin is part of that competition."}, {"time": 4497, "text": "But there'll be many monies, not just crypto monies, but there'll be central bank crypto monies, but there'll be different kinds of monies."}, {"time": 4508, "text": "And even monies are things that you buy and sell."}, {"time": 4512, "text": "NFTs can become a type of money."}, {"time": 4516, "text": "You own it and it's an investment and you could say I'd rather own it than own Bitcoin."}, {"time": 4522, "text": "Has Ray Dalio bought any NFTs?"}, {"time": 4526, "text": "But only just because I definitely want to buy NFTs to just experience them."}, {"time": 4536, "text": "Like I think I should produce one and I should."}, {"time": 4540, "text": "I should have asked that."}, {"time": 4541, "text": "Have you minted an NFT?"}, {"time": 4543, "text": "You probably should just to know what it's like."}, {"time": 4546, "text": "This stuff is happening."}, {"time": 4548, "text": "This stuff is real and how it operates."}, {"time": 4551, "text": "But like all new real things, some are gonna go and some are gonna, it's like in the internet in the year 2000, pets.com could have been a great, but maybe pets.com doesn't make it and who knows."}, {"time": 4568, "text": "That's the beauty of the competitive system that it'll evolve and some things will be treasured and some things will be trashed."}, {"time": 4577, "text": "But when I look at it, I think we are in an environment of what is an alternative money?"}, {"time": 4583, "text": "A money has two purposes, a medium of exchange and a storehold of wealth."}, {"time": 4589, "text": "And we are looking for, and it's portable."}, {"time": 4593, "text": "And it's best if it's recognized in other countries."}, {"time": 4599, "text": "So gold is one of those."}, {"time": 4601, "text": "So I look at it as an alternative gold, but I look at a number of things as alternative gold."}, {"time": 4609, "text": "And I think that, and gold is still my favorite because of certain qualities."}, {"time": 4616, "text": "For example, you can't trace it."}, {"time": 4619, "text": "In Bitcoin, you can trace who owns it, where it's going and so on."}, {"time": 4624, "text": "Governments can't have that ability to trace it and so on."}, {"time": 4627, "text": "A gold piece of coin, it's not connected."}, {"time": 4630, "text": "I think not connected has benefits, particularly in a world where maybe connections can be more risky."}, {"time": 4637, "text": "And then also gold has been for many thousands of years universally recognized as a source of money."}, {"time": 4648, "text": "And central banks, it's the third largest source of money in central bank reserves."}, {"time": 4655, "text": "And I don't think Bitcoin is going to serve those types of purposes and so on."}, {"time": 4660, "text": "So for various reasons, I prefer gold to the other, but it's a little bit part of my mix."}, {"time": 4666, "text": "But then you look at it, it hit, I think 69,000 this year is the high Bitcoin hit."}, {"time": 4672, "text": "Do you think it's possible, you mentioned gold, do you think it's possible it reaches very high numbers, like one million that some people talk about?"}, {"time": 4682, "text": "I don't think that's possible because the way I look at it is there's a certain amount of it."}, {"time": 4691, "text": "A certain amount of it, and there's a certain amount of gold."}, {"time": 4698, "text": "I'll use gold as a benchmark."}, {"time": 4701, "text": "The amount of it is worth about $1 trillion."}, {"time": 4706, "text": "Total crypto is about 2.2 trillion."}, {"time": 4709, "text": "But let's say Bitcoin, it's $1 trillion."}, {"time": 4713, "text": "If you take the amount of money that is in gold that is not used for jewelry purposes and not used by central banks, and I assume Bitcoin won't be used for jewelry purposes or central bank purposes, that amount in gold is about $5 trillion."}, {"time": 4735, "text": "So right now, if you were to have a portfolio that has gold and crypto, gold and Bitcoin, it's worth about 20% of the value of gold."}, {"time": 4747, "text": "Do I think it's going to be worth more than gold in terms of that mix?"}, {"time": 4754, "text": "I don't think it'll be worth more than gold."}, {"time": 4756, "text": "But let's say it became worth as much as gold."}, {"time": 4761, "text": "I don't believe it will be."}, {"time": 4762, "text": "I think that 20% sounds kind of about right."}, {"time": 4765, "text": "I really don't know what the right answer is."}, {"time": 4769, "text": "And then there's the question of what is all of that pool of money that let's say gold and gold equivalents relative to everything else?"}, {"time": 4777, "text": "Does it go from, let's call it six, seven, eight trillion to 16 trillion?"}, {"time": 4784, "text": "Maybe it could double."}, {"time": 4786, "text": "It depends what it is in the world environment."}, {"time": 4788, "text": "But basically, if you use gold as a measure, it just makes no sense that it's going to be used that much more."}, {"time": 4800, "text": "Am I sure about that?"}, {"time": 4801, "text": "I'm not sure about anything."}, {"time": 4803, "text": "But logically, it seems to me that there's a limitation on its price in relationship to other things that are like it."}, {"time": 4813, "text": "Let me ask for your deep financial analysis on a very important issue."}, {"time": 4817, "text": "I just talked a couple days ago with Elon Musk."}, {"time": 4820, "text": "He wants to put a literal Dogecoin on the moon."}, {"time": 4823, "text": "What are your thoughts about Dogecoin?"}, {"time": 4827, "text": "And do you think it'll be the official currency?"}, {"time": 4830, "text": "How many be reserve currency on the moon and on Mars?"}, {"time": 4835, "text": "My reaction is that's cute."}, {"time": 4837, "text": "I remember Elon when he first got, he first got his money from PayPal."}, {"time": 4842, "text": "I think he said to me it was, he got $180 million, $90 million."}, {"time": 4848, "text": "He decided to say, why aren't we going to outer space?"}, {"time": 4852, "text": "And he wanted to take a spaceship that would be modified using Russian technology to put a plant and a watering can on the moon or on Mars, I think it was."}, {"time": 4874, "text": "And he said, first life on Mars, or first life on that as an inspiring notion."}, {"time": 4883, "text": "And so then there's always what's behind it."}, {"time": 4887, "text": "I have a lot of respect for Elon's ability to do other things behind it."}, {"time": 4894, "text": "And so I would take that as symbolic and I'd be asking him what's behind it, what's next."}, {"time": 4901, "text": "And I'm also just on the topic of Dogecoin and memecoin and there's some aspect of humor and lightheartedness that's really interesting about the way we communicate, what ideas become viral, how to captivate people with ideas."}, {"time": 4917, "text": "There's something about taking things too seriously that somehow slows it all down and it's interesting."}, {"time": 4923, "text": "That's part of human nature somehow."}, {"time": 4925, "text": "So like humor is part of this whole thing."}, {"time": 4929, "text": "You've talked about the importance of writing ideas down and you have a fascinating."}, {"time": 4935, "text": "Principles in particular."}, {"time": 4937, "text": "Principles."}, {"time": 4938, "text": "And you have this really nice thing in your book where you actually, I mean there's such a brilliant way."}, {"time": 4946, "text": "You have such a brilliant way of highlighting which parts are extra important and you make them bold."}, {"time": 4953, "text": "That's a brilliant idea."}, {"time": 4954, "text": "But let me just ask the high level question of what's a good system for taking notes?"}, {"time": 4962, "text": "Well, I find that almost everything happens over and over again."}, {"time": 4966, "text": "And we're in the blizzard of these things happening."}, {"time": 4972, "text": "And what I found is that if I'm making a decision that after I make the decision usually or write at the time, if I pause and reflect and I write my principle down, in other words, principle is sort of a recipe, what would I use to, how would I make that decision?"}, {"time": 4996, "text": "And what are the criteria around it?"}, {"time": 4998, "text": "I find that I make it much more clear, it becomes clearer and it applies to the next thing that comes along, it'll be that way."}, {"time": 5008, "text": "Because everything happens over and over and over again and I think people make the mistake of looking at just the one like it's the first one."}, {"time": 5017, "text": "I don't know, they have the first problem of this sort or the first child or whatever it is."}, {"time": 5022, "text": "And this has been happening plenty of times."}, {"time": 5024, "text": "And so if you have the principles, I found that that helped me think more clearly about it and it helped me communicate better, like why."}, {"time": 5034, "text": "And so over the years, over the last 30 years or so, that's what I've done."}, {"time": 5040, "text": "I did it originally to communicate very well with the people I work with."}, {"time": 5044, "text": "I set up my company and it was very important to have good communication."}, {"time": 5049, "text": "And then we could debate the principles and so that's the process."}, {"time": 5054, "text": "I urge people to do that."}, {"time": 5056, "text": "There are many excellent decision makers and I just wish that they wrote down their principles."}, {"time": 5063, "text": "When this set, so for example, we talk about Henry Kissinger and his new book is gonna come out with a book on leadership."}, {"time": 5073, "text": "And don't just describe the leaders, describe then what about them were the essential elements to make a good leader under what circumstances."}, {"time": 5084, "text": "And so if we think about that, then also then you begin to think in a principled way."}, {"time": 5091, "text": "And then when you start to think in a principled way, life becomes, it's so much easier to make decisions and it's so much less confusing because it's like coming up on a species and you say, okay, well, what species is it?"}, {"time": 5108, "text": "Not just another, it's a thing."}, {"time": 5110, "text": "No, what species is it and how do I deal with that species effectively?"}, {"time": 5115, "text": "And so that's what that is."}, {"time": 5117, "text": "And so I encourage people to write it down."}, {"time": 5120, "text": "I wish anybody who's successful wrote down their principles or their recipes for making those types of decisions."}, {"time": 5127, "text": "So the events of interest here happens over and over and over in similar ways."}, {"time": 5133, "text": "As you're looking for the patterns and you're defining the process, that's right to respond to those patterns and you call that the principles and that allows you to deal with the future effectively."}, {"time": 5146, "text": "So like that codifies the lessons from the past to be able to deal with the future."}, {"time": 5152, "text": "What advice do you have for young folks today?"}, {"time": 5155, "text": "In high school, in college, thinking about how to live, have a career they can be proud of or maybe have a life they can be proud of?"}, {"time": 5165, "text": "Know yourself, follow your passion, make your work and passion the same thing while considering the money part because money will get you freedom and choice and be able to bank that."}, {"time": 5179, "text": "But if you know yourself, feel the pull and pursue that passion."}, {"time": 5189, "text": "And along those lines, by the way, I found that using personality profile tests has been very helpful."}, {"time": 5198, "text": "I've used those for about 25 years for people to help to understand themselves and understand each other."}, {"time": 5203, "text": "So I created a free one that is called Principles You."}, {"time": 5209, "text": "It's online."}, {"time": 5211, "text": "It's had remarkable, loving people who've taken it, learn about themselves, but also you can put in somebody else and it'll tell you about your relationship with them."}]}, {"title": "Steve Keen: Marxism, Capitalism, and Economics | Lex Fridman Podcast #303", "id": "1XGiTDWfdpM", "quotes": [{"time": 333, "text": "If you're talking about autonomous, it'll go from state t to t plus one, t plus two, and so on."}, {"time": 339, "text": "But not when you're talking at the aggregate level."}, {"time": 341, "text": "There you use differential equations to measure it all."}, {"time": 344, "text": "Economists have been using difference equations."}, {"time": 346, "text": "So there's like a book, I think it's by Sargent and one other, called Advanced Methods in Economics Using Python, two volumes set."}, {"time": 354, "text": "It's about close to 2,000 pages, and four of those pages are on differential equations."}, {"time": 360, "text": "The rest is all difference equations."}, {"time": 363, "text": "So they're using entirely the wrong mathematics to start with."}, {"time": 365, "text": "For people listening, what is difference equations versus differential equations?"}, {"time": 370, "text": "Difference equation is like you can do in a spreadsheet."}, {"time": 372, "text": "You'll have, this is the value for 1990, this is the value for 1991, 92, 93, 94."}, {"time": 378, "text": "So you have discrete jumps in time, whereas the differential equation says there's a process moving through time."}, {"time": 385, "text": "And you will have a rate of change of a variable is a function of the state of itself and other variables and rates of change of those variables."}, {"time": 395, "text": "And that is what you use when you're doing an aggregate model."}, {"time": 398, "text": "So if you're modeling water, for example, or fluid dynamics, you have a set of differential equations describing the entire body of fluid moving through time."}, {"time": 407, "text": "You don't try to model the discrete motion of each molecule of H2O."}, {"time": 412, "text": "So at the aggregate level, you use differential equations for processes that occur through time."}, {"time": 417, "text": "And that's economics."}, {"time": 418, "text": "It occurs through time."}, {"time": 419, "text": "You should be using that particular technology."}, {"time": 422, "text": "But some economists do learn differential equations, but they don't learn stability analysis."}, {"time": 428, "text": "So they simply assume equilibrium is stable, and they work in equilibrium terms all the time."}, {"time": 433, "text": "And the technical level, it's an incredibly complicated way of modeling the world using entirely the wrong tools."}, {"time": 443, "text": "OK, we'll talk about that because it's unclear what the right tools are."}, {"time": 449, "text": "Maybe it's more clear to you, but I've got to make it clear to an audience."}, {"time": 453, "text": "Well, so this is a very complicated world."}, {"time": 456, "text": "It's a complex world."}, {"time": 457, "text": "You talk about there are some of the most complex systems on Earth are the human mind, the economy and the biosphere."}, {"time": 469, "text": "So we'll go, you know, we'll go to that place."}, {"time": 473, "text": "I'm fascinated by complex systems."}, {"time": 476, "text": "I'm humbled by them, even at their simplest level of like cellular automata."}, {"time": 483, "text": "I'm not sure what the right tools are to understand that, especially when part of the complex system is like a hierarchy of other complex systems."}, {"time": 493, "text": "So you said the economy is a fascinating complex system, but it's made up of human minds."}, {"time": 500, "text": "And those are interesting."}, {"time": 501, "text": "Those are interesting, perhaps impossible to model, but we can try and we can try to figure out how to approximate them."}, {"time": 508, "text": "And maybe that's the challenge of economics."}, {"time": 510, "text": "OK, we'll keep returning to the basics."}, {"time": 513, "text": "Let us try to learn something from history."}, {"time": 516, "text": "I also see as part of economics is us trying to figure out stuff."}, {"time": 520, "text": "And there's a few smart folks that write books throughout human history."}, {"time": 526, "text": "And sometimes they name schools of economics after them."}, {"time": 530, "text": "So let us take a stroll through history."}, {"time": 534, "text": "OK. Can you describe at a high level what are the different schools of economics, perhaps ones that are interesting to you, perhaps ones that the difference between which reveals something useful or insightful for our conversation."}, {"time": 554, "text": "So you know, you could neoclassical, post Keynesian, Austrian, like the biophysical economics and so on, other heterodox economic schools that you find interesting."}, {"time": 566, "text": "OK, I actually find interesting a school which went extinct about 250 years ago."}, {"time": 572, "text": "That's where I'd like to start from."}, {"time": 573, "text": "And they're called the Physiocrats."}, {"time": 575, "text": "And the name itself implies where the knowledge came from, because if you go back far enough in history, we didn't do autopsies."}, {"time": 583, "text": "But when you started doing autopsies, they found wires, they found tubes, etc., etc."}, {"time": 589, "text": "And they started seeing the body as a circulation system, and they applied the same sort of logic to the economy."}, {"time": 595, "text": "And they came out of an agricultural economy, which was France, and they saw that the wealth came effectively from the sun."}, {"time": 603, "text": "So their soil wealth comes from, like I said, the soil, but what they really mean is sun."}, {"time": 606, "text": "The soil absorbs the energy of the sun."}, {"time": 609, "text": "One seed plants, a thousand flea seeds come back."}, {"time": 612, "text": "There is no surplus."}, {"time": 613, "text": "We are simply mining what we can find out of the natural economy."}, {"time": 617, "text": "That's where we should have stayed and developed from that forward."}, {"time": 620, "text": "We then went through the classical school of economics, which comes out of Adam Smith."}, {"time": 624, "text": "And Smith, coming from Scotland, looked at what the Physiocrats said, and what the Physiocrats argued was that agriculture is the source of all wealth, and the manufacturing sector is sterile."}, {"time": 637, "text": "That's literally the term they used to describe the manufacturing sector."}, {"time": 639, "text": "What does sterile mean?"}, {"time": 640, "text": "Sterile means you don't extract value."}, {"time": 643, "text": "You simply change the shape of value."}, {"time": 646, "text": "So the value comes from the soil."}, {"time": 649, "text": "Yeah, it comes from the soil."}, {"time": 651, "text": "That's the free gift of nature."}, {"time": 652, "text": "That's literally the phrase they used."}, {"time": 654, "text": "And we then distribute the free gift of nature around, and we need carriages, which was the manufacturing term they used at the time, as well as wheat."}, {"time": 664, "text": "So to make the carriages, we take what's been taken from the soil, and we convert it to a different form."}, {"time": 670, "text": "But there is no value added in manufacturing."}, {"time": 673, "text": "So Smith looked at that and said, well, I'm from Scotland."}, {"time": 676, "text": "And we've got these industries, and we make stuff, and it's machinery."}, {"time": 681, "text": "And he said, no, it's not land that gives us the source of value, it's labor."}, {"time": 686, "text": "Now, that led to the classical school of thought, and that said that all value comes from labor, that value is objective, so it's the amount of effort you put in, that the price two things will exchange for reflects the relative effort that's involved in the manufacturing."}, {"time": 702, "text": "So this computer takes two hours to make, and this bottle takes two minutes to make, then this is worth 60 times as much as that."}, {"time": 710, "text": "They didn't talk about marginal cost."}, {"time": 713, "text": "It was absolute cost, effectively."}, {"time": 715, "text": "They didn't talk about utility as a subjective thing, they ridiculed subjective utility theory."}, {"time": 721, "text": "That led to Marx, and Marx is probably the most brilliant mind in the history of economics."}, {"time": 727, "text": "The only other competitor I'd see is Schumpeter, possibly Keynes, but in my terms of ranking of intellects, it would be Marx, Schumpeter, Keynes, in terms of the outstanding capacities to think."}, {"time": 738, "text": "But Marx then turned that classical school, which was pro capitalism and anti feudal, into a critique of capitalism, which led to the neoclassical school coming along as a defense of capitalism."}, {"time": 751, "text": "But they defended it using the ideas of the subjective theory of value, so that value does not reflect effort, it's the satisfaction individuals get from different objects that determines their value, marginal utility."}, {"time": 765, "text": "It's the marginal cost that determines how much they sell for."}, {"time": 770, "text": "Capitalism equilibrates marginal cost and marginal utility, and the concepts of equilibrium and marginal this and marginal that became the neoclassical school, and that's still the dominant school now 150 years later."}, {"time": 784, "text": "That's the one that everybody learns."}, {"time": 785, "text": "When you first learn economics, if you don't have the critical background that I managed to acquire, that's what you think is economics, the marginal utility, equilibrium oriented analysis of mainstream economics, and for example, they ignore money."}, {"time": 800, "text": "People think economists, you must be an expert on money because you're an economist."}, {"time": 803, "text": "Well, in fact, economists learn literally in the first few weeks at university that money is irrelevant."}, {"time": 809, "text": "They say money illusion."}, {"time": 811, "text": "They represent people's tastes using what they call indifference curves, and they're like isoquants on a weather map."}, {"time": 819, "text": "If you look at an isoquant, it shows you all the points of the same pressure."}, {"time": 823, "text": "So you can be here or you can be in Denver and the air pressure can be the same if you're in the same weather unit, so you just draw a cell that links together."}, {"time": 830, "text": "Well, they do the same thing with utility and say lots of bananas and very few coconuts can give you the same utility as lots of coconuts and very few bananas, and you draw basically like a hyperbola running down linking the two, and they'll say, well, that's your utility."}, {"time": 846, "text": "That describes your tastes, and then we have your income, and given your income, you can buy that many bananas completely or that many coconuts or a straight line combination of the two, and then if we double the nominal price of coconuts and double the nominal price of bananas and double your income, what happens, and the correct answer is, oh, nothing, sir."}, {"time": 867, "text": "You stay at the same point of tangency between what your budget is and which particular utility curve gives you the maximum satisfaction."}, {"time": 876, "text": "So that gets ingrained into them, and they think anybody who worries about money suffers from money illusion."}, {"time": 882, "text": "You are therefore ignorant of the deep insights of economics if you think money actually matters."}, {"time": 888, "text": "So you have an entire theory of economics which presumes we exchange through barter."}, {"time": 893, "text": "Like I'll swap you that Microsoft Surface for, actually, I'll take two of those for one of these."}, {"time": 899, "text": "We do this bartering type arrangement."}, {"time": 902, "text": "In fact, that only works if money plays no creative role in the economy, and that's where you find, reading Schumpeter, the insight that's the school of thought that I come from that says money is essential."}, {"time": 915, "text": "Money actually adds to demand, and we'll talk about that later on."}, {"time": 919, "text": "So that's the neoclassical school that ends up being subjective theory of value, nonmonetary, as though everything happens in barter, and focusing on equilibrium, as though everything happens in equilibrium, or if you get disturbed from equilibrium, you return back to it again."}, {"time": 938, "text": "And that mindset describes capitalism."}, {"time": 942, "text": "Its most interesting feature is that it reaches equilibrium."}, {"time": 946, "text": "Now what planet are we on to believe that?"}, {"time": 948, "text": "Because if you look at the real world, the real exciting world of capitalism in which we live, change is by far the most obvious characteristic of it."}, {"time": 959, "text": "There's no equilibrium."}, {"time": 961, "text": "It's unstable."}, {"time": 967, "text": "You work out what the Jacobian is."}, {"time": 970, "text": "You work out your Lyapunov exponents in a complex system."}, {"time": 973, "text": "You're used to the idea that equilibrium is unstable."}, {"time": 977, "text": "But economists get schooled into believing that everything happens in equilibrium, and they don't learn stability analysis."}, {"time": 983, "text": "So all that stuff is missing."}, {"time": 985, "text": "So onto the schools of thought, treating the economy as an equilibrium system, which was what the neoclassical school did, is what Keynes disturbed."}, {"time": 996, "text": "And he really disturbed it by talking about, fundamentally, that uncertainty determines our decisions about the future."}, {"time": 1003, "text": "So when we consume, you know if you like Pfizer or whatever particular drink we want to have, you know the current situation."}, {"time": 1011, "text": "But to invest, you must be making guesses about the future."}, {"time": 1015, "text": "But you don't know the future."}, {"time": 1017, "text": "You extrapolate what you currently know."}, {"time": 1020, "text": "And as you said, this is a terrible basis on which to plan for the future."}, {"time": 1025, "text": "But this is the only thing you can do where there is no possibility of solid calculation."}, {"time": 1030, "text": "So investment is therefore subject to uncertainty, and therefore you will get volatility out of investment."}, {"time": 1037, "text": "You will get fads, of course, booms and slumps coming out of that, because people extrapolate for the current conditions."}, {"time": 1044, "text": "And that's the normal state of a capitalist economy."}, {"time": 1047, "text": "And Schumpeter argued that that's what gives it its creativity as well, the fact that you can perceive a potential demand, but first of all, you don't know whether that demand is going to work."}, {"time": 1058, "text": "Secondly, you don't know who your competitor is going to be, whether somebody is going to be ahead of you or behind."}, {"time": 1062, "text": "If there's a fad, you'll overinvest."}, {"time": 1066, "text": "All this stuff is the real nature of capitalism, and that's what we're trying to capture, the dynamic nonequilibrium monetary violence and creativity of capitalism."}, {"time": 1077, "text": "That's what we should be analyzing."}, {"time": 1078, "text": "And the post Keynesian school has gone in that orientation."}, {"time": 1083, "text": "They've been, in my opinion, inhibited by learning their mathematics from neoclassical economists, so they don't have enough of the technology of complex systems."}, {"time": 1092, "text": "There's only a really tiny handful of people working in complex systems analysis in post Keynesian economics, but that is, to me, the most interesting area."}, {"time": 1101, "text": "So their tools may be lacking, but they fundamentally accept the instability of things."}, {"time": 1109, "text": "So let me try to summarize what you said, and then you say how stupid I am."}, {"time": 1113, "text": "So then there was the physiocrats that thought value came from the land."}, {"time": 1120, "text": "Then there's Adam Smith, who said, nah, value comes from human labor."}, {"time": 1130, "text": "That was the classical school."}, {"time": 1132, "text": "And then neoclassical is value comes from bananas and coconuts, human preferences, like human happiness, how happy a banana makes you."}, {"time": 1146, "text": "And then the Keynesian and the post Keynesian were like, yeah, well, you can't, you can never, the moment you try to put value to a banana and a coconut, you're already working in the past."}, {"time": 1161, "text": "It's always going to be chaos and stability."}, {"time": 1164, "text": "And then you just, you're fishing in uncertain waters, and that's why we have to embrace that and come up with tools that model that well."}, {"time": 1172, "text": "And also Joseph Schumpeter, what school would you put him under?"}, {"time": 1176, "text": "Is he a Keynesian or is he Austrian economics?"}, {"time": 1181, "text": "He's an Austrian."}, {"time": 1182, "text": "The Austrians deny."}, {"time": 1184, "text": "That's the intriguing."}, {"time": 1185, "text": "He's from Austria, but he's not an Austrian economist."}, {"time": 1191, "text": "There are elements of the Austrian school of thought, which are worthwhile."}, {"time": 1194, "text": "What is Austrian economics in this beautiful whirlwind picture that you painted?"}, {"time": 1200, "text": "Austrian economics grew out of the rebellion against the classical school."}, {"time": 1204, "text": "So you had three intellects who mainly led the growth of the neoclassical school back in the 1870s."}, {"time": 1210, "text": "It was William Jevons from England, Menger, who's from Austria, and Vollras from France."}, {"time": 1217, "text": "And Vollras tried to work out a set of equations to describe a multiproduct economy where there's numerous producers and numerous consumers."}, {"time": 1229, "text": "Everybody's both a producer and a consumer, and you try to work out a vector of prices that will give you equilibrium in all markets instantaneously."}, {"time": 1237, "text": "And that's his equilibrium orientation."}, {"time": 1240, "text": "Jevons is also one about equilibrium, but he worked more at the aggregate level."}, {"time": 1244, "text": "So there's a supply curve and a demand curve, and that's what Marshall ultimately codified."}, {"time": 1248, "text": "Menger was pretty much saying that, well, yes, there might be an equilibrium, but you're going to get disturbed from it all the time."}, {"time": 1254, "text": "You'll be above or below the equilibrium."}, {"time": 1256, "text": "And what came out of the Austrian school was an acceptance of that sort of vision that a market should reach equilibrium, but then said, well, you'll get disturbed away from the equilibrium."}, {"time": 1265, "text": "And that's what gives you the vitality of capitalism, because an entrepreneur will see an arbitrage advantage and try to close that gap, and that will give you innovation over time."}, {"time": 1276, "text": "And Schumpeter went beyond that and saw the role of money and said that an entrepreneur is somebody with a great idea and no money."}, {"time": 1285, "text": "So to become a capitalist, you've got to get money."}, {"time": 1288, "text": "And therefore, you've got to approach the finance sector to get the money, and the finance sector creates money and also creates a debt for the entrepreneur."}, {"time": 1297, "text": "And so you get this financial engine turning up as well, and you will get movements away from equilibrium out of that."}, {"time": 1304, "text": "You won't necessarily head back towards the equilibrium."}, {"time": 1307, "text": "So Schumpeter has a rich vision of capitalism in which money plays an essential role, in which you will be disturbed from equilibrium all the time."}, {"time": 1319, "text": "And that is really, I think, a much closer vision of actual capitalism than anything by even the leading Austrians, Hayek, et cetera, et cetera, and certainly Rombardo, I find totally like reading a cardboard cutout version of The Wealth of Nations."}, {"time": 1340, "text": "I find his work trivial."}, {"time": 1343, "text": "But Schumpeter was rich, but with the same foundations as the Austrians."}, {"time": 1348, "text": "But because he talked about the importance of money that took him away from the Austrian vision, which is very much based on a hard money idea of capitalism, Schumpeter said you needed the capacity of the financial sector to create money to empower entrepreneurs."}, {"time": 1362, "text": "And that's a very important vision."}, {"time": 1364, "text": "So Schumpeter's argument is the deviation from equilibrium, that's where all the fun happens."}, {"time": 1369, "text": "That's where all the magic happens."}, {"time": 1370, "text": "That's the magic of capitalism."}, {"time": 1371, "text": "And like the Austrians, because they focus on the deviation from equilibrium, they're better than their classicals, but they still have this belief in the, you'll reach equilibrium ultimately or you'll head back towards it, whereas they don't have an explanation of capitalism that gives you cycles apart from having the wrong rate of interest."}, {"time": 1391, "text": "So there's no role for an accumulation of debt over time."}, {"time": 1393, "text": "So what Schumpeter gave us was a vision of the creativity of capitalism being driven by entrepreneurs who are funded by money creation by the finance sector."}, {"time": 1405, "text": "And that's fundamentally the world in which we live."}, {"time": 1409, "text": "So there's also the kids these days are all into modern monetary theory, what's that about?"}, {"time": 1418, "text": "Modern monetary theory is accounting."}, {"time": 1419, "text": "I want to summarize it bluntly."}, {"time": 1422, "text": "It's simply saying let's do the accounting because what money is, is a creature of double entry bookkeeping."}, {"time": 1428, "text": "What's double entry bookkeeping?"}, {"time": 1430, "text": "This was invented back in the 1500s in Italy."}, {"time": 1433, "text": "I've forgotten the particular merchant who did it based on some Arabic ideas as well."}, {"time": 1437, "text": "But the thing is, if you want to keep track of your financial flows, then you divide all the financial claims on you."}, {"time": 1448, "text": "You divide into claims you have on somebody else, which are your assets, claims somebody else has on you, which are your liabilities, and the gap between the two is your equity."}, {"time": 1457, "text": "So you record every transaction twice on one row."}, {"time": 1461, "text": "So for example, if you and I do a financial transfer, you have a bank account, I have a bank account, your bank account will go down, mine goes up."}, {"time": 1471, "text": "And that's the sum of the operation is zero."}, {"time": 1475, "text": "But on the other hand, if I go to a bank and borrow money, then my account goes up, they put money in my deposit account, the bank's assets go up."}, {"time": 1482, "text": "And there's still the same sum applies, assets minus liabilities minus equity equals zero."}, {"time": 1487, "text": "Now that's simply saying money is an accounting, a creature of accounting."}, {"time": 1491, "text": "It's not a creature of a commodity."}, {"time": 1494, "text": "So if you think about how Austrians think about money, and how gold bugs think about money and Bitcoin enthusiasts, if there are any left, think about money, what they see is money is an object."}, {"time": 1505, "text": "And you and I can both have more gold, if we're both willing to go to this mine somewhere and dig a few holes and get a few specks of gold out."}, {"time": 1514, "text": "So there's no competition or no interaction between you and me if money is gold."}, {"time": 1520, "text": "And they think money should be an object, a commodity."}, {"time": 1523, "text": "But money fundamentally is not a commodity."}, {"time": 1525, "text": "It's a claim on somebody else."}, {"time": 1528, "text": "That's money's essence."}, {"time": 1529, "text": "So when you do it, you must use double entry bookkeeping to do it."}, {"time": 1532, "text": "And then when you do, you find all the answers that come out of thinking of money as a commodity are wrong."}, {"time": 1537, "text": "So for example, and I've got Elon on this one."}, {"time": 1539, "text": "So I want to get this with Elon because I saw him making a comment about this a few weeks ago on Twitter."}, {"time": 1544, "text": "He said that it's wrong for the government, effectively it seems wrong for the government to always be in deficit."}, {"time": 1549, "text": "Now, when you look at it and say, well, how is money created?"}, {"time": 1554, "text": "How does money come about when it's not a commodity like gold, which you dig up out of the ground, when it's actually social relations between people that create money?"}, {"time": 1563, "text": "Well, money is the fundamentally the liabilities of the banking sector."}, {"time": 1571, "text": "If we make a transfer between us, your deposit account goes down, my deposit account goes up."}, {"time": 1578, "text": "Deposit exchange is on the liability side of the banking sector."}, {"time": 1583, "text": "But if we have a transaction with a bank, then if the bank lends us money, as its loans go up, its deposits go up, again, that same balance."}, {"time": 1592, "text": "So you've got to look and say, money therefore is fundamentally the liabilities of the banking sector."}, {"time": 1597, "text": "So how do you create additional liabilities?"}, {"time": 1600, "text": "You must have an operation which occurs both on the liability side and the asset side of the banking sector."}, {"time": 1606, "text": "So if you and I make a new transaction, no money is created."}, {"time": 1611, "text": "Existing money is redistributed."}, {"time": 1613, "text": "But if you go to a bank and take out a bank loan, then money is created by the bank loan."}, {"time": 1618, "text": "So the liabilities of the banking sector rise, the assets rise, they're balanced, but more liabilities of the banking sector means more money."}, {"time": 1626, "text": "So that's how private banks create money."}, {"time": 1628, "text": "And that's what I first started working on when I became an academic about 35 years ago, the actual dynamics of private money creation."}, {"time": 1637, "text": "But the government has the same sort of story."}, {"time": 1639, "text": "If the government runs a deficit, it spends more money on the individuals in the economy than it taxes them, which means their bank accounts increase."}, {"time": 1651, "text": "So a government deficit creates money for the private sector."}, {"time": 1656, "text": "So that's where money creation occurs from the government."}, {"time": 1659, "text": "So it puts more money into people's bank accounts by spending, by welfare payments than it takes out by taxation."}, {"time": 1669, "text": "So that's creating new money."}, {"time": 1670, "text": "And then on the other side on the bank, the money turns up in the reserve accounts of the banks, which are basically the private bank's bank accounts at the central bank."}, {"time": 1680, "text": "So rather than the asset of private money creation being loans, the asset of government money creation is reserves."}, {"time": 1695, "text": "So you mentioned a bunch of stuff like private money creation with the liabilities in the banks and then how the government is doing, the reserves, blah, blah, blah."}, {"time": 1704, "text": "At the end of the day, there's a bunch of printers that are printing money."}, {"time": 1709, "text": "And then you also said something interesting, which is social relations between humans is what creates money."}, {"time": 1715, "text": "I think my mind was blown several times over the past minute."}, {"time": 1720, "text": "So it's difficult for me to reconstruct the pieces of my mind back together."}, {"time": 1724, "text": "But basic question, is money creation a good thing or a bad thing?"}, {"time": 1730, "text": "Money creation is a good thing because money creation is what allows commerce to happen."}, {"time": 1736, "text": "Isn't there a conservation of... No, there isn't."}, {"time": 1739, "text": "I had to have arguments with physicists over this and it took me a long time to answer it."}, {"time": 1744, "text": "So the sum total of all money is zero."}, {"time": 1747, "text": "It's the sum total of all assets and liabilities is zero."}, {"time": 1750, "text": "So if you imagine your assets minus your liabilities is your equity and your asset is somebody else's liability and your liability is somebody else's asset."}, {"time": 1761, "text": "When we're talking about financial assets, and this is another mind blowing thing that I've just recently solved myself."}, {"time": 1767, "text": "So the sum total of all financial assets and liabilities is zero."}, {"time": 1773, "text": "I'm sorry to interrupt you rudely."}, {"time": 1776, "text": "What are assets?"}, {"time": 1777, "text": "What are liabilities?"}, {"time": 1778, "text": "Assets are your claims on somebody else."}, {"time": 1782, "text": "Specific."}, {"time": 1783, "text": "Give me an example of an asset."}, {"time": 1785, "text": "Do you have a mortgage for this house?"}, {"time": 1787, "text": "I'm renting."}, {"time": 1788, "text": "You're renting."}, {"time": 1790, "text": "Well, if you had a mortgage, that'd be your liability."}, {"time": 1791, "text": "That would be my liability."}, {"time": 1794, "text": "The mortgage with the bank's asset."}, {"time": 1797, "text": "If you add the two together, you get zero."}, {"time": 1799, "text": "So that's zero."}, {"time": 1800, "text": "That's zero."}, {"time": 1801, "text": "So money is the liabilities side of the banking sector."}, {"time": 1806, "text": "Assets are the..."}, {"time": 1808, "text": "The assets on the other side can be either created by the banking sector, which is where you get bank loans, or created by the government, where you get reserves."}, {"time": 1816, "text": "But money is the liabilities."}, {"time": 1818, "text": "Money is..."}, {"time": 1819, "text": "If you think about protons and anti protons, in that sense, money is like the anti proton."}, {"time": 1823, "text": "It's the negative, the liability."}, {"time": 1825, "text": "But wait, wait, wait."}, {"time": 1827, "text": "The liability is the negative."}, {"time": 1831, "text": "How's that money?"}, {"time": 1832, "text": "I thought money is the positive."}, {"time": 1833, "text": "What is the liability for the banking sector is an asset for you and me."}, {"time": 1837, "text": "And assets includes money?"}, {"time": 1842, "text": "If you have a bank account, you'd have a bank account, and you'd have some cash."}, {"time": 1847, "text": "Those are your assets."}, {"time": 1848, "text": "But the bank account is a liability of the banking sector, and the cash is a liability of the Federal Reserve."}, {"time": 1856, "text": "So what's money?"}, {"time": 1857, "text": "Well, money is the promise of a third party that we both accept to close our transaction."}, {"time": 1864, "text": "And this is... And that's a bank with a liability?"}, {"time": 1866, "text": "That's a bank."}, {"time": 1868, "text": "One of the most important works I've ever read is a work by a wonderful, now unfortunately deceased, Italian economist called Augusto Graziani."}, {"time": 1878, "text": "And he's the most wonderful personality."}, {"time": 1880, "text": "Augusto, I met him on a few occasions, is one of the few human beings who can speak in perfectly formed paragraphs, okay, superbly eloquent."}, {"time": 1891, "text": "And what he did was write a paper called The Monetary Theory of Production."}, {"time": 1896, "text": "You can find it, download it on the web, it's pretty much open source now."}, {"time": 1901, "text": "And what he said is, what distinguishes a monetary economy from a barter economy?"}, {"time": 1905, "text": "So he said, in a barter economy, what we do is, you know, I'll give you two of these for one of those."}, {"time": 1912, "text": "Okay, barter."}, {"time": 1913, "text": "So we've got a relative price, there are two of us involved, and there are two commodities."}, {"time": 1917, "text": "So with money, money is a triangular transaction, okay?"}, {"time": 1922, "text": "There is one commodity, I want to buy that can of drink off you, two people, and the price that's worked out ends up being in a transfer from the promises to pay the bank that the buyer has to the promises to pay the bank that the seller has."}, {"time": 1939, "text": "So if I, so what you have is a monetary transaction in a capitalist economy involves three agents, the buyer, the seller, and the bank."}, {"time": 1948, "text": "So the bank always has to be part of it."}, {"time": 1949, "text": "Well, the bank has to be part of it."}, {"time": 1952, "text": "When I hand you the money, you accept that as you've now got, rather than it's the bank promising to pay me something, it's now the bank promising to pay you something."}, {"time": 1961, "text": "And we exchange the promises of banks, and that's fundamentally money."}, {"time": 1966, "text": "So money is fundamentally a threesome, and everybody gets fucked."}, {"time": 1971, "text": "Is that a good way to put it?"}, {"time": 1974, "text": "It leaves it, it leaves it for the guy to be like, oh no, I can use French in this conversation, that's good."}, {"time": 1978, "text": "That's not French, that's a different language, I'll explain it to you one day."}, {"time": 1983, "text": "You Australians will never understand."}, {"time": 1985, "text": "Okay, if I can return to, we'll jump around if it's okay."}, {"time": 1989, "text": "Oh, that's fine."}, {"time": 1990, "text": "So you mentioned Karl Marx as one of the great intellects, economic thinkers ever."}, {"time": 1998, "text": "He might be number one."}, {"time": 2001, "text": "You study him quite a bit, you disagree with him quite a bit, but you still think he's a powerful thinker."}, {"time": 2008, "text": "A powerful mind."}, {"time": 2010, "text": "So first of all, let's just explore the human."}, {"time": 2016, "text": "Why do you say so?"}, {"time": 2018, "text": "What's interesting in that mind?"}, {"time": 2020, "text": "In the way he saw the world, what are the insights that you find brilliant?"}, {"time": 2025, "text": "Marx once described his major work as, towards a critical examination of everything existing."}, {"time": 2034, "text": "So he's a modest bastard."}, {"time": 2036, "text": "So he wanted to understand and criticize everything."}, {"time": 2040, "text": "And even, he wasn't trained directly by Hegel, but his teachers were Hegelian philosophers."}, {"time": 2048, "text": "And what Hegel developed was a concept called dialectics."}, {"time": 2052, "text": "And dialectics is the philosophy of change."}, {"time": 2055, "text": "And when most people hear the word dialectics, they come up with this unpronounceable trio of words called thesis, antithesis, synthesis."}, {"time": 2065, "text": "I can barely get the words out myself."}, {"time": 2068, "text": "And that actually is not Hegel at all."}, {"time": 2069, "text": "That's another German philosopher."}, {"time": 2070, "text": "Kant?"}, {"time": 2071, "text": "Fichte."}, {"time": 2072, "text": "Oh, I thought it was Kant."}, {"time": 2073, "text": "No, Fichte."}, {"time": 2075, "text": "I mix them up."}, {"time": 2076, "text": "All Germans look the same to me."}, {"time": 2079, "text": "So, but if you look, there's a beautiful book called Marx and Contradiction."}, {"time": 2082, "text": "You want to find a great explanation for Marx's philosophy."}, {"time": 2085, "text": "I've forgotten the author."}, {"time": 2086, "text": "I think it's Wild, W I L D E, Marx and Contradiction."}, {"time": 2090, "text": "And he points out the actual origins of Marx's philosophy, but I didn't know that when I first read Marx."}, {"time": 2096, "text": "So I became exposed to Marx when I was a student at Sydney University."}, {"time": 2101, "text": "And we'd had a strike at the university over the teaching of philosophy."}, {"time": 2106, "text": "And what happened was the philosophy department had a lot of radical philosophers in it and a conservative chief philosopher."}, {"time": 2114, "text": "And the radicals wanted to have a course on what they called philosophical aspects of feminist thought."}, {"time": 2122, "text": "And the staff voted in favor of it."}, {"time": 2124, "text": "This is back in the days when university departments were democratic."}, {"time": 2127, "text": "The professor opposed it."}, {"time": 2129, "text": "He got it blocked at a high level."}, {"time": 2130, "text": "The staff lipfrogged over that, and then finally the vice chancellor blocked it."}, {"time": 2134, "text": "So that led to a strike over the teaching of philosophy at Sydney University, which at one stage, over half the students were on strike."}, {"time": 2145, "text": "Economics began out of that."}, {"time": 2146, "text": "Over teaching of a philosophy of feminism."}, {"time": 2149, "text": "God, it's good to be a student."}, {"time": 2150, "text": "That's such a different life to what we're living now."}, {"time": 2153, "text": "That's the academic milieu in which I developed all my ideas."}, {"time": 2158, "text": "And I had become a critic."}, {"time": 2159, "text": "I've gone from being a believer of mainstream economics when I was a first year student to disbelieving it halfway through first year."}, {"time": 2167, "text": "And I then spent a long time trying to change it, getting nowhere."}, {"time": 2171, "text": "And then this philosophy strike happened and we took it on in economics and we formed what's called the political economy movement and had a successful strike."}, {"time": 2179, "text": "We actually managed to pressure the university into establishing a department of political economy at Sydney University, as well as a department of economics."}, {"time": 2188, "text": "What was the foundational ideas?"}, {"time": 2190, "text": "Were you resistant to the whole censorship of why can't you have a philosophy of anything kind of course?"}, {"time": 2198, "text": "Well, it was much more libertarian in the genuine sense of the word, period of time, at the end of the 60s, beginning of the 70s than the word libertarian has been corrupted since then."}, {"time": 2210, "text": "But it really was about free thought."}, {"time": 2212, "text": "And you went to university to learn."}, {"time": 2214, "text": "It was about education."}, {"time": 2215, "text": "I remember having a fight with my father once where dad was angry about the marks I was getting for some of my courses."}, {"time": 2221, "text": "And he said, if you don't get a decent result, you won't get a decent job."}, {"time": 2224, "text": "And I said, I'm not here to get a job."}, {"time": 2225, "text": "I'm here to get an education."}, {"time": 2228, "text": "Now, the thing is, ultimately, it's been a pretty good job for me as well."}, {"time": 2231, "text": "This is in Sydney, by the way, and Sydney in summer is absolutely gorgeous."}, {"time": 2236, "text": "And what does a bunch of lefties decide to do during summer but read Karl Marx?"}, {"time": 2241, "text": "On the beach or?"}, {"time": 2242, "text": "Actually, inside the room of the philosophy department at the University of Sydney in the main quadrangle."}, {"time": 2248, "text": "There's sandstone all around us, and we have a bunch of about 20 or 30 of us reading our way through Marx."}, {"time": 2253, "text": "Capital?"}, {"time": 2254, "text": "Which capital?"}, {"time": 2255, "text": "It was volume one capital."}, {"time": 2258, "text": "And I remember walking off to that meeting with one of my friends who's a law student."}, {"time": 2266, "text": "And this was a period of a huge construction boom in Sydney, so the whole skyline, which we could see from the campus, was full of what they call kangaroo cranes, which were an Australian invention, that are cranes that can be leapfrogged over each other to build a skyscraper."}, {"time": 2280, "text": "So, here you are reading Karl Marx, looking at the mechanisms of capital."}, {"time": 2285, "text": "And I looked at those mechanisms, and I knew Marx argued that labor was the only source of value."}, {"time": 2291, "text": "And he said machinery doesn't add value."}, {"time": 2292, "text": "So, the cranes are worthless."}, {"time": 2294, "text": "I'm looking at these cranes and thinking, I want a very good explanation by Marx as to why these cranes don't add value."}, {"time": 2300, "text": "So, reading through the first seven chapters of Capital, what you found was Marx applying this dialectic."}, {"time": 2306, "text": "And like the Fichte and stuff is bullshit."}, {"time": 2308, "text": "That is not how Marx thought at all."}, {"time": 2309, "text": "I was reading, trying to find the thesis and the synthesis, and it's not there at all in any of Marx's works."}, {"time": 2315, "text": "And I've read everything he's ever written on economics from 1844 to 1894, when his last books were published."}, {"time": 2324, "text": "There's not one word of mention of that."}, {"time": 2325, "text": "What he does talk about is foreground and background and tension."}, {"time": 2329, "text": "And his idea of a dialectic is that a unity will exist in society, and that unity can be individual, it can be a commodity, anything at all."}, {"time": 2341, "text": "The unity will be understood by that society."}, {"time": 2345, "text": "One particular aspect will be focused upon."}, {"time": 2347, "text": "So, if you think about the human being in capitalism, the focus on the human being as an object is their capacity to work."}, {"time": 2354, "text": "You're a worker, okay?"}, {"time": 2357, "text": "It's put in the foreground."}, {"time": 2359, "text": "The fact that you're human and you want to play a guitar and go surfing and make love and all the other things that humans do is pushed into the background."}, {"time": 2367, "text": "There's a tension between the two of those."}, {"time": 2370, "text": "And that can transform that unity over time."}, {"time": 2373, "text": "And that's a beautiful dynamic vision of change."}, {"time": 2377, "text": "So dialectics is a philosophy of change."}, {"time": 2380, "text": "So synthesis, antithesis is what does every idea have a counter argument?"}, {"time": 2386, "text": "There's a positive and negative and you bring them together somehow."}, {"time": 2388, "text": "And then Marx has this foreground, background, and tension."}, {"time": 2392, "text": "Foreground is all what we think of as economics and background is all the lovemaking we do as humans."}, {"time": 2398, "text": "And why is there a tension?"}, {"time": 2401, "text": "Because if you imagine the unity, like if you take a human in a, any preview, like if you go back to Cro Magnum days, when we're living in caves and we've got to go hunting and cook food and stuff like that, but there's no social hierarchy."}, {"time": 2416, "text": "Because we've become used to, so you don't get labored as a worker or a capitalist."}, {"time": 2420, "text": "You're just a human in that situation."}, {"time": 2422, "text": "Then you've got more an integrated view of who you are."}, {"time": 2426, "text": "And I think that's one of the appeals of a tribal, a genuine tribal culture that you get treated for the whole of who you are."}, {"time": 2432, "text": "You've certainly categorized you're male, you're female, you're young, you're old, you're a hunter, you're a tool maker, et cetera, et cetera."}, {"time": 2439, "text": "But you're treated as more an integrated object."}, {"time": 2441, "text": "When you get put in a complex society, like a capitalist society, then one side of you's emphasized and the others are deemphasized."}, {"time": 2448, "text": "So is it fair to say that the background is like our basic fundamental humanity and the foreground is the machine of capitalism?"}, {"time": 2456, "text": "Effectively."}, {"time": 2457, "text": "And when you look at it in terms of a human, but what Marx did is apply this to a commodity."}, {"time": 2461, "text": "So he said, what is the essential unity in a capitalist economy?"}, {"time": 2465, "text": "And the essential unity is a commodity."}, {"time": 2468, "text": "The essential unit."}, {"time": 2470, "text": "The essential unity."}, {"time": 2472, "text": "What's unity?"}, {"time": 2473, "text": "Unity is an object in society."}, {"time": 2477, "text": "So he started from the point of view of trying to understand how exchange occurs."}, {"time": 2480, "text": "How do we set prices?"}, {"time": 2481, "text": "And his starting vision was to say that a commodity is a unity in a capitalist economy."}, {"time": 2488, "text": "The part of the unity that we focus upon is the exchange value."}, {"time": 2495, "text": "A capitalist produces a commodity, not because of its qualitative characteristics, but because it'd be sold for a profit."}, {"time": 2503, "text": "So the foreground aspect of a commodity is its exchange value."}, {"time": 2507, "text": "The background aspect of it, it won't succeed as a commodity unless it has a use value."}, {"time": 2512, "text": "So the background is the utility thing."}, {"time": 2516, "text": "See, if you made something which didn't work, okay, then you might be able to sell it, but it has no utility."}, {"time": 2522, "text": "You can't make that into a commodity."}, {"time": 2525, "text": "A broken thing can't be sold."}, {"time": 2526, "text": "Does that have the subjective?"}, {"time": 2527, "text": "Yeah, it has to have the subjective side as well as the objective."}, {"time": 2532, "text": "So the objective is what capitalists worry about."}, {"time": 2534, "text": "I'll give you my favorite counter example of that."}, {"time": 2536, "text": "I took a bunch of Australian journalists to China way back in the period when the Gang of Four was being on trial, and we did a tour of the Forbidden City in Beijing."}, {"time": 2548, "text": "And at that stage, all the artifacts of the royal family, the emperor, were actually in the building still."}, {"time": 2554, "text": "And we walked past one of them, and it was this gold, solid gold bar about this long, shaped like a fist, turned over like this."}, {"time": 2563, "text": "And on this side, there were rubies, emeralds, diamonds."}, {"time": 2566, "text": "You'd never seen gemstones."}, {"time": 2567, "text": "I mean, gems that big, okay?"}, {"time": 2569, "text": "And one of the journalists asked me what I thought it was, and I said, oh, it's obvious."}, {"time": 2572, "text": "Jane is a backscratcher, ha, ha, ha."}, {"time": 2575, "text": "I walked away."}, {"time": 2576, "text": "She caught up with me about 20 minutes later, said, I asked one of the guides, it is a backscratcher."}, {"time": 2581, "text": "So here's a backscratcher for the emperor made of solid gold with diamonds and rubies and emeralds during the scratching."}, {"time": 2587, "text": "Now, that's a commodity in a feudal society, okay?"}, {"time": 2591, "text": "The cost doesn't matter."}, {"time": 2593, "text": "You want the most elaborate, beautiful thing because you are the emperor."}, {"time": 2596, "text": "So in a feudal society, the commodity, what's focused upon is the utility."}, {"time": 2602, "text": "And the cost of production when you're the emperor is immaterial."}, {"time": 2606, "text": "Capitalism reverses that."}, {"time": 2608, "text": "So the commodity in a capitalist economy is a plastic $2.00 scratchy you can get from Kmart or Target."}, {"time": 2615, "text": "And so the use value is necessary but irrelevant to forming the price."}, {"time": 2622, "text": "Now, that was a completely different vision of exchange in capitalism to what I found in the neoclassical theory because that says it's the marginal utility and the marginal cost of everything that determines the exchange ratio."}, {"time": 2637, "text": "And the crazy thing about that is not so much the marginal utility, but the argument in the neoclassical theory is that the price ratio, the price will, when there's an exchange going on, there's two person, two commodity exchange of two commodities between two people."}, {"time": 2656, "text": "The price will change until such time as the ratio of the marginal utilities is equal to the ratio of the marginal costs that's supposed to be the equilibrium."}, {"time": 2665, "text": "And Marx says that's bullshit."}, {"time": 2667, "text": "That's a previous society where you exchange stuff that you happen to have for stuff somebody else happened to have without any real production mechanism being involved."}, {"time": 2677, "text": "And he said that's like when you have two ancient tribes meeting for the very first time and one tribe can make something the other tribe can't make."}, {"time": 2686, "text": "And they will therefore, the price they were willing to pay will reflect how unique this other object is that this one tribe can make and the other can't."}, {"time": 2695, "text": "So for example, the story of Manhattan being sold for 40 glass beads, it's actually 40 glass trading beads, I believe it is a true story."}, {"time": 2703, "text": "But the thing is the Indians couldn't make glass beads."}, {"time": 2707, "text": "So they valued the glass beads at the island of Manhattan, okay, which is a utility based comparison."}, {"time": 2713, "text": "And what Marx said, that's the very initial contact over time, even if you don't know the technology."}, {"time": 2718, "text": "Over time, you start to realize how much work goes involved to making what they're selling you versus what you're selling to them."}, {"time": 2726, "text": "And you start making stuff specifically for sale."}, {"time": 2729, "text": "So you know, Elon's not losing personal utility each time a Model 3 goes out the door."}, {"time": 2737, "text": "He might get utility out of the fact that he's created that vehicle, that concept and manufactures it and so on, but he's not losing utility each time a Model T Ford goes out the door, going back for the ancient commodity there."}, {"time": 2750, "text": "So the utility plays no role in setting price in Marx's model."}, {"time": 2756, "text": "Whereas it's essential in the neoclassical model."}, {"time": 2759, "text": "What's the difference between utility and marginal utility?"}, {"time": 2762, "text": "What does the word marginal mean?"}, {"time": 2764, "text": "And why is it such a problem?"}, {"time": 2766, "text": "It turns marginal utility or utility itself has different meanings than the two schools of thought."}, {"time": 2772, "text": "If you take the classical school of thought, which when Marx comes from, utility is effectively objective."}, {"time": 2778, "text": "So the utility of a chair is that you can sit in it, okay, not how comfortable it makes you feel."}, {"time": 2783, "text": "Okay, now if you think about the utility of the chairs, we're both sitting and they're identical from a classical point of view, we're both sitting."}, {"time": 2790, "text": "But from a neoclassical point of view, it's how comfortable it makes you feel."}, {"time": 2794, "text": "And that depends upon your subjective feelings of comfort."}, {"time": 2797, "text": "You might be far more comfortable in the identical chair that I'm sitting in than I am."}, {"time": 2802, "text": "And therefore, the comparison is difficult."}, {"time": 2804, "text": "And therefore, working out a ratio involves you've got a decline in your, each time you give away a chair in exchange for an iPhone, you have a fall in your utility, okay?"}, {"time": 2818, "text": "And then therefore, you want a higher return because you're losing more utility each time."}, {"time": 2823, "text": "The more chairs you give away, the less utility you're getting from chairs."}, {"time": 2826, "text": "So there's a decline in your utility."}, {"time": 2828, "text": "That's your marginal utility."}, {"time": 2831, "text": "So it's including your subjective valuation in setting the price."}, {"time": 2835, "text": "And what Marx pointed out is this is a caricature of actual change in a capitalist economy because we have, in a capitalist economy, huge factories turning out huge quantities, specifically for sale."}, {"time": 2846, "text": "They've got no utility to the seller unless they're sold, okay?"}, {"time": 2852, "text": "So it's a very different vision of how price is set."}, {"time": 2856, "text": "And Marx used that to explain where profit comes from, but he made a mistake."}, {"time": 2862, "text": "And his argument was that talking about a worker, as now your unity, this foreground background tension thing, the foreground is that you hire a worker for their cost of production."}, {"time": 2875, "text": "And the cost of production is a subsistence wage, okay?"}, {"time": 2880, "text": "Their utility to the buyer is the fact that they can work in a factory."}, {"time": 2885, "text": "Now, it might take six hours, let's say, to make the means of subsistence."}, {"time": 2890, "text": "And that's the exchange value, and that's what the capitalist pays as a wage to the worker."}, {"time": 2895, "text": "But they can work in the factory for 12 hours."}, {"time": 2898, "text": "That's the utility."}, {"time": 2899, "text": "12 minus 6 is 6 surplus of value hours, and that's where profit comes from."}, {"time": 2906, "text": "And that was Marx's argument."}, {"time": 2907, "text": "And I thought it was brilliant, but it also applied to machinery."}, {"time": 2912, "text": "Let's blink on that."}, {"time": 2915, "text": "Deep is good."}, {"time": 2916, "text": "You just want to define terms."}, {"time": 2918, "text": "Don't take that statement out of context, the internet, please."}, {"time": 2924, "text": "You said buyer, seller, worker in a factory, who's the seller, who's the buyer?"}, {"time": 2932, "text": "Why is the worker the buyer?"}, {"time": 2935, "text": "The worker is the commodity in this case."}, {"time": 2938, "text": "Because if you're going to make stuff in a factory, you've got to hire workers."}, {"time": 2942, "text": "And what Marx is saying, the buyer in that situation is a capitalist."}, {"time": 2946, "text": "So what does the buyer pay?"}, {"time": 2947, "text": "He says he pays the exchange value."}, {"time": 2949, "text": "That's back to the commodity thing, because that's the starting point."}, {"time": 2953, "text": "He said the essential unity in a capitalist economy is the commodity."}, {"time": 2957, "text": "A commodity has two characteristics, exchange value and use value."}, {"time": 2962, "text": "Exchange value of a commodity in a capitalist economy will be its cost of production."}, {"time": 2966, "text": "The use value is what you do with it, okay, once you've purchased it."}, {"time": 2971, "text": "But labor is a commodity?"}, {"time": 2974, "text": "In this case, when a worker is being hired for a job, yes."}, {"time": 2978, "text": "So the worker's labor has an exchange value and a use value as well?"}, {"time": 2984, "text": "Use value."}, {"time": 2985, "text": "Use value of a worker's labor."}, {"time": 2988, "text": "Exchange value."}, {"time": 2989, "text": "Let me think about that."}, {"time": 2994, "text": "So the hours they put in is the use value."}, {"time": 2999, "text": "So what does the worker want in this?"}, {"time": 3005, "text": "What are the motivations?"}, {"time": 3006, "text": "Are we not considering the worker in this context as a human being?"}, {"time": 3009, "text": "Well, you come in and that's actually, that's the next layer."}, {"time": 3014, "text": "What Marx gives us is like a layered cake, starting from a foundation of saying straight commodity exchange, and then saying, well, you're treating a worker as a commodity."}, {"time": 3023, "text": "Now a commodity is something like this, okay, that has, so far as I'm aware, no soul, okay?"}, {"time": 3030, "text": "Not going to be complaining if I turn it upside down."}, {"time": 3032, "text": "It'll fall over."}, {"time": 3034, "text": "So there's no soul there as a human, is both a commodity and a noncommodity."}, {"time": 3039, "text": "And therefore there'll be a tension in the person."}, {"time": 3041, "text": "I'm being treated as a commodity here."}, {"time": 3043, "text": "I'm being paid just enough to stay alive."}, {"time": 3045, "text": "I've got a wife and kids back at home."}, {"time": 3048, "text": "So that is another layer of thinking in Marx, and on that layer he then says, well, workers will therefore demand more than their value."}, {"time": 3057, "text": "So that's when you get like political."}, {"time": 3058, "text": "You get political and you get money coming above that and so on."}, {"time": 3061, "text": "But the basic idea starts from the commodity is the fundamental unity in capitalism."}, {"time": 3067, "text": "The important commodity in Marx's thinking was the worker, because that's where he said profit came from, okay?"}, {"time": 3074, "text": "And then that explains the motivation of the capitalist, and that ultimately is the labor theory of value and Marx's arguments about how capitalism will come to an end."}, {"time": 3083, "text": "Okay, okay, okay."}, {"time": 3084, "text": "So first of all, what is the labor theory of value?"}, {"time": 3087, "text": "And actually before that, what is value?"}, {"time": 3090, "text": "Is that, this is like me asking what's happiness."}, {"time": 3095, "text": "Is there something interesting to say about trying to define value?"}, {"time": 3098, "text": "You vary, and this is a huge problem in economics is arguments of what does value mean?"}, {"time": 3105, "text": "And the neoclassicals came down as that it's subjective."}, {"time": 3108, "text": "Its value is whatever you get out of it, but it's your personal evaluation of something, your personal feelings."}, {"time": 3115, "text": "So they've got that very subjective idea of value, whereas the Marxists, being inheritors of classical school, talk in terms of objective value."}, {"time": 3126, "text": "So the value is the number of hours it takes to make something, or the effort."}, {"time": 3131, "text": "Value is the effort that goes into making something in the classical school."}, {"time": 3134, "text": "Well, that's just one measure of objective."}, {"time": 3138, "text": "Where do you fall?"}, {"time": 3141, "text": "I fall on... Subjective versus objective spectrum of value."}, {"time": 3145, "text": "I think you have to have the capacity to move between one and the other in a structured way."}, {"time": 3151, "text": "The K model of value."}, {"time": 3152, "text": "Yeah, well, my base model is the objective, okay?"}, {"time": 3155, "text": "But above that, as soon as you start talking, you said about the worker, for example, then you get involved in the subjectivity, because a worker will be angry, and justifiably so, about being treated as a commodity, because I'm not a commodity, I'm a human being, okay?"}, {"time": 3173, "text": "And that's where Marx saw political organization coming from."}, {"time": 3178, "text": "And that's subjective now."}, {"time": 3179, "text": "And then when you get to money itself, Marx actually said, well, what's the value of money?"}, {"time": 3185, "text": "Now if you use an objective theory of value, you would say, well, the value of money is its cost of production."}, {"time": 3191, "text": "What's the cost of producing a dollar?"}, {"time": 3193, "text": "It's about two cents."}, {"time": 3195, "text": "So he said it can't be, the value of money cannot be its cost of production."}, {"time": 3200, "text": "Or the most value, I think if I remember the phrase properly, is value here as it must mean the, effectively, uncertain expectations or subjective valuation."}, {"time": 3213, "text": "Uncertain expectations or subjective valuation."}, {"time": 3215, "text": "Okay, but he's okay with that?"}, {"time": 3216, "text": "He was okay with that, because he could move between different levels, because he had a structured foundation of this dialectical vision of foreground, background tension, commodity, having use value, exchange value, and a gap between the two when you're talking about machines, when you're buying stuff for production."}, {"time": 3236, "text": "And then at the next level, he could look at workers, worker organization, and say that's driven by being treated as a commodity when you're a noncommodity."}, {"time": 3244, "text": "So the basic labor theory of value that is described to Karl Marx is that value at the base layer fundamentally comes from the labor you put into something."}, {"time": 3259, "text": "And you say, well, there's some deep truth there, except he misses one fundamental point, which is machines can also bring value to the world."}, {"time": 3270, "text": "He was saying they don't, the only thing that matters is human labor, not labor."}, {"time": 3278, "text": "How do you measure what's the role of whatever value machines bring to the world?"}, {"time": 3285, "text": "This is another intriguing history, because Marx, when he first started, had what you can call an exclusivist explanation for why labor created value."}, {"time": 3297, "text": "And that was to say that labor is the only commodity with both what he called commodity and commodity power."}, {"time": 3304, "text": "So you have labor and labor power."}, {"time": 3309, "text": "Labor is the, and I get fuzzy about this, I haven't read it for something like 30 years, but labor has both commodity and commodity power."}, {"time": 3317, "text": "The commodity is you can buy labor, which is the means of subsistence."}, {"time": 3322, "text": "Labor power is the capacity to work inside a factory."}, {"time": 3325, "text": "There's a difference between the two, therefore that difference will give rise to surplus."}, {"time": 3329, "text": "And there's no other commodity that has this essence of commodity and commodity power."}, {"time": 3334, "text": "So that was his exclusivist argument."}, {"time": 3336, "text": "In the middle of 1857, he was visited by a guy called Otto Brau in his home in Chelsea."}, {"time": 3344, "text": "And Otto returned to Marx a copy of Hegel's, I think it's called Phenomenology of Right, I haven't read it, but that's the book."}, {"time": 3353, "text": "And Marx was then at that stage reading through all the classical theorists again."}, {"time": 3358, "text": "And he was, suddenly he read Hegel again."}, {"time": 3361, "text": "And if you know Hunter S. Thompson, okay, okay."}, {"time": 3364, "text": "Who doesn't know Hunter S. Thompson?"}, {"time": 3366, "text": "Somebody who hasn't had enough drugs, obviously."}, {"time": 3369, "text": "But Hunter S. Thompson."}, {"time": 3370, "text": "He comes to you in a dream after you take your first puff of... Mescaline or... Or whatever."}, {"time": 3374, "text": "And of course, we've all..."}, {"time": 3375, "text": "If you know your drugs well enough, you can tell, okay, he's stoned, okay, he's on cocaine, you know."}, {"time": 3379, "text": "But suddenly, his writing style in the middle of a book called The Grundrisse completely changed."}, {"time": 3385, "text": "He switched from weed to cocaine."}, {"time": 3386, "text": "He switched from Ricardo to Hegel, okay."}, {"time": 3388, "text": "And what in Ricardo, he had this exclusivist argument about labor, and suddenly Hegel is back talking in terms of dialectics, not actually using a word, but foreground and background and tension."}, {"time": 3400, "text": "And then he... That's where this use value, exchange value, attention thing came from, is rereading Hegel 13 years after he stopped reading philosophy, because made in 44, he was reading just The Economists."}, {"time": 3412, "text": "So you're saying Karl Marx is human after all."}, {"time": 3415, "text": "He's human."}, {"time": 3416, "text": "He could be..."}, {"time": 3417, "text": "I would love to have a beer with Karl."}, {"time": 3418, "text": "For a wine."}, {"time": 3419, "text": "For Karl?"}, {"time": 3420, "text": "He's Karl to you?"}, {"time": 3421, "text": "He's Mr. Marx to me."}, {"time": 3423, "text": "Hang on."}, {"time": 3424, "text": "He'd be Karl to me, I'm afraid, after all these years."}, {"time": 3427, "text": "You've had quite a journey together."}, {"time": 3429, "text": "So that's where after Hegel, his interpretation of the dialectic comes in the form of background, foreground, and background."}, {"time": 3436, "text": "And then on page 267 of the Penguin edition of the Grundrisse."}, {"time": 3441, "text": "What early?"}, {"time": 3442, "text": "Your memory... One and a half pages long footnote."}, {"time": 3444, "text": "It's pretty hard to forget."}, {"time": 3445, "text": "Because when I did this, when I first read Marx way, way back when I was... How old was I?"}, {"time": 3451, "text": "20."}, {"time": 3453, "text": "I tried to explain my explanation of Marx's use value, exchange value stuff to my colleagues in this philosophy discussion room at Sydney University during a beautiful summer that we were inside, concrete and sandstone walls discussing Marx."}, {"time": 3467, "text": "And I went to say, look, the use value, exchange value argument can be applied to a machine."}, {"time": 3472, "text": "What's the exchange value of a machine?"}, {"time": 3474, "text": "It's cost of manufacturing it."}, {"time": 3475, "text": "What's its use value?"}, {"time": 3476, "text": "Its capacity to produce goods for sale."}, {"time": 3479, "text": "No relation between the two, there'll be a gap, a machine can be a source of profit."}, {"time": 3483, "text": "Now, I said that and I got laughed at and I quite literally laughed at."}, {"time": 3487, "text": "So when I went back to university 13 years later to do my master's degree, I chose to read through and find in Marx where he first came across this insight."}, {"time": 3498, "text": "So my first master's thesis failed, by the way, and justifiably so."}, {"time": 3504, "text": "I didn't know the level of academic discourse necessary."}, {"time": 3509, "text": "I had an advisor who didn't understand what I was writing."}, {"time": 3512, "text": "He got me to write for his New Keynesian audience and it was a mess and it got failed."}, {"time": 3519, "text": "So I got rid of him."}, {"time": 3520, "text": "Did it get failed?"}, {"time": 3521, "text": "Why do you think?"}, {"time": 3523, "text": "It wasn't a good thesis."}, {"time": 3524, "text": "I didn't know the level."}, {"time": 3526, "text": "It was written for an audience my supervisor thought that I should be writing for, and it was a mess."}, {"time": 3532, "text": "And so I met another guy, Jeff Fishburne, as a lecturer at New South Wales University."}, {"time": 3539, "text": "And Jeff was open minded."}, {"time": 3540, "text": "He was not a conventional neoclassical thinker."}, {"time": 3544, "text": "And I realized I'd throw out the half that Bill had got me to do, focused just on Marx."}, {"time": 3549, "text": "And so I decided to read Marx in chronological sequence from his very first works of economics, which are called the Economic and Philosophical Manuscripts of 1844."}, {"time": 3558, "text": "And he wrote those in a garret in Paris after he'd been expelled from Prussia."}, {"time": 3563, "text": "And so he decided to read having been an expert on philosophy and regarded it as the towering intellect of Hegelian philosophy in Prussia, but driven out because he was a radical."}, {"time": 3576, "text": "He ended up running a newspaper or being writing for a newspaper, and he was reporting about the eviction of peasants from the forests, taking away their feudal rights."}, {"time": 3587, "text": "And so this is where his passion for economics and humanity came from."}, {"time": 3593, "text": "And he was a poet as well."}, {"time": 3595, "text": "I mean, he loved poetry to Jenny von Westhalen."}, {"time": 3598, "text": "His first published works were pretty much in poetry."}, {"time": 3601, "text": "He was a rouse about, he was a wild character."}, {"time": 3605, "text": "We'd probably fight like crazy, I imagine, if we met."}, {"time": 3609, "text": "Over the beers?"}, {"time": 3610, "text": "I'm slightly, even though I can be, I can get involved in an argument like nobody's business."}, {"time": 3617, "text": "No, really?"}, {"time": 3618, "text": "No, really."}, {"time": 3619, "text": "But I'm a bit more peaceful of personality."}, {"time": 3621, "text": "Oh, you think Marx is feistier than you?"}, {"time": 3623, "text": "He was feisty, but feisty with, he could be arrogant."}, {"time": 3627, "text": "Like I've got an intellectual arrogance, I've come to accept that."}, {"time": 3631, "text": "But there's like a fundamental humility to you."}, {"time": 3633, "text": "You're saying Marx is like, has ego that's hard to control."}, {"time": 3637, "text": "A bit too big ego, yeah."}, {"time": 3639, "text": "I mean, I'm never going to meet him."}, {"time": 3640, "text": "Well, the beard says ego to me."}, {"time": 3642, "text": "The beard is huge, yeah."}, {"time": 3646, "text": "So you went chronologically right through his works, the development of the human being through his works."}, {"time": 3653, "text": "And I was trying to find the point at which he discovered this use value exchange value idea."}, {"time": 3656, "text": "And it occurs in a footnote on page 267 to 268 of the Penguin edition of the Guindrisa, which his notes he was taking literally not meant for publication, literally sitting at a stall inside the British Museum, I think, reading all the classical authors in chronological sequence."}, {"time": 3674, "text": "And then somebody throws Hegel at him, and suddenly he's talking in Hegelian terms."}, {"time": 3679, "text": "And he suddenly says, is not, because it's whole value issues, what is value?"}, {"time": 3684, "text": "Is it exchange value, use value?"}, {"time": 3686, "text": "How do they relate to each other?"}, {"time": 3687, "text": "That's what he was thinking about."}, {"time": 3688, "text": "And he said, is not use value, which was left out of the classical school, a fundamental aspect of the commodity?"}, {"time": 3696, "text": "Is there not a tension between the use value and exchange value?"}, {"time": 3699, "text": "Just so we're clear in that context, use value is kind of the subjective thing, exchange value is the objective thing."}, {"time": 3706, "text": "And Marx was, found a way to integrate the two."}, {"time": 3709, "text": "He was focused on labor being the only thing that can generate both the use value and the exchange value."}, {"time": 3718, "text": "But, no."}, {"time": 3719, "text": "If you look at the classical school, they focus on exchange value, objective."}, {"time": 3723, "text": "Look at the neoclassical, they focus upon use value, subjective, or they call it utility."}, {"time": 3729, "text": "So Marx, coming from the Ricardian tradition, basically dismissed the role of utility."}, {"time": 3734, "text": "And then when he reads Hegel, he's suddenly starting to think in terms of unities."}, {"time": 3740, "text": "And exchange value and use value is the unity of the commodity."}, {"time": 3744, "text": "And he thinks, well, I can't ignore use value."}, {"time": 3747, "text": "So rather than leaving it out completely, which is what Ricardo and Smith does, I've got to somehow bring it in."}, {"time": 3752, "text": "And this Hegelian insight occurs to him."}, {"time": 3755, "text": "And it's remarkable, I really recommend taking a look at the book, even just to look at that particular page, because what it would have been, as shown as a footnote, but it would have been him saying, oh, wow, and his asterisk, asterisk, is not use value, a fundamental aspect of the unity of a commodity."}, {"time": 3773, "text": "So in the notes, you see the discovery of an idea in the human mind, the integration of an idea."}, {"time": 3778, "text": "And it's beautiful."}, {"time": 3779, "text": "And he actually writes, does this have significance in economics, question mark."}, {"time": 3782, "text": "And then he probably went home that night, and that idea changed him."}, {"time": 3786, "text": "Yeah, it changed him completely."}, {"time": 3788, "text": "And from that point on, his writing was completely different."}, {"time": 3791, "text": "But he still had this idea from the Ricardian days of saying that labor is the only source of value, using an exclusive argument to say there's something unique about labor that explains why it's a source of value."}, {"time": 3802, "text": "But suddenly, this insight occurs to him, and he thinks, I can get a positive derivation."}, {"time": 3806, "text": "I can use use value and exchange value and the fact they're not related to each other as a dialectical tension to explain surplus value."}, {"time": 3816, "text": "So he goes from a negative explanation of where value comes from to a positive explanation on that page of the Guindarisa."}, {"time": 3824, "text": "He then triumphantly uses it to explain why labor is a source of value."}, {"time": 3829, "text": "You buy it for its exchange value."}, {"time": 3831, "text": "You use its use value."}, {"time": 3832, "text": "They're unrelated."}, {"time": 3833, "text": "The use value will be bigger."}, {"time": 3835, "text": "That's where profit comes from."}, {"time": 3836, "text": "Then he does exactly the same thing for machinery, about 30 pages on."}, {"time": 3841, "text": "He says it also has to be contemplated, which was not done before."}, {"time": 3846, "text": "This is wrote nice to himself, by the way."}, {"time": 3849, "text": "It's written really in a colloquial style, that the use value of a machine is significantly greater than its exchange value."}, {"time": 3856, "text": "He actually left out the word is."}, {"time": 3857, "text": "It's used to be a translation into English of the German, I'm sure."}, {"time": 3864, "text": "I haven't seen the original notes."}, {"time": 3865, "text": "I'd love to see them."}, {"time": 3866, "text": "But he says, he leaves out the word is."}, {"time": 3869, "text": "It also has to be contemplated that the use value is significantly greater than its exchange value, i.e."}, {"time": 3874, "text": "that the contribution of the machine to production exceeds its depreciation."}, {"time": 3883, "text": "That was an insight which undermined his explanation for revolution."}, {"time": 3892, "text": "The cost of production exceeds its depreciation?"}, {"time": 3898, "text": "Well, what Marx argued, and you read this in Capital, and I read this in Capital when I first saw the contradiction in his own thought."}, {"time": 3907, "text": "He said that no matter how useful a machine is, whether it took a hundred hours to make or cost 150 pounds, it cannot under any circumstances add more to production than 150 pounds, which in his old exclusivist logic he could justify, and which in his post 1857 argument is bullshit."}, {"time": 3931, "text": "Can you steel man his case?"}, {"time": 3933, "text": "Can we go to the mind of Marx and thinking if a machine costs a hundred bucks, it can't be ever more, bring more value than a hundred bucks to the world?"}, {"time": 3943, "text": "But that contradicts his previous logic, because what he said is commodities are the essential unity in capitalism."}, {"time": 3952, "text": "Capitalism focuses upon the exchange value."}, {"time": 3954, "text": "That pushes the use value into the background, and there's a tension between the two."}, {"time": 3959, "text": "What that means is the exchange value of a commodity sets its price."}, {"time": 3964, "text": "The use value is independent."}, {"time": 3966, "text": "He called them incommensurable."}, {"time": 3967, "text": "He literally used the word incommensurability between exchange value and a use value, whereas neoclassicals make them commensurable."}, {"time": 3975, "text": "So he's saying exchange value and use value incommensurable, and that normally means that exchange value is objective, like the number of hours it takes to make something."}, {"time": 3985, "text": "Use value is subjective, how comfortable the chair is, the fact that you can sit in a chair."}, {"time": 3990, "text": "So that's incommensurability, but when you apply it in production, the exchange value of something is objective."}, {"time": 3996, "text": "It's how many hours it takes to make a machine or how many hours it takes to make the means of subsistence for a worker."}, {"time": 4002, "text": "The use value is also objective."}, {"time": 4004, "text": "You're making commodities for sale, and the worker does six hours."}, {"time": 4009, "text": "Six hours of work will make the means of subsistence for the worker, but the worker will work a twelve hour day, and the six hours becomes a gap."}, {"time": 4019, "text": "Now that's incommensurability between use value and exchange value of labor, but when you look at what he said about no matter how long it takes to make a machine or how many pounds it costs, he's saying they're identical, and that's contradicting his own logic."}, {"time": 4035, "text": "Well, what's the use value of a machine?"}, {"time": 4037, "text": "The fact that it can produce goods for sale, exactly the same as the worker."}, {"time": 4043, "text": "Now in my modern reinterpretation of Marx, which brings in my work on energy, I see both labor and machinery as a means to harness energy and produce useful work, and they can both do that."}, {"time": 4057, "text": "In fact, they do it together."}, {"time": 4059, "text": "It's a collective enterprise."}, {"time": 4060, "text": "Okay, so, and we'll go to that."}, {"time": 4064, "text": "So there's no fundamental difference from an exchange value and use value perspective between a human and a machine."}, {"time": 4070, "text": "And therefore, they're using the same logic that can both be a source of surplus, which is what Marx contradicted because his explanation for where socialism would come from is that only profit comes from, like profit comes only from labor."}, {"time": 4083, "text": "Over time, we'll add more machinery than labor that will mean a falling rate of profit and therefore a tendency towards socialism."}, {"time": 4091, "text": "And what he did in that insight in 1857 is contradict his own idea about what would lead to socialism, and he couldn't cope with it."}, {"time": 4099, "text": "Okay, what's the difference between Marxian economics and Marxist political ideology?"}, {"time": 4110, "text": "The gap between the two, the overlap, the differences, what?"}, {"time": 4114, "text": "The real foundation of Marx's political philosophy was the economic argument that there would be a tendency for the rate of profit to fall."}, {"time": 4122, "text": "And that tendency for the rate of profit to fall would lead to capitalists battening down on workers harder, paying them less than their subsistence, a revolt by workers against this, and then you would get socialism on the other side."}, {"time": 4138, "text": "So what he called the tendency for the rate of profit to fall played a critical role in his explanation for why socialism would have to come about."}, {"time": 4147, "text": "He was saying it would have to come about, or is it a good thing for it to come about?"}, {"time": 4153, "text": "He had a should, but he was trying to say it must."}, {"time": 4156, "text": "So if you look at Marx in the history of radical thought, he was preceded by what were called utopian socialists."}, {"time": 4164, "text": "Saint Simon, even the Cadbury's company came out of utopian socialist, and they had an idea about a perfect society in the future where people were properly rewarded, were treated as human beings rather than cogs in a machine and all this sort of stuff."}, {"time": 4178, "text": "And they said socialism should come about because it treats humans better than capitalism does."}, {"time": 4183, "text": "Marx said, I can prove that socialism must come about."}, {"time": 4187, "text": "So he preferred, he had a utopian vision of a future society, but he thought he could prove that it had to come about."}, {"time": 4195, "text": "And the proof relied critically upon tendency for the rate of profit to fall, and that relied upon labor being the only source of profit."}, {"time": 4206, "text": "What was his utopian view?"}, {"time": 4207, "text": "So this idea from each according to his ability to each according to his needs."}, {"time": 4213, "text": "Is that the utopian?"}, {"time": 4216, "text": "I think it's utopian in the context of our modern world."}, {"time": 4221, "text": "It says that rather than being rewarded, like Jeff Bezos gets enormous fortune, you get what you need, not what you want, necessarily."}, {"time": 4232, "text": "All needs is fulfilled."}, {"time": 4233, "text": "It was a vision of utopia where you could be a fisherman in the morning, a poet in the afternoon, and a chef at night, this paraphrasing one of his phrases."}, {"time": 4243, "text": "So he did have a utopian vision of a future society, and he did think human creativity would be much, much greater under socialism than it was under capitalism."}, {"time": 4254, "text": "So let's explore in different ways where he was wrong."}, {"time": 4257, "text": "You're saying there's a fundamental flaw in the logic, but also if we can explore high level philosophical concepts of socialism too, like the dreams of a utopia."}, {"time": 4270, "text": "So first of all, what is socialism?"}, {"time": 4274, "text": "That's another loaded term."}, {"time": 4277, "text": "Socialism particularly in America is a very loaded term."}, {"time": 4279, "text": "What Americans call socialist is a large amount of provision of services by the state, which is commonplace in Europe."}, {"time": 4288, "text": "It's still moderately commonplace in my own home country of Australia."}, {"time": 4294, "text": "And that Americans will call public education socialist."}, {"time": 4298, "text": "It's a total parody of the word."}, {"time": 4302, "text": "Strictly speaking, what socialism meant is the public ownership of the means of production, no private ownership of the means of production."}, {"time": 4309, "text": "What is the means of production?"}, {"time": 4311, "text": "Machine factories."}, {"time": 4312, "text": "Factories."}, {"time": 4313, "text": "So all the goods that are produced in factories, no, the means of producing the goods is owned by a centralized entity."}, {"time": 4322, "text": "Centrally planned."}, {"time": 4323, "text": "This is what actually was done under Gold's plan under the Soviets."}, {"time": 4327, "text": "And even with the collective farms as well."}, {"time": 4329, "text": "You no longer own your land."}, {"time": 4331, "text": "The state owns the land."}, {"time": 4333, "text": "You worked on the land."}, {"time": 4335, "text": "And this was supposed to be a utopia."}, {"time": 4336, "text": "Now it didn't turn out to be one."}, {"time": 4339, "text": "And we'll talk about maybe your ideas of why it didn't turn out to be one."}, {"time": 4343, "text": "So the fascists did the same."}, {"time": 4345, "text": "So is this fascism also central?"}, {"time": 4348, "text": "Fascism, so called national socialism."}, {"time": 4351, "text": "It's also a kind of socialism."}, {"time": 4352, "text": "So yeah, but there was no, it wasn't a public owner, there was public direction."}, {"time": 4356, "text": "So the state would tell factories what to do, but there's still a private profit."}, {"time": 4360, "text": "And a large part of why the Nazis succeeded was the extent to which they managed to coopt major manufacturers in Germany."}, {"time": 4367, "text": "So it's, you know."}, {"time": 4370, "text": "Direction versus ownership."}, {"time": 4372, "text": "A dictatorial, I mean, that's a very particular implementation."}, {"time": 4376, "text": "So you have to consider the full details of the implementation, but it's basically dictator guided."}, {"time": 4383, "text": "And if you want to take a proper vision, then you have to say it's the ownership of the means of production by the state."}, {"time": 4392, "text": "Versus the ownership by private."}, {"time": 4394, "text": "That rules out the Nazi period."}, {"time": 4396, "text": "Use the word that, again, they're bastardizing as much as Americans do in the opposite direction."}, {"time": 4402, "text": "Well, what does ownership exactly mean?"}, {"time": 4406, "text": "Well, it became incredibly complicated."}, {"time": 4411, "text": "And this is actually the best work on this is done by recently deceased Hungarian economist called Janos Kornai."}, {"time": 4418, "text": "And Kornai tried to explain why socialism failed."}, {"time": 4422, "text": "Because why did socialism fail in your view?"}, {"time": 4425, "text": "In his view, in Janos's view, in your view."}, {"time": 4427, "text": "I think Janos is 100% correct."}, {"time": 4429, "text": "It's a brilliant piece of work, so I'm going to be really paraphrasing his view."}, {"time": 4433, "text": "And he imagined an ideal socialist society, and there wasn't a Stalin, there weren't purges, and you lived up to all the ideals that Marx had for socialism."}, {"time": 4444, "text": "So he said, but you do it in a context of an economy which is incredibly primitive, Russia."}, {"time": 4451, "text": "Because if you look at Marx's own vision of the revolution, it was going to happen in England."}, {"time": 4455, "text": "The advanced economies would be first to go through the revolution."}, {"time": 4458, "text": "The socialist, the primitive economies would have to go through a capitalist transition."}, {"time": 4463, "text": "And this is the difference between the Mensheviks and the Bolsheviks."}, {"time": 4466, "text": "So the Mensheviks, when Hyman Minsky came out of the Menshevik family, the Mensheviks believed you had to go through a capitalist phase."}, {"time": 4473, "text": "Russia had to go through a capitalist period before it becomes socialist."}, {"time": 4476, "text": "The Bolsheviks believed they could get there in one go, bypass the capitalist phase, do the development under socialism rather than under capitalism."}, {"time": 4487, "text": "And this is what Yanis was actually analyzing."}, {"time": 4490, "text": "You start from a primitive feudal economy, very little industrialization, and you want to jump to an advanced industrial society from that foundation."}, {"time": 4504, "text": "So he said what you have then for is a whole range of industries, all of which need as much resources as you can get for them."}, {"time": 4512, "text": "So you want to develop agriculture, mining, industry, every little division of it."}, {"time": 4519, "text": "They all have legitimate demands on the resources of the country and the state."}, {"time": 4524, "text": "That means that all your resources are fully employed and are probably over employed."}, {"time": 4529, "text": "So you have a resource constraint in that society."}, {"time": 4533, "text": "The easiest way to cope with a resource constraint is to produce last year's commodity, not to innovate, not to make change."}, {"time": 4540, "text": "So what they will give you is as you start to add, you invest so you now have the beginnings of a steel industry, beginnings of a car industry, and so on, you start investing, but you continue producing the same product you made last year."}, {"time": 4554, "text": "And I have a perfect personal example of that, which I'll throw in now if you like a pretty heavy conversation."}, {"time": 4560, "text": "I know my first major girlfriend had a brother who wanted to get a motorbike, but he couldn't afford a Honda or a Kawasaki."}, {"time": 4571, "text": "At the time, they cost about $3,000 for a 650 cc Japanese motorbike."}, {"time": 4577, "text": "He found he could buy a Cossack for $650, $1 per cc."}, {"time": 4583, "text": "So I was there when he got this is in suburban Sylvania waters in Sydney."}, {"time": 4590, "text": "So this crate arrives with a Cossack motorbike inside it."}, {"time": 4595, "text": "So we take it apart, it's then got all these wooden palings, we have to pull off the wooden palings to open it up."}, {"time": 4600, "text": "Then there's oil soaked rag over this thing, which is tied on a wooden base."}, {"time": 4604, "text": "We take the oil soaked rag off and we stare in all its glory in a 1942 BMW."}, {"time": 4610, "text": "It was exactly the same as Steve McQueen in The Great Escape."}, {"time": 4615, "text": "So the Russians for 30 years were making the same bloody motorbike."}, {"time": 4619, "text": "It had a bicycle seat."}, {"time": 4622, "text": "And that's how they cope."}, {"time": 4623, "text": "They've just made the same damn machine every year."}, {"time": 4626, "text": "And he said, so that's the outcome."}, {"time": 4629, "text": "You actually want the best possible world."}, {"time": 4630, "text": "You're trying to build as fast as possible."}, {"time": 4633, "text": "You're paying workers as high wages as you possibly can."}, {"time": 4636, "text": "And that leads to a world where you don't innovate."}, {"time": 4639, "text": "But he said capitalism, on the other hand, pure capitalist economy, you're trying to pay workers as little as possible."}, {"time": 4646, "text": "You have competitive industries."}, {"time": 4648, "text": "You're trying to take demand away from your rivals."}, {"time": 4651, "text": "You have Kawasaki versus Honda versus BMW, et cetera, et cetera."}, {"time": 4657, "text": "The way you get demand away from your competitors is by innovating."}, {"time": 4661, "text": "So what you will get is cycles and booms and slumps, but you'll innovate and change over time."}, {"time": 4667, "text": "So what you find was this huge gap between socialist volume production with no innovation and capitalism with innovation."}, {"time": 4675, "text": "So that was the fundamental failing that Janos Korneis saw, so why did socialism not innovate?"}, {"time": 4682, "text": "Because if you go back to this famous historical incident with Khrushchev in the United Nations, bangs Texophe Shewan, bangs the desk, says, we will bury you."}, {"time": 4692, "text": "He literally meant we're going to bury you in commodities."}, {"time": 4695, "text": "We're going to produce more output than you are."}, {"time": 4697, "text": "And he was wrong."}, {"time": 4699, "text": "Because fundamentally, in the long term, to bury somebody in commodity production, you have to innovate."}, {"time": 4707, "text": "And there's also another remarkable Soviet engineer who was given the job of interpreting Marx's ideas of industrial sectors."}, {"time": 4716, "text": "So he had the commodity sphere, the industry sphere, sector one, sector two, sector three."}, {"time": 4722, "text": "Sector one producing consumer goods, sector two producing capital goods, sector three producing luxury goods for capitalists."}, {"time": 4729, "text": "And so he had a three sector model of the economy, and he was talking about the dynamics between them."}, {"time": 4734, "text": "And what Feldman did was reinterpret this as an engineer would reinterpret it, which was brilliant work."}, {"time": 4740, "text": "So what he said was, you need to produce the means of production."}, {"time": 4745, "text": "If you want to grow quickly, you focus on producing the means of production rather than commodities."}, {"time": 4750, "text": "So you don't make cars, you make car factories."}, {"time": 4754, "text": "You make a few cars, but most of the effort goes into expanding how many factories you have."}, {"time": 4758, "text": "And what he did was do a mathematical model where you start off with very low levels of consumer good output, but then you would just go exponential."}, {"time": 4765, "text": "Now, I took a look at that back when I was doing my master's degree."}, {"time": 4769, "text": "And the training in mathematics, I took Feldman's equations and then looked at what was actually driving it was he was imagining correctly a huge pool of unemployed labor."}, {"time": 4780, "text": "If you go back to the earliest stages of Soviet industrialization back in 1917, post the Second World, post the First World War, you had all these unemployed workers, you had all these peasants you could take off the land and put into factories."}, {"time": 4793, "text": "So you had a huge supply of workers."}, {"time": 4797, "text": "What you had to do was build the factories."}, {"time": 4799, "text": "See building the factories, but at a certain point you exhaust the supply of lowly employed or unemployed labor."}, {"time": 4807, "text": "And so rather than having this exponential takeoff, you hit a ceiling and then you can only grow as fast as the population because you're not innovating."}, {"time": 4816, "text": "So that's what actually hit the Soviet system."}, {"time": 4820, "text": "And it's why they never buried the Western consumer goods."}, {"time": 4823, "text": "And instead why Western consumers looked in envy at the goods being purchased by their Western people and said, if that's exploitation, we want exploitation."}, {"time": 4833, "text": "So okay, there's a lot of interesting stuff to ask here, which is, so Marx's vision for the socialist utopia is you have to go through capitalism."}, {"time": 4848, "text": "The Mensheviks were true to Marx's original idea."}, {"time": 4850, "text": "So is there a case to be made that in the long arc of human history on like human civilization on earth that we're going to live out Marx's vision for utopia, which is like, will we run into a wall with capitalism?"}, {"time": 4867, "text": "I think we are running into a wall with capitalism."}, {"time": 4869, "text": "In fact, I think we've already gone through the wall and we haven't yet realized we've smashed our skulls."}, {"time": 4876, "text": "But on the other side, we're bleeding and everything like that."}, {"time": 4882, "text": "Does Marx have any insights on what the other side of capitalism, what is beyond capitalism?"}, {"time": 4886, "text": "I think that beautiful phrase of from each according to his ability to each according to his needs describes what we should end up with."}, {"time": 4896, "text": "And I think that's actually, if I think about, you know, I'm an Elon Musk fan."}, {"time": 4900, "text": "That's what I think is partially going to be the nature of society if we build one that functions on Mars."}, {"time": 4907, "text": "Because and I've actually seen the interview with the Italian who's involved in designing what the future colony will look like."}, {"time": 4914, "text": "He was actually asked this question, can there be enormous inequality in Martian civilization?"}, {"time": 4920, "text": "The guy said, absolutely not."}, {"time": 4922, "text": "Because the resources, again, resource constraint applies."}, {"time": 4926, "text": "You simply can't give somebody underground bunker 100 times the size of somebody else's 100 underground bunker."}, {"time": 4934, "text": "Because the scarcity of resources imposes a need for equality overall."}, {"time": 4942, "text": "Is that always?"}, {"time": 4944, "text": "I mean, the scarcity of resources, wait, but I feel like that's a contradiction."}, {"time": 4948, "text": "I thought."}, {"time": 4949, "text": "Are you thinking neoclassical about scarcity?"}, {"time": 4952, "text": "I'm barely thinking at all."}, {"time": 4957, "text": "So wait, I thought scarcity, the best way to build on top of scarcity is a capitalist type of machine."}, {"time": 4965, "text": "No, this is where, again, our vision of what scarcity is, is wrong."}, {"time": 4970, "text": "Because and Ricardo said this, but it's actually better than Marx."}, {"time": 4974, "text": "Because Ricardo said, there are some products whose value is determined entirely by their scarcity."}, {"time": 4982, "text": "Paintings, rare wines, et cetera, et cetera, they are things you cannot reproduce in a factory."}, {"time": 4989, "text": "He said, the essence of capitalism is what you can make in a factory."}, {"time": 4992, "text": "And therefore, for these unique objects, these rare objects, Picasso painting a beautiful bottle of wine, et cetera, et cetera, then the utility, it can't be reproduced easily."}, {"time": 5005, "text": "So its price will be determined by subjective valuation."}, {"time": 5008, "text": "He said, what we're talking about in capitalism is the stuff you can make en masse."}, {"time": 5013, "text": "And that is the true focus of the capitalist economy."}, {"time": 5017, "text": "And that is not about scarcity."}, {"time": 5019, "text": "That is about, the only scarcity applies when you don't have the resources to make them anymore or you can't use the energy involved because you'll damage the biosphere too much, which we've already done."}, {"time": 5030, "text": "But fundamentally, the scarcity that neoclassicals have been able to think about and Austrians think about as well is nonreproducible."}, {"time": 5039, "text": "But the essence of capitalism is the commodity, the backscratcher, the two buck backscratcher, anybody can, you know, the cheapest chips to make, and that's why it can make a profit out of them."}, {"time": 5049, "text": "Not the elaborate gold thing with diamonds and rubies that only the king gets."}, {"time": 5053, "text": "So we think our vision of scarcity has been perverted by neoclassicals analyzing the exception to capitalism and calling it capitalism."}, {"time": 5064, "text": "So, you know, let's put Mars aside because I think there's a lot of strange factors that have to do with a whole nother planet, civilization, that we don't quite understand."}, {"time": 5077, "text": "Think how economics works with different geographic locations, one of which have new challenges, which is what essentially this is."}, {"time": 5088, "text": "I don't know if you can apply the same economic theory."}, {"time": 5090, "text": "No, I'm saying your question, I think we'll be forced into that ultimately by having to make a compromise with the ecology."}, {"time": 5098, "text": "And we've been ruthless about the ecology of this planet, and we're going to pay the price for it."}, {"time": 5103, "text": "So if you have a planet where you can't be ruthless, okay, you have to mind it as carefully as possible, then that utopian might be imposed upon you for the needs for survival on that planet."}, {"time": 5120, "text": "Back here, Marx's utopia was still the one that ignored the ecology."}, {"time": 5125, "text": "And I think if I have a vision of a utopia in future, it's got bugger all to do about what humans get out of it."}, {"time": 5134, "text": "It's what humans respect."}, {"time": 5136, "text": "They have to respect life."}, {"time": 5138, "text": "So I see that as a one eyed utopia, a utopia for a single species, as if it can exist on its own, which we should know it can't."}, {"time": 5147, "text": "Quick bathroom break?"}, {"time": 5151, "text": "We took a little bit of a break and now we're back."}, {"time": 5154, "text": "We needed to take a break because my brain broke and I'm piecing it back together."}, {"time": 5158, "text": "You mentioned ecology and life and the value of all of that."}, {"time": 5162, "text": "We'll return to it if we can."}, {"time": 5165, "text": "But first, we said why this kind of, this idea of why socialism failed, can we linger on this a little bit longer in how did the ideas of Karl Marx lead to Stalinism?"}, {"time": 5183, "text": "So this particular implementation, is there something fundamental to these ideas that leads to a dictator and that leads to atrocities?"}, {"time": 5196, "text": "There's something about the mechanism of the bureaucracy that's built that leads to a human being that's able to attain, integrate absolute power and then start abusing that power?"}, {"time": 5214, "text": "Like some of the history of the 20th century, is that inextricably connected to the ideas of Karl Marx?"}, {"time": 5221, "text": "I think to some extent it is, but I'm going to also say that if it hadn't been for the Bolsheviks interpreting Marx and saying we can reach socialism without going through capitalism, then it might not have happened."}, {"time": 5235, "text": "So if you look at the, like the Mensheviks were a rival political group in Russia and that's where Hyman Minsky, who's a huge inspiration for me."}, {"time": 5244, "text": "So he's an economist who was maybe, can we take a little attention, who was Hyman Minsky?"}, {"time": 5250, "text": "Hyman Minsky was the person who developed an analysis of capitalism based on financial instability."}, {"time": 5258, "text": "And he was actually the PhD student of Joseph Schumpeter and an Austrian economist as well whose name I've forgotten temporarily."}, {"time": 5268, "text": "And he asked him, his parents were both refugees from Russia during the Stalinist period because the Mensheviks were being wiped out in Russia, just like any other opponents to the Bolsheviks were being eliminated."}, {"time": 5286, "text": "So I think his parents met in Chicago, still remain socialist, still remain politically active, and he was educated in a family that was just imbued with Marx as his vision."}, {"time": 5300, "text": "He ended up fighting in the Second World War on the American side, coming back to America and studying mathematics and then also doing an economics degree leading to a PhD."}, {"time": 5314, "text": "And the question he posed for himself is what causes Great Depressions?"}, {"time": 5319, "text": "And he put it beautifully, he said, can it happen again, it being the Great Depression?"}, {"time": 5324, "text": "And if it can't happen, then what has changed between the society before the First and Second World War and after that makes a depression impossible?"}, {"time": 5334, "text": "What's the answer to those two questions?"}, {"time": 5336, "text": "Can it happen again?"}, {"time": 5337, "text": "His answer was yes, it can happen again, but what has prevented it happening by the time he started writing about it, which was the late 50s to the mid 80s, late 80s."}, {"time": 5350, "text": "We met once, but only once."}, {"time": 5351, "text": "Over a beer?"}, {"time": 5354, "text": "No, he gave a seminar at New South Uni and he's a bit of an obstreperous bastard."}, {"time": 5359, "text": "A stripper?"}, {"time": 5360, "text": "Obstreperous."}, {"time": 5363, "text": "It means argumentative and likely to dismiss you."}, {"time": 5366, "text": "So like a good mate of mine was the guy who brought him out to Australia, a guy called Graham White."}, {"time": 5371, "text": "We're still good mates."}, {"time": 5373, "text": "I love your language and your accent."}, {"time": 5375, "text": "It's a great... Actually, there's a really good TikTok I saw earlier today with an Aboriginal guy saying he loves the Australian language because it's absolutely ironic."}, {"time": 5383, "text": "You ask an Australian a question and he'll give you an answer, which is the opposite of what he means, and you've got to work out the rest for yourself."}, {"time": 5391, "text": "So he goes up to another Aboriginal mate and says, G'day, mate."}, {"time": 5393, "text": "He says, how are you?"}, {"time": 5394, "text": "Oh, not bad."}, {"time": 5395, "text": "What have you been doing recently?"}, {"time": 5396, "text": "Oh, not much."}, {"time": 5397, "text": "When are we going?"}, {"time": 5398, "text": "Not too far?"}, {"time": 5399, "text": "Not too soon?"}, {"time": 5402, "text": "Oh, not too far away?"}, {"time": 5404, "text": "All negatives."}, {"time": 5405, "text": "And he's a beautiful, beautiful rendition."}, {"time": 5408, "text": "Yeah, that's the cool thing about the internet culture."}, {"time": 5410, "text": "They appreciate that ironic side."}, {"time": 5413, "text": "Like for example, the best compliment you can give as an Aboriginal to somebody else is that's deadly."}, {"time": 5419, "text": "That's a compliment."}, {"time": 5423, "text": "I've got another mate of mine and this comes to the Australian language."}, {"time": 5424, "text": "If I call you a bastard, that's a compliment."}, {"time": 5427, "text": "Depending on how I insinuate the word bastard."}, {"time": 5435, "text": "And there's something, unfortunately, there's something about the British accent that makes people sound maybe brilliant, maybe sophisticated, wise."}, {"time": 5447, "text": "But actually pompous."}, {"time": 5449, "text": "No, that's unfortunately the downside of that is you can sound pompous."}, {"time": 5455, "text": "There's something about the Australian accent that you just can't sound brilliant."}, {"time": 5463, "text": "It humbles you."}, {"time": 5464, "text": "You sound like you're having a lot of fun."}, {"time": 5466, "text": "There's wit."}, {"time": 5467, "text": "There's all that good stuff."}, {"time": 5470, "text": "But you just can't be like Karl Marx in an Australian accent would just not come off."}, {"time": 5473, "text": "That is a very good point."}, {"time": 5474, "text": "He would not be able to pull off the beard."}, {"time": 5476, "text": "That's like, yeah."}, {"time": 5477, "text": "I mean, I just, yeah."}, {"time": 5478, "text": "It's fascinating that the accent determines something about the person."}, {"time": 5485, "text": "Maybe it's the chicken and the egg too."}, {"time": 5487, "text": "It drives the way of the discourse."}, {"time": 5489, "text": "Obviously there's a lot of brilliance."}, {"time": 5490, "text": "There's a lot of brilliance in your work, but it sounds like you're always having fun."}, {"time": 5494, "text": "And look, this, Pat Poncho has got a lot of Australian mates here."}, {"time": 5499, "text": "He spent, what about, how long in Australia?"}, {"time": 5501, "text": "Year and a half."}, {"time": 5503, "text": "And he's got all these mates here who play Aussie rules football in Austin."}, {"time": 5506, "text": "You should join them one day."}, {"time": 5508, "text": "It's actually, it's a very creative sport."}, {"time": 5510, "text": "It's much more fun."}, {"time": 5511, "text": "It's different than rugby?"}, {"time": 5512, "text": "Oh, very."}, {"time": 5513, "text": "Rugby is hopeless."}, {"time": 5514, "text": "Rugby is two morons smashing their bodies against each other."}, {"time": 5522, "text": "We did not mean to offend the rugby fans in the audience."}, {"time": 5525, "text": "What's, so it's too simplistic."}, {"time": 5527, "text": "It's too simplistic."}, {"time": 5529, "text": "It's, I mean, there's skill in it."}, {"time": 5530, "text": "I've seen some really skillful rugby union and rugby league players in my day."}, {"time": 5535, "text": "But it, fundamentally, if you hit somebody hard enough, they go down."}, {"time": 5540, "text": "Whereas in Aussie rules, it's about catching the ball and then kicking the ball and pass."}, {"time": 5543, "text": "More skill, less pass."}, {"time": 5544, "text": "More skill."}, {"time": 5545, "text": "And it's, and the bodies of the athletes, I can actually get off and measure what a sport is like by the bodies it creates."}, {"time": 5553, "text": "And you get these incredibly elegant lithe muscular forms out of Aussie rules."}, {"time": 5559, "text": "Such beautiful words you have in your vocabulary, lithe, I don't even know."}, {"time": 5562, "text": "But I'll assume you know what it means and maybe somebody in the audience."}, {"time": 5568, "text": "So, all right, fine, fine."}, {"time": 5571, "text": "We should also mention that you, in your youth, you know, like last year, have had Olympic weightlifting as part of your life."}, {"time": 5581, "text": "So you're... A long time ago."}, {"time": 5583, "text": "And like you said, tennis."}, {"time": 5584, "text": "I also played tennis for many, many, many, many years."}, {"time": 5588, "text": "It's a fascinating game."}, {"time": 5589, "text": "It's a wonderful game."}, {"time": 5591, "text": "That's my favorite game."}, {"time": 5595, "text": "Karl Marx and Stalin."}, {"time": 5598, "text": "So how do we get onto Aussie football in Australia and the accent?"}, {"time": 5602, "text": "I'm not really sure you talked about the way I said something about Karl Marx and with Karl Marx."}, {"time": 5608, "text": "Anyway, we got there."}, {"time": 5610, "text": "We got there and now we return."}, {"time": 5611, "text": "But back to Marx."}, {"time": 5613, "text": "It's not the destination."}, {"time": 5614, "text": "It's the journey."}, {"time": 5615, "text": "I think Marx, the failure of socialism with Janos Kornei captured beautifully."}, {"time": 5620, "text": "This idea already called demand constrained versus resource constrained economies."}, {"time": 5624, "text": "And capitalism is demand constrained."}, {"time": 5628, "text": "And this is, again, where neoclassical theory is completely wrong, empirically completely wrong."}, {"time": 5633, "text": "So the neoclassicals have a vision of capitalism being resource constrained, and it's about maximizing your usage of resources subject to constraints."}, {"time": 5642, "text": "And as Kornei said, that's really what happened to socialism."}, {"time": 5645, "text": "What happens under capitalism is that you have 15, 20 companies producing automobiles."}, {"time": 5652, "text": "They are all trying to capture as much of the market as they can."}, {"time": 5655, "text": "If you add up their marketing plans, you're going to get 120, 130% of the actual market."}, {"time": 5660, "text": "So they're all going to have excess capacity."}, {"time": 5663, "text": "When you build a factory, you're building it with a plan for it to exist for five, 10, 15 years."}, {"time": 5668, "text": "You have to have excess capacity in the factory."}, {"time": 5670, "text": "So that means that capitalism has far greater productive capacity than it actually uses."}, {"time": 5675, "text": "And then the way that you manage to get demand into your factories to innovate and produce something nobody else does, or you're producing in volume and when somebody produces like a bung tire, comes out of Firestone, then Goodyear is ready to expand its production and take advantage of that."}, {"time": 5690, "text": "So that's the actual nature of competition in capitalism."}, {"time": 5694, "text": "And that means that we get a cornucopia of goods, even if we're lowly workers."}, {"time": 5699, "text": "The variety of goods in capitalism is overwhelming, and that just doesn't happen in socialism."}, {"time": 5705, "text": "You get your 1942 Cossack as your motorbike, that's it."}, {"time": 5709, "text": "When you put your money down to buy a refrigerator, it'll arrive in 10 years because the factory's already fully constrained."}, {"time": 5715, "text": "So all these resource constraints mean that people aren't happy under socialism."}, {"time": 5721, "text": "And if you've got a whole bunch of people that aren't happy, then the best way to control them is to suppress them."}, {"time": 5729, "text": "So I think in that sense, ultimately, yes, it does lead to something like Stalinism."}, {"time": 5733, "text": "So it's easier to give happy people freedom."}, {"time": 5736, "text": "Yeah, I mean, happy people get pretty silly outside."}, {"time": 5739, "text": "I'm not particularly, the extent to which Americans overuse and distort the word freedom drives me balmy."}, {"time": 5747, "text": "All of these words can be distorted, but they all, at the core, have some fundamental power and beauty, and then we just distort on the surface for the fun of it, just to start battles on Twitter and so on."}, {"time": 5759, "text": "But what citizens of the Soviet world didn't feel was freedom."}, {"time": 5762, "text": "Not just in, first of all, it wasn't freedom to buy commodities."}, {"time": 5766, "text": "The commodities that were supposed to be on the shops weren't there."}, {"time": 5769, "text": "The volume couldn't be produced."}, {"time": 5771, "text": "And what you then got out of that as well was the classic Soviet joke, they pretend to pay us and we pretend to work."}, {"time": 5778, "text": "Yeah, so you're not motivated."}, {"time": 5780, "text": "Oh, look, I went to Cuba about eight years ago, invited to give a talk there."}, {"time": 5786, "text": "And staying in a hotel itself, the hotel's a story."}, {"time": 5788, "text": "There was one day my meetings were canceled, so I thought I might go down to the beach."}, {"time": 5793, "text": "And in the hotel, they had a wing, which is the tourist office, and there were three women working inside the office."}, {"time": 5799, "text": "So I thought I'd just go up and ask them, you know, how do I get to the beach?"}, {"time": 5802, "text": "And one of them says to me, and I stood there, just stood in the room, waiting to see if they'd make eye contact with me."}, {"time": 5810, "text": "Three women, nobody else in the place."}, {"time": 5812, "text": "None of them looked at me."}, {"time": 5813, "text": "So I finally went up to one of them and said, I want to go to the beach and do some surfing work."}, {"time": 5818, "text": "She said, I can get a taxi outside."}, {"time": 5819, "text": "Now, fundamentally, she was saying, well, I'm being paid shit money here, I don't want to work, I'm not going to do anything apart from sit here and qualify for my time."}, {"time": 5833, "text": "And as much as there are reasons the Cubans have suffered from American embargoes and all that sort of stuff, you've still got that fundamental shortage economy that Cornet spoke about coming out of the structure of central ownership and central control of distribution and investment."}, {"time": 5848, "text": "It breaks my heart because I think some of the effects of that persist throughout time."}, {"time": 5855, "text": "It become part of the culture too."}, {"time": 5859, "text": "Negative culture."}, {"time": 5862, "text": "Well, from the Western perspective."}, {"time": 5863, "text": "Well, even from the people living through it."}, {"time": 5864, "text": "I mean, I had enough conversation with Cubans, you know, meeting them on the street, hopping in a cab."}, {"time": 5870, "text": "There was one guy I was talking to, he was an industrial chemist and he'd got a bit of money being a cab driver because he could make money out of taking foreign tourists from the airport to the city."}, {"time": 5881, "text": "By the way, this episode is brought to you by delicious Coca Cola."}, {"time": 5886, "text": "That's why I didn't want to have it on camera, but anyway."}, {"time": 5890, "text": "No, maybe they'll actually sponsor."}, {"time": 5892, "text": "You want to make sure you rotate the label to show, this is capitalism."}, {"time": 5898, "text": "Even though it's red."}, {"time": 5899, "text": "Red and black is actually anarchist."}, {"time": 5904, "text": "I should tell you, I don't know if you know who Michael Malice is."}, {"time": 5907, "text": "Michael."}, {"time": 5909, "text": "He's an anarchist and he lives next door."}, {"time": 5910, "text": "Does he?"}, {"time": 5912, "text": "Now, I've lost touch with anarchist philosophy."}, {"time": 5914, "text": "I actually used to read, you know, Kropotkin and Bakunin and so on, and I enjoyed their philosophy and then I helped organize an anarchist conference once, and that was the biggest antidote possible to being an anarchist."}, {"time": 5928, "text": "That sounds like an entry point to a joke, helped to organize an anarchist party."}, {"time": 5934, "text": "I mean, we literally spent three days arguing over whether there should or should not be a chairperson for conversations."}, {"time": 5942, "text": "Well, that may be that."}, {"time": 5947, "text": "Monty Python's Life of Brian lived out live."}, {"time": 5952, "text": "Look at the bright side of life."}, {"time": 5956, "text": "So part of that explains why, for example, even to this day, in some of those parts of the world, entrepreneurship does not flourish."}, {"time": 5966, "text": "There's not a spirit in the people to start businesses, to launch new endeavors and all those kinds of things."}, {"time": 5973, "text": "We're just taking all kinds of strange little strolls, but how do you explain the mechanisms of China today, where there's quite a bit of sort of flourishing of businesses and so on?"}, {"time": 5988, "text": "It's a very peculiar kind of entrepreneurship."}, {"time": 5991, "text": "They got away from central control, but they still manage central political control, but diversified economic control."}, {"time": 5999, "text": "So you could, it is possible to draw a line between politics and economics."}, {"time": 6003, "text": "It is possible, and I think in some ways, China's more likely to survive as a society going into the future than Western capitalist societies are."}, {"time": 6012, "text": "So it's like, if we do the Karl Marx, the foreground and the background, you can centralize the politics, the humanity, the subjective stuff, and then distribute the objective stuff."}, {"time": 6031, "text": "You've got to have the goods, and the big change from Mao Zedong Xiaoping was the characterizing that little saying that I don't care whether you have a black cat or a white cat, so long as it catches mice."}, {"time": 6044, "text": "And there was a level of pragmatism to the Deng Xiaoping revolution over Mao and Madame Mao in particular, and that was manifest in the desire to get as much of those Western goods as possible."}, {"time": 6086, "text": "And that gives you an idea of the reduction in wages these American corporations were looking at."}, {"time": 6091, "text": "They'd shut down the factory in what's now the Rust Belt of America that might be paying somebody there at that time maybe $2 an hour, and they come across to China and they're paying two cents an hour."}, {"time": 6103, "text": "So the enormous amount of wages that they dropped, they were willing to forego half the profits and the ownership of the firm."}, {"time": 6112, "text": "So what the Chinese were doing wasn't just exploiting their labor force, it was also building a capitalist class, and that meant that you had this, that's where all the Chinese corporations have come from."}, {"time": 6124, "text": "So they were building a capitalist system within a socialist command political system, and that worked, and it's still working."}, {"time": 6134, "text": "So there was the centralization of the economic stuff, the Gosplan approach."}, {"time": 6138, "text": "I think that was where the Soviets failed."}, {"time": 6141, "text": "And what the Chinese realized after what they went through under Mao was you have to have that capitalist period, but they weren't going to abandon the communist control politically of the country at the same time."}, {"time": 6153, "text": "And that worked out brilliantly, and there's a huge amount of innovation taking place in China today."}, {"time": 6158, "text": "And they also will do gigantic infrastructure projects, breathtaking planning going into that."}, {"time": 6165, "text": "You would have seen videos of building a skyscraper in a day."}, {"time": 6169, "text": "The planning that has to go into that, the pre preparation that's necessary is enormous."}, {"time": 6174, "text": "So there's a real respect for engineers as well in that society, which does not apply on the West."}, {"time": 6178, "text": "What do you think about, from the Western perspective, the destructive effects of centralized control of the populace, of the ideas of the discourse, of the censorship and the surveillance, all those kinds of things?"}, {"time": 6190, "text": "It's a bit like we were talking about Russia to some extent beforehand, with centralized versus decentralized corruption."}, {"time": 6201, "text": "And when you had the centralized political stuff, it means you know you can't criticize within China."}, {"time": 6208, "text": "But so long as you don't criticize, you can do what you like."}, {"time": 6211, "text": "And how destructive is that to the human spirit?"}, {"time": 6215, "text": "From the American perspective, that feels destructive."}, {"time": 6219, "text": "I've been to China quite a few times over my life, a lot in the last, not for about four years, but for the six years before that, a few visits."}, {"time": 6228, "text": "And staying in second and third and fourth tier cities, so populations of only four million people, which is quite small on Chinese standards."}, {"time": 6239, "text": "And I had a lot of happy people that I was interacting with."}, {"time": 6242, "text": "My girlfriend at the time, her social circle."}, {"time": 6246, "text": "And you can feel when people can't discuss a political issue."}, {"time": 6249, "text": "For example, in Thailand, you can't discuss the king."}, {"time": 6253, "text": "They still have, you know, les majestes laws, so you can actually be jailed for discussing the king."}, {"time": 6259, "text": "And you can feel that to some extent, and it is a political issue in Thailand now."}, {"time": 6264, "text": "But in China, what I got back from most people, it was a bit like a benevolent big brother."}, {"time": 6271, "text": "But then when you get things out like the lockdown, which was applied recently, then you get the failings of the Soviet system is still there in the Chinese system."}, {"time": 6280, "text": "In that, the easiest way to avoid criticism as an underling carrying out instructions of people above you is to carry those instructions out to the letter beyond what the people actually want you to do at the top."}, {"time": 6296, "text": "So we had a classic illustration of that when I took these journalists."}, {"time": 6300, "text": "There was a news report saying that China's output of light industry had grown by 17 percent in the previous year, but heavy industry had fallen by 7 percent."}, {"time": 6310, "text": "We just don't compute."}, {"time": 6312, "text": "So we kept on asking, why did this happen?"}, {"time": 6314, "text": "Every time we asked a question, this is back in 1981, the answer would be the initial answer, we followed the directive of the Central Committee of the Communist Party of China."}, {"time": 6323, "text": "We finally got a guy to elaborate and say what that was."}, {"time": 6326, "text": "He said, well, the Central Committee sent out a directive to promote light industry."}, {"time": 6330, "text": "So what did you do?"}, {"time": 6331, "text": "Quote unquote, we stripped heavy industry factories and turned them into light industry."}, {"time": 6337, "text": "Now that's destructive of everything."}, {"time": 6340, "text": "And that's the overlay that you've still got sitting over the top of China."}, {"time": 6344, "text": "But a huge part of the industrialization was simply saying, produce whatever you can, make goods, market them, sell them."}, {"time": 6353, "text": "And you get that innovative component of humanity is respected and the goods turn up and everybody's well fed."}, {"time": 6360, "text": "Food in Russia is far better than food in America."}, {"time": 6364, "text": "So in terms of material satisfaction and freedom, for example, enjoy dancing."}, {"time": 6372, "text": "We went to, I think, somewhere in Shanghai, and there's this line of people involving a woman who would have been close to her 90s and a kid who was about six or four."}, {"time": 6384, "text": "Partying it up?"}, {"time": 6385, "text": "Partying it up in the open air and doing this Chinese collective dance."}, {"time": 6387, "text": "You have to be really careful about that kind of thing."}, {"time": 6391, "text": "So in terms of measuring the flourishing of a people by looking at their happiness, I have so many thoughts on this, but I'm imagining North Korea."}, {"time": 6408, "text": "And if you talk to people in North Korea, I think they would say they're happy."}, {"time": 6416, "text": "Well, let me try to complete this argument, not an argument, but a sort of challenge to your thought, which especially in the bigger cities, because they don't know the alternative."}, {"time": 6432, "text": "So what else do you need?"}, {"time": 6434, "text": "There's enough food on the table."}, {"time": 6436, "text": "We have a leader that loves us and we love him."}, {"time": 6442, "text": "Our hearts are full of love."}, {"time": 6444, "text": "Our table is full of food, they would say, because it's enough food."}, {"time": 6453, "text": "What else do you want from life?"}, {"time": 6454, "text": "No, I think, okay, like that's..."}, {"time": 6456, "text": "So let me sort of chat, because like... That's an alternative."}, {"time": 6459, "text": "I mean, I've spent time in Romania."}, {"time": 6461, "text": "So let me sort of complete that, sorry."}, {"time": 6464, "text": "Because I'm taking the most challenging aspect."}, {"time": 6467, "text": "When there's centralized control of information, that you don't know the alternative, that you don't know how green the grass is on the other side."}, {"time": 6477, "text": "And so your idea of happiness might be very constrained."}, {"time": 6480, "text": "So you could also argue that is happiness, if you don't know."}, {"time": 6486, "text": "Ignorance is bliss."}, {"time": 6488, "text": "And then so is happiness really the correct measure for the flourishing?"}, {"time": 6494, "text": "But I mean, there's actually a classic book, a movie as well, called Mao's Last Dancer."}, {"time": 6502, "text": "And that is a young man explaining his progression from being a dancer in the Cultural Revolution through to a leading dancer in American and ultimately Australian ballet."}, {"time": 6513, "text": "And he explicitly says at one point that he's told that the Chinese people have the highest standard of living in the world."}, {"time": 6521, "text": "And the reaction of him and his kids, like his fellow six year olds, is, God, it must be miserable elsewhere in the world then."}, {"time": 6527, "text": "So they knew."}, {"time": 6528, "text": "They still know."}, {"time": 6530, "text": "There's no such thing as that complete ignorance."}, {"time": 6532, "text": "But what I'm talking about is experiences in China say back in about 2016, 2014, there was a feeling of freedom within limits that you didn't want to transgress because the system was working."}, {"time": 6549, "text": "So if you like, it's kind of like marriage, it's kind of like marriage, hey, that's a good example."}, {"time": 6556, "text": "You can have fun within those limits."}, {"time": 6560, "text": "And people did have fun and they did feel free, but they didn't want to go and get divorced."}, {"time": 6564, "text": "But that dilemma was accommodated because the boundaries, until you started hitting restrictions were wide."}, {"time": 6573, "text": "And like when you look at it, I mean, look at the, again, with the Chinese Communist Party, the administrators of that are often highly qualified engineers who can then make intelligent decisions about what should be done as infrastructure and so on."}, {"time": 6587, "text": "And you go to China and you've got incredible high speed rail, fantastic infrastructure, internet, telecommunications and so on, rapidly evolving solar."}, {"time": 6599, "text": "There's a range of things there that are so well done that reflect the fact that the selection process that gives you your political elite is partially focused upon sucking up, et cetera, et cetera."}, {"time": 6612, "text": "It's still there, but it's also focused upon your skill levels."}, {"time": 6616, "text": "And you get people making decisions who damn well know what they're talking about."}, {"time": 6620, "text": "Like Australia's got a classic example, the internet in Australia sucks."}, {"time": 6625, "text": "The reason it sucks is that the Labour Party, which is our version of the Democrats, was in control during the global financial crisis."}, {"time": 6634, "text": "And as part of that, they wanted to bring in optical fiber connections to the house."}, {"time": 6641, "text": "So you'd have an optical fiber backbone and an optical fiber right to your T100 output from your home."}, {"time": 6649, "text": "And the Liberal Party fought that and said, that's going to be too expensive, it'd take too long to do."}, {"time": 6655, "text": "We're going to do cable to the node and then have a copper network linking from a node on a street to all the houses in the street."}, {"time": 6663, "text": "It's going to be cheaper and faster, have it more soon, blah, blah, blah."}, {"time": 6667, "text": "It was a total technical fuck up."}, {"time": 6669, "text": "And Australia now has internet that's about 50 or 60 years fast in the world."}, {"time": 6673, "text": "It's dreadful for the internet."}, {"time": 6676, "text": "Two political figures made that decision, Tony Abbott and Malcolm Turnbull, rivals and leaders of the Conservative Party we call Liberal over there."}, {"time": 6687, "text": "Now that was shitty decisions that wouldn't happen in a country like China because you've got actual engineers making the decisions."}, {"time": 6696, "text": "They say you can't get decent speed if you link optical fiber to copper."}, {"time": 6702, "text": "So what you get is even though you can't make the decisions yourself, a vast majority of the decisions are made intelligently and therefore you expect it."}, {"time": 6712, "text": "It's interesting, but don't you worry about the corrupting aspects of power?"}, {"time": 6720, "text": "That you start, you know, you have engineers making intelligent decisions, but at which point does the fat king start saying, oh, these engineers are annoying."}, {"time": 6731, "text": "I have good internet."}, {"time": 6734, "text": "Bring me the grapes."}, {"time": 6735, "text": "Well, that's, you know, you get your colligular effects."}, {"time": 6739, "text": "Like Z from what I've seen has got elements of that."}, {"time": 6742, "text": "So friends of mine who are Caucasians can get away with it."}, {"time": 6746, "text": "They have a game that they play at conferences, scoring how often people use with Z's name in a presentation and giving extra points for the number of photographs of Z that turn up in the whole thing."}, {"time": 6756, "text": "So you've got this sort of personality cult coming along as well."}, {"time": 6760, "text": "But at the same time, the planning for the infrastructure that's being built, the social services, the general freedom that exists is so great."}, {"time": 6770, "text": "And like any Chinese person alive today, like somebody who's Chinese my age, would have been an adult under the early period of, the late period of Mao."}, {"time": 6782, "text": "And God almighty, the change, the improvement they've seen in their lives, that's what they think about."}, {"time": 6787, "text": "But it's the, if you just look at the history of the 20th century, your intuition would say that some of the mechanisms we see in China now will get you into trouble in the long term."}, {"time": 6799, "text": "So it seems to be working really well in many ways in terms of improving the quality of life of the average citizen in China, but you start to get worried about how does this go wrong?"}, {"time": 6812, "text": "But at the same time, maybe, I mean, often people will say, you know, what's your vision for the future?"}, {"time": 6816, "text": "And what they mean is what vision for the future do you have that I'm going to like?"}, {"time": 6822, "text": "What if you have a vision of the future that you don't like?"}, {"time": 6825, "text": "It's dreadful."}, {"time": 6826, "text": "I mean, that's the ecological crisis I think we're walking blindfolded into."}, {"time": 6834, "text": "That part of the picture we'll have to talk about how fundamental of a problem that is."}, {"time": 6841, "text": "But what does that have to do with the future of China?"}, {"time": 6842, "text": "What it has to do is that if you wish to impose dramatic controls on the consumption of the rich, which would be necessary to reduce our consumption burden so that we can get closer to the ecological envelope we've destroyed already, then you're going to make more likely successful doing that with a centralized system where people accept centralized political control."}, {"time": 6865, "text": "Then you're in a country where it's all diversified and you scream freedom between every point in a tennis match."}, {"time": 6870, "text": "And I've literally seen that when I was in Philadelphia some time back."}, {"time": 6875, "text": "So the ideology that accepts a collectivist attitude may be more successful in controlling our reducing human consumption levels."}, {"time": 6884, "text": "Because when we talk about democracy, I mean, who's voting here?"}, {"time": 6889, "text": "How many horses and elephants and birds get to vote?"}, {"time": 6896, "text": "It's very... What's a bird?"}, {"time": 6899, "text": "You don't see them around here."}, {"time": 6901, "text": "It's a very human centric vision we have of this planet."}, {"time": 6904, "text": "And we're going to pay a price for that."}, {"time": 6908, "text": "So you're saying to deal with global catastrophic events, centralized planning might be..."}, {"time": 6914, "text": "I think will work better, period."}, {"time": 6918, "text": "But there is some centralized stuff in the United States, for example."}, {"time": 6922, "text": "Oh, your military."}, {"time": 6927, "text": "Now there's that feisty Australian."}, {"time": 6931, "text": "So besides the military, that's the ideal of the federal government in the United States is that there is some centralized infrastructure building."}, {"time": 6940, "text": "There's some big..."}, {"time": 6941, "text": "There's not enough of it, yeah."}, {"time": 6943, "text": "But there's some."}, {"time": 6945, "text": "The question is, when you deal with greater and greater global catastrophic events, like the pandemic that we're just living through, that the government would be able to step up and impose enough centralized planning to allow us to deal, sort of enable, empower the citizenry to deal with these catastrophic events."}, {"time": 6964, "text": "In the case of the pandemic, a lot of people argue that the, first of all, the world, but also the United States failed to effectively deal with the pandemic."}, {"time": 6975, "text": "On the medical side, on the social side, on the financial side, the supply chain, everything."}, {"time": 6981, "text": "In terms of communication, in terms of inspiring the populace with the power of science and all the fronts."}, {"time": 6991, "text": "They failed."}, {"time": 6992, "text": "But the ideal is that we'd be able to succeed."}, {"time": 6994, "text": "You would have to have a small, efficient, the ideal, the American ideal is you have a small, efficient government that's able to take on tasks precisely like the pandemic."}, {"time": 7003, "text": "But the thing is, maybe it shouldn't have been as small as it was."}, {"time": 7006, "text": "I mean, my favorite instance of that actually involves the UK because the whole neoliberal approach is about small, efficient government."}, {"time": 7014, "text": "Well, small, efficient government works when you face small, efficient challenges."}, {"time": 7018, "text": "When you face something systemic rather than episodic, then it's going to break down."}, {"time": 7023, "text": "And like this is, I mean, one of the things I greatly respect is Taleb's idea of antifragile."}, {"time": 7028, "text": "You want a society which is antifragile, not easily broken, whereas neoliberalism has pushed us towards this vision of efficiency, but it's easily snapped."}, {"time": 7036, "text": "Like in the UK, I've forgotten the government minister involved, but she was, she asked her expert committee, how many, this is before, well before the pandemic, how many masks should we have on hand in case of a pandemic?"}, {"time": 7051, "text": "And the answer from the experts was about a billion."}, {"time": 7054, "text": "That's 50 masks, that's 20 masks per person."}, {"time": 7058, "text": "Oh, that's too many."}, {"time": 7059, "text": "Let's just make 50 million masks."}, {"time": 7062, "text": "That's one mask per person."}, {"time": 7063, "text": "It was gone in a matter of a day."}, {"time": 7066, "text": "And therefore that's why they told us, well, masks don't work."}, {"time": 7068, "text": "You know, what they meant was we don't have enough masks for our health people, let alone for you and the public."}, {"time": 7074, "text": "So we're going to bullshit you and tell you those masks don't really work."}, {"time": 7078, "text": "And then people don't wear masks and then we've got enough masks, we rush up the production job."}, {"time": 7082, "text": "And by the time it comes along, people have got the skepticism about masks."}, {"time": 7085, "text": "So who does, can you elaborate, who does the blame in that case go on to?"}, {"time": 7090, "text": "The blame comes down to the philosophy that says government should always be small."}, {"time": 7093, "text": "No, but do you, do you really think that bigger government would be the solution to the mask issue?"}, {"time": 7100, "text": "So let me, let me push back."}, {"time": 7101, "text": "Sort of it's possible that that's capitalism solves that problem."}, {"time": 7104, "text": "Well, not, not if there's no money in really longterm planning and capitalism."}, {"time": 7111, "text": "There's money, there's money in the, isn't it possible to construct, isn't possible for capitalism to construct the system that ensures against catastrophic events?"}, {"time": 7122, "text": "Not when they're systemic, you can ensure against episodic events."}, {"time": 7127, "text": "If you occasionally have a really bad storm, but in general the weather's not so bad that all the infrastructure is being destroyed, then you can share that around on a percentage basis."}, {"time": 7137, "text": "If you have a Gaussian distribution for your events and you don't, the mean doesn't move around too much and the standard deviation doesn't change all that much, then insurance works fine."}, {"time": 7147, "text": "But if you have an, if that's episodic, if you have systemic stuff where the climate is changing completely and you're going to wipe out your agricultural capabilities, you simply can't do insurance on that front."}, {"time": 7160, "text": "You can't make a profit out of catastrophe and capitalism."}, {"time": 7165, "text": "So that example of climate change, let's talk about it."}, {"time": 7170, "text": "So you mentioned that the human brain, the economy, and the biosphere are three of the most complex systems we know."}, {"time": 7181, "text": "And you also criticize the economics community for looking at the effects of climate change when measured as the effect on the GDP."}, {"time": 7195, "text": "So you're saying it's a catastrophic thing that the biggest challenge our society, our world is facing."}, {"time": 7203, "text": "If the economists disagree with you, the effects on the GDP will be minor."}, {"time": 7210, "text": "So we'll deal with it when it comes."}, {"time": 7214, "text": "That's the argument against, that's the devil's advocate."}, {"time": 7216, "text": "You're saying, no, it is a thing that will change our world forever in ways that we should really, really, really be thinking about."}, {"time": 7227, "text": "Make the case of why you disagree with the economists."}, {"time": 7228, "text": "The case is simple."}, {"time": 7230, "text": "Economists have made up their own numbers to say that it's trivial."}, {"time": 7234, "text": "And you didn't."}, {"time": 7235, "text": "No, I haven't even tried to make the numbers."}, {"time": 7237, "text": "I'm reading what the scientists write."}, {"time": 7241, "text": "And what the economists have done, and like this is William Nordhaus in particular, Nobel Prize winner, ex president of the American Economic Association, literally assumed that a roof will protect you from climate change."}, {"time": 7252, "text": "And he didn't say it in those words."}, {"time": 7254, "text": "What he said was 87% of American industry occurs in carefully controlled environments, which will not be subject to climate change."}, {"time": 7262, "text": "Now the only things that all of manufacturing, all of services, he included mining as well, meaning about open cut mining, government activities, and the finance sector, all they have in common is they happen beneath a roof."}, {"time": 7276, "text": "So he's basically saying climate affects the weather, climate is weather."}, {"time": 7282, "text": "Now that is not at all what is meant by climate change."}, {"time": 7285, "text": "It's changing the entire pattern of the weather system of the planet."}, {"time": 7292, "text": "For example, the most extreme form of climate change would be a breakdown in the three circulation cells that exist in each hemisphere."}, {"time": 7299, "text": "The Hadley cell, the Ferrer cell, I think it's called, and the polar cell, 0 to 30, 30 to 60, 60 to 90, those are the main bubbles, if you like, in the atmosphere."}, {"time": 7310, "text": "Now if we get enough increase in the energy in the atmosphere, just like you turn the temperature up on a stove and you have nice bubbles occurring in a pot of soup and then turn the temperature up and they all break down and you've got bubbles everywhere, that's called the equitable climate."}, {"time": 7326, "text": "If that happens, then most of the rainfall is going to occur between 0 and 20 and 70 and 90, and the middle is going to be dry, except for extreme storms."}, {"time": 7338, "text": "We built our societies in a period of extreme stability of the climate, and when you look at the long term temperature records, it's up and down like a seesaw, like a sawtooth blade between, say, one degree warmer than now and four degrees or six degrees cooler over the last million years."}, {"time": 7359, "text": "When you look at where we evolved, it's just at a turning point on the peak of one of those ups and downs."}, {"time": 7364, "text": "I've forgotten the name of the cycles, but the cycles are caused by changes in the Earth's rotation around the sun, and so we evolved our civilization just at the top, so coming up from a cold period, and then we're going to head down to another cold period, and that's when human civilization came along."}, {"time": 7384, "text": "It's about a period of about 12,000 years."}, {"time": 7387, "text": "So across that period, the temperature has changed by not much more than half a degree up and down."}, {"time": 7392, "text": "Now, we're blasting it well and truly out of those confines, and my way of interpreting what climate change means is the stability of that climate that enables to build sedentary civilizations and not be a nomadic species is being destroyed."}, {"time": 7410, "text": "So the challenge, and by the way, I'm playing devil's advocate right here."}, {"time": 7418, "text": "The question is, is there something fundamentally different now about human civilization that we're able to build technology that alleviates some of the destructive effects that we have on the climate?"}, {"time": 7433, "text": "We're going to find out the hard way."}, {"time": 7436, "text": "And the uncertainty, you think, would be very costly."}, {"time": 7438, "text": "Extremely."}, {"time": 7439, "text": "Like, many of the trajectories we might take would be much more costly than they're profitable."}, {"time": 7446, "text": "And like, when we're seeing some of the storms that are happening now in Europe, the ones that washed away a village in Germany some time ago, the firestorm that hit Canada of all places, I've forgotten the name of the town that was burnt down, but enormous temperatures in Canada, again, the storms that have been happening back in Australia."}, {"time": 7464, "text": "These are all manifestations of a complete shift in the weather patterns of the planet."}, {"time": 7469, "text": "And they can wipe out, like a village just disappears, just wiped out by unprecedented rains, and this keeps on happening."}, {"time": 7479, "text": "We are still living in a sedentary lifestyle when we're a nomadic species."}, {"time": 7484, "text": "So to be able to maintain that sedentary lifestyle, we do need to engineer the planet."}, {"time": 7489, "text": "We need to keep it within that range of plus half a degree Celsius, minus half a degree, which is really what it's been like for the last 10,000, 12,000 years, instead we're blasting it right out of that range."}, {"time": 7503, "text": "And we know some of the past climates that have existed then."}, {"time": 7507, "text": "We can model what they imply for our food production systems, for example."}, {"time": 7512, "text": "Not the only example, but obviously crucial."}, {"time": 7515, "text": "So when you look at what are called global climate models produced by scientists, one of the examples, and it was published by the OECD last year, 2021, in the chapter on what would happen if we lose what's called the Atlantic Meridional Overturning Circulation, or AMOC, and people would colloquially know that as the Gulf Stream."}, {"time": 7535, "text": "And that's what distributes heat around all the oceans of the planet."}, {"time": 7539, "text": "It's part of a huge chain called the thermohaline circulation."}, {"time": 7543, "text": "But the part that goes across from the equator to the North Atlantic, that's called the AMOC and Gulf Stream colloquially, if that disappears in the context of a two and a half degree Celsius increase in average global temperature, then the proportion of the Earth's surface, which is suitable for producing wheat, will fall from 20% to 7%."}, {"time": 7569, "text": "Proportion for corn, similar sort of fall."}, {"time": 7571, "text": "The proportion suitable for rice will go from 2% to 3%."}, {"time": 7575, "text": "Now that means a catastrophic, and that's the word used in the report, catastrophic collapse in food production."}, {"time": 7582, "text": "So that's what we're toying with."}, {"time": 7584, "text": "And we are one and a half, we're actually less than, we're about halfway there to that two degrees, 2.5."}, {"time": 7592, "text": "And economists, on the other hand, and this is Richard Toll, published a paper 2016, claiming using what he calls an integrated assessment model that economists developed, that losing the Gulf Stream would increase global GDP by 1.1%."}, {"time": 7611, "text": "Now his model, this is what really pisses me off about these people, it's the worst work I've read in 50 years of being a critic of neoclassical economics."}, {"time": 7620, "text": "The GCMs, the one scientists produce, of course include precipitation as well as temperature."}, {"time": 7626, "text": "The IAMs that the economists produce, and this is stated yet again in a paper in 2021, do not include precipitation, they simply have temperature."}, {"time": 7637, "text": "So they assume that if temperature improves by moving towards a temperature which is better for producing aquaculture, okay, then so will precipitation."}, {"time": 7646, "text": "Now that's completely wrong, they've left out a crucial, imagine trying to model the climate while ignoring the fact that there's rainfall."}, {"time": 7653, "text": "That's what they've done."}, {"time": 7655, "text": "So their work is so bad, so dreadfully bad, it should never have been published."}, {"time": 7659, "text": "So they over, all right, all right, okay."}, {"time": 7660, "text": "I'm not gonna go for them, sorry, this is... Well, no, no, 100% as they deserve it, so it's an oversimplification, but I also want you to steel man people you disagree with and criticize people you agree with, if possible, to be sort of intellectually honest here."}, {"time": 7677, "text": "You do say, sort of to push back on the catastrophic thinking about climate change, that the ecology, the biosphere is a complex system, economics, the economy is a complex system."}, {"time": 7698, "text": "So how can we make predictions about complex systems?"}, {"time": 7702, "text": "How can we make a hope of having a semi confident predictions about the complex system?"}, {"time": 7708, "text": "So the scientific community is very confident about the complex system that is the biosphere and the crisis that's before us on the horizon."}, {"time": 7723, "text": "And then the economists are, as a community, I don't know, I don't know what percentage, but... Too much."}, {"time": 7729, "text": "Too much, that part of the community is very confident looking at the economics complex system in saying that, no, this system we have of labor and money and capital and so on, we'll be able to deal with that crisis and any other crisis."}, {"time": 7752, "text": "And they kind of construct simplified models that justify their confidence."}, {"time": 7759, "text": "So how do we know who to believe?"}, {"time": 7761, "text": "For a start, if you believe the economists, you need your head read."}, {"time": 7766, "text": "Because when you..."}, {"time": 7767, "text": "It's not an argument."}, {"time": 7768, "text": "No, it's not an argument."}, {"time": 7769, "text": "It's a summary of an argument."}, {"time": 7770, "text": "And that is the... No, that sounds a lot like an opinion and an emotional..."}, {"time": 7774, "text": "I'm so angry about it."}, {"time": 7775, "text": "Listen, I'll tell you where I stand."}, {"time": 7779, "text": "And I've begun looking, studying the climate change much more."}, {"time": 7784, "text": "I used to be on things I don't understand, have not spent time on."}, {"time": 7792, "text": "I have so many colleagues that are scientists that I deeply respect, and I trust their opinion."}, {"time": 7801, "text": "I have seen the lesser angels of my colleagues on the pandemic side, on the COVID side."}, {"time": 7812, "text": "The confidence, the arrogance that in part blinded, I believe, the jump between basic scientific research to public policy."}, {"time": 7825, "text": "And then, so I've become a little bit more cautious in my trust on climate change."}, {"time": 7832, "text": "I'm still in the same place, and I don't mean climate change, on anything scientists say."}, {"time": 7837, "text": "I become a little bit, wait a minute."}, {"time": 7844, "text": "How does the basic scientific facts of our reality map to what we should do as a human civilization?"}, {"time": 7851, "text": "There, I want to be a little bit careful."}, {"time": 7852, "text": "So whenever now I see arrogance and confidence, I become suspicious."}, {"time": 7857, "text": "Well, I'm the same, and that's why I'm being angry about The Economist, because there's incredible arrogance, incredible stupidity at the arrogance, assumptions which you look at it and think, how did anybody let that get published?"}, {"time": 7874, "text": "So the economic analysis of the effects of climate change are poor, in many cases."}, {"time": 7879, "text": "Incredibly poor."}, {"time": 7880, "text": "And this is like, Bjorn Lomborg styles himself as the skeptical environmentalist and criticizes the environmental models."}, {"time": 7888, "text": "He doesn't take a look."}, {"time": 7890, "text": "He doesn't criticize the work come out by economists."}, {"time": 7894, "text": "It's so bad."}, {"time": 7895, "text": "Is it possible to do good economics modeling of the effects of climate change?"}, {"time": 7899, "text": "Yeah, it is possible."}, {"time": 7903, "text": "Or is it like one complex systems tech?"}, {"time": 7905, "text": "It's two modes."}, {"time": 7906, "text": "In that case, yeah."}, {"time": 7907, "text": "I mean, like to me, what you should be looking at is saying, what are the scientists saying are the consequences, probable consequences, not guaranteed, but probable consequences of increasing the energy level of the atmosphere by the amount we're doing."}, {"time": 7923, "text": "What can the scientists say in terms of like, the effects, because it's so complicated, the effects of sort of shifting resources, so basically, what are the effects of climate change?"}, {"time": 7936, "text": "How can we really model that?"}, {"time": 7937, "text": "Because it's basically you're looking through the fog of uncertainty because they're rising sea levels."}, {"time": 7944, "text": "How can we know what effect that has?"}, {"time": 7946, "text": "Well, we know there'll be a lot of change."}, {"time": 7949, "text": "Well, I don't actually, I think the sea level one is a poor argument, and I don't focus on it."}, {"time": 7954, "text": "What I mainly focus upon is the weather patterns, okay?"}, {"time": 7958, "text": "And if you look at, like we've got the, the wheat belt in America goes through what Idaho and countries, places like that, and you've got an incredibly deep topsoil, like Ukraine is another classic example."}, {"time": 7969, "text": "The depth of the topsoil in Ukraine is remarkable, and that's the wheat bowl of Europe."}, {"time": 7975, "text": "And that requires both the right temperature for growing wheat and the right rainfall for growing wheat."}, {"time": 7981, "text": "Now, when you look at the models that climate scientists are building of that, you have pretty much, your ultimate foundation is the Lorenz model of turbulent flow."}, {"time": 7993, "text": "And of course, that's the first model which we saw chaos theory, complexity, that beautiful simple model, three variables, three parameters, an incredible complexity out of the system."}, {"time": 8005, "text": "But and what that meant was you also had an exponential decay in the accuracy of your model over time."}, {"time": 8012, "text": "So if you have, if you're accurate to a thousand decimal places, then in a thousand days, you'll have no data whatsoever, because each time you're losing an order of magnitude of accuracy."}, {"time": 8024, "text": "So that's the point about the inability to predict for the very long future."}, {"time": 8028, "text": "But what you can do is say, well, there's a prediction horizon."}, {"time": 8031, "text": "If we're close enough to the, if our statistical measurement of where we are is close enough to where we actually are, and our forecast horizon is narrow enough to not extrapolate too far, then for this direction forward, we can make a reasonable fist of predicting what the weather's going to be."}, {"time": 8048, "text": "And that's the foundation of meteorological, the stuff we watch on TV."}, {"time": 8052, "text": "You know, most of the time, the forecasts are going to be correct these days."}, {"time": 8056, "text": "40, 50 years ago, most of the time, the forecasts were wrong."}, {"time": 8060, "text": "So that's the background foundation to these GCMs."}, {"time": 8064, "text": "But even they've got to massively simplify the world."}, {"time": 8066, "text": "So you have this enormous sphere of where they might divide it down to 100 kilometer by 100 kilometer by 10 kilometer cube, rectangles, whatever, oblongs."}, {"time": 8080, "text": "That's how they're modeling the transition of where they're from one location to another."}, {"time": 8085, "text": "So they've got a chunky vision of the planet, which they have to."}, {"time": 8089, "text": "They can't model it now down to the last molecule."}, {"time": 8092, "text": "So you're losing it."}, {"time": 8094, "text": "It's getting better, better, better, better."}, {"time": 8096, "text": "I think that's just too much processing power."}, {"time": 8098, "text": "But you're going to have some confines."}, {"time": 8100, "text": "You can't go, I mean, if you look at the models to do the weather, they used to be of that 100 kilometer, I think they're about 10 kilometer grids now, I don't know."}, {"time": 8108, "text": "So the processing powers let us get more and more precise that way."}, {"time": 8111, "text": "I do know that the models now include chemical mixing that occurs above cities."}, {"time": 8116, "text": "They've added that complexity to them over time."}, {"time": 8119, "text": "So you're looking at the increasingly accurate models of weather patterns, the effect they have on agriculture, on food."}, {"time": 8125, "text": "And you're saying that there's a lot of possibilities in which that's going to be really destructive to society on the food production side."}, {"time": 8134, "text": "And if you have that increase in temperature, you're going to get a change in precipitation."}, {"time": 8138, "text": "And it could mean that where the rainfall and the sunshine are adequate for growing wheat is an area where there's no topsoil."}, {"time": 8145, "text": "Like a huge part of the models, the models the economists use, which only use temperature, don't include precipitation."}, {"time": 8151, "text": "They predict that a large amount of the wheat output of the world is going to occur in Siberia in the frozen tundra."}, {"time": 8160, "text": "What about, so that's a straightforward criticism of oversimplified models."}, {"time": 8165, "text": "What about the idea that we innovate our way out of it?"}, {"time": 8169, "text": "So there's totally new, what is the, there's a silly, poor example at this time perhaps, but lab grown meat, sort of engineered food."}, {"time": 8182, "text": "So a completely shifting source of food for civilization."}, {"time": 8190, "text": "So therefore alleviating some of the pressure on agriculture."}, {"time": 8193, "text": "That comes down to the difference that Elon makes between producing a prototype and mass producing the prototype."}, {"time": 8201, "text": "You can develop the idea very rapidly to put that into production on the scale that's necessary to replace what we're currently doing."}, {"time": 8211, "text": "And we haven't got years."}, {"time": 8212, "text": "We've got, we might have decades."}, {"time": 8213, "text": "We certainly haven't got centuries."}, {"time": 8216, "text": "So in the timeframe we've got, I can't see that engineering going from prototype to production levels to replace what we're currently doing in the stable environment they're currently destroying."}, {"time": 8228, "text": "What do you think about the sort of the catastrophic predictions that people that have thought have written about climate have made in the past that haven't come to people?"}, {"time": 8236, "text": "That's mainly unfortunately involving Paul Ehrlich and the population bomb and the predictions Paul was making."}, {"time": 8242, "text": "A few individuals or the one individual in that case."}, {"time": 8245, "text": "So I'm mostly playing devil's advocate in this conversation and enjoying doing so."}, {"time": 8251, "text": "I do think I'm in agreement with the majority of the scientific community."}, {"time": 8258, "text": "But you still see that argument made."}, {"time": 8260, "text": "I still see the argument made."}, {"time": 8262, "text": "And I also am a little bit worried about the arrogance and the ineffectiveness of the arrogance."}, {"time": 8267, "text": "This is the problem."}, {"time": 8268, "text": "It's ineffective."}, {"time": 8270, "text": "And that's what worries me because it's all been put into the sort of sea level rise, temperature changes."}, {"time": 8281, "text": "It's not put into the fragility of the system in which we currently live."}, {"time": 8288, "text": "And the Earth will survive."}, {"time": 8289, "text": "And there's a wonderful science fiction book called The Earth Abides about a world in which humans get wiped out."}, {"time": 8295, "text": "There's only a tiny little band left and then the Earth reasserts itself."}, {"time": 8299, "text": "So the Earth's going to survive us."}, {"time": 8300, "text": "Will we survive what we do to the Earth?"}, {"time": 8304, "text": "And my feeling is that we have underplayed the extent to which the civilizations were built have depended upon a relatively stable climate."}, {"time": 8316, "text": "And it's then there's that turning point in the global average temperature that we evolved right on the top of it."}, {"time": 8322, "text": "And if we had done nothing, we could find that heading back down towards another ice age could equally destroy the possibility of sedentary life."}, {"time": 8331, "text": "So for example, if we'd never developed fossil fuel based industries, we'd never built superphosphate, so our population would never have reached one billion people, and we were still living like fairly sophisticated animals, but like 17th century level of load on the planet, then we would have gone down that decline."}, {"time": 8352, "text": "And the approaching ice age would have started to wipe out our farming areas, the glaciers would have encroached, and we would have been driven out of like an agricultural sedentary civilization by that change."}, {"time": 8364, "text": "So it's just the fact that we evolved on this stable period in the overall temperature cycle of the planet."}, {"time": 8371, "text": "And that stability is something which just reflects the turning point in the regular cycle of Malicevich cycle, I think it's called."}, {"time": 8378, "text": "I've forgotten the actual name, but it's a cycle caused by change in the Earth's orbit around the sun, reflectivity and so on."}, {"time": 8388, "text": "That cycle, it's just that tiny top bit that we evolved in."}, {"time": 8393, "text": "So what we should have done is, well, that's really useful for us, we should stay at that level."}, {"time": 8397, "text": "Now, if we hadn't done it, we'd go back down here and that'd be the end of our civilization by an ice age."}, {"time": 8402, "text": "Instead, we're going up here really rapidly, and we're causing a change in temperature compared to that long term cycle 100,000 times faster."}, {"time": 8414, "text": "So yeah, I mean, my biggest worry is even subtle changes in climate might result in geopolitical pressures that then lead to nuclear war."}, {"time": 8428, "text": "And that's, yeah, I mean, there's an argument that's actually behind, to some extent, not the Ukraine war so much, but the Arab Spring, the wars in Syria, which partially has led to what's happening in Ukraine."}, {"time": 8442, "text": "And our weapons are getting more and more powerful and more and more destructive."}, {"time": 8445, "text": "More and more nations are having these destructive weapons."}, {"time": 8449, "text": "And now we're entering cyberspace, where it's even easier to be destructive."}, {"time": 8454, "text": "And hyperbaric weapons, which didn't exist in the Second World War."}, {"time": 8458, "text": "So you don't need nuclear weapons to have catastrophic attacks on each other."}, {"time": 8463, "text": "So yeah, it's incredibly scary that the warlike side of human nature could be extremely enhanced by climate breakdown."}, {"time": 8474, "text": "So in this world, on a happy note, I don't know how we went from Marxism and Stalinism to ecology, but all those are beautiful, complex systems."}, {"time": 8488, "text": "What is the best form of government, would you say?"}, {"time": 8491, "text": "We talked about the economics of things."}, {"time": 8496, "text": "You ran for office, so you care about politics too."}, {"time": 8500, "text": "How can politics, what political systems can help us here?"}, {"time": 8503, "text": "I think we first of all have to appreciate we're one species on a planet out of millions."}, {"time": 8510, "text": "And as the intelligent species, we should be enabling a harmonious life for those other species as well."}, {"time": 8518, "text": "Can we actually linger on that?"}, {"time": 8519, "text": "What is, you mentioned that we need to acknowledge the value of life on Earth."}, {"time": 8528, "text": "Can we integrate the labor theory of value, can we integrate into that the value of life?"}, {"time": 8538, "text": "So there's human life, and there's life."}, {"time": 8541, "text": "If you take that structure that I talked about of Marx's use value, exchange value, dialectic, and foreground background, that only exists, that only works because we're exploiting the free energy we find in the universe."}, {"time": 8555, "text": "There could be no production system without free energy, which is the first law of thermodynamics that exists."}, {"time": 8562, "text": "There is free lunch, after all, and it's grounded in the energy that's provided to us by the universe."}, {"time": 8568, "text": "Well, yeah, that's the free lunch."}, {"time": 8569, "text": "That's what we're exploiting."}, {"time": 8570, "text": "It's the only free lunch we get."}, {"time": 8571, "text": "You know Ginsburg's summary of the laws of thermodynamics, don't you?"}, {"time": 8574, "text": "Allen Ginsberg?"}, {"time": 8576, "text": "The laws of thermodynamics are summarized as A, you can't win, B, you can't break even, C, you can't leave the game."}, {"time": 8590, "text": "But the fact that it exists in the first place is the free lunch."}, {"time": 8594, "text": "So we're exploiting the free lunch."}, {"time": 8595, "text": "But to be able to do it, we can't put waste back into that system so much that it undermines the free lunch."}, {"time": 8601, "text": "And that's what we've been doing."}, {"time": 8603, "text": "And once you respect the fact that we have to, living on the biosphere, the planet we're actually on, we have to enable that biosphere to survive us."}, {"time": 8615, "text": "Because if it doesn't survive us, we won't survive it disappearing."}, {"time": 8620, "text": "And there's not that realization in humanity in general."}, {"time": 8623, "text": "And when you say the value of life, you know, all the different living organisms on Earth are part of that biosphere."}, {"time": 8631, "text": "So in order to maintain the biosphere, we have to respect, like pragmatically speaking, what that means is actually respecting all of life on Earth."}, {"time": 8641, "text": "Even the mosquitoes?"}, {"time": 8642, "text": "I've got some, no."}, {"time": 8644, "text": "I mean, we are a parasite."}, {"time": 8650, "text": "When you look at it, we're the mosquitoes of the large organizations."}, {"time": 8657, "text": "You're a fan of the Matrix movies at all?"}, {"time": 8660, "text": "That's what I'm wearing."}, {"time": 8662, "text": "I was wondering what the inspiration was."}, {"time": 8663, "text": "I was thinking..."}, {"time": 8664, "text": "It's not really inspiration."}, {"time": 8665, "text": "We are living in a simulation, and I have a conversation offline to have with you about that."}, {"time": 8671, "text": "You've been misbehaving, and we're going to have to put you back in line."}, {"time": 8674, "text": "So what's Agent Smith says when he's got Morpheus in his possession, he said, I've been trying to classify your species, and I've decided you're a virus."}, {"time": 8685, "text": "Now there's truth to that."}, {"time": 8686, "text": "We have intruded into everything."}, {"time": 8688, "text": "We've taken over every element of the biosphere, and we think we can continue doing that."}, {"time": 8695, "text": "And the thing is, we're breaking that."}, {"time": 8697, "text": "We're exporting it so much, we're breaking it down."}, {"time": 8699, "text": "And I think it's E.O."}, {"time": 8699, "text": "Wilson who argued the 50 percent rule."}, {"time": 8703, "text": "He believed that we should reserve 50 percent of the planet for nonhuman species."}, {"time": 8709, "text": "In other words, we make 50 percent of it off limits."}, {"time": 8713, "text": "Humans cannot go there."}, {"time": 8715, "text": "And we just let that evolve as it does."}, {"time": 8717, "text": "And then we control the other 50 percent."}, {"time": 8719, "text": "I think it's probably giving too much to us."}, {"time": 8722, "text": "I think we should actually save like 20 percent, 25 percent max on the rest of the planet."}, {"time": 8727, "text": "We let life go on and evolve as it does without our interference, without our dominance."}, {"time": 8734, "text": "Now that's neither a democratic system nor an authoritarian one."}, {"time": 8740, "text": "It's one which starts off with saying the first thing humans have to do is respect life itself."}, {"time": 8746, "text": "So would we do that?"}, {"time": 8750, "text": "We haven't done it, obviously."}, {"time": 8752, "text": "I don't think the Soviets would have done it if we had a generally Soviet system."}, {"time": 8756, "text": "We haven't done it under a capitalist."}, {"time": 8758, "text": "We continue intruding."}, {"time": 8759, "text": "So I think we have to go through something like a Star Trek, a Star Trek, you know, catastrophic 200 years to realize that ultimately if we're going to survive as a species, we have to respect life in general."}, {"time": 8772, "text": "And then that means parts of the planet we can no longer touch, while we also try to maintain the planet at the temperature that we found it in what we now call the Anthropocene."}, {"time": 8785, "text": "So politically, we have to have, like in many ways what native societies often have, a vision of the cycle of life, not this exponential progression we've developed over the last 250 years."}, {"time": 8802, "text": "And again, I'll use another movie, the Avatar type respect for the cycle of life."}, {"time": 8806, "text": "We need to have that as part of our innate nature."}, {"time": 8809, "text": "And then on top of that, the political system comes out."}, {"time": 8813, "text": "Now that political system has to be one that lets us feel like we have a say in the direction of society while that part is sacrosanct."}, {"time": 8824, "text": "We can't touch it."}, {"time": 8826, "text": "But we also, because we are now living with so many challenges created by our own civilization, I mean, the main threat to the existence of human civilization is the existence of human civilization."}, {"time": 8838, "text": "Is both a feature and a bug."}, {"time": 8840, "text": "And therefore, we need to have people who can understand complex systems making those decisions."}, {"time": 8845, "text": "Now that means it isn't a political system as much as it is an appreciation that the world is a complex system."}, {"time": 8852, "text": "And therefore, effects, which we think are direct effects, will actually come through an oblique fashion."}, {"time": 8858, "text": "And we cannot, there's no simple linear progression from where we are to where we want to be."}, {"time": 8865, "text": "So you have to see how everything feeds together in a systemic way."}, {"time": 8867, "text": "And that's why, one reason I designed this off where I'm wearing the tshirt for now, Minsky, is to have, it's nowhere near to this scale, I hope it one way will be, but something which means we can bring together all that complexity, all those systems, and perceive them on an enormous screen where we have all the various interacts and we can see what a potential future is."}, {"time": 8888, "text": "And that then guides us."}, {"time": 8890, "text": "So it isn't a case of democracy and, you know, our side wins a vote and therefore we ban abortion or we don't, you know, whatever else happens."}, {"time": 8899, "text": "It's seeing what the, respecting the fact that we're in a complex system, and being uncertain about the consequences, and not making the bold, expansionary ideas that we've been doing."}, {"time": 8915, "text": "So like, being a little bit more, uh, humble."}, {"time": 8921, "text": "Humble."}, {"time": 8923, "text": "Humble is a good word."}, {"time": 8924, "text": "But wouldn't you like to apply that same humility both to the considerations of the pros of capitalism and to the catastrophic view of the effects of climate change?"}, {"time": 8941, "text": "And also, like, I think we can afford to be bold in space."}, {"time": 8945, "text": "And that's one reason I respect the practical vision of Musk and so far impractical vision of Bezos, that if we're going, we look for the very far future, the only way we can continue expanding our knowledge of the universe is to move our civilization, the productive side of off the planet."}, {"time": 8964, "text": "Offsite backup."}, {"time": 8966, "text": "So can you actually linger on this?"}, {"time": 8968, "text": "So let's actually talk about this."}, {"time": 8969, "text": "So first of all, you have the new book, uh, humbly named, uh, named The New Economics A Manifesto."}, {"time": 8978, "text": "Publisher chose the title."}, {"time": 8980, "text": "No, but I'm joking, but, um, maybe I will ask you about why Manifesto, but we'll go through some of the ideas in this book."}, {"time": 8988, "text": "We have been already, uh, so some of it is embracing the fact that the economy, our world, our mind is a complex system."}, {"time": 8998, "text": "So this t shirt that you're wearing, yep, take it out, yeah, is, uh, the software I'll do that."}, {"time": 9007, "text": "There you go, there you go, you're wearing a, what is this, an infomercial?"}, {"time": 9013, "text": "So there's a t shirt that says Minsky, um, after not, not, not my Minsky, it's your Minsky."}, {"time": 9022, "text": "Not Hyman."}, {"time": 9023, "text": "So no, the Hyman Minsky, not Marvin Minsky."}, {"time": 9025, "text": "Not Marvin Minsky, right."}, {"time": 9026, "text": "So that's, so AI Minsky is, is Marvin and then, uh, Harman, uh, it all rhymes."}, {"time": 9033, "text": "So stability is free open source system dynamic software invented by Mr. Steve Keen, uh, coded by Russell Standish, it's on SourceForge."}, {"time": 9051, "text": "It's destabilizing."}, {"time": 9052, "text": "Stability is destabilizing."}, {"time": 9053, "text": "So that's sort of embracing the, the complex aspect of it."}, {"time": 9059, "text": "So how can you model the economy?"}, {"time": 9061, "text": "What are some of the interesting, whether detailed or high level, big picture ideas behind your efforts of Minsky?"}, {"time": 9071, "text": "Minsky, um, meaning the software, the modeling software that, that models the dynamic system."}, {"time": 9076, "text": "Basically what Minsky is doing is system dynamics modeling."}, {"time": 9079, "text": "So it's, if anybody's used Stellar or Vensim or Simulink, um, then they've used exactly the same family of software that Minsky is part of."}, {"time": 9088, "text": "So I didn't invent that."}, {"time": 9089, "text": "It was invented by Jay Forrester, who's one of the great intellects, one of the great engineers, uh, in American history."}, {"time": 9096, "text": "And the idea of, of, of Forrester's system was, uh, complex interactions."}, {"time": 9101, "text": "So he was doing his work in the fifties, um, uh, if people don't know Forrester's work, he actually built the models of the, um, uh, the, the mathematics for the gun turrets on American warships in the second world war mechanical systems, obviously."}, {"time": 9117, "text": "So he had to work out, you know, how to give a feedback system that meant when the boat rolled in one direction, the, the tower did not roll the other way."}, {"time": 9125, "text": "All that stuff was his work."}, {"time": 9126, "text": "So marvelous engineering."}, {"time": 9128, "text": "And then he realized if you want to look at a, even like a factory, a factory is a complex system."}, {"time": 9134, "text": "And so you get cycles generated out of the interaction between different components of the factory that he was first involved in taming, that he built the software to model complex interactive systems."}, {"time": 9143, "text": "So Minsky is that, the thing that Minsky adds, which is unique is the Godley table."}, {"time": 9147, "text": "And that's the double entry bookkeeping."}, {"time": 9149, "text": "So you can model the financial system, Godley, the economist, Godley, the economy, Wynn Godley, another great, great man."}, {"time": 9155, "text": "So there, there's like this, so you're modeling it as like a state diagram."}, {"time": 9161, "text": "Fundamentally."}, {"time": 9162, "text": "It's actually, it is circuit diagrams."}, {"time": 9163, "text": "It's exactly what engineers have been using for decades, almost a century."}, {"time": 9168, "text": "So you're using a circuit diagram to model the economy."}, {"time": 9172, "text": "And that's, that's the, so other factories have done it."}, {"time": 9175, "text": "What they, what they haven't had in the circuit diagram is a way of handling the dynamics of the financial system."}, {"time": 9182, "text": "So what the Godley table does is bring it financial flows as being everything goes from somewhere and ends up somewhere."}, {"time": 9191, "text": "So you have a positive and a negative, if you're looking on the liability side, a positive and a positive or negative and a negative, you're looking at assets and liabilities side and Minsky gets the accounting right for that."}, {"time": 9202, "text": "So you can do an enormous complex model looking at the economy financially from the point of view of a dozen different actors in the economy and know that the mathematics is right."}, {"time": 9212, "text": "Even though what you're building is set of differential equations, which might be 50 differential equations with 350 terms in them."}, {"time": 9220, "text": "If you've got the Godley tables right, you know the mathematics is correct."}, {"time": 9223, "text": "So that's the main innovation that Minsky adds."}, {"time": 9225, "text": "And you're operating there at the macroeconomics level."}, {"time": 9229, "text": "It's definitely macro."}, {"time": 9230, "text": "It's not agent based."}, {"time": 9232, "text": "And then this, I'm just open on random page that I think is very relevant here."}, {"time": 9237, "text": "The process, this is referring to Minsky, not the software, maybe the software."}, {"time": 9242, "text": "The process can be captured in an extremely simple causal chain."}, {"time": 9245, "text": "Capital determines output, output determines employment."}, {"time": 9248, "text": "The rate of employment determines the rate of change of wages."}, {"time": 9251, "text": "Output minus wages and interest payments determines profit."}, {"time": 9254, "text": "The profit rate determines the, there's a very nice circuit here."}, {"time": 9257, "text": "The profit rate determines the level of investment, which is the change in capital, which takes us back to the beginning of this causal chain."}, {"time": 9266, "text": "And the difference between investment and profits determines the change in private debt."}, {"time": 9272, "text": "And there's some nice, the Keen Minsky model and the intermittent route to chaos on page 86 of your book."}, {"time": 9280, "text": "These are, do these come from the software?"}, {"time": 9284, "text": "I was a mathematician back in 1992, August, 1992."}, {"time": 9290, "text": "Mathematics is another amazing piece of software."}, {"time": 9293, "text": "And I find it, it's very much a programmer's approach to mathematics."}, {"time": 9295, "text": "I prefer like a program called Mathcad, which is what I'm using for all my, when I do my mathematics on the computer, I write in Mathcad."}, {"time": 9304, "text": "CAD or CAB?"}, {"time": 9305, "text": "CAD."}, {"time": 9307, "text": "It's been ruined by bad management."}, {"time": 9309, "text": "They chucked out all the good engineers and I'm still using a version which is 12 years old."}, {"time": 9314, "text": "If only engineers ruled the world."}, {"time": 9316, "text": "If only engineers, rather than this particular case, there was a bunch of marketers for CAD software agreed."}, {"time": 9322, "text": "I'm definitely a fan of engineers."}, {"time": 9324, "text": "What are the plots that we're looking at here?"}, {"time": 9326, "text": "Growth rate, private debt ratio, employment versus wages, employment versus debt, income distribution."}, {"time": 9332, "text": "So this is across years, like different trade offs."}, {"time": 9336, "text": "Is there something interesting to say about the plots and the insights from those plots that are generated by the software?"}, {"time": 9341, "text": "That's a particular parameter value is to give that outcome."}, {"time": 9346, "text": "But what happened when I first simulated the model, I took a model by a guy called Richard Goodwin who's one of the great neglected economists, American Marxist, mathematical Marxist."}, {"time": 9356, "text": "And what he did was build a model of cycles."}, {"time": 9359, "text": "And he actually wrote a paper called, it's only about a five page paper published in a book and a very, very obscure conference paper."}, {"time": 9369, "text": "And what he was doing was trying to build a model of Marx."}, {"time": 9373, "text": "So he wrote it in 1967 and it was putting into mathematical form a model that Marx came up with in 1867."}, {"time": 9381, "text": "So it was a centenary birthday present to Marx."}, {"time": 9384, "text": "And what Marx had argued in chapter 25, I think, of volume one of Capital, section three, he built a verbal model of a cyclical system."}, {"time": 9399, "text": "And it's quite out of character with the rest of the book."}, {"time": 9401, "text": "So when you read volume one of Capital, people think Marx has got a commodity view of money."}, {"time": 9407, "text": "He doesn't at all."}, {"time": 9410, "text": "The idea was he had like an onion, you start off on the middle level and you ignore the outer layer, then you bring the outer layer and so on and so forth."}, {"time": 9416, "text": "Anyway, in this model, in volume one of Capital, he normally just assumed work has got a subsistence wage."}, {"time": 9423, "text": "In this little chapter, he said that if the economy is, effectively he said, the economy is booming, then workers will demand wage rises."}, {"time": 9434, "text": "And the wage rises will cut into the profit so that capitalists will not get the level of profit they're expecting."}, {"time": 9440, "text": "Therefore they will invest less and the economy will slump."}, {"time": 9443, "text": "And the slump will mean workers become unemployed and have to accept wage cuts."}, {"time": 9448, "text": "And it was a model of a cyclical economy."}, {"time": 9451, "text": "And as it happens, Marx spent his later years trying to learn enough calculus to be able to model it himself mathematically."}, {"time": 9457, "text": "And he never managed."}, {"time": 9458, "text": "There's Marx's mathematical notes on calculus, which are quite fun to read if you have a mathematical background."}, {"time": 9463, "text": "Did he get far?"}, {"time": 9467, "text": "He got too caught up in the whole philosophy and never really got to build the model."}, {"time": 9470, "text": "But what Goodman realized was a predator prey model."}, {"time": 9475, "text": "The Locta Volterra model was the basis of the idea."}, {"time": 9477, "text": "So the idea is you have a prey, and the example that Locta actually used initially was grass."}, {"time": 9487, "text": "Grass is the prey."}, {"time": 9488, "text": "And then you have a predator, and the predator were cows."}, {"time": 9492, "text": "So you start off with a very few cows, lots of grass."}, {"time": 9495, "text": "And then because of lots of grass, the numbers of cows grow."}, {"time": 9499, "text": "And then because the cows grow, they start to eat the grass."}, {"time": 9501, "text": "So the grass runs out, so the cows starve, and you get a cycle."}, {"time": 9505, "text": "And what Locta was amazed by was that the cycles were persistent."}, {"time": 9508, "text": "They didn't die out."}, {"time": 9510, "text": "So Goodman got that vision, and he then built a predator prey model."}, {"time": 9513, "text": "And I, first of all, read Goodman and really found it really hard to follow his writing."}, {"time": 9517, "text": "He's not a very good writer, but a guy called John Blatt, who was a professor of mathematics at New South Wales University, wrote a brilliant explanation of Goodman's model in a book called Dynamic Economic Systems."}, {"time": 9529, "text": "And I read that."}, {"time": 9530, "text": "It was superb, and he said a way he could extend this was to include finance."}, {"time": 9535, "text": "So I thought, okay, what I'm going to have is that what Goodman presumed is capitalists invest all their profits."}, {"time": 9542, "text": "So you get a boom when there's a high rate of profit because they invest all that money, and then a slump when there's low profit because depreciation will wipe away capital and you'll go boom and slump."}, {"time": 9554, "text": "So I simply added in, well, capitalists will invest more than their profits during a boom, but less than their profits during a slump."}, {"time": 9563, "text": "And that therefore means they had to borrow money to finance the gap and pay interest on the debt."}, {"time": 9568, "text": "So I ended up with a model with just three systems states, the income share, the wages distribution of income between workers, capitalists, and bankers, the level of employment, and the level of private debt."}, {"time": 9580, "text": "And those three equations are fundamentally like going from the Locke to Volterra model with just two equations, and therefore you get a fixed cycle, to the Lorenz model where you have three."}, {"time": 9591, "text": "And therefore what I got out of it was a chaotic outcome."}, {"time": 9594, "text": "So what you're seeing is a manifestation of chaos, complexity in those plots."}, {"time": 9600, "text": "But one of the many fascinating parts about it was that as the level of private debt rose, in my model I had capitalists being the only ones who borrowed, but the people who paid for the high level of private debt were the workers."}, {"time": 9617, "text": "The rising banker's share corresponded exactly to a falling worker's share."}, {"time": 9622, "text": "So you can infer from that that the workers are the ones paying."}, {"time": 9626, "text": "Effectively, the workers end up paying for it."}, {"time": 9628, "text": "They get a lower level of wages."}, {"time": 9630, "text": "And the basic dynamic is that capitalists, when you have a three social class system, your income goes between workers, capitalists, and bankers."}, {"time": 9638, "text": "Now in the system, the good one did, they're just workers and capitalists."}, {"time": 9641, "text": "So if workers share rose, capitalists share had to fall."}, {"time": 9645, "text": "But when you have three social classes, then capitalists share can remain constant while workers fall and bankers rise."}, {"time": 9653, "text": "So that's what actually happened."}, {"time": 9655, "text": "Because capitalists, the simple way I modeled it was there's a certain rate of profit at which capitalists invest all their profits."}, {"time": 9662, "text": "Above that they borrow more, below that they pay off debt."}, {"time": 9665, "text": "So what would happen is when you got back to that point, then the level of investment would be a precise share of GDP."}, {"time": 9673, "text": "And therefore you'd get a precise rate of economic growth."}, {"time": 9675, "text": "But if there was a higher percentage going to bankers and offset by a lower share going to workers, it didn't affect the capitalists."}, {"time": 9683, "text": "So what you get is the cycles sort of diminish for a while because there's the income distribution effect is important."}, {"time": 9692, "text": "So the workers pay for the increasing level of debt."}, {"time": 9697, "text": "But the other side of it was that the cycles would diminish for a while."}, {"time": 9700, "text": "Now what you get is a period of diminishing cycles, then leading to rising cycles."}, {"time": 9705, "text": "And technically this is known as the Pomeranville route to chaos, and it's one particular element of Lorenzo's equations of fluid dynamics."}, {"time": 9717, "text": "So what they found was in examining laminar flow in a fluid, you have a period where the laminar flow got more laminar, and then suddenly it'd start to get less laminar and go turbulent."}, {"time": 9729, "text": "And this is what actually goes on in the model, so in my model of Minsky."}, {"time": 9734, "text": "So what you have is a period where there's big berms and cycles, and then as the debt level rises, the berms and slumps get smaller."}, {"time": 9743, "text": "And that looks like what neoclassical economists call the Great Moderation."}, {"time": 9748, "text": "So when I first modeled this in 1982, I finished up my paper, which was published in 95, with what I thought was a nice rhetorical flourish, saying the chaotic dynamics of this paper should warn us against regarding a period of relative stability in a capitalist economy as anything more than a lull before the storm."}, {"time": 9765, "text": "Now I thought it was a great speed of rhetoric, I didn't think it was going to fucking happen."}, {"time": 9770, "text": "But it did, because you had this period from 1990 through to 2007 where there were diminishing cycles, and the neoclassicals labeled that the Great Moderation, and they took the credit for it."}, {"time": 9781, "text": "They thought that the economy was being managed by them to a lower rate of inflation, a lower level of unemployment, less instability over time, and they literally took credit for it."}, {"time": 9791, "text": "And I was watching that and thinking, that's like my model running, and I'm scared as shit that there'll be a breakdown."}, {"time": 9797, "text": "I ended up not working in the area for a while because I wrote Debunking Economics, and I got involved in a fight over the modeling of competition in neoclassical theory that took me away for about four or five years."}, {"time": 9811, "text": "And then I got asked to do a court case in 2005, end of 2005, and I used Minsky as my framework for arguing that somebody who was involved in predatory lending should be able to get out of the debt they were in."}, {"time": 9827, "text": "And I explained Minsky's theory, and I used this throwaway line of saying debt levels of private debt have been rising exponentially."}, {"time": 9835, "text": "And then I thought, well, I can't, as an expert, just make a claim like that."}, {"time": 9839, "text": "I've got to check the data."}, {"time": 9841, "text": "And the debt ratio was rising exponentially, and I thought, holy shit, we're in for a financial crisis, and somebody has to warn about it, and at least in Australia, I was that somebody."}, {"time": 9850, "text": "So can you, given this chaotic dynamics idea, can you talk about the crises ahead of us in the future?"}, {"time": 9857, "text": "So one of the things, I mean, it's a fundamental question of economics."}, {"time": 9861, "text": "Is economics about understanding the past or predicting the future?"}, {"time": 9866, "text": "Because you can construct models that do poetic, like in 95, poetic, you know, yeah, and then you can, you know, watch years fly by, and some of the predictions in retrospect that you make turn out to be true, but, you know, all kinds of gurus throughout history have done that kind of thing, and you can call yourself right and forget all the many times you've been wrong."}, {"time": 9896, "text": "Let's talk about the future."}, {"time": 9897, "text": "What kind of stuff, you mentioned about the importance of the biosphere, but what are the crises that are ahead of us that a chaotic dynamics view allows us to predict and be concerned about?"}, {"time": 9911, "text": "Getting out of it, leaving aside the ecological, wasn't a crisis, it was stagnation."}, {"time": 9917, "text": "Because what we got out of the crisis was caused by a rising level of private debt."}, {"time": 9923, "text": "Now you reach a peak level where the willingness to take on debt collapses."}, {"time": 9929, "text": "And so you go to a period where debt is rising all the time."}, {"time": 9932, "text": "So credit, which is the annual change in debt, and that's credit as part of aggregate demand and aggregate income."}, {"time": 9939, "text": "So credit goes from positive to negative, and that causes a slump."}, {"time": 9944, "text": "So can you describe why that causes a slump?"}, {"time": 9947, "text": "So credit goes to negative."}, {"time": 9949, "text": "If you ask Paul Krugman, he'll tell you credit plays no role in aggregate demand."}, {"time": 9955, "text": "Credit plays no role in aggregate demand."}, {"time": 9958, "text": "So the vision that the neoclassicals have for the banking system is what they call learnable funds."}, {"time": 9963, "text": "Is Paul Krugman, by the way, the knight at the front of the army that is the neoclassical economist?"}, {"time": 9971, "text": "Yeah, fundamentally."}, {"time": 9974, "text": "He's politically reasonable, which makes him more dangerous than those that aren't."}, {"time": 9981, "text": "He's politically... Yeah, there's quite a lot of people that would disagree with that characterization of Paul Krugman as he's politically reasonable."}, {"time": 9988, "text": "You should see the people behind him."}, {"time": 9989, "text": "The alternatives."}, {"time": 9993, "text": "So he's not a negative or positive statement, that's just he can be feisty as well."}, {"time": 9996, "text": "Oh, he can."}, {"time": 9997, "text": "He can."}, {"time": 9998, "text": "But he's like the human face of neoclassical economics."}, {"time": 10000, "text": "It doesn't deserve having a human face."}, {"time": 10003, "text": "It's anti human theory."}, {"time": 10005, "text": "But he's the human face."}, {"time": 10006, "text": "Tell me what you really think."}, {"time": 10009, "text": "Well, so but the credit does not have any effect on aggregate demand."}, {"time": 10014, "text": "In their model."}, {"time": 10015, "text": "And you're saying that's not the case at all."}, {"time": 10016, "text": "It's absolutely crucial to aggregate demand."}, {"time": 10019, "text": "So what they model is, again, the example of you lending to me or vice versa."}, {"time": 10023, "text": "If I lend money to you, I can spend less, you can spend more."}, {"time": 10027, "text": "So credit is the change in debt."}, {"time": 10031, "text": "So if I lend money to you, then there's a level of private debt rises."}, {"time": 10037, "text": "So there's an increase in credit."}, {"time": 10039, "text": "But that increase in credit comes at an expense of my spending power."}, {"time": 10042, "text": "So you can spend what I've lent you, but I can't spend what I've lent you."}, {"time": 10046, "text": "So credit cancels out."}, {"time": 10048, "text": "When you look at that's learnable funds."}, {"time": 10050, "text": "But in the real world, and the Bank of England has said this is the real world and the textbooks are wrong categorically in 2014."}, {"time": 10058, "text": "When the bank lends, it adds to its asset side and says, you owe us more money."}, {"time": 10063, "text": "And it adds to its liability side and says, here's the money in your bank account."}, {"time": 10067, "text": "Now you spend that money."}, {"time": 10069, "text": "So what happens when you do your sums, credit is part of aggregate demand and aggregate income."}, {"time": 10075, "text": "And that's something I first solved in 2019, I think, 2000, I only recently proved it mathematically."}, {"time": 10082, "text": "So what that means is credit is a component of aggregate demand, and credit is also very volatile."}, {"time": 10089, "text": "It's like consumption demand never goes negative, investment demand never goes negative, but credit can go from positive to negative."}, {"time": 10095, "text": "And when you take a look at the long run of American history after the Second World War, there was no period until 2007 where credit was negative."}, {"time": 10106, "text": "It was a positive number, therefore, when you do it as a percentage of GDP, it was a positive percentage of GDP."}, {"time": 10116, "text": "It peaked at 16% of GDP in 2006, 2007."}, {"time": 10122, "text": "It fell to minus 5% in 2008, 2009."}, {"time": 10127, "text": "So you had a 20% of GDP turnaround in aggregate demand."}, {"time": 10131, "text": "Now when you plot that against unemployment, the correlation of credit to unemployment across the period from about 1990 to 2010 is about minus 0.9, okay?"}, {"time": 10149, "text": "Enormous negative correlation."}, {"time": 10150, "text": "Now according to the neoclassicals, it should be close to zero."}, {"time": 10154, "text": "Empirically it's bleedingly obvious it's not."}, {"time": 10156, "text": "And it applies to every country in the world that had a financial crisis at that period."}, {"time": 10161, "text": "So it's bleedingly obvious in the data."}, {"time": 10164, "text": "And they ignore it because credit's not part of their model."}, {"time": 10168, "text": "And you're saying it's causation."}, {"time": 10169, "text": "It is causal."}, {"time": 10171, "text": "Today we sit there, it's extremely high inflation."}, {"time": 10175, "text": "What role does inflation play in this picture?"}, {"time": 10181, "text": "Is a little bit of inflation good?"}, {"time": 10183, "text": "We talked about money creation at the beginning."}, {"time": 10188, "text": "What's a little bit of inflation good or bad?"}, {"time": 10190, "text": "A lot of inflation good or bad?"}, {"time": 10192, "text": "How concerned are you about?"}, {"time": 10193, "text": "A little bit is good for a simple reason that, like again, it's taken me a while to get my head around this."}, {"time": 10198, "text": "But if you think about how people say, what are the functions of money?"}, {"time": 10201, "text": "They say money, it's a unit of account, so you're measuring."}, {"time": 10204, "text": "It's a means of exchange, okay?"}, {"time": 10206, "text": "And it's a store of value, okay?"}, {"time": 10209, "text": "Now yes, okay, it has those three roles, but the last one is contradictory to the previous two."}, {"time": 10216, "text": "Because, and this is where you see this with the Bitcoin phenomenon, if you want to hang onto money as a store of value, then if prices are falling, the value of money is rising."}, {"time": 10229, "text": "And it's actually in your interests as a store of value to hang onto it and not spend it."}, {"time": 10235, "text": "So that contradicts its role as a means of exchange."}, {"time": 10239, "text": "Now if you have money which depreciates, and this was actually tried in the Austrian town of Wargel during the Great Depression."}, {"time": 10248, "text": "If you have money that depreciates, then if you don't use it, you lose it fundamentally."}, {"time": 10253, "text": "So it has a high rate of circulation."}, {"time": 10255, "text": "So there's a monetary theorist called Silvio Gazzell, and he wrote this proposal that money should depreciate."}, {"time": 10263, "text": "And he was ridiculed and opposed and derided, but Keynes said he was a great intellect."}, {"time": 10269, "text": "And the mayor of the town of Wargel in Austria during the Great Depression was facing an unemployment rate of 25% pretty much."}, {"time": 10278, "text": "Germany had the worst experience in the Great Depression in the world, as bad as America, slightly worse than America."}, {"time": 10285, "text": "And so he thought, how can I stimulate demand here?"}, {"time": 10288, "text": "So he produced a script which could only be used for buying goods and services in Wargel."}, {"time": 10293, "text": "And it could be used to pay your local rates."}, {"time": 10297, "text": "But it was depreciated by putting a stamp on the money if you didn't use it."}, {"time": 10301, "text": "So what happened was people would pay their rates, they needed to pay the rates using this money, so the script, so they used the script."}, {"time": 10309, "text": "And because it depreciated, you'd use it rapidly."}, {"time": 10312, "text": "So people were using that money, this alternative to the Austrian shilling, and the economic activity in town took off, and unemployment fell to zero."}, {"time": 10322, "text": "And it was an absolute miracle, and everybody loved a Wargel experiment, and the Austrian central bank sued them for establishing an alternative form of money and shut it down."}, {"time": 10332, "text": "Unemployment went back up to 25% again, and Austria voted 99.6% for the Nazis, something crazy number like that when Hitler marched in."}, {"time": 10342, "text": "So the Wargel experiment showed that a depreciating currency led to a high rate of circulation."}, {"time": 10349, "text": "But of course, we're not talking Weimar Republic levels of inflation."}, {"time": 10353, "text": "So when you get that much inflation, and that's normally caused by, as the Weimar inflation was caused by, the reparation terms imposed on Germany, fundamentally by France at the Treaty of Versailles, they paid a large part of that with just basically printing the notes, and you went into this crazy period of hyperinflation."}, {"time": 10374, "text": "So hyperinflation almost always occurs when there's a massive destruction of physical resources, and the monetary authority tries to paper, literally, over it, and then you get hyperinflation, that's total social breakdown."}, {"time": 10385, "text": "So a moderate level of inflation inspires the means of exchange usage of money, but undermines the store of value usage of money."}, {"time": 10397, "text": "And that dilemma is why we have this antagonistic attitude towards inflation."}, {"time": 10402, "text": "Yeah, I mean, you're describing it as a tension, but it nevertheless is, like money is a store of value and a means of exchange, and I don't, you know, to push back, it's not necessarily that there's a tension, it's just that depending on the dynamics of this beautiful economic system of ours, it's used as one more than the other."}, {"time": 10425, "text": "If there's inflation, you're using it more for the means of exchange, there's deflation using more for store of value, but that doesn't, I don't see that as a tension, that's just a, how much you use it for those different, like..."}, {"time": 10440, "text": "But it ends up saying that overall, the level of effective commerce, a bit of inflation is a good thing, because that's depreciating the money slightly and encourage its use."}, {"time": 10451, "text": "Yeah, but so the argument that some Bitcoin folks use or gold standard folks, again, HODL is not an argument, is that having an inflation of zero is actually achieving that balance."}, {"time": 10472, "text": "But they're actually in favor of negative, they want it to be appreciated rapidly, and because of the negative inflation, the value of the money rising relative to commodities, that's what they want, that's the HODL philosophy."}, {"time": 10485, "text": "Well, that's more of like an investment, I don't know if that, that's more of investment philosophy than the fundamental principles of why they believe in cryptocurrency, in forced scarcity, it's a model."}, {"time": 10498, "text": "The concern there is that when you print money, the public policy is detached from the actual value."}, {"time": 10506, "text": "Yeah, well, I mean, this is where, again, it matters to get money creation right, because the government's not the only money creator, banks are as well, private banks."}, {"time": 10519, "text": "And if we obsess too much about limiting government money creation, what we end up getting, if there is money creation going on, it's private banks doing it, and you get an increase in private debt, and fundamentally, private debt and its collapse, the collapse of credit, when it stops growing, that's the fundamental cause of financial crises."}, {"time": 10541, "text": "So yeah, but the question is, what's the cause for the collapse of the... Well, I think this is like the Austrian thinking leaves out the debt deflation."}, {"time": 10551, "text": "And that's like, I think one of the most important papers ever written was by Irving Fisher called the Debt Deflation Theory of Great Depressions."}, {"time": 10559, "text": "Fisher was somebody who accepted the neoclassical vision."}, {"time": 10562, "text": "He wrote the pre Efficiency Market Hypothesis, Efficiency Market Hypothesis."}, {"time": 10569, "text": "He had his own PhD called the Theory of Interest."}, {"time": 10574, "text": "And in that, he argued effectively for a supply and demand analysis of the financial system."}, {"time": 10581, "text": "And he argued for equilibrium, he said when you're working with a commodity market, then the sale and the transaction and the exchange occur at the same point in time."}, {"time": 10595, "text": "When you're working with the financial market, then the exchange occurs through time."}, {"time": 10599, "text": "So he said he assumed that debts are repaid, all debts are repaid, and he assumed that equilibrium through time was an essential part of his assumption."}, {"time": 10610, "text": "This is...and then the Great Depression comes along."}, {"time": 10614, "text": "And he has become a major shareholder in the rank Xerox because he invented the Roller Dex."}, {"time": 10621, "text": "He's a tinkerer."}, {"time": 10623, "text": "And so he had taken out shares on margin, and he was worth about 100 million in modern terms when the Great Depression hit."}, {"time": 10632, "text": "And 90% of that was share market valuation."}, {"time": 10634, "text": "He'd taken out margin debt just like everybody else."}, {"time": 10638, "text": "And with margin debt, you could put down $100,000 and buy a million dollars worth of shares."}, {"time": 10644, "text": "So you got this huge leverage into debt."}, {"time": 10647, "text": "Now that when the financial crisis hit, the level of margin debt in America had risen from half a percent of GDP in 1920 to 13% of GDP in 1929."}, {"time": 10658, "text": "It then fell to zero again."}, {"time": 10660, "text": "That's why the stock market crash in 1929 was so devastating, that scale of margin lending."}, {"time": 10666, "text": "And everybody was being wiped out, they were selling Rolls Royces for 20 quid."}, {"time": 10669, "text": "You literally have photographs showing people doing that."}, {"time": 10672, "text": "Because a margin call comes in, you've got to liquidate everything."}, {"time": 10676, "text": "So he said the danger of a debt deflation is what we have to avoid."}, {"time": 10682, "text": "And that means you don't want too much private debt to accumulate, and you don't want falling prices because the falling prices will amplify the impact of being insolvent to begin with."}, {"time": 10694, "text": "And that's what we saw in the Great Depression."}, {"time": 10696, "text": "It's partially what we saw in 2007."}, {"time": 10699, "text": "But we didn't have anything like the level of margin debt."}, {"time": 10703, "text": "Margin debt was reduced from 90% to 50% ratio after the Great Depression."}, {"time": 10709, "text": "So there were limits on how bad it was in 2007."}, {"time": 10713, "text": "But the danger is still the period of deflation amplifies your debts."}, {"time": 10718, "text": "And I call it Fisher's Paradox, he didn't write those terms himself."}, {"time": 10722, "text": "But he wrote a line saying the more debtors pay, the more they owe."}, {"time": 10727, "text": "And this is because you're liquidating to try to meet your own debts."}, {"time": 10732, "text": "When you liquidate, the price level falls."}, {"time": 10735, "text": "You will end up having a lower level of monetary debt, but a higher level of debt when you deflate it using the price level."}, {"time": 10742, "text": "So the biggest danger in capitalism is the debt deflation, far more dangerous than inflation."}, {"time": 10748, "text": "And the cause of debt deflation is?"}, {"time": 10751, "text": "Too much lending."}, {"time": 10752, "text": "Too much bank lending."}, {"time": 10753, "text": "Too much private money creation."}, {"time": 10754, "text": "And if you take a look at the 1920s, Calvin Coolidge explained the boom of the 1920s on his surplus."}, {"time": 10762, "text": "He said, my government running a surplus of 1% of GDP pretty much from 1922 through to 1930 is the foundation of our stability."}, {"time": 10770, "text": "It should be continued."}, {"time": 10772, "text": "What he didn't look at was that over that same time period, on average, Americans were borrowing 5% of GDP per year from the private banks."}, {"time": 10782, "text": "So you had a housing bubble at the beginning of the 1920s, which Richard Vague covers beautifully in the brief history of doom."}, {"time": 10789, "text": "And then you had this huge rise in margin debt as well, gigantic increase in margin debt."}, {"time": 10795, "text": "So all this borrowed money was being spent into the economy, and this is where credit becomes part of aggregate demand."}, {"time": 10801, "text": "And it's both not just for goods and services, it's also for shares and houses and so on."}, {"time": 10805, "text": "So a huge valuation effect."}, {"time": 10807, "text": "But then when the margin debt turned around, when people would not take out margin debt anymore, the demand for margin debt disappeared."}, {"time": 10816, "text": "And then it was, you know, what we call badly a positive feedback loop is actually an amplifying feedback loop."}, {"time": 10822, "text": "And that caused a collapse."}, {"time": 10825, "text": "So what elements of that do you see today that we need to fix and how do we fix it?"}, {"time": 10830, "text": "We have to regard the level of private debt as a target of economic policy, just as much as the rate of inflation or the rate of unemployment."}, {"time": 10838, "text": "What is the moderate amount of private debt that's good?"}, {"time": 10841, "text": "I would say something of anywhere between 30 and 70% of GDP."}, {"time": 10845, "text": "What is it currently?"}, {"time": 10847, "text": "In America, it's 170%."}, {"time": 10853, "text": "Oh, that's nice."}, {"time": 10854, "text": "I've got, we'll have to talk after we talk, but I can show you the data in this."}, {"time": 10857, "text": "And it is just this huge increase in private debt that first of all caused the boom, but then financing the credit causes, ultimately causes the slump."}, {"time": 10870, "text": "And so if we remove the rate level at which debt can reach and we stop speculative lending and basically have a lending for both innovation, investment and essential consumption items, we won't have the slump on the other side."}, {"time": 10885, "text": "We can get rid of financial instability."}, {"time": 10887, "text": "We can't stop financial cycles, but we can stop financial breakdown."}, {"time": 10891, "text": "So we should really be focusing on the instability and getting that under control."}, {"time": 10895, "text": "By the way, as you point to your laptop, my laptops, I have a lot of, how many computers do I have?"}, {"time": 10901, "text": "I have a lot of them, but my little Surface, whatever the heck this thing is, is getting definite size envy because your laptop, you said is 18 something inches."}, {"time": 10912, "text": "I don't think I've ever seen one that big and I'll give the internet that one."}, {"time": 10920, "text": "That's for the graphics."}, {"time": 10921, "text": "So it's a gaming laptop."}, {"time": 10922, "text": "It's a gaming laptop."}, {"time": 10923, "text": "It's basically a desktop."}, {"time": 10924, "text": "It probably weighs like 40 pounds and you have to."}, {"time": 10928, "text": "Eight kilos?"}, {"time": 10931, "text": "You reckon eight or?"}, {"time": 10937, "text": "That's, you know, you're pushing 40 pounds."}, {"time": 10938, "text": "You've seen the power supply for it?"}, {"time": 10939, "text": "It's over there somewhere."}, {"time": 10940, "text": "The power supply weighs about twice as much as your laptop."}, {"time": 10942, "text": "And you have to power it on with a crank."}, {"time": 10943, "text": "Pretty close."}, {"time": 10944, "text": "You have to like pull it."}, {"time": 10945, "text": "Is it gas powered or is it coal?"}, {"time": 10946, "text": "Oh, well, I feel like it's a nuclear power station."}, {"time": 10949, "text": "Nuclear."}, {"time": 10951, "text": "A nuclear diamond in the back there."}, {"time": 10953, "text": "So let me, before I forget, just let me ask you about, we've covered brilliantly the nuanced disagreements you have and the wisdom you've drawn from Karl Marx."}, {"time": 10966, "text": "But there's also, like you mentioned in popular discourse, a kind of a distorted use of different terms and one of them is Marxism today."}, {"time": 10978, "text": "Is there something you could just speak to about, you know, increased use of that word and is it misused?"}, {"time": 10986, "text": "Does it concern you that there's a lot of actually young people that say they're sort of proudly Marxist?"}, {"time": 10993, "text": "Are they misusing the term?"}, {"time": 10995, "text": "They are definitely misusing the term if they don't understand the use value exchange value dialectic I went through earlier."}, {"time": 11003, "text": "So if I could."}, {"time": 11004, "text": "And they don't."}, {"time": 11005, "text": "If I could just pause, the idea of socialism and Marxism is used in sort of popular lingo."}, {"time": 11013, "text": "It's basically, you know, a lot of people have a disproportionately hard life."}, {"time": 11020, "text": "Why can't we help them out?"}, {"time": 11023, "text": "Why can't we be kind to our fellow man?"}, {"time": 11026, "text": "Kind of that's a short embodiment of an idea as opposed to some super complicated elaborate model of the economy and politics and all that kind of stuff."}, {"time": 11039, "text": "I mean, we could do that by using the insights that come out of modern monetary theory, which I've confirmed just using my simple Minsky models."}, {"time": 11046, "text": "And that is that, to use the term, usually a feature, not a bug."}, {"time": 11050, "text": "A government running a deficit is a feature of a well functioning mixed fiat credit economy, not a bug."}, {"time": 11057, "text": "The government should normally run a deficit because that's how the government creates money."}, {"time": 11062, "text": "We've also had this obsession from mainstream economists of running a surplus, which is what caused the Great Depression, Calvin Coolidge doing it for eight years."}, {"time": 11070, "text": "Because of that obsession, we've cut back on social services, we've cut back on health, we've cut back on education, we've cut back on infrastructure."}, {"time": 11077, "text": "Now all that stuff predominantly affects the poor because the rich can afford to buy it themselves."}, {"time": 11083, "text": "So if we had, Sonovich, realized that the government should run a deficit, it's a feature, not a bug of a fiat money system."}, {"time": 11090, "text": "And that's where Elon's made one mistake recently, I'm not going back to funded first principles."}, {"time": 11095, "text": "That deficit enables you to provide enough of a decent standard of living for those who don't come out on top in the capitalist game."}, {"time": 11105, "text": "And with that, you wouldn't have the angst of the young people."}, {"time": 11108, "text": "Now we still have the climate parameters within which we have to survive, but a decent level of government funding would mean the angst that you get where people say, I want to be a Marxist, and they've got what I call a cardboard cutout version of Marx in their minds."}, {"time": 11123, "text": "That wouldn't be happening."}, {"time": 11125, "text": "So it's potential to have a good society where the government runs a deficit that finances the needs of the poor, where the rich get enough to indulge and take care of themselves, and you don't get this breakdown."}, {"time": 11141, "text": "If you try to cause the government running a surplus, then the burden of that is borne by the poor, middle class and poor, and that will lead to the angst we're now seeing."}, {"time": 11152, "text": "That was a beautiful whirlwind exploration of all of economics and economics history."}, {"time": 11159, "text": "Let me ask you, you tweeted, I think, we are the opposite of ants."}, {"time": 11165, "text": "Individually intelligent, collectively stupid."}, {"time": 11169, "text": "You need to develop systems thinking fast to counter our limitations."}, {"time": 11179, "text": "Do you really believe we're individually intelligent and collectively stupid?"}, {"time": 11185, "text": "I mean, some of that is just cheeky tweets, but... RG."}, {"time": 11188, "text": "It's a cheeky tweet I've had in my mind for a long time."}, {"time": 11191, "text": "It's one that actually went moderately viral, not enough, but moderately viral for me."}, {"time": 11197, "text": "Nevertheless, if you could analyze it as if it's some deep, profound statement you made in a book."}, {"time": 11202, "text": "Well, the reason is that we are the incredibly individually intelligent, things like these devices we're playing with now."}, {"time": 11208, "text": "That's the creation of individual minds."}, {"time": 11210, "text": "Creative individual mind and a collective labor over centuries that led to this level of technology, and that has to be respected."}, {"time": 11218, "text": "But at the same time, I think what humans are, if you want to distinguish humans from other species on the planet, we don't weave webs, okay, we don't make bird calls."}, {"time": 11228, "text": "What we do is we share beliefs."}, {"time": 11234, "text": "Now... LW."}, {"time": 11236, "text": "You don't think that's a catalyst for intelligence?"}, {"time": 11238, "text": "Yeah, it is a catalyst."}, {"time": 11239, "text": "But what it means is we can delude ourselves as much as we can inform ourselves."}, {"time": 11243, "text": "So because we share beliefs, we can do things in a collective way."}, {"time": 11247, "text": "And if we believe that if we take the incantations of the witch doctors and we happen to have a couple of spears and things, we can go and attack the local herd, a tribe of lions and drive them out, and we become the dominant species."}, {"time": 11263, "text": "So it works at the stage where we were in competition with other species on the planet."}, {"time": 11268, "text": "Now that we're the dominant species, then our beliefs get in the way."}, {"time": 11273, "text": "So you agree with Einstein, who said there are only two things that are infinite, the universe and human stupidity."}, {"time": 11282, "text": "And he wasn't sure about the universe."}, {"time": 11288, "text": "Yeah, so you think that the collective, I mean, there's an infinity to the destructive and the stupid, the inhumane that's possible when we humans get together, but it feels like there's more trajectories, there's more possibility for creation."}, {"time": 11305, "text": "There are."}, {"time": 11306, "text": "I mean, I think that's why we have to, I say if we were built around the idea that our role as a species is to maintain and extend life on the planet and if not find it elsewhere, then seed it elsewhere, then that is a vision which makes us creative and confines the worst elements of our capacities to share beliefs."}, {"time": 11326, "text": "So that's what I, my hope is that we'll reach that stage, but I think we've overshot it so badly that my real fear is we'll end up blaming technology for the type of world we find ourselves living in in the next 20 to 50 years."}, {"time": 11342, "text": "So you think technology is going to be one of the, part of the solution?"}, {"time": 11346, "text": "Part of the solution."}, {"time": 11348, "text": "But if we go through and blame it, which is quite possible, we'll blame the technology rather than blaming too much of the technology and the too much comes down to what economists have told us, that we can just continue consuming infinitely on a finite planet."}, {"time": 11361, "text": "And Kenneth Boulding said that beautifully."}, {"time": 11363, "text": "If somebody believes that you can have exponential growth on a finite planet, they're either mad or they're an economist."}, {"time": 11370, "text": "So you're, you made a long journey for which I'm deeply honoured from, from, this distant place."}, {"time": 11381, "text": "Antibodies."}, {"time": 11382, "text": "There's myth."}, {"time": 11384, "text": "You've got to go there one day, you'd enjoy it."}, {"time": 11385, "text": "If I go there, I will stay forever."}, {"time": 11387, "text": "And so... LW."}, {"time": 11389, "text": "No, it's a bit too, there's more vitality back in this economy."}, {"time": 11391, "text": "So you'd come back."}, {"time": 11395, "text": "You know, I'm not a fan of the economy or money or any of that."}, {"time": 11398, "text": "Nature calls me."}, {"time": 11402, "text": "Let me, so I'm honoured that you make that trip."}, {"time": 11404, "text": "You've also said that while you're here in Austin, you're going to go to this American factory that makes cars here in Austin and also visit Starbase."}, {"time": 11418, "text": "So let me ask you about expanding out into the universe."}, {"time": 11422, "text": "Is that something that excites you?"}, {"time": 11425, "text": "You mentioned about the economics of it, do you think, what do you think Marx would think about this?"}, {"time": 11431, "text": "Like what, economically speaking, what is this?"}, {"time": 11435, "text": "Is it a good thing?"}, {"time": 11437, "text": "I think it's vital."}, {"time": 11438, "text": "I mean, we can have capitalism in outer space far more successfully than we can have it on the planet because we don't face, when we dump the waste, it ends up in the sun."}, {"time": 11446, "text": "Not a problem, okay?"}, {"time": 11449, "text": "So it means the potential, we don't undermine our own productive capacity if we're doing it in outer space."}, {"time": 11456, "text": "So the destructive element of waste has a lesser impact in outer space."}, {"time": 11460, "text": "Far lesser, yeah."}, {"time": 11461, "text": "I mean, who cares if we throw a bit of our iron back into the sun again?"}, {"time": 11463, "text": "It'd take a fair bit of it to turn it into what would be the next stage, it'd be a red giant."}, {"time": 11468, "text": "And we have to get away because if there's a red giant at some stage, the sun will head out past the orbit of Mars, I think, certainly past the orbit of Earth."}, {"time": 11476, "text": "So to have longevity of just human life, life that evolved on this planet, we have to be able to take it off planet, ultimately."}, {"time": 11488, "text": "So if you think in the really long term, then it's our responsibility, we're going to want to maintain life, is to establish life off the planet."}, {"time": 11498, "text": "What do you think about robots and AI as part of the expanding out into the universe?"}, {"time": 11504, "text": "Oh yeah, we have to."}, {"time": 11505, "text": "I mean, that ends labor."}, {"time": 11506, "text": "You can't go for a, you know, your daily joint can't be from here to the asteroid belt and back again for dinner with your family."}, {"time": 11514, "text": "So production would be entirely mechanized."}, {"time": 11516, "text": "There'd have to be a handful of people who service the machines."}, {"time": 11520, "text": "So it's about production and automation."}, {"time": 11522, "text": "What about elements of consciousness that make humans so special, what about that persisting within the machine?"}, {"time": 11530, "text": "That, I mean, I'm still a skeptic about us ever being able to create a machine which is truly conscious."}, {"time": 11534, "text": "If I can throw my, it's only two cents worth."}, {"time": 11537, "text": "That would really piss off Karl Marx, by the way, if we create machines that are conscious."}, {"time": 11543, "text": "This is actually part of the, there's two good logical arguments against the labor theory of value."}, {"time": 11546, "text": "One of what it becomes, machines become intelligent, and the other was that if the declining rate of profit applies in socialism, it'll apply as a rate of accumulation, sorry, in capitalism, it'll apply as a rate of socialism as well."}, {"time": 11558, "text": "A guy called Khalid made that argument."}, {"time": 11559, "text": "So his argument was just unsound."}, {"time": 11562, "text": "But yeah, intelligent machines would completely screw Marx up, you know?"}, {"time": 11567, "text": "Do you not like that world where machines have not only intelligence, but a consciousness, a soul?"}, {"time": 11575, "text": "I know that's one of your interests, one of your potential endeavors, and the Kurtz will argue that there's some singularity we're approaching as we just get increasing processing power."}, {"time": 11586, "text": "It's not processing power, it's imagination."}, {"time": 11591, "text": "Whatever the heck that means."}, {"time": 11594, "text": "Whatever the heck that means, yeah."}, {"time": 11595, "text": "I mean, you would have had imaginative insights."}, {"time": 11596, "text": "I mean, your papers on, like, in automating motoring between the hyperintelligent machine or the machine human interface where the standards can be lower for the machine and higher for the human, okay?"}, {"time": 11609, "text": "That's an insight you would have had at some point, and then you've worked it further."}, {"time": 11613, "text": "So I've had insights like that as well, and I have no idea where they come from."}, {"time": 11616, "text": "They just hit me in the head, and I just write them down, and they solve a problem that I didn't even know my mind was working on, okay?"}, {"time": 11623, "text": "So how can we get a machine to do that?"}, {"time": 11627, "text": "And I do not know the answer, but one thing I think is the potential is I think we have to create AI that has feelings, AI that wants to survive."}, {"time": 11638, "text": "Because if you think how our intelligence evolved, it's on this planet in a struggle between predator and prey, and intelligent became a survival technique."}, {"time": 11648, "text": "I find the ideas of Ernest Becker with denial of death really powerful, which is that humans not only have emotions and are trying to survive, they're able to ponder out in the distant future their mortality, and that is a driving force for even greater creation that animals are able to do, more primitive animals."}, {"time": 11678, "text": "So there is some element where I agree with you."}, {"time": 11682, "text": "I think for AI systems to have something like consciousness, they have to fear their mortality."}, {"time": 11691, "text": "And I think that's, if you do it then, you can't produce an AI whose behavior you can control."}, {"time": 11699, "text": "I mean, when you have kids."}, {"time": 11704, "text": "You can't control their behavior."}, {"time": 11705, "text": "That's the tradeoff."}, {"time": 11707, "text": "You give life to an anarchist."}, {"time": 11708, "text": "Like one of my favorite instances in my family life is one of my favorite, I like all my nurses and nephews, but one's got a real quirk to her, and I was standing over her cot when she was literally like about six months old, and she was gurgling away to herself."}, {"time": 11724, "text": "And her father waved his fingers and said, stop making that noise."}, {"time": 11728, "text": "And this little six month old kid goes, and I said, boy, you're going to have issues with that one, mate."}, {"time": 11736, "text": "An anarchist was born."}, {"time": 11738, "text": "So you can't control this life you give birth to, and that's, I think, the threat of AI."}, {"time": 11742, "text": "That's terrifying and exciting."}, {"time": 11745, "text": "And I think we should take that risk at some stage."}, {"time": 11747, "text": "But I think to do it with what actually let artificial intelligence involve in this environment in which it fears its own death."}, {"time": 11758, "text": "I think there's a lot of beauty there, but there's also a lot of destruction that's possible."}, {"time": 11764, "text": "So you have to be extremely careful, but that's kind of the cutting edge of which we all often operate as a humanity."}, {"time": 11772, "text": "Let me ask you for advice."}, {"time": 11773, "text": "Can you give advice to young people in high school and college?"}, {"time": 11779, "text": "Maybe they're interested in economics."}, {"time": 11782, "text": "Maybe they have other career ideas."}, {"time": 11785, "text": "What advice would you give them about a career they can have that they can be proud of or a life they can be proud of?"}, {"time": 11791, "text": "Mainly in a career, I say don't do an economics degree."}, {"time": 11795, "text": "I say if you... RL."}, {"time": 11797, "text": "There's a little book."}, {"time": 11799, "text": "Econ Comics."}, {"time": 11801, "text": "Econ Comics, Taking the Con Out of Economics."}, {"time": 11805, "text": "So they should start with that and then say screw it to an economics degree."}, {"time": 11811, "text": "Yeah, because what you learn is an obsolete technology."}, {"time": 11814, "text": "Learning economics at a university is like learning to make astronomy."}, {"time": 11819, "text": "Earth centric, equilibrium, you know, epicycles being added to make your models fit the data."}, {"time": 11827, "text": "So it's not that economics is not a discipline worth deeply studying, it's that the university education around economics is bad."}, {"time": 11834, "text": "Is so bad."}, {"time": 11836, "text": "So I'd say learn system dynamics."}, {"time": 11837, "text": "Do a course in system dynamics which you can apply in any field and then apply what you learn out of system dynamics to the issues of economics if that's what interests you."}, {"time": 11847, "text": "So get a sort of base engineering... LW."}, {"time": 11851, "text": "...education."}, {"time": 11853, "text": "A base engineering education."}, {"time": 11854, "text": "That is far better than doing an economics degree."}, {"time": 11855, "text": "In terms of life, my life is pretty chaotic in many, many ways."}, {"time": 11860, "text": "My friends and family will tell me that at every opportunity."}, {"time": 11864, "text": "But the thing is, I once had a, I'll tell you an example of a really funny incident that occurred to me because I led this student revolt at Sydney University as I mentioned when I was 20 years old."}, {"time": 11876, "text": "So I was at a restaurant one night and I found a bunch of guys, all guys, who'd done accounting at the university but had also been part of the student revolt."}, {"time": 11884, "text": "So they hadn't seen me for about a decade and they said, what have you been doing, Steve?"}, {"time": 11887, "text": "And I talked about what I'd done."}, {"time": 11889, "text": "So I'd been a school teacher for a while."}, {"time": 11890, "text": "I then worked in overseas aid."}, {"time": 11893, "text": "I was doing computer programming at the time and had forgotten what else I was doing at that point."}, {"time": 11898, "text": "So I explained it to all of them and they were at a Bucks night, one of them having a wedding coming up the next week."}, {"time": 11903, "text": "And one of them said, I wish I'd done that."}, {"time": 11907, "text": "And there was silence around the table, it was obviously a silent agreement."}, {"time": 11911, "text": "And I looked at them and said, hang on, guys, look at the downside of my life."}, {"time": 11915, "text": "You know, like you're getting married, I don't have a girlfriend right now, you've all got secure jobs, I'm unemployed, okay, you own a house, I haven't even got a car, you know, look at the downside of my life."}, {"time": 11929, "text": "And the bloke was the kingpin of that group, they're a very innovative bunch of guys in the student revolt."}, {"time": 11934, "text": "And so he said, Steve, we would still all rather have done what you have done."}, {"time": 11941, "text": "And they did a county because it was safe, you always get a job, and they were bored shitless."}, {"time": 11946, "text": "Did you have a sense that the chaos you're always jumping into was dangerous or was it just the pull of it?"}, {"time": 11956, "text": "I simply couldn't not do it."}, {"time": 11958, "text": "It was part of me that I couldn't swallow this economic stuff."}, {"time": 11962, "text": "Once I was exposed to why it was so wrong, then I was on a crusade to make it right."}, {"time": 11969, "text": "And that's been part of my nature all through my life, I don't know why."}, {"time": 11972, "text": "So it wasn't that I made a choice to do it, it's that I couldn't be true to myself without doing it."}, {"time": 11978, "text": "And I find a lot of people get caught in a life where they're doing it because it works for some financial or other reason, but they're not being true to themselves."}, {"time": 11986, "text": "And as messy as my life is, as much shit I've got myself caught up in, and there's a lot of that in my personal and financial life right now, which is a pain in the ass."}, {"time": 11995, "text": "I would rather have had that nature than not."}, {"time": 11998, "text": "You would rather take the pain in the ass than not."}, {"time": 12002, "text": "Let me ask a dark question."}, {"time": 12006, "text": "What's the darkest place you've ever gone to in your mind?"}, {"time": 12009, "text": "So in all that rollercoaster of life, have there been periods where it's been really tough?"}, {"time": 12016, "text": "I've had to cope with depression in the last five years since I started reading Neoclassical Economists on Climate Change."}, {"time": 12023, "text": "Sorry to laugh."}, {"time": 12024, "text": "Got to come back to that one."}, {"time": 12025, "text": "So that's where my wife's going to come into this story."}, {"time": 12028, "text": "So I was reading Richard Toll, a paper from 2009 called The Economics of Climate Change, Journal of Economic Perspectives, I think."}, {"time": 12037, "text": "And I read this section where he says that one of the ways they tried to calibrate what climate change was due is they assumed that the relationship between GDP and temperature over space would apply over time as well."}, {"time": 12054, "text": "And I read that and thought, that is so fucking stupid, because all it's saying is that if there's a 10 degree temperature difference between New York and Florida and a 20% difference in income, then a 10 degree increase in temperature will cause GDP to fall by 20%."}, {"time": 12068, "text": "It is so insanely stupid."}, {"time": 12070, "text": "So when I read that line, I just did this."}, {"time": 12076, "text": "I was in shock at how stupid it was."}, {"time": 12078, "text": "My wife, who's Thai and brings in treats for me all day, walks into the room and she speaks in a staccato English and says to me, why are you like this?"}, {"time": 12089, "text": "And I said, I'm just doing this work on climate change."}, {"time": 12091, "text": "And she interrupts me and says, oh, why you do that stuff?"}, {"time": 12095, "text": "Nobody's interested in climate change."}, {"time": 12096, "text": "You can't do anything to change it."}, {"time": 12098, "text": "If we die, we die."}, {"time": 12101, "text": "And that's perfect Buddhist grounding."}, {"time": 12104, "text": "And I thought, well, I can't argue with her again."}, {"time": 12108, "text": "So that sort of stopped me on the depression, but that's the darkest point when I looked at it and I thought that this arrogance, this stupidity, this humbug in the economists meant that we were potentially jeopardizing the lives of billions of people and Christ knows how many other life forms."}, {"time": 12128, "text": "And having that knowledge is the most depressing experience of my life."}, {"time": 12133, "text": "That ideas, simple models combined with arrogance can lead to the potential destruction of human civilization."}, {"time": 12144, "text": "That was a very heavy."}, {"time": 12145, "text": "And then your wife came in with Nature Wins in the End and sort of accept the flow of life."}, {"time": 12156, "text": "I really enjoy that book, The Earth Abides, because it's got that same beautiful sense to it."}, {"time": 12161, "text": "Life will survive whatever we do."}, {"time": 12162, "text": "I mean, they talk about the people, I was actually talking with a good mate of mine, an ex geologist, and he's now a professor of economics."}, {"time": 12169, "text": "And he said as a geologist, he really hated people talking about the Anthropocene epoch."}, {"time": 12174, "text": "And I said, well, it shouldn't be the Anthropocene epoch, it'll be the Anthropocene event."}, {"time": 12180, "text": "Anthropocene epoch is millions of years and a huge period of life on the planet."}, {"time": 12186, "text": "And we might be snuffed out in 10,000 years of human civilization."}, {"time": 12192, "text": "And that's not much slower than the meteors wiping out the dinosaurs."}, {"time": 12196, "text": "The dinosaurs lasted for a long time after that event."}, {"time": 12199, "text": "So we'd just be a layer in the surface of the planet with plastics and strange metals like that at some point."}, {"time": 12209, "text": "So we're just an epoch."}, {"time": 12210, "text": "Life will abide."}, {"time": 12211, "text": "Life will survive us."}, {"time": 12212, "text": "But there's so much life we're going to take down with us in this whole period."}, {"time": 12217, "text": "And there's so many of our own lives we're going to terminate for no good reason."}, {"time": 12223, "text": "I'm looking at this Richard Toll character."}, {"time": 12226, "text": "I'll definitely have to look at some of his papers."}, {"time": 12228, "text": "It does look like, boy, is he oversimplifying and do a lot of people."}, {"time": 12233, "text": "Check his one on how good it'll be to lose Amok."}, {"time": 12237, "text": "That said, I'm going to approach all of these topics with humility."}, {"time": 12243, "text": "And I would like to have some conversations if people can recommend."}, {"time": 12247, "text": "My default position is always with the scientists, but even above that, my default position is with those who are humble versus those who are arrogant."}, {"time": 12256, "text": "This idea that because you're a quote unquote expert, you deserve to have arrogance is a silly idea to me."}, {"time": 12263, "text": "Again, going to the broader view of life on earth, nature."}, {"time": 12269, "text": "Nature's the only one that gets to be arrogant and it chooses not to."}, {"time": 12275, "text": "So let me ask you about love."}, {"time": 12279, "text": "What role does love play in this whole thing?"}, {"time": 12281, "text": "Did Karl Marx have a model for that?"}, {"time": 12283, "text": "Oh, Marx was madly in love with Jenny von Westphalen and wrote love poetry to her long before he wrote Das Kapital."}, {"time": 12291, "text": "And he was infatuated with her."}, {"time": 12292, "text": "He ended up also impregnating his housekeeper."}, {"time": 12297, "text": "So there's a son of Karl Marx, who was the son of the housekeeper, not the Jenny."}, {"time": 12302, "text": "There are numerous daughters."}, {"time": 12305, "text": "So he had a complicated view of love."}, {"time": 12310, "text": "There's a dialectic on love there."}, {"time": 12312, "text": "He had an idealistic view with Jenny and he was rejected because he wasn't, not by Jenny, she was madly in love with him as well."}, {"time": 12322, "text": "So it was a real passionate love affair from the very outset."}, {"time": 12325, "text": "But then of course you have children, lots of them die."}, {"time": 12328, "text": "There's a huge amount of tragedy in his life as well."}, {"time": 12331, "text": "He and Jenny were forced out of Chelsea by a cholera epidemic."}, {"time": 12337, "text": "My vision for London back in the 1850s and 60s was Calcutta in the 1970s."}, {"time": 12343, "text": "That's really what life was like."}, {"time": 12345, "text": "So there's a lot of hardship in his life as well."}, {"time": 12348, "text": "And he was always poor."}, {"time": 12350, "text": "So only Ingalls kept him alive financially."}, {"time": 12354, "text": "He applied for one job outside of, he never got an academic job."}, {"time": 12361, "text": "He was pushed out of Prussia as a newspaper author, but he also applied for a job as a clerk in the British railway system, was turned down because they couldn't read his handwriting."}, {"time": 12375, "text": "I think I'm a bit similar there."}, {"time": 12378, "text": "So yeah, there's a lot of love and passion."}, {"time": 12381, "text": "But in general, what do you think is the role of love in the human condition?"}, {"time": 12384, "text": "It's vital."}, {"time": 12385, "text": "It's, I mean, that feeling of passionate desire and respect for somebody else."}, {"time": 12393, "text": "And there's perverted forms of love as well."}, {"time": 12395, "text": "So I'll leave that out, but somebody having a really, a deep bond, which goes beyond just sexual attraction."}, {"time": 12403, "text": "Like I've had that four or five times in my life with different women at different times."}, {"time": 12408, "text": "And I've stuffed up the most important one very early on."}, {"time": 12412, "text": "And that feeling is incredible."}, {"time": 12416, "text": "And you couldn't have life worth living without that."}, {"time": 12421, "text": "So it's an essential part of who we are."}, {"time": 12424, "text": "But what we have to do is to transfer it, not just to the rest of our species, but to all the species."}, {"time": 12430, "text": "And that's, I think, what's vital."}, {"time": 12432, "text": "And how do we maintain that over generations?"}, {"time": 12436, "text": "And I think that idea that we can actually hang on to that general sense of respect and not lose it again."}, {"time": 12443, "text": "Because the amount of life we've terminated on this planet, the warlike side of humanity, that is too much of a defining feature of our species."}, {"time": 12452, "text": "That's the opposite of love, it's hate."}, {"time": 12455, "text": "But it's pleasure and inflicting pain on others."}, {"time": 12457, "text": "When you see people killing others in a warlike environment, they're enjoying themselves."}, {"time": 12462, "text": "It's rarely, sometimes it's self defense."}, {"time": 12464, "text": "But there's, when I've spoken to people who've been involved in combat and been involved in riots and said, when you see somebody rioting, bashing people up, they're enjoying themselves."}, {"time": 12474, "text": "It's not anger they're feeling, it's pleasure."}, {"time": 12476, "text": "There's a dark aspect to human nature."}, {"time": 12478, "text": "Very dark."}, {"time": 12479, "text": "But there's also the capacity to rise above that."}]}, {"title": "Noam Chomsky: Putin, Ukraine, China, and Nuclear War | Lex Fridman Podcast #316", "id": "7uHGlfeCBbE", "quotes": [{"time": 437, "text": "Putin objected."}, {"time": 437, "text": "Other Russian leaders objected."}, {"time": 437, "text": "They're unified on this, but didn't do much."}, {"time": 446, "text": "They continued with the proposals that Ukraine be excluded from NATO, and that there be some form of autonomy for the Donbass region."}, {"time": 463, "text": "Meanwhile, in reaction to the uprising, the Maidan Uprising 2014, Russia moved in and took over Crimea, protecting its warm water base and major naval base."}, {"time": 481, "text": "The US objected and recognised it, but things continued without notable conflict."}, {"time": 489, "text": "I won't go through all the details."}, {"time": 489, "text": "When Joe Biden came in, he expanded the program of what US military journals call a defective integration of Ukraine within NATO, proposed September 2021, proposed enhanced program of preparation for NATO mission, extended with a formal statement in November."}, {"time": 520, "text": "We're now practically up to the invasion."}, {"time": 528, "text": "Putin's position hardened."}, {"time": 528, "text": "France, mainly France, to an extent Germany, did make some moves towards possible negotiations."}, {"time": 535, "text": "Putin dismissed them, moved on to the direct invasion."}, {"time": 544, "text": "What are his, to get back to your question, what motivates him?"}, {"time": 556, "text": "I presume what he's been saying all along, namely establishing his legacy as a leader who overcame the extensive destruction of Russia, massive weakening over it, restored his position as a world power, prevented Ukraine from entering NATO."}, {"time": 582, "text": "It may have further ambitions as to dominating and controlling Ukraine, very likely."}, {"time": 590, "text": "There is a theory in the West that he suddenly became a total madman who wants to restore the great Russian empire."}, {"time": 602, "text": "This is combined with the gloating over the fact that the Russian military is a paper tiger that can't even conquer cities a couple of kilometers from the border, but defended not even by a regular army."}, {"time": 623, "text": "But somehow along with this, he's planning to attack NATO powers, conquer Europe, who knows what."}, {"time": 632, "text": "It's impossible to put all these concepts together."}, {"time": 632, "text": "They're totally internally contradictory."}, {"time": 639, "text": "So what's my judgment?"}, {"time": 639, "text": "I think what motivates him is what he's been demonstrating in his actions."}, {"time": 648, "text": "Restore Russia as a great power, restore its economy, control it as a total dictatorship, enrich himself and his cronies, establish a legacy as a major figure in Russian history, make sure that Ukraine does not join NATO, and probably by now he's hardened the position, maintain Crimea and the southeastern corridor to Russia, and some ambiguous agreements about the Donbass region."}, {"time": 692, "text": "That looks like his motivation."}, {"time": 692, "text": "There's much speculation that goes beyond this, but it's very hard to reconcile with the assessment of the real world by the same people who are making the grandiose speculations."}, {"time": 714, "text": "I don't think anything's changed."}, {"time": 724, "text": "It seems to me his policies are about the same as what they were."}, {"time": 724, "text": "They've changed in response to changed circumstances."}, {"time": 734, "text": "So very recently, right before the invasion, a few weeks before, for the first time, Putin announced recognition of the independence of the Donbass region."}, {"time": 742, "text": "That's a stronger position than before, much stronger."}, {"time": 754, "text": "Up till then, he had pretty much kept to the longstanding position of some kind of accommodation within a federal structure in which the Donbass region would have considerable autonomy."}, {"time": 765, "text": "So that's a harshening of the position."}, {"time": 773, "text": "So even the human mind of Vladimir Putin, the man?"}, {"time": 777, "text": "I can't read his mind."}, {"time": 777, "text": "I can only see the policies that he's pursued and the statements that he's made."}, {"time": 784, "text": "There are many people speculating about his mind."}, {"time": 784, "text": "And as I say, these speculations are, first of all, not based on anything."}, {"time": 795, "text": "Never said anything about trying to conquer NATO."}, {"time": 795, "text": "But more importantly, they are totally inconsistent with the analyses of Russian power by the same people who are making the speculations."}, {"time": 811, "text": "So we see the same individual speculating about Putin's grandiose plans to become Peter the Great and conquer, start attacking NATO powers, on the one hand saying that, on the other hand gloating over the fact that his military powers so minuscule he can't even conquer towns a couple miles from the border."}, {"time": 843, "text": "Well, it's impossible to make sense of that position."}, {"time": 847, "text": "Why did Russia invade Ukraine on February 24th?"}, {"time": 847, "text": "Who do you think is to blame?"}, {"time": 847, "text": "Who do you place the blame on?"}, {"time": 857, "text": "Well, who's to blame?"}, {"time": 857, "text": "Any power that commits aggression is to blame."}, {"time": 857, "text": "So I continue to say, as I have been for many months, that Putin's invasion of Ukraine is on a par with such acts of aggression as the U.S. invasion of Iraq, the Stalin, Hitler invasion of Poland, other acts of supreme international crime under international law."}, {"time": 895, "text": "Of course he's to blame."}, {"time": 898, "text": "The U.S. committed $6.9 billion in military assistance to Ukraine since the Russian invasion."}, {"time": 904, "text": "Should U.S. keep up with this support?"}, {"time": 908, "text": "There are two questions."}, {"time": 908, "text": "One has to do with providing support for defense against the invasion, which is certainly legitimate."}, {"time": 918, "text": "The other is seeking ways to end the crime before even worse disasters arise."}, {"time": 928, "text": "Now that second part is not discussed in the West, barely discussed."}, {"time": 933, "text": "Anyone who dares to discuss it is immediately subjected to a flood of invective and hysterical condemnation."}, {"time": 943, "text": "But if you're serious about Ukraine, there are two things you ask."}, {"time": 948, "text": "One, what can we do to support Ukraine in defense against aggression?"}, {"time": 954, "text": "Second, how can we move to end the war before it leads to even worse destruction of Ukraine, more starvation worldwide, reversing the limited efforts to deal with global warming, possibly moving up an escalation out of the war, the nuclear war."}, {"time": 977, "text": "That's the second half of the borrow, a phrase attributed to Winston Churchill."}, {"time": 987, "text": "There's a lot of war, war, but no joy, joy, joy."}, {"time": 993, "text": "And there ought to be joy, joy if you care about Ukraine and the rest of the world."}, {"time": 999, "text": "Can it be done?"}, {"time": 1001, "text": "Official U.S. policy is to reject a diplomatic settlement, to move to weaken Russia severely so that it cannot carry out further aggression, but not do anything on the joy, joy side, not think of how to bring the crimes and atrocities to an end."}, {"time": 1027, "text": "That's the second part of the question."}, {"time": 1030, "text": "So, yes, the U.S. should continue with the kind of calibrated support that's been given."}, {"time": 1040, "text": "The Pentagon wisely has vetoed initiatives to go well beyond support for defense up to attack on Russia."}, {"time": 1054, "text": "So far, the Pentagon, which seems to be the dovish component in the U.S. administration, has vetoed plans which very likely would lead on to nuclear war, which would destroy everything."}, {"time": 1069, "text": "So calibrated provision of weapons to blunt the offensive, allow Ukraine to defend itself, if sensible, combined with efforts to see if something can be done to bring the crimes and atrocities to an end and avert the much worse consequences that are in store, that would be instead the U.S. only dealing with the first."}, {"time": 1101, "text": "And all of our discussions limit themselves to the first in the United States and in Britain, not in Europe."}, {"time": 1109, "text": "Do you worry about nuclear war in the 21st century?"}, {"time": 1109, "text": "How do we avoid it?"}, {"time": 1115, "text": "Anyone who doesn't worry about nuclear war doesn't have a gray cell functioning."}, {"time": 1121, "text": "Of course, everyone is worried about nuclear war, or should be."}, {"time": 1126, "text": "It's very easy to see how steps could be taken, even been recommended, that would lead to nuclear war."}, {"time": 1134, "text": "So you can read articles even by liberal commentators who say we should drop all the pretenses, just go to war against Russia."}, {"time": 1145, "text": "They have to be destroyed."}, {"time": 1148, "text": "You can see proposals coming from Congress, the leading figures, saying we should establish a no fly zone."}, {"time": 1159, "text": "Pentagon objects."}, {"time": 1159, "text": "They point out correctly that to establish a no fly zone, you have to have control of the air, which means destroying Russian air defense systems, which happen to be inside Russia."}, {"time": 1177, "text": "We don't know that Russia won't react."}, {"time": 1181, "text": "Even the call, now almost universal, to ensure that Ukraine wins, drives out all the Russians, drives them out of the country, sounds nice on paper, but notice the assumption."}, {"time": 1198, "text": "The assumption is that Vladimir Putin, this madman who just seeks power and is out of control, will sit there quietly, accept defeat, slink away, not use the military means that of course he has to destroy Ukraine."}, {"time": 1220, "text": "One of the interesting comments that came out in today's long article, I think Washington Post reviewing a lot of leaks, actually not leaks, actually presented by U.S. intelligence and U.S. leaders about the long build up to the war."}, {"time": 1241, "text": "One of the points it made was surprised on the part of British and U.S. leaders about Putin's strategy and his failure to adopt, to fight the war the way the U.S. and Britain would, with real shock and awe, destruction of communication facilities, of energy facilities and so on."}, {"time": 1264, "text": "They can't understand why he hasn't done all that."}, {"time": 1267, "text": "If you want to make it very likely that that will happen, then insist on fighting until somehow Russia faces total defeat."}, {"time": 1281, "text": "Then it's a gamble, but if he's as crazy and insane as you claim, presumably will use weapons that he hasn't used yet to destroy Ukraine."}, {"time": 1295, "text": "So the West is taking an extraordinary gamble with the fate of Ukraine."}, {"time": 1301, "text": "Gambling that the madman, lunatic, mad Vlad won't use the weapons he has to destroy Ukraine and set the stage for escalation of the latter which might lead to nuclear war."}, {"time": 1318, "text": "It's quite a gamble."}, {"time": 1320, "text": "How much propaganda is there in the world today in Russia, in Ukraine, in the West?"}, {"time": 1326, "text": "It's extraordinary."}, {"time": 1328, "text": "In Russia, of course, it's total."}, {"time": 1332, "text": "Ukraine is a different story."}, {"time": 1334, "text": "They're at war."}, {"time": 1335, "text": "They expect propaganda."}, {"time": 1337, "text": "In the West, let me quote Graham Fuller, very highly placed in U.S. intelligence, one of the top officials for decades dealing mostly with Russia and Central Asia."}, {"time": 1356, "text": "He recently said that in all the years of the Cold War, he's never seen any extreme Russia phobia to the extent that he sees today."}, {"time": 1369, "text": "I think that's pretty accurate."}, {"time": 1373, "text": "I mean, the U.S. has even canceled Russian outlets, which means if you want to find out what Sergei Lavrov or other Russian officials are saying, you can't look it up on their own outlets."}, {"time": 1394, "text": "You have to go through Al Jazeera, Indian state television or someplace where they still allow Russian positions to be expressed."}, {"time": 1407, "text": "And of course, the propaganda is just outlandish."}, {"time": 1411, "text": "I think Fuller is quite correct on this."}, {"time": 1414, "text": "In Russia, of course, you expect total propaganda."}, {"time": 1418, "text": "There's nothing, any independent outlets such as there were have been crushed."}, {"time": 1426, "text": "If the media is a source of inaccuracies and even lies, then how do we find the truth?"}, {"time": 1434, "text": "I don't regard the media as a source of inaccuracies and lies."}, {"time": 1441, "text": "They do exist."}, {"time": 1443, "text": "But by and large, media reporting is reasonably accurate."}, {"time": 1449, "text": "Reporters, the journalists themselves, as in the past, do courageous, honest work."}, {"time": 1459, "text": "I've written about this for 50 years."}, {"time": 1463, "text": "My opinion hasn't changed."}, {"time": 1466, "text": "But they do pick certain things and not other things."}, {"time": 1471, "text": "There's selection, there's framing, there's ways of presenting things."}, {"time": 1477, "text": "All of that forms a kind of propaganda system, which you have to work your way through."}, {"time": 1485, "text": "But it's rarely a matter of straight, outright lying."}, {"time": 1490, "text": "So there's a difference between propaganda and lying?"}, {"time": 1494, "text": "Of course, a propaganda system shapes and limits the material that's presented."}, {"time": 1502, "text": "It may tell the truth within that framework."}, {"time": 1505, "text": "So let me give you a concrete example, which I wrote about extensively."}, {"time": 1512, "text": "I have a book called Manufacturing Consent jointly with Edward Herman."}, {"time": 1519, "text": "It's about his term, which I had accepted a propaganda model of the media."}, {"time": 1526, "text": "A large part of the book is defense of the media."}, {"time": 1530, "text": "Defense of the media against harsh attacks by Freedom House."}, {"time": 1536, "text": "Several volumes they published attacking the media, charging that the media were so adversarial and dishonest that they lost the war in Vietnam."}, {"time": 1547, "text": "Well, it took the trouble of reading through the two volumes."}, {"time": 1552, "text": "One volume is charges, the next volume is evidence."}, {"time": 1557, "text": "Turns out that all of the evidence is lies."}, {"time": 1561, "text": "They had no evidence."}, {"time": 1563, "text": "They were just lying."}, {"time": 1565, "text": "The media, in fact, the journalists were doing honest, courageous work."}, {"time": 1571, "text": "But within a certain framework."}, {"time": 1576, "text": "A framework of assuming that the American cause was basically just, basically honorable, making mistakes, doing bad things."}, {"time": 1588, "text": "But the idea of questioning that the United States was engaged in a major war crime."}, {"time": 1598, "text": "That's off the record."}, {"time": 1600, "text": "So unfortunately, there was this crime and that crime which harmed their effort to do good and so on."}, {"time": 1610, "text": "Well, that's not lying, it's propaganda."}, {"time": 1613, "text": "So how do we find the truth?"}, {"time": 1615, "text": "How do we find the truth?"}, {"time": 1618, "text": "That's what you have a brain for."}, {"time": 1621, "text": "It's not deep."}, {"time": 1623, "text": "It's quite shallow."}, {"time": 1625, "text": "It's not quantum physics."}, {"time": 1627, "text": "Put a little effort into it."}, {"time": 1629, "text": "Think about, look for other sources."}, {"time": 1633, "text": "Think a little about history."}, {"time": 1635, "text": "Look at the documentary record."}, {"time": 1638, "text": "They're all pretty well fools together and you can get a reasonable understanding of what's happening."}, {"time": 1645, "text": "If you could sit down with Vladimir Putin and ask him a question or talk to him about an idea, what would you say?"}, {"time": 1655, "text": "I would walk out of the room, just as with almost any other leader."}, {"time": 1660, "text": "I know what he's going to say."}, {"time": 1662, "text": "I read the party line."}, {"time": 1663, "text": "I read his pronouncements."}, {"time": 1665, "text": "Doesn't want to hear from me."}, {"time": 1667, "text": "Am I going to say, why did you carry out a crime that's comparable to the US invasion of Iraq and the Stalin Hitler invasion of Poland?"}, {"time": 1679, "text": "Am I going to ask that question?"}, {"time": 1682, "text": "If I met with John F. Kennedy today, would I ask, why did you radically escalate the war in Vietnam, launch the US Air Force, start authorized napalm, drive launch programs to drive villagers who you know are supporting the National Liberation Front, drive them into concentration camps to separate them from the forces they're defending?"}, {"time": 1712, "text": "Would I have asked him that?"}, {"time": 1716, "text": "Do you think the people who led us into the war in Vietnam, the war in Afghanistan and Iraq, the war in Ukraine are evil?"}, {"time": 1730, "text": "I mean, it's very hard to be in a position of leadership of a violent, aggressive power without carrying out evil acts."}, {"time": 1743, "text": "Are the people evil?"}, {"time": 1746, "text": "I mean, I'm not their moral advisors."}, {"time": 1753, "text": "I look at their actions, their statements, their policies, evaluate those."}, {"time": 1759, "text": "Their families can evaluate their personalities."}, {"time": 1764, "text": "Will there be a war between US and China in the 21st century?"}, {"time": 1769, "text": "If there is, we're finished."}, {"time": 1773, "text": "A war between the US and China would destroy the possibilities of organized life on Earth."}, {"time": 1783, "text": "In fact, we can put it differently."}, {"time": 1783, "text": "Unless the US and China reach an accommodation and work together and cooperatively, it's very unlikely that organized human society will survive."}, {"time": 1800, "text": "We are facing enormous problems, problems, destruction of the environment, endemics, threat of nuclear war."}, {"time": 1814, "text": "None of these decline of democratic functioning of an arena for rational discourse."}, {"time": 1823, "text": "None of these things have boundaries."}, {"time": 1826, "text": "We either work together to overcome them, which we can do, or we'll all sink together."}, {"time": 1834, "text": "That's the real question we should be asking."}, {"time": 1837, "text": "What the United States is doing is not helping."}, {"time": 1842, "text": "So the current US policy, which is perfectly open, nothing secret about it, is to what's called encircle China with sentinel states, South Korea, Japan, Australia, which will be heavily armed, provided by Biden with precision weapons aimed at China, backed by major naval operations, huge naval operations just took place in the Pacific."}, {"time": 1883, "text": "Many nations participating, RIMPAC didn't get reported here, as far as I know, but an enormous operation threatening China."}, {"time": 1892, "text": "All of this to encircle China, to continue with policies like that."}, {"time": 1901, "text": "Somebody like Pelosi, just to probably make her look more, I don't know what her motives are, taking a highly provocative, stupid act, opposed by the military, opposed by the White House."}, {"time": 1922, "text": "Yes, acts like that, which of course called for the response of highly dangerous."}, {"time": 1929, "text": "We don't have to do that."}, {"time": 1929, "text": "We don't have to increase the threat."}, {"time": 1934, "text": "I mean, right now, the last NATO summit, take a look at it."}, {"time": 1940, "text": "For the first time, it invited to attend countries that are in the sentinel states surrounding China and circling China from the east."}, {"time": 1953, "text": "And it, in fact, extended the range of NATO to what's called the Indo Pacific region."}, {"time": 1961, "text": "So all of us by now, the North Atlantic includes the whole Indo Pacific region to try to ensure that we can overcome the so called China threat."}, {"time": 1975, "text": "Certainly, we might ask exactly what the China threat is."}, {"time": 1975, "text": "It's done sometimes."}, {"time": 1983, "text": "So former prime minister of Australia, Paul Keating, well known international diplomat, had an article a while ago in the Australian press."}, {"time": 1996, "text": "That's right in the claws of the dragon asking, going through what the China threat is."}, {"time": 2002, "text": "He ran through the various claims, finally concluded the China threat is that China exists."}, {"time": 2010, "text": "It exists."}, {"time": 2010, "text": "It does not follow U.S. orders."}, {"time": 2010, "text": "It's not like Europe."}, {"time": 2016, "text": "Europe does what the United States tells it to do, even if it doesn't like it."}, {"time": 2022, "text": "China just ignores what the U.S. says."}, {"time": 2022, "text": "There's a formal way of describing this."}, {"time": 2029, "text": "There are two versions of the international order."}, {"time": 2034, "text": "One version is the U.N. based international order, which theoretically we subscribe to, but we don't accept."}, {"time": 2044, "text": "The U.N. based international order is unacceptable to the United States because it bans U.S. foreign policy."}, {"time": 2054, "text": "Literally, it explicitly bans the threat or use of force in international affairs, except under circumstances that almost never arise."}, {"time": 2067, "text": "Well, that's U.S. foreign policy."}, {"time": 2067, "text": "Try to find a president who isn't engaged in the threat or use of force in international affairs."}, {"time": 2076, "text": "So obviously we can't accept the U.N. based international system, even though under the Constitution, that's the supreme law of the land."}, {"time": 2088, "text": "So the United States has what's called a rule based international order."}, {"time": 2096, "text": "That's acceptable because it's the United States that sets the rules."}, {"time": 2102, "text": "So we want a rule based international order where the U.S. sets the rules."}, {"time": 2108, "text": "In commentary in the United States, even in scholarship, almost 100 percent calling for a rule based international order."}, {"time": 2120, "text": "Is that false?"}, {"time": 2120, "text": "Is it propaganda?"}, {"time": 2120, "text": "Of course it's propaganda because of what's not said and because of what's presupposed."}, {"time": 2131, "text": "An answer to an earlier question."}, {"time": 2131, "text": "Well, China does not accept the rule based international order."}, {"time": 2139, "text": "So when the U.S. imposes demands, Europe may not like them, but they follow them."}, {"time": 2147, "text": "China ignores them."}, {"time": 2147, "text": "So take, for example, the U.S. sanctions on Iran."}, {"time": 2155, "text": "The U.S. has to punish Iran because the United States pulled out of the, unilaterally pulled out of the Iran nuclear agreements."}, {"time": 2168, "text": "So in order to punish Iran for wrecking the agreements in violation of Security Council orders, we impose very harsh sanctions."}, {"time": 2179, "text": "Europe strongly opposes the sanctions, condemn them harshly, but it adheres to them because you don't disobey U.S. orders."}, {"time": 2195, "text": "That's too dangerous."}, {"time": 2195, "text": "They're not keeping to the rule based international order."}, {"time": 2203, "text": "Well, that's unacceptable."}, {"time": 2203, "text": "In fact, it's said pretty openly."}, {"time": 2203, "text": "You can hear the Secretary of State and others saying China is challenging our global hegemony."}, {"time": 2218, "text": "Yes, they are."}, {"time": 2218, "text": "They don't accept U.S. global hegemony, especially in the waters off China."}, {"time": 2225, "text": "They do a lot of rotten things, China."}, {"time": 2225, "text": "I mean, internally, there's all kind of repression, violence and so on."}, {"time": 2236, "text": "But first of all, that's not a threat to us."}, {"time": 2236, "text": "And second, the U.S. doesn't care about it because it easily accepts and supports comparable crimes and atrocities internal to allies."}, {"time": 2249, "text": "So, yes, we should protest it, but without hypocrisy."}, {"time": 2249, "text": "We have no standing to protest it."}, {"time": 2249, "text": "We support comparable things in all sorts of other places."}, {"time": 2261, "text": "Just take a look at the U.S. foreign aid."}, {"time": 2261, "text": "The leading recipient of U.S. foreign aid is Israel, which is engaged in constant terror, violence and repression, constant, almost daily."}, {"time": 2277, "text": "Second leading recipient is Egypt, one of the worst dictatorships in Egypt's history."}, {"time": 2285, "text": "About 60,000 people in jail, political prisoners tortured and so on."}, {"time": 2285, "text": "Do we care?"}, {"time": 2293, "text": "Second leading recipient."}, {"time": 2293, "text": "I mean, what are we talking about?"}, {"time": 2293, "text": "That's why most of the world just laughs at us."}, {"time": 2301, "text": "There's a lot of failure to understand here about why the global South doesn't join us in our proxy war against Russia, fighting Russia until it's severely weakened."}, {"time": 2318, "text": "They don't join us."}, {"time": 2318, "text": "Here, the question is, what's wrong with them?"}, {"time": 2323, "text": "They look into their minds to figure out what's wrong."}, {"time": 2323, "text": "They have a different attitude."}, {"time": 2323, "text": "They say, yes, we oppose the invasion of Ukraine, terrible crime."}, {"time": 2336, "text": "But what are you talking about?"}, {"time": 2336, "text": "This is what you do to us all the time."}, {"time": 2336, "text": "You don't care about crimes like this."}, {"time": 2336, "text": "That's most of the global South."}, {"time": 2346, "text": "We can't comprehend that because we're so insulated that we are just obviously right and everyone who doesn't go along must be wrong."}, {"time": 2357, "text": "Do you think the United States as a global leader, as an empire, may collapse in this century?"}, {"time": 2357, "text": "Why and how will it happen and how can we avoid it?"}, {"time": 2369, "text": "The United States can certainly harm itself severely."}, {"time": 2369, "text": "That's what we're doing right now."}, {"time": 2369, "text": "Right now, the greatest threat to the United States is internal countries tearing itself apart."}, {"time": 2389, "text": "I really don't have to run through it with you."}, {"time": 2389, "text": "Take a look at something as elementary as mortality."}, {"time": 2389, "text": "The United States is the only country outside of war, life expectancy is declining, mortality is increasing."}, {"time": 2412, "text": "It doesn't happen anywhere."}, {"time": 2412, "text": "You take a look at health outcomes generally."}, {"time": 2412, "text": "They're among the worst among the developed societies and health spending is about twice as high as the developed societies."}, {"time": 2428, "text": "You look at the charts, all of this starts around the late 1970s, early 80s."}, {"time": 2428, "text": "If you go back to that point, the United States was pretty much a normal developed country in terms of mortality, incarceration, health expenses, other measures."}, {"time": 2450, "text": "Since then, the United States has fallen off the chart."}, {"time": 2450, "text": "It's gone way off the chart."}, {"time": 2450, "text": "Well, that's the neoliberal assault of the last 40 years."}, {"time": 2450, "text": "It's had a major effect on the United States."}, {"time": 2465, "text": "It's left a lot of anger, resentment, violence."}, {"time": 2465, "text": "Meanwhile, the Republican Party has simply drifted off the spectrum."}]}]