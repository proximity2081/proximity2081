[{"title": "Yoshua Bengio: Deep Learning | Lex Fridman Podcast #4", "id": "azOmzumh0vQ", "quotes": [{"time": 477, "text": "Yeah, I've heard you mention in several contexts, the idea of sort of the way children learn, they interact with objects in the world."}, {"time": 484, "text": "And it seems fascinating because in some sense, except with some cases in reinforcement learning, that idea is not part of the learning process in artificial neural networks."}, {"time": 495, "text": "So it's almost like, do you envision something like an objective function saying, you know what, if you poke this object in this kind of way, it would be really helpful for me to further learn."}, {"time": 517, "text": "Sort of almost guiding some aspect of the learning."}, {"time": 520, "text": "Right, right, right."}, {"time": 520, "text": "So I was talking to Rebecca Sacks just a few minutes ago, and she was talking about lots and lots of evidence from infants seem to clearly pick what interests them in a directed way."}, {"time": 532, "text": "And so they're not passive learners, they focus their attention on aspects of the world, which are most interesting, surprising in a non trivial way."}, {"time": 550, "text": "That makes them change their theories of the world."}, {"time": 556, "text": "So that's a fascinating view of the future progress."}, {"time": 556, "text": "But on a more maybe boring question, do you think going deeper and larger, so do you think just increasing the size of the things that have been increasing a lot in the past few years, is going to be a big thing?"}, {"time": 578, "text": "I think increasing the size of the things that have been increasing a lot in the past few years will also make significant progress."}, {"time": 584, "text": "So some of the representational issues that you mentioned, they're kind of shallow, in some sense."}, {"time": 594, "text": "Oh, shallow in the sense of abstraction."}, {"time": 598, "text": "In the sense of abstraction, they're not getting some..."}, {"time": 600, "text": "I don't think that having more depth in the network in the sense of instead of 100 layers, you're going to have more layers."}, {"time": 606, "text": "I don't think so."}, {"time": 606, "text": "Is that obvious to you?"}, {"time": 611, "text": "What is clear to me is that engineers and companies and labs and grad students will continue to tune architectures and explore all kinds of tweaks to make the current state of the art slightly ever slightly better."}, {"time": 625, "text": "But I don't think that's going to be nearly enough."}, {"time": 625, "text": "I think we need changes in the way that we're considering learning to achieve the goal that these learners actually understand in a deep way the environment in which they are, you know, observing and acting."}, {"time": 646, "text": "But I guess I was trying to ask a question that's more interesting than just more layers."}, {"time": 653, "text": "It's basically, once you figure out a way to learn through interacting, how many parameters it takes to store that information."}, {"time": 660, "text": "So I think our brain is quite bigger than most neural networks."}, {"time": 667, "text": "Oh, I see what you mean."}, {"time": 667, "text": "Oh, I'm with you there."}, {"time": 667, "text": "So I agree that in order to build neural nets with the kind of broad knowledge of the world that typical adult humans have, probably the kind of computing power we have now is going to be insufficient."}, {"time": 685, "text": "So the good news is there are hardware companies building neural net chips."}, {"time": 685, "text": "And so it's going to get better."}, {"time": 690, "text": "However, the good news in a way, which is also a bad news, is that even our state of the art, deep learning methods fail to learn models that understand even very simple environments, like some grid worlds that we have built."}, {"time": 712, "text": "Even these fairly simple environments, I mean, of course, if you train them with enough examples, eventually they get it."}, {"time": 716, "text": "But it's just like, instead of what humans might need just dozens of examples, these things will need millions for very, very, very simple tasks."}, {"time": 730, "text": "And so I think there's an opportunity for academics who don't have the kind of computing power that, say, Google has to do really important and exciting research to advance the state of the art in training frameworks, learning models, agent learning in even simple environments that are synthetic, that seem trivial, but yet current machine learning fails on."}, {"time": 758, "text": "We talked about priors and common sense knowledge."}, {"time": 758, "text": "It seems like we humans take a lot of knowledge for granted."}, {"time": 763, "text": "So what's your view of these priors of forming this broad view of the world, this accumulation of information and how we can teach neural networks or learning systems to pick that knowledge up?"}, {"time": 778, "text": "So knowledge, for a while, the artificial intelligence was maybe in the 80s, like there's a time where knowledge representation, knowledge, acquisition, expert systems, I mean, the symbolic AI was a view, was an interesting problem set to solve and it was kind of put on hold a little bit, it seems like."}, {"time": 802, "text": "Because it doesn't work."}, {"time": 807, "text": "It doesn't work."}, {"time": 807, "text": "But that's right."}, {"time": 807, "text": "But the goals of that remain important."}, {"time": 814, "text": "Remain important."}, {"time": 814, "text": "And how do you think those goals can be addressed?"}, {"time": 819, "text": "So first of all, I believe that one reason why the classical expert systems approach failed is because a lot of the knowledge we have, so you talked about common sense intuition, there's a lot of knowledge like this, which is not consciously accessible."}, {"time": 841, "text": "There are lots of decisions we're taking that we can't really explain, even if sometimes we make up a story."}, {"time": 845, "text": "And that knowledge is also necessary for machines to take good decisions."}, {"time": 845, "text": "And that knowledge is hard to codify in expert systems, rule based systems and classical AI formalism."}, {"time": 862, "text": "And there are other issues, of course, with the old AI, like not really good ways of handling uncertainty, I would say something more subtle, which we understand better now, but I think still isn't enough in the minds of people."}, {"time": 877, "text": "There's something really powerful that comes from distributed representations, the thing that really makes neural nets work so well."}, {"time": 889, "text": "And it's hard to replicate that kind of power in a symbolic world."}, {"time": 889, "text": "The knowledge in expert systems and so on is nicely decomposed into like a bunch of rules."}, {"time": 898, "text": "Whereas if you think about a neural net, it's the opposite."}, {"time": 904, "text": "You have this big blob of parameters which work intensely together to represent everything the network knows."}, {"time": 910, "text": "And it's not sufficiently factorized."}, {"time": 910, "text": "It's not sufficiently factorized."}, {"time": 916, "text": "And so I think this is one of the weaknesses of current neural nets, that we have to take lessons from classical AI in order to bring in another kind of compositionality, which is common in language, for example, and in these rules, but that isn't so native to neural nets."}, {"time": 938, "text": "And on that line of thinking, disentangled representations."}, {"time": 938, "text": "So let me connect with disentangled representations, if you might, if you don't mind."}, {"time": 948, "text": "So for many years, I've thought, and I still believe that it's really important that we come up with learning algorithms, either unsupervised or supervised, but reinforcement, whatever, that build representations in which the important factors, hopefully causal factors are nicely separated and easy to pick up from the representation."}, {"time": 973, "text": "So that's the idea of disentangled representations."}, {"time": 973, "text": "It says transform the data into a space where everything becomes easy."}, {"time": 978, "text": "We can maybe just learn with linear models about the things we care about."}, {"time": 985, "text": "And I still think this is important, but I think this is missing out on a very important ingredient, which classical AI systems can remind us of."}, {"time": 998, "text": "So let's say we have these disentangled representations."}, {"time": 998, "text": "You still need to learn about the relationships between the variables, those high level semantic variables."}, {"time": 1003, "text": "They're not going to be independent."}, {"time": 1007, "text": "I mean, this is like too much of an assumption."}, {"time": 1007, "text": "They're going to have some interesting relationships that allow to predict things in the future, to explain what happened in the past."}, {"time": 1016, "text": "The kind of knowledge about those relationships in a classical AI system is encoded in the rules."}, {"time": 1021, "text": "Like a rule is just like a little piece of knowledge that says, oh, I have these two, three, four variables that are linked in this interesting way, then I can say something about one or two of them given a couple of others, right?"}, {"time": 1034, "text": "In addition to disentangling the elements of the representation, which are like the variables in a rule based system, you also need to disentangle the mechanisms that relate those variables to each other."}, {"time": 1051, "text": "So like the rules."}, {"time": 1051, "text": "So the rules are neatly separated."}, {"time": 1051, "text": "Like each rule is, you know, living on its own."}, {"time": 1057, "text": "And when I change a rule because I'm learning, it doesn't need to break other rules."}, {"time": 1063, "text": "Whereas current neural nets, for example, are very sensitive to what's called catastrophic forgetting, where after I've learned some things and then I learn new things, they can destroy the old things that I had learned, right?"}, {"time": 1074, "text": "If the knowledge was better factorized and separated, disentangled, then you would avoid a lot of that."}, {"time": 1086, "text": "Now, you can't do this in the sensory domain."}, {"time": 1090, "text": "What do you mean by sensory domain?"}, {"time": 1093, "text": "Like in pixel space."}, {"time": 1093, "text": "But my idea is that when you project the data in the right semantic space, it becomes possible to now represent this extra knowledge beyond the transformation from inputs to representations, which is how representations act on each other and predict the future and so on in a way that can be neatly disentangled."}, {"time": 1111, "text": "So now it's the rules that are disentangled from each other and not just the variables that are disentangled from each other."}, {"time": 1120, "text": "And you draw a distinction between semantic space and pixel, like does there need to be an architectural difference?"}, {"time": 1126, "text": "So there's the sensory space like pixels, which where everything is entangled."}, {"time": 1132, "text": "The information, like the variables are completely interdependent in very complicated ways."}, {"time": 1138, "text": "And also computation, like it's not just the variables, it's also how they are related to each other is all intertwined."}, {"time": 1143, "text": "But I'm hypothesizing that in the right high level representation space, both the variables and how they relate to each other can be disentangled."}, {"time": 1156, "text": "And that will provide a lot of generalization power."}, {"time": 1160, "text": "Generalization power."}, {"time": 1162, "text": "Distribution of the test set is assumed to be the same as the distribution of the training set."}, {"time": 1169, "text": "This is where current machine learning is too weak."}, {"time": 1169, "text": "It doesn't tell us anything, is not able to tell us anything about how our neural nets, say, are going to generalize to a new distribution."}, {"time": 1180, "text": "And, you know, people may think, well, but there's nothing we can say if we don't know what the new distribution will be."}, {"time": 1185, "text": "The truth is humans are able to generalize to new distributions."}, {"time": 1192, "text": "How are we able to do that?"}, {"time": 1194, "text": "Because there is something, these new distributions, even though they could look very different from the training distributions, they have things in common."}, {"time": 1197, "text": "So let me give you a concrete example."}, {"time": 1202, "text": "You read a science fiction novel."}, {"time": 1202, "text": "The science fiction novel, maybe, you know, brings you in some other planet where things look very different on the surface, but it's still the same laws of physics."}, {"time": 1215, "text": "And so you can read the book and you understand what's going on."}, {"time": 1220, "text": "So the distribution is very different."}, {"time": 1220, "text": "But because you can transport a lot of the knowledge you had from Earth about the underlying cause and effect relationships and physical mechanisms and all that, and maybe even social interactions, you can now make sense of what is going on on this planet where, like, visually, for example, things are totally different."}, {"time": 1245, "text": "Taking that analogy further and distorting it, let's enter a science fiction world of, say, Space Odyssey, 2001, with Hal."}, {"time": 1250, "text": "Or maybe, which is probably one of my favorite AI movies."}, {"time": 1260, "text": "And then there's another one that a lot of people love that may be a little bit outside of the AI community is Ex Machina."}, {"time": 1265, "text": "I don't know if you've seen it."}, {"time": 1271, "text": "By the way, what are your views on that movie?"}, {"time": 1271, "text": "Are you able to enjoy it?"}, {"time": 1276, "text": "Are there things I like and things I hate?"}, {"time": 1281, "text": "So you could talk about that in the context of a question I want to ask, which is, there's quite a large community of people from different backgrounds, often outside of AI, who are concerned about existential threat of artificial intelligence."}, {"time": 1292, "text": "You've seen this community develop over time."}, {"time": 1297, "text": "You've seen you have a perspective."}, {"time": 1297, "text": "So what do you think is the best way to talk about AI safety, to think about it, to have discourse about it within AI community and outside and grounded in the fact that Ex Machina is one of the main sources of information for the general public about AI?"}, {"time": 1316, "text": "So I think you're putting it right."}, {"time": 1316, "text": "There's a big difference between the sort of discussion we ought to have within the AI community and the sort of discussion that really matter in the general public."}, {"time": 1327, "text": "So I think the picture of Terminator and AI loose and killing people and super intelligence that's going to destroy us, whatever we try, isn't really so useful for the public discussion."}, {"time": 1378, "text": "Just to clarify, when you said killer robots, you mean autonomous weapon, weapon systems."}, {"time": 1384, "text": "Yes, I don't mean that's right."}, {"time": 1386, "text": "So I think these short and medium term concerns should be important parts of the public debate."}, {"time": 1393, "text": "Now, existential risk, for me is a very unlikely consideration, but still worth academic investigation in the same way that you could say, should we study what could happen if meteorite, you know, came to earth and destroyed it."}, {"time": 1410, "text": "So I think it's very unlikely that this is going to happen in or happen in a reasonable future."}, {"time": 1413, "text": "The sort of scenario of an AI getting loose goes against my understanding of at least current machine learning and current neural nets and so on."}, {"time": 1426, "text": "It's not plausible to me."}, {"time": 1426, "text": "But of course, I don't have a crystal ball and who knows what AI will be in 50 years from now."}, {"time": 1431, "text": "So I think it is worth that scientists study those problems."}, {"time": 1435, "text": "It's just not a pressing question as far as I'm concerned."}, {"time": 1439, "text": "So before I continue down that line, I have a few questions there."}, {"time": 1439, "text": "But what do you like and not like about Ex Machina as a movie?"}, {"time": 1445, "text": "Because I actually watched it for the second time and enjoyed it."}, {"time": 1449, "text": "I hated it the first time, and I enjoyed it quite a bit more the second time when I sort of learned to accept certain pieces of it, see it as a concept movie."}, {"time": 1463, "text": "What was your experience?"}, {"time": 1463, "text": "What were your thoughts?"}, {"time": 1466, "text": "So the negative is the picture it paints of science is totally wrong."}, {"time": 1466, "text": "Science in general and AI in particular."}, {"time": 1476, "text": "Science is not happening in some hidden place by some, you know, really smart guy, one person."}, {"time": 1484, "text": "This is totally unrealistic."}, {"time": 1484, "text": "This is not how it happens."}, {"time": 1484, "text": "Even a team of people in some isolated place will not make it."}, {"time": 1492, "text": "Science moves by small steps, thanks to the collaboration and community of a large number of people interacting."}, {"time": 1499, "text": "And all the scientists who are expert in their field kind of know what is going on, even in the industrial labs."}, {"time": 1514, "text": "It's information flows and leaks and so on."}, {"time": 1514, "text": "And the spirit of it is very different from the way science is painted in this movie."}, {"time": 1525, "text": "Yeah, let me ask on that point."}, {"time": 1525, "text": "It's been the case to this point that kind of even if the research happens inside Google or Facebook, inside companies, it still kind of comes out, ideas come out."}, {"time": 1536, "text": "Do you think that will always be the case with AI?"}, {"time": 1536, "text": "Is it possible to bottle ideas to the point where there's a set of breakthroughs that go completely undiscovered by the general research community?"}, {"time": 1547, "text": "Do you think that's even possible?"}, {"time": 1552, "text": "It's possible, but it's unlikely."}, {"time": 1552, "text": "It's not how it is done now."}, {"time": 1552, "text": "It's not how I can foresee it in the foreseeable future."}, {"time": 1559, "text": "But of course, I don't have a crystal ball and science is a crystal ball."}, {"time": 1569, "text": "And so who knows?"}, {"time": 1569, "text": "This is science fiction after all."}, {"time": 1574, "text": "I think it's ominous that the lights went off during that discussion."}, {"time": 1581, "text": "So the problem, again, there's one thing is the movie and you could imagine all kinds of science fiction."}, {"time": 1585, "text": "The problem for me, maybe similar to the question about existential risk, is that this kind of movie paints such a wrong picture of what is the actual science and how it's going on that it can have unfortunate effects on people's understanding of current science."}, {"time": 1605, "text": "And so that's kind of sad."}, {"time": 1610, "text": "There's an important principle in research, which is diversity."}, {"time": 1610, "text": "So in other words, research is exploration."}, {"time": 1618, "text": "Research is exploration in the space of ideas."}, {"time": 1618, "text": "And different people will focus on different directions."}, {"time": 1623, "text": "And this is not just good, it's essential."}, {"time": 1623, "text": "So I'm totally fine with people exploring directions that are contrary to mine or look orthogonal to mine."}, {"time": 1636, "text": "I am more than fine."}, {"time": 1636, "text": "I think it's important."}, {"time": 1636, "text": "I and my friends don't claim we have universal truth about what will, especially about what will happen in the future."}, {"time": 1644, "text": "Now that being said, we have our intuitions and then we act accordingly according to where we think we can be most useful and where society has the most to gain or to lose."}, {"time": 1656, "text": "We should have those debates and not end up in a society where there's only one voice and one way of thinking and research money is spread out."}, {"time": 1673, "text": "So disagreement is a sign of good research, good science."}, {"time": 1680, "text": "The idea of bias in the human sense of bias."}, {"time": 1680, "text": "How do you think about instilling in machine learning something that's aligned with human values in terms of bias?"}, {"time": 1688, "text": "We intuitively as human beings have a concept of what bias means, of what fundamental respect for other human beings means."}, {"time": 1701, "text": "But how do we instill that into machine learning systems, do you think?"}, {"time": 1706, "text": "So I think there are short term things that are already happening and then there are long term things that we need to do."}, {"time": 1712, "text": "In the short term, there are techniques that have been proposed and I think will continue to be improved and maybe alternatives will come up to take data sets in which we know there is bias, we can measure it."}, {"time": 1724, "text": "Pretty much any data set where humans are being observed taking decisions will have some sort of bias, discrimination against particular groups and so on."}, {"time": 1739, "text": "And we can use machine learning techniques to try to build predictors, classifiers that are going to be less biased."}, {"time": 1744, "text": "We can do it, for example, using adversarial methods to make our systems less sensitive to these variables we should not be sensitive to."}, {"time": 1758, "text": "So these are clear, well defined ways of trying to address the problem."}, {"time": 1758, "text": "Maybe they have weaknesses and more research is needed and so on."}, {"time": 1763, "text": "But I think in fact they are sufficiently mature that governments should start regulating companies where it matters, say like insurance companies, so that they use those techniques."}, {"time": 1775, "text": "Because those techniques will probably reduce the bias but at a cost."}, {"time": 1780, "text": "For example, maybe their predictions will be less accurate and so companies will not do it until you force them."}, {"time": 1788, "text": "All right, so this is short term."}, {"time": 1788, "text": "Long term, I'm really interested in thinking how we can instill moral values into computers."}, {"time": 1796, "text": "Obviously, this is not something we'll achieve in the next five or 10 years."}, {"time": 1801, "text": "How can we, you know, there's already work in detecting emotions, for example, in images, in sounds, in texts, and also studying how different agents interacting in different ways may correspond to patterns of, say, injustice, which could trigger anger."}, {"time": 1828, "text": "So these are things we can do in the medium term and eventually train computers to model, for example, how humans react emotionally."}, {"time": 1837, "text": "I would say the simplest thing is unfair situations which trigger anger."}, {"time": 1846, "text": "This is one of the most basic emotions that we share with other animals."}, {"time": 1852, "text": "I think it's quite feasible within the next few years that we can build systems that can detect these kinds of things to the extent, unfortunately, that they understand enough about the world around us, which is a long time away."}, {"time": 1861, "text": "But maybe we can initially do this in virtual environments."}, {"time": 1868, "text": "So you can imagine a video game where agents interact in some ways and then some situations trigger an emotion."}, {"time": 1874, "text": "I think we could train machines to detect those situations and predict that the particular emotion will likely be felt if a human was playing one of the characters."}, {"time": 1889, "text": "You have shown excitement and done a lot of excellent work with unsupervised learning."}, {"time": 1895, "text": "But there's been a lot of success on the supervised learning side."}, {"time": 1900, "text": "And one of the things I'm really passionate about is how humans and robots work together."}, {"time": 1906, "text": "And in the context of supervised learning, that means the process of annotation."}, {"time": 1906, "text": "Do you think about the problem of annotation put in a more interesting way as humans teaching machines?"}, {"time": 1922, "text": "Is there?"}, {"time": 1923, "text": "I think it's an important subject."}, {"time": 1923, "text": "Reducing it to annotation may be useful for somebody building a system tomorrow."}, {"time": 1929, "text": "But longer term, the process of teaching, I think, is something that deserves a lot more attention from the machine learning community."}, {"time": 1936, "text": "So there are people who have coined the term machine teaching."}, {"time": 1939, "text": "So what are good strategies for teaching a learning agent?"}, {"time": 1944, "text": "And can we design and train a system that is going to be a good teacher?"}, {"time": 1953, "text": "So in my group, we have a project called BBI or BBI game, where there is a game or scenario where there's a learning agent and a teaching agent."}, {"time": 1962, "text": "Presumably, the teaching agent would eventually be a human."}, {"time": 1968, "text": "But we're not there yet."}, {"time": 1968, "text": "And the role of the teacher is to use its knowledge of the environment, which it can acquire using whatever way brute force to help the learner learn as quickly as possible."}, {"time": 1984, "text": "So the learner is going to try to learn by itself, maybe using some exploration and whatever."}, {"time": 1990, "text": "But the teacher can choose, can have an influence on the interaction with the learner, so as to guide the learner, maybe teach it the things that the learner has most trouble with, or just add the boundary between what it knows and doesn't know, and so on."}, {"time": 2010, "text": "So there's a tradition of these kind of ideas from other fields and like tutorial systems, for example, and AI."}, {"time": 2016, "text": "And of course, people in the humanities have been thinking about these questions."}, {"time": 2025, "text": "But I think it's time that machine learning people look at this, because in the future, we'll have more and more human machine interaction with the human in the loop."}, {"time": 2035, "text": "And I think understanding how to make this work better, all the problems around that are very interesting and not sufficiently addressed."}, {"time": 2041, "text": "You've done a lot of work with language, too."}, {"time": 2046, "text": "What aspect of the traditionally formulated Turing test, a test of natural language understanding and generation in your eyes is the most difficult of conversation?"}, {"time": 2059, "text": "What in your eyes is the hardest part of conversation to solve for machines?"}, {"time": 2059, "text": "So I would say it's everything having to do with the non linguistic knowledge, which implicitly you need in order to make sense of sentences, things like the Winograd schema."}, {"time": 2072, "text": "So these sentences that are semantically ambiguous."}, {"time": 2077, "text": "In other words, you need to understand enough about the world in order to really interpret properly those sentences."}, {"time": 2083, "text": "I think these are interesting challenges for machine learning, because they point in the direction of building systems that both understand how the world works and this causal relationships in the world and associate that knowledge with how to express it in language, either for reading or writing."}, {"time": 2112, "text": "You speak French?"}, {"time": 2113, "text": "Yes, it's my mother tongue."}, {"time": 2114, "text": "It's one of the romance languages."}, {"time": 2114, "text": "Do you think passing the Turing test and all the underlying challenges we just mentioned depend on language?"}, {"time": 2120, "text": "Do you think it might be easier in French than it is in English, or is independent of language?"}, {"time": 2128, "text": "I think it's independent of language."}, {"time": 2128, "text": "I would like to build systems that can use the same principles, the same learning mechanisms to learn from human agents, whatever their language."}, {"time": 2146, "text": "Well, certainly us humans can talk more beautifully and smoothly in poetry, some Russian originally."}, {"time": 2153, "text": "I know poetry in Russian is maybe easier to convey complex ideas than it is in English."}, {"time": 2162, "text": "But maybe I'm showing my bias and some people could say that about French."}, {"time": 2162, "text": "But of course, the goal ultimately is our human brain is able to utilize any kind of those languages to use them as tools to convey meaning."}, {"time": 2178, "text": "Yeah, of course, there are differences between languages, and maybe some are slightly better at some things, but in the grand scheme of things, where we're trying to understand how the brain works and language and so on, I think these differences are minute."}, {"time": 2192, "text": "So you've lived perhaps through an AI winter of sorts?"}, {"time": 2199, "text": "How did you stay warm and continue your research?"}, {"time": 2204, "text": "Stay warm with friends."}, {"time": 2205, "text": "With friends."}]}, {"title": "Eric Schmidt: Google | Lex Fridman Podcast #8", "id": "hIC9FQpxVwQ", "quotes": [{"time": 304, "text": "What I did not understand was scaling."}, {"time": 308, "text": "I did not understand what would happen when you had 100 million as opposed to 100."}, {"time": 312, "text": "And so the, since then, and I have learned the benefit of scale, I always look for things which are going to scale to platforms, right?"}, {"time": 319, "text": "So mobile phones, Android, all those things."}, {"time": 323, "text": "There are, the world is in numerous, there are many, many people in the world, people really have needs."}, {"time": 328, "text": "They really will use these platforms and you can build big businesses on top of them."}, {"time": 332, "text": "So it's interesting."}, {"time": 333, "text": "So when you see a piece of technology, now you think, what will this technology look like when it's in the hands of a billion people?"}, {"time": 339, "text": "So an example would be that the market is so competitive now that if you can't figure out a way for something to have a million users or a billion users, it probably is not going to be successful because something else will become the general platform and your idea will become a lost idea or a specialized service with relatively few users."}, {"time": 364, "text": "So it's a path to generality."}, {"time": 365, "text": "It's a path to general platform use."}, {"time": 367, "text": "It's a path to broad applicability."}, {"time": 370, "text": "Now there are plenty of good businesses that are tiny."}, {"time": 372, "text": "So luxury goods, for example."}, {"time": 374, "text": "But if you want to have an impact at scale, you have to look for things which are of common value, common pricing, common distribution and solve common problems."}, {"time": 384, "text": "They're problems that everyone has."}, {"time": 386, "text": "And by the way, people have lots of problems."}, {"time": 388, "text": "Information, medicine, health, education and so forth."}, {"time": 391, "text": "Work on those problems."}, {"time": 392, "text": "Like you said, you're a big fan of the middle class."}, {"time": 396, "text": "Because there's so many of them."}, {"time": 397, "text": "There's so many of them."}, {"time": 398, "text": "By definition."}, {"time": 400, "text": "So any product, any thing that has a huge impact and improves their lives is a great business decision and it's just good for society."}, {"time": 408, "text": "And there's nothing wrong with starting off in the high end as long as you have a plan to get to the middle class."}, {"time": 415, "text": "There's nothing wrong with starting with a specialized market in order to learn and to build and to fund things."}, {"time": 421, "text": "So you start with a luxury market to build a general purpose market."}, {"time": 424, "text": "But if you define yourself as only a narrow market, someone else can come along with a general purpose market that can push you to the corner, can restrict the scale of operation, can force you to be a lesser impact than you might be."}, {"time": 437, "text": "So it's very important to think in terms of broad businesses and broad impact."}, {"time": 442, "text": "Even if you start in a little corner somewhere."}, {"time": 446, "text": "So as you look to the 70s but also in the decades to come and you saw computers, did you see them as tools or was there a little element of another entity?"}, {"time": 460, "text": "I remember a quote saying AI began with our dream to create the gods."}, {"time": 466, "text": "Is there a feeling when you wrote that program that you were creating another entity, giving life to something?"}, {"time": 472, "text": "I wish I could say otherwise, but I simply found the technology platforms so exciting."}, {"time": 478, "text": "That's what I was focused on."}, {"time": 480, "text": "I think the majority of the people that I've worked with, and there are a few exceptions, Steve Jobs being an example, really saw this as a great technological play."}, {"time": 489, "text": "I think relatively few of the technical people understood the scale of its impact."}, {"time": 495, "text": "So I used NCP, which is a predecessor to TCPIP."}, {"time": 499, "text": "It just made sense to connect things."}, {"time": 501, "text": "We didn't think of it in terms of the internet and then companies and then Facebook and then Twitter and then politics and so forth."}, {"time": 509, "text": "We never did that build."}, {"time": 510, "text": "We didn't have that vision."}, {"time": 512, "text": "And I think most people, it's a rare person who can see compounding at scale."}, {"time": 518, "text": "Most people can see, if you ask people to predict the future, they'll give you an answer of six to nine months or 12 months, because that's about as far as people can imagine."}, {"time": 527, "text": "But there's an old saying, which actually was attributed to a professor at MIT a long time ago, that we overestimate what can be done in one year and we underestimate what can be done in a decade."}, {"time": 540, "text": "And there's a great deal of evidence that these core platforms at hardware and software take a decade, right?"}, {"time": 547, "text": "So think about self driving cars."}, {"time": 549, "text": "Self driving cars were thought about in the 90s."}, {"time": 552, "text": "There were projects around them."}, {"time": 553, "text": "The first DARPA Grand Challenge was roughly 2004."}, {"time": 557, "text": "So that's roughly 15 years ago."}, {"time": 559, "text": "And today we have self driving cars operating in a city in Arizona, right?"}, {"time": 563, "text": "It's 15 years and we still have a ways to go before they're more generally available."}, {"time": 571, "text": "So you've spoken about the importance, you just talked about predicting into the future."}, {"time": 577, "text": "You've spoken about the importance of thinking five years ahead and having a plan for those five years."}, {"time": 582, "text": "The way to say it is that almost everybody has a one year plan."}, {"time": 587, "text": "Almost no one has a proper five year plan."}, {"time": 590, "text": "And the key thing to having a five year plan is to having a model for what's going to happen under the underlying platforms."}, {"time": 596, "text": "So here's an example."}, {"time": 599, "text": "Moore's Law as we know it, the thing that powered improvements in CPUs has largely halted in its traditional shrinking mechanism because the costs have just gotten so high."}, {"time": 610, "text": "It's getting harder and harder."}, {"time": 612, "text": "But there's plenty of algorithmic improvements and specialized hardware improvements."}, {"time": 616, "text": "So you need to understand the nature of those improvements and where they'll go in order to understand how it will change the platform."}, {"time": 624, "text": "In the area of network connectivity, what are the gains that are gonna be possible in wireless?"}, {"time": 629, "text": "It looks like there's an enormous expansion of wireless connectivity at many different bands."}, {"time": 636, "text": "And that we will primarily, historically I've always thought that we were primarily gonna be using fiber, but now it looks like we're gonna be using fiber plus very powerful high bandwidth sort of short distance connectivity to bridge the last mile."}, {"time": 651, "text": "That's an amazing achievement."}, {"time": 653, "text": "If you know that, then you're gonna build your systems differently."}, {"time": 656, "text": "By the way, those networks have different latency properties, right?"}, {"time": 659, "text": "Because they're more symmetric, the algorithms feel faster for that reason."}, {"time": 664, "text": "And so when you think about whether it's a fiber or just technologies in general, so there's this barber wooden poem or quote that I really like."}, {"time": 675, "text": "It's from the champions of the impossible rather than the slaves of the possible that evolution draws its creative force."}, {"time": 683, "text": "So in predicting the next five years, I'd like to talk about the impossible and the possible."}, {"time": 689, "text": "Well, and again, one of the great things about humanity is that we produce dreamers, right?"}, {"time": 694, "text": "We literally have people who have a vision and a dream."}, {"time": 697, "text": "They are, if you will, disagreeable in the sense that they disagree with the, they disagree with what the sort of zeitgeist is."}, {"time": 705, "text": "They say there is another way."}, {"time": 708, "text": "They have a belief, they have a vision."}, {"time": 710, "text": "If you look at science, science is always marked by such people who went against some conventional wisdom, collected the knowledge at the time and assembled it in a way that produced a powerful platform."}, {"time": 778, "text": "So in Google's case, we're big enough and well enough managed and so forth that we have a pretty good sense of what our revenue will be for the next year or two, at least for a while."}, {"time": 787, "text": "And so we have enough cash generation that we can make bets, and indeed, Google has become alphabet, so the corporation is organized around these bets, and these bets are in areas of fundamental importance to the world, whether it's artificial intelligence, medical technology, self driving cars, connectivity through balloons, on and on and on."}, {"time": 813, "text": "And there's more coming and more coming."}, {"time": 815, "text": "So one way you could express this is that the current business is successful enough that we have the luxury of making bets."}, {"time": 824, "text": "And another one that you could say is that we have the wisdom of being able to see that a corporate structure needs to be created to enhance the likelihood of the success of those bets."}, {"time": 835, "text": "So we essentially turned ourselves into a conglomerate of bets and then this underlying corporation, Google, which is itself innovative."}, {"time": 844, "text": "So in order to pull this off, you have to have a bunch of belief systems, and one of them is that you have to have bottoms up and tops down."}, {"time": 851, "text": "The bottoms up we call 20% time, and the idea is that people can spend 20% of the time whatever they want, and the top down is that our founders in particular have a keen eye on technology and they're reviewing things constantly."}, {"time": 863, "text": "So an example would be they'll hear about an idea or I'll hear about something and it sounds interesting, let's go visit them."}, {"time": 870, "text": "And then let's begin to assemble the pieces to see if that's possible."}, {"time": 874, "text": "And if you do this long enough, you get pretty good at predicting what's likely to work."}, {"time": 879, "text": "So that's a beautiful balance that struck."}, {"time": 882, "text": "Is this something that applies at all scale?"}, {"time": 884, "text": "It seems to be that Sergey, again, 15 years ago, came up with a concept called 10% of the budget should be on things that are unrelated."}, {"time": 898, "text": "It was called 70, 20, 10."}, {"time": 900, "text": "70% of our time on core business, 20% on adjacent business, and 10% on other."}, {"time": 906, "text": "And he proved mathematically, of course he's a brilliant mathematician, that you needed that 10% to make the sum of the growth work."}, {"time": 914, "text": "And it turns out he was right."}, {"time": 918, "text": "So getting into the world of artificial intelligence, you've talked quite extensively and effectively to the impact in the near term, the positive impact of artificial intelligence, whether it's especially machine learning in medical applications and education, and just making information more accessible, right?"}, {"time": 941, "text": "In the AI community, there is a kind of debate."}, {"time": 945, "text": "There's this shroud of uncertainty as we face this new world with artificial intelligence in it."}, {"time": 950, "text": "And there's some people, like Elon Musk, you've disagreed, at least on the degree of emphasis he places on the existential threat of AI."}, {"time": 960, "text": "So I've spoken with Stuart Russell, Max Tegmark, who share Elon Musk's view, and Yoshua Bengio, Steven Pinker, who do not."}, {"time": 969, "text": "And so there's a lot of very smart people who are thinking about this stuff, disagreeing, which is really healthy, of course."}, {"time": 977, "text": "So what do you think is the healthiest way for the AI community to, and really for the general public, to think about AI and the concern of the technology being mismanaged in some kind of way?"}, {"time": 992, "text": "So the source of education for the general public has been robot killer movies."}, {"time": 998, "text": "And Terminator, et cetera."}, {"time": 1000, "text": "And the one thing I can assure you we're not building are those kinds of solutions."}, {"time": 1006, "text": "Furthermore, if they were to show up, someone would notice and unplug them, right?"}, {"time": 1011, "text": "So as exciting as those movies are, and they're great movies, were the killer robots to start, we would find a way to stop them, right?"}, {"time": 1020, "text": "So I'm not concerned about that."}, {"time": 1024, "text": "And much of this has to do with the timeframe of conversation."}, {"time": 1028, "text": "So you can imagine a situation 100 years from now when the human brain is fully understood and the next generation and next generation of brilliant MIT scientists have figured all this out, we're gonna have a large number of ethics questions, right?"}, {"time": 1045, "text": "Around science and thinking and robots and computers and so forth and so on."}, {"time": 1049, "text": "So it depends on the question of the timeframe."}, {"time": 1052, "text": "In the next five to 10 years, we're not facing those questions."}, {"time": 1057, "text": "What we're facing in the next five to 10 years is how do we spread this disruptive technology as broadly as possible to gain the maximum benefit of it?"}, {"time": 1066, "text": "The primary benefits should be in healthcare and in education."}, {"time": 1070, "text": "Healthcare because it's obvious."}, {"time": 1072, "text": "We're all the same even though we somehow believe we're not."}, {"time": 1075, "text": "As a medical matter, the fact that we have big data about our health will save lives, allow us to deal with skin cancer and other cancers, ophthalmological problems."}, {"time": 1085, "text": "There's people working on psychological diseases and so forth using these techniques."}, {"time": 1090, "text": "I can go on and on."}, {"time": 1091, "text": "The promise of AI in medicine is extraordinary."}, {"time": 1095, "text": "There are many, many companies and startups and funds and solutions and we will all live much better for that."}, {"time": 1102, "text": "The same argument in education."}, {"time": 1105, "text": "Can you imagine that for each generation of child and even adult, you have a tutor educator that's AI based, that's not a human but is properly trained, that helps you get smarter, helps you address your language difficulties or your math difficulties or what have you."}, {"time": 1121, "text": "Why don't we focus on those two?"}, {"time": 1123, "text": "The gains societally of making humans smarter and healthier are enormous and those translate for decades and decades and we'll all benefit from them."}, {"time": 1133, "text": "There are people who are working on AI safety, which is the issue that you're describing and there are conversations in the community that should there be such problems, what should the rules be like?"}, {"time": 1144, "text": "Google, for example, has announced its policies with respect to AI safety, which I certainly support and I think most everybody would support and they make sense, right?"}, {"time": 1154, "text": "So it helps guide the research but the killer robots are not arriving this year and they're not even being built."}, {"time": 1162, "text": "And on that line of thinking, you said the time scale."}, {"time": 1166, "text": "In this topic or other topics, have you found it useful on the business side or the intellectual side to think beyond five, 10 years, to think 50 years out?"}, {"time": 1179, "text": "Has it ever been useful or productive?"}, {"time": 1181, "text": "In our industry, there are essentially no examples of 50 year predictions that have been correct."}, {"time": 1188, "text": "Let's review AI, right?"}, {"time": 1190, "text": "AI, which was largely invented here at MIT and a couple of other universities in the 1956, 1957, 1958, the original claims were a decade or two."}, {"time": 1201, "text": "And when I was a PhD student, I studied AI a bit and it entered during my looking at it, a period which is known as AI winter, which went on for about 30 years, which is a whole generation of science, scientists and a whole group of people who didn't make a lot of progress because the algorithms had not improved and the computers had not approved."}, {"time": 1222, "text": "It took some brilliant mathematicians starting with a fellow named Jeff Hinton at Toronto and Montreal who basically invented this deep learning model which empowers us today."}, {"time": 1233, "text": "The seminal work there was 20 years ago and in the last 10 years, it's become popularized."}, {"time": 1239, "text": "So think about the timeframes for that level of discovery."}, {"time": 1243, "text": "It's very hard to predict."}, {"time": 1245, "text": "Many people think that we'll be flying around in the equivalent of flying cars, who knows?"}, {"time": 1251, "text": "My own view, if I wanna go out on a limb, is to say that we know a couple of things about 50 years from now."}, {"time": 1257, "text": "We know that there'll be more people alive."}, {"time": 1260, "text": "We know that we'll have to have platforms that are more sustainable because the earth is limited in the ways we all know and that the kind of platforms that are gonna get built will be consistent with the principles that I've described."}, {"time": 1273, "text": "They will be much more empowering of individuals."}, {"time": 1275, "text": "They'll be much more sensitive to the ecology because they have to be, they just have to be."}, {"time": 1280, "text": "I also think that humans are gonna be a great deal smarter and I think they're gonna be a lot smarter because of the tools that I've discussed with you and of course, people will live longer."}, {"time": 1289, "text": "Life extension is continuing apace."}, {"time": 1292, "text": "A baby born today has a reasonable chance of living to 100, which is pretty exciting."}, {"time": 1297, "text": "It's well past the 21st century, so we better take care of them."}, {"time": 1300, "text": "And you mentioned an interesting statistic on some very large percentage, 60, 70% of people may live in cities."}, {"time": 1308, "text": "Today, more than half the world lives in cities and one of the great stories of humanity in the last 20 years has been the rural to urban migration."}, {"time": 1317, "text": "This has occurred in the United States, it's occurred in Europe, it's occurring in Asia and it's occurring in Africa."}, {"time": 1324, "text": "When people move to cities, the cities get more crowded, but believe it or not, their health gets better, their productivity gets better, their IQ and educational capabilities improve."}, {"time": 1335, "text": "So it's good news that people are moving to cities, but we have to make them livable and safe."}, {"time": 1340, "text": "So you, first of all, you are, but you've also worked with some of the greatest leaders in the history of tech."}, {"time": 1349, "text": "What insights do you draw from the difference in leadership styles of yourself, Steve Jobs, Elon Musk, Larry Page, now the new CEO, Sandra Pichai and others?"}, {"time": 1362, "text": "From the, I would say, calm sages to the mad geniuses."}, {"time": 1367, "text": "One of the things that I learned as a young executive is that there's no single formula for leadership."}, {"time": 1374, "text": "They try to teach one, but that's not how it really works."}, {"time": 1378, "text": "There are people who just understand what they need to do and they need to do it quickly."}, {"time": 1382, "text": "Those people are often entrepreneurs."}, {"time": 1385, "text": "They just know and they move fast."}, {"time": 1387, "text": "There are other people who are systems thinkers and planners, that's more who I am, somewhat more conservative, more thorough in execution, a little bit more risk of risk."}, {"time": 1396, "text": "A little bit more risk averse."}, {"time": 1398, "text": "There's also people who are sort of slightly insane, in the sense that they are emphatic and charismatic and they feel it and they drive it and so forth."}, {"time": 1408, "text": "There's no single formula to success."}, {"time": 1411, "text": "There is one thing that unifies all of the people that you named, which is very high intelligence."}, {"time": 1416, "text": "At the end of the day, the thing that characterizes all of them is that they saw the world quicker, faster, they processed information faster."}, {"time": 1425, "text": "They didn't necessarily make the right decisions all the time, but they were on top of it."}, {"time": 1429, "text": "And the other thing that's interesting about all those people is they all started young."}, {"time": 1434, "text": "So think about Steve Jobs starting Apple roughly at 18 or 19."}, {"time": 1438, "text": "Think about Bill Gates starting at roughly 20, 21."}, {"time": 1441, "text": "Think about by the time they were 30, Mark Zuckerberg, a good example, at 19, 20."}, {"time": 1446, "text": "By the time they were 30, they had 10 years."}, {"time": 1450, "text": "At 30 years old, they had 10 years of experience of dealing with people and products and shipments and the press and business and so forth."}, {"time": 1459, "text": "It's incredible how much experience they had compared to the rest of us who were busy getting our PhDs."}, {"time": 1466, "text": "So we should celebrate these people because they've just had more life experience, right?"}, {"time": 1472, "text": "And that helps inform the judgment."}, {"time": 1474, "text": "At the end of the day, when you're at the top of these organizations, all the easy questions have been dealt with, right?"}, {"time": 1483, "text": "How should we design the buildings?"}, {"time": 1485, "text": "Where should we put the colors on our product?"}, {"time": 1488, "text": "What should the box look like, right?"}, {"time": 1491, "text": "The problems, that's why it's so interesting to be in these rooms, the problems that they face, right, in terms of the way they operate, the way they deal with their employees, their customers, their innovation, are profoundly challenging."}, {"time": 1503, "text": "Each of the companies is demonstrably different culturally."}, {"time": 1509, "text": "They are not, in fact, cut of the same."}, {"time": 1511, "text": "They behave differently based on input."}, {"time": 1514, "text": "Their internal cultures are different."}, {"time": 1515, "text": "Their compensation schemes are different."}, {"time": 1517, "text": "Their values are different."}, {"time": 1519, "text": "So there's proof that diversity works."}, {"time": 1524, "text": "So, so when faced with a tough decision, in need of advice, it's been said that the best thing one can do is to find the best person in the world who can give that advice and find a way to be in a room with them, one on one and ask."}, {"time": 1544, "text": "So here we are, and let me ask in a long winded way, I wrote this down."}, {"time": 1550, "text": "In 1998, there were many good search engines, Lycos, Excite, AltaVista, Infoseek, Ask Jeeves maybe, Yahoo even."}, {"time": 1561, "text": "So Google stepped in and disrupted everything."}, {"time": 1564, "text": "They disrupted the nature of search, the nature of our access to information, the way we discover new knowledge."}, {"time": 1571, "text": "So now it's 2018, actually 20 years later."}, {"time": 1576, "text": "There are many good personal AI assistants, including, of course, the best from Google."}, {"time": 1582, "text": "So you've spoken in medical and education, the impact of such an AI assistant could bring."}, {"time": 1588, "text": "So we arrive at this question."}, {"time": 1590, "text": "So it's a personal one for me, but I hope my situation represents that of many other, as we said, dreamers and the crazy engineers."}, {"time": 1600, "text": "So my whole life, I've dreamed of creating such an AI assistant."}, {"time": 1605, "text": "Every step I've taken has been towards that goal."}, {"time": 1608, "text": "Now I'm a research scientist in human centered AI here at MIT."}, {"time": 1612, "text": "So the next step for me as I sit here, so facing my passion is to do what Larry and Sergey did in 98, this simple startup."}, {"time": 1624, "text": "And so here's my simple question."}, {"time": 1626, "text": "Given the low odds of success, the timing and luck required, the countless other factors that can't be controlled or predicted, which is all the things that Larry and Sergey faced, is there some calculation, some strategy to follow in this step?"}, {"time": 1641, "text": "Or do you simply follow the passion just because there's no other choice?"}, {"time": 1646, "text": "I think the people who are in universities are always trying to study the extraordinarily chaotic nature of innovation and entrepreneurship."}, {"time": 1657, "text": "My answer is that they didn't have that conversation."}, {"time": 1661, "text": "They just did it."}, {"time": 1662, "text": "They sensed a moment when in the case of Google, there was all of this data that needed to be organized and they had a better algorithm."}, {"time": 1671, "text": "They had invented a better way."}, {"time": 1673, "text": "So today with human centered AI, which is your area of research, there must be new approaches."}, {"time": 1680, "text": "It's such a big field."}, {"time": 1682, "text": "There must be new approaches, different from what we and others are doing."}, {"time": 1687, "text": "There must be startups to fund."}, {"time": 1689, "text": "There must be research projects to try."}]}, {"title": "Eric Weinstein: Revolutionary Ideas in Science, Math, and Society | Lex Fridman Podcast #16", "id": "2wq9x2QcZN0", "quotes": [{"time": 268, "text": "Well, do you think that's connected to intelligence or are we just two Jews on a mic that appreciate that kind of humor?"}, {"time": 274, "text": "No, I think that it's absolutely connected to intelligence."}, {"time": 277, "text": "So you can, you can see it."}, {"time": 280, "text": "There's a place where Tom Lehrer decides that he's going to lampoon Gilbert of Gilbert and Sullivan and he's going to outdo Gilbert with clever, meaningless wordplay."}, {"time": 289, "text": "And he has, forget the, well, let's see, he's doing Clementine as if Gilbert and Sullivan wrote it."}, {"time": 296, "text": "That I misunderstood depressed her young sister named Mr."}, {"time": 296, "text": "This Mr. Depester, she tried pestering sisters of festering blister you best to resist or say I, the sister persisted the Mr."}, {"time": 300, "text": "Resisted I kissed her all loyalty slip when he said, when she said I could have her, her sister's cadaver must surely have turned in its crypt."}, {"time": 310, "text": "That's so dense."}, {"time": 311, "text": "It's so insane that that's clearly intelligence because it's hard to construct something like that."}, {"time": 320, "text": "If I look at my favorite Tom Lehrer, Tom Lehrer lyric, you know, there's a perfectly absurd one, which is once all the Germans were warlike and mean, but that couldn't happen again."}, {"time": 330, "text": "We taught them a lesson in 1918 and they've hardly bothered us since then, right?"}, {"time": 334, "text": "That is a different kind of intelligence."}, {"time": 336, "text": "You know, you're taking something that is so horrific and you're, you're sort of making it palatable and funny and demonstrating also, um, just your humanity."}, {"time": 347, "text": "I mean, I think the thing that came through as, as Tom Lehrer wrote all of these terrible, horrible lines was just what a sensitive and beautiful soul he was, who was channeling pain through humor and through grace."}, {"time": 362, "text": "I've seen throughout Europe, throughout Russia, that same kind of humor emerged from the generation of world war II."}, {"time": 369, "text": "It seemed like that humor is required to somehow deal with the pain and the suffering of that, that war created."}, {"time": 376, "text": "You do need the environment to create the broad Slavic soul."}, {"time": 379, "text": "I don't think that many Americans really appreciate, um, Russian humor, how you had to joke during the time of, let's say article 58 under Stalin, you had to be very, very careful."}, {"time": 395, "text": "You know, the concept of a Russian satirical magazine like Crocodile, uh, doesn't make sense."}, {"time": 401, "text": "So you have this cross cultural problem that there are certain areas of human experience that it would be better to know nothing about."}, {"time": 411, "text": "And quite unfortunately, Eastern Europe knows a great deal about them, which makes the, you know, the songs of Vladimir Vysotsky so potent, the, uh, you know, the pros of Pushkin, whatever it is, uh, you have to appreciate the depth of the Eastern European experience."}, {"time": 429, "text": "And I would think that perhaps Americans knew something like this around the time of the civil war or merit maybe, um, you know, under slavery and Jim Crow or even the, uh, harsh tyranny of, uh, the coal and steel employers during the labor wars."}, {"time": 448, "text": "Um, but in general, I would say it's hard for us to understand and imagine the collective culture unless we have the system of selective pressures that, for example, uh, Russians were subjected to."}, {"time": 461, "text": "Yeah, so if there's one good thing that comes out of war, it's literature, art, and humor and music."}, {"time": 470, "text": "Oh, I don't think so."}, {"time": 472, "text": "I think almost everything is good about war except for death and destruction."}, {"time": 479, "text": "Without the death, it would bring, uh, the romance of it."}, {"time": 482, "text": "The whole thing is nice."}, {"time": 483, "text": "Well, this is why we're always caught up in war and we have this very ambiguous relationship to it is that it makes life real and pressing and meaningful and at an unacceptable price and the price has never been higher."}, {"time": 497, "text": "So just jump in, uh, into AI a little bit."}, {"time": 502, "text": "You, uh, in one of the conversations you had or one of the videos, you described that one of the things AI systems can't do and biological systems can is self replicate in the physical world."}, {"time": 515, "text": "Oh no, no."}, {"time": 517, "text": "In the physical world."}, {"time": 518, "text": "Well, yes, the physical robots can't self replicate, but the fit, but you, this is a very tricky point, which is that the only thing that we've been able to create that's really complex that has an analog of our reproductive system is software."}, {"time": 537, "text": "But nevertheless, software replicates itself."}, {"time": 541, "text": "Uh, if we're speaking strictly for the replication in this kind of digital space."}, {"time": 545, "text": "So let me just to begin, let me ask a question."}, {"time": 548, "text": "Do you see a protective barrier or a gap between the physical world and the digital world?"}, {"time": 555, "text": "Let's not call it digital."}, {"time": 556, "text": "Let's call it the logical world versus the physical world."}, {"time": 560, "text": "Why logical?"}, {"time": 561, "text": "Well, because even though we had, let's say Einstein's brain preserved, uh, it was meaningless to us as a physical object because we couldn't do anything with what was stored in it at a logical level."}, {"time": 575, "text": "And so the idea that something may be stored logically and that it may be stored physically, uh, are not necessarily, uh, we don't always benefit from synonymizing."}, {"time": 585, "text": "I'm not suggesting that there isn't a material basis to the logical world, but that it does warrant identification with a separate layer that need not invoke logic gates and zeros and ones."}, {"time": 599, "text": "And uh, so connecting those two worlds, the logical world and the physical world, or maybe just connecting to the logical world inside our brain, Einstein's brain."}, {"time": 609, "text": "You mentioned the idea of out, outtelligence."}, {"time": 614, "text": "Artificial outtelligence."}, {"time": 617, "text": "This is the only essay that John Brockman ever invited me to write that he refused to publish in Edge."}, {"time": 625, "text": "Well, maybe it wasn't, it wasn't well written, um, but I don't know."}, {"time": 630, "text": "The idea is quite compelling is quite unique and new and at least from my view of a stance point, maybe you can explain it."}, {"time": 639, "text": "What I was thinking about is why it is that we're waiting to be terrified by artificial general intelligence when in fact, artificial life, uh, is terrifying in and of itself and it's already here."}, {"time": 654, "text": "So in order to have a system of selective pressures, you need three distinct elements."}, {"time": 660, "text": "You need variation within a population."}, {"time": 664, "text": "You need heritability and you need differential success."}, {"time": 668, "text": "So what's really unique and I've made this point, I think elsewhere about software is that if you think about what humans know how to build, that's impressive."}, {"time": 679, "text": "So I always take a car and I say, does it have an analog of each of the physical physiological systems?"}, {"time": 686, "text": "Does it have a skeletal structure?"}, {"time": 687, "text": "That's its frame."}, {"time": 688, "text": "Does it have a neurological structure?"}, {"time": 690, "text": "Has an on board computer, has a digestive system."}, {"time": 695, "text": "The one thing it doesn't have is a reproductive system."}, {"time": 698, "text": "But if you can call spawn on a process, effectively you do have a reproductive system and that means that you can create something with variation, heritability and differential success."}, {"time": 713, "text": "Now the next step in the chain of thinking was where do we see inanimate, non intelligent life outwitting intelligent life?"}, {"time": 725, "text": "And um, I have two favorite systems and I try to stay on them so that we don't get distracted."}, {"time": 731, "text": "One of which is the Ofres orchid, um, subspecies or subclade."}, {"time": 736, "text": "I don't know what to call it."}, {"time": 737, "text": "There's a type of flower."}, {"time": 738, "text": "Yeah, it's a type of flower that mimics the female of a pollinator species in order to dupe the males into, uh, engaging."}, {"time": 747, "text": "It was called pseudo copulation with the fake female, which is usually represented by the lowest pedal."}, {"time": 754, "text": "And there's also a pheromone component to fool the males into thinking they have a mating opportunity."}, {"time": 758, "text": "But the flower doesn't have to give up energy energy in the form of nectar as a lure because it's tricking the males."}, {"time": 765, "text": "The other system is a particular species, uh, of muscle lampicillus in the clear streams of Missouri and it fools bass into biting a fleshy lip that contain its young."}, {"time": 782, "text": "And when the bass see this fleshy lip, which looks exactly like a species of fish that the bass like to eat, the, uh, the young explode and clamp onto the gills and parasitize the bass and also lose the best redistribute them as they eventually release both of these systems."}, {"time": 800, "text": "You have a highly intelligent dupe being fooled by a lower life form and what is sculpting these, these convincing lures."}, {"time": 814, "text": "It's the intelligence of previously duped targets for these strategies."}, {"time": 821, "text": "So when the target is smart enough to avoid the strategy, uh, those weaker mimics, uh, fall off."}, {"time": 829, "text": "They have terminal lines and only the better ones survive."}, {"time": 832, "text": "So it's an arms race between the target species, uh, that is being parasitized, getting smarter and this other less intelligent or non intelligent object getting as if smarter."}, {"time": 849, "text": "And so what you see is, is that artificial intelligence, artificial general intelligence is not needed to parasitize us."}, {"time": 857, "text": "It's simply sufficient for us to outwit ourselves."}, {"time": 862, "text": "So you could have a program, let's say, you know, one of these Nigerian scams, um, that writes letters and uses whoever sends it Bitcoin, uh, to figure out which aspects of the program should be kept, which should be varied and thrown away."}, {"time": 878, "text": "And you don't need it to be in any way intelligent in order to have a really nightmarish scenario of being parasitized by something that has no idea what it's doing."}, {"time": 886, "text": "So you, you, you phrased a few concepts really eloquently."}, {"time": 889, "text": "So let me try to, uh, as a few directions this goes."}, {"time": 893, "text": "So one first, first of all, in the way we write software today, it's not common that we allow it to self modify."}, {"time": 901, "text": "But we do have that ability."}, {"time": 902, "text": "Now we have the ability, it's just not common."}, {"time": 905, "text": "It's not just common."}, {"time": 906, "text": "So, so your, your thought is that that is a serious worry."}, {"time": 913, "text": "If there becomes, uh, Self modifying code is, is available now."}, {"time": 918, "text": "So there's, there's different types of self modification, right?"}, {"time": 921, "text": "There's a personalization, you know, your email app, your Gmail is a self modifying to you after you log in or whatever you can think of it that way."}, {"time": 932, "text": "But ultimately it's central, all the information is centralized, but you're thinking of ideas where you're completely, so this is an unique entity, uh, operating under selective pressures and it changes."}, {"time": 982, "text": "Uh, so that's a beautiful thing."}, {"time": 985, "text": "Well, terrifying thing to worry about because it's so within our reach."}, {"time": 990, "text": "Whatever I suggest these things, I do always have a concern as to whether or not I will bring them into being by talking about them."}, {"time": 997, "text": "So, uh, there's this thing from open AI, uh, next, next week to talk to the founder of open AI, uh, this idea that, uh, their text generation, the new, uh, the new stuff they have for generating texts is they didn't want to bring it, they didn't want to release it because they're worried about the."}, {"time": 1017, "text": "I'm delighted to hear that, but they're going to end up releasing."}, {"time": 1021, "text": "So that's the thing is I think talking about it, um, well, at least from my end, I'm more a proponent of technology preventing tech, uh, so further innovation, preventing the detrimental effects of innovation."}, {"time": 1036, "text": "Well, we're at a, we're sort of tumbling down a hill at accelerating speed."}, {"time": 1042, "text": "So whether or not we're proponents or it doesn't, it doesn't really, it may not matter, but I, well, I do feel that there are people who've held things back and, uh, you know, died poor than they might've otherwise been."}, {"time": 1055, "text": "We don't even know their names."}, {"time": 1057, "text": "I don't think that we should discount the idea that having the smartest people showing off how smart they are by what they've developed may be a terminal process."}, {"time": 1099, "text": "I do think that not enough of us feel in our gut what it is we are playing with when we are working on technical problems."}, {"time": 1106, "text": "And I would recommend to anyone who hasn't seen it, a movie called the bridge over the bridge on the river Kwai about, I believe captured British POWs who just in a desire to do a bridge well, end up over collaborating with their Japanese captors."}, {"time": 1123, "text": "Well now you're making me a question the unrestricted open discussion of ideas and AI."}, {"time": 1131, "text": "I'm not saying I know the answer, I'm just saying that I could make a decent case for either our need to talk about this and to become technologically focused on containing it or need to stop talking about this and try to hope that the relatively small number of highly adept individuals who are looking at these problems is small enough that we should in fact be talking about how to contain them."}, {"time": 1154, "text": "Well the way ideas, the way innovation happens, what new ideas develop, Newton with calculus, whether if he was silent, the idea would be, would emerge elsewhere in the case of Newton of course."}, {"time": 1167, "text": "But in the case of AI, how small is the set of individuals out of which such ideas would arise?"}, {"time": 1175, "text": "Well the idea is that the researchers we know and those that we don't know who may live in countries that don't wish us to know what level they're currently at are very disciplined in keeping these things to themselves."}, {"time": 1190, "text": "Of course I will point out that there's a religious school in Kerala that developed something very close to the calculus, certainly in terms of infinite series in I guess religious prayer and rhyme and prose."}, {"time": 1210, "text": "So it's not that Newton had any ability to hold that back and I don't really believe that we have an ability to hold it back."}, {"time": 1217, "text": "I do think that we could change the proportion of the time we spend worrying about the effects of what if we are successful rather than simply trying to succeed and hope that we'll be able to contain things later."}, {"time": 1229, "text": "So on the idea of intelligence, what form, treading cautiously as we've agreed as we tumbled down the hill, what form... We can't stop ourselves, can we?"}, {"time": 1239, "text": "We cannot."}, {"time": 1242, "text": "What form do you see it taking?"}, {"time": 1243, "text": "So one example, Facebook, Google, do want to, I don't know a better word, you want to influence users to behave a certain way and so that's one kind of example of how intelligence is systems perhaps modifying the behavior of these intelligent human beings in order to sell more product of different kinds."}, {"time": 1268, "text": "But do you see other examples of this actually emerging in... Just take any parasitic system, make sure that there's some way in which that there's differential success, heritability, and variation."}, {"time": 1285, "text": "And those are the magic ingredients and if you really wanted to build a nightmare machine, make sure that the system that expresses the variability has a spanning set so that it can learn to arbitrary levels by making it sufficiently expressive."}, {"time": 1301, "text": "That's your nightmare."}, {"time": 1303, "text": "So it's your nightmare, but it could also be, it's a really powerful mechanism by which to create, well, powerful systems."}, {"time": 1312, "text": "So are you more worried about the negative direction that might go versus the positive?"}, {"time": 1319, "text": "So you said parasitic, but that doesn't necessarily need to be what the system converges towards."}, {"time": 1325, "text": "It could be, what is it?"}, {"time": 1327, "text": "And the dividing line between parasitism and symbiosis is not so clear."}, {"time": 1333, "text": "That's what they tell me about marriage."}, {"time": 1335, "text": "I'm still single, so I don't know."}, {"time": 1337, "text": "Well yeah, we could go into that too, but no, I think we have to appreciate, are you infected by your own mitochondria?"}, {"time": 1381, "text": "That's a very tricky situation to analyze and I would say that predators and parasites drive much of our evolution and I don't know whether to be angry at them or thank them."}, {"time": 1394, "text": "Well ultimately, I mean nobody knows the meaning of life or what even happiness is, but there is some metrics."}, {"time": 1400, "text": "They didn't tell you?"}, {"time": 1403, "text": "That's why all the poetry and books are about, you know, there's some metrics under which you can kind of measure how good it is that these AI systems are roaming about."}, {"time": 1415, "text": "So you're more nervous about software than you are optimistic about ideas of, yeah, self replicating largely."}, {"time": 1425, "text": "I don't think we've really felt where we are."}, {"time": 1430, "text": "You know, occasionally we get a wake up, 9 11 was so anomalous compared to everything else we've experienced on American soil that it came to us as a complete shock that that was even a possibility."}, {"time": 1445, "text": "What it really was was a highly creative and determined R and D team deep in the bowels of Afghanistan showing us that we had certain exploits that we were open to that nobody had chosen to express."}, {"time": 1459, "text": "I can think of several of these things that I don't talk about publicly that just seem to have to do with, um, how relatively unimaginative those who wish to cause havoc and destruction have been up until now."}, {"time": 1473, "text": "But the great mystery of our time of this particular little era is how remarkably stable we've been since 1945 when we demonstrated the ability to use a nuclear weapons in anger."}, {"time": 1490, "text": "And we don't know why things like that haven't happened since then."}, {"time": 1498, "text": "We've had several close calls, we've had mistakes, we've had a brinksmanship."}, {"time": 1503, "text": "And what's now happened is that we've settled into a sense that, Oh, it's, it'll always be nothing."}, {"time": 1510, "text": "It's been so long since something was at that level of danger that we've got a wrong idea in our head."}, {"time": 1521, "text": "And that's why when I went on the Ben Shapiro show, I talked about the need to resume above ground testing of nuclear devices because we have people whose developmental experience suggests that when let's say Donald Trump and North Korea engage on Twitter, Oh, it's nothing."}, {"time": 1538, "text": "It's just posturing."}, {"time": 1539, "text": "Everybody's just in it for money."}, {"time": 1541, "text": "There's, there's an, a sense that people are in a video game mode, which has been the right call since 1945."}, {"time": 1549, "text": "We've been mostly in video game mode."}, {"time": 1552, "text": "So you're worried about a generation which has not seen any existential."}, {"time": 1557, "text": "We've lived under it."}, {"time": 1558, "text": "You see, you're younger."}, {"time": 1560, "text": "I don't know if, if, and again, you came from, from Moscow."}, {"time": 1565, "text": "There was a TV show called the day after that had a huge effect on a generation growing up in the U S and it talked about what life would be like after a nuclear exchange."}, {"time": 1581, "text": "We have not gone through an embodied experience collectively where we've thought about this."}, {"time": 1587, "text": "And I think it's one of the most irresponsible things that the elders among us have done, which is to provide this beautiful garden in which the thorns are cut off of the, of the Rose bushes and all of the edges are rounded and sanded."}, {"time": 1607, "text": "And so people have developed this, this totally unreal idea, which is everything's going to be just fine."}, {"time": 1614, "text": "And do I think that my leading concern is AGI or my leading concern is a thermonuclear exchange or gene drives or any one of these things?"}, {"time": 1624, "text": "I don't know, but I know that our time here in this very long experiment here is finite because the toys that we've built are so impressive and the wisdom to accompany them has not materialized."}, {"time": 1639, "text": "And I think it's, we actually got a wisdom uptick since 1945."}, {"time": 1644, "text": "We had a lot of dangerous skilled players on the world stage who nevertheless, no matter how bad they were managed to not embroil us in something that we couldn't come back from the cold war."}, {"time": 1659, "text": "Yeah, and the distance from the cold war, you know, I'm very mindful of a, there was a Russian tradition actually of on your wedding day, going to visit a memorial to those who gave their lives."}, {"time": 1675, "text": "Can you imagine this where you, on the happiest day of your life, you go and you pay homage to the people who fought and died in the battle of Stalingrad."}, {"time": 1688, "text": "I'm not a huge fan of communism, I got to say, but there were a couple of things that the Russians did that were really positive in the Soviet era."}, {"time": 1698, "text": "And I think trying to let people know how serious life actually is, is the Russian model of seriousness is better than the American model."}, {"time": 1708, "text": "And maybe like you mentioned, there was a small echo of that after 9 11."}, {"time": 1714, "text": "But we wouldn't let it form."}, {"time": 1716, "text": "We talk about 9 11, but it's 9 12 that really moved the needle when we were all just there and nobody wanted to speak."}, {"time": 1726, "text": "We witnessed something super serious and we didn't want to run to our computers and blast out our deep thoughts and our feelings."}, {"time": 1739, "text": "And it was profound because we woke up briefly, you know, I talk about the gated institutional narrative that sort of programs our lives."}, {"time": 1748, "text": "I've seen it break three times in my life, one of which was the election of Donald Trump."}, {"time": 1755, "text": "Another time was the fall of Lehman Brothers when everybody who knew that Bear Stearns wasn't that important knew that Lehman Brothers met AIG was next."}, {"time": 1767, "text": "And the other one was 9 11."}, {"time": 1769, "text": "And so if I'm 53 years old and I only remember three times that the global narrative was really interrupted, that tells you how much we've been on top of developing events."}, {"time": 1782, "text": "You know, I mean we had the Murrow federal building explosion, but it didn't cause the narrative to break."}, {"time": 1787, "text": "It wasn't profound enough."}, {"time": 1789, "text": "Around 9 12 we started to wake up out of our slumber and the powers that be did not want to coming together."}, {"time": 1799, "text": "They, you know, the admonition was go shopping."}, {"time": 1803, "text": "And the powers that be was what is that force as opposed to blaming individuals?"}, {"time": 1808, "text": "So whatever that, whatever that force is, there's a component of it that's emergent and there's a component of it that's deliberate."}, {"time": 1815, "text": "So give yourself a portfolio with two components."}, {"time": 1818, "text": "Some amount of it is emergent, but some amount of it is also an understanding that if people come together, they become an incredible force."}, {"time": 1827, "text": "And what you're seeing right now I think is there are forces that are trying to come together and there are forces that are trying to push things apart."}, {"time": 1839, "text": "And you know, one of them is the globalist narrative versus the national narrative where to the global, uh, globalist perspective, uh, the nation nations are bad things in essence that they're temporary, they're nationalistic, they're jingoistic, it's all negative to people in the national, more in the national idiom, they're saying, look, this is where I pay my taxes."}, {"time": 1860, "text": "This is where I do my army service."}, {"time": 1862, "text": "This is where I have a vote."}, {"time": 1864, "text": "This is where I have a passport."}, {"time": 1866, "text": "Who the hell are you to tell me that because you've moved into someplace that you can make money globally, that you've chosen to abandon other people to whom you have a special and elevated duty."}, {"time": 1876, "text": "And I think that these competing narratives have been pushing towards the global perspective, uh, from the elite and a larger and larger number of disenfranchised people are saying, hey, I actually live in a, in a place and I have laws and I speak a language, I have a culture."}, {"time": 1893, "text": "And who are you to tell me that because you can profit in some far away land that my obligations to my fellow countrymen are so, so much diminished."}, {"time": 1903, "text": "So these tensions between nations and so on, ultimately you see being proud of your country and so on, which creates potentially the kind of things that led to wars and so on."}, {"time": 1913, "text": "They, they ultimately, it is human nature and it is good for us for wake up calls of different kinds."}, {"time": 1919, "text": "Well, I think that these are tensions and my point isn't, I mean, nationalism run amok is a nightmare and internationalism run amok is a nightmare."}, {"time": 1929, "text": "And the problem is we're trying to push these pendulums, uh, to some place where they're somewhat balanced, where we, we have a higher duty of care to those, uh, who share our log, our laws and our citizenship, but we don't forget our duties of care to the global system."}, {"time": 1950, "text": "I would think this is elementary, but the problem that we're facing concerns the ability for some to profit at the, by abandoning their obligations, uh, to others within their system."}, {"time": 1965, "text": "And that's what we've had for decades."}, {"time": 1968, "text": "You mentioned nuclear weapons."}, {"time": 1970, "text": "I was hoping to get answers from you since one of the many things you've done as a economics and maybe you can understand human behavior of why the heck we haven't blown each other up yet."}, {"time": 1982, "text": "So, uh, we'll get back."}, {"time": 1983, "text": "I don't know the answer."}, {"time": 1985, "text": "It's a, it's a fast."}, {"time": 1986, "text": "It's really important to say that we really don't know."}, {"time": 1987, "text": "A mild uptick in wisdom."}, {"time": 1990, "text": "Well, Steven Pinker, who I've talked with has a lot of really good ideas about why, but I don't trust his optimism."}, {"time": 2000, "text": "Listen, I'm Russian, so I never trust a guy who was that optimistic."}, {"time": 2004, "text": "No, no, no."}, {"time": 2005, "text": "It's just that you're talking about a guy who's looking at a system in which more and more of the kinetic energy like war has been turned into potential energy, like unused nuclear weapons."}, {"time": 2019, "text": "You know, now I'm looking at that system and I'm saying, okay, well, if you don't have a potential energy term, then everything's just getting better and better."}, {"time": 2028, "text": "That's beautifully put."}, {"time": 2029, "text": "Only a physicist could."}, {"time": 2031, "text": "I'm not a physicist."}, {"time": 2032, "text": "Is that a dirty word?"}, {"time": 2036, "text": "I wish I were a physicist."}, {"time": 2038, "text": "My dad's a physicist."}, {"time": 2039, "text": "I'm trying to live up that probably for the rest of my life."}, {"time": 2042, "text": "He's probably gonna listen to this too."}, {"time": 2047, "text": "So your friend, Sam Harris, uh, worries a lot about the existential threat of AI."}, {"time": 2053, "text": "Not in the way that you've described, but in the more, well, he hangs out with Elon."}, {"time": 2058, "text": "I don't know Elon."}, {"time": 2097, "text": "So that's been one of the big awakenings that you can write a pretty convincing sports story from stats alone, uh, without needing to have watched the game."}, {"time": 2110, "text": "So you know, is it possible to write lively pros about politics?"}, {"time": 2113, "text": "Yeah, no, not yet."}, {"time": 2117, "text": "So we were sort of all over the map."}, {"time": 2120, "text": "One of the, one of the things about chess that you'll, there's a question I once asked on Quora that didn't get a lot of response, which was what is the greatest brilliancy ever produced by a computer in a chess game, which was different than the question of what is the greatest game ever played."}, {"time": 2135, "text": "So if you think about brilliancies is what really animates many of us to think of chess as an art form."}, {"time": 2142, "text": "Those are those moves and combinations that just show such flair, panache and, and, and in soul, um, computers weren't really great at that."}, {"time": 2150, "text": "They were great positional monsters and you know, recently we, we've started seeing brilliancies and so."}, {"time": 2157, "text": "The grandmasters have identified with, uh, with alpha zero that things were quite brilliant."}, {"time": 2164, "text": "So that's, that's, that's a, you know, that's an example of something we don't think that that's AGI, but in a very restricted set, a set of rules like chess, you're starting to see poetry, uh, of a high order."}, {"time": 2175, "text": "And, and so I'm not, I don't like the idea that we're waiting for AGI, AGI is sort of slowly infiltrating our lives in the same way that I don't think a worm should be, you know, the C elegans shouldn't be treated as non conscious because it only has 300 neurons."}, {"time": 2194, "text": "Maybe it just has a very low level of consciousness because we don't understand what these things mean as they scale up."}, {"time": 2200, "text": "So am I worried about this general phenomena?"}, {"time": 2204, "text": "But I think that one of the things that's happening is that a lot of us are fretting about this, uh, in part because of human needs."}, {"time": 2213, "text": "We've always been worried about the Golem, right?"}, {"time": 2216, "text": "Well, the Golem is the artificially created life, you know, it's like Frankenstein."}, {"time": 2222, "text": "It's a Jewish version and, um, Frankenberg, Frankenstein, yeah, that's makes sense, right?"}, {"time": 2230, "text": "So the, uh, but we've always been worried about creating something like this and it's getting closer and closer and there are ways in which we have to realize that the whole thing is kind of, the whole thing that we've experienced are the context of our lives is almost certainly coming to an end."}, {"time": 2252, "text": "And I don't mean to suggest that, uh, we won't survive."}, {"time": 2259, "text": "And I don't mean to suggest that it's coming tomorrow and it could be 300, 500 years, but there's no plan that I'm aware of if we have three rocks that we could possibly inhabit that are, uh, sensible within current technological dreams, the earth, the moon and Mars."}, {"time": 2278, "text": "And we have a very competitive civilization that is still forced into violence to sort out disputes that cannot be arbitrated."}, {"time": 2286, "text": "It is not clear to me that we have a longterm future until we get to the next stage, which is to figure out whether or not the Einsteinian speed limit can be broken."}, {"time": 2298, "text": "And that requires our source code."}, {"time": 2301, "text": "Our source code, the stuff in our brains to figure out what do you mean by our source code?"}, {"time": 2306, "text": "The source code of the context, whatever it is that produces the quarks, the electrons, the neutrinos."}, {"time": 2311, "text": "Oh, our source code."}, {"time": 2313, "text": "I got it."}, {"time": 2314, "text": "So this is, You're talking about stuff that's written in a higher level language."}, {"time": 2321, "text": "You're talking about the low level, the bits."}, {"time": 2323, "text": "That's what is currently keeping us here."}, {"time": 2326, "text": "We can't even imagine, you know, we have harebrained schemes for staying within the Einsteinian speed limit."}, {"time": 2334, "text": "Uh, you know, maybe if we could just drug ourselves and go into a suspended state or we could have multiple generations of that, I think all that stuff is pretty silly, but I think it's also pretty silly to imagine that our wisdom is going to increase to the point that we can have the toys we have and, uh, we're not going to use them for 500 years."}, {"time": 2354, "text": "Speaking of Einstein, I had a profound breakthrough when I realized you're just one letter away from the guy."}, {"time": 2359, "text": "Yeah, but I'm also one letter away from Feinstein."}, {"time": 2362, "text": "It's, well, you get to pick."}, {"time": 2366, "text": "So unified theory, you know, you've worked, uh, you, you enjoy the beauty of geometry."}, {"time": 2372, "text": "I don't actually know if you enjoy it."}, {"time": 2374, "text": "You certainly are quite good at it."}, {"time": 2375, "text": "I tremble before it."}, {"time": 2376, "text": "If you're religious, that is one of the, I don't have to be religious."}, {"time": 2382, "text": "It's just so beautiful."}, {"time": 2383, "text": "You will tremble anyway."}, {"time": 2384, "text": "I mean, I just read Einstein's biography and one of the ways, uh, one of the things you've done is try to explore a unified theory, uh, talking about a 14 dimensional observers that has the 4d space time continuum embedded in it."}, {"time": 2402, "text": "I, I'm just curious how you think and how philosophically at a high level about something more than four dimensions, uh, how do you try to, what, what does it make you feel?"}, {"time": 2417, "text": "Talking in the mathematical world about dimensions that are greater than the ones we can perceive."}, {"time": 2423, "text": "Is there something that you take away that's more than just the math?"}, {"time": 2427, "text": "Well, first of all, stick out your tongue at me."}, {"time": 2433, "text": "Now on the front of that time, yeah, there was a sweet receptor and next to that were salt receptors and two different sides, a little bit farther back."}, {"time": 2445, "text": "There were sour receptors and you wouldn't show me the back of your tongue where your bitter receptor was."}, {"time": 2450, "text": "Show the good side always."}, {"time": 2452, "text": "So you had four dimensions of taste receptors, but you also had pain receptors on that tongue and probably heat receptors on that time."}, {"time": 2461, "text": "So let's assume that you had one of each, that would be six dimensions."}, {"time": 2465, "text": "So when you eat something, you eat a slice of pizza and it's got some, some, uh, some hot pepper on it, maybe some jalapeno, you're having a six dimensional experience, dude."}, {"time": 2477, "text": "Do you think we overemphasize the value of time as one of the dimensions or space?"}, {"time": 2483, "text": "Well, we certainly overemphasize the value of time cause we like things to start and end or we really don't like things to end, but they seem to."}, {"time": 2490, "text": "Well, what if you flipped one of the spatial dimensions into being a temporal dimension?"}, {"time": 2497, "text": "And you and I were to meet in New York city and say, well, where, where and when should we meet?"}, {"time": 2502, "text": "What about, I'll meet you on a 36 in Lexington at two in the afternoon and uh, 11 oclock in the morning."}, {"time": 2513, "text": "That would be very confusing."}, {"time": 2515, "text": "Well, so it's convenient for us to think about time, you mean."}, {"time": 2519, "text": "We happen to be in a delicious situation in which we have three dimensions of space and one of time and they're woven together in this sort of strange fabric where we can trade off a little space for a little time, but we still only have one dimension that is picked out relative to the other three."}, {"time": 2533, "text": "It's very much Gladys Knight and the pips."}, {"time": 2535, "text": "So which one developed for who?"}, {"time": 2537, "text": "Do we develop for these dimensions or did the dimensions or were they always there and it doesn't?"}, {"time": 2543, "text": "Well, do you imagine that there isn't a place where there are four temporal dimensions or two and two of space and time or three of time and one of space and then would time not be playing the role of space?"}, {"time": 2553, "text": "Why do you imagine that the sector that you're in is all that there is?"}, {"time": 2557, "text": "I certainly do not, but I can't imagine otherwise."}, {"time": 2560, "text": "I mean, I haven't done ayahuasca or any of those drugs that hope to one day, but instead of doing ayahuasca, you could just head over to building two."}, {"time": 2569, "text": "That's where the mathematicians are?"}, {"time": 2570, "text": "Yeah, that's where they hang."}, {"time": 2572, "text": "Just to look at some geometry."}, {"time": 2573, "text": "Well, just ask about pseudo Ramanian geometry."}, {"time": 2575, "text": "That's what you're interested in."}, {"time": 2578, "text": "Or you could talk to a shaman and end up in Peru."}, {"time": 2581, "text": "And then it's an extra money for that trip."}, {"time": 2583, "text": "Yeah, but you won't be able to do any calculations if that's how you choose to go about it."}, {"time": 2586, "text": "Well, a different kind of calculation, so to speak."}, {"time": 2590, "text": "One of my favorite people, Edward Frankel, Berkeley professor, author of Love and Math, great title for a book, said that you are quite a remarkable intellect to come up with such beautiful original ideas in terms of unified theory and so on, but you're working outside academia."}, {"time": 2608, "text": "So one question in developing ideas that are truly original, truly interesting, what's the difference between inside academia and outside academia when it comes to developing such ideas?"}, {"time": 2620, "text": "Oh, it's a terrible choice."}, {"time": 2621, "text": "Terrible choice."}, {"time": 2623, "text": "So if you do it inside of academics, you are forced to constantly show great loyalty to the consensus and you distinguish yourself with small, almost microscopic heresies to make your reputation in general."}, {"time": 2647, "text": "And you have very competent people and brilliant people who are working together, who form very deep social networks and have a very high level of behavior, at least within mathematics and at least technically within physics, theoretical physics."}, {"time": 2667, "text": "When you go outside, you meet lunatics and crazy people, madmen."}, {"time": 2675, "text": "And these are people who do not usually subscribe to the consensus position and almost always lose their way."}, {"time": 2684, "text": "And the key question is, will progress likely come from someone who has miraculously managed to stay within the system and is able to take on a larger amount of heresy that is sort of unthinkable?"}, {"time": 2701, "text": "In which case, that will be fascinating, or is it more likely that somebody will maintain a level of discipline from outside of academics and be able to make use of the freedom that comes from not having to constantly affirm your loyalty to the consensus of your field?"}, {"time": 2721, "text": "So you've characterized in ways that academia in this particular sense is declining."}, {"time": 2728, "text": "You posted a plot, the older population of the faculty is getting larger, the younger is getting smaller and so on."}, {"time": 2737, "text": "So which direction of the two are you more hopeful about?"}, {"time": 2740, "text": "Well, the baby boomers can't hang on forever."}, {"time": 2742, "text": "First of all, in general, true, and second of all, in academia."}, {"time": 2746, "text": "But that's really what this time is about."}, {"time": 2751, "text": "We're used to financial bubbles that last a few years in length and then pop."}, {"time": 2757, "text": "The baby boomer bubble is this really long lived thing, and all of the ideology, all of the behavior patterns, the norms."}, {"time": 2767, "text": "For example, string theory is an almost entirely baby boomer phenomenon."}, {"time": 2771, "text": "It was something that baby boomers were able to do because it required a very high level of mathematical ability."}, {"time": 2780, "text": "You don't think of string theory as an original idea?"}, {"time": 2784, "text": "Oh, I mean, it was original to Veneziano, probably is older than the baby boomers."}, {"time": 2789, "text": "And there are people who are younger than the baby boomers who are still doing string theory."}, {"time": 2793, "text": "And I'm not saying that nothing discovered within the large string theoretic complex is wrong."}, {"time": 2798, "text": "Quite the contrary."}, {"time": 2799, "text": "A lot of brilliant mathematics and a lot of the structure of physics was elucidated by string theorists."}, {"time": 2806, "text": "What do I think of the deliverable nature of this product that will not ship called string theory?"}, {"time": 2812, "text": "I think that it is largely an affirmative action program for highly mathematically and geometrically talented baby boomer physics physicists so that they can say that they're working on something within the constraints of what they will say is quantum gravity."}, {"time": 2830, "text": "Now there are other schemes, you know, there's like asymptotic safety, there are other things that you could imagine doing."}, {"time": 2837, "text": "I don't think much of any of the major programs, but to have inflicted this level of loyalty through a shibboleth."}, {"time": 2847, "text": "Well, surely you don't question X."}, {"time": 2849, "text": "Well, I question almost everything in the string program."}, {"time": 2852, "text": "And that's why I got out of physics."}, {"time": 2854, "text": "When you called me a physicist, it was a great honor, but the reason I didn't become a physicist wasn't that I fell in love with mathematics."}, {"time": 2861, "text": "I said, wow, in 1984, 1983, I saw the field going mad and I saw that mathematics, which has all sorts of problems, was not going insane."}, {"time": 2872, "text": "And so instead of studying things within physics, I thought it was much safer to study the same objects within mathematics."}, {"time": 2879, "text": "There's a huge price to pay for that."}, {"time": 2881, "text": "You lose physical intuition."}, {"time": 2883, "text": "But the point is, is that it wasn't a North Korean reeducation camp either."}, {"time": 2888, "text": "Are you hopeful about cracking open the Einstein unified theory in a way that has been really, really understanding whether this, uh, uniting everything together with quantum theory and so on?"}, {"time": 2902, "text": "I mean, I'm trying to play this role myself to do it to the extent of handing it over to the more responsible, more professional, more competent community."}, {"time": 2914, "text": "Um, so I think that they're wrong about a great number of their belief structures, but I do believe, I mean, I have a really profound love, hate relationship with this group of people."}, {"time": 2926, "text": "I think the physics side, cause the mathematicians actually seem to be much more open minded and uh, well they are and they aren't, they're open minded about anything that looks like great math."}, {"time": 2938, "text": "They'll study something that isn't very important physics, but if it's beautiful mathematics, then they'll have a, they have great intuition about these things as good as the mathematicians are."}, {"time": 2948, "text": "And I might even intellectually at some horsepower level, give them the edge."}, {"time": 2952, "text": "The theoretical theoretical physics community is bar none."}, {"time": 2956, "text": "The most profound intellectual community that we have ever created."}, {"time": 2962, "text": "It is the number one."}, {"time": 2963, "text": "There's nobody in second place as far as I'm concerned, like in their spare time and the spare time they invented molecular biology."}, {"time": 2970, "text": "What, what was the origin of molecular biology?"}, {"time": 2973, "text": "You're saying something like Francis Crick."}, {"time": 2974, "text": "I mean, a lot of, a lot of the early molecular biologists were physicists."}, {"time": 2980, "text": "I mean, you know, Schrodinger wrote what is life and that was highly inspirational."}, {"time": 2984, "text": "I mean, you have to appreciate that there is no community like the basic research community in theoretical physics and it's not something I'm highly critical of these guys."}, {"time": 2999, "text": "I think that they would just wasted the decades of time with a near religious devotion to their misconception of where the problems were in physics."}, {"time": 3013, "text": "But this has been the greatest intellectual collapse ever witnessed within academics."}, {"time": 3020, "text": "You see it as a collapse or just a lull?"}, {"time": 3022, "text": "Oh, I'm terrified that we're about to lose the vitality."}, {"time": 3026, "text": "We can't afford to pay these people."}, {"time": 3029, "text": "We can't afford to give them an accelerator just to play with in case they find something at the next energy level."}, {"time": 3035, "text": "These people created our economy."}, {"time": 3038, "text": "They gave us the rad lab and radar."}, {"time": 3041, "text": "They gave us two atomic devices to end world war two."}, {"time": 3045, "text": "They created the semiconductor and the transistor to power our economy through Moore's law."}, {"time": 3051, "text": "As a positive externality of particle accelerators, they created the worldwide web and we have the insolence to say, why should we fund you with our taxpayer dollars?"}, {"time": 3062, "text": "No, the question is, are you enjoying your physics dollars?"}, {"time": 3098, "text": "So, first of all, you have to know that I'm very critical of this community."}, {"time": 3102, "text": "Second of all, it is our most important community."}, {"time": 3105, "text": "We have neglected it."}, {"time": 3106, "text": "We've abused it."}, {"time": 3107, "text": "We don't take it seriously."}, {"time": 3109, "text": "We don't even care to get them to rehab after a couple of generations of failure, right?"}, {"time": 3115, "text": "No one, I think the youngest person to have really contributed to the standard model of theoretical level was born in 1951, right?"}, {"time": 3125, "text": "Frank Wilczek and almost nothing has happened that in theoretical physics after 1973, 74 that sent somebody to Stockholm for theoretical development that predicted experiment."}, {"time": 3141, "text": "So we have to understand that we are doing this to ourselves."}, {"time": 3144, "text": "Now, with that said, these guys have behaved abysmally in my opinion because they haven't owned up to where they actually are, what problems they're really facing, how definite they can actually be."}, {"time": 3157, "text": "They haven't shared some of their most brilliant discoveries, which are desperately needed in other fields like gauge theory, which at least the mathematicians can, can share, which is an upgrade of the differential calculus of Newton and Leibniz."}, {"time": 3169, "text": "And they haven't shared the importance of renormalization theory."}, {"time": 3173, "text": "Even though this should be standard operating procedure for people across the sciences dealing with different layers and different levels of phenomena."}, {"time": 3181, "text": "And by shared, you mean communicated in such a way that it disseminates throughout the different sizes."}, {"time": 3187, "text": "These guys are sitting, both theoretical physicists and mathematicians are sitting on top of a giant stockpile of intellectual gold, right?"}, {"time": 3196, "text": "They have so many things that have not been manifested anywhere."}, {"time": 3199, "text": "I was just on Twitter, I think I mentioned the Habermann switch pitch that shows the self duality of the tetrahedron realized as a linkage mechanism."}, {"time": 3208, "text": "Now this is like a triviality and it makes an amazing toy that's, you know, built a market, hopefully a fortune for Chuck Habermann."}, {"time": 3218, "text": "Well, you have no idea how much great stuff that these priests have in their monastery."}, {"time": 3224, "text": "So it's truly a love and hate relationship for you."}, {"time": 3228, "text": "Well, it sounds like it's more on the love side."}, {"time": 3229, "text": "This building that we're in right here is the building in which I really put together the conspiracy between the National Academy of Sciences and the National Science Foundation through the government university industry research round table to destroy the bargaining power of American academics, uh, using foreign labor with, uh, on microfeature in the base."}, {"time": 3251, "text": "That was done here in this building."}, {"time": 3253, "text": "Isn't that weird?"}, {"time": 3254, "text": "And I'm, I'm truly speaking with a revolutionary and a radical, uh, no, no, no, no, no, no, no, no, no, no, no, no."}, {"time": 3260, "text": "At an intellectual level, I am absolutely garden variety."}, {"time": 3265, "text": "I'm just straight down the middle."}, {"time": 3267, "text": "The system that we are in this, this university is functionally insane."}, {"time": 3274, "text": "Harvard is functionally insane and we don't understand that when we get these things wrong, the financial crisis made this very clear."}, {"time": 3283, "text": "There was a long period where every grownup, everybody with a tie, uh, who spoke in a, you know, in Barrett, baritone tones, uh, with, with the right degree at the end of their name."}, {"time": 3296, "text": "Uh, we're talking about how we banished volunteer volatility."}, {"time": 3299, "text": "We were in the great moderation."}, {"time": 3302, "text": "They were all crazy."}, {"time": 3304, "text": "And who was, who was right?"}, {"time": 3305, "text": "It was like Nassim Taleb, Nouriel Roubini."}, {"time": 3308, "text": "Now what happens is, is that they claimed the market went crazy, but the market didn't go crazy."}, {"time": 3314, "text": "The market had been crazy and what happened is, is that it suddenly went sane."}, {"time": 3318, "text": "Well, that's where we are with academics."}, {"time": 3321, "text": "Academics right now is mad as a hatter and it's, it's absolutely evident."}, {"time": 3325, "text": "I can show you graph after graph."}, {"time": 3327, "text": "I can show you the internal discussions."}, {"time": 3328, "text": "I can show you the conspiracies."}, {"time": 3330, "text": "Barrett's dealing with one right now over, uh, it's admissions policies for people, uh, of color, uh, who happened to come from Asia."}, {"time": 3338, "text": "All of this madness is necessary to keep the game going."}, {"time": 3341, "text": "What we're talking about just on, well, we're on the topic of revolutionaries is we're talking about the danger of an outbreak of sanity."}, {"time": 3351, "text": "You're, you're the guy pointing out the elephant in the room here and the elephant has no clothes."}, {"time": 3357, "text": "Is that how that goes?"}, {"time": 3359, "text": "I was going to talk a little bit to, uh, Joe Rogan about this, ran out of time, but I think you're, you have some, you, just listening to you, you could probably speak really eloquently to academia on the difference between the different fields."}, {"time": 3376, "text": "So you think there's a difference between science, engineering, and then the humanities in academia in terms of tolerance that they're willing to tolerate?"}, {"time": 3385, "text": "So from my perspective, I thought computer science and maybe engineering is more tolerant to radical ideas, but that's perhaps innocent of me is that I always, you know, all the battles going on now are a little bit more on the humanity side and gender studies and so on."}, {"time": 3403, "text": "Have you seen the, uh, American mathematical society's publication of an essay called get out the way?"}, {"time": 3409, "text": "I have not."}, {"time": 3410, "text": "What's, what's the idea is that white men who hold, uh, positions."}, {"time": 3416, "text": "Within universities and mathematics should vacate their positions so that young black women can take over something like this."}, {"time": 3452, "text": "So the question is what compiles if you want to take the computer science metaphor, what will get you into a journal?"}, {"time": 3462, "text": "Will you spend your life trying to push some paper into a journal or will it be accepted easily?"}, {"time": 3468, "text": "What about the characteristics of the submitter and what gets taken up and what does not?"}, {"time": 3476, "text": "All of these fields are experiencing pressure because no field is performing so brilliantly well, um, that it's revolutionizing our way of speaking and thinking in the ways in which we've become accustomed."}, {"time": 3492, "text": "But don't you think even in theoretical physics, a lot of times, even with theories like string theory, you could speak to this, it does eventually lead to what are the ways that this theory would be testable."}, {"time": 3505, "text": "Yeah, ultimately, although look, there's this thing about popper and the scientific method that's a cancer and a disease and the minds of very smart people."}, {"time": 3516, "text": "That's not really how most of the stuff gets worked out."}, {"time": 3519, "text": "It's how it gets checked."}, {"time": 3521, "text": "All right, so, and there is a dialogue between theory and experiment, but everybody should read Paul directs 1963 American scientific American article where he, he, you know, it's very interesting."}, {"time": 3537, "text": "He talks about it as if it was about the Schrodinger equation and Schrodinger's failure to advance his own work because of his failure to account for some phenomenon."}, {"time": 3546, "text": "The key point is that if your theory is a slight bit off, it won't agree with experiment, but it doesn't mean that the theory is actually wrong."}, {"time": 3552, "text": "Um, but direct could as easily have been talking about his own equation in which he predicted that the electrons should have an antiparticle."}, {"time": 3562, "text": "And since the only positively charged particle that was known at the time was the proton, Heisenberg pointed out, well, shouldn't your antiparticle, the proton have the same mass as the electron and doesn't that invalidate your theory?"}, {"time": 3573, "text": "So I think the direct was actually being quite potentially quite sneaky, um, and, uh, talking about the fact that he had been pushed off of his own theory to some extent by Heisenberg."}, {"time": 3582, "text": "Um, but look, we've fetishized the scientific method and popper and falsification, um, because it protects us from crazy ideas entering the field."}, {"time": 3595, "text": "So you know, it's a question of balancing type one and type two error."}, {"time": 3598, "text": "And we're pretty, we were pretty maxed out in one direction."}, {"time": 3601, "text": "The opposite of that, let me say what comforts me sort of biology or engineering, uh, at the end of the day, does the thing work?"}, {"time": 3611, "text": "You can test the crazies away and the crazy."}, {"time": 3615, "text": "Well see now you're saying, but some ideas are truly crazy and some are, are actually correct."}, {"time": 3620, "text": "So, well there's pre correct currently crazy."}, {"time": 3626, "text": "And so you don't want to get rid of everybody who's pre correct and currently crazy."}, {"time": 3630, "text": "Um, the problem is, is that we don't have standards in general for trying to determine who has to be put to the sword in terms of their career and who has to be protected, uh, as some sort of giant time suck pain in the ass, uh, who may change everything."}, {"time": 3647, "text": "Do you think that's possible?"}, {"time": 3648, "text": "Uh, creating a mechanism of those select?"}, {"time": 3651, "text": "Well, you're not going to like the answer, but here it comes."}, {"time": 3654, "text": "It has to do with very human elements."}, {"time": 3659, "text": "We're trying to do this at the level of like rules and fairness."}, {"time": 3662, "text": "That's not going to work cause the only thing that really understands this, you read the double helix?"}, {"time": 3671, "text": "It's a book."}, {"time": 3672, "text": "Oh, you have to read this book."}, {"time": 3676, "text": "Not only did Jim Watson, uh, half discover this three dimensional structure of DNA, he's also one hell of a writer before he became an ass, uh, that no, he's tried to destroy his own reputation."}, {"time": 3689, "text": "I knew about the ass, I didn't know about the good writer."}, {"time": 3693, "text": "Jim Watson is one of the most important people now living."}, {"time": 3696, "text": "And uh, as I've said before, Jim Watson is too important, a legacy to be left to Jim Watson."}, {"time": 3703, "text": "Um, yeah, that book tells you more about what actually moves the dial, right?"}, {"time": 3709, "text": "There's another story about him, which I don't, don't agree with, which is that he stole everything from Rosalind Franklin."}, {"time": 3714, "text": "I mean the, the problems that he had with Rosalind Franklin are real, but we should actually honor that tension in our history by delving into it rather than having a simple solution."}, {"time": 3725, "text": "Jim Watson talks about Francis Crick being a pain in the ass that everybody secretly knew was super brilliant."}, {"time": 3732, "text": "And there's an encounter between, uh, Chargaff, uh, who came up with the equimolar relations between the nucleotides who should have gotten the structure of DNA and Watson and Crick."}, {"time": 3745, "text": "And you know, he talks about missing a shiver in the heartbeat of biology and stuff is so gorgeous."}, {"time": 3751, "text": "It just makes you tremble even thinking about it."}, {"time": 3755, "text": "Um, look, we know very often who is to be feared and we need to fund the people that we fear."}, {"time": 3765, "text": "The people who are wasting our time need to be excluded from the conversation."}, {"time": 3769, "text": "You see, and you know, maybe we'll make some errors in both directions."}, {"time": 3774, "text": "But we have known our own people."}, {"time": 3778, "text": "We know the pains in the asses that might work out and we know the people who are really just blowhards who really have very little to contribute most of the time."}, {"time": 3786, "text": "It's not a hundred percent, but you're not going to get there with rules."}, {"time": 3791, "text": "It's a using some kind of instinct."}, {"time": 3792, "text": "I mean, I, to be honest, I'm going to make you roll your eyes for a second, but uh, and the first time I heard that there is a large community of people who believe the earth is flat actually made me pause and ask myself the question, why would there be such a community?"}, {"time": 3808, "text": "Is it possible the earth is flat?"}, {"time": 3810, "text": "So I had to like, wait a minute."}, {"time": 3813, "text": "I mean, then you go through a thinking process that I think is really healthy."}, {"time": 3817, "text": "It ultimately ends up being a geometry thing."}, {"time": 3819, "text": "I think, uh, it's an interesting, it's an interesting thought experiment at the very least."}, {"time": 3824, "text": "Well, I don't, I do a different version of it."}, {"time": 3826, "text": "I say, why is this community stable?"}, {"time": 3829, "text": "That's a good, uh, way to analyze it."}, {"time": 3831, "text": "Well, interesting that whatever we've done has not erased the community."}, {"time": 3836, "text": "So you know, they're taking a long shot bet that won't pan out, you know, maybe we just haven't thought enough about the rationality of the square root of two and somebody brilliant will figure it out."}, {"time": 3845, "text": "Maybe we will eventually land one day on the surface of Jupiter and explore it, right?"}, {"time": 3851, "text": "These are crazy things that will never happen."}, {"time": 3854, "text": "So much of social media operates by AI algorithms."}, {"time": 3857, "text": "You talked about this a little bit, uh, recommending the content you see."}, {"time": 3861, "text": "So on this idea of radical thought, how much should AI show you things you disagree with on Twitter and so on in a Twitter word verse in this question?"}, {"time": 3876, "text": "Cause you don't know the answer?"}, {"time": 3877, "text": "No, no, no, no."}, {"time": 3878, "text": "Look, we've been, they've pushed out this cognitive Lego to us that will just lead to madness."}, {"time": 3885, "text": "It's good to be challenged with things that you disagree with."}, {"time": 3889, "text": "The answer is no, it's good to be challenged with interesting things with which you currently disagree, but that might be true."}, {"time": 3896, "text": "So I don't really care about whether or not I disagree with something or don't disagree."}, {"time": 3900, "text": "I need to know why that particular disagreeable thing is being pushed out."}, {"time": 3905, "text": "Is it because it's likely to be true?"}, {"time": 3907, "text": "Is it because, is there some reason?"}, {"time": 3909, "text": "Because I can write, I can write a computer generator, uh, to come up with an infinite number of disagreeable statements that nobody needs to look at."}, {"time": 3917, "text": "So please, before you push things at me that are disagreeable, tell me why."}, {"time": 3922, "text": "There is an aspect in which that question is quite dumb, especially because it's being used to, uh, almost, um, uh, very generically by these different networks to say, well, we're trying to work this out."}, {"time": 3935, "text": "But you know, basically, uh, how much do you see the value of seeing things, uh, you don't like, not you disagree with, because it's very difficult to know exactly what you articulated, which is, uh, the stuff that's important for you to consider that you disagree with."}, {"time": 3953, "text": "That's really hard to figure out."}, {"time": 3955, "text": "The bottom line is this stuff you don't like."}, {"time": 3957, "text": "If you're a, uh, uh, Hillary Clinton supporter, you may not want to, it might not make you feel good to see anything about Donald Trump."}, {"time": 3965, "text": "That's the only thing algorithms can really optimize for currently."}, {"time": 3968, "text": "They really can't."}, {"time": 3969, "text": "Now they can do better."}, {"time": 3970, "text": "This is where we're."}, {"time": 3971, "text": "You think so?"}, {"time": 3972, "text": "No, we're engaged in some moronic back and forth where I have no idea why people who are capable of building Google, Facebook, Twitter are having us in these incredibly low level discussions."}, {"time": 3988, "text": "Do they not know any smart people?"}, {"time": 3991, "text": "Do they not have the phone numbers of people who can elevate these discussions?"}, {"time": 3996, "text": "They do, but this, they're optimizing for a different thing and they're pushing those people out of those rooms."}, {"time": 4002, "text": "They're, they're optimizing for things we can't see."}, {"time": 4007, "text": "And yes, profit is there."}, {"time": 4008, "text": "Nobody, nobody's questioning that, but they're also optimizing for things like political control or the fact that they're doing business in Pakistan."}, {"time": 4017, "text": "And so they don't want to talk about all the things that they're going to be bending to in Pakistan."}, {"time": 4023, "text": "So we're involved in a fake discussion."}, {"time": 4027, "text": "You think these conversations at that depth are happening inside Google?"}, {"time": 4031, "text": "You don't think they have some basic metrics under user engagements?"}, {"time": 4035, "text": "You're having a fake conversation with us guys."}, {"time": 4038, "text": "We know you're having a fake conversation."}, {"time": 4039, "text": "I do not wish to be part of your fake conversation."}, {"time": 4043, "text": "You know how to cool, you know, these units, you know, high availability, like nobody's business."}, {"time": 4049, "text": "My Gmail never goes down."}, {"time": 4051, "text": "Almost."}, {"time": 4052, "text": "So you think just because they can do incredible work on the software side with infrastructure, they can also deal with some of these difficult questions about human behavior, human understanding."}, {"time": 4067, "text": "I mean, I've seen the, I've seen the developers screens that people take shots of inside of Google."}, {"time": 4075, "text": "And I've heard stories inside of Facebook and Apple."}, {"time": 4078, "text": "We're not, we're engaged."}, {"time": 4080, "text": "They're engaging us in the wrong conversations."}, {"time": 4084, "text": "We are not at this low level."}, {"time": 4086, "text": "Here's one of my favorite questions."}, {"time": 4088, "text": "Why is every piece of hardware that I purchase in tech space equipped as a listening device?"}, {"time": 4097, "text": "Where's my physical shutter to cover my lens?"}, {"time": 4099, "text": "We had this in the 1970s, cameras that had lens caps, you know, how much would it cost to have a security model pay five extra bucks?"}, {"time": 4109, "text": "Why is my indicator light software controlled?"}, {"time": 4113, "text": "Why when my camera is on, do I not see that the light is on by putting it as something that cannot be bypassed?"}, {"time": 4119, "text": "Why have you set up my, all of my devices at some difficulty to yourselves as listening devices and we don't even talk about this."}, {"time": 4127, "text": "This is, this thing is total fucking bullshit."}, {"time": 4130, "text": "Well, I hope these discussions are happening about privacy."}, {"time": 4135, "text": "Is there a more difficult thing you're giving them credit for?"}, {"time": 4137, "text": "It's not just privacy."}, {"time": 4139, "text": "It's about social control."}, {"time": 4141, "text": "We're talking about social control."}, {"time": 4143, "text": "Why do I not have controls over my own levers?"}, {"time": 4147, "text": "Just have a really cute UI where I can switch, I can dial things or I can at least see what the algorithms are."}, {"time": 4153, "text": "You think that there is some deliberate choices being made here."}, {"time": 4157, "text": "There's emergence and there is intention."}, {"time": 4161, "text": "There are two dimensions."}, {"time": 4163, "text": "The vector does not collapse onto either axis, but the idea that anybody who suggests that intention is completely absent is a child."}, {"time": 4174, "text": "That's really beautifully put and uh, like many things you've said is going to make me can I turn this around slightly?"}, {"time": 4181, "text": "I sit down with you and you say that you're obsessed with my feed."}, {"time": 4185, "text": "I don't even know what my feed is."}, {"time": 4187, "text": "What are you seeing that I'm not?"}, {"time": 4189, "text": "I was obsessively looking through your feed on Twitter because it was really enjoyable because there's the Tom layer element is the humor in it."}, {"time": 4198, "text": "By the way, that feed is Eric R. Weinstein on Twitter at Eric R. Weinstein."}, {"time": 4203, "text": "No, but seriously, why?"}, {"time": 4206, "text": "Why did I find it enjoyable or what was I seeing?"}, {"time": 4210, "text": "What are you looking for?"}, {"time": 4211, "text": "Why are we doing this?"}, {"time": 4213, "text": "What is this podcast about?"}, {"time": 4214, "text": "I know you've got all these interesting people."}, {"time": 4216, "text": "I'm just some guy who's sort of a podcast guest."}, {"time": 4218, "text": "Sort of a podcast."}, {"time": 4221, "text": "You're not even wearing a tie."}, {"time": 4222, "text": "I mean, it's not even a serious interview."}, {"time": 4225, "text": "I'm searching for meaning, for happiness, for a dopamine rush, so short term, long term."}, {"time": 4234, "text": "And how are you finding your way to me?"}, {"time": 4237, "text": "I don't honestly know what I'm doing to reach you."}, {"time": 4241, "text": "The representing ideas which feel common sense to me and not many people are speaking."}, {"time": 4248, "text": "So it's kind of like the intellectual dark web folks, right?"}, {"time": 4254, "text": "These folks from Sam Harris to Jordan Peterson to yourself are saying things where you're like saying, look, there's an elephant and he's not wearing any clothes."}, {"time": 4265, "text": "And I say, yeah, yeah, let's have more of that conversation."}, {"time": 4269, "text": "That's how I'm finding you."}, {"time": 4270, "text": "I'm desperate to try to change the conversation we're having."}, {"time": 4274, "text": "I'm very worried we've got an election in 2020."}, {"time": 4277, "text": "I don't think we can afford four more years of a misinterpreted message, which is what Donald Trump was."}, {"time": 4285, "text": "And I don't want the destruction of our institutions."}, {"time": 4288, "text": "They all seem hell bent on destroying themselves."}, {"time": 4290, "text": "So I'm trying to save theoretical physics, trying to save the New York Times, trying to save our various processes."}, {"time": 4298, "text": "And I think it feels delusional to me that this is falling to a tiny group of people who are willing to speak out without getting so freaked out that everything they say will be misinterpreted and that their lives will be ruined through the process."}, {"time": 4312, "text": "I mean, I think we're in an absolutely bananas period of time and I don't believe it should fall to such a tiny number of shoulders to shoulder this way."}, {"time": 4322, "text": "So I have to ask you on the capitalism side, you mentioned that technology is killing capitalism or it has effects that are unintended, well, not unintended, but not what economists would predict or speak of capitalism creating."}, {"time": 4338, "text": "I just want to talk to you about in general, the effect of even then artificial intelligence or technology automation taking away jobs and these kinds of things and what you think is the way to alleviate that, whether the Andrew Ng presidential candidate with universal basic income, UBI, what are your thoughts there?"}, {"time": 4358, "text": "How do we fight off the negative effects of technology that... All right, you're a software guy, right?"}, {"time": 4364, "text": "A human being is a worker is an old idea, a human being has a worker is a different object, right?"}, {"time": 4374, "text": "So if you think about object oriented programming as a paradigm, a human being has a worker and a human being has a soul."}, {"time": 4381, "text": "We're talking about the fact that for a period of time, the worker that a human being has was in a position to feed the soul that a human being has."}, {"time": 4391, "text": "However, we have two separate claims on the value in society."}, {"time": 4398, "text": "One is as a worker and the other is as a soul and the soul needs sustenance, it needs dignity, it needs meaning, it needs purpose."}, {"time": 4407, "text": "As long as your means of support is not highly repetitive, I think you have a while to go before you need to start worrying."}, {"time": 4417, "text": "And if what you do is highly repetitive and it's not terribly generative, you are in the cross hairs of for loops and while loops."}, {"time": 4426, "text": "And that's what computers excel at, repetitive behavior and when I say repetitive, I may mean things that have never happened through combinatorial possibilities, but as long as it has a looped characteristic to it, you're in trouble."}, {"time": 4439, "text": "We are seeing a massive push towards socialism because capitalists are slow to address the fact that a worker may not be able to make claims, a relatively undistinguished median member of our society is still has needs to reproduce, needs to have to dignity."}, {"time": 4460, "text": "And when capitalism abandons the median individual or the bottom 10th or whatever it's going to do, it's flirting with revolution."}, {"time": 4472, "text": "And what concerns me is that the capitalists aren't sufficiently capitalistic to understand this."}, {"time": 4479, "text": "You really want to court authoritarian control in our society because you can't see that people may not be able to defend themselves in the marketplace because the marginal product of their labor was too low to feed their dignity as a soul."}, {"time": 4495, "text": "So my great concern is that our free society has to do with the fact that we are self organized."}, {"time": 4502, "text": "I remember looking down from my office in Manhattan when Lehman brothers collapsed and thinking who's going to tell all these people that they need to show up at work when they don't have a financial system to incentivize them to show up at work."}, {"time": 4517, "text": "So my complaint is first of all, not with the socialists, but with the capitalists, which is you guys are being idiots."}, {"time": 4524, "text": "You're courting revolution by continuing to harp on the same old ideas that, well, you know, try, try harder, bootstrap yourself."}, {"time": 4532, "text": "Yeah, to an extent that works to an extent, but we are clearly headed in a place that there's nothing that ties together our need to contribute and our need to consume."}, {"time": 4545, "text": "And that may not be provided by capitalism because it may have been a temporary phenomena."}, {"time": 4549, "text": "So check out my article on anthropic capitalism and the new gimmick economy."}, {"time": 4555, "text": "I think people are late getting the wake up call and we would be doing a better job saving capitalism from itself because I don't want this done under authoritarian control."}, {"time": 4565, "text": "And the more we insist that everybody who's not thriving in our society during their reproductive years in order to have a family is failing at a personal level."}, {"time": 4575, "text": "I mean, what a disgusting thing that we're saying."}, {"time": 4578, "text": "What horrible message who, who the hell have we become that we've so bought into the Chicago model that we can't see the humanity that we're destroying in that process."}, {"time": 4588, "text": "And it's, I hate, I hate the thought of communism."}, {"time": 4591, "text": "I really do."}, {"time": 4592, "text": "My family has flirted with it decades past."}, {"time": 4594, "text": "It's a wrong, bad idea, but we are going to need to figure out how to make sure that those souls are nourished and respected and capitalism better have an answer."}, {"time": 4605, "text": "And I'm betting on capitalism, but I've got to tell you, I'm pretty disappointed with my team."}, {"time": 4609, "text": "So you're still on the capitalism team."}, {"time": 4612, "text": "You just, uh, there's a theme here."}, {"time": 4615, "text": "Radical capitalism."}, {"time": 4616, "text": "Hyper capitalism."}, {"time": 4618, "text": "I want, I think hyper capitalism is going to have to be coupled to hyper socialism."}, {"time": 4622, "text": "You need to allow the most productive people to create wonders and you've got to stop bogging them down with all of these extra nice requirements."}, {"time": 4631, "text": "You know, nice is dead."}, {"time": 4633, "text": "Good has a future."}, {"time": 4634, "text": "Nice doesn't have a future because nice ends up with, with gulags."}, {"time": 4638, "text": "Damn, that's a good line."}, {"time": 4642, "text": "Last question."}]}, {"title": "Jeff Hawkins: Thousand Brains Theory of Intelligence | Lex Fridman Podcast #25", "id": "-EVqrDlAqYo", "quotes": [{"time": 293, "text": "There's not been a single thing humans have ever put their minds to that we've said, oh, we reached the wall, we can't go any further."}, {"time": 299, "text": "It's just, people keep saying that."}, {"time": 301, "text": "People used to believe that about life."}, {"time": 303, "text": "Alain Vital, right, there's like, what's the difference between living matter and nonliving matter, something special that we never understand."}, {"time": 309, "text": "We no longer think that."}, {"time": 310, "text": "So there's no historical evidence that suggests this is the case, and I just never even consider that's a possibility."}, {"time": 317, "text": "I would also say, today, we understand so much about the neocortex."}, {"time": 322, "text": "We've made tremendous progress in the last few years that I no longer think of it as an open question."}, {"time": 330, "text": "The answers are very clear to me."}, {"time": 332, "text": "The pieces we don't know are clear to me, but the framework is all there, and it's like, oh, okay, we're gonna be able to do this."}, {"time": 338, "text": "This is not a problem anymore, just takes time and effort, but there's no mystery, a big mystery anymore."}, {"time": 344, "text": "So then let's get into it for people like myself who are not very well versed in the human brain, except my own."}, {"time": 354, "text": "Can you describe to me, at the highest level, what are the different parts of the human brain, and then zooming in on the neocortex, the parts of the neocortex, and so on, a quick overview."}, {"time": 366, "text": "The human brain, we can divide it roughly into two parts."}, {"time": 370, "text": "There's the old parts, lots of pieces, and then there's the new part."}, {"time": 375, "text": "The new part is the neocortex."}, {"time": 378, "text": "It's new because it didn't exist before mammals."}, {"time": 380, "text": "The only mammals have a neocortex, and in humans, in primates, it's very large."}, {"time": 384, "text": "In the human brain, the neocortex occupies about 70 to 75% of the volume of the brain."}, {"time": 392, "text": "And the old parts of the brain are, there's lots of pieces there."}, {"time": 396, "text": "There's the spinal cord, and there's the brain stem, and the cerebellum, and the different parts of the basal ganglia, and so on."}, {"time": 402, "text": "In the old parts of the brain, you have the autonomic regulation, like breathing and heart rate."}, {"time": 406, "text": "You have basic behaviors, so like walking and running are controlled by the old parts of the brain."}, {"time": 411, "text": "All the emotional centers of the brain are in the old part of the brain, so when you feel anger or hungry, lust, or things like that, those are all in the old parts of the brain."}, {"time": 417, "text": "And we associate with the neocortex all the things we think about as sort of high level perception and cognitive functions, anything from seeing and hearing and touching things to language to mathematics and engineering and science and so on."}, {"time": 436, "text": "Those are all associated with the neocortex, and they're certainly correlated."}, {"time": 441, "text": "Our abilities in those regards are correlated with the relative size of our neocortex compared to other mammals."}, {"time": 447, "text": "So that's like the rough division, and you obviously can't understand the neocortex completely isolated, but you can understand a lot of it with just a few interfaces to the old parts of the brain, and so it gives you a system to study."}, {"time": 464, "text": "The other remarkable thing about the neocortex, compared to the old parts of the brain, is the neocortex is extremely uniform."}, {"time": 472, "text": "It's not visibly or anatomically, it's very, I always like to say it's like the size of a dinner napkin, about two and a half millimeters thick, and it looks remarkably the same everywhere."}, {"time": 485, "text": "Everywhere you look in that two and a half millimeters is this detailed architecture, and it looks remarkably the same everywhere, and that's across species."}, {"time": 492, "text": "A mouse versus a cat and a dog and a human."}, {"time": 495, "text": "Where if you look at the old parts of the brain, there's lots of little pieces do specific things."}, {"time": 519, "text": "This is like, wow, this is incredible."}, {"time": 522, "text": "So all the evidence we have, and this is an idea that was first articulated in a very cogent and beautiful argument by a guy named Vernon Malcastle in 1978, I think it was, that the neocortex all works on the same principle."}, {"time": 541, "text": "So language, hearing, touch, vision, engineering, all these things are basically underlying, are all built on the same computational substrate."}, {"time": 550, "text": "They're really all the same problem."}, {"time": 551, "text": "So the low level of the building blocks all look similar."}, {"time": 554, "text": "Yeah, and they're not even that low level."}, {"time": 556, "text": "We're not talking about like neurons."}, {"time": 557, "text": "We're talking about this very complex circuit that exists throughout the neocortex."}, {"time": 561, "text": "It's remarkably similar."}, {"time": 563, "text": "It's like, yes, you see variations of it here and there, more of the cell, less and less, and so on."}, {"time": 569, "text": "But what Malcastle argued was, he says, you know, if you take a section of neocortex, why is one a visual area and one is a auditory area?"}, {"time": 578, "text": "Or why is, and his answer was, it's because one is connected to eyes and one is connected to ears."}, {"time": 585, "text": "Literally, you mean just it's most closest in terms of number of connections to the sensor."}, {"time": 589, "text": "Literally, literally, if you took the optic nerve and attached it to a different part of the neocortex, that part would become a visual region."}, {"time": 597, "text": "This actually, this experiment was actually done by Merkankasur in developing, I think it was lemurs, I can't remember what it was, some animal."}, {"time": 606, "text": "And there's a lot of evidence to this."}, {"time": 608, "text": "You know, if you take a blind person, a person who's born blind at birth, they're born with a visual neocortex."}, {"time": 615, "text": "It doesn't, may not get any input from the eyes because of some congenital defect or something."}, {"time": 621, "text": "And that region becomes, does something else."}, {"time": 624, "text": "It picks up another task."}, {"time": 627, "text": "So, and it's, so it's this very complex thing."}, {"time": 632, "text": "It's not like, oh, they're all built on neurons."}, {"time": 633, "text": "No, they're all built in this very complex circuit and somehow that circuit underlies everything."}, {"time": 640, "text": "And so this is the, it's called the common cortical algorithm, if you will."}, {"time": 645, "text": "Some scientists just find it hard to believe and they just, I can't believe that's true, but the evidence is overwhelming in this case."}, {"time": 652, "text": "And so a large part of what it means to figure out how the brain creates intelligence and what is intelligence in the brain is to understand what that circuit does."}, {"time": 662, "text": "If you can figure out what that circuit does, as amazing as it is, then you can, then you understand what all these other cognitive functions are."}, {"time": 670, "text": "So if you were to sort of put neocortex outside of your book on intelligence, you look, if you wrote a giant tome, a textbook on the neocortex, and you look maybe a couple of centuries from now, how much of what we know now would still be accurate two centuries from now?"}, {"time": 687, "text": "So how close are we in terms of understanding?"}, {"time": 690, "text": "I have to speak from my own particular experience here."}, {"time": 692, "text": "So I run a small research lab here."}, {"time": 695, "text": "It's like any other research lab."}, {"time": 698, "text": "I'm sort of the principal investigator."}, {"time": 699, "text": "There's actually two of us and there's a bunch of other people."}, {"time": 702, "text": "And this is what we do."}, {"time": 703, "text": "We study the neocortex and we publish our results and so on."}, {"time": 706, "text": "So about three years ago, we had a real breakthrough in this field."}, {"time": 712, "text": "Just tremendous breakthrough."}, {"time": 713, "text": "We've now published, I think, three papers on it."}, {"time": 716, "text": "And so I have a pretty good understanding of all the pieces and what we're missing."}, {"time": 722, "text": "I would say that almost all the empirical data we've collected about the brain, which is enormous."}, {"time": 728, "text": "If you don't know the neuroscience literature, it's just incredibly big."}, {"time": 733, "text": "And it's, for the most part, all correct."}, {"time": 736, "text": "It's facts and experimental results and measurements and all kinds of stuff."}, {"time": 742, "text": "But none of that has been really assimilated into a theoretical framework."}, {"time": 747, "text": "It's data without, in the language of Thomas Kuhn, the historian, would be a sort of a pre paradigm science."}, {"time": 755, "text": "Lots of data, but no way to fit it together."}, {"time": 758, "text": "I think almost all of that's correct."}, {"time": 759, "text": "There's just gonna be some mistakes in there."}, {"time": 762, "text": "And for the most part, there aren't really good cogent theories about it, how to put it together."}, {"time": 767, "text": "It's not like we have two or three competing good theories, which ones are right and which ones are wrong."}, {"time": 771, "text": "It's like, nah, people are just scratching their heads."}, {"time": 774, "text": "Some people have given up on trying to figure out what the whole thing does."}, {"time": 777, "text": "In fact, there's very, very few labs that we do that focus really on theory and all this unassimilated data and trying to explain it."}, {"time": 786, "text": "So it's not like we've got it wrong."}, {"time": 788, "text": "It's just that we haven't got it at all."}, {"time": 791, "text": "So it's really, I would say, pretty early days in terms of understanding the fundamental theory's forces of the way our mind works."}, {"time": 801, "text": "I would have said that's true five years ago."}, {"time": 805, "text": "So as I said, we had some really big breakthroughs on this recently and we started publishing papers on this."}, {"time": 810, "text": "So we'll get to that."}, {"time": 814, "text": "But so I don't think it's, I'm an optimist and from where I sit today, most people would disagree with this, but from where I sit today, from what I know, it's not super early days anymore."}, {"time": 824, "text": "We are, the way these things go is it's not a linear path, right?"}, {"time": 828, "text": "You don't just start accumulating and get better and better and better."}, {"time": 830, "text": "No, all this stuff you've collected, none of it makes sense."}, {"time": 833, "text": "All these different things are just sort of around."}, {"time": 835, "text": "And then you're gonna have some breaking points where all of a sudden, oh my God, now we got it right."}, {"time": 839, "text": "That's how it goes in science."}, {"time": 841, "text": "And I personally feel like we passed that little thing about a couple of years ago, all that big thing a couple of years ago."}, {"time": 847, "text": "So we can talk about that."}, {"time": 849, "text": "Time will tell if I'm right, but I feel very confident about it."}, {"time": 852, "text": "That's why I'm willing to say it on tape like this."}, {"time": 855, "text": "At least very optimistic."}, {"time": 858, "text": "So let's, before those few years ago, let's take a step back to HTM, the hierarchical temporal memory theory, which you first proposed on intelligence and went through a few different generations."}, {"time": 869, "text": "Can you describe what it is, how it evolved through the three generations since you first put it on paper?"}, {"time": 875, "text": "Yeah, so one of the things that neuroscientists just sort of missed for many, many years, and especially people who were thinking about theory, was the nature of time in the brain."}, {"time": 889, "text": "Brains process information through time."}, {"time": 891, "text": "The information coming into the brain is constantly changing."}, {"time": 895, "text": "The patterns from my speech right now, if you were listening to it at normal speed, would be changing on your ears about every 10 milliseconds or so, you'd have a change."}, {"time": 904, "text": "This constant flow, when you look at the world, your eyes are moving constantly, three to five times a second, and the input's completely changing."}, {"time": 911, "text": "If I were to touch something like a coffee cup, as I move my fingers, the input changes."}, {"time": 915, "text": "So this idea that the brain works on time changing patterns is almost completely, or was almost completely missing from a lot of the basic theories, like fears of vision and so on."}, {"time": 925, "text": "It's like, oh no, we're gonna put this image in front of you and flash it and say, what is it?"}, {"time": 929, "text": "Convolutional neural networks work that way today, right?"}, {"time": 932, "text": "Classify this picture."}, {"time": 934, "text": "But that's not what vision is like."}, {"time": 935, "text": "Vision is this sort of crazy time based pattern that's going all over the place, and so is touch and so is hearing."}, {"time": 941, "text": "So the first part of hierarchical temporal memory was the temporal part."}, {"time": 945, "text": "It's to say, you won't understand the brain, nor will you understand intelligent machines unless you're dealing with time based patterns."}, {"time": 952, "text": "The second thing was, the memory component of it was, is to say that we aren't just processing input, we learn a model of the world."}, {"time": 962, "text": "And the memory stands for that model."}, {"time": 965, "text": "The point of the brain, the part of the neocortex, it learns a model of the world."}, {"time": 968, "text": "We have to store things, our experiences, in a form that leads to a model of the world."}, {"time": 974, "text": "So we can move around the world, we can pick things up and do things and navigate and know how it's going on."}, {"time": 978, "text": "So that's what the memory referred to."}, {"time": 979, "text": "And many people just, they were thinking about like certain processes without memory at all."}, {"time": 985, "text": "They're just like processing things."}, {"time": 986, "text": "And then finally, the hierarchical component was a reflection to that the neocortex, although it's this uniform sheet of cells, different parts of it project to other parts, which project to other parts."}, {"time": 999, "text": "And there is a sort of rough hierarchy in terms of that."}, {"time": 1003, "text": "So the hierarchical temporal memory is just saying, look, we should be thinking about the brain as time based, model memory based, and hierarchical processing."}, {"time": 1014, "text": "And that was a placeholder for a bunch of components that we would then plug into that."}, {"time": 1020, "text": "We still believe all those things I just said, but we now know so much more that I'm stopping to use the word hierarchical temporal memory yet because it's insufficient to capture the stuff we know."}, {"time": 1031, "text": "So again, it's not incorrect, but it's, I now know more and I would rather describe it more accurately."}, {"time": 1036, "text": "Yeah, so you're basically, we could think of HTM as emphasizing that there's three aspects of intelligence that are important to think about whatever the eventual theory it converges to."}, {"time": 1048, "text": "So in terms of time, how do you think of nature of time across different time scales?"}, {"time": 1053, "text": "So you mentioned things changing, sensory inputs changing every 10, 20 minutes."}, {"time": 1059, "text": "What about every few minutes, every few months and years?"}, {"time": 1062, "text": "Well, if you think about a neuroscience problem, the brain problem, neurons themselves can stay active for certain periods of time, parts of the brain where they stay active for minutes."}, {"time": 1074, "text": "You could hold a certain perception or an activity for a certain period of time, but most of them don't last that long."}, {"time": 1084, "text": "And so if you think about your thoughts are the activity of neurons, if you're gonna wanna involve something that happened a long time ago, even just this morning, for example, the neurons haven't been active throughout that time."}, {"time": 1096, "text": "So you have to store that."}, {"time": 1097, "text": "So if I ask you, what did you have for breakfast today?"}, {"time": 1100, "text": "That is memory, that is you've built into your model the world now, you remember that."}, {"time": 1104, "text": "And that memory is in the synapses, is basically in the formation of synapses."}, {"time": 1109, "text": "And so you're sliding into what, you know, it's the different timescales."}, {"time": 1116, "text": "There's timescales of which we are like understanding my language and moving about and seeing things rapidly and over time, that's the timescales of activities of neurons."}, {"time": 1124, "text": "But if you wanna get in longer timescales, then it's more memory."}, {"time": 1127, "text": "And we have to invoke those memories to say, oh yes, well now I can remember what I had for breakfast because I stored that someplace."}, {"time": 1134, "text": "I may forget it tomorrow, but I'd store it for now."}, {"time": 1138, "text": "So does memory also need to have, so the hierarchical aspect of reality is not just about concepts, it's also about time?"}, {"time": 1148, "text": "Do you think of it that way?"}, {"time": 1150, "text": "Yeah, time is infused in everything."}, {"time": 1152, "text": "It's like you really can't separate it out."}, {"time": 1155, "text": "If I ask you, what is your, you know, how's the brain learn a model of this coffee cup here?"}, {"time": 1161, "text": "I have a coffee cup and I'm at the coffee cup."}, {"time": 1163, "text": "I say, well, time is not an inherent property of the model I have of this cup, whether it's a visual model or a tactile model."}, {"time": 1171, "text": "I can sense it through time, but the model itself doesn't really have much time."}, {"time": 1174, "text": "If I asked you, if I said, well, what is the model of my cell phone?"}, {"time": 1178, "text": "My brain has learned a model of the cell phone."}, {"time": 1180, "text": "So if you have a smartphone like this, and I said, well, this has time aspects to it."}, {"time": 1185, "text": "I have expectations when I turn it on, what's gonna happen, what or how long it's gonna take to do certain things, if I bring up an app, what sequences, and so I have, and it's like melodies in the world, you know?"}, {"time": 1197, "text": "Melody has a sense of time."}, {"time": 1198, "text": "So many things in the world move and act, and there's a sense of time related to them."}, {"time": 1203, "text": "Some don't, but most things do actually."}, {"time": 1208, "text": "So it's sort of infused throughout the models of the world."}, {"time": 1212, "text": "You build a model of the world, you're learning the structure of the objects in the world, and you're also learning how those things change through time."}, {"time": 1220, "text": "Okay, so it really is just a fourth dimension that's infused deeply, and you have to make sure that your models of intelligence incorporate it."}, {"time": 1230, "text": "So, like you mentioned, the state of neuroscience is deeply empirical, a lot of data collection."}, {"time": 1237, "text": "It's, you know, that's where it is."}, {"time": 1241, "text": "You mentioned Thomas Kuhn, right?"}, {"time": 1244, "text": "And then you're proposing a theory of intelligence, and which is really the next step, the really important step to take, but why is HTM, or what we'll talk about soon, the right theory?"}, {"time": 1263, "text": "So is it more in the, is it backed by intuition?"}, {"time": 1267, "text": "Is it backed by evidence?"}, {"time": 1269, "text": "Is it backed by a mixture of both?"}, {"time": 1271, "text": "Is it kind of closer to where string theory is in physics, where there's mathematical components which show that, you know what, it seems that this, it fits together too well for it not to be true, which is where string theory is."}, {"time": 1288, "text": "Is that where you're kind of seeing?"}, {"time": 1289, "text": "It's a mixture of all those things, although definitely where we are right now is definitely much more on the empirical side than, let's say, string theory."}, {"time": 1297, "text": "The way this goes about, we're theorists, right?"}, {"time": 1299, "text": "So we look at all this data, and we're trying to come up with some sort of model that explains it, basically, and there's, unlike string theory, there's vast more amounts of empirical data here that I think than most physicists deal with."}, {"time": 1314, "text": "And so our challenge is to sort through that and figure out what kind of constructs would explain this."}, {"time": 1322, "text": "And when we have an idea, you come up with a theory of some sort, you have lots of ways of testing it."}, {"time": 1328, "text": "First of all, there are 100 years of assimilated, assimilated, unassimilated empirical data from neuroscience."}, {"time": 1336, "text": "So we go back and read papers, and we say, oh, did someone find this already?"}, {"time": 1340, "text": "We can predict X, Y, and Z, and maybe no one's even talked about it since 1972 or something, but we go back and find that, and we say, oh, either it can support the theory or it can invalidate the theory."}, {"time": 1353, "text": "And we say, okay, we have to start over again."}, {"time": 1354, "text": "Oh, no, it's supportive, let's keep going with that one."}, {"time": 1358, "text": "So the way I kind of view it, when we do our work, we look at all this empirical data, and what I call it is a set of constraints."}, {"time": 1367, "text": "We're not interested in something that's biologically inspired."}, {"time": 1369, "text": "We're trying to figure out how the actual brain works."}, {"time": 1372, "text": "So every piece of empirical data is a constraint on a theory."}, {"time": 1375, "text": "In theory, if you have the correct theory, it needs to explain every pin, right?"}, {"time": 1379, "text": "So we have this huge number of constraints on the problem, which initially makes it very, very difficult."}, {"time": 1385, "text": "If you don't have many constraints, you can make up stuff all the day."}, {"time": 1388, "text": "You can say, oh, here's an answer on how you can do this, you can do that, you can do this."}, {"time": 1391, "text": "But if you consider all biology as a set of constraints, all neuroscience as a set of constraints, and even if you're working in one little part of the neocortex, for example, there are hundreds and hundreds of constraints."}, {"time": 1400, "text": "These are empirical constraints that it's very, very difficult initially to come up with a theoretical framework for that."}, {"time": 1407, "text": "But when you do, and it solves all those constraints at once, you have a high confidence that you got something close to correct."}, {"time": 1415, "text": "It's just mathematically almost impossible not to be."}, {"time": 1419, "text": "So that's the curse and the advantage of what we have."}, {"time": 1423, "text": "The curse is we have to solve, we have to meet all these constraints, which is really hard."}, {"time": 1428, "text": "But when you do meet them, then you have a great confidence that you've discovered something."}, {"time": 1434, "text": "In addition, then we work with scientific labs."}, {"time": 1438, "text": "So we'll say, oh, there's something we can't find, we can predict something, but we can't find it anywhere in the literature."}, {"time": 1444, "text": "So we will then, we have people we've collaborated with, we'll say, sometimes they'll say, you know what?"}, {"time": 1449, "text": "I have some collected data, which I didn't publish, but we can go back and look at it and see if we can find that, which is much easier than designing a new experiment."}, {"time": 1457, "text": "You know, neuroscience experiments take a long time, years."}, {"time": 1460, "text": "So, although some people are doing that now too."}, {"time": 1463, "text": "So, but between all of these things, I think it's a reasonable, actually a very, very good approach."}, {"time": 1471, "text": "We are blessed with the fact that we can test our theories out the yin yang here because there's so much unassimilar data and we can also falsify our theories very easily, which we do often."}, {"time": 1481, "text": "So it's kind of reminiscent to whenever that was with Copernicus, you know, when you figure out that the sun's at the center of the solar system as opposed to earth, the pieces just fall into place."}, {"time": 1494, "text": "Yeah, I think that's the general nature of aha moments is, and it's Copernicus, it could be, you could say the same thing about Darwin, you could say the same thing about, you know, about the double helix, that people have been working on a problem for so long and have all this data and they can't make sense of it, they can't make sense of it."}, {"time": 1515, "text": "But when the answer comes to you and everything falls into place, it's like, oh my gosh, that's it."}, {"time": 1521, "text": "That's got to be right."}, {"time": 1523, "text": "I asked both Jim Watson and Francis Crick about this."}, {"time": 1529, "text": "I asked them, you know, when you were working on trying to discover the structure of the double helix, and when you came up with the sort of the structure that ended up being correct, but it was sort of a guess, you know, it wasn't really verified yet."}, {"time": 1545, "text": "I said, did you know that it was right?"}, {"time": 1548, "text": "And they both said, absolutely."}, {"time": 1550, "text": "So we absolutely knew it was right."}, {"time": 1551, "text": "And it doesn't matter if other people didn't believe it or not, we knew it was right."}, {"time": 1555, "text": "They'd get around to thinking it and agree with it eventually anyway."}, {"time": 1559, "text": "And that's the kind of thing you hear a lot with scientists who really are studying a difficult problem."}, {"time": 1564, "text": "And I feel that way too about our work."}, {"time": 1567, "text": "Have you talked to Crick or Watson about the problem you're trying to solve, the, of finding the DNA of the brain?"}, {"time": 1575, "text": "Yeah, in fact, Francis Crick was very interested in this in the latter part of his life."}, {"time": 1581, "text": "And in fact, I got interested in brains by reading an essay he wrote in 1979 called Thinking About the Brain."}, {"time": 1588, "text": "And that was when I decided I'm gonna leave my profession of computers and engineering and become a neuroscientist."}, {"time": 1595, "text": "Just reading that one essay from Francis Crick."}, {"time": 1597, "text": "I got to meet him later in life."}, {"time": 1601, "text": "I spoke at the Salk Institute and he was in the audience."}, {"time": 1604, "text": "And then I had a tea with him afterwards."}, {"time": 1608, "text": "He was interested in a different problem."}, {"time": 1610, "text": "He was focused on consciousness."}, {"time": 1613, "text": "The easy problem, right?"}, {"time": 1614, "text": "Well, I think it's the red herring."}, {"time": 1618, "text": "And so we weren't really overlapping a lot there."}, {"time": 1622, "text": "Jim Watson, who's still alive, is also interested in this problem."}, {"time": 1627, "text": "And he was, when he was director of the Cold Spring Harbor Laboratories, he was really sort of behind moving in the direction of neuroscience there."}, {"time": 1636, "text": "And so he had a personal interest in this field."}, {"time": 1640, "text": "And I have met with him numerous times."}, {"time": 1643, "text": "And in fact, the last time was a little bit over a year ago, I gave a talk at Cold Spring Harbor Labs about the progress we were making in our work."}, {"time": 1654, "text": "And it was a lot of fun because he said, well, you wouldn't be coming here unless you had something important to say."}, {"time": 1662, "text": "So I'm gonna go attend your talk."}, {"time": 1664, "text": "So he sat in the very front row."}, {"time": 1666, "text": "Next to him was the director of the lab, Bruce Stillman."}, {"time": 1670, "text": "So these guys are in the front row of this auditorium."}, {"time": 1672, "text": "Nobody else in the auditorium wants to sit in the front row because there's Jim Watson and there's the director."}, {"time": 1676, "text": "And I gave a talk and then I had dinner with him afterwards."}, {"time": 1683, "text": "But there's a great picture of my colleague Subitai Amantak where I'm up there sort of like screaming the basics of this new framework we have."}, {"time": 1691, "text": "And Jim Watson's on the edge of his chair."}, {"time": 1693, "text": "He's literally on the edge of his chair, like intently staring up at the screen."}, {"time": 1697, "text": "And when he discovered the structure of DNA, the first public talk he gave was at Cold Spring Harbor Labs."}, {"time": 1705, "text": "And there's a picture, there's a famous picture of Jim Watson standing at the whiteboard with an overrated thing pointing at something, pointing at the double helix with his pointer."}, {"time": 1713, "text": "And it actually looks a lot like the picture of me."}, {"time": 1714, "text": "So there was a sort of funny, there's Arian talking about the brain and there's Jim Watson staring intently at it."}, {"time": 1719, "text": "And of course there with, whatever, 60 years earlier, he was standing pointing at the double helix."}, {"time": 1724, "text": "That's one of the great discoveries in all of, whatever, biology, science, all science and DNA."}, {"time": 1729, "text": "So it's funny that there's echoes of that in your presentation."}, {"time": 1734, "text": "Do you think, in terms of evolutionary timeline and history, the development of the neocortex was a big leap?"}, {"time": 1741, "text": "Or is it just a small step?"}, {"time": 1747, "text": "So like, if we ran the whole thing over again, from the birth of life on Earth, how likely would we develop the mechanism of the neocortex?"}, {"time": 1755, "text": "Okay, well those are two separate questions."}, {"time": 1757, "text": "One is, was it a big leap?"}, {"time": 1758, "text": "And one was how likely it is, okay?"}, {"time": 1761, "text": "They're not necessarily related."}, {"time": 1762, "text": "Maybe correlated."}, {"time": 1763, "text": "Maybe correlated, maybe not."}, {"time": 1765, "text": "And we don't really have enough data to make a judgment about that."}, {"time": 1768, "text": "I would say definitely it was a big leap."}, {"time": 1769, "text": "And I can tell you why."}, {"time": 1770, "text": "I don't think it was just another incremental step."}, {"time": 1774, "text": "I don't get that at the moment."}, {"time": 1775, "text": "I don't really have any idea how likely it is."}, {"time": 1778, "text": "If we look at evolution, we have one data point, which is Earth, right?"}, {"time": 1782, "text": "Life formed on Earth billions of years ago, whether it was introduced here or it created it here, or someone introduced it, we don't really know, but it was here early."}, {"time": 1791, "text": "It took a long, long time to get to multicellular life."}, {"time": 1795, "text": "And then for multicellular life, it took a long, long time to get the neocortex."}, {"time": 1802, "text": "And we've only had the neocortex for a few 100,000 years."}, {"time": 1805, "text": "So that's like nothing, okay?"}, {"time": 1808, "text": "So is it likely?"}, {"time": 1809, "text": "Well, it certainly isn't something that happened right away on Earth."}, {"time": 1813, "text": "And there were multiple steps to get there."}, {"time": 1815, "text": "So I would say it's probably not gonna be something that would happen instantaneously on other planets that might have life."}, {"time": 1820, "text": "It might take several billion years on average."}, {"time": 1823, "text": "Is it likely?"}, {"time": 1824, "text": "I don't know, but you'd have to survive for several billion years to find out."}, {"time": 1829, "text": "Is it a big leap?"}, {"time": 1830, "text": "Yeah, I think it is a qualitative difference in all other evolutionary steps."}, {"time": 1837, "text": "I can try to describe that if you'd like."}, {"time": 1839, "text": "Sure, in which way?"}, {"time": 1841, "text": "Yeah, I can tell you how."}, {"time": 1843, "text": "Pretty much, let's start with a little preface."}, {"time": 1847, "text": "Many of the things that humans are able to do do not have obvious survival advantages precedent."}, {"time": 1858, "text": "We could create music, is that, is there a really survival advantage to that?"}, {"time": 1862, "text": "Maybe, maybe not."}, {"time": 1863, "text": "What about mathematics?"}, {"time": 1864, "text": "Is there a real survival advantage to mathematics?"}, {"time": 1867, "text": "Well, you could stretch it."}, {"time": 1869, "text": "You can try to figure these things out, right?"}, {"time": 1873, "text": "But most of evolutionary history, everything had immediate survival advantages to it."}, {"time": 1878, "text": "So, I'll tell you a story, which I like, may or may not be true, but the story goes as follows."}, {"time": 1889, "text": "Organisms have been evolving for, since the beginning of life here on Earth, and adding this sort of complexity onto that, and this sort of complexity onto that, and the brain itself is evolved this way."}, {"time": 1899, "text": "In fact, there's old parts, and older parts, and older, older parts of the brain that kind of just keeps calming on new things, and we keep adding capabilities."}, {"time": 1907, "text": "When we got to the neocortex, initially it had a very clear survival advantage in that it produced better vision, and better hearing, and better touch, and maybe, and so on."}, {"time": 1917, "text": "But what I think happens is that evolution discovered, it took a mechanism, and this is in our recent theories, but it took a mechanism evolved a long time ago for navigating in the world, for knowing where you are."}, {"time": 1930, "text": "These are the so called grid cells and place cells of an old part of the brain."}, {"time": 1935, "text": "And it took that mechanism for building maps of the world, and knowing where you are on those maps, and how to navigate those maps, and turns it into a sort of a slimmed down, idealized version of it."}, {"time": 1949, "text": "And that idealized version could now apply to building maps of other things."}, {"time": 1952, "text": "Maps of coffee cups, and maps of phones, maps of mathematics."}, {"time": 1956, "text": "Concepts almost."}, {"time": 1957, "text": "Concepts, yes, and not just almost, exactly."}, {"time": 1960, "text": "And so, and it just started replicating this stuff, right?"}, {"time": 1964, "text": "You just think more, and more, and more."}, {"time": 1965, "text": "So we went from being sort of dedicated purpose neural hardware to solve certain problems that are important to survival, to a general purpose neural hardware that could be applied to all problems."}, {"time": 1978, "text": "And now it's escaped the orbit of survival."}, {"time": 1982, "text": "We are now able to apply it to things which we find enjoyment, but aren't really clearly survival characteristics."}, {"time": 1993, "text": "And that it seems to only have happened in humans, to the large extent."}, {"time": 1999, "text": "And so that's what's going on, where we sort of have, we've sort of escaped the gravity of evolutionary pressure, in some sense, in the neocortex."}, {"time": 2008, "text": "And it now does things which are not, that are really interesting, discovering models of the universe, which may not really help us."}, {"time": 2016, "text": "Does it matter?"}, {"time": 2017, "text": "How does it help us surviving, knowing that there might be multiverses, or that there might be the age of the universe, or how do various stellar things occur?"}, {"time": 2026, "text": "It doesn't really help us survive at all."}, {"time": 2027, "text": "But we enjoy it, and that's what happened."}, {"time": 2030, "text": "Or at least not in the obvious way, perhaps."}, {"time": 2033, "text": "It is required, if you look at the entire universe in an evolutionary way, it's required for us to do interplanetary travel, and therefore survive past our own sun."}, {"time": 2043, "text": "But you know, let's not get too."}, {"time": 2044, "text": "Yeah, but evolution works at one time frame, it's survival, if you think of survival of the phenotype, survival of the individual."}, {"time": 2053, "text": "What you're talking about there is spans well beyond that."}, {"time": 2056, "text": "So there's no genetic, I'm not transferring any genetic traits to my children that are gonna help them survive better on Mars."}, {"time": 2066, "text": "Totally different mechanism, that's right."}, {"time": 2068, "text": "So let's get into the new, as you've mentioned, this idea of the, I don't know if you have a nice name, thousand."}, {"time": 2075, "text": "We call it the thousand brain theory of intelligence."}, {"time": 2077, "text": "I like it."}, {"time": 2078, "text": "Can you talk about this idea of a spatial view of concepts and so on?"}, {"time": 2084, "text": "Yeah, so can I just describe sort of the, there's an underlying core discovery, which then everything comes from that."}, {"time": 2091, "text": "That's a very simple, this is really what happened."}, {"time": 2095, "text": "We were deep into problems about understanding how we build models of stuff in the world and how we make predictions about things."}, {"time": 2103, "text": "And I was holding a coffee cup just like this in my hand."}, {"time": 2107, "text": "And my finger was touching the side, my index finger."}, {"time": 2110, "text": "And then I moved it to the top and I was gonna feel the rim at the top of the cup."}, {"time": 2115, "text": "And I asked myself a very simple question."}, {"time": 2118, "text": "I said, well, first of all, I say, I know that my brain predicts what it's gonna feel before it touches it."}, {"time": 2123, "text": "You can just think about it and imagine it."}, {"time": 2126, "text": "And so we know that the brain's making predictions all the time."}, {"time": 2128, "text": "So the question is, what does it take to predict that?"}, {"time": 2131, "text": "And there's a very interesting answer."}, {"time": 2133, "text": "First of all, it says the brain has to know it's touching a coffee cup."}, {"time": 2136, "text": "It has to have a model of a coffee cup."}, {"time": 2138, "text": "It needs to know where the finger currently is on the cup relative to the cup."}, {"time": 2143, "text": "Because when I make a movement, it needs to know where it's going to be on the cup after the movement is completed relative to the cup."}, {"time": 2150, "text": "And then it can make a prediction about what it's gonna sense."}, {"time": 2153, "text": "So this told me that the neocortex, which is making this prediction, needs to know that it's sensing it's touching a cup."}, {"time": 2159, "text": "And it needs to know the location of my finger relative to that cup in a reference frame of the cup."}, {"time": 2164, "text": "It doesn't matter where the cup is relative to my body."}, {"time": 2166, "text": "It doesn't matter its orientation."}, {"time": 2168, "text": "None of that matters."}, {"time": 2169, "text": "It's where my finger is relative to the cup, which tells me then that the neocortex has a reference frame that's anchored to the cup."}, {"time": 2177, "text": "Because otherwise I wouldn't be able to say the location and I wouldn't be able to predict my new location."}, {"time": 2181, "text": "And then we quickly, very instantly can say, well, every part of my skin could touch this cup."}, {"time": 2186, "text": "And therefore every part of my skin is making predictions and every part of my skin must have a reference frame that it's using to make predictions."}, {"time": 2193, "text": "So the big idea is that throughout the neocortex, there are, everything is being stored and referenced in reference frames."}, {"time": 2206, "text": "You can think of them like XYZ reference frames, but they're not like that."}, {"time": 2210, "text": "We know a lot about the neural mechanisms for this, but the brain thinks in reference frames."}, {"time": 2214, "text": "And as an engineer, if you're an engineer, this is not surprising."}, {"time": 2217, "text": "You'd say, if I wanted to build a CAD model of the coffee cup, well, I would bring it up and some CAD software, and I would assign some reference frame and say this features at this locations and so on."}, {"time": 2226, "text": "But the fact that this, the idea that this is occurring throughout the neocortex everywhere, it was a novel idea."}, {"time": 2234, "text": "And then a zillion things fell into place after that, a zillion."}, {"time": 2239, "text": "So now we think about the neocortex as processing information quite differently than we used to do it."}, {"time": 2244, "text": "We used to think about the neocortex as processing sensory data and extracting features from that sensory data and then extracting features from the features, very much like a deep learning network does today."}, {"time": 2254, "text": "But that's not how the brain works at all."}, {"time": 2256, "text": "The brain works by assigning everything, every input, everything to reference frames."}, {"time": 2261, "text": "And there are thousands, hundreds of thousands of them active at once in your neocortex."}, {"time": 2267, "text": "It's a surprising thing to think about, but once you sort of internalize this, you understand that it explains almost every, almost all the mysteries we've had about this structure."}, {"time": 2277, "text": "So one of the consequences of that is that every small part of the neocortex, say a millimeter square, and there's 150,000 of those."}, {"time": 2286, "text": "So it's about 150,000 square millimeters."}, {"time": 2288, "text": "If you take every little square millimeter of the cortex, it's got some input coming into it and it's gonna have reference frames where it's assigned that input to."}, {"time": 2296, "text": "And each square millimeter can learn complete models of objects."}, {"time": 2300, "text": "So what do I mean by that?"}, {"time": 2302, "text": "If I'm touching the coffee cup, well, if I just touch it in one place, I can't learn what this coffee cup is because I'm just feeling one part."}, {"time": 2308, "text": "But if I move it around the cup and touch it at different areas, I can build up a complete model of the cup because I'm now filling in that three dimensional map, which is the coffee cup."}, {"time": 2317, "text": "I can say, oh, what am I feeling at all these different locations?"}, {"time": 2319, "text": "That's the basic idea, it's more complicated than that."}, {"time": 2323, "text": "But so through time, and we talked about time earlier, through time, even a single column, which is only looking at, or a single part of the cortex, which is only looking at a small part of the world, can build up a complete model of an object."}, {"time": 2335, "text": "And so if you think about the part of the brain, which is getting input from all my fingers, so they're spread across the top of your head here."}, {"time": 2341, "text": "This is the somatosensory cortex."}, {"time": 2344, "text": "There's columns associated with all the different areas of my skin."}, {"time": 2347, "text": "And what we believe is happening is that all of them are building models of this cup, every one of them, or things."}, {"time": 2355, "text": "They're not all building, not every column or every part of the cortex builds models of everything, but they're all building models of something."}, {"time": 2361, "text": "And so you have, so when I touch this cup with my hand, there are multiple models of the cup being invoked."}, {"time": 2368, "text": "If I look at it with my eyes, there are, again, many models of the cup being invoked, because each part of the visual system, the brain doesn't process an image."}, {"time": 2375, "text": "That's a misleading idea."}, {"time": 2378, "text": "It's just like your fingers touching the cup, so different parts of my retina are looking at different parts of the cup."}, {"time": 2382, "text": "And thousands and thousands of models of the cup are being invoked at once."}, {"time": 2387, "text": "And they're all voting with each other, trying to figure out what's going on."}, {"time": 2390, "text": "So that's why we call it the thousand brains theory of intelligence, because there isn't one model of a cup."}, {"time": 2394, "text": "There are thousands of models of this cup."}, {"time": 2396, "text": "There are thousands of models of your cellphone and about cameras and microphones and so on."}, {"time": 2400, "text": "It's a distributed modeling system, which is very different than the way people have thought about it."}, {"time": 2404, "text": "And so that's a really compelling and interesting idea."}, {"time": 2407, "text": "I have two first questions."}, {"time": 2408, "text": "So one, on the ensemble part of everything coming together, you have these thousand brains."}, {"time": 2414, "text": "How do you know which one has done the best job of forming the... Great question."}, {"time": 2419, "text": "Let me try to explain it."}, {"time": 2420, "text": "There's a problem that's known in neuroscience called the sensor fusion problem."}, {"time": 2426, "text": "And so the idea is there's something like, oh, the image comes from the eye."}, {"time": 2429, "text": "There's a picture on the retina and then it gets projected to the neocortex."}, {"time": 2432, "text": "Oh, by now it's all spread out all over the place and it's kind of squirrely and distorted and pieces are all over the..."}, {"time": 2439, "text": "It doesn't look like a picture anymore."}, {"time": 2440, "text": "When does it all come back together again?"}, {"time": 2443, "text": "Or you might say, well, yes, but I also have sounds or touches associated with the cup."}, {"time": 2448, "text": "So I'm seeing the cup and touching the cup."}, {"time": 2450, "text": "How do they get combined together again?"}, {"time": 2452, "text": "So it's called the sensor fusion problem."}, {"time": 2454, "text": "As if all these disparate parts have to be brought together into one model someplace."}, {"time": 2459, "text": "That's the wrong idea."}, {"time": 2461, "text": "The right idea is that you've got all these guys voting."}, {"time": 2463, "text": "There's auditory models of the cup."}, {"time": 2465, "text": "There's visual models of the cup."}, {"time": 2466, "text": "There's tactile models of the cup."}, {"time": 2469, "text": "In the vision system, there might be ones that are more focused on black and white and ones focusing on color."}, {"time": 2473, "text": "It doesn't really matter."}, {"time": 2474, "text": "There's just thousands and thousands of models of this cup."}, {"time": 2477, "text": "And they vote."}, {"time": 2477, "text": "They don't actually come together in one spot."}, {"time": 2480, "text": "Just literally think of it this way."}, {"time": 2481, "text": "Imagine you have these columns that are like about the size of a little piece of spaghetti."}, {"time": 2486, "text": "Like a two and a half millimeters tall and about a millimeter in wide."}, {"time": 2490, "text": "They're not physical, but you could think of them that way."}, {"time": 2493, "text": "And each one's trying to guess what this thing is or touching."}, {"time": 2496, "text": "Now, they can do a pretty good job if they're allowed to move over time."}, {"time": 2500, "text": "So I can reach my hand into a black box and move my finger around an object."}, {"time": 2503, "text": "And if I touch enough spaces, I go, okay, now I know what it is."}, {"time": 2506, "text": "But often we don't do that."}, {"time": 2508, "text": "Often I can just reach and grab something with my hand all at once and I get it."}, {"time": 2511, "text": "Or if I had to look through the world through a straw, so I'm only invoking one little column, I can only see part of something because I have to move the straw around."}, {"time": 2518, "text": "But if I open my eyes, I see the whole thing at once."}, {"time": 2520, "text": "So what we think is going on is all these little pieces of spaghetti, if you will, all these little columns in the cortex, are all trying to guess what it is that they're sensing."}, {"time": 2528, "text": "They'll do a better guess if they have time and can move over time."}, {"time": 2531, "text": "So if I move my eyes, I move my fingers."}, {"time": 2533, "text": "But if they don't, they have a poor guess."}, {"time": 2536, "text": "It's a probabilistic guess of what they might be touching."}, {"time": 2540, "text": "Now, imagine they can post their probability at the top of a little piece of spaghetti."}, {"time": 2544, "text": "Each one of them says, I think, and it's not really a probability distribution."}, {"time": 2547, "text": "It's more like a set of possibilities."}, {"time": 2549, "text": "In the brain, it doesn't work as a probability distribution."}, {"time": 2551, "text": "It works as more like what we call a union."}, {"time": 2554, "text": "So you could say, and one column says, I think it could be a coffee cup, a soda can, or a water bottle."}, {"time": 2559, "text": "And another column says, I think it could be a coffee cup or a telephone or a camera or whatever, right?"}, {"time": 2566, "text": "And all these guys are saying what they think it might be."}, {"time": 2569, "text": "And there's these long range connections in certain layers in the cortex."}, {"time": 2573, "text": "So there's in some layers in some cells types in each column, send the projections across the brain."}, {"time": 2580, "text": "And that's the voting occurs."}, {"time": 2581, "text": "And so there's a simple associative memory mechanism."}, {"time": 2584, "text": "We've described this in a recent paper and we've modeled this that says, they can all quickly settle on the only or the one best answer for all of them."}, {"time": 2594, "text": "If there is a single best answer, they all vote and say, yep, it's gotta be the coffee cup."}, {"time": 2598, "text": "And at that point, they all know it's a coffee cup."}, {"time": 2601, "text": "And at that point, everyone acts as if it's a coffee cup."}, {"time": 2603, "text": "They're like, yep, we know it's a coffee, even though I've only seen one little piece of this world, I know it's a coffee cup I'm touching or I'm seeing or whatever."}, {"time": 2608, "text": "And so you can think of all these columns are looking at different parts in different places, different sensory input, different locations, they're all different."}, {"time": 2616, "text": "But this layer that's doing the voting, it solidifies."}, {"time": 2620, "text": "It's just like it crystallizes and says, oh, we all know what we're doing."}, {"time": 2624, "text": "And so you don't bring these models together in one model, you just vote and there's a crystallization of the vote."}, {"time": 2629, "text": "Great, that's at least a compelling way to think about the way you form a model of the world."}, {"time": 2638, "text": "Now, you talk about a coffee cup."}, {"time": 2640, "text": "Do you see this, as far as I understand, you are proposing this as well, that this extends to much more than coffee cups?"}, {"time": 2649, "text": "Or at least the physical world, it expands to the world of concepts."}, {"time": 2655, "text": "And well, first, the primary thing is evidence for that is that the regions of the neocortex that are associated with language or high level thought or mathematics or things like that, they look like the regions of the neocortex that process vision, hearing, and touch."}, {"time": 2668, "text": "They don't look any different."}, {"time": 2669, "text": "Or they look only marginally different."}, {"time": 2672, "text": "And so one would say, well, if Vernon Mountcastle, who proposed that all the parts of the neocortex do the same thing, if he's right, then the parts that are doing language or mathematics or physics are working on the same principle."}, {"time": 2685, "text": "They must be working on the principle of reference frames."}, {"time": 2688, "text": "So that's a little odd thought."}, {"time": 2691, "text": "But of course, we had no prior idea how these things happen."}, {"time": 2695, "text": "So let's go with that."}, {"time": 2697, "text": "And we, in our recent paper, we talked a little bit about that."}, {"time": 2701, "text": "I've been working on it more since."}, {"time": 2702, "text": "I have better ideas about it now."}, {"time": 2705, "text": "I'm sitting here very confident that that's what's happening."}, {"time": 2708, "text": "And I can give you some examples that help you think about that."}, {"time": 2711, "text": "It's not we understand it completely, but I understand it better than I've described it in any paper so far."}, {"time": 2715, "text": "So, but we did put that idea out there."}, {"time": 2717, "text": "It says, okay, this is, it's a good place to start, you know?"}, {"time": 2722, "text": "And the evidence would suggest it's how it's happening."}, {"time": 2724, "text": "And then we can start tackling that problem one piece at a time."}, {"time": 2727, "text": "Like, what does it mean to do high level thought?"}, {"time": 2729, "text": "What does it mean to do language?"}, {"time": 2730, "text": "How would that fit into a reference frame framework?"}, {"time": 2734, "text": "Yeah, so there's a, I don't know if you could tell me if there's a connection, but there's an app called Anki that helps you remember different concepts."}, {"time": 2742, "text": "And they talk about like a memory palace that helps you remember completely random concepts by trying to put them in a physical space in your mind and putting them next to each other."}, {"time": 2752, "text": "It's called the method of loci."}, {"time": 2753, "text": "Loci, yeah."}, {"time": 2754, "text": "For some reason, that seems to work really well."}, {"time": 2757, "text": "Now, that's a very narrow kind of application of just remembering some facts."}, {"time": 2760, "text": "But that's a very, very telling one."}, {"time": 2764, "text": "So this seems like you're describing a mechanism why this seems to work."}, {"time": 2769, "text": "So basically the way what we think is going on is all things you know, all concepts, all ideas, words, everything you know are stored in reference frames."}, {"time": 2780, "text": "And so if you want to remember something, you have to basically navigate through a reference frame the same way a rat navigates through a maze and the same way my finger navigates to this coffee cup."}, {"time": 2791, "text": "You are moving through some space."}, {"time": 2793, "text": "And so if you have a random list of things you were asked to remember, by assigning them to a reference frame, you've already know very well to see your house, right?"}, {"time": 2802, "text": "And the idea of the method of loci is you can say, okay, in my lobby, I'm going to put this thing."}, {"time": 2805, "text": "And then the bedroom, I put this one."}, {"time": 2807, "text": "I go down the hall, I put this thing."}, {"time": 2808, "text": "And then you want to recall those facts or recall those things."}, {"time": 2811, "text": "You just walk mentally, you walk through your house."}, {"time": 2814, "text": "You're mentally moving through a reference frame that you already had."}, {"time": 2817, "text": "And that tells you, there's two things that are really important about that."}, {"time": 2820, "text": "It tells us the brain prefers to store things in reference frames."}, {"time": 2823, "text": "And that the method of recalling things or thinking, if you will, is to move mentally through those reference frames."}, {"time": 2831, "text": "You could move physically through some reference frames, like I could physically move through the reference frame of this coffee cup."}, {"time": 2836, "text": "I can also mentally move through the reference frame of the coffee cup, imagining me touching it."}, {"time": 2839, "text": "But I can also mentally move my house."}, {"time": 2842, "text": "And so now we can ask yourself, or are all concepts stored this way?"}, {"time": 2846, "text": "There was some recent research using human subjects in fMRI, and I'm going to apologize for not knowing the name of the scientists who did this."}, {"time": 2856, "text": "But what they did is they put humans in this fMRI machine, which is one of these imaging machines."}, {"time": 2862, "text": "And they gave the humans tasks to think about birds."}, {"time": 2866, "text": "So they had different types of birds, and birds that look big and small, and long necks and long legs, things like that."}, {"time": 2872, "text": "And what they could tell from the fMRI was a very clever experiment."}, {"time": 2877, "text": "You get to tell when humans were thinking about the birds, that the birds, the knowledge of birds was arranged in a reference frame, similar to the ones that are used when you navigate in a room."}, {"time": 2888, "text": "That these are called grid cells, and there are grid cell like patterns of activity in the neocortex when they do this."}, {"time": 2895, "text": "So it's a very clever experiment."}, {"time": 2898, "text": "And what it basically says, that even when you're thinking about something abstract, and you're not really thinking about it as a reference frame, it tells us the brain is actually using a reference frame."}, {"time": 2906, "text": "And it's using the same neural mechanisms."}, {"time": 2908, "text": "These grid cells are the basic same neural mechanism that we propose that grid cells, which exist in the old part of the brain, the entorhinal cortex, that that mechanism is now similar mechanism is used throughout the neocortex."}, {"time": 2920, "text": "It's the same nature to preserve this interesting way of creating reference frames."}, {"time": 2924, "text": "And so now they have empirical evidence that when you think about concepts like birds, that you're using reference frames that are built on grid cells."}, {"time": 2933, "text": "So that's similar to the method of loci, but in this case, the birds are related."}, {"time": 2936, "text": "So they create their own reference frame, which is consistent with bird space."}, {"time": 2941, "text": "And when you think about something, you go through that."}, {"time": 2943, "text": "You can make the same example, let's take mathematics."}, {"time": 2946, "text": "Let's say you wanna prove a conjecture."}, {"time": 2949, "text": "What is a conjecture?"}, {"time": 2950, "text": "A conjecture is a statement you believe to be true, but you haven't proven it."}, {"time": 2955, "text": "And so it might be an equation."}, {"time": 2956, "text": "I wanna show that this is equal to that."}, {"time": 2959, "text": "And you have some places you start with."}, {"time": 2961, "text": "You say, well, I know this is true, and I know this is true."}, {"time": 2963, "text": "And I think that maybe to get to the final proof, I need to go through some intermediate results."}, {"time": 2968, "text": "What I believe is happening is literally these equations or these points are assigned to a reference frame, a mathematical reference frame."}, {"time": 2977, "text": "And when you do mathematical operations, a simple one might be multiply or divide, but you might be a little plus transform or something else."}, {"time": 2984, "text": "That is like a movement in the reference frame of the math."}, {"time": 2987, "text": "And so you're literally trying to discover a path from one location to another location in a space of mathematics."}, {"time": 2996, "text": "And if you can get to these intermediate results, then you know your map is pretty good, and you know you're using the right operations."}, {"time": 3002, "text": "Much of what we think about is solving hard problems is designing the correct reference frame for that problem, figuring out how to organize the information and what behaviors I wanna use in that space to get me there."}, {"time": 3016, "text": "Yeah, so if you dig in an idea of this reference frame, whether it's the math, you start a set of axioms to try to get to proving the conjecture."}, {"time": 3025, "text": "Can you try to describe, maybe take a step back, how you think of the reference frame in that context?"}, {"time": 3030, "text": "Is it the reference frame that the axioms are happy in?"}, {"time": 3036, "text": "Is it the reference frame that might contain everything?"}, {"time": 3038, "text": "Is it a changing thing as you?"}, {"time": 3041, "text": "You have many, many reference frames."}, {"time": 3043, "text": "I mean, in fact, the way the theory, the thousand brain theory of intelligence says that every single thing in the world has its own reference frame."}, {"time": 3048, "text": "So every word has its own reference frames."}, {"time": 3050, "text": "And we can talk about this."}, {"time": 3052, "text": "The mathematics work out, this is no problem for neurons to do this."}, {"time": 3055, "text": "But how many reference frames does a coffee cup have?"}, {"time": 3058, "text": "Well, it's on a table."}, {"time": 3060, "text": "Let's say you ask how many reference frames could a column in my finger that's touching the coffee cup have?"}, {"time": 3067, "text": "Because there are many, many copy, there are many, many models of the coffee cup."}, {"time": 3070, "text": "So the coffee, there is no one model of a coffee cup."}, {"time": 3073, "text": "There are many models of a coffee cup."}, {"time": 3074, "text": "And you could say, well, how many different things can my finger learn?"}, {"time": 3077, "text": "Is this the question you want to ask?"}, {"time": 3079, "text": "Imagine I say every concept, every idea, everything you've ever know about that you can say, I know that thing has a reference frame associated with it."}, {"time": 3088, "text": "And what we do when we build composite objects, we assign reference frames to point another reference frame."}, {"time": 3093, "text": "So my coffee cup has multiple components to it."}, {"time": 3097, "text": "It's got a limb, it's got a cylinder, it's got a handle."}, {"time": 3100, "text": "And those things have their own reference frames and they're assigned to a master reference frame, which is called this cup."}, {"time": 3106, "text": "And now I have this Numenta logo on it."}, {"time": 3108, "text": "Well, that's something that exists elsewhere in the world."}, {"time": 3110, "text": "It's its own thing."}, {"time": 3111, "text": "So it has its own reference frame."}, {"time": 3112, "text": "So we now have to say, how can I assign the Numenta logo reference frame onto the cylinder or onto the coffee cup?"}, {"time": 3119, "text": "So it's all, we talked about this in the paper that came out in December of this last year."}, {"time": 3126, "text": "The idea of how you can assign reference frames to reference frames, how neurons could do this."}, {"time": 3130, "text": "So, well, my question is, even though you mentioned reference frames a lot, I almost feel it's really useful to dig into how you think of what a reference frame is."}, {"time": 3140, "text": "I mean, it was already helpful for me to understand that you think of reference frames as something there is a lot of."}, {"time": 3146, "text": "Okay, so let's just say that we're gonna have some neurons in the brain, not many, actually, 10,000, 20,000 are gonna create a whole bunch of reference frames."}, {"time": 3154, "text": "What does it mean?"}, {"time": 3155, "text": "What is a reference frame?"}, {"time": 3157, "text": "First of all, these reference frames are different than the ones you might be used to."}, {"time": 3162, "text": "We know lots of reference frames."}, {"time": 3163, "text": "For example, we know the Cartesian coordinates, X, Y, Z, that's a type of reference frame."}, {"time": 3167, "text": "We know longitude and latitude, that's a different type of reference frame."}, {"time": 3172, "text": "If I look at a printed map, you might have columns A through M, and rows one through 20, that's a different type of reference frame."}, {"time": 3181, "text": "It's kind of a Cartesian coordinate reference frame."}, {"time": 3184, "text": "The interesting thing about the reference frames in the brain, and we know this because these have been established through neuroscience studying the entorhinal cortex."}, {"time": 3192, "text": "So I'm not speculating here, okay?"}, {"time": 3193, "text": "This is known neuroscience in an old part of the brain."}, {"time": 3196, "text": "The way these cells create reference frames, they have no origin."}, {"time": 3200, "text": "So what it's more like, you have a point, a point in some space, and you, given a particular movement, you can then tell what the next point should be."}, {"time": 3212, "text": "And you can then tell what the next point would be, and so on."}, {"time": 3215, "text": "You can use this to calculate how to get from one point to another."}, {"time": 3220, "text": "So how do I get from my house to my home, or how do I get my finger from the side of my cup to the top of the cup?"}, {"time": 3226, "text": "How do I get from the axioms to the conjecture?"}, {"time": 3230, "text": "So it's a different type of reference frame, and I can, if you want, I can describe in more detail, I can paint a picture of how you might want to think about that."}, {"time": 3239, "text": "It's really helpful to think it's something you can move through, but is there, is it helpful to think of it as spatial in some sense, or is there something that's more?"}, {"time": 3249, "text": "No, it's definitely spatial."}, {"time": 3251, "text": "It's spatial in a mathematical sense."}, {"time": 3253, "text": "How many dimensions?"}, {"time": 3254, "text": "Can it be a crazy number of dimensions?"}, {"time": 3256, "text": "Well, that's an interesting question."}, {"time": 3257, "text": "In the old part of the brain, the entorhinal cortex, they studied rats, and initially it looks like, oh, this is just two dimensional."}, {"time": 3264, "text": "It's like the rat is in some box in the maze or whatever, and they know where the rat is using these two dimensional reference frames to know where it is in the maze."}, {"time": 3272, "text": "We said, well, okay, but what about bats?"}, {"time": 3275, "text": "That's a mammal, and they fly in three dimensional space."}, {"time": 3278, "text": "How do they do that?"}, {"time": 3279, "text": "They seem to know where they are, right?"}, {"time": 3281, "text": "So this is a current area of active research, and it seems like somehow the neurons in the entorhinal cortex can learn three dimensional space."}, {"time": 3290, "text": "We just, two members of our team, along with Elif Fett from MIT, just released a paper this literally last week."}, {"time": 3299, "text": "It's on bioRxiv, where they show that you can, if you, the way these things work, and I won't get, unless you want to, I won't get into the detail, but grid cells can represent any n dimensional space."}, {"time": 3312, "text": "It's not inherently limited."}, {"time": 3315, "text": "You can think of it this way."}, {"time": 3316, "text": "If you had two dimensional, the way it works is you had a bunch of two dimensional slices."}, {"time": 3320, "text": "That's the way these things work."}, {"time": 3321, "text": "There's a whole bunch of two dimensional models, and you can just, you can slice up any n dimensional space with two dimensional projections."}, {"time": 3329, "text": "So, and you could have one dimensional models."}, {"time": 3331, "text": "So there's nothing inherent about the mathematics about the way the neurons do this, which constrain the dimensionality of the space, which I think was important."}, {"time": 3341, "text": "So obviously I have a three dimensional map of this cup."}, {"time": 3344, "text": "Maybe it's even more than that, I don't know."}, {"time": 3346, "text": "But it's clearly a three dimensional map of the cup."}, {"time": 3348, "text": "I don't just have a projection of the cup."}, {"time": 3350, "text": "But when I think about birds, or when I think about mathematics, perhaps it's more than three dimensions."}, {"time": 3356, "text": "So in terms of each individual column building up more and more information over time, do you think that mechanism is well understood?"}, {"time": 3366, "text": "In your mind, you've proposed a lot of architectures there."}, {"time": 3369, "text": "Is that a key piece, or is it, is the big piece, the thousand brain theory of intelligence, the ensemble of it all?"}, {"time": 3377, "text": "Well, I think they're both big."}, {"time": 3378, "text": "I mean, clearly the concept, as a theorist, the concept is most exciting, right?"}, {"time": 3383, "text": "The high level concept."}, {"time": 3384, "text": "This is a totally new way of thinking about how the neocortex works."}, {"time": 3387, "text": "So that is appealing."}, {"time": 3388, "text": "It has all these ramifications."}, {"time": 3390, "text": "And with that, as a framework for how the brain works, you can make all kinds of predictions and solve all kinds of problems."}, {"time": 3396, "text": "Now we're trying to work through many of these details right now."}, {"time": 3398, "text": "Okay, how do the neurons actually do this?"}, {"time": 3400, "text": "Well, it turns out, if you think about grid cells and place cells in the old parts of the brain, there's a lot that's known about them, but there's still some mysteries."}, {"time": 3407, "text": "There's a lot of debate about exactly the details, how these work and what are the signs."}, {"time": 3410, "text": "And we have that still, that same level of detail, that same level of concern."}, {"time": 3414, "text": "What we spend here most of our time doing is trying to make a very good list of the things we don't understand yet."}, {"time": 3422, "text": "That's the key part here."}, {"time": 3424, "text": "What are the constraints?"}, {"time": 3425, "text": "It's not like, oh, this thing seems to work, we're done."}, {"time": 3427, "text": "No, it's like, okay, it kind of works, but these are other things we know it has to do and it's not doing those yet."}, {"time": 3432, "text": "I would say we're well on the way here."}, {"time": 3435, "text": "We're not done yet."}, {"time": 3437, "text": "There's a lot of trickiness to this system, but the basic principles about how different layers in the neocortex are doing much of this, we understand."}, {"time": 3447, "text": "But there's some fundamental parts that we don't understand as well."}, {"time": 3450, "text": "So what would you say is one of the harder open problems or one of the ones that have been bothering you, keeping you up at night the most?"}, {"time": 3458, "text": "Oh, well, right now, this is a detailed thing that wouldn't apply to most people, okay?"}, {"time": 3463, "text": "But you want me to answer that question?"}, {"time": 3466, "text": "We've talked about as if, oh, to predict what you're going to sense on this coffee cup, I need to know where my finger is gonna be on the coffee cup."}, {"time": 3473, "text": "That is true, but it's insufficient."}, {"time": 3476, "text": "Think about my finger touches the edge of the coffee cup."}, {"time": 3478, "text": "My finger can touch it at different orientations."}, {"time": 3481, "text": "I can rotate my finger around here and that doesn't change."}, {"time": 3486, "text": "I can make that prediction and somehow, so it's not just the location."}, {"time": 3490, "text": "There's an orientation component of this as well."}, {"time": 3493, "text": "This is known in the old parts of the brain too."}, {"time": 3495, "text": "There's things called head direction cells, which way the rat is facing."}, {"time": 3498, "text": "It's the same kind of basic idea."}, {"time": 3500, "text": "So if my finger were a rat, you know, in three dimensions, I have a three dimensional orientation and I have a three dimensional location."}, {"time": 3507, "text": "If I was a rat, I would have a, you might think of it as a two dimensional location, a two dimensional orientation, a one dimensional orientation, like just which way is it facing?"}, {"time": 3515, "text": "So how the two components work together, how it is that I combine orientation, the orientation of my sensor, as well as the location is a tricky problem."}, {"time": 3529, "text": "And I think I've made progress on it."}, {"time": 3532, "text": "So at a bigger version of that, so perspective is super interesting, but super specific."}, {"time": 3538, "text": "Yeah, I warned you."}, {"time": 3540, "text": "No, no, no, that's really good, but there's a more general version of that."}, {"time": 3543, "text": "Do you think context matters, the fact that we're in a building in North America, that we, in the day and age where we have mugs?"}, {"time": 3555, "text": "I mean, there's all this extra information that you bring to the table about everything else in the room that's outside of just the coffee cup."}, {"time": 3564, "text": "How does it get connected, do you think?"}, {"time": 3567, "text": "Yeah, and that is another really interesting question."}, {"time": 3570, "text": "I'm gonna throw that under the rubric or the name of attentional problems."}, {"time": 3575, "text": "First of all, we have this model, I have many, many models."}, {"time": 3578, "text": "And also the question, does it matter?"}, {"time": 3580, "text": "Well, it matters for certain things, of course it does."}, {"time": 3582, "text": "Maybe what we think of that as a coffee cup in another part of the world is viewed as something completely different."}, {"time": 3587, "text": "Or maybe our logo, which is very benign in this part of the world, it means something very different in another part of the world."}, {"time": 3593, "text": "So those things do matter."}, {"time": 3597, "text": "I think the way to think about it is the following, one way to think about it, is we have all these models of the world, okay?"}, {"time": 3604, "text": "And we model everything."}, {"time": 3606, "text": "And as I said earlier, I kind of snuck it in there, our models are actually, we build composite structure."}, {"time": 3612, "text": "So every object is composed of other objects, which are composed of other objects, and they become members of other objects."}, {"time": 3618, "text": "So this room has chairs and a table and a room and walls and so on."}, {"time": 3621, "text": "Now we can just arrange these things in a certain way and go, oh, that's the nomenclature conference room."}, {"time": 3626, "text": "So, and what we do is when we go around the world and we experience the world, by walking into a room, for example, the first thing I do is I can say, oh, I'm in this room, do I recognize the room?"}, {"time": 3638, "text": "Then I can say, oh, look, there's a table here."}, {"time": 3641, "text": "And by attending to the table, I'm then assigning this table in the context of the room."}, {"time": 3645, "text": "Then I can say, oh, on the table, there's a coffee cup."}, {"time": 3648, "text": "Oh, and on the table, there's a logo."}, {"time": 3649, "text": "And in the logo, there's the word Nementa."}, {"time": 3651, "text": "Oh, and look in the logo, there's the letter E. Oh, and look, it has an unusual serif."}, {"time": 3655, "text": "And it doesn't actually, but I pretended to serif."}, {"time": 3659, "text": "So the point is your attention is kind of drilling deep in and out of these nested structures."}, {"time": 3667, "text": "And I can pop back up and I can pop back down."}, {"time": 3669, "text": "I can pop back up and I can pop back down."}, {"time": 3670, "text": "So when I attend to the coffee cup, I haven't lost the context of everything else, but it's sort of, there's this sort of nested structure."}, {"time": 3678, "text": "So the attention filters the reference frame information for that particular period of time?"}, {"time": 3684, "text": "Yes, it basically, moment to moment, you attend the sub components, and then you can attend the sub components to sub components."}, {"time": 3690, "text": "And you can move up and down."}, {"time": 3691, "text": "You can move up and down."}, {"time": 3692, "text": "We do that all the time."}, {"time": 3693, "text": "You're not even, now that I'm aware of it, I'm very conscious of it."}, {"time": 3696, "text": "But until, but most people don't even think about this."}, {"time": 3699, "text": "You just walk in a room and you don't say, oh, I looked at the chair and I looked at the board and looked at that word on the board and I looked over here, what's going on, right?"}, {"time": 3707, "text": "So what percent of your day are you deeply aware of this?"}, {"time": 3710, "text": "And what part can you actually relax and just be Jeff?"}, {"time": 3712, "text": "Me personally, like my personal day?"}, {"time": 3715, "text": "Unfortunately, I'm afflicted with too much of the former."}, {"time": 3721, "text": "Well, unfortunately or unfortunately."}, {"time": 3723, "text": "You don't think it's useful?"}, {"time": 3724, "text": "Oh, it is useful, totally useful."}, {"time": 3726, "text": "I think about this stuff almost all the time."}, {"time": 3729, "text": "And one of my primary ways of thinking is when I'm in sleep at night, I always wake up in the middle of the night."}, {"time": 3735, "text": "And then I stay awake for at least an hour with my eyes shut in sort of a half sleep state thinking about these things."}, {"time": 3741, "text": "I come up with answers to problems very often in that sort of half sleeping state."}, {"time": 3745, "text": "I think about it on my bike ride, I think about it on walks."}, {"time": 3747, "text": "I'm just constantly thinking about this."}, {"time": 3748, "text": "I have to almost schedule time to not think about this stuff because it's very, it's mentally taxing."}, {"time": 3757, "text": "Are you, when you're thinking about this stuff, are you thinking introspectively, like almost taking a step outside of yourself and trying to figure out what is your mind doing right now?"}, {"time": 3765, "text": "I do that all the time, but that's not all I do."}, {"time": 3769, "text": "I'm constantly observing myself."}, {"time": 3770, "text": "So as soon as I started thinking about grid cells, for example, and getting into that, I started saying, oh, well, grid cells can have my place of sense in the world."}, {"time": 3778, "text": "That's where you know where you are."}, {"time": 3779, "text": "And it's interesting, we always have a sense of where we are unless we're lost."}, {"time": 3783, "text": "And so I started at night when I got up to go to the bathroom, I would start trying to do it completely with my eyes closed all the time."}, {"time": 3788, "text": "And I would test my sense of grid cells."}, {"time": 3790, "text": "I would walk five feet and say, okay, I think I'm here."}, {"time": 3793, "text": "Am I really there?"}, {"time": 3794, "text": "What's my error?"}, {"time": 3795, "text": "And then I would calculate my error again and see how the errors could accumulate."}, {"time": 3797, "text": "So even something as simple as getting up in the middle of the night to go to the bathroom, I'm testing these theories out."}, {"time": 3802, "text": "It's kind of fun."}, {"time": 3803, "text": "I mean, the coffee cup is an example of that too."}, {"time": 3805, "text": "So I find that these sort of everyday introspections are actually quite helpful."}, {"time": 3812, "text": "It doesn't mean you can ignore the science."}, {"time": 3814, "text": "I mean, I spend hours every day reading ridiculously complex papers."}, {"time": 3820, "text": "That's not nearly as much fun, but you have to sort of build up those constraints and the knowledge about the field and who's doing what and what exactly they think is happening here."}, {"time": 3828, "text": "And then you can sit back and say, okay, let's try to piece this all together."}, {"time": 3833, "text": "Let's come up with some, I'm very, in this group here, people, they know they do, I do this all the time."}, {"time": 3839, "text": "I come in with these introspective ideas and say, well, have you ever thought about this?"}, {"time": 3842, "text": "Now watch, well, let's all do this together."}, {"time": 3844, "text": "And it's helpful."}, {"time": 3845, "text": "It's not, as long as you don't, all you did was that, then you're just making up stuff."}, {"time": 3852, "text": "But if you're constraining it by the reality of the neuroscience, then it's really helpful."}, {"time": 3857, "text": "So let's talk a little bit about deep learning and the successes in the applied space of neural networks, ideas of training model on data and these simple computational units, artificial neurons that with backpropagation, statistical ways of being able to generalize from the training set onto data that's similar to that training set."}, {"time": 3884, "text": "So where do you think are the limitations of those approaches?"}, {"time": 3888, "text": "What do you think are its strengths relative to your major efforts of constructing a theory of human intelligence?"}, {"time": 3896, "text": "Well, I'm not an expert in this field."}, {"time": 3897, "text": "I'm somewhat knowledgeable."}, {"time": 3899, "text": "So, but I'm not."}, {"time": 3899, "text": "Some of it is in just your intuition."}, {"time": 3901, "text": "What are your?"}, {"time": 3902, "text": "Well, I have a little bit more than intuition, but I just want to say like, you know, one of the things that you asked me, do I spend all my time thinking about neuroscience?"}, {"time": 3910, "text": "That's to the exclusion of thinking about things like convolutional neural networks."}, {"time": 3913, "text": "But I try to stay current."}, {"time": 3915, "text": "So look, I think it's great, the progress they've made."}, {"time": 3918, "text": "And as I mentioned earlier, it's very highly useful for many things."}, {"time": 3922, "text": "The models that we have today are actually derived from a lot of neuroscience principles."}, {"time": 3928, "text": "There are distributed processing systems and distributed memory systems, and that's how the brain works."}, {"time": 3933, "text": "They use things that we might call them neurons, but they're really not neurons at all."}, {"time": 3937, "text": "So we can just, they're not really neurons."}, {"time": 3939, "text": "So they're distributed processing systems."}, {"time": 3941, "text": "And that nature of hierarchy, that came also from neuroscience."}, {"time": 3947, "text": "And so there's a lot of things, the learning rules, basically, not back prop, but other, you know, sort of heavy on top of that."}, {"time": 3952, "text": "I'd be curious to say they're not neurons at all."}, {"time": 3955, "text": "Can you describe in which way?"}, {"time": 3956, "text": "I mean, some of it is obvious, but I'd be curious if you have specific ways in which you think are the biggest differences."}, {"time": 3962, "text": "Yeah, we had a paper in 2016 called Why Neurons Have Thousands of Synapses."}, {"time": 3966, "text": "And if you read that paper, you'll know what I'm talking about here."}, {"time": 3971, "text": "A real neuron in the brain is a complex thing."}, {"time": 3974, "text": "And let's just start with the synapses on it, which is a connection between neurons."}, {"time": 3979, "text": "Real neurons can have everywhere from five to 30,000 synapses on them."}, {"time": 3985, "text": "The ones near the cell body, the ones that are close to the soma of the cell body, those are like the ones that people model in artificial neurons."}, {"time": 3993, "text": "There is a few hundred of those."}, {"time": 3995, "text": "Maybe they can affect the cell."}, {"time": 3997, "text": "They can make the cell become active."}, {"time": 3999, "text": "95% of the synapses can't do that."}, {"time": 4003, "text": "They're too far away."}, {"time": 4004, "text": "So if you activate one of those synapses, it just doesn't affect the cell body enough to make any difference."}, {"time": 4008, "text": "Any one of them individually."}, {"time": 4010, "text": "Any one of them individually, or even if you do a mass of them."}, {"time": 4014, "text": "What real neurons do is the following."}, {"time": 4017, "text": "If you activate or you get 10 to 20 of them active at the same time, meaning they're all receiving an input at the same time, and those 10 to 20 synapses or 40 synapses within a very short distance on the dendrite, like 40 microns, a very small area."}, {"time": 4033, "text": "So if you activate a bunch of these right next to each other at some distant place, what happens is it creates what's called the dendritic spike."}, {"time": 4041, "text": "And the dendritic spike travels through the dendrites and can reach the soma or the cell body."}, {"time": 4047, "text": "Now, when it gets there, it changes the voltage, which is sort of like gonna make the cell fire, but never enough to make the cell fire."}, {"time": 4056, "text": "It's sort of what we call, it says we depolarize the cell, you raise the voltage a little bit, but not enough to do anything."}, {"time": 4061, "text": "It's like, well, what good is that?"}, {"time": 4062, "text": "And then it goes back down again."}, {"time": 4064, "text": "So we propose a theory, which I'm very confident in basics are, is that what's happening there is those 95% of the synapses are recognizing dozens to hundreds of unique patterns."}, {"time": 4078, "text": "They can write about 10, 20 synapses at a time, and they're acting like predictions."}, {"time": 4084, "text": "So the neuron actually is a predictive engine on its own."}, {"time": 4087, "text": "It can fire when it gets enough, what they call proximal input from those ones near the cell fire, but it can get ready to fire from dozens to hundreds of patterns that it recognizes from the other guys."}, {"time": 4098, "text": "And the advantage of this to the neuron is that when it actually does produce a spike in action potential, it does so slightly sooner than it would have otherwise."}, {"time": 4107, "text": "And so what could is slightly sooner?"}, {"time": 4109, "text": "Well, the slightly sooner part is it, all the excitatory neurons in the brain are surrounded by these inhibitory neurons, and they're very fast, the inhibitory neurons, these basket cells."}, {"time": 4120, "text": "And if I get my spike out a little bit sooner than someone else, I inhibit all my neighbors around me, right?"}, {"time": 4127, "text": "And what you end up with is a different representation."}, {"time": 4129, "text": "You end up with a reputation that matches your prediction."}, {"time": 4132, "text": "It's a sparser representation, meaning fewer neurons are active, but it's much more specific."}, {"time": 4137, "text": "And so we showed how networks of these neurons can do very sophisticated temporal prediction, basically."}, {"time": 4144, "text": "So this, summarize this, real neurons in the brain are time based prediction engines, and there's no concept of this at all in artificial, what we call point neurons."}, {"time": 4158, "text": "I don't think you can build a brain without them."}, {"time": 4160, "text": "I don't think you can build intelligence without them, because it's where a large part of the time comes from."}, {"time": 4166, "text": "These are predictive models, and the time is, there's a prior and a prediction and an action, and it's inherent through every neuron in the neocortex."}, {"time": 4174, "text": "So I would say that point neurons sort of model a piece of that, and not very well at that either."}, {"time": 4180, "text": "But like for example, synapses are very unreliable, and you cannot assign any precision to them."}, {"time": 4189, "text": "So even one digit of precision is not possible."}, {"time": 4192, "text": "So the way real neurons work is they don't add these, they don't change these weights accurately like artificial neural networks do."}, {"time": 4199, "text": "They basically form new synapses, and so what you're trying to always do is detect the presence of some 10 to 20 active synapses at the same time, as opposed, and they're almost binary."}, {"time": 4211, "text": "It's like, because you can't really represent anything much finer than that."}, {"time": 4214, "text": "So these are the kind of, and I think that's actually another essential component, because the brain works on sparse patterns, and all that mechanism is based on sparse patterns, and I don't actually think you could build real brains or machine intelligence without incorporating some of those ideas."}, {"time": 4230, "text": "It's hard to even think about the complexity that emerges from the fact that the timing of the firing matters in the brain, the fact that you form new synapses, and I mean, everything you just mentioned in the past couple minutes."}, {"time": 4244, "text": "Trust me, if you spend time on it, you can get your mind around it."}, {"time": 4247, "text": "It's not like, it's no longer a mystery to me."}, {"time": 4249, "text": "No, but sorry, as a function, in a mathematical way, can you start getting an intuition about what gets it excited, what not, and what kind of representation?"}, {"time": 4259, "text": "Yeah, it's not as easy as, there's many other types of neural networks that are more amenable to pure analysis, especially very simple networks."}, {"time": 4270, "text": "Oh, I have four neurons, and they're doing this."}, {"time": 4272, "text": "Can we describe to them mathematically what they're doing type of thing?"}, {"time": 4276, "text": "Even the complexity of convolutional neural networks today, it's sort of a mystery."}, {"time": 4280, "text": "They can't really describe the whole system."}, {"time": 4282, "text": "And so it's different."}, {"time": 4284, "text": "My colleague Subitai Ahmad, he did a nice paper on this."}, {"time": 4291, "text": "You can get all this stuff on our website if you're interested, talking about sort of the mathematical properties of sparse representations."}, {"time": 4297, "text": "And so what we can do is we can show mathematically, for example, why 10 to 20 synapses to recognize a pattern is the correct number, is the right number you'd wanna use."}, {"time": 4307, "text": "And by the way, that matches biology."}, {"time": 4309, "text": "We can show mathematically some of these concepts about the show why the brain is so robust to noise and error and fallout and so on."}, {"time": 4321, "text": "We can show that mathematically as well as empirically in simulations."}, {"time": 4325, "text": "But the system can't be analyzed completely."}, {"time": 4327, "text": "Any complex system can't, and so that's out of the realm."}, {"time": 4331, "text": "But there is mathematical benefits and intuitions that can be derived from mathematics."}, {"time": 4339, "text": "And we try to do that as well."}, {"time": 4340, "text": "Most of our papers have a section about that."}, {"time": 4343, "text": "So I think it's refreshing and useful for me to be talking to you about deep neural networks, because your intuition basically says that we can't achieve anything like intelligence with artificial neural networks."}, {"time": 4355, "text": "Well, not in the current form."}, {"time": 4356, "text": "Not in the current form."}, {"time": 4357, "text": "I'm sure we can do it in the ultimate form, sure."}, {"time": 4360, "text": "So let me dig into it and see what your thoughts are there a little bit."}, {"time": 4363, "text": "So I'm not sure if you read this little blog post called Bitter Lesson by Rich Sutton recently."}, {"time": 4369, "text": "He's a reinforcement learning pioneer."}, {"time": 4371, "text": "I'm not sure if you're familiar with him."}, {"time": 4373, "text": "His basic idea is that all the stuff we've done in AI in the past 70 years, he's one of the old school guys."}, {"time": 4382, "text": "The biggest lesson learned is that all the tricky things we've done, they benefit in the short term, but in the long term, what wins out is a simple general method that just relies on Moore's law, on computation getting faster and faster."}, {"time": 4399, "text": "This is what he's saying."}, {"time": 4401, "text": "This is what has worked up to now."}, {"time": 4405, "text": "If you're trying to build a system, if we're talking about, he's not concerned about intelligence."}, {"time": 4411, "text": "He's concerned about a system that works in terms of making predictions on applied narrow AI problems, right?"}, {"time": 4418, "text": "That's what this discussion is about."}, {"time": 4420, "text": "That you just try to go as general as possible and wait years or decades for the computation to make it actually."}, {"time": 4430, "text": "Is he saying that as a criticism or is he saying this is a prescription of what we ought to be doing?"}, {"time": 4434, "text": "Well, it's very difficult."}, {"time": 4435, "text": "He's saying this is what has worked and yes, a prescription, but it's a difficult prescription because it says all the fun things you guys are trying to do, we are trying to do."}, {"time": 4445, "text": "He's part of the community."}, {"time": 4447, "text": "He's saying it's only going to be short term gains."}, {"time": 4450, "text": "So this all leads up to a question, I guess, on artificial neural networks and maybe our own biological neural networks is do you think if we just scale things up significantly, so take these dumb artificial neurons, the point neurons, I like that term."}, {"time": 4470, "text": "If we just have a lot more of them, do you think some of the elements that we see in the brain may start emerging?"}, {"time": 4479, "text": "We can do bigger problems of the same type."}, {"time": 4483, "text": "I mean, it's been pointed out by many people that today's convolutional neural networks aren't really much different than the ones we had quite a while ago."}, {"time": 4490, "text": "They're bigger and train more and we have more labeled data and so on."}, {"time": 4496, "text": "But I don't think you can get to the kind of things I know the brain can do and that we think about as intelligence by just scaling it up."}, {"time": 4503, "text": "So that may be, it's a good description of what's happened in the past, what's happened recently with the reemergence of artificial neural networks."}, {"time": 4512, "text": "It may be a good prescription for what's gonna happen in the short term."}, {"time": 4517, "text": "But I don't think that's the path."}, {"time": 4519, "text": "I've said that earlier."}, {"time": 4520, "text": "There's an alternate path."}, {"time": 4521, "text": "I should mention to you, by the way, that we've made sufficient progress on the whole cortical theory in the last few years that last year we decided to start actively pursuing how do we get these ideas embedded into machine learning?"}, {"time": 4540, "text": "Well, that's, again, being led by my colleague, Subed Tariman, and he's more of a machine learning guy."}, {"time": 4545, "text": "I'm more of a neuroscience guy."}, {"time": 4546, "text": "So this is now, I wouldn't say our focus, but it is now an equal focus here because we need to proselytize what we've learned and we need to show how it's beneficial to the machine learning layer."}, {"time": 4563, "text": "So we're putting, we have a plan in place right now."}, {"time": 4565, "text": "In fact, we just did our first paper on this."}, {"time": 4567, "text": "I can tell you about that."}, {"time": 4569, "text": "But one of the reasons I wanna talk to you is because I'm trying to get more people in the machine learning community to say, I need to learn about this stuff."}, {"time": 4577, "text": "And maybe we should just think about this a bit more about what we've learned about the brain and what are those team at Nimenta, what have they done?"}, {"time": 4583, "text": "Is that useful for us?"}, {"time": 4585, "text": "Yeah, so is there elements of all the cortical theory that things we've been talking about that may be useful in the short term?"}, {"time": 4591, "text": "Yes, in the short term, yes."}, {"time": 4593, "text": "This is the, sorry to interrupt, but the open question is, it certainly feels from my perspective that in the long term, some of the ideas we've been talking about will be extremely useful."}, {"time": 4604, "text": "The question is whether in the short term."}, {"time": 4606, "text": "Well, this is always what I would call the entrepreneur's dilemma."}, {"time": 4610, "text": "So you have this long term vision, oh, we're gonna all be driving electric cars or we're all gonna have computers or we're all gonna, whatever."}, {"time": 4619, "text": "And you're at some point in time and you say, I can see that long term vision, I'm sure it's gonna happen."}, {"time": 4623, "text": "How do I get there without killing myself?"}, {"time": 4625, "text": "Without going out of business, right?"}, {"time": 4627, "text": "That's the challenge."}, {"time": 4628, "text": "That's the dilemma."}, {"time": 4629, "text": "That's the really difficult thing to do."}, {"time": 4631, "text": "So we're facing that right now."}, {"time": 4633, "text": "So ideally what you'd wanna do is find some steps along the way that you can get there incrementally."}, {"time": 4637, "text": "You don't have to like throw it all out and start over again."}, {"time": 4640, "text": "The first thing that we've done is we focus on the sparse representations."}, {"time": 4645, "text": "So just in case you don't know what that means or some of the listeners don't know what that means, in the brain, if I have like 10,000 neurons, what you would see is maybe 2% of them active at a time."}, {"time": 4656, "text": "You don't see 50%, you don't see 30%, you might see 2%."}, {"time": 4661, "text": "And it's always like that."}, {"time": 4662, "text": "For any set of sensory inputs?"}, {"time": 4664, "text": "It doesn't matter if anything, doesn't matter any part of the brain."}, {"time": 4667, "text": "But which neurons differs?"}, {"time": 4671, "text": "Which neurons are active?"}, {"time": 4672, "text": "Yeah, so let's say I take 10,000 neurons that are representing something."}, {"time": 4676, "text": "They're sitting there in a little block together."}, {"time": 4677, "text": "It's a teeny little block of neurons, 10,000 neurons."}, {"time": 4680, "text": "And they're representing a location, they're representing a cup, they're representing the input from my sensors."}, {"time": 4684, "text": "I don't know, it doesn't matter."}, {"time": 4685, "text": "It's representing something."}, {"time": 4687, "text": "The way the representations occur, it's always a sparse representation."}, {"time": 4690, "text": "Meaning it's a population code."}, {"time": 4691, "text": "So which 200 cells are active tells me what's going on."}, {"time": 4694, "text": "It's not, individual cells aren't that important at all."}, {"time": 4698, "text": "It's the population code that matters."}, {"time": 4700, "text": "And when you have sparse population codes, then all kinds of beautiful properties come out of them."}, {"time": 4706, "text": "So the brain uses sparse population codes."}, {"time": 4708, "text": "We've written and described these benefits in some of our papers."}, {"time": 4712, "text": "So they give this tremendous robustness to the systems."}, {"time": 4717, "text": "Brains are incredibly robust."}, {"time": 4719, "text": "Neurons are dying all the time and spasming and synapses are falling apart all the time."}, {"time": 4723, "text": "And it keeps working."}, {"time": 4725, "text": "So what Sibutai and Louise, one of our other engineers here have done, have shown they're introducing sparseness into convolutional neural networks."}, {"time": 4736, "text": "Now other people are thinking along these lines, but we're going about it in a more principled way, I think."}, {"time": 4740, "text": "And we're showing that if you enforce sparseness throughout these convolutional neural networks in both the act, which sort of, which neurons are active and the connections between them, that you get some very desirable properties."}, {"time": 4755, "text": "So one of the current hot topics in deep learning right now are these adversarial examples."}, {"time": 4760, "text": "So, you know, you give me any deep learning network and I can give you a picture that looks perfect and you're going to call it, you know, you're going to say the monkey is, you know, an airplane."}, {"time": 4770, "text": "So that's a problem."}, {"time": 4772, "text": "And DARPA just announced some big thing."}, {"time": 4774, "text": "They're trying to, you know, have some contest for this."}, {"time": 4776, "text": "But if you enforce sparse representations here, many of these problems go away."}, {"time": 4781, "text": "They're much more robust and they're not easy to fool."}, {"time": 4784, "text": "So we've already shown some of those results, just literally in January or February, just like last month we did that."}, {"time": 4793, "text": "And you can, I think it's on bioRxiv right now, or on iRxiv, you can read about it."}, {"time": 4799, "text": "But, so that's like a baby step, okay?"}, {"time": 4803, "text": "That's taking something from the brain."}, {"time": 4804, "text": "We know about sparseness."}, {"time": 4805, "text": "We know why it's important."}, {"time": 4806, "text": "We know what it gives the brain."}, {"time": 4808, "text": "So let's try to enforce that onto this."}, {"time": 4809, "text": "What's your intuition why sparsity leads to robustness?"}, {"time": 4812, "text": "Because it feels like it would be less robust."}, {"time": 4815, "text": "Why would you feel the rest robust to you?"}, {"time": 4817, "text": "So it just feels like if the fewer neurons are involved, the more fragile the representation."}, {"time": 4826, "text": "But I didn't say there was lots of few neurons."}, {"time": 4828, "text": "I said, let's say 200."}, {"time": 4829, "text": "That's a lot."}, {"time": 4831, "text": "There's still a lot, it's just."}, {"time": 4832, "text": "So here's an intuition for it."}, {"time": 4835, "text": "This is a bit technical, so for engineers, machine learning people, this will be easy, but all the listeners, maybe not."}, {"time": 4844, "text": "If you're trying to classify something, you're trying to divide some very high dimensional space into different pieces, A and B."}, {"time": 4850, "text": "And you're trying to create some point where you say, all these points in this high dimensional space are A, and all these points in this high dimensional space are B."}, {"time": 4857, "text": "And if you have points that are close to that line, it's not very robust."}, {"time": 4862, "text": "It works for all the points you know about, but it's not very robust, because you can just move a little bit and you've crossed over the line."}, {"time": 4870, "text": "When you have sparse representations, imagine I pick, I'm gonna pick 200 cells active out of 10,000, okay?"}, {"time": 4879, "text": "So I have 200 cells active."}, {"time": 4880, "text": "Now let's say I pick randomly another, a different representation, 200."}, {"time": 4884, "text": "The overlap between those is gonna be very small, just a few."}, {"time": 4888, "text": "I can pick millions of samples randomly of 200 neurons, and not one of them will overlap more than just a few."}, {"time": 4896, "text": "So one way to think about it is, if I wanna fool one of these representations to look like one of those other representations, I can't move just one cell, or two cells, or three cells, or four cells."}, {"time": 4906, "text": "I have to move 100 cells."}, {"time": 4909, "text": "And that makes them robust."}, {"time": 4912, "text": "In terms of further, so you mentioned sparsity."}, {"time": 4916, "text": "What would be the next thing?"}, {"time": 4918, "text": "Okay, so we have, we picked one."}, {"time": 4920, "text": "We don't know if it's gonna work well yet."}, {"time": 4922, "text": "So again, we're trying to come up with incremental ways to moving from brain theory to add pieces to machine learning, current machine learning world, and one step at a time."}, {"time": 4932, "text": "So the next thing we're gonna try to do is sort of incorporate some of the ideas of the thousand brains theory, that you have many, many models that are voting."}, {"time": 4942, "text": "Now that idea is not new."}, {"time": 4943, "text": "There's a mixture of models that's been around for a long time."}, {"time": 4947, "text": "But the way the brain does it is a little different."}, {"time": 4949, "text": "And the way it votes is different."}, {"time": 4953, "text": "And the kind of way it represents uncertainty is different."}, {"time": 4957, "text": "So we're just starting this work, but we're gonna try to see if we can sort of incorporate some of the principles of voting, or principles of the thousand brain theory."}, {"time": 4965, "text": "Like lots of simple models that talk to each other in a certain way."}, {"time": 4973, "text": "And can we build more machines, systems that learn faster and also, well mostly are multimodal and robust to multimodal type of issues."}, {"time": 4987, "text": "So one of the challenges there is the machine learning computer vision community has certain sets of benchmarks, sets of tests based on which they compete."}, {"time": 4998, "text": "And I would argue, especially from your perspective, that those benchmarks aren't that useful for testing the aspects that the brain is good at, or intelligence."}, {"time": 5009, "text": "They're not really testing intelligence."}, {"time": 5011, "text": "They're very fine."}, {"time": 5012, "text": "And it's been extremely useful for developing specific mathematical models, but it's not useful in the long term for creating intelligence."}, {"time": 5021, "text": "So you think you also have a role in proposing better tests?"}, {"time": 5027, "text": "Yeah, this is a very, you've identified a very serious problem."}, {"time": 5031, "text": "First of all, the tests that they have are the tests that they want."}, {"time": 5034, "text": "Not the tests of the other things that we're trying to do, right?"}, {"time": 5038, "text": "You know, what are the, so on."}, {"time": 5041, "text": "The second thing is sometimes these, to be competitive in these tests, you have to have huge data sets and huge computing power."}, {"time": 5050, "text": "And so, you know, and we don't have that here."}, {"time": 5053, "text": "We don't have it as well as other big teams that big companies do."}, {"time": 5058, "text": "So there's numerous issues there."}, {"time": 5060, "text": "You know, we come out, you know, where our approach to this is all based on, in some sense, you might argue, elegance."}, {"time": 5066, "text": "We're coming at it from like a theoretical base that we think, oh my God, this is so clearly elegant."}, {"time": 5069, "text": "This is how brains work."}, {"time": 5070, "text": "This is what intelligence is."}, {"time": 5071, "text": "But the machine learning world has gotten in this phase where they think it doesn't matter."}, {"time": 5075, "text": "Doesn't matter what you think, as long as you do, you know, 0.1% better on this benchmark, that's what, that's all that matters."}, {"time": 5080, "text": "And that's a problem."}, {"time": 5083, "text": "You know, we have to figure out how to get around that."}, {"time": 5086, "text": "That's a challenge for us."}, {"time": 5087, "text": "That's one of the challenges that we have to deal with."}, {"time": 5090, "text": "So I agree, you've identified a big issue."}, {"time": 5092, "text": "It's difficult for those reasons."}, {"time": 5095, "text": "But you know, part of the reasons I'm talking to you here today is I hope I'm gonna get some machine learning people to say, I'm gonna read those papers."}, {"time": 5103, "text": "Those might be some interesting ideas."}, {"time": 5104, "text": "I'm tired of doing this 0.1% improvement stuff, you know?"}, {"time": 5108, "text": "Well, that's why I'm here as well, because I think machine learning now as a community is at a place where the next step needs to be orthogonal to what has received success in the past."}, {"time": 5121, "text": "Well, you see other leaders saying this, machine learning leaders, you know, Jeff Hinton with his capsules idea."}, {"time": 5127, "text": "Many people have gotten up to say, you know, we're gonna hit road map, maybe we should look at the brain, you know, things like that."}, {"time": 5133, "text": "So hopefully that thinking will occur organically."}, {"time": 5138, "text": "And then we're in a nice position for people to come and look at our work and say, well, what can we learn from these guys?"}, {"time": 5143, "text": "Yeah, MIT is launching a billion dollar computing college that's centered around this idea, so."}, {"time": 5149, "text": "Is it on this idea of what?"}, {"time": 5150, "text": "Well, the idea that, you know, the humanities, psychology, and neuroscience have to work all together to get to build the S. Yeah, I mean, Stanford just did this Human Centered AI Center."}, {"time": 5162, "text": "I'm a little disappointed in these initiatives because, you know, they're focusing on sort of the human side of it, and it could very easily slip into how humans interact with intelligent machines, which is nothing wrong with that, but that's not, that is orthogonal to what we're trying to do."}, {"time": 5180, "text": "We're trying to say, like, what is the essence of intelligence?"}, {"time": 5182, "text": "I don't care."}, {"time": 5183, "text": "In fact, I wanna build intelligent machines that aren't emotional, that don't smile at you, that, you know, that aren't trying to tuck you in at night."}, {"time": 5191, "text": "Yeah, there is that pattern that you, when you talk about understanding humans is important for understanding intelligence, that you start slipping into topics of ethics or, yeah, like you said, the interactive elements as opposed to, no, no, no, we have to zoom in on the brain, study what the human brain, the baby, the... Let's study what a brain does."}, {"time": 5212, "text": "Does."}, {"time": 5213, "text": "And then we can decide which parts of that we wanna recreate in some system, but until you have that theory about what the brain does, what's the point, you know, it's just, you're gonna be wasting time, I think."}, {"time": 5222, "text": "Right, just to break it down on the artificial neural network side, maybe you could speak to this on the biological neural network side, the process of learning versus the process of inference."}, {"time": 5233, "text": "Maybe you can explain to me, is there a difference between, you know, in artificial neural networks, there's a difference between the learning stage and the inference stage."}, {"time": 5242, "text": "Do you see the brain as something different?"}, {"time": 5244, "text": "One of the big distinctions that people often say, I don't know how correct it is, is artificial neural networks need a lot of data."}, {"time": 5252, "text": "They're very inefficient learning."}, {"time": 5254, "text": "Do you see that as a correct distinction from the biology of the human brain, that the human brain is very efficient, or is that just something we deceive ourselves?"}, {"time": 5264, "text": "No, it is efficient, obviously."}, {"time": 5265, "text": "We can learn new things almost instantly."}, {"time": 5267, "text": "And so what elements do you think are useful?"}, {"time": 5270, "text": "Yeah, I can talk about that."}, {"time": 5270, "text": "You brought up two issues there."}, {"time": 5272, "text": "So remember I talked early about the constraints we always feel, well, one of those constraints is the fact that brains are continually learning."}, {"time": 5280, "text": "That's not something we said, oh, we can add that later."}, {"time": 5283, "text": "That's something that was upfront, had to be there from the start, made our problems harder."}, {"time": 5291, "text": "But we showed, going back to the 2016 paper on sequence memory, we showed how that happens, how the brains infer and learn at the same time."}, {"time": 5299, "text": "And our models do that."}, {"time": 5301, "text": "And they're not two separate phases, or two separate sets of time."}, {"time": 5306, "text": "I think that's a big, big problem in AI, at least for many applications, not for all."}, {"time": 5313, "text": "So I can talk about that."}, {"time": 5314, "text": "There are some, it gets detailed, there are some parts of the neocortex in the brain where actually what's going on, there's these cycles of activity in the brain."}, {"time": 5326, "text": "And there's very strong evidence that you're doing more of inference on one part of the phase, and more of learning on the other part of the phase."}, {"time": 5334, "text": "So the brain can actually sort of separate different populations of cells or going back and forth like this."}, {"time": 5338, "text": "But in general, I would say that's an important problem."}, {"time": 5341, "text": "We have all of our networks that we've come up with do both."}, {"time": 5345, "text": "And they're continuous learning networks."}, {"time": 5348, "text": "And you mentioned benchmarks earlier."}, {"time": 5350, "text": "Well, there are no benchmarks about that."}, {"time": 5352, "text": "So we have to, we get in our little soapbox, and hey, by the way, this is important, and here's a mechanism for doing that."}, {"time": 5360, "text": "But until you can prove it to someone in some commercial system or something, it's a little harder."}, {"time": 5366, "text": "So yeah, one of the things I had to linger on that is in some ways to learn the concept of a coffee cup, you only need this one coffee cup and maybe some time alone in a room with it."}, {"time": 5377, "text": "Well, the first thing is, imagine I reach my hand into a black box and I'm reaching, I'm trying to touch something."}, {"time": 5383, "text": "I don't know upfront if it's something I already know or if it's a new thing."}, {"time": 5387, "text": "And I have to, I'm doing both at the same time."}, {"time": 5390, "text": "I don't say, oh, let's see if it's a new thing."}, {"time": 5393, "text": "Oh, let's see if it's an old thing."}, {"time": 5394, "text": "I don't do that."}, {"time": 5395, "text": "As I go, my brain says, oh, it's new or it's not new."}, {"time": 5399, "text": "And if it's new, I start learning what it is."}, {"time": 5402, "text": "And by the way, it starts learning from the get go, even if it's gonna recognize it."}, {"time": 5406, "text": "So they're not separate problems."}, {"time": 5408, "text": "And so that's the thing there."}, {"time": 5410, "text": "The other thing you mentioned was the fast learning."}, {"time": 5413, "text": "So I was just talking about continuous learning, but there's also fast learning."}, {"time": 5416, "text": "Literally, I can show you this coffee cup and I say, here's a new coffee cup."}, {"time": 5420, "text": "It's got the logo on it."}, {"time": 5421, "text": "Take a look at it, done, you're done."}, {"time": 5423, "text": "You can predict what it's gonna look like, you know, in different positions."}, {"time": 5427, "text": "So I can talk about that too."}, {"time": 5429, "text": "In the brain, the way learning occurs, I mentioned this earlier, but I'll mention it again."}, {"time": 5435, "text": "The way learning occurs, imagine I am a section of a dendrite of a neuron, and I'm gonna learn something new."}, {"time": 5443, "text": "Doesn't matter what it is."}, {"time": 5444, "text": "I'm just gonna learn something new."}, {"time": 5446, "text": "I need to recognize a new pattern."}, {"time": 5448, "text": "So what I'm gonna do is I'm gonna form new synapses."}, {"time": 5452, "text": "New synapses, we're gonna rewire the brain onto that section of the dendrite."}, {"time": 5457, "text": "Once I've done that, everything else that neuron has learned is not affected by it."}, {"time": 5462, "text": "That's because it's isolated to that small section of the dendrite."}, {"time": 5466, "text": "They're not all being added together, like a point neuron."}, {"time": 5469, "text": "So if I learn something new on this segment here, it doesn't change any of the learning that occur anywhere else in that neuron."}, {"time": 5474, "text": "So I can add something without affecting previous learning."}, {"time": 5478, "text": "And I can do it quickly."}, {"time": 5480, "text": "Now let's talk, we can talk about the quickness, how it's done in real neurons."}, {"time": 5484, "text": "You might say, well, doesn't it take time to form synapses?"}, {"time": 5486, "text": "Yes, it can take maybe an hour to form a new synapse."}, {"time": 5490, "text": "We can form memories quicker than that, and I can explain that how it happens too, if you want."}, {"time": 5495, "text": "But it's getting a bit neurosciencey."}, {"time": 5499, "text": "That's great, but is there an understanding of these mechanisms at every level?"}, {"time": 5503, "text": "So from the short term memories and the forming."}, {"time": 5508, "text": "So this idea of synaptogenesis, the growth of new synapses, that's well described, it's well understood."}, {"time": 5514, "text": "And that's an essential part of learning."}, {"time": 5515, "text": "That is learning."}, {"time": 5521, "text": "Going back many, many years, people, you know, it was, what's his name, the psychologist who proposed, Hebb, Donald Hebb."}, {"time": 5529, "text": "He proposed that learning was the modification of the strength of a connection between two neurons."}, {"time": 5535, "text": "People interpreted that as the modification of the strength of a synapse."}, {"time": 5539, "text": "He didn't say that."}, {"time": 5540, "text": "He just said there's a modification between the effect of one neuron and another."}, {"time": 5544, "text": "So synaptogenesis is totally consistent with what Donald Hebb said."}, {"time": 5548, "text": "But anyway, there's these mechanisms, the growth of new synapses."}, {"time": 5550, "text": "You can go online, you can watch a video of a synapse growing in real time."}, {"time": 5553, "text": "It's literally, you can see this little thing going boop."}, {"time": 5557, "text": "It's pretty impressive."}, {"time": 5558, "text": "So those mechanisms are known."}, {"time": 5559, "text": "Now there's another thing that we've speculated and we've written about, which is consistent with known neuroscience, but it's less proven."}, {"time": 5568, "text": "And this is the idea, how do I form a memory really, really quickly?"}, {"time": 5571, "text": "Like instantaneous."}, {"time": 5572, "text": "If it takes an hour to grow a synapse, like that's not instantaneous."}, {"time": 5576, "text": "So there are types of synapses called silent synapses."}, {"time": 5581, "text": "They look like a synapse, but they don't do anything."}, {"time": 5584, "text": "They're just sitting there."}, {"time": 5584, "text": "It's like if an action potential comes in, it doesn't release any neurotransmitter."}, {"time": 5590, "text": "Some parts of the brain have more of these than others."}, {"time": 5592, "text": "For example, the hippocampus has a lot of them, which is where we associate most short term memory with."}, {"time": 5598, "text": "So what we speculated, again, in that 2016 paper, we proposed that the way we form very quick memories, very short term memories, or quick memories, is that we convert silent synapses into active synapses."}, {"time": 5613, "text": "It's like saying a synapse has a zero weight and a one weight, but the longterm memory has to be formed by synaptogenesis."}, {"time": 5621, "text": "So you can remember something really quickly by just flipping a bunch of these guys from silent to active."}, {"time": 5626, "text": "It's not from 0.1 to 0.15."}, {"time": 5629, "text": "It's like, it doesn't do anything till it releases transmitter."}, {"time": 5632, "text": "And if I do that over a bunch of these, I've got a very quick short term memory."}, {"time": 5636, "text": "So I guess the lesson behind this is that most neural networks today are fully connected."}, {"time": 5641, "text": "Every neuron connects every other neuron from layer to layer."}, {"time": 5644, "text": "That's not correct in the brain."}, {"time": 5646, "text": "We don't want that."}, {"time": 5646, "text": "We actually don't want that."}, {"time": 5649, "text": "You want a very sparse connectivity so that any neuron connects to some subset of the neurons in the other layer."}, {"time": 5655, "text": "And it does so on a dendrite by dendrite segment basis."}, {"time": 5658, "text": "So it's a very some parcelated out type of thing."}, {"time": 5661, "text": "And that then learning is not adjusting all these weights, but learning is just saying, okay, connect to these 10 cells here right now."}, {"time": 5670, "text": "In that process, you know, with artificial neural networks, it's a very simple process of backpropagation that adjusts the weights."}, {"time": 5677, "text": "The process of synaptogenesis."}, {"time": 5682, "text": "It's even easier."}, {"time": 5684, "text": "Backpropagation requires something that really can't happen in brains."}, {"time": 5688, "text": "This backpropagation of this error signal, that really can't happen."}, {"time": 5692, "text": "People are trying to make it happen in brains, but it doesn't happen in brains."}, {"time": 5694, "text": "This is pure Hebbian learning."}, {"time": 5696, "text": "Well, synaptogenesis is pure Hebbian learning."}, {"time": 5698, "text": "It's basically saying, there's a population of cells over here that are active right now."}, {"time": 5703, "text": "And there's a population of cells over here active right now."}, {"time": 5705, "text": "How do I form connections between those active cells?"}, {"time": 5707, "text": "And it's literally saying this guy became active."}, {"time": 5711, "text": "These 100 neurons here became active before this neuron became active."}, {"time": 5715, "text": "So form connections to those ones."}, {"time": 5717, "text": "There's no propagation of error, nothing."}, {"time": 5719, "text": "All the networks we do, all the models we have work on almost completely on Hebbian learning, but on dendritic segments and multiple synapses at the same time."}, {"time": 5733, "text": "So now let's sort of turn the question that you already answered, and maybe you can answer it again."}, {"time": 5738, "text": "If you look at the history of artificial intelligence, where do you think we stand?"}, {"time": 5743, "text": "How far are we from solving intelligence?"}, {"time": 5745, "text": "You said you were very optimistic."}, {"time": 5747, "text": "Can you elaborate on that?"}, {"time": 5748, "text": "Yeah, it's always the crazy question to ask because no one can predict the future."}, {"time": 5755, "text": "So I'll tell you a story."}, {"time": 5758, "text": "I used to run a different neuroscience institute called the Redwood Neuroscience Institute, and we would hold these symposiums and we'd get like 35 scientists from around the world to come together."}, {"time": 5768, "text": "And I used to ask them all the same question."}, {"time": 5770, "text": "I would say, well, how long do you think it'll be before we understand how the neocortex works?"}, {"time": 5774, "text": "And everyone went around the room and they had introduced the name and they have to answer that question."}, {"time": 5778, "text": "So I got, the typical answer was 50 to 100 years."}, {"time": 5782, "text": "Some people would say 500 years."}, {"time": 5784, "text": "Some people said never."}, {"time": 5785, "text": "I said, why are you a neuroscientist?"}, {"time": 5787, "text": "It's never gonna, it's a good pay."}, {"time": 5794, "text": "So, you know, but it doesn't work like that."}, {"time": 5796, "text": "As I mentioned earlier, these are not, these are step functions."}, {"time": 5799, "text": "Things happen and then bingo, they happen."}, {"time": 5801, "text": "You can't predict that."}, {"time": 5803, "text": "I feel I've already passed a step function."}, {"time": 5805, "text": "So if I can do my job correctly over the next five years, then, meaning I can proselytize these ideas."}, {"time": 5813, "text": "I can convince other people they're right."}, {"time": 5816, "text": "We can show that other people, machine learning people should pay attention to these ideas."}, {"time": 5821, "text": "Then we're definitely in an under 20 year timeframe."}, {"time": 5824, "text": "If I can do those things, if I'm not successful in that, and this is the last time anyone talks to me and no one reads our papers and you know, and I'm wrong or something like that, then I don't know."}, {"time": 5835, "text": "But it's not 50 years."}, {"time": 5841, "text": "Think about electric cars."}, {"time": 5842, "text": "How quickly are they gonna populate the world?"}, {"time": 5844, "text": "It probably takes about a 20 year span."}, {"time": 5847, "text": "It'll be something like that."}, {"time": 5848, "text": "But I think if I can do what I said, we're starting it."}, {"time": 5851, "text": "And of course there could be other, you said step functions."}, {"time": 5855, "text": "It could be everybody gives up on your ideas for 20 years and then all of a sudden somebody picks it up again."}, {"time": 5862, "text": "Wait, that guy was onto something."}, {"time": 5863, "text": "Yeah, so that would be a failure on my part, right?"}, {"time": 5867, "text": "Think about Charles Babbage."}, {"time": 5869, "text": "Charles Babbage, he's the guy who invented the computer back in the 18 something, 1800s."}, {"time": 5875, "text": "And everyone forgot about it until 100 years later."}, {"time": 5879, "text": "And say, hey, this guy figured this stuff out a long time ago."}, {"time": 5882, "text": "But he was ahead of his time."}, {"time": 5883, "text": "I don't think, as I said, I recognize this is part of any entrepreneur's challenge."}, {"time": 5889, "text": "I use entrepreneur broadly in this case."}, {"time": 5891, "text": "I'm not meaning like I'm building a business or trying to sell something."}, {"time": 5893, "text": "I mean, I'm trying to sell ideas."}, {"time": 5895, "text": "And this is the challenge as to how you get people to pay attention to you, how do you get them to give you positive or negative feedback, how do you get the people to act differently based on your ideas."}, {"time": 5907, "text": "So we'll see how well we do on that."}, {"time": 5910, "text": "So you know that there's a lot of hype behind artificial intelligence currently."}, {"time": 5914, "text": "Do you, as you look to spread the ideas that are of neocortical theory, the things you're working on, do you think there's some possibility we'll hit an AI winter once again?"}, {"time": 5927, "text": "Yeah, it's certainly a possibility."}, {"time": 5928, "text": "No question about it."}, {"time": 5929, "text": "Is that something you worry about?"}, {"time": 5930, "text": "Yeah, well, I guess, do I worry about it?"}, {"time": 5934, "text": "I haven't decided yet if that's good or bad for my mission."}, {"time": 5937, "text": "That's true, that's very true."}, {"time": 5939, "text": "Because it's almost like you need the winter to refresh the palette."}, {"time": 5944, "text": "Yeah, it's like, I want, here's what you wanna have it is."}, {"time": 5947, "text": "You want, like to the extent that everyone is so thrilled about the current state of machine learning and AI and they don't imagine they need anything else, it makes my job harder."}, {"time": 5959, "text": "If everything crashed completely and every student left the field and there was no money for anybody to do anything and it became an embarrassment to talk about machine intelligence and AI, that wouldn't be good for us either."}, {"time": 5970, "text": "You want sort of the soft landing approach, right?"}, {"time": 5973, "text": "You want enough people, the senior people in AI and machine learning to say, you know, we need other approaches."}, {"time": 5978, "text": "We really need other approaches."}, {"time": 5980, "text": "Damn, we need other approaches."}, {"time": 5982, "text": "Maybe we should look to the brain."}, {"time": 5983, "text": "Okay, let's look to the brain."}, {"time": 5984, "text": "Who's got some brain ideas?"}, {"time": 5985, "text": "Okay, let's start a little project on the side here trying to do brain idea related stuff."}, {"time": 5989, "text": "That's the ideal outcome we would want."}, {"time": 5991, "text": "So I don't want a total winter and yet I don't want it to be sunny all the time either."}, {"time": 5997, "text": "So what do you think it takes to build a system with human level intelligence where once demonstrated you would be very impressed?"}, {"time": 6006, "text": "So does it have to have a body?"}, {"time": 6008, "text": "Does it have to have the C word we used before, consciousness as an entirety in a holistic sense?"}, {"time": 6019, "text": "First of all, I don't think the goal is to create a machine that is human level intelligence."}, {"time": 6023, "text": "I think it's a false goal."}, {"time": 6024, "text": "Back to Turing, I think it was a false statement."}, {"time": 6027, "text": "We want to understand what intelligence is and then we can build intelligent machines of all different scales, all different capabilities."}, {"time": 6034, "text": "A dog is intelligent."}, {"time": 6035, "text": "I don't need, that'd be pretty good to have a dog."}, {"time": 6038, "text": "But what about something that doesn't look like an animal at all, in different spaces?"}, {"time": 6041, "text": "So my thinking about this is that we want to define what intelligence is, agree upon what makes an intelligent system."}, {"time": 6048, "text": "We can then say, okay, we're now gonna build systems that work on those principles or some subset of them and we can apply them to all different types of problems."}, {"time": 6057, "text": "And the kind, the idea, it's not computing."}, {"time": 6060, "text": "We don't ask, if I take a little one chip computer, I don't say, well, that's not a computer because it's not as powerful as this big server over here."}, {"time": 6069, "text": "No, no, because we know that what the principles of computing are and I can apply those principles to a small problem or into a big problem."}, {"time": 6074, "text": "And same, intelligence needs to get there."}, {"time": 6076, "text": "We have to say, these are the principles."}, {"time": 6077, "text": "I can make a small one, a big one."}, {"time": 6079, "text": "I can make them distributed."}, {"time": 6079, "text": "I can put them on different sensors."}, {"time": 6081, "text": "They don't have to be human like at all."}, {"time": 6083, "text": "Now, you did bring up a very interesting question about embodiment."}, {"time": 6085, "text": "Does it have to have a body?"}, {"time": 6087, "text": "It has to have some concept of movement."}, {"time": 6090, "text": "It has to be able to move through these reference frames I talked about earlier."}, {"time": 6094, "text": "Whether it's physically moving, like I need, if I'm gonna have an AI that understands coffee cups, it's gonna have to pick up the coffee cup and touch it and look at it with its eyes and hands or something equivalent to that."}, {"time": 6105, "text": "If I have a mathematical AI, maybe it needs to move through mathematical spaces."}, {"time": 6111, "text": "I could have a virtual AI that lives in the internet and its movements are traversing links and digging into files, but it's got a location that it's traveling through some space."}, {"time": 6124, "text": "You can't have an AI that just take some flash thing input."}, {"time": 6129, "text": "We call it flash inference."}, {"time": 6130, "text": "Here's a pattern, done."}, {"time": 6132, "text": "No, it's movement pattern, movement pattern, movement pattern, attention, digging, building structure, figuring out the model of the world."}, {"time": 6140, "text": "So some sort of embodiment, whether it's physical or not, has to be part of it."}, {"time": 6145, "text": "So self awareness and the way to be able to answer where am I?"}, {"time": 6148, "text": "Well, you're bringing up self, that's a different topic, self awareness."}, {"time": 6151, "text": "No, the very narrow definition of self, meaning knowing a sense of self enough to know where am I in the space where it's actually."}, {"time": 6159, "text": "Yeah, basically the system needs to know its location or each component of the system needs to know where it is in the world at that point in time."}, {"time": 6168, "text": "So self awareness and consciousness."}, {"time": 6171, "text": "Do you think one, from the perspective of neuroscience and neurocortex, these are interesting topics, solvable topics."}, {"time": 6179, "text": "Do you have any ideas of why the heck it is that we have a subjective experience at all?"}, {"time": 6184, "text": "Yeah, I have a lot of thoughts on that."}, {"time": 6185, "text": "And is it useful or is it just a side effect of us?"}, {"time": 6188, "text": "It's interesting to think about."}, {"time": 6190, "text": "I don't think it's useful as a means to figure out how to build intelligent machines."}, {"time": 6196, "text": "It's something that systems do and we can talk about what it is that are like, well, if I build a system like this, then it would be self aware."}, {"time": 6205, "text": "Or if I build it like this, it wouldn't be self aware."}, {"time": 6208, "text": "So that's a choice I can have."}, {"time": 6210, "text": "It's not like, oh my God, it's self aware."}, {"time": 6212, "text": "I can't turn, I heard an interview recently with this philosopher from Yale, I can't remember his name, I apologize for that."}, {"time": 6219, "text": "But he was talking about, well, if these computers are self aware, then it would be a crime to unplug them."}, {"time": 6222, "text": "And I'm like, oh, come on, that's not, I unplug myself every night, I go to sleep."}, {"time": 6227, "text": "Is that a crime?"}, {"time": 6228, "text": "I plug myself in again in the morning and there I am."}, {"time": 6231, "text": "So people get kind of bent out of shape about this."}, {"time": 6236, "text": "I have very definite, very detailed understanding or opinions about what it means to be conscious and what it means to be self aware."}, {"time": 6244, "text": "I don't think it's that interesting a problem."}, {"time": 6246, "text": "You've talked to Christoph Koch."}, {"time": 6248, "text": "He thinks that's the only problem."}, {"time": 6250, "text": "I didn't actually listen to your interview with him, but I know him and I know that's the thing he cares about."}, {"time": 6255, "text": "He also thinks intelligence and consciousness are disjoint."}, {"time": 6258, "text": "So I mean, it's not, you don't have to have one or the other."}, {"time": 6261, "text": "So he is."}, {"time": 6261, "text": "I disagree with that."}, {"time": 6262, "text": "I just totally disagree with that."}, {"time": 6264, "text": "So where's your thoughts and consciousness, where does it emerge from?"}, {"time": 6267, "text": "Because it is."}, {"time": 6268, "text": "So then we have to break it down to the two parts, okay?"}, {"time": 6270, "text": "Because consciousness isn't one thing."}, {"time": 6272, "text": "That's part of the problem with that term is it means different things to different people and there's different components of it."}, {"time": 6277, "text": "There is a concept of self awareness, okay?"}, {"time": 6280, "text": "That can be very easily explained."}, {"time": 6283, "text": "You have a model of your own body."}, {"time": 6286, "text": "The neocortex models things in the world and it also models your own body."}, {"time": 6290, "text": "And then it has a memory."}, {"time": 6293, "text": "It can remember what you've done, okay?"}, {"time": 6295, "text": "So it can remember what you did this morning, can remember what you had for breakfast and so on."}, {"time": 6299, "text": "And so I can say to you, okay, Lex, were you conscious this morning when you had your bagel?"}, {"time": 6306, "text": "And you'd say, yes, I was conscious."}, {"time": 6308, "text": "Now what if I could take your brain and revert all the synapses back to the state they were this morning?"}, {"time": 6314, "text": "And then I said to you, Lex, were you conscious when you ate the bagel?"}, {"time": 6317, "text": "And you said, no, I wasn't conscious."}, {"time": 6318, "text": "I said, here's a video of eating the bagel."}, {"time": 6319, "text": "And you said, I wasn't there."}, {"time": 6322, "text": "That's not possible because I must've been unconscious at that time."}, {"time": 6325, "text": "So we can just make this one to one correlation between memory of your body's trajectory through the world over some period of time, a memory and the ability to recall that memory is what you would call conscious."}, {"time": 6335, "text": "I was conscious of that, it's a self awareness."}, {"time": 6338, "text": "And any system that can recall, memorize what it's done recently and bring that back and invoke it again would say, yeah, I'm aware."}, {"time": 6348, "text": "I remember what I did."}, {"time": 6349, "text": "All right, I got it."}, {"time": 6351, "text": "That's an easy one."}, {"time": 6352, "text": "Although some people think that's a hard one."}, {"time": 6354, "text": "The more challenging part of consciousness is this one that's sometimes used going by the word of qualia, which is, why does an object seem red?"}, {"time": 6364, "text": "Or what is pain?"}, {"time": 6366, "text": "And why does pain feel like something?"}, {"time": 6368, "text": "Why do I feel redness?"}, {"time": 6370, "text": "Or why do I feel painness?"}, {"time": 6372, "text": "And then I could say, well, why does sight seems different than hearing?"}, {"time": 6375, "text": "It's the same problem."}, {"time": 6376, "text": "It's really, these are all just neurons."}, {"time": 6378, "text": "And so how is it that, why does looking at you feel different than hearing you?"}, {"time": 6384, "text": "It feels different, but there's just neurons in my head."}, {"time": 6386, "text": "They're all doing the same thing."}, {"time": 6387, "text": "So that's an interesting question."}, {"time": 6389, "text": "The best treatise I've read about this is by a guy named Oregon."}, {"time": 6393, "text": "He wrote a book called, Why Red Doesn't Sound Like a Bell."}, {"time": 6397, "text": "It's a little, it's not a trade book, easy to read, but it, and it's an interesting question."}, {"time": 6406, "text": "Take something like color."}, {"time": 6407, "text": "Color really doesn't exist in the world."}, {"time": 6409, "text": "It's not a property of the world."}, {"time": 6411, "text": "Property of the world that exists is light frequency."}, {"time": 6414, "text": "And that gets turned into, we have certain cells in the retina that respond to different frequencies different than others."}, {"time": 6420, "text": "And so when they enter the brain, you just have a bunch of axons that are firing at different rates."}, {"time": 6424, "text": "And from that, we perceive color."}, {"time": 6426, "text": "But there is no color in the brain."}, {"time": 6427, "text": "I mean, there's no color coming in on those synapses."}, {"time": 6430, "text": "It's just a correlation between some axons and some property of frequency."}, {"time": 6437, "text": "And that isn't even color itself."}, {"time": 6438, "text": "Frequency doesn't have a color."}, {"time": 6440, "text": "It's just what it is."}, {"time": 6442, "text": "So then the question is, well, why does it even appear to have a color at all?"}, {"time": 6447, "text": "Just as you're describing it, there seems to be a connection to those ideas of reference frames."}, {"time": 6452, "text": "I mean, it just feels like consciousness having the subject, assigning the feeling of red to the actual color or to the wavelength is useful for intelligence."}, {"time": 6467, "text": "Yeah, I think that's a good way of putting it."}, {"time": 6469, "text": "It's useful as a predictive mechanism or useful as a generalization idea."}, {"time": 6473, "text": "It's a way of grouping things together to say, it's useful to have a model like this."}, {"time": 6477, "text": "So think about the well known syndrome that people who've lost a limb experience called phantom limbs."}, {"time": 6486, "text": "And what they claim is they can have their arm is removed, but they feel their arm."}, {"time": 6493, "text": "That not only feel it, they know it's there."}, {"time": 6495, "text": "It's there, I know it's there."}, {"time": 6497, "text": "They'll swear to you that it's there."}, {"time": 6499, "text": "And then they can feel pain in their arm and they'll feel pain in their finger."}, {"time": 6501, "text": "And if they move their non existent arm behind their back, then they feel the pain behind their back."}, {"time": 6507, "text": "So this whole idea that your arm exists is a model of your brain."}, {"time": 6511, "text": "It may or may not really exist."}, {"time": 6514, "text": "And just like, but it's useful to have a model of something that sort of correlates to things in the world."}, {"time": 6520, "text": "So you can make predictions about what would happen when those things occur."}, {"time": 6523, "text": "It's a little bit of a fuzzy, but I think you're getting quite towards the answer there."}, {"time": 6526, "text": "It's useful for the model to express things certain ways that we can then map them into these reference frames and make predictions about them."}, {"time": 6535, "text": "I need to spend more time on this topic."}, {"time": 6537, "text": "It doesn't bother me."}, {"time": 6538, "text": "Do you really need to spend more time?"}, {"time": 6541, "text": "It does feel special that we have subjective experience, but I'm yet to know why."}, {"time": 6547, "text": "I'm just personally curious."}, {"time": 6549, "text": "It's not necessary for the work we're doing here."}, {"time": 6551, "text": "I don't think I need to solve that problem to build intelligent machines at all, not at all."}, {"time": 6555, "text": "But there is sort of the silly notion that you described briefly that doesn't seem so silly to us humans is, if you're successful building intelligent machines, it feels wrong to then turn them off."}, {"time": 6570, "text": "Because if you're able to build a lot of them, it feels wrong to then be able to turn off the... Well, why?"}, {"time": 6579, "text": "Let's break that down a bit."}, {"time": 6581, "text": "As humans, why do we fear death?"}, {"time": 6583, "text": "There's two reasons we fear death."}, {"time": 6587, "text": "Well, first of all, I'll say, when you're dead, it doesn't matter at all."}, {"time": 6590, "text": "So why do we fear death?"}, {"time": 6591, "text": "We fear death for two reasons."}, {"time": 6593, "text": "One is because we are programmed genetically to fear death."}, {"time": 6597, "text": "That's a survival and pop beginning of the genes thing."}, {"time": 6602, "text": "And we also are programmed to feel sad when people we know die."}, {"time": 6606, "text": "We don't feel sad for someone we don't know dies."}, {"time": 6608, "text": "There's people dying right now, they're only just gonna say, I don't feel bad about them, because I don't know them."}, {"time": 6612, "text": "But if I knew them, I'd feel really bad."}, {"time": 6613, "text": "So again, these are old brain, genetically embedded things that we fear death."}, {"time": 6619, "text": "It's outside of those uncomfortable feelings."}, {"time": 6624, "text": "There's nothing else to worry about."}, {"time": 6625, "text": "Well, wait, hold on a second."}, {"time": 6627, "text": "Do you know the denial of death by Becker?"}, {"time": 6631, "text": "There's a thought that death is, our whole conception of our world model kind of assumes immortality."}, {"time": 6643, "text": "And then death is this terror that underlies it all."}, {"time": 6647, "text": "Some people's world model, not mine."}, {"time": 6650, "text": "But, okay, so what Becker would say is that you're just living in an illusion."}, {"time": 6654, "text": "You've constructed an illusion for yourself because it's such a terrible terror, the fact that this... What's the illusion?"}, {"time": 6661, "text": "The illusion that death doesn't matter."}, {"time": 6662, "text": "You're still not coming to grips with..."}, {"time": 6664, "text": "The illusion of what?"}, {"time": 6665, "text": "That death is..."}, {"time": 6667, "text": "Going to happen."}, {"time": 6668, "text": "Oh, like it's not gonna happen?"}, {"time": 6670, "text": "You're actually operating."}, {"time": 6671, "text": "You haven't, even though you said you've accepted it, you haven't really accepted the notion that you're gonna die is what you say."}, {"time": 6676, "text": "So it sounds like you disagree with that notion."}, {"time": 6681, "text": "Yeah, yeah, totally."}, {"time": 6682, "text": "I literally, every night I go to bed, it's like dying."}, {"time": 6688, "text": "Like little deaths."}, {"time": 6688, "text": "It's little deaths."}, {"time": 6689, "text": "And if I didn't wake up, it wouldn't matter to me."}, {"time": 6692, "text": "Only if I knew that was gonna happen would it be bothersome."}, {"time": 6695, "text": "If I didn't know it was gonna happen, how would I know?"}, {"time": 6697, "text": "Then I would worry about my wife."}, {"time": 6699, "text": "So imagine I was a loner and I lived in Alaska and I lived out there and there was no animals."}, {"time": 6705, "text": "Nobody knew I existed."}, {"time": 6706, "text": "I was just eating these roots all the time."}, {"time": 6708, "text": "And nobody knew I was there."}, {"time": 6711, "text": "And one day I didn't wake up."}, {"time": 6714, "text": "What pain in the world would there exist?"}, {"time": 6717, "text": "Well, so most people that think about this problem would say that you're just deeply enlightened or are completely delusional."}, {"time": 6724, "text": "One of the two."}, {"time": 6725, "text": "But I would say that's a very enlightened way to see the world."}, {"time": 6733, "text": "That's the rational one as well."}, {"time": 6734, "text": "It's rational, that's right."}, {"time": 6735, "text": "But the fact is we don't, I mean, we really don't have an understanding of why the heck it is we're born and why we die and what happens after we die."}, {"time": 6745, "text": "Well, maybe there isn't a reason, maybe there is."}, {"time": 6747, "text": "So I'm interested in those big problems too, right?"}, {"time": 6750, "text": "You interviewed Max Tegmark, and there's people like that, right?"}, {"time": 6753, "text": "I'm interested in those big problems as well."}, {"time": 6755, "text": "And in fact, when I was young, I made a list of the biggest problems I could think of."}, {"time": 6761, "text": "First, why does anything exist?"}, {"time": 6763, "text": "Second, why do we have the laws of physics that we have?"}, {"time": 6766, "text": "Third, is life inevitable?"}, {"time": 6769, "text": "And why is it here?"}, {"time": 6770, "text": "Fourth, is intelligence inevitable?"}, {"time": 6773, "text": "I stopped there because I figured if you can make a truly intelligent system, that will be the quickest way to answer the first three questions."}, {"time": 6784, "text": "And so I said, my mission, you asked me earlier, my first mission is to understand the brain, but I felt that is the shortest way to get to true machine intelligence."}, {"time": 6792, "text": "And I wanna get to true machine intelligence because even if it doesn't occur in my lifetime, other people will benefit from it because I think it'll occur in my lifetime, but 20 years, you never know."}, {"time": 6803, "text": "But that will be the quickest way for us to, we can make super mathematicians, we can make super space explorers, we can make super physicist brains that do these things and that can run experiments that we can't run."}, {"time": 6817, "text": "We don't have the abilities to manipulate things and so on, but we can build intelligent machines that do all those things with the ultimate goal of finding out the answers to the other questions."}, {"time": 6828, "text": "Let me ask you another depressing and difficult question, which is once we achieve that goal of creating, no, of understanding intelligence, do you think we would be happier, more fulfilled as a species?"}, {"time": 6844, "text": "The understanding intelligence or understanding the answers to the big questions?"}, {"time": 6847, "text": "Understanding intelligence."}, {"time": 6848, "text": "Oh, totally, totally."}, {"time": 6851, "text": "It would be far more fun place to live."}, {"time": 6854, "text": "Oh yeah, why not?"}, {"time": 6855, "text": "I mean, just put aside this terminator nonsense and just think about, you can think about, we can talk about the risks of AI if you want."}, {"time": 6866, "text": "I'd love to, so let's talk about."}, {"time": 6868, "text": "But I think the world would be far better knowing things."}, {"time": 6870, "text": "We're always better than know things."}, {"time": 6872, "text": "Do you think it's better, is it a better place to live in that I know that our planet is one of many in the solar system and the solar system's one of many in the galaxy?"}, {"time": 6880, "text": "I think it's a more, I dread, I sometimes think like, God, what would it be like to live 300 years ago?"}, {"time": 6885, "text": "I'd be looking up at the sky, I can't understand anything."}, {"time": 6887, "text": "Oh my God, I'd be like going to bed every night going, what's going on here?"}, {"time": 6890, "text": "Well, I mean, in some sense I agree with you, but I'm not exactly sure."}, {"time": 6894, "text": "So I'm also a scientist, so I share your views, but I'm not, we're like rolling down the hill together."}, {"time": 6902, "text": "What's down the hill?"}, {"time": 6903, "text": "I feel like we're climbing a hill."}, {"time": 6906, "text": "We're getting closer to enlightenment and you're going down the hill."}, {"time": 6910, "text": "We're climbing, we're getting pulled up a hill by our curiosity."}, {"time": 6913, "text": "Our curiosity is, we're pulling ourselves up the hill by our curiosity."}, {"time": 6916, "text": "Yeah, Sisyphus was doing the same thing with the rock."}, {"time": 6919, "text": "Yeah, yeah, yeah, yeah."}, {"time": 6920, "text": "But okay, our happiness aside, do you have concerns about, you talk about Sam Harris, Elon Musk, of existential threats of intelligent systems?"}, {"time": 6931, "text": "No, I'm not worried about existential threats at all."}, {"time": 6933, "text": "There are some things we really do need to worry about."}, {"time": 6936, "text": "Even today's AI, we have things we have to worry about."}, {"time": 6938, "text": "We have to worry about privacy and about how it impacts false beliefs in the world."}, {"time": 6942, "text": "And we have real problems and things to worry about with today's AI."}, {"time": 6948, "text": "And that will continue as we create more intelligent systems."}, {"time": 6951, "text": "There's no question, the whole issue about making intelligent armaments and weapons is something that really we have to think about carefully."}, {"time": 6959, "text": "I don't think of those as existential threats."}, {"time": 6961, "text": "I think those are the kind of threats we always face and we'll have to face them here and we'll have to deal with them."}, {"time": 6970, "text": "We could talk about what people think are the existential threats, but when I hear people talking about them, they all sound hollow to me."}, {"time": 6977, "text": "They're based on ideas, they're based on people who really have no idea what intelligence is."}, {"time": 6982, "text": "And if they knew what intelligence was, they wouldn't say those things."}, {"time": 6986, "text": "So those are not experts in the field."}, {"time": 6988, "text": "Yeah, so there's two, right?"}, {"time": 6992, "text": "So one is like super intelligence."}, {"time": 6993, "text": "So a system that becomes far, far superior in reasoning ability than us humans."}, {"time": 7003, "text": "How is that an existential threat?"}, {"time": 7006, "text": "Then, so there's a lot of ways in which it could be."}, {"time": 7009, "text": "One way is us humans are actually irrational, inefficient and get in the way of, not happiness, but whatever the objective function is of maximizing that objective function."}, {"time": 7024, "text": "Super intelligent."}, {"time": 7025, "text": "The paperclip problem and things like that."}, {"time": 7026, "text": "So the paperclip problem but with the super intelligent."}, {"time": 7030, "text": "So we already face this threat in some sense."}, {"time": 7035, "text": "They're called bacteria."}, {"time": 7037, "text": "These are organisms in the world that would like to turn everything into bacteria."}, {"time": 7041, "text": "And they're constantly morphing, they're constantly changing to evade our protections."}, {"time": 7046, "text": "And in the past, they have killed huge swaths of populations of humans on this planet."}, {"time": 7053, "text": "So if you wanna worry about something that's gonna multiply endlessly, we have it."}, {"time": 7058, "text": "And I'm far more worried in that regard."}, {"time": 7060, "text": "I'm far more worried that some scientists in the laboratory will create a super virus or a super bacteria that we cannot control."}, {"time": 7067, "text": "That is a more of an existential threat."}, {"time": 7069, "text": "Putting an intelligence thing on top of it actually seems to make it less existential to me."}, {"time": 7074, "text": "It's like, it limits its power."}, {"time": 7076, "text": "It limits where it can go."}, {"time": 7077, "text": "It limits the number of things it can do in many ways."}, {"time": 7079, "text": "A bacteria is something you can't even see."}, {"time": 7083, "text": "So that's only one of those problems."}, {"time": 7085, "text": "So the other one, just in your intuition about intelligence, when you think about intelligence of us humans, do you think of that as something, if you look at intelligence on a spectrum from zero to us humans, do you think you can scale that to something far, far superior to all the mechanisms we've been talking about?"}, {"time": 7104, "text": "I wanna make another point here, Lex, before I get there."}, {"time": 7108, "text": "Intelligence is the neocortex."}, {"time": 7110, "text": "It is not the entire brain."}, {"time": 7114, "text": "The goal is not to make a human."}, {"time": 7116, "text": "The goal is not to make an emotional system."}, {"time": 7118, "text": "The goal is not to make a system that wants to have sex and reproduce."}, {"time": 7121, "text": "Why would I build that?"}, {"time": 7122, "text": "If I wanna have a system that wants to reproduce and have sex, make bacteria, make computer viruses."}, {"time": 7127, "text": "Those are bad things, don't do that."}, {"time": 7129, "text": "Those are really bad, don't do those things."}, {"time": 7132, "text": "Regulate those."}, {"time": 7133, "text": "But if I just say I want an intelligent system, why does it have to have any of the human like emotions?"}, {"time": 7138, "text": "Why does it even care if it lives?"}, {"time": 7140, "text": "Why does it even care if it has food?"}, {"time": 7142, "text": "It doesn't care about those things."}, {"time": 7143, "text": "It's just, you know, it's just in a trance thinking about mathematics or it's out there just trying to build the space for it on Mars."}, {"time": 7154, "text": "That's a choice we make."}, {"time": 7155, "text": "Don't make human like things, don't make replicating things, don't make things that have emotions, just stick to the neocortex."}, {"time": 7161, "text": "So that's a view actually that I share but not everybody shares in the sense that you have faith and optimism about us as engineers of systems, humans as builders of systems to not put in stupid, not."}, {"time": 7174, "text": "So this is why I mentioned the bacteria one."}, {"time": 7177, "text": "Because you might say, well, some person's gonna do that."}, {"time": 7180, "text": "Well, some person today could create a bacteria that's resistant to all the known antibacterial agents."}, {"time": 7186, "text": "So we already have that threat."}, {"time": 7189, "text": "We already know this is going on."}, {"time": 7191, "text": "It's not a new threat."}, {"time": 7192, "text": "So just accept that and then we have to deal with it, right?"}, {"time": 7196, "text": "Yeah, so my point is nothing to do with intelligence."}, {"time": 7199, "text": "Intelligence is a separate component that you might apply to a system that wants to reproduce and do stupid things."}, {"time": 7206, "text": "Let's not do that."}, {"time": 7207, "text": "Yeah, in fact, it is a mystery why people haven't done that yet."}, {"time": 7210, "text": "My dad is a physicist, believes that the reason, he says, for example, nuclear weapons haven't proliferated amongst evil people."}, {"time": 7219, "text": "So one belief that I share is that there's not that many evil people in the world that would use, whether it's bacteria or nuclear weapons or maybe the future AI systems to do bad."}, {"time": 7235, "text": "So the fraction is small."}, {"time": 7236, "text": "And the second is that it's actually really hard, technically, so the intersection between evil and competent is small in terms of, and that's the."}, {"time": 7245, "text": "And by the way, to really annihilate humanity, you'd have to have sort of the nuclear winter phenomenon, which is not one person shooting or even 10 bombs."}, {"time": 7254, "text": "You'd have to have some automated system that detonates a million bombs or whatever many thousands we have."}, {"time": 7260, "text": "So extreme evil combined with extreme competence."}, {"time": 7263, "text": "And to start with building some stupid system that would automatically, Dr. Strangelove type of thing, you know, I mean, look, we could have some nuclear bomb go off in some major city in the world."}, {"time": 7274, "text": "I think that's actually quite likely, even in my lifetime."}, {"time": 7277, "text": "I don't think that's an unlikely thing."}, {"time": 7278, "text": "And it'd be a tragedy."}, {"time": 7280, "text": "But it won't be an existential threat."}, {"time": 7283, "text": "And it's the same as, you know, the virus of 1917, whatever it was, you know, the influenza."}, {"time": 7290, "text": "These bad things can happen and the plague and so on."}, {"time": 7293, "text": "We can't always prevent them."}, {"time": 7295, "text": "We always try, but we can't."}, {"time": 7297, "text": "But they're not existential threats until we combine all those crazy things together."}, {"time": 7301, "text": "So on the spectrum of intelligence from zero to human, do you have a sense of whether it's possible to create several orders of magnitude or at least double that of human intelligence?"}, {"time": 7314, "text": "Talking about neuro context."}, {"time": 7315, "text": "I think it's the wrong thing to say double the intelligence."}, {"time": 7319, "text": "Break it down into different components."}, {"time": 7321, "text": "Can I make something that's a million times fast than a human brain?"}, {"time": 7324, "text": "Yes, I can do that."}, {"time": 7326, "text": "Could I make something that is, has a lot more storage than the human brain?"}, {"time": 7330, "text": "Yes, I could do that."}, {"time": 7331, "text": "More common, more copies of common."}, {"time": 7333, "text": "Can I make something that attaches to different sensors than human brain?"}, {"time": 7337, "text": "Could I make something that's distributed?"}, {"time": 7339, "text": "So these people, yeah, we talked early about the departure of the neocortex voting."}, {"time": 7343, "text": "They don't have to be co located."}, {"time": 7344, "text": "Like, you know, they can be all around the place."}, {"time": 7345, "text": "I could do that too."}, {"time": 7349, "text": "Those are the levers I have, but is it more intelligent?"}, {"time": 7352, "text": "Well, it depends what I train it on."}, {"time": 7353, "text": "What is it doing?"}, {"time": 7354, "text": "If it's."}, {"time": 7355, "text": "Well, so here's the thing."}, {"time": 7356, "text": "So let's say larger neocortex and or whatever size that allows for higher and higher hierarchies to form, we're talking about reference frames and concepts."}, {"time": 7370, "text": "Could I have something that's a super physicist or a super mathematician?"}, {"time": 7373, "text": "And the question is, once you have a super physicist, will they be able to understand something?"}, {"time": 7380, "text": "Do you have a sense that it will be orders of math, like us compared to ants?"}, {"time": 7383, "text": "Could we ever understand it?"}, {"time": 7386, "text": "Most people cannot understand general relativity."}, {"time": 7391, "text": "It's a really hard thing to get."}, {"time": 7393, "text": "I mean, yeah, you can paint it in a fuzzy picture, stretchy space, you know?"}, {"time": 7397, "text": "But the field equations to do that and the deep intuitions are really, really hard."}, {"time": 7403, "text": "And I've tried, I'm unable to do it."}, {"time": 7405, "text": "Like it's easy to get special relativity, but general relativity, man, that's too much."}, {"time": 7412, "text": "And so we already live with this to some extent."}, {"time": 7414, "text": "The vast majority of people can't understand actually what the vast majority of other people actually know."}, {"time": 7420, "text": "We're just, either we don't have the effort to, or we can't, or we don't have time, or just not smart enough, whatever."}, {"time": 7426, "text": "But we have ways of communicating."}, {"time": 7428, "text": "Einstein has spoken in a way that I can understand."}, {"time": 7431, "text": "He's given me analogies that are useful."}, {"time": 7434, "text": "I can use those analogies from my own work and think about concepts that are similar."}, {"time": 7441, "text": "It's not stupid."}, {"time": 7442, "text": "It's not like he's existing some other plane and there's no connection with my plane in the world here."}, {"time": 7446, "text": "So that will occur."}, {"time": 7447, "text": "It already has occurred."}, {"time": 7449, "text": "That's what my point of this story is."}, {"time": 7451, "text": "We live it every day."}, {"time": 7454, "text": "One could argue that when we create machine intelligence that think a million times faster than us that it'll be so far we can't make the connections."}, {"time": 7460, "text": "But you know, at the moment, everything that seems really, really hard to figure out in the world, when you actually figure it out, it's not that hard."}, {"time": 7469, "text": "You know, almost everyone can understand the multiverses."}, {"time": 7472, "text": "Almost everyone can understand quantum physics."}, {"time": 7474, "text": "Almost everyone can understand these basic things, even though hardly any people could figure those things out."}, {"time": 7479, "text": "Yeah, but really understand."}, {"time": 7481, "text": "But you don't need to really."}, {"time": 7482, "text": "Only a few people really understand."}, {"time": 7483, "text": "You need to only understand the projections, the sprinkles of the useful insights from that."}, {"time": 7490, "text": "That was my example of Einstein, right?"}, {"time": 7491, "text": "His general theory of relativity is one thing that very, very, very few people can get."}, {"time": 7496, "text": "And what if we just said those other few people are also artificial intelligences?"}, {"time": 7500, "text": "How bad is that?"}, {"time": 7501, "text": "In some sense they are, right?"}, {"time": 7502, "text": "Yeah, they say already."}, {"time": 7504, "text": "I mean, Einstein wasn't a really normal person."}, {"time": 7506, "text": "He had a lot of weird quirks."}, {"time": 7507, "text": "And so did the other people who worked with him."}, {"time": 7509, "text": "So, you know, maybe they already were sort of this astral plane of intelligence that, we live with it already."}, {"time": 7515, "text": "It's not a problem."}, {"time": 7517, "text": "It's still useful and, you know."}, {"time": 7520, "text": "So do you think we are the only intelligent life out there in the universe?"}, {"time": 7524, "text": "I would say that intelligent life has and will exist elsewhere in the universe."}, {"time": 7529, "text": "I'll say that."}, {"time": 7531, "text": "There was a question about contemporaneous intelligence life, which is hard to even answer when we think about relativity and the nature of space time."}, {"time": 7539, "text": "Can't say what exactly is this time someplace else in the world."}, {"time": 7543, "text": "But I think it's, you know, I do worry a lot about the filter idea, which is that perhaps intelligent species don't last very long."}, {"time": 7554, "text": "And so we haven't been around very long."}, {"time": 7555, "text": "And as a technological species, we've been around for almost nothing, you know."}, {"time": 7559, "text": "What, 200 years, something like that."}, {"time": 7562, "text": "And we don't have any data, a good data point on whether it's likely that we'll survive or not."}, {"time": 7568, "text": "So do I think that there have been intelligent life elsewhere in the universe?"}, {"time": 7571, "text": "Almost certainly, of course."}, {"time": 7573, "text": "In the past, in the future, yes."}, {"time": 7576, "text": "Does it survive for a long time?"}, {"time": 7578, "text": "This is another reason I'm excited about our work, is our work meaning the general world of AI."}, {"time": 7584, "text": "I think we can build intelligent machines that outlast us."}, {"time": 7592, "text": "You know, they don't have to be tied to Earth."}]}, {"title": "David Ferrucci: IBM Watson, Jeopardy & Deep Conversations with AI | Lex Fridman Podcast #44", "id": "Whtt2H5_isM", "quotes": [{"time": 405, "text": "Of course, humans capable of doing both."}, {"time": 408, "text": "They do sort of one more naturally than they do the other, but they're capable of doing both."}, {"time": 413, "text": "You're saying they do the one that responds quickly more naturally."}, {"time": 417, "text": "Because that's the thing we kind of need to not be eaten by the predators in the world."}, {"time": 422, "text": "For example, but then we've learned to reason through logic, we've developed science, we train people to do that."}, {"time": 433, "text": "I think that's harder for the individual to do."}, {"time": 436, "text": "I think it requires training and teaching."}, {"time": 440, "text": "I think we are, the human mind certainly is capable of it, but we find it more difficult."}, {"time": 445, "text": "And then there are other weaknesses, if you will, as you mentioned earlier, just memory capacity and how many chains of inference can you actually go through without like losing your way?"}, {"time": 457, "text": "So just focus and..."}, {"time": 460, "text": "So the way you think about intelligence, and we're really sort of floating in this philosophical space, but I think you're like the perfect person to talk about this, because we'll get to Jeopardy and beyond."}, {"time": 475, "text": "That's like one of the most incredible accomplishments in AI, in the history of AI, but hence the philosophical discussion."}, {"time": 483, "text": "So let me ask, you've kind of alluded to it, but let me ask again, what is intelligence?"}, {"time": 489, "text": "Underlying the discussions we'll have with Jeopardy and beyond, how do you think about intelligence?"}, {"time": 497, "text": "Is it a sufficiently complicated problem being able to reason your way through solving that problem?"}, {"time": 502, "text": "Is that kind of how you think about what it means to be intelligent?"}, {"time": 505, "text": "So I think of intelligence primarily two ways."}, {"time": 509, "text": "One is the ability to predict."}, {"time": 513, "text": "So in other words, if I have a problem, can I predict what's gonna happen next?"}, {"time": 517, "text": "Whether it's to predict the answer of a question or to say, look, I'm looking at all the market dynamics and I'm gonna tell you what's gonna happen next, or you're in a room and somebody walks in and you're gonna predict what they're gonna do next or what they're gonna say next."}, {"time": 533, "text": "You're in a highly dynamic environment full of uncertainty, be able to predict."}, {"time": 538, "text": "The more variables, the more complex."}, {"time": 541, "text": "The more possibilities, the more complex."}, {"time": 544, "text": "But can I take a small amount of prior data and learn the pattern and then predict what's gonna happen next accurately and consistently?"}, {"time": 553, "text": "That's certainly a form of intelligence."}, {"time": 556, "text": "What do you need for that, by the way?"}, {"time": 558, "text": "You need to have an understanding of the way the world works in order to be able to unroll it into the future, right?"}, {"time": 566, "text": "What do you think is needed to predict?"}, {"time": 568, "text": "Depends what you mean by understanding."}, {"time": 569, "text": "I need to be able to find that function."}, {"time": 572, "text": "This is very much what deep learning does, machine learning does, is if you give me enough prior data and you tell me what the output variable is that matters, I'm gonna sit there and be able to predict it."}, {"time": 584, "text": "And if I can predict it accurately so that I can get it right more often than not, I'm smart, if I can do that with less data and less training time, I'm even smarter."}, {"time": 598, "text": "If I can figure out what's even worth predicting, I'm smarter, meaning I'm figuring out what path is gonna get me toward a goal."}, {"time": 606, "text": "What about picking a goal?"}, {"time": 607, "text": "Sorry, you left again."}, {"time": 608, "text": "Well, that's interesting about picking a goal, sort of an interesting thing."}, {"time": 611, "text": "I think that's where you bring in what are you preprogrammed to do?"}, {"time": 615, "text": "We talk about humans, and well, humans are preprogrammed to survive."}, {"time": 619, "text": "So it's sort of their primary driving goal."}, {"time": 623, "text": "What do they have to do to do that?"}, {"time": 624, "text": "And that can be very complex, right?"}, {"time": 627, "text": "So it's not just figuring out that you need to run away from the ferocious tiger, but we survive in a social context as an example."}, {"time": 638, "text": "So understanding the subtleties of social dynamics becomes something that's important for surviving, finding a mate, reproducing, right?"}, {"time": 647, "text": "So we're continually challenged with complex sets of variables, complex constraints, rules, if you will, or patterns."}, {"time": 656, "text": "And we learn how to find the functions and predict the things."}, {"time": 660, "text": "In other words, represent those patterns efficiently and be able to predict what's gonna happen."}, {"time": 664, "text": "And that's a form of intelligence."}, {"time": 666, "text": "That doesn't really require anything specific other than the ability to find that function and predict that right answer."}, {"time": 678, "text": "But then when we say, well, do we understand each other?"}, {"time": 683, "text": "In other words, would you perceive me as intelligent beyond that ability to predict?"}, {"time": 691, "text": "So now I can predict, but I can't really articulate how I'm going through that process, what my underlying theory is for predicting, and I can't get you to understand what I'm doing so that you can figure out how to do this yourself if you did not have, for example, the right pattern matching machinery that I did."}, {"time": 713, "text": "And now we potentially have this breakdown where, in effect, I'm intelligent, but I'm sort of an alien intelligence relative to you."}, {"time": 722, "text": "You're intelligent, but nobody knows about it, or I can't."}, {"time": 725, "text": "Well, I can see the output."}, {"time": 728, "text": "So you're saying, let's sort of separate the two things."}, {"time": 731, "text": "One is you explaining why you were able to predict the future, and the second is me being able to, impressing me that you're intelligent, me being able to know that you successfully predicted the future."}, {"time": 748, "text": "Do you think that's?"}, {"time": 749, "text": "Well, it's not impressing you that I'm intelligent."}, {"time": 751, "text": "In other words, you may be convinced that I'm intelligent in some form."}, {"time": 755, "text": "So how, what would convince?"}, {"time": 757, "text": "Because of my ability to predict."}, {"time": 758, "text": "So I would look at the metrics."}, {"time": 759, "text": "When you can't, I'd say, wow."}, {"time": 761, "text": "You're right more times than I am."}, {"time": 764, "text": "You're doing something interesting."}, {"time": 766, "text": "That's a form of intelligence."}, {"time": 769, "text": "But then what happens is, if I say, how are you doing that?"}, {"time": 773, "text": "And you can't communicate with me, and you can't describe that to me, now I may label you a savant."}, {"time": 780, "text": "I may say, well, you're doing something weird, and it's just not very interesting to me, because you and I can't really communicate."}, {"time": 789, "text": "And so now, so this is interesting, right?"}, {"time": 792, "text": "Because now this is, you're in this weird place where for you to be recognized as intelligent the way I'm intelligent, then you and I sort of have to be able to communicate."}, {"time": 804, "text": "And then my, we start to understand each other, and then my respect and my appreciation, my ability to relate to you starts to change."}, {"time": 816, "text": "So now you're not an alien intelligence anymore."}, {"time": 819, "text": "You're a human intelligence now, because you and I can communicate."}, {"time": 823, "text": "And so I think when we look at animals, for example, animals can do things we can't quite comprehend, we don't quite know how they do them, but they can't really communicate with us."}, {"time": 834, "text": "They can't put what they're going through in our terms."}, {"time": 838, "text": "And so we think of them as sort of, well, they're these alien intelligences, and they're not really worth necessarily what we're worth."}, {"time": 843, "text": "We don't treat them the same way as a result of that."}, {"time": 846, "text": "But it's hard because who knows what's going on."}, {"time": 851, "text": "So just a quick elaboration on that, the explaining that you're intelligent, the explaining the reasoning that went into the prediction is not some kind of mathematical proof."}, {"time": 867, "text": "If we look at humans, look at political debates and discourse on Twitter, it's mostly just telling stories."}, {"time": 875, "text": "So your task is, sorry, your task is not to tell an accurate depiction of how you reason, but to tell a story, real or not, that convinces me that there was a mechanism by which you."}, {"time": 892, "text": "Ultimately, that's what a proof is."}, {"time": 893, "text": "I mean, even a mathematical proof is that."}, {"time": 896, "text": "Because ultimately, the other mathematicians have to be convinced by your proof."}, {"time": 901, "text": "Otherwise, in fact, there have been."}, {"time": 903, "text": "That's the metric for success, yeah."}, {"time": 904, "text": "There have been several proofs out there where mathematicians would study for a long time before they were convinced that it actually proved anything, right?"}, {"time": 910, "text": "You never know if it proved anything until the community of mathematicians decided that it did."}, {"time": 914, "text": "So I mean, but it's a real thing, right?"}, {"time": 918, "text": "And that's sort of the point, right?"}, {"time": 920, "text": "Is that ultimately, this notion of understanding us, understanding something is ultimately a social concept."}, {"time": 928, "text": "In other words, I have to convince enough people that I did this in a reasonable way."}, {"time": 933, "text": "I did this in a way that other people can understand and replicate and that it makes sense to them."}, {"time": 939, "text": "So human intelligence is bound together in that way."}, {"time": 944, "text": "We're bound up in that sense."}, {"time": 947, "text": "We sort of never really get away with it until we can sort of convince others that our thinking process makes sense."}, {"time": 955, "text": "Did you think the general question of intelligence is then also a social construct?"}, {"time": 961, "text": "So if we ask questions of an artificial intelligence system, is this system intelligent?"}, {"time": 968, "text": "The answer will ultimately be a socially constructed."}, {"time": 972, "text": "I think, so I think I'm making two statements."}, {"time": 976, "text": "I'm saying we can try to define intelligence in this super objective way that says, here's this data."}, {"time": 983, "text": "I wanna predict this type of thing, learn this function."}, {"time": 986, "text": "And then if you get it right, often enough, we consider you intelligent."}, {"time": 992, "text": "But that's more like a sub bond."}, {"time": 994, "text": "I think it is."}, {"time": 995, "text": "It doesn't mean it's not useful."}, {"time": 997, "text": "It could be incredibly useful."}, {"time": 998, "text": "It could be solving a problem we can't otherwise solve and can solve it more reliably than we can."}, {"time": 1004, "text": "But then there's this notion of, can humans take responsibility for the decision that you're making?"}, {"time": 1013, "text": "Can we make those decisions ourselves?"}, {"time": 1016, "text": "Can we relate to the process that you're going through?"}, {"time": 1018, "text": "And now you as an agent, whether you're a machine or another human, frankly, are now obliged to make me understand how it is that you're arriving at that answer and allow me, me or obviously a community or a judge of people to decide whether or not that makes sense."}, {"time": 1037, "text": "And by the way, that happens with the humans as well."}, {"time": 1040, "text": "You're sitting down with your staff, for example, and you ask for suggestions about what to do next."}, {"time": 1046, "text": "And someone says, oh, I think you should buy."}, {"time": 1048, "text": "And I actually think you should buy this much or whatever or sell or whatever it is."}, {"time": 1053, "text": "Or I think you should launch the product today or tomorrow or launch this product versus that product, whatever the decision may be."}, {"time": 1058, "text": "And you ask why."}, {"time": 1059, "text": "And the person says, I just have a good feeling about it."}, {"time": 1062, "text": "And you're not very satisfied."}, {"time": 1064, "text": "Now, that person could be, you might say, well, you've been right before, but I'm gonna put the company on the line."}, {"time": 1074, "text": "Can you explain to me why I should believe this?"}, {"time": 1078, "text": "And that explanation may have nothing to do with the truth."}, {"time": 1080, "text": "You just, the ultimate."}, {"time": 1081, "text": "It's gotta convince the other person."}, {"time": 1083, "text": "Still be wrong, still be wrong."}, {"time": 1085, "text": "She's gotta be convincing."}, {"time": 1086, "text": "But it's ultimately gotta be convincing."}, {"time": 1087, "text": "And that's why I'm saying it's, we're bound together, right?"}, {"time": 1092, "text": "Our intelligences are bound together in that sense."}, {"time": 1094, "text": "We have to understand each other."}, {"time": 1095, "text": "And if, for example, you're giving me an explanation, I mean, this is a very important point, right?"}, {"time": 1101, "text": "You're giving me an explanation, and I'm not good, and then I'm not good at reasoning well, and being objective, and following logical paths and consistent paths, and I'm not good at measuring and sort of computing probabilities across those paths."}, {"time": 1125, "text": "What happens is collectively, we're not gonna do well."}, {"time": 1132, "text": "The second one."}, {"time": 1133, "text": "So I think we'll talk quite a bit about the first on a specific objective metric benchmark performing well."}, {"time": 1143, "text": "But being able to explain the steps, the reasoning, how hard is that problem?"}, {"time": 1150, "text": "I think that's very hard."}, {"time": 1151, "text": "I mean, I think that that's, well, it's hard for humans."}, {"time": 1158, "text": "The thing that's hard for humans, as you know, may not necessarily be hard for computers and vice versa."}, {"time": 1164, "text": "So, sorry, so how hard is that problem for computers?"}, {"time": 1171, "text": "I think it's hard for computers, and the reason why I related to, or saying that it's also hard for humans is because I think when we step back and we say we wanna design computers to do that, one of the things we have to recognize is we're not sure how to do it well."}, {"time": 1190, "text": "I'm not sure we have a recipe for that."}, {"time": 1192, "text": "And even if you wanted to learn it, it's not clear exactly what data we use and what judgments we use to learn that well."}, {"time": 1203, "text": "And so what I mean by that is if you look at the entire enterprise of science, science is supposed to be at about objective reason and reason, right?"}, {"time": 1213, "text": "So we think about, gee, who's the most intelligent person or group of people in the world?"}, {"time": 1220, "text": "Do we think about the savants who can close their eyes and give you a number?"}, {"time": 1225, "text": "We think about the think tanks, or the scientists or the philosophers who kind of work through the details and write the papers and come up with the thoughtful, logical proofs and use the scientific method."}, {"time": 1239, "text": "I think it's the latter."}, {"time": 1242, "text": "And my point is that how do you train someone to do that?"}, {"time": 1245, "text": "And that's what I mean by it's hard."}, {"time": 1246, "text": "How do you, what's the process of training people to do that well?"}, {"time": 1250, "text": "That's a hard process."}, {"time": 1252, "text": "We work, as a society, we work pretty hard to get other people to understand our thinking and to convince them of things."}, {"time": 1262, "text": "Now we could persuade them, obviously you talked about this, like human flaws or weaknesses, we can persuade them through emotional means."}, {"time": 1272, "text": "But to get them to understand and connect to and follow a logical argument is difficult."}, {"time": 1279, "text": "We try it, we do it, we do it as scientists, we try to do it as journalists, we try to do it as even artists in many forms, as writers, as teachers."}, {"time": 1289, "text": "We go through a fairly significant training process to do that."}, {"time": 1294, "text": "And then we could ask, well, why is that so hard?"}, {"time": 1299, "text": "But it's hard."}, {"time": 1299, "text": "And for humans, it takes a lot of work."}, {"time": 1304, "text": "And when we step back and say, well, how do we get a machine to do that?"}, {"time": 1309, "text": "It's a vexing question."}, {"time": 1311, "text": "How would you begin to try to solve that?"}, {"time": 1315, "text": "And maybe just a quick pause, because there's an optimistic notion in the things you're describing, which is being able to explain something through reason."}, {"time": 1325, "text": "But if you look at algorithms that recommend things that we'll look at next, whether it's Facebook, Google, advertisement based companies, their goal is to convince you to buy things based on anything."}, {"time": 1343, "text": "So that could be reason, because the best of advertisement is showing you things that you really do need and explain why you need it."}, {"time": 1351, "text": "But it could also be through emotional manipulation."}, {"time": 1357, "text": "The algorithm that describes why a certain decision was made, how hard is it to do it through emotional manipulation?"}, {"time": 1368, "text": "And why is that a good or a bad thing?"}, {"time": 1372, "text": "So you've kind of focused on reason, logic, really showing in a clear way why something is good."}, {"time": 1382, "text": "One, is that even a thing that us humans do?"}, {"time": 1385, "text": "And two, how do you think of the difference in the reasoning aspect and the emotional manipulation?"}, {"time": 1395, "text": "So you call it emotional manipulation, but more objectively is essentially saying, there are certain features of things that seem to attract your attention."}, {"time": 1404, "text": "I mean, it kind of give you more of that stuff."}, {"time": 1406, "text": "Manipulation is a bad word."}, {"time": 1408, "text": "Yeah, I mean, I'm not saying it's good right or wrong."}, {"time": 1411, "text": "It works to get your attention and it works to get you to buy stuff."}, {"time": 1414, "text": "And when you think about algorithms that look at the patterns of features that you seem to be spending your money on and say, I'm gonna give you something with a similar pattern."}, {"time": 1424, "text": "So I'm gonna learn that function because the objective is to get you to click on it or get you to buy it or whatever it is."}, {"time": 1431, "text": "I don't know, I mean, it is what it is."}, {"time": 1433, "text": "I mean, that's what the algorithm does."}, {"time": 1435, "text": "You can argue whether it's good or bad."}, {"time": 1437, "text": "It depends what your goal is."}, {"time": 1440, "text": "I guess this seems to be very useful for convincing, for telling a story."}, {"time": 1445, "text": "For convincing humans, it's good because again, this goes back to what is the human behavior like, how does the human brain respond to things?"}, {"time": 1457, "text": "I think there's a more optimistic view of that too, which is that if you're searching for certain kinds of things, you've already reasoned that you need them."}, {"time": 1466, "text": "And these algorithms are saying, look, that's up to you to reason whether you need something or not."}, {"time": 1472, "text": "That's your job."}, {"time": 1473, "text": "You may have an unhealthy addiction to this stuff or you may have a reasoned and thoughtful explanation for why it's important to you."}, {"time": 1484, "text": "And the algorithms are saying, hey, that's like, whatever."}, {"time": 1487, "text": "Like, that's your problem."}, {"time": 1488, "text": "All I know is you're buying stuff like that."}, {"time": 1490, "text": "You're interested in stuff like that."}, {"time": 1491, "text": "Could be a bad reason, could be a good reason."}, {"time": 1493, "text": "That's up to you."}, {"time": 1495, "text": "I'm gonna show you more of that stuff."}, {"time": 1497, "text": "And I think that it's not good or bad."}, {"time": 1501, "text": "It's not reasoned or not reasoned."}, {"time": 1503, "text": "The algorithm is doing what it does, which is saying, you seem to be interested in this."}, {"time": 1509, "text": "And I think we're seeing this not just in buying stuff, but even in social media."}, {"time": 1512, "text": "You're reading this kind of stuff."}, {"time": 1513, "text": "I'm not judging on whether it's good or bad."}, {"time": 1515, "text": "I'm not reasoning at all."}, {"time": 1516, "text": "I'm just saying, I'm gonna show you other stuff with similar features."}, {"time": 1520, "text": "And like, and that's it."}, {"time": 1522, "text": "And I wash my hands from it and I say, that's all that's going on."}, {"time": 1525, "text": "You know, there is, people are so harsh on AI systems."}, {"time": 1531, "text": "So one, the bar of performance is extremely high."}, {"time": 1534, "text": "And yet we also ask them to, in the case of social media, to help find the better angels of our nature and help make a better society."}, {"time": 1545, "text": "What do you think about the role of AI there?"}, {"time": 1547, "text": "So that, I agree with you."}, {"time": 1548, "text": "That's the interesting dichotomy, right?"}, {"time": 1551, "text": "Because on one hand, we're sitting there and we're sort of doing the easy part, which is finding the patterns."}, {"time": 1557, "text": "We're not building, the system's not building a theory that is consumable and understandable to other humans that can be explained and justified."}, {"time": 1566, "text": "And so on one hand to say, oh, you know, AI is doing this."}, {"time": 1571, "text": "Why isn't doing this other thing?"}, {"time": 1573, "text": "Well, this other thing's a lot harder."}, {"time": 1576, "text": "And it's interesting to think about why it's harder."}, {"time": 1580, "text": "And because you're interpreting the data in the context of prior models."}, {"time": 1586, "text": "In other words, understandings of what's important in the world, what's not important."}, {"time": 1590, "text": "What are all the other abstract features that drive our decision making?"}, {"time": 1595, "text": "What's sensible, what's not sensible, what's good, what's bad, what's moral, what's valuable, what isn't?"}, {"time": 1600, "text": "Where is that stuff?"}, {"time": 1601, "text": "No one's applying the interpretation."}, {"time": 1603, "text": "So when I see you clicking on a bunch of stuff and I look at these simple features, the raw features, the features that are there in the data, like what words are being used or how long the material is or other very superficial features, what colors are being used in the material."}, {"time": 1622, "text": "Like, I don't know why you're clicking on this stuff you're clicking."}, {"time": 1624, "text": "Or if it's products, what the price is or what the categories and stuff like that."}, {"time": 1629, "text": "And I just feed you more of the same stuff."}, {"time": 1631, "text": "That's very different than kind of getting in there and saying, what does this mean?"}, {"time": 1636, "text": "The stuff you're reading, like why are you reading it?"}, {"time": 1641, "text": "What assumptions are you bringing to the table?"}, {"time": 1643, "text": "Are those assumptions sensible?"}, {"time": 1646, "text": "Does the material make any sense?"}, {"time": 1648, "text": "Does it lead you to thoughtful, good conclusions?"}, {"time": 1654, "text": "Again, there's interpretation and judgment involved in that process that isn't really happening in the AI today."}, {"time": 1662, "text": "That's harder because you have to start getting at the meaning of the stuff, of the content."}, {"time": 1672, "text": "You have to get at how humans interpret the content relative to their value system and deeper thought processes."}, {"time": 1680, "text": "So that's what meaning means is not just some kind of deep, timeless, semantic thing that the statement represents, but also how a large number of people are likely to interpret."}, {"time": 1695, "text": "So that's again, even meaning is a social construct."}, {"time": 1699, "text": "So you have to try to predict how most people would understand this kind of statement."}, {"time": 1704, "text": "Yeah, meaning is often relative, but meaning implies that the connections go beneath the surface of the artifacts."}, {"time": 1711, "text": "If I show you a painting, it's a bunch of colors on a canvas, what does it mean to you?"}, {"time": 1717, "text": "And it may mean different things to different people because of their different experiences."}, {"time": 1722, "text": "It may mean something even different to the artist who painted it."}, {"time": 1727, "text": "As we try to get more rigorous with our communication, we try to really nail down that meaning."}, {"time": 1733, "text": "So we go from abstract art to precise mathematics, precise engineering drawings and things like that."}, {"time": 1741, "text": "We're really trying to say, I wanna narrow that space of possible interpretations because the precision of the communication ends up becoming more and more important."}, {"time": 1753, "text": "And so that means that I have to specify, and I think that's why this becomes really hard, because if I'm just showing you an artifact and you're looking at it superficially, whether it's a bunch of words on a page, or whether it's brushstrokes on a canvas or pixels on a photograph, you can sit there and you can interpret lots of different ways at many, many different levels."}, {"time": 1778, "text": "But when I wanna align our understanding of that, I have to specify a lot more stuff that's actually not directly in the artifact."}, {"time": 1792, "text": "Now I have to say, well, how are you interpreting this image and that image?"}, {"time": 1797, "text": "And what about the colors and what do they mean to you?"}, {"time": 1799, "text": "What perspective are you bringing to the table?"}, {"time": 1802, "text": "What are your prior experiences with those artifacts?"}, {"time": 1805, "text": "What are your fundamental assumptions and values?"}, {"time": 1808, "text": "What is your ability to kind of reason, to chain together logical implication as you're sitting there and saying, well, if this is the case, then I would conclude this."}, {"time": 1816, "text": "And if that's the case, then I would conclude that."}, {"time": 1819, "text": "So your reasoning processes and how they work, your prior models and what they are, your values and your assumptions, all those things now come together into the interpretation."}, {"time": 1830, "text": "Getting in sync of that is hard."}, {"time": 1834, "text": "And yet humans are able to intuit some of that without any pre."}, {"time": 1839, "text": "Because they have the shared experience."}, {"time": 1841, "text": "And we're not talking about shared, two people having shared experience."}, {"time": 1844, "text": "I mean, as a society."}, {"time": 1846, "text": "We have the shared experience and we have similar brains."}, {"time": 1851, "text": "So we tend to, in other words, part of our shared experiences are shared local experience."}, {"time": 1856, "text": "Like we may live in the same culture, we may live in the same society and therefore we have similar educations."}, {"time": 1862, "text": "We have some of what we like to call prior models about the word prior experiences."}, {"time": 1865, "text": "And we use that as a, think of it as a wide collection of interrelated variables and they're all bound to similar things."}, {"time": 1872, "text": "And so we take that as our background and we start interpreting things similarly."}, {"time": 1877, "text": "But as humans, we have a lot of shared experience."}, {"time": 1881, "text": "We do have similar brains, similar goals, similar emotions under similar circumstances."}, {"time": 1888, "text": "Because we're both humans."}, {"time": 1889, "text": "So now one of the early questions you asked, how is biological and computer information systems fundamentally different?"}, {"time": 1897, "text": "Well, one is humans come with a lot of pre programmed stuff."}, {"time": 1903, "text": "A ton of program stuff."}, {"time": 1905, "text": "And they're able to communicate because they share that stuff."}, {"time": 1910, "text": "Do you think that shared knowledge, if we can maybe escape the hard work question, how much is encoded in the hardware?"}, {"time": 1919, "text": "Just the shared knowledge in the software, the history, the many centuries of wars and so on that came to today, that shared knowledge."}, {"time": 1929, "text": "How hard is it to encode?"}, {"time": 1934, "text": "Do you have a hope?"}, {"time": 1935, "text": "Can you speak to how hard is it to encode that knowledge systematically in a way that could be used by a computer?"}, {"time": 1942, "text": "So I think it is possible to learn to, for a machine to program a machine, to acquire that knowledge with a similar foundation."}, {"time": 1951, "text": "In other words, a similar interpretive foundation for processing that knowledge."}, {"time": 1959, "text": "So in other words, we view the world in a particular way."}, {"time": 1964, "text": "So in other words, we have a, if you will, as humans, we have a framework for interpreting the world around us."}, {"time": 1972, "text": "So we have multiple frameworks for interpreting the world around us."}, {"time": 1976, "text": "But if you're interpreting, for example, socio political interactions, you're thinking about where there's people, there's collections and groups of people, they have goals, goals largely built around survival and quality of life."}, {"time": 1990, "text": "There are fundamental economics around scarcity of resources."}, {"time": 1996, "text": "And when humans come and start interpreting a situation like that, because you brought up like historical events, they start interpreting situations like that."}, {"time": 2005, "text": "They apply a lot of this fundamental framework for interpreting that."}, {"time": 2010, "text": "Well, who are the people?"}, {"time": 2012, "text": "What were their goals?"}, {"time": 2013, "text": "What resources did they have?"}, {"time": 2015, "text": "How much power influence did they have over the other?"}, {"time": 2017, "text": "Like this fundamental substrate, if you will, for interpreting and reasoning about that."}, {"time": 2023, "text": "So I think it is possible to imbue a computer with that stuff that humans like take for granted when they go and sit down and try to interpret things."}, {"time": 2034, "text": "And then with that foundation, they acquire, they start acquiring the details, the specifics in a given situation, are then able to interpret it with regard to that framework."}, {"time": 2045, "text": "And then given that interpretation, they can do what?"}, {"time": 2048, "text": "They can predict."}, {"time": 2050, "text": "But not only can they predict, they can predict now with an explanation that can be given in those terms, in the terms of that underlying framework that most humans share."}, {"time": 2062, "text": "Now you could find humans that come and interpret events very differently than other humans because they're like using a different framework."}, {"time": 2070, "text": "The movie Matrix comes to mind where they decided humans were really just batteries, and that's how they interpreted the value of humans as a source of electrical energy."}, {"time": 2081, "text": "So, but I think that for the most part, we have a way of interpreting the events or the social events around us because we have this shared framework."}, {"time": 2094, "text": "It comes from, again, the fact that we're similar beings that have similar goals, similar emotions, and we can make sense out of these."}, {"time": 2102, "text": "These frameworks make sense to us."}, {"time": 2105, "text": "So how much knowledge is there, do you think?"}, {"time": 2108, "text": "So you said it's possible."}, {"time": 2109, "text": "Well, there's a tremendous amount of detailed knowledge in the world."}, {"time": 2112, "text": "You could imagine effectively infinite number of unique situations and unique configurations of these things."}, {"time": 2122, "text": "But the knowledge that you need, what I refer to as like the frameworks, for you need for interpreting them, I don't think."}, {"time": 2129, "text": "I think those are finite."}, {"time": 2131, "text": "You think the frameworks are more important than the bulk of the knowledge?"}, {"time": 2136, "text": "So it's like framing."}, {"time": 2137, "text": "Yeah, because what the frameworks do is they give you now the ability to interpret and reason, and to interpret and reason, to interpret and reason over the specifics in ways that other humans would understand."}, {"time": 2149, "text": "What about the specifics?"}, {"time": 2151, "text": "You know, you acquire the specifics by reading and by talking to other people."}, {"time": 2155, "text": "So I'm mostly actually just even, if we can focus on even the beginning, the common sense stuff, the stuff that doesn't even require reading, or it almost requires playing around with the world or something, just being able to sort of manipulate objects, drink water and so on, all of that."}, {"time": 2173, "text": "Every time we try to do that kind of thing in robotics or AI, it seems to be like an onion."}, {"time": 2181, "text": "You seem to realize how much knowledge is really required to perform even some of these basic tasks."}, {"time": 2187, "text": "Do you have that sense as well?"}, {"time": 2190, "text": "And if so, how do we get all those details?"}, {"time": 2193, "text": "Are they written down somewhere?"}, {"time": 2195, "text": "Do they have to be learned through experience?"}, {"time": 2199, "text": "So I think when, like, if you're talking about sort of the physics, the basic physics around us, for example, acquiring information about, acquiring how that works."}, {"time": 2209, "text": "Yeah, I mean, I think there's a combination of things going, I think there's a combination of things going on."}, {"time": 2214, "text": "I think there is like fundamental pattern matching, like what we were talking about before, where you see enough examples, enough data about something and you start assuming that."}, {"time": 2223, "text": "And with similar input, I'm gonna predict similar outputs."}, {"time": 2227, "text": "You can't necessarily explain it at all."}, {"time": 2230, "text": "You may learn very quickly that when you let something go, it falls to the ground."}, {"time": 2236, "text": "But you can't necessarily explain that."}, {"time": 2239, "text": "But that's such a deep idea, that if you let something go, like the idea of gravity."}, {"time": 2246, "text": "I mean, people are letting things go and counting on them falling well before they understood gravity."}, {"time": 2250, "text": "But that seems to be, that's exactly what I mean, is before you take a physics class or study anything about Newton, just the idea that stuff falls to the ground and then you'd be able to generalize that all kinds of stuff falls to the ground."}, {"time": 2269, "text": "It just seems like a non, without encoding it, like hard coding it in, it seems like a difficult thing to pick up."}, {"time": 2277, "text": "It seems like you have to have a lot of different knowledge to be able to integrate that into the framework, sort of into everything else."}, {"time": 2287, "text": "So both know that stuff falls to the ground and start to reason about sociopolitical discourse."}, {"time": 2296, "text": "So both, like the very basic and the high level reasoning decision making."}, {"time": 2302, "text": "I guess my question is, how hard is this problem?"}, {"time": 2306, "text": "And sorry to linger on it because again, and we'll get to it for sure, as what Watson with Jeopardy did is take on a problem that's much more constrained but has the same hugeness of scale, at least from the outsider's perspective."}, {"time": 2320, "text": "So I'm asking the general life question of to be able to be an intelligent being and reason in the world about both gravity and politics, how hard is that problem?"}, {"time": 2333, "text": "So I think it's solvable."}, {"time": 2339, "text": "Okay, now beautiful."}, {"time": 2340, "text": "So what about time travel?"}, {"time": 2344, "text": "Okay, I'm just saying the same answer."}, {"time": 2348, "text": "Not as convinced."}, {"time": 2349, "text": "Not as convinced yet, okay."}, {"time": 2351, "text": "No, I think it is solvable."}, {"time": 2354, "text": "I mean, I think that it's a learn, first of all, it's about getting machines to learn."}, {"time": 2358, "text": "Learning is fundamental."}, {"time": 2361, "text": "And I think we're already in a place that we understand, for example, how machines can learn in various ways."}, {"time": 2368, "text": "Right now, our learning stuff is sort of primitive in that we haven't sort of taught machines to learn the frameworks."}, {"time": 2379, "text": "We don't communicate our frameworks because of how shared they are, in some cases we do, but we don't annotate, if you will, all the data in the world with the frameworks that are inherent or underlying our understanding."}, {"time": 2393, "text": "Instead, we just operate with the data."}, {"time": 2396, "text": "So if we wanna be able to reason over the data in similar terms in the common frameworks, we need to be able to teach the computer, or at least we need to program the computer to acquire, to have access to and acquire, learn the frameworks as well and connect the frameworks to the data."}, {"time": 2415, "text": "I think this can be done."}, {"time": 2418, "text": "I think we can start, I think machine learning, for example, with enough examples, can start to learn these basic dynamics."}, {"time": 2428, "text": "Will they relate them necessarily to the gravity?"}, {"time": 2432, "text": "Not unless they can also acquire those theories as well and put the experiential knowledge and connect it back to the theoretical knowledge."}, {"time": 2443, "text": "I think if we think in terms of these class of architectures that are designed to both learn the specifics, find the patterns, but also acquire the frameworks and connect the data to the frameworks."}, {"time": 2456, "text": "If we think in terms of robust architectures like this, I think there is a path toward getting there."}, {"time": 2463, "text": "In terms of encoding architectures like that, do you think systems that are able to do this will look like neural networks or representing, if you look back to the 80s and 90s with the expert systems, they're more like graphs, systems that are based in logic, able to contain a large amount of knowledge where the challenge was the automated acquisition of that knowledge."}, {"time": 2489, "text": "I guess the question is when you collect both the frameworks and the knowledge from the data, what do you think that thing will look like?"}, {"time": 2497, "text": "Yeah, so I mean, I think asking the question, they look like neural networks is a bit of a red herring."}, {"time": 2501, "text": "I mean, I think that they will certainly do inductive or pattern match based reasoning."}, {"time": 2533, "text": "So for example, at elemental cognition, we do both."}, {"time": 2536, "text": "We have architectures that do both, both those things, but also have a learning method for acquiring the frameworks themselves and saying, look, ultimately, I need to take this data."}, {"time": 2547, "text": "I need to interpret it in the form of these frameworks so they can reason over it."}, {"time": 2550, "text": "So there is a fundamental knowledge representation, like what you're saying, like these graphs of logic, if you will."}, {"time": 2556, "text": "There are also neural networks that acquire a certain class of information."}, {"time": 2563, "text": "Then they then align them with these frameworks, but there's also a mechanism to acquire the frameworks themselves."}, {"time": 2569, "text": "Yeah, so it seems like the idea of frameworks requires some kind of collaboration with humans."}, {"time": 2576, "text": "So do you think of that collaboration as direct?"}, {"time": 2579, "text": "Well, and let's be clear."}, {"time": 2581, "text": "Only for the express purpose that you're designing, you're designing an intelligence that can ultimately communicate with humans in the terms of frameworks that help them understand things."}, {"time": 2597, "text": "So to be really clear, you can independently create a machine learning system, an intelligence that I might call an alien intelligence that does a better job than you with some things, but can't explain the framework to you."}, {"time": 2613, "text": "That doesn't mean it might be better than you at the thing."}, {"time": 2616, "text": "It might be that you cannot comprehend the framework that it may have created for itself that is inexplicable to you."}, {"time": 2623, "text": "That's a reality."}, {"time": 2625, "text": "But you're more interested in a case where you can."}, {"time": 2628, "text": "I am, yeah."}, {"time": 2631, "text": "My sort of approach to AI is because I've set the goal for myself."}, {"time": 2635, "text": "I want machines to be able to ultimately communicate, understanding with humans."}, {"time": 2641, "text": "I want them to be able to acquire and communicate, acquire knowledge from humans and communicate knowledge to humans."}, {"time": 2676, "text": "Of course, the machine is gonna have the strength that it has, the richer, longer memory, but it has the more rigorous reasoning abilities, the deeper reasoning abilities, so it'll be an interesting complementary relationship between the human and the machine."}, {"time": 2693, "text": "Do you think that ultimately needs explainability like a machine?"}, {"time": 2695, "text": "So if we look, we study, for example, Tesla autopilot a lot, where humans, I don't know if you've driven the vehicle, are aware of what it is."}, {"time": 2704, "text": "So you're basically the human and machine are working together there, and the human is responsible for their own life to monitor the system, and the system fails every few miles, and so there's hundreds, there's millions of those failures a day, and so that's like a moment of interaction."}, {"time": 2725, "text": "Do you see?"}, {"time": 2726, "text": "Yeah, that's exactly right."}, {"time": 2727, "text": "That's a moment of interaction where the machine has learned some stuff, it has a failure, somehow the failure's communicated, the human is now filling in the mistake, if you will, or maybe correcting or doing something that is more successful in that case, the computer takes that learning."}, {"time": 2747, "text": "So I believe that the collaboration between human and machine, I mean, that's sort of a primitive example and sort of a more, another example is where the machine's literally talking to you and saying, look, I'm reading this thing."}, {"time": 2762, "text": "I know that the next word might be this or that, but I don't really understand why."}, {"time": 2768, "text": "I have my guess."}, {"time": 2769, "text": "Can you help me understand the framework that supports this and then can kind of acquire that, take that and reason about it and reuse it the next time it's reading to try to understand something, not unlike a human student might do."}, {"time": 2784, "text": "I mean, I remember when my daughter was in first grade and she had a reading assignment about electricity and somewhere in the text it says, and electricity is produced by water flowing over turbines or something like that."}, {"time": 2799, "text": "And then there's a question that says, well, how is electricity created?"}, {"time": 2803, "text": "And so my daughter comes to me and says, I mean, I could, you know, created and produced are kind of synonyms in this case."}, {"time": 2809, "text": "So I can go back to the text and I can copy by water flowing over turbines, but I have no idea what that means."}, {"time": 2816, "text": "Like I don't know how to interpret water flowing over turbines and what electricity even is."}, {"time": 2820, "text": "I mean, I can get the answer right by matching the text, but I don't have any framework for understanding what this means at all."}, {"time": 2827, "text": "And framework really is, I mean, it's a set of, not to be mathematical, but axioms of ideas that you bring to the table and interpreting stuff and then you build those up somehow."}, {"time": 2838, "text": "You build them up with the expectation that there's a shared understanding of what they are."}, {"time": 2843, "text": "Sure, yeah, it's the social, that us humans, do you have a sense that humans on earth in general share a set of, like how many frameworks are there?"}, {"time": 2856, "text": "I mean, it depends on how you bound them, right?"}, {"time": 2858, "text": "So in other words, how big or small, like their individual scope, but there's lots and there are new ones."}, {"time": 2864, "text": "I think the way I think about it is kind of in a layer."}, {"time": 2867, "text": "I think that the architectures are being layered in that."}, {"time": 2870, "text": "There's a small set of primitives."}, {"time": 2873, "text": "They allow you the foundation to build frameworks."}, {"time": 2876, "text": "And then there may be many frameworks, but you have the ability to acquire them."}, {"time": 2880, "text": "And then you have the ability to reuse them."}, {"time": 2883, "text": "I mean, one of the most compelling ways of thinking about this is a reasoning by analogy, where I can say, oh, wow, I've learned something very similar."}, {"time": 2891, "text": "I never heard of this game soccer, but if it's like basketball in the sense that the goal's like the hoop and I have to get the ball in the hoop and I have guards and I have this and I have that, like where are the similarities and where are the differences?"}, {"time": 2907, "text": "And I have a foundation now for interpreting this new information."}, {"time": 2911, "text": "And then the different groups, like the millennials will have a framework."}, {"time": 2916, "text": "And then, you know, the Democrats and Republicans."}, {"time": 2921, "text": "Millennials, nobody wants that framework."}, {"time": 2923, "text": "Well, I mean, I think, right, I mean, you're talking about political and social ways of interpreting the world around them."}, {"time": 2929, "text": "And I think these frameworks are still largely, largely similar."}, {"time": 2932, "text": "I think they differ in maybe what some fundamental assumptions and values are."}, {"time": 2937, "text": "Now, from a reasoning perspective, like the ability to process the framework, it might not be that different."}, {"time": 2944, "text": "The implications of different fundamental values or fundamental assumptions in those frameworks may reach very different conclusions."}, {"time": 2952, "text": "So from a social perspective, the conclusions may be very different."}, {"time": 2956, "text": "From an intelligence perspective, I just followed where my assumptions took me."}, {"time": 2961, "text": "Yeah, the process itself will look similar."}, {"time": 2963, "text": "But that's a fascinating idea that frameworks really help carve how a statement will be interpreted."}, {"time": 2973, "text": "I mean, having a Democrat and a Republican framework and then read the exact same statement and the conclusions that you derive will be totally different from an AI perspective is fascinating."}, {"time": 2987, "text": "What we would want out of the AI is to be able to tell you that this perspective, one perspective, one set of assumptions is gonna lead you here, another set of assumptions is gonna lead you there."}, {"time": 2998, "text": "And in fact, to help people reason and say, oh, I see where our differences lie."}, {"time": 3005, "text": "I have this fundamental belief about that."}, {"time": 3009, "text": "Yeah, that's quite brilliant."}, {"time": 3010, "text": "From my perspective, NLP, there's this idea that there's one way to really understand a statement, but that probably isn't."}, {"time": 3018, "text": "There's probably an infinite number of ways to understand a statement, depending on the question."}, {"time": 3021, "text": "There's lots of different interpretations, and the broader the content, the richer it is."}, {"time": 3031, "text": "And so you and I can have very different experiences with the same text, obviously."}, {"time": 3037, "text": "And if we're committed to understanding each other, we start, and that's the other important point, if we're committed to understanding each other, we start decomposing and breaking down our interpretation to its more and more primitive components until we get to that point where we say, oh, I see why we disagree."}, {"time": 3058, "text": "And we try to understand how fundamental that disagreement really is."}, {"time": 3062, "text": "But that requires a commitment to breaking down that interpretation in terms of that framework in a logical way."}, {"time": 3095, "text": "And if the machine can help us break that argument down and say, wait a second, what do you really think about this, right?"}, {"time": 3102, "text": "So essentially holding us accountable to doing more critical thinking."}, {"time": 3107, "text": "We're gonna have to sit and think about this fast."}, {"time": 3109, "text": "That's, I love that."}, {"time": 3110, "text": "I think that's really empowering use of AI for the public discourse is completely disintegrating currently as we learn how to do it on social media."}, {"time": 3122, "text": "So one of the greatest accomplishments in the history of AI is Watson competing in the game of Jeopardy against humans."}, {"time": 3134, "text": "And you were a lead in that, a critical part of that."}, {"time": 3138, "text": "Let's start at the very basics."}, {"time": 3140, "text": "What is the game of Jeopardy?"}, {"time": 3142, "text": "The game for us humans, human versus human."}, {"time": 3145, "text": "Right, so it's to take a question and answer it."}, {"time": 3153, "text": "The game of Jeopardy."}, {"time": 3154, "text": "It's just the opposite."}, {"time": 3155, "text": "Actually, well, no, but it's not, right?"}, {"time": 3158, "text": "It's really not."}, {"time": 3159, "text": "It's really to get a question and answer, but it's what we call a factoid question."}, {"time": 3163, "text": "So this notion of like, it really relates to some fact that two people would argue whether the facts are true or not."}, {"time": 3170, "text": "In fact, most people wouldn't."}, {"time": 3171, "text": "Jeopardy kind of counts on the idea that these statements have factual answers."}, {"time": 3177, "text": "And the idea is to, first of all, determine whether or not you know the answer, which is sort of an interesting twist."}, {"time": 3186, "text": "So first of all, understand the question."}, {"time": 3187, "text": "You have to understand the question."}, {"time": 3188, "text": "What is it asking?"}, {"time": 3189, "text": "And that's a good point because the questions are not asked directly, right?"}, {"time": 3194, "text": "They're all like, the way the questions are asked is nonlinear."}, {"time": 3198, "text": "It's like, it's a little bit witty."}, {"time": 3200, "text": "It's a little bit playful sometimes."}, {"time": 3202, "text": "It's a little bit tricky."}, {"time": 3205, "text": "Yeah, they're asked in exactly numerous witty, tricky ways."}, {"time": 3210, "text": "Exactly what they're asking is not obvious."}, {"time": 3212, "text": "It takes inexperienced humans a while to go, what is it even asking?"}, {"time": 3216, "text": "And it's sort of an interesting realization that you have when somebody says, oh, what's, Jeopardy is a question answering show."}, {"time": 3222, "text": "And then he's like, oh, like, I know a lot."}, {"time": 3223, "text": "And then you read it and you're still trying to process the question and the champions have answered and moved on."}, {"time": 3229, "text": "There are three questions ahead by the time you figured out what the question even meant."}, {"time": 3234, "text": "So there's definitely an ability there to just parse out what the question even is."}, {"time": 3239, "text": "So that was certainly challenging."}, {"time": 3240, "text": "It's interesting historically though, if you look back at the Jeopardy games much earlier, you know, early games."}, {"time": 3245, "text": "Like 60s, 70s, that kind of thing."}, {"time": 3248, "text": "The questions were much more direct."}, {"time": 3250, "text": "They weren't quite like that."}, {"time": 3251, "text": "They got sort of more and more interesting, the way they asked them that sort of got more and more interesting and subtle and nuanced and humorous and witty over time, which really required the human to kind of make the right connections in figuring out what the question was even asking."}, {"time": 3266, "text": "So yeah, you have to figure out the questions even asking."}, {"time": 3269, "text": "Then you have to determine whether or not you think you know the answer."}, {"time": 3274, "text": "And because you have to buzz in really quickly, you sort of have to make that determination as quickly as you possibly can."}, {"time": 3281, "text": "Otherwise you lose the opportunity to buzz in."}, {"time": 3283, "text": "You mean..."}, {"time": 3284, "text": "Even before you really know if you know the answer."}, {"time": 3286, "text": "I think a lot of humans will assume, they'll process it very superficially."}, {"time": 3293, "text": "In other words, what's the topic?"}, {"time": 3294, "text": "What are some keywords?"}, {"time": 3295, "text": "And just say, do I know this area or not before they actually know the answer?"}, {"time": 3300, "text": "Then they'll buzz in and think about it."}, {"time": 3303, "text": "So it's interesting what humans do."}, {"time": 3304, "text": "Now, some people who know all things, like Ken Jennings or something, or the more recent big Jeopardy player, I mean, they'll just buzz in."}, {"time": 3312, "text": "They'll just assume they know all of Jeopardy and they'll just buzz in."}, {"time": 3315, "text": "Watson, interestingly, didn't even come close to knowing all of Jeopardy, right?"}, {"time": 3320, "text": "Watson really..."}, {"time": 3320, "text": "Even at the peak, even at its best."}, {"time": 3322, "text": "Yeah, so for example, I mean, we had this thing called recall, which is like how many of all the Jeopardy questions, how many could we even find the right answer for anywhere?"}, {"time": 3334, "text": "Like, can we come up with, we had a big body of knowledge, something in the order of several terabytes."}, {"time": 3339, "text": "I mean, from a web scale, it was actually very small, but from like a book scale, we're talking about millions of books, right?"}, {"time": 3346, "text": "So the equivalent of millions of books, encyclopedias, dictionaries, books, it's still a ton of information."}, {"time": 3352, "text": "And I think it was only 85% was the answer anywhere to be found."}, {"time": 3357, "text": "So you're already down at that level just to get started, right?"}, {"time": 3362, "text": "So, and so it was important to get a very quick sense of do you think you know the right answer to this question?"}, {"time": 3370, "text": "So we had to compute that confidence as quickly as we possibly could."}, {"time": 3374, "text": "So in effect, we had to answer it and at least spend some time essentially answering it and then judging the confidence that our answer was right and then deciding whether or not we were confident enough to buzz in."}, {"time": 3390, "text": "And that would depend on what else was going on in the game."}, {"time": 3391, "text": "Because there was a risk."}, {"time": 3393, "text": "So like if you're really in a situation where I have to take a guess, I have very little to lose, then you'll buzz in with less confidence."}, {"time": 3400, "text": "So that was accounted for the financial standings of the different competitors."}, {"time": 3405, "text": "How much of the game was left?"}, {"time": 3406, "text": "How much time was left?"}, {"time": 3408, "text": "Where you were in the standing, things like that."}, {"time": 3410, "text": "How many hundreds of milliseconds that we're talking about here?"}, {"time": 3413, "text": "Do you have a sense of what is?"}, {"time": 3415, "text": "We targeted, yeah, we targeted."}, {"time": 3418, "text": "So, I mean, we targeted answering in under three seconds and."}, {"time": 3424, "text": "Buzzing in."}, {"time": 3425, "text": "So the decision to buzz in and then the actual answering are those two different stages?"}, {"time": 3430, "text": "Yeah, they were two different things."}, {"time": 3432, "text": "In fact, we had multiple stages, whereas like we would say, let's estimate our confidence, which was sort of a shallow answering process."}, {"time": 3441, "text": "And then ultimately decide to buzz in and then we may take another second or something to kind of go in there and do that."}, {"time": 3450, "text": "But by and large, we were saying like, we can't play the game."}, {"time": 3453, "text": "We can't even compete if we can't on average answer these questions in around three seconds or less."}, {"time": 3460, "text": "So you stepped in."}, {"time": 3461, "text": "So there's these three humans playing a game and you stepped in with the idea that IBM Watson would be one of, replace one of the humans and compete against two."}, {"time": 3472, "text": "Can you tell the story of Watson taking on this game?"}, {"time": 3477, "text": "It seems exceptionally difficult."}, {"time": 3478, "text": "Yeah, so the story was that it was coming up, I think to the 10 year anniversary of Big Blue, not Big Blue, Deep Blue."}, {"time": 3488, "text": "IBM wanted to do sort of another kind of really fun challenge, public challenge that can bring attention to IBM research and the kind of the cool stuff that we were doing."}, {"time": 3499, "text": "I had been working in AI at IBM for some time."}, {"time": 3503, "text": "I had a team doing what's called open domain factoid question answering, which is, we're not gonna tell you what the questions are."}, {"time": 3511, "text": "We're not even gonna tell you what they're about."}, {"time": 3513, "text": "Can you go off and get accurate answers to these questions?"}, {"time": 3516, "text": "And it was an area of AI research that I was involved in."}, {"time": 3521, "text": "And so it was a very specific passion of mine."}, {"time": 3524, "text": "Language understanding had always been a passion of mine."}, {"time": 3527, "text": "One sort of narrow slice on whether or not you could do anything with language was this notion of open domain and meaning I could ask anything about anything."}, {"time": 3534, "text": "Factoid meaning it essentially had an answer and being able to do that accurately and quickly."}, {"time": 3540, "text": "So that was a research area that my team had already been in."}, {"time": 3543, "text": "And so completely independently, several IBM executives, like what are we gonna do?"}, {"time": 3549, "text": "What's the next cool thing to do?"}, {"time": 3551, "text": "And Ken Jennings was on his winning streak."}, {"time": 3553, "text": "This was like, whatever it was, 2004, I think, was on his winning streak."}, {"time": 3558, "text": "And someone thought, hey, that would be really cool if the computer can play Jeopardy."}, {"time": 3563, "text": "And so this was like in 2004, they were shopping this thing around and everyone was telling the research execs, no way."}, {"time": 3573, "text": "Like, this is crazy."}, {"time": 3575, "text": "And we had some pretty senior people in the field and they're saying, no, this is crazy."}, {"time": 3578, "text": "And it would come across my desk and I was like, but that's kind of what I'm really interested in doing."}, {"time": 3584, "text": "But there was such this prevailing sense of this is nuts."}, {"time": 3587, "text": "We're not gonna risk IBM's reputation on this."}, {"time": 3589, "text": "We're just not doing it."}, {"time": 3590, "text": "And this happened in 2004, it happened in 2005."}, {"time": 3593, "text": "At the end of 2006, it was coming around again."}, {"time": 3599, "text": "And I was coming off of a, I was doing the open domain question answering stuff, but I was coming off a couple other projects."}, {"time": 3605, "text": "I had a lot more time to put into this."}, {"time": 3608, "text": "And I argued that it could be done."}, {"time": 3610, "text": "And I argue it would be crazy not to do this."}, {"time": 3612, "text": "Can I, you can be honest at this point."}, {"time": 3615, "text": "So even though you argued for it, what's the confidence that you had yourself privately that this could be done?"}, {"time": 3622, "text": "Was, we just told the story, how you tell stories to convince others."}, {"time": 3627, "text": "How confident were you?"}, {"time": 3628, "text": "What was your estimation of the problem at that time?"}, {"time": 3632, "text": "So I thought it was possible."}, {"time": 3634, "text": "And a lot of people thought it was impossible."}, {"time": 3636, "text": "I thought it was possible."}, {"time": 3637, "text": "The reason why I thought it was possible was because I did some brief experimentation."}, {"time": 3641, "text": "I knew a lot about how we were approaching open domain factoid question answering."}, {"time": 3645, "text": "I've been doing it for some years."}, {"time": 3647, "text": "I looked at the Jeopardy stuff."}, {"time": 3649, "text": "I said, this is gonna be hard for a lot of the points that we mentioned earlier."}, {"time": 3654, "text": "Hard to interpret the question."}, {"time": 3657, "text": "Hard to do it quickly enough."}, {"time": 3658, "text": "Hard to compute an accurate confidence."}, {"time": 3660, "text": "None of this stuff had been done well enough before."}, {"time": 3663, "text": "But a lot of the technologies we're building were the kinds of technologies that should work."}, {"time": 3667, "text": "But more to the point, what was driving me was, I was in IBM research."}, {"time": 3672, "text": "I was a senior leader in IBM research."}, {"time": 3674, "text": "And this is the kind of stuff we were supposed to do."}, {"time": 3677, "text": "In other words, we were basically supposed to."}, {"time": 3678, "text": "This is the moonshot."}, {"time": 3679, "text": "This is the."}, {"time": 3680, "text": "We were supposed to take things and say, this is an active research area."}, {"time": 3684, "text": "It's our obligation to kind of, if we have the opportunity, to push it to the limits."}, {"time": 3690, "text": "And if it doesn't work, to understand more deeply why we can't do it."}, {"time": 3694, "text": "And so I was very committed to that notion saying, folks, this is what we do."}, {"time": 3700, "text": "It's crazy not to do this."}, {"time": 3702, "text": "This is an active research area."}, {"time": 3703, "text": "We've been in this for years."}, {"time": 3704, "text": "Why wouldn't we take this grand challenge and push it as hard as we can?"}, {"time": 3710, "text": "At the very least, we'd be able to come out and say, here's why this problem is way hard."}, {"time": 3717, "text": "Here's what we tried and here's how we failed."}, {"time": 3718, "text": "So I was very driven as a scientist from that perspective."}, {"time": 3723, "text": "And then I also argued, based on what we did a feasibility study, why I thought it was hard but possible."}, {"time": 3730, "text": "And I showed examples of where it succeeded, where it failed, why it failed, and sort of a high level architecture approach for why we should do it."}, {"time": 3739, "text": "But for the most part, at that point, the execs really were just looking for someone crazy enough to say yes, because for several years at that point, everyone had said, no, I'm not willing to risk my reputation and my career on this thing."}, {"time": 3754, "text": "Clearly you did not have such fears."}, {"time": 3756, "text": "I did not."}, {"time": 3757, "text": "So you dived right in."}, {"time": 3759, "text": "And yet, for what I understand, it was performing very poorly in the beginning."}, {"time": 3766, "text": "So what were the initial approaches and why did they fail?"}, {"time": 3771, "text": "Well, there were lots of hard aspects to it."}, {"time": 3774, "text": "I mean, one of the reasons why prior approaches that we had worked on in the past failed was because the questions were difficult to interpret."}, {"time": 3787, "text": "Like, what are you even asking for, right?"}, {"time": 3790, "text": "Very often, like if the question was very direct, like what city, or what, even then it could be tricky, but what city or what person, is often when it would name it very clearly, you would know that."}, {"time": 3805, "text": "And if there were just a small set of them, in other words, we're gonna ask about these five types."}, {"time": 3811, "text": "Like, it's gonna be an answer, and the answer will be a city in this state or a city in this country."}, {"time": 3817, "text": "The answer will be a person of this type, right?"}, {"time": 3821, "text": "Like an actor or whatever it is."}, {"time": 3822, "text": "But it turns out that in Jeopardy, there were like tens of thousands of these things."}, {"time": 3827, "text": "And it was a very, very long tail, meaning that it just went on and on."}, {"time": 3832, "text": "And so even if you focused on trying to encode the types at the very top, like there's five that were the most, let's say five of the most frequent, you still cover a very small percentage of the data."}, {"time": 3844, "text": "So you couldn't take that approach of saying, I'm just going to try to collect facts about these five or 10 types or 20 types or 50 types or whatever."}, {"time": 3854, "text": "So that was like one of the first things, like what do you do about that?"}, {"time": 3858, "text": "And so we came up with an approach toward that."}, {"time": 3861, "text": "And the approach looked promising, and we continued to improve our ability to handle that problem throughout the project."}, {"time": 3869, "text": "The other issue was that right from the outside, I said, we're not going to, I committed to doing this in three to five years."}, {"time": 3877, "text": "So we did it in four."}, {"time": 3879, "text": "So I got lucky."}, {"time": 3880, "text": "But one of the things that that, putting that like stake in the ground was, and I knew how hard the language understanding problem was."}, {"time": 3887, "text": "I said, we're not going to actually understand language to solve this problem."}, {"time": 3893, "text": "We are not going to interpret the question and the domain of knowledge that the question refers to and reason over that to answer these questions."}, {"time": 3902, "text": "Obviously we're not going to be doing that."}, {"time": 3904, "text": "At the same time, simple search wasn't good enough to confidently answer with a single correct answer."}, {"time": 3913, "text": "First of all, that's like brilliant."}, {"time": 3914, "text": "That's such a great mix of innovation and practical engineering three, four, eight."}, {"time": 3918, "text": "So you're not trying to solve the general NLU problem."}, {"time": 3921, "text": "You're saying, let's solve this in any way possible."}, {"time": 3926, "text": "No, I was committed to saying, look, we're going to solving the open domain question answering problem."}, {"time": 3931, "text": "We're using Jeopardy as a driver for that."}, {"time": 3933, "text": "That's a big benchmark."}, {"time": 3934, "text": "Good enough, big benchmark, exactly."}, {"time": 3936, "text": "And now we're."}, {"time": 3939, "text": "We could just like, whatever, like just figure out what works because I want to be able to go back to the academic science community and say, here's what we tried."}, {"time": 3945, "text": "Here's what worked."}, {"time": 3946, "text": "Here's what didn't work."}, {"time": 3948, "text": "I don't want to go in and say, oh, I only have one technology."}, {"time": 3951, "text": "I have a hammer."}, {"time": 3952, "text": "I'm only going to use this."}, {"time": 3953, "text": "I'm going to do whatever it takes."}, {"time": 3954, "text": "I'm like, I'm going to think out of the box and do whatever it takes."}, {"time": 3957, "text": "One, and I also, there was another thing I believed."}, {"time": 3960, "text": "I believed that the fundamental NLP technologies and machine learning technologies would be adequate."}, {"time": 3968, "text": "And this was an issue of how do we enhance them?"}, {"time": 3971, "text": "How do we integrate them?"}, {"time": 3973, "text": "How do we advance them?"}, {"time": 3975, "text": "So I had one researcher who came to me who had been working on question answering with me for a very long time, who had said, we're going to need Maxwell's equations for question answering."}, {"time": 3985, "text": "And I said, if we need some fundamental formula that breaks new ground in how we understand language, we're screwed."}, {"time": 3993, "text": "We're not going to get there from here."}, {"time": 3994, "text": "Like I am not counting."}, {"time": 3998, "text": "My assumption is I'm not counting on some brand new invention."}, {"time": 4002, "text": "What I'm counting on is the ability to take everything it has done before to figure out an architecture on how to integrate it well and then see where it breaks and make the necessary advances we need to make until this thing works."}, {"time": 4018, "text": "Push it hard to see where it breaks and then patch it up."}, {"time": 4021, "text": "I mean, that's how people change the world."}, {"time": 4023, "text": "I mean, that's the Elon Musk approach to the rockets, SpaceX, that's the Henry Ford and so on."}, {"time": 4029, "text": "And I happen to be, in this case, I happen to be right, but like we didn't know."}, {"time": 4034, "text": "But you kind of have to put a stake in the rest of how you're going to run the project."}, {"time": 4037, "text": "So yeah, and backtracking to search."}, {"time": 4040, "text": "So if you were to do, what's the brute force solution?"}, {"time": 4044, "text": "What would you search over?"}, {"time": 4046, "text": "So you have a question, how would you search the possible space of answers?"}, {"time": 4051, "text": "Look, web search has come a long way even since then."}, {"time": 4054, "text": "But at the time, first of all, I mean, there were a couple of other constraints around the problem, which is interesting."}, {"time": 4060, "text": "So you couldn't go out to the web."}, {"time": 4063, "text": "You couldn't search the internet."}, {"time": 4064, "text": "In other words, the AI experiment was, we want a self contained device."}, {"time": 4070, "text": "If the device is as big as a room, fine, it's as big as a room, but we want a self contained device."}, {"time": 4077, "text": "You're not going out to the internet."}, {"time": 4079, "text": "You don't have a lifeline to anything."}, {"time": 4081, "text": "So it had to kind of fit in a shoe box, if you will, or at least a size of a few refrigerators, whatever it might be."}, {"time": 4088, "text": "See, but also you couldn't just get out there."}, {"time": 4090, "text": "You couldn't go off network, right, to kind of go."}, {"time": 4093, "text": "So there was that limitation."}, {"time": 4094, "text": "But then we did, but the basic thing was go do web search."}, {"time": 4099, "text": "Problem was, even when we went and did a web search, I don't remember exactly the numbers, but somewhere in the order of 65% of the time, the answer would be somewhere, you know, in the top 10 or 20 documents."}, {"time": 4112, "text": "So first of all, that's not even good enough to play Jeopardy."}, {"time": 4116, "text": "You know, the words, even if you could pull the, even if you could perfectly pull the answer out of the top 20 documents, top 10 documents, whatever it was, which we didn't know how to do."}, {"time": 4125, "text": "But even if you could do that, you'd be, and you knew it was right, unless you had enough confidence in it, right?"}, {"time": 4130, "text": "So you'd have to pull out the right answer."}, {"time": 4132, "text": "You'd have to have confidence it was the right answer."}, {"time": 4134, "text": "And then you'd have to do that fast enough to now go buzz in and you'd still only get 65% of them right, which doesn't even put you in the winner's circle."}, {"time": 4142, "text": "Winner's circle, you have to be up over 70 and you have to do it really quick and you have to do it really quickly."}, {"time": 4148, "text": "But now the problem is, well, even if I had somewhere in the top 10 documents, how do I figure out where in the top 10 documents that answer is and how do I compute a confidence of all the possible candidates?"}, {"time": 4159, "text": "So it's not like I go in knowing the right answer and I have to pick it."}, {"time": 4162, "text": "I don't know the right answer."}, {"time": 4163, "text": "I have a bunch of documents, somewhere in there is the right answer."}, {"time": 4167, "text": "How do I, as a machine, go out and figure out which one's right?"}, {"time": 4170, "text": "And then how do I score it?"}, {"time": 4172, "text": "So, and now how do I deal with the fact that I can't actually go out to the web?"}, {"time": 4177, "text": "First of all, if you pause on that, just think about it."}, {"time": 4180, "text": "If you could go to the web, do you think that problem is solvable if you just pause on it?"}, {"time": 4185, "text": "Just thinking even beyond jeopardy, do you think the problem of reading text defined where the answer is?"}, {"time": 4193, "text": "Well, we solved that in some definition of solves given the jeopardy challenge."}, {"time": 4198, "text": "How did you do it for jeopardy?"}, {"time": 4199, "text": "So how do you take a body of work in a particular topic and extract the key pieces of information?"}, {"time": 4205, "text": "So now forgetting about the huge volumes that are on the web, right?"}, {"time": 4210, "text": "So now we have to figure out, we did a lot of source research."}, {"time": 4212, "text": "In other words, what body of knowledge is gonna be small enough, but broad enough to answer jeopardy?"}, {"time": 4219, "text": "And we ultimately did find the body of knowledge that did that."}, {"time": 4222, "text": "I mean, it included Wikipedia and a bunch of other stuff."}, {"time": 4225, "text": "So like encyclopedia type of stuff."}, {"time": 4226, "text": "I don't know if you can speak to it."}, {"time": 4227, "text": "Encyclopedias, dictionaries, different types of semantic resources, like WordNet and other types of semantic resources like that, as well as like some web crawls."}, {"time": 4236, "text": "In other words, where we went out and took that content and then expanded it based on producing, statistically producing seeds, using those seeds for other searches and then expanding that."}, {"time": 4248, "text": "So using these like expansion techniques, we went out and had found enough content and we're like, okay, this is good."}, {"time": 4254, "text": "And even up until the end, we had a thread of research."}, {"time": 4258, "text": "It was always trying to figure out what content could we efficiently include."}, {"time": 4262, "text": "I mean, there's a lot of popular, like what is the church lady?"}, {"time": 4265, "text": "Well, I think was one of the, like what, where do you, I guess that's probably an encyclopedia, so."}, {"time": 4272, "text": "So that was an encyclopedia, but then we would take that stuff and we would go out and we would expand."}, {"time": 4277, "text": "In other words, we'd go find other content that wasn't in the core resources and expand it."}, {"time": 4283, "text": "The amount of content, we grew it by an order of magnitude, but still, again, from a web scale perspective, this is very small amount of content."}, {"time": 4290, "text": "It's very select."}, {"time": 4291, "text": "We then took all that content, we preanalyzed the crap out of it, meaning we parsed it, broke it down into all those individual words and then we did semantic, syntactic and semantic parses on it, had computer algorithms that annotated it and we indexed that in a very rich and very fast index."}, {"time": 4313, "text": "So we have a relatively huge amount of, let's say the equivalent of, for the sake of argument, two to 5 million bucks."}, {"time": 4318, "text": "We've now analyzed all that, blowing up its size even more because now we have all this metadata and then we richly indexed all of that and by the way, in a giant in memory cache."}, {"time": 4328, "text": "So Watson did not go to disk."}, {"time": 4331, "text": "So the infrastructure component there, if you could just speak to it, how tough it, I mean, I know 2000, maybe this is 2008, nine, that's kind of a long time ago."}, {"time": 4345, "text": "How hard is it to use multiple machines?"}, {"time": 4348, "text": "How hard is the infrastructure component, the hardware component?"}, {"time": 4351, "text": "So we used IBM hardware."}, {"time": 4353, "text": "We had something like, I forgot exactly, but close to 3000 cores completely connected."}, {"time": 4360, "text": "So you had a switch where every CPU was connected to every other CPU."}, {"time": 4363, "text": "And they were sharing memory in some kind of way."}, {"time": 4366, "text": "Large shared memory, right?"}, {"time": 4367, "text": "And all this data was preanalyzed and put into a very fast indexing structure that was all in memory."}, {"time": 4378, "text": "And then we took that question, we would analyze the question."}, {"time": 4384, "text": "So all the content was now preanalyzed."}, {"time": 4387, "text": "So if I went and tried to find a piece of content, it would come back with all the metadata that we had precomputed."}, {"time": 4394, "text": "How do you shove that question?"}, {"time": 4396, "text": "How do you connect the big knowledge base with the metadata and that's indexed to the simple little witty confusing question?"}, {"time": 4407, "text": "So therein lies the Watson architecture, right?"}, {"time": 4411, "text": "So we would take the question, we would analyze the question."}, {"time": 4414, "text": "So which means that we would parse it and interpret it a bunch of different ways."}, {"time": 4418, "text": "We'd try to figure out what is it asking about?"}, {"time": 4420, "text": "So we had multiple strategies to kind of determine what was it asking for."}, {"time": 4427, "text": "That might be represented as a simple string, a character string, or something we would connect back to different semantic types that were from existing resources."}, {"time": 4436, "text": "So anyway, the bottom line is we would do a bunch of analysis in the question."}, {"time": 4440, "text": "And question analysis had to finish and had to finish fast."}, {"time": 4444, "text": "So we do the question analysis because then from the question analysis, we would now produce searches."}, {"time": 4449, "text": "So we would, and we had built using open source search engines, we modified them, but we had a number of different search engines we would use that had different characteristics."}, {"time": 4460, "text": "We went in there and engineered and modified those search engines, ultimately to now take our question analysis, produce multiple queries based on different interpretations of the question and fire out a whole bunch of searches in parallel."}, {"time": 4476, "text": "And they would come back with passages."}, {"time": 4479, "text": "So these are passive search algorithms."}, {"time": 4482, "text": "They would come back with passages."}, {"time": 4483, "text": "And so now let's say you had a thousand passages."}, {"time": 4487, "text": "Now for each passage, you parallelize again."}, {"time": 4490, "text": "So you went out and you parallelize the search."}, {"time": 4495, "text": "Each search would now come back with a whole bunch of passages."}, {"time": 4498, "text": "Maybe you had a total of a thousand or 5,000 whatever passages."}, {"time": 4502, "text": "For each passage now, you'd go and figure out whether or not there was a candidate, we'd call it candidate answer in there."}, {"time": 4508, "text": "So you had a whole bunch of other algorithms that would find candidate answers, possible answers to the question."}, {"time": 4515, "text": "And so you had candidate answer, called candidate answer generators, a whole bunch of those."}, {"time": 4520, "text": "So for every one of these components, the team was constantly doing research coming up, better ways to generate search queries from the questions, better ways to analyze the question, better ways to generate candidates."}, {"time": 4531, "text": "And speed, so better is accuracy and speed."}, {"time": 4535, "text": "Correct, so right, speed and accuracy for the most part were separated."}, {"time": 4540, "text": "We handle that sort of in separate ways."}, {"time": 4542, "text": "Like I focus purely on accuracy, end to end accuracy."}, {"time": 4545, "text": "Are we ultimately getting more questions and producing more accurate confidences?"}, {"time": 4548, "text": "And then a whole nother team that was constantly analyzing the workflow to find the bottlenecks."}, {"time": 4553, "text": "And then figuring out how to both parallelize and drive the algorithm speed."}, {"time": 4558, "text": "But anyway, so now think of it like, you have this big fan out now, right?"}, {"time": 4561, "text": "Because you had multiple queries, now you have thousands of candidate answers."}, {"time": 4566, "text": "For each candidate answer, you're gonna score it."}, {"time": 4569, "text": "So you're gonna use all the data that built up."}, {"time": 4572, "text": "You're gonna use the question analysis, you're gonna use how the query was generated, you're gonna use the passage itself, and you're gonna use the candidate answer that was generated, and you're gonna score that."}, {"time": 4585, "text": "So now we have a group of researchers coming up with scores."}, {"time": 4590, "text": "There are hundreds of different scores."}, {"time": 4592, "text": "So now you're getting a fan out of it again from however many candidate answers you have to all the different scores."}, {"time": 4599, "text": "So if you have 200 different scores and you have a thousand candidates, now you have 200,000 scores."}, {"time": 4605, "text": "And so now you gotta figure out, how do I now rank these answers based on the scores that came back?"}, {"time": 4614, "text": "And I wanna rank them based on the likelihood that they're a correct answer to the question."}, {"time": 4618, "text": "So every scorer was its own research project."}, {"time": 4621, "text": "What do you mean by scorer?"}, {"time": 4622, "text": "So is that the annotation process of basically a human being saying that this answer has a quality of?"}, {"time": 4654, "text": "So that's the annotation task."}, {"time": 4656, "text": "That's the annotation process."}, {"time": 4657, "text": "That's the scoring task."}, {"time": 4658, "text": "But scoring implies zero to one kind of continuous."}, {"time": 4662, "text": "You give it a zero to one score."}, {"time": 4662, "text": "So it's not a binary."}, {"time": 4664, "text": "No, you give it a score."}, {"time": 4666, "text": "Give it a zero to, yeah, exactly, zero to one score."}, {"time": 4668, "text": "But humans give different scores, so you have to somehow normalize and all that kind of stuff that deal with all that complexity."}, {"time": 4674, "text": "It depends on what your strategy is."}, {"time": 4675, "text": "We both, we..."}, {"time": 4677, "text": "It could be relative, too."}, {"time": 4678, "text": "It could be... We actually looked at the raw scores as well as standardized scores, because humans are not involved in this."}, {"time": 4684, "text": "Humans are not involved."}, {"time": 4685, "text": "Sorry, so I'm misunderstanding the process here."}, {"time": 4688, "text": "This is passages."}, {"time": 4690, "text": "Where is the ground truth coming from?"}, {"time": 4693, "text": "Ground truth is only the answers to the questions."}, {"time": 4696, "text": "So it's end to end."}, {"time": 4697, "text": "It's end to end."}, {"time": 4699, "text": "So I was always driving end to end performance."}, {"time": 4702, "text": "It's a very interesting, a very interesting engineering approach, and ultimately scientific research approach, always driving end to end."}, {"time": 4711, "text": "Now, that's not to say we wouldn't make hypotheses that individual component performance was related in some way to end to end performance."}, {"time": 4724, "text": "Of course we would, because people would have to build individual components."}, {"time": 4728, "text": "But ultimately, to get your component integrated to the system, you have to show impact on end to end performance, question answering performance."}, {"time": 4735, "text": "So there's many very smart people working on this, and they're basically trying to sell their ideas as a component that should be part of the system."}, {"time": 4744, "text": "And they would do research on their component, and they would say things like, I'm gonna improve this as a candidate generator, or I'm gonna improve this as a question score, or as a passive scorer, I'm gonna improve this, or as a parser, and I can improve it by 2% on its component metric, like a better parse, or a better candidate, or a better type estimation, whatever it is."}, {"time": 4770, "text": "And then I would say, I need to understand how the improvement on that component metric is gonna affect the end to end performance."}, {"time": 4777, "text": "If you can't estimate that, and can't do experiments to demonstrate that, it doesn't get in."}, {"time": 4783, "text": "That's like the best run AI project I've ever heard."}, {"time": 4788, "text": "Okay, what breakthrough would you say, like, I'm sure there's a lot of day to day breakthroughs, but was there like a breakthrough that really helped improve performance?"}, {"time": 4797, "text": "Like where people began to believe, or is it just a gradual process?"}, {"time": 4802, "text": "Well, I think it was a gradual process, but one of the things that I think gave people confidence that we can get there was that, as we follow this procedure of different ideas, build different components, plug them into the architecture, run the system, see how we do, do the error analysis, start off new research projects to improve things."}, {"time": 4828, "text": "And the very important idea that the individual component work did not have to deeply understand everything that was going on with every other component."}, {"time": 4842, "text": "And this is where we leverage machine learning in a very important way."}, {"time": 4847, "text": "So while individual components could be statistically driven machine learning components, some of them were heuristic, some of them were machine learning components, the system has a whole combined all the scores using machine learning."}, {"time": 4860, "text": "This was critical because that way you can divide and conquer."}, {"time": 4864, "text": "So you can say, okay, you work on your candidate generator, or you work on this approach to answer scoring, you work on this approach to type scoring, you work on this approach to passage search or to pass a selection and so forth."}, {"time": 4877, "text": "But when we just plug it in, and we had enough training data to say, now we can train and figure out how do we weigh all the scores relative to each other based on the predicting the outcome, which is right or wrong on Jeopardy."}, {"time": 4893, "text": "And we had enough training data to do that."}, {"time": 4896, "text": "So this enabled people to work independently and to let the machine learning do the integration."}, {"time": 4903, "text": "Beautiful, so yeah, the machine learning is doing the fusion, and then it's a human orchestrated ensemble of different approaches."}, {"time": 4913, "text": "Still impressive that you were able to get it done in a few years."}, {"time": 4917, "text": "That's not obvious to me that it's doable, if I just put myself in that mindset."}, {"time": 4923, "text": "But when you look back at the Jeopardy challenge, again, when you're looking up at the stars, what are you most proud of, looking back at those days?"}, {"time": 4937, "text": "I'm most proud of my, my commitment and my team's commitment to be true to the science, to not be afraid to fail."}, {"time": 4958, "text": "That's beautiful because there's so much pressure, because it is a public event, it is a public show, that you were dedicated to the idea."}, {"time": 4970, "text": "Do you think it was a success?"}, {"time": 4973, "text": "In the eyes of the world, it was a success."}, {"time": 4976, "text": "By your, I'm sure, exceptionally high standards, is there something you regret you would do differently?"}, {"time": 4983, "text": "It was a success."}, {"time": 4985, "text": "It was a success for our goal."}, {"time": 4988, "text": "Our goal was to build the most advanced open domain question answering system."}, {"time": 4994, "text": "We went back to the old problems that we used to try to solve, and we did dramatically better on all of them, as well as we beat Jeopardy."}, {"time": 5004, "text": "So we won at Jeopardy."}, {"time": 5005, "text": "So it was a success."}, {"time": 5008, "text": "It was, I worry that the community or the world would not understand it as a success because it came down to only one game."}, {"time": 5018, "text": "And I knew statistically speaking, this can be a huge technical success, and we could still lose that one game."}, {"time": 5023, "text": "And that's a whole nother theme of this, of the journey."}, {"time": 5027, "text": "But it was a success."}, {"time": 5030, "text": "It was not a success in natural language understanding, but that was not the goal."}, {"time": 5036, "text": "Yeah, that was, but I would argue, I understand what you're saying in terms of the science, but I would argue that the inspiration of it, right?"}, {"time": 5047, "text": "The, not a success in terms of solving natural language understanding."}, {"time": 5052, "text": "There was a success of being an inspiration to future challenges."}, {"time": 5058, "text": "That drive future efforts."}, {"time": 5061, "text": "What's the difference between how human being compete in Jeopardy and how Watson does it?"}, {"time": 5066, "text": "That's important in terms of intelligence."}, {"time": 5068, "text": "Yeah, so that actually came up very early on in the project also."}, {"time": 5072, "text": "In fact, I had people who wanted to be on the project who were early on, who sort of approached me once I committed to do it, had wanted to think about how humans do it."}, {"time": 5084, "text": "And they were, from a cognition perspective, like human cognition and how that should play."}, {"time": 5089, "text": "And I would not take them on the project because another assumption or another stake I put in the ground was, I don't really care how humans do this."}, {"time": 5100, "text": "At least in the context of this project."}, {"time": 5101, "text": "I need to build in the context of this project."}, {"time": 5103, "text": "In NLU and in building an AI that understands how it needs to ultimately communicate with humans, I very much care."}, {"time": 5111, "text": "So it wasn't that I didn't care in general."}, {"time": 5116, "text": "In fact, as an AI scientist, I care a lot about that, but I'm also a practical engineer and I committed to getting this thing done and I wasn't gonna get distracted."}, {"time": 5127, "text": "I had to kind of say, like, if I'm gonna get this done, I'm gonna chart this path."}, {"time": 5131, "text": "And this path says, we're gonna engineer a machine that's gonna get this thing done."}, {"time": 5137, "text": "And we know what search and NLP can do."}, {"time": 5141, "text": "We have to build on that foundation."}, {"time": 5144, "text": "If I come in and take a different approach and start wondering about how the human mind might or might not do this, I'm not gonna get there from here in the timeframe."}, {"time": 5154, "text": "I think that's a great way to lead the team."}, {"time": 5156, "text": "But now that it's done and there's one, when you look back, analyze what's the difference actually."}, {"time": 5163, "text": "So I was a little bit surprised actually to discover over time, as this would come up from time to time and we'd reflect on it, and talking to Ken Jennings a little bit and hearing Ken Jennings talk about how he answered questions, that it might've been closer to the way humans answer questions than I might've imagined previously."}, {"time": 5184, "text": "Because humans are probably in the game of Jeopardy!"}, {"time": 5187, "text": "at the level of Ken Jennings, are probably also cheating their way to winning, right?"}, {"time": 5195, "text": "Not cheating, but shallow."}, {"time": 5196, "text": "Well, they're doing shallow analysis."}, {"time": 5197, "text": "They're doing the fastest possible."}, {"time": 5199, "text": "They're doing shallow analysis."}, {"time": 5200, "text": "So they are very quickly analyzing the question and coming up with some key vectors or cues, if you will."}, {"time": 5209, "text": "And they're taking those cues and they're very quickly going through like their library of stuff, not deeply reasoning about what's going on."}, {"time": 5217, "text": "And then sort of like a lots of different, like what we would call these scores, would kind of score that in a very shallow way and then say, oh, boom, you know, that's what it is."}, {"time": 5228, "text": "And so it's interesting as we reflected on that."}, {"time": 5232, "text": "So we may be doing something that's not too far off from the way humans do it, but we certainly didn't approach it by saying, how would a human do this?"}, {"time": 5242, "text": "Now in elemental cognition, like the project I'm leading now, we ask those questions all the time because ultimately we're trying to do something that is to make the intelligence of the machine and the intelligence of the human very compatible."}, {"time": 5257, "text": "Well, compatible in the sense they can communicate with one another and they can reason with this shared understanding."}, {"time": 5264, "text": "So how they think about things and how they build answers, how they build explanations becomes a very important question to consider."}, {"time": 5272, "text": "So what's the difference between this open domain, but cold constructed question answering of Jeopardy and more something that requires understanding for shared communication with humans and machines?"}, {"time": 5290, "text": "Yeah, well, this goes back to the interpretation of what we were talking about before."}, {"time": 5295, "text": "Jeopardy, the system's not trying to interpret the question and it's not interpreting the content it's reusing with regard to any particular framework."}, {"time": 5303, "text": "I mean, it is parsing it and parsing the content and using grammatical cues and stuff like that."}, {"time": 5309, "text": "So if you think of grammar as a human framework in some sense, it has that, but when you get into the richer semantic frameworks, what do people, how do they think, what motivates them, what are the events that are occurring and why are they occurring and what causes what else to happen and where are things in time and space?"}, {"time": 5327, "text": "And like when you start thinking about how humans formulate and structure the knowledge that they acquire in their head and wasn't doing any of that."}, {"time": 5337, "text": "What do you think are the essential challenges of like free flowing communication, free flowing dialogue versus question answering even with the framework of the interpretation dialogue?"}, {"time": 5352, "text": "Do you see free flowing dialogue as a fundamentally more difficult than question answering even with shared interpretation?"}, {"time": 5363, "text": "So dialogue is important in a number of different ways."}, {"time": 5366, "text": "I mean, it's a challenge."}, {"time": 5392, "text": "So in some sense it needs to dialogue."}, {"time": 5395, "text": "That doesn't mean that it, sometimes people talk about dialogue and they think, you know, how do humans talk to like, talk to each other in a casual conversation and you can mimic casual conversations."}, {"time": 5411, "text": "We're not trying to mimic casual conversations."}, {"time": 5414, "text": "We're really trying to produce a machine whose goal is to help you think and help you reason about your answers and explain why."}, {"time": 5423, "text": "So instead of like talking to your friend down the street about having a small talk conversation with your friend down the street, this is more about like you would be communicating to the computer on Star Trek where like, what do you wanna think about?"}, {"time": 5436, "text": "Like, what do you wanna reason about?"}, {"time": 5437, "text": "I'm gonna tell you the information I have."}, {"time": 5438, "text": "I'm gonna have to summarize it."}, {"time": 5439, "text": "I'm gonna ask you questions."}, {"time": 5441, "text": "You're gonna answer those questions."}, {"time": 5442, "text": "I'm gonna go back and forth with you."}, {"time": 5444, "text": "I'm gonna figure out what your mental model is."}, {"time": 5446, "text": "I'm gonna now relate that to the information I have and present it to you in a way that you can understand it and then we could ask followup questions."}, {"time": 5454, "text": "So it's that type of dialogue that you wanna construct."}, {"time": 5458, "text": "It's more structured, it's more goal oriented, but it needs to be fluid."}, {"time": 5464, "text": "In other words, it has to be engaging and fluid."}, {"time": 5469, "text": "It has to be productive and not distracting."}, {"time": 5473, "text": "So there has to be a model of, in other words, the machine has to have a model of how humans think through things and discuss them."}, {"time": 5482, "text": "So basically a productive, rich conversation unlike this podcast."}, {"time": 5492, "text": "I'd like to think it's more similar to this podcast."}, {"time": 5494, "text": "I wasn't joking."}, {"time": 5497, "text": "I'll ask you about humor as well, actually."}, {"time": 5499, "text": "But what's the hardest part of that?"}, {"time": 5503, "text": "Because it seems we're quite far away as a community from that still to be able to, so one is having a shared understanding."}, {"time": 5513, "text": "That's, I think, a lot of the stuff you said with frameworks is quite brilliant."}, {"time": 5517, "text": "But just creating a smooth discourse."}, {"time": 5522, "text": "It feels clunky right now."}, {"time": 5525, "text": "Which aspects of this whole problem that you just specified of having a productive conversation is the hardest?"}, {"time": 5532, "text": "And that we're, or maybe any aspect of it you can comment on because it's so shrouded in mystery."}, {"time": 5540, "text": "So I think to do this you kind of have to be creative in the following sense."}, {"time": 5546, "text": "If I were to do this as purely a machine learning approach and someone said learn how to have a good, fluent, structured knowledge acquisition conversation, I'd go out and say, okay, I have to collect a bunch of data of people doing that."}, {"time": 5562, "text": "People reasoning well, having a good, structured conversation that both acquires knowledge efficiently as well as produces answers and explanations as part of the process."}, {"time": 5574, "text": "And you struggle."}, {"time": 5578, "text": "To collect the data."}, {"time": 5579, "text": "To collect the data because I don't know how much data is like that."}, {"time": 5582, "text": "Okay, there's one, there's a humorous commentary on the lack of rational discourse."}, {"time": 5588, "text": "But also even if it's out there, say it was out there, how do you actually annotate, like how do you collect an accessible example?"}, {"time": 5597, "text": "Right, so I think any problem like this where you don't have enough data to represent the phenomenon you want to learn, in other words you want, if you have enough data you could potentially learn the pattern."}, {"time": 5608, "text": "In an example like this it's hard to do."}, {"time": 5610, "text": "This is sort of a human sort of thing to do."}, {"time": 5614, "text": "What recently came out at IBM was the debater projects and it's interesting, right, because now you do have these structured dialogues, these debate things where they did use machine learning techniques to generate these debates."}, {"time": 5629, "text": "Dialogues are a little bit tougher in my opinion than generating a structured argument where you have lots of other structured arguments like this, you could potentially annotate that data and you could say this is a good response, this is a bad response in a particular domain."}, {"time": 5643, "text": "Here I have to be responsive and I have to be opportunistic with regard to what is the human saying."}, {"time": 5651, "text": "So I'm goal oriented in saying I want to solve the problem, I want to acquire the knowledge necessary, but I also have to be opportunistic and responsive to what the human is saying."}, {"time": 5661, "text": "So I think that it's not clear that we could just train on the body of data to do this, but we could bootstrap it."}, {"time": 5668, "text": "In other words, we can be creative and we could say, what do we think the structure of a good dialogue is that does this well?"}, {"time": 5675, "text": "And we can start to create that."}, {"time": 5677, "text": "If we can create that more programmatically, at least to get this process started and I can create a tool that now engages humans effectively, I could start generating data, I could start the human learning process and I can update my machine, but I could also start the automatic learning process as well, but I have to understand what features to even learn over."}, {"time": 5701, "text": "So I have to bootstrap the process a little bit first."}, {"time": 5704, "text": "And that's a creative design task that I could then use as input into a more automatic learning task."}, {"time": 5713, "text": "So some creativity in bootstrapping."}, {"time": 5716, "text": "What elements of a conversation do you think you would like to see?"}, {"time": 5721, "text": "So one of the benchmarks for me is humor, right?"}, {"time": 5725, "text": "That seems to be one of the hardest."}, {"time": 5727, "text": "And to me, the biggest contrast is sort of Watson."}, {"time": 5731, "text": "So one of the greatest sketches, comedy sketches of all time, right, is the SNL celebrity Jeopardy with Alex Trebek and Sean Connery and Burt Reynolds and so on, with Sean Connery commentating on Alex Trebek's while they're alive."}, {"time": 5749, "text": "And I think all of them are in the negative pointwise."}, {"time": 5752, "text": "So they're clearly all losing in terms of the game of Jeopardy, but they're winning in terms of comedy."}, {"time": 5758, "text": "So what do you think about humor in this whole interaction in the dialogue that's productive?"}, {"time": 5766, "text": "Or even just what humor represents to me is the same idea that you're saying about framework, because humor only exists within a particular human framework."}, {"time": 5778, "text": "So what do you think about humor?"}, {"time": 5779, "text": "What do you think about things like humor that connect to the kind of creativity you mentioned that's needed?"}, {"time": 5785, "text": "I think there's a couple of things going on there."}, {"time": 5786, "text": "So I sort of feel like, and I might be too optimistic this way, but I think that there are, we did a little bit about with puns in Jeopardy."}, {"time": 5799, "text": "We literally sat down and said, how do puns work?"}, {"time": 5803, "text": "And it's like wordplay, and you could formalize these things."}, {"time": 5806, "text": "So I think there's a lot aspects of humor that you could formalize."}, {"time": 5810, "text": "You could also learn humor."}, {"time": 5811, "text": "You could just say, what do people laugh at?"}, {"time": 5813, "text": "And if you have enough, again, if you have enough data to represent the phenomenon, you might be able to weigh the features and figure out what humans find funny and what they don't find funny."}, {"time": 5822, "text": "The machine might not be able to explain why the human is funny unless we sit back and think about that more formally."}, {"time": 5830, "text": "I think, again, I think you do a combination of both."}, {"time": 5832, "text": "And I'm always a big proponent of that."}, {"time": 5833, "text": "I think robust architectures and approaches are always a little bit combination of us reflecting and being creative about how things are structured, how to formalize them, and then taking advantage of large data and doing learning and figuring out how to combine these two approaches."}, {"time": 5849, "text": "I think there's another aspect to humor though, which goes to the idea that I feel like I can relate to the person telling the story."}, {"time": 5858, "text": "And I think that's an interesting theme in the whole AI theme, which is, do I feel differently when I know it's a robot?"}, {"time": 5868, "text": "And when I imagine that the robot is not conscious the way I'm conscious, when I imagine the robot does not actually have the experiences that I experience, do I find it funny?"}, {"time": 5880, "text": "Or do, because it's not as related, I don't imagine that the person's relating it to it the way I relate to it."}, {"time": 5887, "text": "I think this also, you see this in the arts and in entertainment where, sometimes you have savants who are remarkable at a thing, whether it's sculpture or it's music or whatever, but the people who get the most attention are the people who can evoke a similar emotional response, who can get you to emote, right?"}, {"time": 5910, "text": "About the way they are."}, {"time": 5911, "text": "In other words, who can basically make the connection from the artifact, from the music or the painting of the sculpture to the emotion and get you to share that emotion with them."}, {"time": 5922, "text": "And then, and that's when it becomes compelling."}, {"time": 5924, "text": "So they're communicating at a whole different level."}, {"time": 5926, "text": "They're just not communicating the artifact."}, {"time": 5929, "text": "They're communicating their emotional response to the artifact."}, {"time": 5931, "text": "And then you feel like, oh wow, I can relate to that person, I can connect to that, I can connect to that person."}, {"time": 5937, "text": "So I think humor has that aspect as well."}, {"time": 5940, "text": "So the idea that you can connect to that person, person being the critical thing, but we're also able to anthropomorphize objects pretty, robots and AI systems pretty well."}, {"time": 5955, "text": "So we're almost looking to make them human."}, {"time": 5958, "text": "So maybe from your experience with Watson, maybe you can comment on, did you consider that as part, well, obviously the problem of jeopardy doesn't require anthropomorphization, but nevertheless."}, {"time": 5970, "text": "Well, there was some interest in doing that."}, {"time": 5972, "text": "And that's another thing I didn't want to do because I didn't want to distract from the actual scientific task."}, {"time": 5979, "text": "I mean, humans do anthropomorphize and without necessarily a lot of work."}, {"time": 5985, "text": "I mean, you just put some eyes and a couple of eyebrow movements and you're getting humans to react emotionally."}, {"time": 5991, "text": "And I think you can do that."}, {"time": 5993, "text": "So I didn't mean to suggest that, that that connection cannot be mimicked."}, {"time": 6000, "text": "I think that connection can be mimicked and can produce that emotional response."}, {"time": 6007, "text": "I just wonder though, if you're told what's really going on, if you know that the machine is not conscious, not having the same richness of emotional reactions and understanding that it doesn't really share the understanding, but it's essentially just moving its eyebrow or drooping its eyes or making them bigger, whatever it's doing, just getting the emotional response, will you still feel it?"}, {"time": 6032, "text": "I think you probably would for a while."}, {"time": 6034, "text": "And then when it becomes more important that there's a deeper share of understanding, it may run flat, but I don't know."}, {"time": 6040, "text": "I'm pretty confident that majority of the world, even if you tell them how it works, well, it will not matter, especially if the machine herself says that she is conscious."}, {"time": 6055, "text": "That's very possible."}, {"time": 6056, "text": "So you, the scientist that made the machine is saying that this is how the algorithm works."}, {"time": 6062, "text": "Everybody will just assume you're lying and that there's a conscious being there."}, {"time": 6066, "text": "So you're deep into the science fiction genre now, but yeah."}, {"time": 6070, "text": "I don't think it's, it's actually psychology."}, {"time": 6072, "text": "I think it's not science fiction."}, {"time": 6073, "text": "I think it's reality."}, {"time": 6074, "text": "I think it's a really powerful one that we'll have to be exploring in the next few decades."}, {"time": 6080, "text": "It's a very interesting element of intelligence."}, {"time": 6083, "text": "So what do you think, we've talked about social constructs of intelligences and frameworks and the way humans kind of interpret information."}, {"time": 6096, "text": "So there's the Alan Turing with the Turing test."}, {"time": 6101, "text": "Watson accomplished something very impressive with Jeopardy."}, {"time": 6104, "text": "What do you think is a test that would impress the heck out of you that you saw that a computer could do?"}, {"time": 6112, "text": "They would say, this is crossing a kind of threshold that gives me pause in a good way."}, {"time": 6122, "text": "My expectations for AI are generally high."}, {"time": 6126, "text": "What does high look like by the way?"}, {"time": 6127, "text": "So not the threshold, test is a threshold."}, {"time": 6130, "text": "What do you think is the destination?"}, {"time": 6132, "text": "What do you think is the ceiling?"}, {"time": 6135, "text": "I think machines will in many measures will be better than us, will become more effective."}, {"time": 6141, "text": "In other words, better predictors about a lot of things than ultimately we can do."}, {"time": 6148, "text": "I think where they're gonna struggle is what we talked about before, which is relating to communicating with and understanding humans in deeper ways."}, {"time": 6160, "text": "And so I think that's a key point, like we can create the super parrot."}, {"time": 6164, "text": "What I mean by the super parrot is given enough data, a machine can mimic your emotional response, can even generate language that will sound smart and what someone else might say under similar circumstances."}, {"time": 6177, "text": "Like I would just pause on that, like that's the super parrot, right?"}, {"time": 6181, "text": "So given similar circumstances, moves its faces in similar ways, changes its tone of voice in similar ways, produces strings of language that would similar that a human might say, not necessarily being able to produce a logical interpretation or understanding that would ultimately satisfy a critical interrogation or a critical understanding."}, {"time": 6207, "text": "I think you just described me in a nutshell."}, {"time": 6210, "text": "So I think philosophically speaking, you could argue that that's all we're doing as human beings to work super parrots."}, {"time": 6217, "text": "So I was gonna say, it's very possible, you know, humans do behave that way too."}, {"time": 6222, "text": "And so upon deeper probing and deeper interrogation, you may find out that there isn't a shared understanding because I think humans do both."}, {"time": 6230, "text": "Like humans are statistical language model machines and they are capable reasoners."}, {"time": 6237, "text": "You know, they're both."}, {"time": 6239, "text": "And you don't know which is going on, right?"}, {"time": 6242, "text": "So, and I think it's an interesting problem."}, {"time": 6249, "text": "We talked earlier about like where we are in our social and political landscape."}, {"time": 6254, "text": "Can you distinguish someone who can string words together and sound like they know what they're talking about from someone who actually does?"}, {"time": 6264, "text": "Can you do that without dialogue, without interrogative or probing dialogue?"}, {"time": 6267, "text": "So it's interesting because humans are really good in their own mind, justifying or explaining what they hear because they project their understanding onto yours."}, {"time": 6278, "text": "So you could say, you could put together a string of words and someone will sit there and interpret it in a way that's extremely biased to the way they wanna interpret it."}, {"time": 6287, "text": "They wanna assume that you're an idiot and they'll interpret it one way."}, {"time": 6290, "text": "They will assume you're a genius and they'll interpret it another way that suits their needs."}, {"time": 6294, "text": "So this is tricky business."}, {"time": 6296, "text": "So I think to answer your question, as AI gets better and better, better and better mimic, you recreate the super parrots, we're challenged just as we are with, we're challenged with humans."}, {"time": 6308, "text": "Do you really know what you're talking about?"}, {"time": 6310, "text": "Do you have a meaningful interpretation, a powerful framework that you could reason over and justify your answers, justify your predictions and your beliefs, why you think they make sense."}, {"time": 6325, "text": "Can you convince me what the implications are?"}, {"time": 6328, "text": "So can you reason intelligently and make me believe that the implications of your prediction and so forth?"}, {"time": 6340, "text": "So what happens is it becomes reflective."}, {"time": 6344, "text": "My standard for judging your intelligence depends a lot on mine."}, {"time": 6349, "text": "But you're saying there should be a large group of people with a certain standard of intelligence that would be convinced by this particular AI system."}, {"time": 6362, "text": "Then they'll pass."}, {"time": 6363, "text": "There should be, but I think depending on the content, one of the problems we have there is that if that large community of people are not judging it with regard to a rigorous standard of objective logic and reason, you still have a problem."}, {"time": 6379, "text": "Like masses of people can be persuaded."}, {"time": 6383, "text": "The millennials, yeah."}, {"time": 6385, "text": "To turn their brains off."}, {"time": 6392, "text": "By the way, I have nothing against the millennials."}, {"time": 6393, "text": "No, I don't, I'm just, just."}, {"time": 6396, "text": "So you're a part of one of the great benchmarks, challenges of AI history."}, {"time": 6403, "text": "What do you think about AlphaZero, OpenAI5, AlphaStar accomplishments on video games recently, which are also, I think, at least in the case of Go, with AlphaGo and AlphaZero playing Go, was a monumental accomplishment as well."}, {"time": 6419, "text": "What are your thoughts about that challenge?"}, {"time": 6421, "text": "I think it was a giant landmark for AI."}, {"time": 6423, "text": "I think it was phenomenal."}, {"time": 6424, "text": "I mean, it was one of those other things nobody thought like solving Go was gonna be easy, particularly because it's hard for, particularly hard for humans."}, {"time": 6432, "text": "Hard for humans to learn, hard for humans to excel at."}, {"time": 6435, "text": "And so it was another measure, a measure of intelligence."}, {"time": 6441, "text": "It's very cool."}, {"time": 6442, "text": "I mean, it's very interesting what they did."}, {"time": 6445, "text": "And I loved how they solved the data problem, which again, they bootstrapped it and got the machine to play itself, to generate enough data to learn from."}, {"time": 6452, "text": "I think that was brilliant."}, {"time": 6453, "text": "I think that was great."}, {"time": 6455, "text": "And of course, the result speaks for itself."}, {"time": 6458, "text": "I think it makes us think about, again, it is, okay, what's intelligence?"}, {"time": 6462, "text": "What aspects of intelligence are important?"}, {"time": 6465, "text": "Can the Go machine help me make me a better Go player?"}, {"time": 6469, "text": "Is it an alien intelligence?"}, {"time": 6471, "text": "Am I even capable of, like again, if we put in very simple terms, it found the function, it found the Go function."}, {"time": 6479, "text": "Can I even comprehend the Go function?"}, {"time": 6480, "text": "Can I talk about the Go function?"}, {"time": 6482, "text": "Can I conceptualize the Go function, like whatever it might be?"}, {"time": 6485, "text": "So one of the interesting ideas of that system is that it plays against itself, right?"}, {"time": 6490, "text": "But there's no human in the loop there."}, {"time": 6492, "text": "So like you're saying, it could have by itself created an alien intelligence."}, {"time": 6499, "text": "Toward a Go, imagine you're sentencing, you're a judge and you're sentencing people, or you're setting policy, or you're making medical decisions, and you can't explain, you can't get anybody to understand what you're doing or why."}, {"time": 6517, "text": "So it's an interesting dilemma for the applications of AI."}, {"time": 6523, "text": "Do we hold AI to this accountability that says humans have to be willing to take responsibility for the decision?"}, {"time": 6536, "text": "In other words, can you explain why you would do the thing?"}, {"time": 6538, "text": "Will you get up and speak to other humans and convince them that this was a smart decision?"}, {"time": 6544, "text": "Is the AI enabling you to do that?"}, {"time": 6547, "text": "Can you get behind the logic that was made there?"}, {"time": 6550, "text": "Do you think, sorry to land on this point, because it's a fascinating one."}, {"time": 6555, "text": "It's a great goal for AI."}, {"time": 6557, "text": "Do you think it's achievable in many cases?"}, {"time": 6561, "text": "Or, okay, there's two possible worlds that we have in the future."}, {"time": 6565, "text": "One is where AI systems do like medical diagnosis or things like that, or drive a car without ever explaining to you why it fails when it does."}, {"time": 6576, "text": "That's one possible world and we're okay with it."}, {"time": 6580, "text": "Or the other where we are not okay with it and we really hold back the technology from getting too good before it's able to explain."}, {"time": 6588, "text": "Which of those worlds are more likely, do you think, and which are concerning to you or not?"}, {"time": 6593, "text": "I think the reality is it's gonna be a mix."}, {"time": 6596, "text": "I'm not sure I have a problem with that."}, {"time": 6597, "text": "I mean, I think there are tasks that are perfectly fine with machines show a certain level of performance and that level of performance is already better than humans."}, {"time": 6607, "text": "So for example, I don't know that I take driverless cars."}, {"time": 6611, "text": "If driverless cars learn how to be more effective drivers than humans but can't explain what they're doing, but bottom line, statistically speaking, they're 10 times safer than humans, I don't know that I care."}, {"time": 6624, "text": "I think when we have these edge cases when something bad happens and we wanna decide who's liable for that thing and who made that mistake and what do we do about that?"}, {"time": 6633, "text": "And I think those edge cases are interesting cases."}, {"time": 6636, "text": "And now do we go to designers of the AI and the AI says, I don't know if that's what it learned to do and it says, well, you didn't train it properly."}, {"time": 6643, "text": "You were negligent in the training data that you gave that machine."}, {"time": 6647, "text": "Like, how do we drive down the reliability?"}, {"time": 6649, "text": "So I think those are interesting questions."}, {"time": 6653, "text": "So the optimization problem there, sorry, is to create an AI system that's able to explain the lawyers away."}, {"time": 6661, "text": "I think it's gonna be interesting."}, {"time": 6664, "text": "I mean, I think this is where technology and social discourse are gonna get like deeply intertwined and how we start thinking about problems, decisions and problems like that."}, {"time": 6673, "text": "I think in other cases it becomes more obvious where it's like, why did you decide to give that person a longer sentence or deny them parole?"}, {"time": 6687, "text": "Again, policy decisions or why did you pick that treatment?"}, {"time": 6690, "text": "Like that treatment ended up killing that guy."}, {"time": 6692, "text": "Like, why was that a reasonable choice to make?"}, {"time": 6696, "text": "And people are gonna demand explanations."}, {"time": 6700, "text": "Now there's a reality though here."}, {"time": 6703, "text": "And the reality is that it's not, I'm not sure humans are making reasonable choices when they do these things."}, {"time": 6709, "text": "They are using statistical hunches, biases, or even systematically using statistical averages to make calls."}, {"time": 6719, "text": "This is what happened to my dad and if you saw the talk I gave about that."}, {"time": 6721, "text": "But they decided that my father was brain dead."}, {"time": 6727, "text": "He had went into cardiac arrest and it took a long time for the ambulance to get there and he was not resuscitated right away and so forth."}, {"time": 6734, "text": "And they came and they told me he was brain dead and why was he brain dead?"}, {"time": 6737, "text": "Because essentially they gave me a purely statistical argument under these conditions with these four features, 98% chance he's brain dead."}, {"time": 6745, "text": "I said, but can you just tell me not inductively, but deductively go there and tell me his brain's not functioning is the way for you to do that."}, {"time": 6752, "text": "And the protocol in response was, no, this is how we make this decision."}, {"time": 6757, "text": "I said, this is inadequate for me."}, {"time": 6759, "text": "I understand the statistics and I don't know how, there's a 2% chance he's still alive."}, {"time": 6764, "text": "I just don't know the specifics."}, {"time": 6766, "text": "I need the specifics of this case and I want the deductive logical argument about why you actually know he's brain dead."}, {"time": 6773, "text": "So I wouldn't sign the do not resuscitate."}, {"time": 6775, "text": "And I don't know, it was like they went through lots of procedures, it was a big long story, but the bottom was a fascinating story by the way, but how I reasoned and how the doctors reasoned through this whole process."}, {"time": 6785, "text": "But I don't know, somewhere around 24 hours later or something, he was sitting up in bed with zero brain damage."}, {"time": 6793, "text": "I mean, what lessons do you draw from that story, that experience?"}, {"time": 6799, "text": "That the data that's being used to make statistical inferences doesn't adequately reflect the phenomenon."}, {"time": 6835, "text": "And perhaps AI has a role to say the exact thing what you just said, which is perhaps this is a case you should think for yourself, you should reason deductively."}, {"time": 6848, "text": "Well, so it's hard because it's hard to know that."}, {"time": 6854, "text": "You'd have to go back and you'd have to have enough data to essentially say, and this goes back to how do we, this goes back to the case of how do we decide whether the AI is good enough to do a particular task and regardless of whether or not it produces an explanation."}, {"time": 6870, "text": "And what standard do we hold for that?"}, {"time": 6874, "text": "So if you look more broadly, for example, as my father, as a medical case, the medical system ultimately helped him a lot throughout his life, without it, he probably would have died much sooner."}, {"time": 6895, "text": "So overall, it sort of worked for him in sort of a net, net kind of way."}, {"time": 6902, "text": "Actually, I don't know that that's fair."}, {"time": 6904, "text": "But maybe not in that particular case, but overall, like the medical system overall does more good than bad."}, {"time": 6910, "text": "Yeah, the medical system overall was doing more good than bad."}, {"time": 6914, "text": "Now, there's another argument that suggests that wasn't the case, but for the sake of argument, let's say like that's, let's say a net positive."}, {"time": 6921, "text": "And I think you have to sit there and there and take that into consideration."}, {"time": 6924, "text": "Now you look at a particular use case, like for example, making this decision, have you done enough studies to know how good that prediction really is?"}, {"time": 6937, "text": "And have you done enough studies to compare it, to say, well, what if we dug in in a more direct, let's get the evidence, let's do the deductive thing and not use statistics here, how often would that have done better?"}, {"time": 6952, "text": "So you have to do the studies to know how good the AI actually is."}, {"time": 6956, "text": "And it's complicated because it depends how fast you have to make the decision."}, {"time": 6959, "text": "So if you have to make the decision super fast, you have no choice."}, {"time": 6964, "text": "If you have more time, right?"}, {"time": 6966, "text": "But if you're ready to pull the plug, and this is a lot of the argument that I had with a doctor, I said, what's he gonna do if you do it, what's gonna happen to him in that room if you do it my way?"}, {"time": 6976, "text": "You know, well, he's gonna die anyway."}, {"time": 6978, "text": "So let's do it my way then."}, {"time": 6980, "text": "I mean, it raises questions for our society to struggle with, as the case with your father, but also when things like race and gender start coming into play when certain, when judgments are made based on things that are complicated in our society, at least in the discourse."}, {"time": 7000, "text": "And it starts, you know, I think I'm safe to say that most of the violent crimes committed by males, so if you discriminate based, you know, it's a male versus female saying that if it's a male, more likely to commit the crime."}, {"time": 7016, "text": "This is one of my very positive and optimistic views of why the study of artificial intelligence, the process of thinking and reasoning logically and statistically, and how to combine them is so important for the discourse today, because it's causing a, regardless of what state AI devices are or not, it's causing this dialogue to happen."}, {"time": 7042, "text": "This is one of the most important dialogues that in my view, the human species can have right now, which is how to think well, how to reason well, how to understand our own cognitive biases and what to do about them."}, {"time": 7060, "text": "That has got to be one of the most important things we as a species can be doing, honestly."}, {"time": 7067, "text": "We are, we've created an incredibly complex society."}, {"time": 7071, "text": "We've created amazing abilities to amplify noise faster than we can amplify signal."}, {"time": 7079, "text": "We are challenged."}, {"time": 7081, "text": "We are deeply, deeply challenged."}, {"time": 7083, "text": "We have, you know, big segments of the population getting hit with enormous amounts of information."}, {"time": 7088, "text": "Do they know how to do critical thinking?"}, {"time": 7090, "text": "Do they know how to objectively reason?"}, {"time": 7094, "text": "Do they understand what they are doing, nevermind what their AI is doing?"}, {"time": 7099, "text": "This is such an important dialogue to be having."}, {"time": 7103, "text": "And, you know, we are fundamentally, our thinking can be and easily becomes fundamentally bias."}, {"time": 7111, "text": "And there are statistics and we shouldn't blind our, we shouldn't discard statistical inference, but we should understand the nature of statistical inference."}, {"time": 7120, "text": "As a society, as you know, we decide to reject statistical inference to favor understanding and deciding on the individual."}, {"time": 7137, "text": "We consciously make that choice."}, {"time": 7140, "text": "So even if the statistics said, even if the statistics said males are more likely to have, you know, to be violent criminals, we still take each person as an individual and we treat them based on the logic and the knowledge of that situation."}, {"time": 7160, "text": "We purposefully and intentionally reject the statistical inference."}, {"time": 7168, "text": "We do that out of respect for the individual."}, {"time": 7171, "text": "For the individual."}, {"time": 7172, "text": "Yeah, and that requires reasoning and thinking."}, {"time": 7175, "text": "Looking forward, what grand challenges would you like to see in the future?"}, {"time": 7178, "text": "Because the Jeopardy challenge, you know, captivated the world."}, {"time": 7185, "text": "AlphaGo, AlphaZero captivated the world."}, {"time": 7188, "text": "Deep Blue certainly beating Kasparov."}, {"time": 7191, "text": "Gary's bitterness aside captivated the world."}, {"time": 7195, "text": "What do you think, do you have ideas for next grand challenges for future challenges of that?"}, {"time": 7200, "text": "You know, look, I mean, I think there are lots of really great ideas for grand challenges."}, {"time": 7205, "text": "I'm particularly focused on one right now, which is, you know, can you demonstrate that they understand, that they could read and understand, that they can acquire these frameworks and communicate, you know, reason and communicate with humans."}, {"time": 7221, "text": "So it is kind of like the Turing test, but it's a little bit more demanding than the Turing test."}, {"time": 7226, "text": "It's not enough to convince me that you might be human because you could, you know, you can parrot a conversation."}, {"time": 7234, "text": "I think, you know, the standard is a little bit higher, is for example, can you, you know, the standard is higher."}, {"time": 7243, "text": "And I think one of the challenges of devising this grand challenge is that we're not sure what intelligence is, we're not sure how to determine whether or not two people actually understand each other and in what depth they understand it, you know, to what depth they understand each other."}, {"time": 7264, "text": "So the challenge becomes something along the lines of, can you satisfy me that we have a shared understanding?"}, {"time": 7274, "text": "So if I were to probe and probe and you probe me, can machines really act like thought partners where they can satisfy me that we have a shared, our understanding is shared enough that we can collaborate and produce answers together and that, you know, they can help me explain and justify those answers."}, {"time": 7296, "text": "So maybe here's an idea."}, {"time": 7298, "text": "So we'll have AI system run for president and convince."}, {"time": 7304, "text": "That's too easy."}, {"time": 7306, "text": "I'm sorry, go ahead."}, {"time": 7306, "text": "Well, no, you have to convince the voters that they should vote."}, {"time": 7311, "text": "So like, I guess what does winning look like?"}, {"time": 7313, "text": "Again, that's why I think this is such a challenge because we go back to the emotional persuasion."}, {"time": 7319, "text": "We go back to, you know, now we're checking off an aspect of human cognition that is in many ways weak or flawed, right, we're so easily manipulated."}, {"time": 7333, "text": "Our minds are drawn for often the wrong reasons, right?"}, {"time": 7339, "text": "Not the reasons that ultimately matter to us, but the reasons that can easily persuade us."}, {"time": 7343, "text": "I think we can be persuaded to believe one thing or another for reasons that ultimately don't serve us well in the longterm."}, {"time": 7353, "text": "And a good benchmark should not play with those elements of emotional manipulation."}, {"time": 7361, "text": "And I think that's where we have to set the higher standard for ourselves of what, you know, what does it mean?"}, {"time": 7367, "text": "This goes back to rationality and it goes back to objective thinking."}, {"time": 7370, "text": "And can you produce, can you acquire information and produce reasoned arguments and to those reasoned arguments pass a certain amount of muster and is it, and can you acquire new knowledge?"}, {"time": 7382, "text": "You know, can you, for example, can you reason, I have acquired new knowledge, can you identify where it's consistent or contradictory with other things you've learned?"}, {"time": 7392, "text": "And can you explain that to me and get me to understand that?"}, {"time": 7395, "text": "So I think another way to think about it perhaps is can a machine teach you, can it help you understand something that you didn't really understand before where it's taking you, so you're not, again, it's almost like can it teach you, can it help you learn and in an arbitrary space so it can open those domain space?"}, {"time": 7429, "text": "So can you tell the machine, and again, this borrows from some science fiction, but can you go off and learn about this topic that I'd like to understand better and then work with me to help me understand it?"}, {"time": 7442, "text": "That's quite brilliant."}, {"time": 7443, "text": "What, the machine that passes that kind of test, do you think it would need to have self awareness or even consciousness?"}, {"time": 7453, "text": "What do you think about consciousness and the importance of it maybe in relation to having a body, having a presence, an entity?"}, {"time": 7464, "text": "Do you think that's important?"}, {"time": 7466, "text": "You know, people used to ask me if Watson was conscious and I used to say, he's conscious of what exactly?"}, {"time": 7472, "text": "I mean, I think, you know, maybe it depends what it is that you're conscious of."}, {"time": 7476, "text": "I mean, like, so, you know, did it, if you, you know, it's certainly easy for it to answer questions about, it would be trivial to program it to answer questions about whether or not it was playing Jeopardy."}, {"time": 7487, "text": "I mean, it could certainly answer questions that would imply that it was aware of things."}, {"time": 7491, "text": "Exactly, what does it mean to be aware and what does it mean to be conscious of?"}, {"time": 7493, "text": "It's sort of interesting."}, {"time": 7494, "text": "I mean, I think that we differ from one another based on what we're conscious of."}, {"time": 7501, "text": "But wait, wait a minute, yes, for sure."}, {"time": 7502, "text": "There's degrees of consciousness in there, so."}, {"time": 7505, "text": "Well, and there's just areas."}, {"time": 7506, "text": "Like, it's not just degrees, what are you aware of?"}, {"time": 7510, "text": "Like, what are you not aware of?"}, {"time": 7511, "text": "But nevertheless, there's a very subjective element to our experience."}, {"time": 7516, "text": "Let me even not talk about consciousness."}, {"time": 7518, "text": "Let me talk about another, to me, really interesting topic of mortality, fear of mortality."}, {"time": 7525, "text": "Watson, as far as I could tell, did not have a fear of death."}, {"time": 7533, "text": "Most, most humans do."}, {"time": 7536, "text": "Wasn't conscious of death."}, {"time": 7539, "text": "It wasn't, yeah."}, {"time": 7540, "text": "So there's an element of finiteness to our existence that I think, like you mentioned, survival, that adds to the whole thing."}, {"time": 7549, "text": "I mean, consciousness is tied up with that, that we are a thing."}, {"time": 7552, "text": "It's a subjective thing that ends."}, {"time": 7556, "text": "And that seems to add a color and flavor to our motivations in a way that seems to be fundamentally important for intelligence, or at least the kind of human intelligence."}, {"time": 7567, "text": "Well, I think for generating goals, again, I think you could have, you could have an intelligence capability and a capability to learn, a capability to predict."}, {"time": 7578, "text": "But I think without, I mean, again, you get fear, but essentially without the goal to survive."}, {"time": 7587, "text": "So you think you can just encode that without having to really?"}, {"time": 7590, "text": "I think you could encode."}, {"time": 7591, "text": "I mean, you could create a robot now, and you could say, you know, plug it in, and say, protect your power source, you know, and give it some capabilities, and it'll sit there and operate to try to protect its power source and survive."}, {"time": 7602, "text": "I mean, so I don't know that that's philosophically a hard thing to demonstrate."}, {"time": 7606, "text": "It sounds like a fairly easy thing to demonstrate that you can give it that goal."}, {"time": 7610, "text": "Will it come up with that goal by itself?"}, {"time": 7612, "text": "I think you have to program that goal in."}, {"time": 7614, "text": "But there's something, because I think, as we touched on, intelligence is kind of like a social construct."}, {"time": 7621, "text": "The fact that a robot will be protecting its power source would add depth and grounding to its intelligence in terms of us being able to respect it."}, {"time": 7635, "text": "I mean, ultimately, it boils down to us acknowledging that it's intelligent."}, {"time": 7640, "text": "And the fact that it can die, I think, is an important part of that."}, {"time": 7646, "text": "The interesting thing to reflect on is how trivial that would be."}, {"time": 7649, "text": "And I don't think, if you knew how trivial that was, you would associate that with being intelligence."}, {"time": 7655, "text": "I mean, I literally put in a statement of code that says you have the following actions you can take."}, {"time": 7660, "text": "You give it a bunch of actions, like maybe you mount a laser gun on it, or you give it the ability to scream or screech or whatever."}, {"time": 7668, "text": "And you say, if you see your power source threatened, then you could program that in, and you're gonna take these actions to protect it."}, {"time": 7678, "text": "You know, you could train it on a bunch of things."}, {"time": 7682, "text": "So, and now you're gonna look at that and you say, well, you know, that's intelligence, which is protecting its power source?"}, {"time": 7686, "text": "Maybe, but that's, again, this human bias that says, the thing I identify, my intelligence and my conscious, so fundamentally with the desire, or at least the behaviors associated with the desire to survive, that if I see another thing doing that, I'm going to assume it's intelligent."}, {"time": 7707, "text": "What timeline, year, will society have something that would, that you would be comfortable calling an artificial general intelligence system?"}, {"time": 7719, "text": "Well, what's your intuition?"}, {"time": 7721, "text": "Nobody can predict the future, certainly not the next few months or 20 years away, but what's your intuition?"}, {"time": 7727, "text": "How far away are we?"}, {"time": 7730, "text": "It's hard to make these predictions."}, {"time": 7732, "text": "I mean, I would be guessing, and there's so many different variables, including just how much we want to invest in it and how important we think it is, what kind of investment we're willing to make in it, what kind of talent we end up bringing to the table, the incentive structure, all these things."}, {"time": 7750, "text": "So I think it is possible to do this sort of thing."}, {"time": 7755, "text": "I think it's, I think trying to sort of ignore many of the variables and things like that, is it a 10 year thing, is it a 23 year?"}, {"time": 7765, "text": "Probably closer to a 20 year thing, I guess."}, {"time": 7767, "text": "But not several hundred years."}, {"time": 7769, "text": "No, I don't think it's several hundred years."}, {"time": 7772, "text": "I don't think it's several hundred years."}, {"time": 7773, "text": "But again, so much depends on how committed we are to investing and incentivizing this type of work."}, {"time": 7783, "text": "And it's sort of interesting."}, {"time": 7785, "text": "Like, I don't think it's obvious how incentivized we are."}, {"time": 7790, "text": "I think from a task perspective, if we see business opportunities to take this technique or that technique to solve that problem, I think that's the main driver for many of these things."}, {"time": 7803, "text": "From a general intelligence, it's kind of an interesting question."}, {"time": 7806, "text": "Are we really motivated to do that?"}, {"time": 7809, "text": "And like, we just struggled ourselves right now to even define what it is."}, {"time": 7814, "text": "So it's hard to incentivize when we don't even know what it is we're incentivized to create."}, {"time": 7818, "text": "And if you said mimic a human intelligence, I just think there are so many challenges with the significance and meaning of that."}, {"time": 7827, "text": "That there's not a clear directive."}, {"time": 7829, "text": "There's no clear directive to do precisely that thing."}, {"time": 7832, "text": "So assistance in a larger and larger number of tasks."}, {"time": 7836, "text": "So being able to, a system that's particularly able to operate my microwave and making a grilled cheese sandwich."}, {"time": 7842, "text": "I don't even know how to make one of those."}, {"time": 7844, "text": "And then the same system will be doing the vacuum cleaning."}, {"time": 7848, "text": "And then the same system would be teaching my kids that I don't have math."}, {"time": 7856, "text": "I think that when you get into a general intelligence for learning physical tasks, and again, I wanna go back to your body question because I think your body question was interesting, but you wanna go back to learning the abilities to physical tasks."}, {"time": 7871, "text": "You might have, we might get, I imagine in that timeframe, we will get better and better at learning these kinds of tasks, whether it's mowing your lawn or driving a car or whatever it is."}, {"time": 7882, "text": "I think we will get better and better at that where it's learning how to make predictions over large bodies of data."}, {"time": 7887, "text": "I think we're gonna continue to get better and better at that."}, {"time": 7890, "text": "And machines will outpace humans in a variety of those things."}, {"time": 7895, "text": "The underlying mechanisms for doing that may be the same, meaning that maybe these are deep nets, there's infrastructure to train them, reusable components to get them to do different classes of tasks, and we get better and better at building these kinds of machines."}, {"time": 7913, "text": "You could argue that the general learning infrastructure in there is a form of a general type of intelligence."}, {"time": 7921, "text": "I think what starts getting harder is this notion of, can we effectively communicate and understand and build that shared understanding?"}, {"time": 7930, "text": "Because of the layers of interpretation that are required to do that, and the need for the machine to be engaged with humans at that level in a continuous basis."}, {"time": 7940, "text": "So how do you get the machine in the game?"}, {"time": 7943, "text": "How do you get the machine in the intellectual game?"}, {"time": 7946, "text": "Yeah, and to solve AGI, you probably have to solve that problem."}, {"time": 7951, "text": "You have to get the machine, so it's a little bit of a bootstrapping thing."}, {"time": 7953, "text": "Can we get the machine engaged in the intellectual game, but in the intellectual dialogue with the humans?"}, {"time": 7962, "text": "Are the humans sufficiently in intellectual dialogue with each other to generate enough data in this context?"}, {"time": 7969, "text": "And how do you bootstrap that?"}, {"time": 7971, "text": "Because every one of those conversations, every one of those conversations, those intelligent interactions, require so much prior knowledge that it's a challenge to bootstrap it."}, {"time": 7981, "text": "So the question is, and how committed?"}, {"time": 7985, "text": "So I think that's possible, but when I go back to, are we incentivized to do that?"}, {"time": 7990, "text": "I know we're incentivized to do the former."}, {"time": 7993, "text": "Are we incentivized to do the latter significantly enough?"}, {"time": 7995, "text": "Do people understand what the latter really is well enough?"}, {"time": 7998, "text": "Part of the elemental cognition mission is to try to articulate that better and better through demonstrations and through trying to craft these grand challenges and get people to say, look, this is a class of intelligence."}, {"time": 8010, "text": "This is a class of AI."}, {"time": 8011, "text": "Do we want this?"}, {"time": 8013, "text": "What is the potential of this?"}, {"time": 8015, "text": "What's the business potential?"}, {"time": 8017, "text": "What's the societal potential to that?"}, {"time": 8020, "text": "And to build up that incentive system around that."}, {"time": 8025, "text": "Yeah, I think if people don't understand yet, I think they will."}, {"time": 8027, "text": "I think there's a huge business potential here."}, {"time": 8029, "text": "So it's exciting that you're working on it."}, {"time": 8034, "text": "We kind of skipped over, but I'm a huge fan of physical presence of things."}, {"time": 8039, "text": "Do you think Watson had a body?"}, {"time": 8043, "text": "Do you think having a body adds to the interactive element between the AI system and a human, or just in general to intelligence?"}, {"time": 8054, "text": "So I think going back to that shared understanding bit, humans are very connected to their bodies."}, {"time": 8061, "text": "I mean, one of the challenges in getting an AI to kind of be a compatible human intelligence is that our physical bodies are generating a lot of features that make up the input."}, {"time": 8077, "text": "So in other words, our bodies are the tool we use to affect output, but they also generate a lot of input for our brains."}, {"time": 8086, "text": "So we generate emotion, we generate all these feelings, we generate all these signals that machines don't have."}, {"time": 8092, "text": "So machines don't have this as the input data and they don't have the feedback that says, I've gotten this emotion or I've gotten this idea, I now want to process it, and then it then affects me as a physical being, and I can play that out."}, {"time": 8112, "text": "In other words, I could realize the implications of that, implications again, on my mind body complex, I then process that, and the implications again, our internal features are generated, I learn from them, they have an effect on my mind body complex."}, {"time": 8126, "text": "So it's interesting when we think, do we want a human intelligence?"}, {"time": 8130, "text": "Well, if we want a human compatible intelligence, probably the best thing to do is to embed it in a human body."}, {"time": 8136, "text": "Just to clarify, and both concepts are beautiful, is humanoid robots, so robots that look like humans is one, or did you mean actually sort of what Elon Musk was working with Neuralink, really embedding intelligence systems to ride along human bodies?"}, {"time": 8159, "text": "No, I mean riding along is different."}, {"time": 8161, "text": "I meant like if you want to create an intelligence that is human compatible, meaning that it can learn and develop a shared understanding of the world around it, you have to give it a lot of the same substrate."}, {"time": 8175, "text": "Part of that substrate is the idea that it generates these kinds of internal features, like sort of emotional stuff, it has similar senses, it has to do a lot of the same things with those same senses, right?"}, {"time": 8188, "text": "So I think if you want that, again, I don't know that you want that."}, {"time": 8192, "text": "That's not my specific goal, I think that's a fascinating scientific goal, I think it has all kinds of other implications."}, {"time": 8197, "text": "That's sort of not the goal."}, {"time": 8199, "text": "I want to create, I think of it as I create intellectual thought partners for humans, so that kind of intelligence."}, {"time": 8207, "text": "I know there are other companies that are creating physical thought partners, physical partners for humans, but that's kind of not where I'm at."}, {"time": 8216, "text": "But the important point is that a big part of what we process is that physical experience of the world around us."}, {"time": 8228, "text": "On the point of thought partners, what role does an emotional connection, or forgive me, love, have to play in that thought partnership?"}, {"time": 8239, "text": "Is that something you're interested in, put another way, sort of having a deep connection, beyond intellectual?"}, {"time": 8249, "text": "With the AI?"}, {"time": 8250, "text": "Yeah, with the AI, between human and AI."}, {"time": 8252, "text": "Is that something that gets in the way of the rational discourse?"}, {"time": 8257, "text": "Is that something that's useful?"}, {"time": 8259, "text": "I worry about biases, obviously."}, {"time": 8261, "text": "So in other words, if you develop an emotional relationship with a machine, all of a sudden you start, are more likely to believe what it's saying, even if it doesn't make any sense."}, {"time": 8270, "text": "So I worry about that."}, {"time": 8273, "text": "But at the same time, I think the opportunity to use machines to provide human companionship is actually not crazy."}, {"time": 8279, "text": "And intellectual and social companionship is not a crazy idea."}, {"time": 8286, "text": "Do you have concerns, as a few people do, Elon Musk, Sam Harris, about long term existential threats of AI, and perhaps short term threats of AI?"}, {"time": 8298, "text": "We talked about bias, we talked about different misuses, but do you have concerns about thought partners, systems that are able to help us make decisions together as humans, somehow having a significant negative impact on society in the long term?"}, {"time": 8313, "text": "I think there are things to worry about."}, {"time": 8315, "text": "I think giving machines too much leverage is a problem."}, {"time": 8321, "text": "And what I mean by leverage is, is too much control over things that can hurt us, whether it's socially, psychologically, intellectually, or physically."}, {"time": 8331, "text": "And if you give the machines too much control, I think that's a concern."}, {"time": 8334, "text": "You forget about the AI, just once you give them too much control, human bad actors can hack them and produce havoc."}]}, {"title": "Jim Keller: Moore's Law, Microprocessors, and First Principles | Lex Fridman Podcast #70", "id": "Nb2tebYAaOA", "quotes": [{"time": 309, "text": "Which today there's a whole bunch of metrics about what that is."}, {"time": 313, "text": "And then in an organization of 1,000 people who build a computer, there's lots of different disciplines that you have to operate on."}, {"time": 325, "text": "And so..."}, {"time": 327, "text": "So there's a bunch of levels of abstraction in an organization like Intel and in your own vision, there's a lot of brilliance that comes in at every one of those layers."}, {"time": 339, "text": "Some of it is science, some of it is engineering, some of it is art, what's the most, if you could pick favorites, what's the most important, your favorite layer on these layers of abstractions?"}, {"time": 351, "text": "Where does the magic enter this hierarchy?"}, {"time": 355, "text": "I don't really care."}, {"time": 357, "text": "That's the fun, you know, I'm somewhat agnostic to that."}, {"time": 360, "text": "So I would say for relatively long periods of time, instruction sets are stable."}, {"time": 368, "text": "So the x86 instruction set, the ARM instruction set."}, {"time": 372, "text": "What's an instruction set?"}, {"time": 373, "text": "So it says, how do you encode the basic operations?"}, {"time": 376, "text": "Load, store, multiply, add, subtract, conditional, branch."}, {"time": 380, "text": "You know, there aren't that many interesting instructions."}, {"time": 383, "text": "Look, if you look at a program and it runs, you know, 90% of the execution is on 25 opcodes, you know, 25 instructions."}, {"time": 391, "text": "And those are stable, right?"}, {"time": 393, "text": "What does it mean, stable?"}, {"time": 395, "text": "Intel architecture's been around for 25 years."}, {"time": 399, "text": "And that's because the basics, you know, are defined a long time ago, right?"}, {"time": 405, "text": "Now, the way an old computer ran is you fetched instructions and you executed them in order."}, {"time": 412, "text": "Do the load, do the add, do the compare."}, {"time": 417, "text": "The way a modern computer works is you fetch large numbers of instructions, say 500."}, {"time": 423, "text": "And then you find the dependency graph between the instructions."}, {"time": 427, "text": "And then you execute in independent units those little micrographs."}, {"time": 435, "text": "So a modern computer, like people like to say, computers should be simple and clean."}, {"time": 440, "text": "But it turns out the market for simple, clean, slow computers is zero, right?"}, {"time": 446, "text": "We don't sell any simple, clean computers."}, {"time": 449, "text": "No, you can, how you build it can be clean, but the computer people want to buy, that's, say, in a phone or a data center, fetches a large number of instructions, computes the dependency graph, and then executes it in a way that gets the right answers."}, {"time": 469, "text": "And optimizes that graph somehow."}, {"time": 470, "text": "Yeah, they run deeply out of order."}, {"time": 473, "text": "And then there's semantics around how memory ordering works and other things work."}, {"time": 478, "text": "So the computer sort of has a bunch of bookkeeping tables that says what order should these operations finish in or appear to finish in?"}, {"time": 487, "text": "But to go fast, you have to fetch a lot of instructions and find all the parallelism."}, {"time": 492, "text": "Now, there's a second kind of computer, which we call GPUs today."}, {"time": 497, "text": "And I call it the difference."}, {"time": 499, "text": "There's found parallelism, like you have a program with a lot of dependent instructions."}, {"time": 504, "text": "You fetch a bunch and then you go figure out the dependency graph and you issue instructions out of order."}, {"time": 509, "text": "That's because you have one serial narrative to execute, which, in fact, can be done out of order."}, {"time": 515, "text": "Did you call it a narrative?"}, {"time": 518, "text": "Yeah, so humans think of serial narrative."}, {"time": 520, "text": "So read a book, right?"}, {"time": 522, "text": "There's a sentence after sentence after sentence, and there's paragraphs."}, {"time": 526, "text": "Now, you could diagram that."}, {"time": 529, "text": "Imagine you diagrammed it properly and you said, which sentences could be read in any order, any order without changing the meaning, right?"}, {"time": 539, "text": "That's a fascinating question to ask of a book, yeah."}, {"time": 542, "text": "Yeah, you could do that, right?"}, {"time": 544, "text": "So some paragraphs could be reordered, some sentences can be reordered."}, {"time": 548, "text": "You could say, he is tall and smart and X, right?"}, {"time": 555, "text": "And it doesn't matter the order of tall and smart."}, {"time": 559, "text": "But if you say the tall man is wearing a red shirt, what colors, you can create dependencies, right?"}, {"time": 568, "text": "And so GPUs, on the other hand, run simple programs on pixels, but you're given a million of them."}, {"time": 576, "text": "And the first order, the screen you're looking at doesn't care which order you do it in."}, {"time": 582, "text": "So I call that given parallelism."}, {"time": 584, "text": "Simple narratives around the large numbers of things where you can just say, it's parallel because you told me it was."}, {"time": 592, "text": "So found parallelism where the narrative is sequential, but you discover like little pockets of parallelism versus."}, {"time": 601, "text": "Turns out large pockets of parallelism."}, {"time": 603, "text": "Large, so how hard is it to discover?"}, {"time": 605, "text": "Well, how hard is it?"}, {"time": 606, "text": "That's just transistor count, right?"}, {"time": 608, "text": "So once you crack the problem, you say, here's how you fetch 10 instructions at a time."}, {"time": 613, "text": "Here's how you calculate the dependencies between them."}, {"time": 616, "text": "Here's how you describe the dependencies."}, {"time": 618, "text": "Here's, you know, these are pieces, right?"}, {"time": 620, "text": "So once you describe the dependencies, then it's just a graph."}, {"time": 627, "text": "Sort of, it's an algorithm that finds, what is that?"}, {"time": 631, "text": "I'm sure there's a graph theoretical answer here that's solvable."}, {"time": 635, "text": "In general, programs, modern programs that human beings write, how much found parallelism is there in them?"}, {"time": 645, "text": "What does 10X mean?"}, {"time": 647, "text": "So if you execute it in order, you would get what's called cycles per instruction, and it would be about, you know, three instructions, three cycles per instruction because of the latency of the operations and stuff."}, {"time": 662, "text": "And in a modern computer, excuse it, but like 0.2, 0.25 cycles per instruction."}, {"time": 668, "text": "So it's about, we today find 10X."}, {"time": 671, "text": "And there's two things."}, {"time": 673, "text": "One is the found parallelism in the narrative, right?"}, {"time": 677, "text": "And the other is the predictability of the narrative, right?"}, {"time": 681, "text": "So certain operations say, do a bunch of calculations, and if greater than one, do this, else do that."}, {"time": 690, "text": "That decision is predicted in modern computers to high 90% accuracy."}, {"time": 696, "text": "So branches happen a lot."}, {"time": 698, "text": "So imagine you have a decision to make every six instructions, which is about the average, right?"}, {"time": 703, "text": "But you want to fetch 500 instructions, figure out the graph, and execute them all in parallel."}, {"time": 708, "text": "That means you have, let's say, if you fetch 600 instructions and it's every six, you have to fetch, you have to predict 99 out of 100 branches correctly for that window to be effective."}, {"time": 722, "text": "Okay, so parallelism, you can't parallelize branches."}, {"time": 726, "text": "Or you can."}, {"time": 727, "text": "No, you can predict."}, {"time": 728, "text": "You can predict."}, {"time": 729, "text": "What does predicted branch mean?"}, {"time": 731, "text": "So imagine you do a computation over and over."}, {"time": 733, "text": "You're in a loop."}, {"time": 734, "text": "So while n is greater than one, do."}, {"time": 739, "text": "And you go through that loop a million times."}, {"time": 741, "text": "So every time you look at the branch, you say, it's probably still greater than one."}, {"time": 745, "text": "And you're saying you could do that accurately."}, {"time": 747, "text": "Very accurately."}, {"time": 748, "text": "Modern computers."}, {"time": 749, "text": "My mind is blown."}, {"time": 750, "text": "How the heck do you do that?"}, {"time": 752, "text": "Well, you want to know?"}, {"time": 753, "text": "This is really sad."}, {"time": 755, "text": "20 years ago, you simply recorded which way the branch went last time and predicted the same thing."}, {"time": 764, "text": "What's the accuracy of that?"}, {"time": 766, "text": "85%."}, {"time": 768, "text": "So then somebody said, hey, let's keep a couple of bits and have a little counter so when it predicts one way, we count up and then pins."}, {"time": 776, "text": "So say you have a three bit counter."}, {"time": 778, "text": "So you count up and then you count down."}, {"time": 780, "text": "And you can use the top bit as the signed bit so you have a signed two bit number."}, {"time": 785, "text": "So if it's greater than one, you predict taken."}, {"time": 787, "text": "And less than one, you predict not taken, right?"}, {"time": 791, "text": "Or less than zero, whatever the thing is."}, {"time": 794, "text": "And that got us to 92%."}, {"time": 797, "text": "Okay, no, it gets better."}, {"time": 799, "text": "This branch depends on how you got there."}, {"time": 802, "text": "So if you came down the code one way, you're talking about Bob and Jane, right?"}, {"time": 808, "text": "And then said, does Bob like Jane?"}, {"time": 810, "text": "It went one way."}, {"time": 811, "text": "But if you're talking about Bob and Jill, does Bob like Jane?"}, {"time": 813, "text": "You go a different way."}, {"time": 815, "text": "Right, so that's called history."}, {"time": 816, "text": "So you take the history and a counter."}, {"time": 820, "text": "That's cool, but that's not how anything works today."}, {"time": 823, "text": "They use something that looks a little like a neural network."}, {"time": 828, "text": "So modern, you take all the execution flows."}, {"time": 832, "text": "And then you do basically deep pattern recognition of how the program is executing."}, {"time": 839, "text": "And you do that multiple different ways."}, {"time": 843, "text": "And you have something that chooses what the best result is."}, {"time": 847, "text": "There's a little supercomputer inside the computer."}, {"time": 850, "text": "That's trying to predict branching."}, {"time": 851, "text": "That calculates which way branches go."}, {"time": 854, "text": "So the effective window that it's worth finding grass in gets bigger."}, {"time": 859, "text": "Why was that gonna make me sad?"}, {"time": 861, "text": "Because that's amazing."}, {"time": 862, "text": "It's amazingly complicated."}, {"time": 865, "text": "Well, here's the funny thing."}, {"time": 867, "text": "So to get to 85% took 1,000 bits."}, {"time": 871, "text": "To get to 99% takes tens of megabits."}, {"time": 878, "text": "So this is one of those, to get the result, to get from a window of say 50 instructions to 500, it took three orders of magnitude or four orders of magnitude more bits."}, {"time": 892, "text": "Now if you get the prediction of a branch wrong, what happens then?"}, {"time": 896, "text": "You flush the pipe."}, {"time": 897, "text": "You flush the pipe, so it's just the performance cost."}, {"time": 899, "text": "But it gets even better."}, {"time": 901, "text": "So we're starting to look at stuff that says, so they executed down this path, and then you had two ways to go."}, {"time": 909, "text": "But far away, there's something that doesn't matter which path you went."}, {"time": 914, "text": "So you took the wrong path."}, {"time": 917, "text": "You executed a bunch of stuff."}, {"time": 920, "text": "Then you had the mispredicting."}, {"time": 921, "text": "You backed it up."}, {"time": 922, "text": "You remembered all the results you already calculated."}, {"time": 925, "text": "Some of those are just fine."}, {"time": 927, "text": "Like if you read a book and you misunderstand a paragraph, your understanding of the next paragraph sometimes is invariant to that understanding."}, {"time": 935, "text": "Sometimes it depends on it."}, {"time": 938, "text": "And you can kind of anticipate that invariance."}, {"time": 943, "text": "Yeah, well, you can keep track of whether the data changed."}, {"time": 947, "text": "And so when you come back through a piece of code, should you calculate it again or do the same thing?"}, {"time": 951, "text": "Okay, how much of this is art and how much of it is science?"}, {"time": 955, "text": "Because it sounds pretty complicated."}, {"time": 959, "text": "Well, how do you describe a situation?"}, {"time": 960, "text": "So imagine you come to a point in the road where you have to make a decision, right?"}, {"time": 965, "text": "And you have a bunch of knowledge about which way to go."}, {"time": 967, "text": "Maybe you have a map."}, {"time": 968, "text": "So you wanna go the shortest way, or do you wanna go the fastest way, or do you wanna take the nicest road?"}, {"time": 974, "text": "So there's some set of data."}, {"time": 977, "text": "So imagine you're doing something complicated like building a computer."}, {"time": 981, "text": "And there's hundreds of decision points, all with hundreds of possible ways to go."}, {"time": 987, "text": "And the ways you pick interact in a complicated way."}, {"time": 993, "text": "And then you have to pick the right spot."}, {"time": 995, "text": "Right, so that's."}, {"time": 996, "text": "So that's art or science, I don't know."}, {"time": 997, "text": "You avoided the question."}, {"time": 998, "text": "You just described the Robert Frost problem of road less taken."}, {"time": 1003, "text": "I described the Robert Frost problem?"}, {"time": 1005, "text": "That's what we do as computer designers."}, {"time": 1009, "text": "It's all poetry."}, {"time": 1012, "text": "Yeah, I don't know how to describe that because some people are very good at making those intuitive leaps."}, {"time": 1017, "text": "It seems like just combinations of things."}, {"time": 1020, "text": "Some people are less good at it, but they're really good at evaluating the alternatives."}, {"time": 1025, "text": "Right, and everybody has a different way to do it."}, {"time": 1029, "text": "And some people can't make those leaps, but they're really good at analyzing it."}, {"time": 1034, "text": "So when you see computers are designed by teams of people who have very different skill sets."}, {"time": 1039, "text": "And a good team has lots of different kinds of people."}, {"time": 1044, "text": "I suspect you would describe some of them as artistic, but not very many."}, {"time": 1050, "text": "Unfortunately, or fortunately."}, {"time": 1053, "text": "Well, you know, computer design's hard."}, {"time": 1056, "text": "It's 99% perspiration."}, {"time": 1060, "text": "And the 1% inspiration is really important."}, {"time": 1064, "text": "But you still need the 99."}, {"time": 1065, "text": "Yeah, you gotta do a lot of work."}, {"time": 1067, "text": "And then there are interesting things to do at every level of that stack."}, {"time": 1072, "text": "So at the end of the day, if you run the same program multiple times, does it always produce the same result?"}, {"time": 1081, "text": "Is there some room for fuzziness there?"}, {"time": 1084, "text": "That's a math problem."}, {"time": 1086, "text": "So if you run a correct C program, the definition is every time you run it, you get the same answer."}, {"time": 1092, "text": "Yeah, well that's a math statement."}, {"time": 1094, "text": "But that's a language definitional statement."}, {"time": 1097, "text": "So for years when people did, when we first did 3D acceleration of graphics, you could run the same scene multiple times and get different answers."}, {"time": 1109, "text": "Right, and then some people thought that was okay and some people thought it was a bad idea."}, {"time": 1114, "text": "And then when the HPC world used GPUs for calculations, they thought it was a really bad idea."}, {"time": 1121, "text": "Okay, now in modern AI stuff, people are looking at networks where the precision of the data is low enough that the data is somewhat noisy."}, {"time": 1133, "text": "And the observation is the input data is unbelievably noisy."}, {"time": 1137, "text": "So why should the calculation be not noisy?"}, {"time": 1140, "text": "And people have experimented with algorithms that say can get faster answers by being noisy."}, {"time": 1145, "text": "Like as a network starts to converge, if you look at the computation graph, it starts out really wide and then it gets narrower."}, {"time": 1152, "text": "And you can say is that last little bit that important or should I start the graph on the next rev before we whittle it all the way down to the answer, right?"}, {"time": 1161, "text": "So you can create algorithms that are noisy."}, {"time": 1164, "text": "Now if you're developing something and every time you run it, you get a different answer, it's really annoying."}, {"time": 1169, "text": "And so most people think even today, every time you run the program, you get the same answer."}, {"time": 1176, "text": "No, I know, but the question is that's the formal definition of a programming language."}, {"time": 1182, "text": "There is a definition of languages that don't get the same answer, but people who use those, you always want something because you get a bad answer and then you're wondering is it because of something in the algorithm or because of this?"}, {"time": 1195, "text": "And so everybody wants a little switch that says no matter what, do it deterministically."}, {"time": 1200, "text": "And it's really weird because almost everything going into modern calculations is noisy."}, {"time": 1205, "text": "So why do the answers have to be so clear?"}, {"time": 1208, "text": "Right, so where do you stand?"}, {"time": 1209, "text": "I design computers for people who run programs."}, {"time": 1212, "text": "So if somebody says I want a deterministic answer, like most people want that."}, {"time": 1218, "text": "Can you deliver a deterministic answer, I guess is the question."}, {"time": 1221, "text": "Like when you."}, {"time": 1222, "text": "Yeah, hopefully, sure."}, {"time": 1224, "text": "What people don't realize is you get a deterministic answer even though the execution flow is very undeterministic."}, {"time": 1231, "text": "So you run this program 100 times, it never runs the same way twice, ever."}, {"time": 1236, "text": "And the answer, it arrives at the same answer."}, {"time": 1237, "text": "But it gets the same answer every time."}, {"time": 1239, "text": "It's just amazing."}, {"time": 1242, "text": "Okay, you've achieved, in the eyes of many people, legend status as a chip art architect."}, {"time": 1253, "text": "What design creation are you most proud of?"}, {"time": 1256, "text": "Perhaps because it was challenging, because of its impact, or because of the set of brilliant ideas that were involved in bringing it to life?"}, {"time": 1266, "text": "I find that description odd."}, {"time": 1270, "text": "And I have two small children, and I promise you, they think it's hilarious."}, {"time": 1275, "text": "This question."}, {"time": 1277, "text": "I do it for them."}, {"time": 1278, "text": "So I'm really interested in building computers."}, {"time": 1283, "text": "And I've worked with really, really smart people."}, {"time": 1287, "text": "I'm not unbelievably smart."}, {"time": 1290, "text": "I'm fascinated by how they go together, both as a thing to do and as an endeavor that people do."}, {"time": 1298, "text": "How people and computers go together?"}, {"time": 1300, "text": "Like how people think and build a computer."}, {"time": 1304, "text": "And I find sometimes that the best computer architects aren't that interested in people, or the best people managers aren't that good at designing computers."}, {"time": 1314, "text": "So the whole stack of human beings is fascinating."}, {"time": 1316, "text": "So the managers, the individual engineers."}, {"time": 1319, "text": "Yeah, I said I realized after a lot of years of building computers, where you sort of build them out of transistors, logic gates, functional units, computational elements, that you could think of people the same way, so people are functional units."}, {"time": 1332, "text": "And then you could think of organizational design as a computer architecture problem."}, {"time": 1336, "text": "And then it was like, oh, that's super cool, because the people are all different, just like the computational elements are all different."}, {"time": 1343, "text": "And they like to do different things."}, {"time": 1345, "text": "And so I had a lot of fun reframing how I think about organizations."}, {"time": 1351, "text": "Just like with computers, we were saying execution paths, you can have a lot of different paths that end up at the same good destination."}, {"time": 1361, "text": "So what have you learned about the human abstractions from individual functional human units to the broader organization?"}, {"time": 1371, "text": "What does it take to create something special?"}, {"time": 1375, "text": "Well, most people don't think simple enough."}, {"time": 1380, "text": "All right, so the difference between a recipe and the understanding."}, {"time": 1384, "text": "There's probably a philosophical description of this."}, {"time": 1389, "text": "So imagine you're gonna make a loaf of bread."}, {"time": 1391, "text": "The recipe says get some flour, add some water, add some yeast, mix it up, let it rise, put it in a pan, put it in the oven."}, {"time": 1399, "text": "It's a recipe."}, {"time": 1401, "text": "Understanding bread, you can understand biology, supply chains, grain grinders, yeast, physics, thermodynamics, there's so many levels of understanding."}, {"time": 1417, "text": "And then when people build and design things, they frequently are executing some stack of recipes."}, {"time": 1425, "text": "And the problem with that is the recipes all have limited scope."}, {"time": 1428, "text": "Like if you have a really good recipe book for making bread, it won't tell you anything about how to make an omelet."}, {"time": 1434, "text": "But if you have a deep understanding of cooking, right, than bread, omelets, you know, sandwich, you know, there's a different way of viewing everything."}, {"time": 1447, "text": "And most people, when you get to be an expert at something, you know, you're hoping to achieve deeper understanding, not just a large set of recipes to go execute."}, {"time": 1460, "text": "And it's interesting to walk groups of people because executing recipes is unbelievably efficient if it's what you want to do."}, {"time": 1470, "text": "If it's not what you want to do, you're really stuck."}, {"time": 1474, "text": "And that difference is crucial."}, {"time": 1476, "text": "And everybody has a balance of, let's say, deeper understanding of recipes."}, {"time": 1480, "text": "And some people are really good at recognizing when the problem is to understand something deeply."}, {"time": 1489, "text": "It totally makes sense, does every stage of development, deep understanding on the team needed?"}, {"time": 1495, "text": "Oh, this goes back to the art versus science question."}, {"time": 1499, "text": "If you constantly unpack everything for deeper understanding, you never get anything done."}, {"time": 1504, "text": "And if you don't unpack understanding when you need to, you'll do the wrong thing."}, {"time": 1509, "text": "And then at every juncture, like human beings are these really weird things because everything you tell them has a million possible outputs, right?"}, {"time": 1518, "text": "And then they all interact in a hilarious way."}, {"time": 1521, "text": "Yeah, it's very interesting."}, {"time": 1521, "text": "And then having some intuition about what you tell them, what you do, when do you intervene, when do you not, it's complicated."}, {"time": 1529, "text": "It's essentially computationally unsolvable."}, {"time": 1533, "text": "Yeah, it's an intractable problem, sure."}, {"time": 1536, "text": "Humans are a mess."}, {"time": 1537, "text": "But with deep understanding, do you mean also sort of fundamental questions of things like what is a computer?"}, {"time": 1551, "text": "Or why, like the why questions, why are we even building this, like of purpose?"}, {"time": 1558, "text": "Or do you mean more like going towards the fundamental limits of physics, sort of really getting into the core of the science?"}, {"time": 1567, "text": "In terms of building a computer, think a little simpler."}, {"time": 1571, "text": "So common practice is you build a computer, and then when somebody says, I wanna make it 10% faster, you'll go in and say, all right, I need to make this buffer bigger, and maybe I'll add an add unit."}, {"time": 1583, "text": "Or I have this thing that's three instructions wide, I'm gonna make it four instructions wide."}, {"time": 1587, "text": "And what you see is each piece gets incrementally more complicated, right?"}, {"time": 1594, "text": "And then at some point you hit this limit, like adding another feature or buffer doesn't seem to make it any faster."}, {"time": 1601, "text": "And then people will say, well, that's because it's a fundamental limit."}, {"time": 1605, "text": "And then somebody else will look at it and say, well, actually the way you divided the problem up and the way the different features are interacting is limiting you, and it has to be rethought, rewritten."}, {"time": 1616, "text": "So then you refactor it and rewrite it, and what people commonly find is the rewrite is not only faster, but half as complicated."}, {"time": 1623, "text": "From scratch?"}, {"time": 1625, "text": "So how often in your career, but just have you seen is needed, maybe more generally, to just throw the whole thing out and start over?"}, {"time": 1634, "text": "This is where I'm on one end of it, every three to five years."}, {"time": 1639, "text": "Which end are you on?"}, {"time": 1641, "text": "Rewrite more often."}, {"time": 1642, "text": "Rewrite, and three to five years is?"}, {"time": 1645, "text": "If you wanna really make a lot of progress on computer architecture, every five years you should do one from scratch."}, {"time": 1651, "text": "So where does the x86.64 standard come in?"}, {"time": 1656, "text": "How often do you?"}, {"time": 1658, "text": "I was the coauthor of that spec in 98."}, {"time": 1662, "text": "That's 20 years ago."}, {"time": 1663, "text": "Yeah, so that's still around."}, {"time": 1665, "text": "The instruction set itself has been extended quite a few times."}, {"time": 1670, "text": "And instruction sets are less interesting than the implementation underneath."}, {"time": 1674, "text": "There's been, on x86 architecture, Intel's designed a few, AIM designed a few very different architectures."}, {"time": 1682, "text": "And I don't wanna go into too much of the detail about how often, but there's a tendency to rewrite it every 10 years, and it really should be every five."}, {"time": 1695, "text": "So you're saying you're an outlier in that sense."}, {"time": 1700, "text": "Well, and here's the problem."}, {"time": 1700, "text": "Isn't that scary?"}, {"time": 1703, "text": "Well, scary to who?"}, {"time": 1705, "text": "To everybody involved, because like you said, repeating the recipe is efficient."}, {"time": 1710, "text": "Companies wanna make money."}, {"time": 1714, "text": "No, individual engineers wanna succeed, so you wanna incrementally improve, increase the buffer from three to four."}, {"time": 1721, "text": "Well, this is where you get into the diminishing return curves."}, {"time": 1725, "text": "I think Steve Jobs said this, right?"}, {"time": 1726, "text": "So every, you have a project, and you start here, and it goes up, and you have diminishing return."}, {"time": 1732, "text": "And to get to the next level, you have to do a new one, and the initial starting point will be lower than the old optimization point, but it'll get higher."}, {"time": 1741, "text": "So now you have two kinds of fear, short term disaster and long term disaster."}, {"time": 1747, "text": "And you're, you're haunted."}, {"time": 1748, "text": "So grown ups, right, like, you know, people with a quarter by quarter business objective are terrified about changing everything."}, {"time": 1757, "text": "And people who are trying to run a business or build a computer for a long term objective know that the short term limitations block them from the long term success."}, {"time": 1769, "text": "So if you look at leaders of companies that had really good long term success, every time they saw that they had to redo something, they did."}, {"time": 1779, "text": "And so somebody has to speak up."}, {"time": 1781, "text": "Or you do multiple projects in parallel, like you optimize the old one while you build a new one."}, {"time": 1786, "text": "But the marketing guys are always like, make promise me that the new computer is faster on every single thing."}, {"time": 1792, "text": "And the computer architect says, well, the new computer will be faster on the average, but there's a distribution of results and performance, and you'll have some outliers that are slower."}, {"time": 1801, "text": "And that's very hard, because they have one customer who cares about that one."}, {"time": 1805, "text": "So speaking of the long term, for over 50 years now, Moore's Law has served, for me and millions of others, as an inspiring beacon of what kind of amazing future brilliant engineers can build."}, {"time": 1819, "text": "I'm just making your kids laugh all of today."}, {"time": 1821, "text": "That was great."}, {"time": 1823, "text": "So first, in your eyes, what is Moore's Law, if you could define for people who don't know?"}, {"time": 1829, "text": "Well, the simple statement was, from Gordon Moore, was double the number of transistors every two years."}, {"time": 1839, "text": "And then my operational model is, we increase the performance of computers by two X every two or three years."}, {"time": 1848, "text": "And it's wiggled around substantially over time."}, {"time": 1851, "text": "And also, in how we deliver, performance has changed."}, {"time": 1855, "text": "But the foundational idea was two X to transistors every two years."}, {"time": 1862, "text": "The current cadence is something like, they call it a shrink factor, like 0.6 every two years, which is not 0.5."}, {"time": 1871, "text": "But that's referring strictly, again, to the original definition of just."}, {"time": 1875, "text": "A transistor count."}, {"time": 1876, "text": "A shrink factor's just getting them smaller and smaller and smaller."}, {"time": 1879, "text": "Well, it's for a constant chip area."}, {"time": 1881, "text": "If you make the transistors smaller by 0.6, then you get one over 0.6 more transistors."}, {"time": 1887, "text": "So can you linger on it a little longer?"}, {"time": 1889, "text": "What's a broader, what do you think should be the broader definition of Moore's Law?"}, {"time": 1893, "text": "When you mentioned how you think of performance, just broadly, what's a good way to think about Moore's Law?"}, {"time": 1902, "text": "Well, first of all, I've been aware of Moore's Law for 30 years."}, {"time": 1908, "text": "In which sense?"}, {"time": 1909, "text": "Well, I've been designing computers for 40."}, {"time": 1912, "text": "You're just watching it before your eyes kind of thing."}, {"time": 1916, "text": "And somewhere where I became aware of it, I was also informed that Moore's Law was gonna die in 10 to 15 years."}, {"time": 1922, "text": "And then I thought that was true at first."}, {"time": 1923, "text": "But then after 10 years, it was gonna die in 10 to 15 years."}, {"time": 1927, "text": "And then at one point, it was gonna die in five years."}, {"time": 1929, "text": "And then it went back up to 10 years."}, {"time": 1931, "text": "And at some point, I decided not to worry about that particular prognostication for the rest of my life, which is fun."}, {"time": 1939, "text": "And then I joined Intel and everybody said Moore's Law is dead."}, {"time": 1942, "text": "And I thought that's sad, because it's the Moore's Law company."}, {"time": 1945, "text": "And it's not dead."}, {"time": 1946, "text": "And it's always been gonna die."}, {"time": 1949, "text": "And humans like these apocryphal kind of statements, like we'll run out of food, or we'll run out of air, or we'll run out of room, or we'll run out of something."}, {"time": 1959, "text": "Right, but it's still incredible that it's lived for as long as it has."}, {"time": 1964, "text": "And yes, there's many people who believe now that Moore's Law is dead."}, {"time": 1970, "text": "You know, they can join the last 50 years of people who had the same idea."}, {"time": 1973, "text": "Yeah, there's a long tradition."}, {"time": 1975, "text": "But why do you think, if you can try to understand it, why do you think it's not dead?"}, {"time": 1983, "text": "Well, let's just think, people think Moore's Law is one thing, transistors get smaller."}, {"time": 1989, "text": "But actually, under the sheet, there's literally thousands of innovations."}, {"time": 1992, "text": "And almost all those innovations have their own diminishing return curves."}, {"time": 1997, "text": "So if you graph it, it looks like a cascade of diminishing return curves."}, {"time": 2001, "text": "I don't know what to call that."}, {"time": 2002, "text": "But the result is an exponential curve."}, {"time": 2006, "text": "Well, at least it has been."}, {"time": 2007, "text": "So, and we keep inventing new things."}, {"time": 2010, "text": "So if you're an expert in one of the things on a diminishing return curve, right, and you can see it's plateau, you will probably tell people, well, this is done."}, {"time": 2022, "text": "Meanwhile, some other pile of people are doing something different."}, {"time": 2026, "text": "So that's just normal."}, {"time": 2028, "text": "So then there's the observation of how small could a switching device be?"}, {"time": 2034, "text": "So a modern transistor is something like a thousand by a thousand by a thousand atoms, right?"}, {"time": 2039, "text": "And you get quantum effects down around two to 10 atoms."}, {"time": 2044, "text": "So you can imagine the transistor as small as 10 by 10 by 10."}, {"time": 2048, "text": "So that's a million times smaller."}, {"time": 2052, "text": "And then the quantum computational people are working away at how to use quantum effects."}, {"time": 2060, "text": "A thousand by a thousand by a thousand."}, {"time": 2061, "text": "Atoms."}, {"time": 2063, "text": "That's a really clean way of putting it."}, {"time": 2066, "text": "Well, a fan, like a modern transistor, if you look at the fan, it's like 120 atoms wide, but we can make that thinner."}, {"time": 2073, "text": "And then there's a gate wrapped around it, and then there's spacing."}, {"time": 2076, "text": "There's a whole bunch of geometry."}, {"time": 2078, "text": "And a competent transistor designer could count both atoms in every single direction."}, {"time": 2088, "text": "Like there's techniques now to already put down atoms in a single atomic layer."}, {"time": 2093, "text": "And you can place atoms if you want to."}, {"time": 2095, "text": "It's just from a manufacturing process, if placing an atom takes 10 minutes and you need to put 10 to the 23rd atoms together to make a computer, it would take a long time."}, {"time": 2108, "text": "So the methods are both shrinking things and then coming up with effective ways to control what's happening."}, {"time": 2117, "text": "Manufacture stably and cheaply."}, {"time": 2121, "text": "So the innovation stock's pretty broad."}, {"time": 2123, "text": "There's equipment, there's optics, there's chemistry, there's physics, there's material science, there's metallurgy, there's lots of ideas about when you put different materials together, how do they interact, are they stable, is it stable over temperature, like are they repeatable?"}, {"time": 2140, "text": "There's like literally thousands of technologies involved."}, {"time": 2145, "text": "But just for the shrinking, you don't think we're quite yet close to the fundamental limits of physics?"}, {"time": 2150, "text": "I did a talk on Moore's Law and I asked for a roadmap to a path of 100 and after two weeks, they said we only got to 50."}, {"time": 2158, "text": "100 what, sorry?"}, {"time": 2159, "text": "100 X shrink."}, {"time": 2160, "text": "100 X shrink?"}, {"time": 2161, "text": "We only got to 50."}, {"time": 2162, "text": "And I said, why don't you give it another two weeks?"}, {"time": 2165, "text": "Well, here's the thing about Moore's Law, right?"}, {"time": 2169, "text": "So I believe that the next 10 or 20 years of shrinking is gonna happen, right?"}, {"time": 2176, "text": "Now, as a computer designer, you have two stances."}, {"time": 2180, "text": "You think it's going to shrink, in which case you're designing and thinking about architecture in a way that you'll use more transistors."}, {"time": 2189, "text": "Or conversely, not be swamped by the complexity of all the transistors you get, right?"}, {"time": 2196, "text": "You have to have a strategy, you know?"}, {"time": 2199, "text": "So you're open to the possibility and waiting for the possibility of a whole new army of transistors ready to work."}, {"time": 2205, "text": "I'm expecting more transistors every two or three years by a number large enough that how you think about design, how you think about architecture has to change."}, {"time": 2217, "text": "Like, imagine you build buildings out of bricks, and every year the bricks are half the size, or every two years."}, {"time": 2225, "text": "Well, if you kept building bricks the same way, so many bricks per person per day, the amount of time to build a building would go up exponentially, right?"}, {"time": 2236, "text": "But if you said, I know that's coming, so now I'm gonna design equipment that moves bricks faster, uses them better, because maybe you're getting something out of the smaller bricks, more strength, thinner walls, you know, less material, efficiency out of that."}, {"time": 2250, "text": "So once you have a roadmap with what's gonna happen, transistors, we're gonna get more of them, then you design all this collateral around it to take advantage of it, and also to cope with it."}, {"time": 2262, "text": "Like, that's the thing people don't understand."}, {"time": 2263, "text": "It's like, if I didn't believe in Moore's Law, and then Moore's Law transistors showed up, my design teams would all drown."}, {"time": 2270, "text": "So what's the hardest part of this inflow of new transistors?"}, {"time": 2277, "text": "I mean, even if you just look historically, throughout your career, what's the thing, what fundamentally changes when you add more transistors in the task of designing an architecture?"}, {"time": 2290, "text": "Well, there's two constants, right?"}, {"time": 2292, "text": "One is people don't get smarter."}, {"time": 2296, "text": "By the way, there's some science showing that we do get smarter because of nutrition or whatever."}, {"time": 2301, "text": "Sorry to bring that up."}, {"time": 2302, "text": "Blend effect."}, {"time": 2303, "text": "Yeah, I'm familiar with it."}, {"time": 2304, "text": "Nobody understands it, nobody knows if it's still going on."}, {"time": 2306, "text": "So that's a... Or whether it's real or not."}, {"time": 2308, "text": "But yeah, it's a..."}, {"time": 2310, "text": "I sort of..."}, {"time": 2311, "text": "Anyway, but not exponentially."}, {"time": 2312, "text": "I would believe for the most part, people aren't getting much smarter."}, {"time": 2315, "text": "The evidence doesn't support it, that's right."}, {"time": 2317, "text": "And then teams can't grow that much."}, {"time": 2320, "text": "Right, so human beings, you know, we're really good in teams of 10, you know, up to teams of 100, they can know each other."}, {"time": 2328, "text": "Beyond that, you have to have organizational boundaries."}, {"time": 2330, "text": "So you're kind of, you have, those are pretty hard constraints, right?"}, {"time": 2334, "text": "So then you have to divide and conquer, like as the designs get bigger, you have to divide it into pieces."}, {"time": 2340, "text": "You know, the power of abstraction layers is really high."}, {"time": 2343, "text": "We used to build computers out of transistors."}, {"time": 2346, "text": "Now we have a team that turns transistors into logic cells and another team that turns them into functional units, another one that turns them into computers, right?"}, {"time": 2353, "text": "So we have abstraction layers in there and you have to think about when do you shift gears on that."}, {"time": 2361, "text": "We also use faster computers to build faster computers."}, {"time": 2364, "text": "So some algorithms run twice as fast on new computers, but a lot of algorithms are N squared."}, {"time": 2370, "text": "So, you know, a computer with twice as many transistors and it might take four times as long to run."}, {"time": 2376, "text": "So you have to refactor the software."}, {"time": 2379, "text": "Like simply using faster computers to build bigger computers doesn't work."}, {"time": 2384, "text": "So you have to think about all these things."}, {"time": 2386, "text": "So in terms of computing performance and the exciting possibility that more powerful computers bring, is shrinking the thing which you've been talking about, for you, one of the biggest exciting possibilities of advancement in performance?"}, {"time": 2401, "text": "Or is there other directions that you're interested in, like in the direction of sort of enforcing given parallelism or like doing massive parallelism in terms of many, many CPUs, you know, stacking CPUs on top of each other, that kind of parallelism or any kind of parallelism?"}, {"time": 2420, "text": "Well, think about it a different way."}, {"time": 2422, "text": "So old computers, you know, slow computers, you said A equal B plus C times D, pretty simple, right?"}, {"time": 2430, "text": "And then we made faster computers with vector units and you can do proper equations and matrices, right?"}, {"time": 2438, "text": "And then modern like AI computations or like convolutional neural networks, where you convolve one large data set against another."}, {"time": 2447, "text": "And so there's sort of this hierarchy of mathematics, you know, from simple equation to linear equations, to matrix equations, to deeper kind of computation."}, {"time": 2458, "text": "And the data sets are getting so big that people are thinking of data as a topology problem."}, {"time": 2464, "text": "You know, data is organized in some immense shape."}, {"time": 2467, "text": "And then the computation, which sort of wants to be, get data from immense shape and do some computation on it."}, {"time": 2475, "text": "So what computers have allowed people to do is have algorithms go much, much further."}, {"time": 2482, "text": "So that paper you reference, the Sutton paper, they talked about, you know, like when AI started, it was apply rule sets to something."}, {"time": 2491, "text": "That's a very simple computational situation."}, {"time": 2495, "text": "And then when they did first chess thing, they solved deep searches."}, {"time": 2499, "text": "So have a huge database of moves and results, deep search, but it's still just a search, right?"}, {"time": 2508, "text": "Now we take large numbers of images and we use it to train these weight sets that we convolve across."}, {"time": 2516, "text": "It's a completely different kind of phenomena."}, {"time": 2518, "text": "We call that AI."}, {"time": 2519, "text": "Now they're doing the next generation."}, {"time": 2522, "text": "And if you look at it, they're going up this mathematical graph, right?"}, {"time": 2527, "text": "And then computations, both computation and data sets support going up that graph."}, {"time": 2533, "text": "Yeah, the kind of computation that might, I mean, I would argue that all of it is still a search, right?"}, {"time": 2540, "text": "Just like you said, a topology problem with data sets, you're searching the data sets for valuable data and also the actual optimization of neural networks is a kind of search for the..."}, {"time": 2553, "text": "I don't know, if you had looked at the interlayers of finding a cat, it's not a search."}, {"time": 2559, "text": "It's a set of endless projections."}, {"time": 2561, "text": "So, you know, a projection, here's a shadow of this phone, right?"}, {"time": 2565, "text": "And then you can have a shadow of that on the something and a shadow on that of something."}, {"time": 2569, "text": "And if you look in the layers, you'll see this layer actually describes pointy ears and round eyeness and fuzziness."}, {"time": 2576, "text": "But the computation to tease out the attributes is not search."}, {"time": 2583, "text": "Like the inference part might be search, but the training's not search."}, {"time": 2587, "text": "And then in deep networks, they look at layers and they don't even know it's represented."}, {"time": 2594, "text": "And yet, if you take the layers out, it doesn't work."}, {"time": 2596, "text": "So I don't think it's search."}, {"time": 2598, "text": "But you'd have to talk to a mathematician about what that actually is."}, {"time": 2602, "text": "Well, we could disagree, but it's just semantics, I think, it's not, but it's certainly not..."}, {"time": 2609, "text": "I would say it's absolutely not semantics, but..."}, {"time": 2611, "text": "Okay, all right, well, if you want to go there."}, {"time": 2617, "text": "So optimization to me is search, and we're trying to optimize the ability of a neural network to detect cat ears."}, {"time": 2625, "text": "And the difference between chess and the space, the incredibly multidimensional, 100,000 dimensional space that neural networks are trying to optimize over is nothing like the chessboard database."}, {"time": 2642, "text": "So it's a totally different kind of thing."}, {"time": 2644, "text": "And okay, in that sense, you can say it loses the meaning."}, {"time": 2647, "text": "I can see how you might say, if you..."}, {"time": 2651, "text": "The funny thing is, it's the difference between given search space and found search space."}, {"time": 2657, "text": "Yeah, maybe that's a different way to describe it."}, {"time": 2658, "text": "That's a beautiful way to put it, okay."}, {"time": 2659, "text": "But you're saying, what's your sense in terms of the basic mathematical operations and the architectures, computer hardware that enables those operations?"}, {"time": 2669, "text": "Do you see the CPUs of today still being a really core part of executing those mathematical operations?"}, {"time": 2678, "text": "Well, the operations continue to be add, subtract, load, store, compare, and branch."}, {"time": 2684, "text": "It's remarkable."}, {"time": 2686, "text": "So it's interesting, the building blocks of computers or transistors under that atoms."}, {"time": 2692, "text": "So you got atoms, transistors, logic gates, computers, functional units of computers."}, {"time": 2698, "text": "The building blocks of mathematics at some level are things like adds and subtracts and multiplies, but the space mathematics can describe is, I think, essentially infinite."}, {"time": 2711, "text": "But the computers that run the algorithms are still doing the same things."}, {"time": 2716, "text": "Now, a given algorithm might say, I need sparse data, or I need 32 bit data, or I need, you know, like a convolution operation that naturally takes eight bit data, multiplies it, and sums it up a certain way."}, {"time": 2731, "text": "So like the data types in TensorFlow imply an optimization set."}, {"time": 2738, "text": "But when you go right down and look at the computers, it's and and or gates doing adds and multiplies."}, {"time": 2742, "text": "Like that hasn't changed much."}, {"time": 2746, "text": "Now, the quantum researchers think they're going to change that radically, and then there's people who think about analog computing because you look in the brain, and it seems to be more analogish."}, {"time": 2755, "text": "You know, that maybe there's a way to do that more efficiently."}, {"time": 2759, "text": "But we have a million X on computation, and I don't know the relationship between computational, let's say, intensity and ability to hit mathematical abstractions."}, {"time": 2775, "text": "I don't know any way to describe that, but just like you saw in AI, you went from rule sets to simple search to complex search to, say, found search."}, {"time": 2786, "text": "Like those are orders of magnitude more computation to do."}, {"time": 2791, "text": "And as we get the next two orders of magnitude, like a friend, Roger Gaduri, said, like every order of magnitude changes the computation."}, {"time": 2800, "text": "Fundamentally changes what the computation is doing."}, {"time": 2804, "text": "Oh, you know the expression the difference in quantity is the difference in kind."}, {"time": 2809, "text": "You know, the difference between ant and anthill, right?"}, {"time": 2813, "text": "Or neuron and brain."}, {"time": 2816, "text": "You know, there's this indefinable place where the quantity changed the quality, right?"}, {"time": 2822, "text": "And we've seen that happen in mathematics multiple times, and you know, my guess is it's going to keep happening."}, {"time": 2828, "text": "So your sense is, yeah, if you focus head down and shrinking the transistor."}, {"time": 2834, "text": "Well, it's not just head down, we're aware of the software stacks that are running in the computational loads, and we're kind of pondering what do you do with a petabyte of memory that wants to be accessed in a sparse way and have, you know, the kind of calculations AI programmers want."}, {"time": 2852, "text": "So there's a dialogue interaction, but when you go in the computer chip, you know, you find adders and subtractors and multipliers."}, {"time": 2863, "text": "So if you zoom out then with, as you mentioned very sudden, the idea that most of the development in the last many decades in AI research came from just leveraging computation and just simple algorithms waiting for the computation to improve."}, {"time": 2880, "text": "Well, software guys have a thing that they call it the problem of early optimization."}, {"time": 2887, "text": "So you write a big software stack, and if you start optimizing like the first thing you write, the odds of that being the performance limiter is low."}, {"time": 2895, "text": "But when you get the whole thing working, can you make it 2x faster by optimizing the right things?"}, {"time": 2901, "text": "While you're optimizing that, could you have written a new software stack, which would have been a better choice?"}, {"time": 2907, "text": "Now you have creative tension."}, {"time": 2910, "text": "But the whole time as you're doing the writing, that's the software we're talking about."}, {"time": 2914, "text": "The hardware underneath gets faster and faster."}, {"time": 2916, "text": "Well, this goes back to the Moore's law."}, {"time": 2918, "text": "If Moore's law is going to continue, then your AI research should expect that to show up, and then you make a slightly different set of choices then."}, {"time": 2928, "text": "We've hit the wall."}, {"time": 2929, "text": "Nothing's going to happen."}, {"time": 2931, "text": "And from here, it's just us rewriting algorithms."}, {"time": 2935, "text": "That seems like a failed strategy for the last 30 years of Moore's law's death."}, {"time": 2940, "text": "So can you just linger on it?"}, {"time": 2943, "text": "I think you've answered it, but I'll just ask the same dumb question over and over."}, {"time": 2946, "text": "So why do you think Moore's law is not going to die?"}, {"time": 2952, "text": "Which is the most promising, exciting possibility of why it won't die in the next 5, 10 years?"}, {"time": 2957, "text": "So is it the continued shrinking of the transistor, or is it another S curve that steps in and it totally sort of matches up?"}, {"time": 2966, "text": "Shrinking the transistor is literally thousands of innovations."}, {"time": 2970, "text": "Right, so there's stacks of S curves in there."}, {"time": 2973, "text": "There's a whole bunch of S curves just kind of running their course and being reinvented and new things."}, {"time": 2981, "text": "The semiconductor fabricators and technologists have all announced what's called nanowires."}, {"time": 2987, "text": "So they took a fan, which had a gate around it, and turned that into little wires so you have better control of that, and they're smaller."}, {"time": 2995, "text": "And then from there, there are some obvious steps about how to shrink that."}, {"time": 2999, "text": "The metallurgy around wire stacks and stuff has very obvious abilities to shrink."}, {"time": 3007, "text": "And there's a whole combination of things there to do."}, {"time": 3011, "text": "Your sense is that we're going to get a lot if this innovation performed just that, shrinking."}, {"time": 3016, "text": "Yeah, like a factor of 100 is a lot."}, {"time": 3019, "text": "Yeah, I would say that's incredible."}, {"time": 3022, "text": "And it's totally unknown."}, {"time": 3023, "text": "It's only 10 or 15 years."}, {"time": 3025, "text": "Now, you're smarter, you might know, but to me it's totally unpredictable of what that 100x would bring in terms of the nature of the computation that people would be."}, {"time": 3034, "text": "Yeah, are you familiar with Bell's law?"}, {"time": 3037, "text": "So for a long time, it was mainframes, minis, workstation, PC, mobile."}, {"time": 3042, "text": "Moore's law drove faster, smaller computers."}, {"time": 3046, "text": "And then when we were thinking about Moore's law, Rajagaduri said, every 10x generates a new computation."}, {"time": 3053, "text": "So scalar, vector, matrix, topological computation."}, {"time": 3061, "text": "And if you go look at the industry trends, there was mainframes, and then minicomputers, and then PCs, and then the internet took off."}, {"time": 3068, "text": "And then we got mobile devices."}, {"time": 3070, "text": "And now we're building 5G wireless with one millisecond latency."}, {"time": 3074, "text": "And people are starting to think about the smart world where everything knows you, recognizes you."}, {"time": 3083, "text": "The transformations are going to be unpredictable."}, {"time": 3087, "text": "How does it make you feel that you're one of the key architects of this kind of future?"}, {"time": 3095, "text": "So we're not talking about the architects of the high level people who build the Angry Bird apps, and Snapchat."}, {"time": 3103, "text": "Angry Bird apps."}, {"time": 3105, "text": "Maybe that's the whole point of the universe."}, {"time": 3107, "text": "I'm going to take a stand at that, and the attention distracting nature of mobile phones."}, {"time": 3112, "text": "I'll take a stand."}, {"time": 3113, "text": "But anyway, in terms of the side effects of smartphones, or the attention distraction, which part?"}, {"time": 3123, "text": "Well, who knows where this is all leading?"}, {"time": 3126, "text": "It's changing so fast."}, {"time": 3128, "text": "My parents used to yell at my sisters for hiding in the closet with a wired phone with a dial on it."}, {"time": 3133, "text": "Stop talking to your friends all day."}, {"time": 3135, "text": "Now my wife yells at my kids for talking to their friends all day on text."}, {"time": 3140, "text": "It looks the same to me."}, {"time": 3141, "text": "It's always echoes of the same thing."}, {"time": 3143, "text": "But you are one of the key people architecting the hardware of this future."}, {"time": 3150, "text": "Do you feel responsible?"}, {"time": 3153, "text": "Do you feel excited?"}, {"time": 3156, "text": "So we're in a social context."}, {"time": 3158, "text": "So there's billions of people on this planet."}, {"time": 3160, "text": "There are literally millions of people working on technology."}, {"time": 3165, "text": "I feel lucky to be doing what I do and getting paid for it, and there's an interest in it."}, {"time": 3172, "text": "But there's so many things going on in parallel."}, {"time": 3176, "text": "The actions are so unpredictable."}, {"time": 3178, "text": "If I wasn't here, somebody else would do it."}, {"time": 3181, "text": "The vectors of all these different things are happening all the time."}, {"time": 3186, "text": "You know, there's a, I'm sure, some philosopher or metaphilosopher is wondering about how we transform our world."}, {"time": 3196, "text": "So you can't deny the fact that these tools are changing our world."}, {"time": 3205, "text": "Do you think it's changing for the better?"}, {"time": 3209, "text": "I read this thing recently."}, {"time": 3211, "text": "It said the two disciplines with the highest GRE scores in college are physics and philosophy."}, {"time": 3219, "text": "And they're both sort of trying to answer the question, why is there anything?"}, {"time": 3223, "text": "And the philosophers are on the kind of theological side, and the physicists are obviously on the material side."}, {"time": 3232, "text": "And there's 100 billion galaxies with 100 billion stars."}, {"time": 3236, "text": "It seems, well, repetitive at best."}, {"time": 3241, "text": "So you know, there's on our way to 10 billion people."}, {"time": 3246, "text": "I mean, it's hard to say what it's all for, if that's what you're asking."}, {"time": 3249, "text": "Yeah, I guess I am."}, {"time": 3251, "text": "Things do tend to significantly increase in complexity."}, {"time": 3256, "text": "And I'm curious about how computation, like our physical world inherently generates mathematics."}, {"time": 3265, "text": "It's kind of obvious, right?"}, {"time": 3266, "text": "So we have x, y, z coordinates."}, {"time": 3268, "text": "You take a sphere, you make it bigger."}, {"time": 3270, "text": "You get a surface that grows by r squared."}, {"time": 3274, "text": "Like, it generally generates mathematics."}, {"time": 3276, "text": "And the mathematicians and the physicists have been having a lot of fun talking to each other for years."}, {"time": 3281, "text": "And computation has been, let's say, relatively pedestrian."}, {"time": 3286, "text": "Like, computation in terms of mathematics has been doing binary algebra, while those guys have been gallivanting through the other realms of possibility."}, {"time": 3298, "text": "Now recently, the computation lets you do mathematical computations that are sophisticated enough that nobody understands how the answers came out."}, {"time": 3312, "text": "It used to be you get data set, you guess at a function."}, {"time": 3316, "text": "The function is considered physics if it's predictive of new functions, new data sets."}, {"time": 3323, "text": "Modern, you can take a large data set with no intuition about what it is and use machine learning to find a pattern that has no function, right?"}, {"time": 3334, "text": "And it can arrive at results that I don't know if they're completely mathematically describable."}, {"time": 3339, "text": "So computation has kind of done something interesting compared to a equal b plus c. There's something reminiscent of that step from the basic operations of addition to taking a step towards neural networks that's reminiscent of what life on Earth at its origins was doing."}, {"time": 3361, "text": "Do you think we're creating sort of the next step in our evolution in creating artificial intelligence systems that will?"}, {"time": 3368, "text": "I mean, there's so much in the universe already, it's hard to say."}, {"time": 3372, "text": "Where we stand in this whole thing."}, {"time": 3374, "text": "Are human beings working on additional abstraction layers and possibilities?"}, {"time": 3378, "text": "Yeah, it appears so."}, {"time": 3380, "text": "Does that mean that human beings don't need dogs?"}, {"time": 3382, "text": "You know, no."}, {"time": 3384, "text": "Like, there's so many things that are all simultaneously interesting and useful."}, {"time": 3390, "text": "Well, you've seen, throughout your career, you've seen greater and greater level abstractions built in artificial machines, right?"}, {"time": 3399, "text": "Do you think, when you look at humans, do you think that the look of all life on Earth is a single organism building this thing, this machine with greater and greater levels of abstraction?"}, {"time": 3409, "text": "Do you think humans are the peak, the top of the food chain in this long arc of history on Earth?"}, {"time": 3418, "text": "Or do you think we're just somewhere in the middle?"}, {"time": 3420, "text": "Are we the basic functional operations of a CPU?"}, {"time": 3425, "text": "Are we the C++ program, the Python program, or the neural network?"}, {"time": 3430, "text": "Like, somebody's, you know, people have calculated, like, how many operations does the brain do?"}, {"time": 3434, "text": "Something, you know, I've seen the number 10 to the 18th a bunch of times, arrive different ways."}, {"time": 3440, "text": "So could you make a computer that did 10 to the 20th operations?"}, {"time": 3445, "text": "We're going to do that."}, {"time": 3447, "text": "Now, is there something magical about how brains compute things?"}, {"time": 3452, "text": "You know, my personal experience is interesting, because, you know, you think you know how you think, and then you have all these ideas, and you can't figure out how they happened."}, {"time": 3461, "text": "And if you meditate, you know, what you can be aware of is interesting."}, {"time": 3468, "text": "So I don't know if brains are magical or not."}, {"time": 3471, "text": "You know, the physical evidence says no."}, {"time": 3474, "text": "Lots of people's personal experience says yes."}, {"time": 3477, "text": "So what would be funny is if brains are magical, and yet we can make brains with more computation."}, {"time": 3484, "text": "You know, I don't know what to say about that."}, {"time": 3487, "text": "But do you think magic is an emergent phenomena?"}, {"time": 3492, "text": "I have no explanation for it."}, {"time": 3493, "text": "Let me ask Jim Keller of what in your view is consciousness?"}, {"time": 3499, "text": "With consciousness?"}, {"time": 3500, "text": "Yeah, like what, you know, consciousness, love, things that are these deeply human things that seems to emerge from our brain, is that something that we'll be able to make encode in chips that get faster and faster and faster and faster?"}, {"time": 3518, "text": "That's like a 10 hour conversation."}, {"time": 3520, "text": "Nobody really knows."}, {"time": 3521, "text": "Can you summarize it in a couple of sentences?"}, {"time": 3525, "text": "Many people have observed that organisms run at lots of different levels, right?"}, {"time": 3531, "text": "If you had two neurons, somebody said you'd have one sensory neuron and one motor neuron, right?"}, {"time": 3536, "text": "So we move towards things and away from things."}, {"time": 3538, "text": "And we have physical integrity and safety or not, right?"}, {"time": 3543, "text": "And then if you look at the animal kingdom, you can see brains that are a little more complicated."}, {"time": 3548, "text": "And at some point, there's a planning system."}, {"time": 3550, "text": "And then there's an emotional system that's happy about being safe or unhappy about being threatened."}, {"time": 3557, "text": "And then our brains have massive numbers of structures, like planning and movement and thinking and feeling and drives and emotions."}, {"time": 3567, "text": "And we seem to have multiple layers of thinking systems."}, {"time": 3571, "text": "And we have a dream system that nobody understands whatsoever, which I find completely hilarious."}, {"time": 3577, "text": "And you can think in a way that those systems are more independent."}, {"time": 3585, "text": "And you can observe the different parts of yourself can observe them."}, {"time": 3589, "text": "I don't know which one's magical."}, {"time": 3591, "text": "I don't know which one's not computational."}, {"time": 3596, "text": "Is it possible that it's all computation?"}, {"time": 3600, "text": "Is there a limit to computation?"}, {"time": 3603, "text": "Do you think the universe is a computer?"}, {"time": 3606, "text": "It seems to be."}, {"time": 3607, "text": "It's a weird kind of computer."}, {"time": 3609, "text": "Because if it was a computer, like when they do calculations on how much calculation it takes to describe quantum effects, it's unbelievably high."}, {"time": 3620, "text": "So if it was a computer, wouldn't you have built it out of something that was easier to compute?"}, {"time": 3626, "text": "That's a funny system."}, {"time": 3629, "text": "But then the simulation guys pointed out that the rules are kind of interesting."}, {"time": 3632, "text": "When you look really close, it's uncertain."}, {"time": 3635, "text": "And the speed of light says you can only look so far."}, {"time": 3637, "text": "And things can't be simultaneous, except for the odd entanglement problem where they seem to be."}, {"time": 3642, "text": "The rules are all kind of weird."}, {"time": 3645, "text": "And somebody said physics is like having 50 equations with 50 variables to define 50 variables."}, {"time": 3655, "text": "Physics itself has been a shit show for thousands of years."}, {"time": 3659, "text": "It seems odd when you get to the corners of everything."}, {"time": 3662, "text": "It's either uncomputable or undefinable or uncertain."}, {"time": 3667, "text": "It's almost like the designers of the simulation are trying to prevent us from understanding it perfectly."}, {"time": 3672, "text": "But also, the things that require calculations require so much calculation that our idea of the universe of a computer is absurd, because every single little bit of it takes all the computation in the universe to figure out."}, {"time": 3686, "text": "So that's a weird kind of computer."}, {"time": 3688, "text": "You say the simulation is running in a computer, which has, by definition, infinite computation."}, {"time": 3694, "text": "Not infinite."}, {"time": 3695, "text": "Oh, you mean if the universe is infinite?"}, {"time": 3698, "text": "Well, every little piece of our universe seems to take infinite computation to figure out."}, {"time": 3703, "text": "Not infinite, just a lot."}, {"time": 3704, "text": "Well, a lot."}, {"time": 3704, "text": "Some pretty big number."}, {"time": 3706, "text": "Compute this little teeny spot takes all the mass in the local one light year by one light year space."}, {"time": 3713, "text": "It's close enough to infinite."}, {"time": 3714, "text": "Well, it's a heck of a computer if it is one."}, {"time": 3717, "text": "It's a weird description, because the simulation description seems to break when you look closely at it."}, {"time": 3724, "text": "But the rules of the universe seem to imply something's up."}, {"time": 3728, "text": "That seems a little arbitrary."}, {"time": 3730, "text": "The universe, the whole thing, the laws of physics, it just seems like, how did it come out to be the way it is?"}, {"time": 3740, "text": "Well, lots of people talk about that."}, {"time": 3742, "text": "Like I said, the two smartest groups of humans are working on the same problem."}, {"time": 3746, "text": "From different aspects."}, {"time": 3747, "text": "And they're both complete failures."}, {"time": 3749, "text": "So that's kind of cool."}, {"time": 3752, "text": "They might succeed eventually."}, {"time": 3754, "text": "Well, after 2,000 years, the trend isn't good."}, {"time": 3757, "text": "Oh, 2,000 years is nothing in the span of the history of the universe."}, {"time": 3760, "text": "That's for sure."}, {"time": 3761, "text": "We have some time."}, {"time": 3762, "text": "But the next 1,000 years doesn't look good either."}, {"time": 3766, "text": "That's what everybody says at every stage."}, {"time": 3768, "text": "But with Moore's law, as you've just described, not being dead, the exponential growth of technology, the future seems pretty incredible."}, {"time": 3777, "text": "Well, it'll be interesting, that's for sure."}, {"time": 3780, "text": "So what are your thoughts on Ray Kurzweil's sense that exponential improvement in technology will continue indefinitely?"}, {"time": 3787, "text": "Is that how you see Moore's law?"}, {"time": 3789, "text": "Do you see Moore's law more broadly, in the sense that technology of all kinds has a way of stacking S curves on top of each other, where it'll be exponential, and then we'll see all kinds of... What does an exponential of a million mean?"}, {"time": 3807, "text": "That's a pretty amazing number."}, {"time": 3809, "text": "And that's just for a local little piece of silicon."}, {"time": 3812, "text": "Now let's imagine you, say, decided to get 1,000 tons of silicon to collaborate in one computer at a million times the density."}, {"time": 3824, "text": "Now you're talking, I don't know, 10 to the 20th more computation power than our current, already unbelievably fast computers."}, {"time": 3834, "text": "Nobody knows what that's going to mean."}, {"time": 3835, "text": "The sci fi guys call it computronium, like when a local civilization turns the nearby star into a computer."}, {"time": 3845, "text": "I don't know if that's true, but..."}, {"time": 3846, "text": "So just even when you shrink a transistor, the... That's only one dimension."}, {"time": 3852, "text": "The ripple effects of that."}, {"time": 3854, "text": "People tend to think about computers as a cost problem."}, {"time": 3857, "text": "So computers are made out of silicon and minor amounts of metals and this and that."}, {"time": 3864, "text": "None of those things cost any money."}, {"time": 3867, "text": "There's plenty of sand."}, {"time": 3870, "text": "You could just turn the beach and a little bit of ocean water into computers."}, {"time": 3873, "text": "So all the cost is in the equipment to do it."}, {"time": 3876, "text": "And the trend on equipment is once you figure out how to build the equipment, the trend of cost is zero."}, {"time": 3881, "text": "Elon said, first you figure out what configuration you want the atoms in, and then how to put them there."}, {"time": 3890, "text": "His great insight is people are how constrained."}, {"time": 3896, "text": "I have this thing, I know how it works, and then little tweaks to that will generate something, as opposed to what do I actually want, and then figure out how to build it."}, {"time": 3907, "text": "It's a very different mindset."}, {"time": 3909, "text": "And almost nobody has it, obviously."}, {"time": 3912, "text": "Well, let me ask on that topic, you were one of the key early people in the development of autopilot, at least in the hardware side, Elon Musk believes that autopilot and vehicle autonomy, if you just look at that problem, can follow this kind of exponential improvement."}, {"time": 3929, "text": "In terms of the how question that we're talking about, there's no reason why you can't."}, {"time": 3934, "text": "What are your thoughts on this particular space of vehicle autonomy, and your part of it and Elon Musk's and Tesla's vision for vehicle autonomy?"}, {"time": 3945, "text": "Well, the computer you need to build is straightforward."}, {"time": 3948, "text": "And you could argue, well, does it need to be two times faster or five times or 10 times?"}, {"time": 3954, "text": "But that's just a matter of time or price in the short run."}, {"time": 3958, "text": "So that's not a big deal."}, {"time": 3960, "text": "You don't have to be especially smart to drive a car."}, {"time": 3963, "text": "So it's not like a super hard problem."}, {"time": 3965, "text": "I mean, the big problem with safety is attention, which computers are really good at, not skills."}, {"time": 3971, "text": "Well, let me push back on one."}, {"time": 3975, "text": "You see, everything you said is correct, but we as humans tend to take for granted how incredible our vision system is."}, {"time": 3986, "text": "So you can drive a car with 20, 50 vision, and you can train a neural network to extract the distance of any object in the shape of any surface from a video and data."}, {"time": 3998, "text": "Yeah, but that's really simple."}, {"time": 4000, "text": "No, it's not simple."}, {"time": 4002, "text": "That's a simple data problem."}, {"time": 4004, "text": "It's not, it's not simple."}, {"time": 4006, "text": "It's because it's not just detecting objects, it's understanding the scene, and it's being able to do it in a way that doesn't make errors."}, {"time": 4016, "text": "So the beautiful thing about the human vision system and our entire brain around the whole thing is we're able to fill in the gaps."}, {"time": 4025, "text": "It's not just about perfectly detecting cars."}, {"time": 4028, "text": "It's inferring the occluded cars."}, {"time": 4029, "text": "It's trying to, it's understanding the physics."}, {"time": 4032, "text": "I think that's mostly a data problem."}, {"time": 4034, "text": "So you think what data would compute with improvement of computation with improvement in collection of data?"}, {"time": 4040, "text": "Well, there is a, you know, when you're driving a car and somebody cuts you off, your brain has theories about why they did it."}, {"time": 4046, "text": "You know, they're a bad person, they're distracted, they're dumb, you know, you can listen to yourself, right?"}, {"time": 4052, "text": "So, you know, if you think that narrative is important to be able to successfully drive a car, then current autopilot systems can't do it."}, {"time": 4061, "text": "But if cars are ballistic things with tracks and probabilistic changes of speed and direction, and roads are fixed and given, by the way, they don't change dynamically, right?"}, {"time": 4073, "text": "You can map the world really thoroughly."}, {"time": 4076, "text": "You can place every object really thoroughly."}, {"time": 4081, "text": "Right, you can calculate trajectories of things really thoroughly, right?"}, {"time": 4086, "text": "But everything you said about really thoroughly has a different degree of difficulty, so."}, {"time": 4093, "text": "And you could say at some point, computer autonomous systems will be way better at things that humans are lousy at."}, {"time": 4100, "text": "Like, they'll be better at attention, they'll always remember there was a pothole in the road that humans keep forgetting about, they'll remember that this set of roads has these weirdo lines on it that the computers figured out once, and especially if they get updates, so if somebody changes a given, like, the key to robots and stuff somebody said is to maximize the givens, right?"}, {"time": 4125, "text": "So having a robot pick up this bottle cap is way easier if you put a red dot on the top, because then you'll have to figure out, and if you wanna do a certain thing with it, maximize the givens is the thing."}, {"time": 4137, "text": "And autonomous systems are happily maximizing the givens."}, {"time": 4141, "text": "Like, humans, when you drive someplace new, you remember it, because you're processing it the whole time, and after the 50th time you drove to work, you get to work, you don't know how you got there, right?"}, {"time": 4151, "text": "You're on autopilot, right?"}, {"time": 4154, "text": "Autonomous cars are always on autopilot."}, {"time": 4157, "text": "But the cars have no theories about why they got cut off, or why they're in traffic."}, {"time": 4162, "text": "So they also never stop paying attention."}, {"time": 4164, "text": "Right, so I tend to believe you do have to have theories, meta models of other people, especially with pedestrian cyclists, but also with other cars."}, {"time": 4172, "text": "So everything you said is actually essential to driving."}, {"time": 4178, "text": "Driving is a lot more complicated than people realize, I think, so to push back slightly, but to..."}, {"time": 4184, "text": "So to cut into traffic, right?"}, {"time": 4187, "text": "You can't just wait for a gap, you have to be somewhat aggressive."}, {"time": 4190, "text": "You'll be surprised how simple a calculation for that is."}, {"time": 4193, "text": "I may be on that particular point, but there's, maybe I actually have to push back."}, {"time": 4200, "text": "I would be surprised."}, {"time": 4201, "text": "You know what, yeah, I'll just say where I stand."}, {"time": 4203, "text": "I would be very surprised, but I think you might be surprised how complicated it is."}, {"time": 4210, "text": "I tell people, progress disappoints in the short run, and surprises in the long run."}, {"time": 4213, "text": "It's very possible, yeah."}, {"time": 4215, "text": "I suspect in 10 years it'll be just taken for granted."}, {"time": 4219, "text": "But you're probably right, not look like..."}, {"time": 4222, "text": "It's gonna be a $50 solution that nobody cares about."}, {"time": 4225, "text": "It's like GPSes, like, wow, GPSes."}, {"time": 4227, "text": "We have satellites in space that tell you where your location is."}, {"time": 4231, "text": "It was a really big deal, now everything has a GPS in it."}, {"time": 4233, "text": "Yeah, that's true, but I do think that systems that involve human behavior are more complicated than we give them credit for."}, {"time": 4240, "text": "So we can do incredible things with technology that don't involve humans, but when you..."}, {"time": 4245, "text": "I think humans are less complicated than people."}, {"time": 4248, "text": "You know, frequently ascribed."}, {"time": 4250, "text": "Maybe I feel... We tend to operate out of large numbers of patterns and just keep doing it over and over."}, {"time": 4255, "text": "But I can't trust you because you're a human."}, {"time": 4258, "text": "That's something a human would say."}, {"time": 4260, "text": "But my hope is on the point you've made is, even if, no matter who's right, I'm hoping that there's a lot of things that humans aren't good at that machines are definitely good at, like you said, attention and things like that."}, {"time": 4275, "text": "Well, they'll be so much better that the overall picture of safety and autonomy will be, obviously cars will be safer, even if they're not as good at understanding."}, {"time": 4284, "text": "I'm a big believer in safety."}, {"time": 4286, "text": "I mean, there are already the current safety systems, like cruise control that doesn't let you run into people and lane keeping."}, {"time": 4293, "text": "There are so many features that you just look at the parade of accidents and knocking off like 80% of them is super doable."}, {"time": 4302, "text": "Just to linger on the autopilot team and the efforts there, it seems to be that there's a very intense scrutiny by the media and the public in terms of safety, the pressure, the bar put before autonomous vehicles."}, {"time": 4318, "text": "What are your, sort of as a person there working on the hardware and trying to build a system that builds a safe vehicle and so on, what was your sense about that pressure?"}, {"time": 4328, "text": "Is it unfair?"}, {"time": 4329, "text": "Is it expected of new technology?"}, {"time": 4332, "text": "Yeah, it seems reasonable."}, {"time": 4333, "text": "I was interested, I talked to both American and European regulators, and I was worried that the regulations would write into the rules technology solutions, like modern brake systems imply hydraulic brakes."}, {"time": 4350, "text": "So if you read the regulations, to meet the letter of the law for brakes, it sort of has to be hydraulic, right?"}, {"time": 4357, "text": "And the regulator said they're interested in the use cases, like a head on crash, an offset crash, don't hit pedestrians, don't run into people, don't leave the road, don't run a red light or a stoplight."}, {"time": 4370, "text": "They were very much into the scenarios."}, {"time": 4373, "text": "And they had all the data about which scenarios injured or killed the most people."}, {"time": 4379, "text": "And for the most part, those conversations were like, what's the right thing to do to take the next step?"}, {"time": 4388, "text": "Now, Elon's very interested also in the benefits of autonomous driving or freeing people's time and attention, as well as safety."}, {"time": 4398, "text": "And I think that's also an interesting thing, but building autonomous systems so they're safe and safer than people seemed, since the goal is to be 10X safer than people, having the bar to be safer than people and scrutinizing accidents seems philosophically correct."}, {"time": 4419, "text": "So I think that's a good thing."}, {"time": 4421, "text": "What are, is different than the things you worked at, Intel, AMD, Apple, with autopilot chip design and hardware design, what are interesting or challenging aspects of building this specialized kind of computing system in the automotive space?"}, {"time": 4440, "text": "I mean, there's two tricks to building like an automotive computer."}, {"time": 4442, "text": "One is the software team, the machine learning team is developing algorithms that are changing fast."}, {"time": 4450, "text": "So as you're building the accelerator, you have this, you know, worry or intuition that the algorithms will change enough that the accelerator will be the wrong one, right?"}, {"time": 4462, "text": "And there's the generic thing, which is, if you build a really good general purpose computer, say its performance is one, and then GPU guys will deliver about 5X to performance for the same amount of silicon, because instead of discovering parallelism, you're given parallelism."}, {"time": 4479, "text": "And then special accelerators get another two to 5X on top of a GPU, because you say, I know the math is always eight bit integers into 32 bit accumulators, and the operations are the subset of mathematical possibilities."}, {"time": 4495, "text": "So AI accelerators have a claimed performance benefit over GPUs because in the narrow math space, you're nailing the algorithm."}, {"time": 4507, "text": "Now, you still try to make it programmable, but the AI field is changing really fast."}, {"time": 4513, "text": "So there's a, you know, there's a little creative tension there of, I want the acceleration afforded by specialization without being over specialized so that the new algorithm is so much more effective that you'd have been better off on a GPU."}, {"time": 4527, "text": "So there's a tension there."}, {"time": 4530, "text": "To build a good computer for an application like automotive, there's all kinds of sensor inputs and safety processors and a bunch of stuff."}, {"time": 4539, "text": "So one of Elon's goals is to make it super affordable."}, {"time": 4542, "text": "So every car gets an autopilot computer."}, {"time": 4544, "text": "So some of the recent startups you look at, and they have a server in the trunk, because they're saying, I'm gonna build this autopilot computer, replaces the driver."}, {"time": 4552, "text": "So their cost budget's 10 or $20,000."}, {"time": 4555, "text": "And Elon's constraint was, I'm gonna put one in every car, whether people buy autonomous driving or not."}, {"time": 4561, "text": "So the cost constraint he had in mind was great, right?"}, {"time": 4565, "text": "And to hit that, you had to think about the system design."}, {"time": 4568, "text": "That's complicated, and it's fun."}, {"time": 4569, "text": "You know, it's like, it's like, it's craftsman's work."}, {"time": 4572, "text": "Like, you know, a violin maker, right?"}, {"time": 4574, "text": "You can say, Stradivarius is this incredible thing, the musicians are incredible."}, {"time": 4578, "text": "But the guy making the violin, you know, picked wood and sanded it, and then he cut it, you know, and he glued it, you know, and he waited for the right day so that when he put the finish on it, it didn't, you know, do something dumb."}, {"time": 4591, "text": "That's craftsman's work, right?"}, {"time": 4593, "text": "You may be a genius craftsman because you have the best techniques and you discover a new one, but most engineers, craftsman's work."}, {"time": 4601, "text": "And humans really like to do that."}, {"time": 4604, "text": "You know the expression?"}, {"time": 4605, "text": "Smart humans."}, {"time": 4605, "text": "No, everybody."}, {"time": 4606, "text": "All humans."}, {"time": 4608, "text": "I used to, I dug ditches when I was in college."}, {"time": 4610, "text": "I got really good at it."}, {"time": 4611, "text": "Satisfying."}, {"time": 4614, "text": "Digging ditches is also craftsman's work."}, {"time": 4616, "text": "So there's an expression called complex mastery behavior."}, {"time": 4620, "text": "So when you're learning something, that's fine, because you're learning something."}, {"time": 4624, "text": "When you do something, it's relatively simple."}, {"time": 4625, "text": "It's not that satisfying."}, {"time": 4626, "text": "But if the steps that you have to do are complicated and you're good at them, it's satisfying to do them."}, {"time": 4634, "text": "And then if you're intrigued by it all, as you're doing them, you sometimes learn new things that you can raise your game."}, {"time": 4641, "text": "But craftsman's work is good."}, {"time": 4643, "text": "And engineers, like engineering is complicated enough that you have to learn a lot of skills."}, {"time": 4648, "text": "And then a lot of what you do is then craftsman's work, which is fun."}, {"time": 4653, "text": "Autonomous driving, building a very resource constrained computer."}, {"time": 4657, "text": "So a computer has to be cheap enough to put in every single car."}, {"time": 4661, "text": "That essentially boils down to craftsman's work."}, {"time": 4665, "text": "It's engineering, it's innovation."}, {"time": 4665, "text": "Yeah, you know, there's thoughtful decisions and problems to solve and trade offs to make."}, {"time": 4670, "text": "Do you need 10 camera and ports or eight?"}, {"time": 4672, "text": "You know, you're building for the current car or the next one."}, {"time": 4676, "text": "You know, how do you do the safety stuff?"}, {"time": 4677, "text": "You know, there's a whole bunch of details."}, {"time": 4680, "text": "But it's fun."}, {"time": 4681, "text": "It's not like I'm building a new type of neural network, which has a new mathematics and a new computer to work."}, {"time": 4688, "text": "You know, that's like, there's more invention than that."}, {"time": 4692, "text": "But the rejection to practice, once you pick the architecture, you look inside and what do you see?"}, {"time": 4697, "text": "Adders and multipliers and memories and, you know, the basics."}, {"time": 4701, "text": "So computers is always this weird set of abstraction layers of ideas and thinking that reduction to practice is transistors and wires and, you know, pretty basic stuff."}, {"time": 4713, "text": "And that's an interesting phenomenon."}, {"time": 4717, "text": "By the way, like factory work, like lots of people think factory work is road assembly stuff."}, {"time": 4722, "text": "I've been on the assembly line."}, {"time": 4724, "text": "Like the people who work there really like it."}, {"time": 4726, "text": "It's a really great job."}, {"time": 4727, "text": "It's really complicated."}, {"time": 4728, "text": "Putting cars together is hard, right?"}, {"time": 4730, "text": "And the car is moving and the parts are moving and sometimes the parts are damaged and you have to coordinate putting all the stuff together and people are good at it."}, {"time": 4739, "text": "They're good at it."}, {"time": 4740, "text": "And I remember one day I went to work and the line was shut down for some reason and some of the guys sitting around were really bummed because they had reorganized a bunch of stuff and they were gonna hit a new record for the number of cars built that day."}, {"time": 4752, "text": "And they were all gung ho to do it."}, {"time": 4754, "text": "And these were big, tough buggers."}, {"time": 4755, "text": "And, you know, but what they did was complicated and you couldn't do it."}, {"time": 4760, "text": "Yeah, and I mean."}, {"time": 4761, "text": "Well, after a while you could, but you'd have to work your way up because, you know, like putting the bright, what's called the brights, the trim on a car on a moving assembly line where it has to be attached 25 places in a minute and a half is unbelievably complicated."}, {"time": 4779, "text": "And human beings can do it, it's really good."}, {"time": 4782, "text": "I think that's harder than driving a car, by the way."}, {"time": 4785, "text": "Putting together, working at a."}, {"time": 4787, "text": "Working on a factory."}, {"time": 4788, "text": "Two smart people can disagree."}, {"time": 4792, "text": "I think driving a car."}, {"time": 4794, "text": "We'll get you in the factory someday and then we'll see how you do."}, {"time": 4797, "text": "No, not for us humans driving a car is easy."}, {"time": 4799, "text": "I'm saying building a machine that drives a car is not easy."}, {"time": 4805, "text": "Driving a car is easy for humans because we've been evolving for billions of years."}, {"time": 4810, "text": "Drive cars."}, {"time": 4811, "text": "Yeah, I noticed that."}, {"time": 4813, "text": "The pale of the cars are super cool."}, {"time": 4816, "text": "No, now you join the rest of the internet and mocking me."}, {"time": 4820, "text": "I wasn't mocking, I was just."}, {"time": 4823, "text": "Intrigued by your anthropology."}, {"time": 4827, "text": "I'll have to go dig into that."}, {"time": 4828, "text": "There's some inaccuracies there, yes."}, {"time": 4831, "text": "Okay, but in general, what have you learned in terms of thinking about passion, craftsmanship, tension, chaos."}, {"time": 4847, "text": "Jesus."}, {"time": 4848, "text": "The whole mess of it."}, {"time": 4850, "text": "What have you learned, have taken away from your time working with Elon Musk, working at Tesla, which is known to be a place of chaos innovation, craftsmanship, and all of those things."}, {"time": 4863, "text": "I really like the way you thought."}, {"time": 4866, "text": "You think you have an understanding about what first principles of something is, and then you talk to Elon about it, and you didn't scratch the surface."}, {"time": 4875, "text": "He has a deep belief that no matter what you do, it's a local maximum, right?"}, {"time": 4881, "text": "And I had a friend, he invented a better electric motor, and it was a lot better than what we were using."}, {"time": 4886, "text": "And one day he came by, he said, I'm a little disappointed, because this is really great, and you didn't seem that impressed."}, {"time": 4893, "text": "And I said, when the super intelligent aliens come, are they going to be looking for you?"}, {"time": 4898, "text": "Like, where is he?"}, {"time": 4899, "text": "The guy who built the motor."}, {"time": 4903, "text": "You know, like, but doing interesting work that's both innovative and, let's say, craftsman's work on the current thing is really satisfying, and it's good."}, {"time": 4914, "text": "And that's cool."}, {"time": 4915, "text": "And then Elon was good at taking everything apart, and like, what's the deep first principle?"}, {"time": 4921, "text": "Oh, no, what's really, no, what's really?"}, {"time": 4923, "text": "You know, that ability to look at it without assumptions and how constraints is super wild."}, {"time": 4933, "text": "You know, he built a rocket ship, and an electric car, and you know, everything."}, {"time": 4939, "text": "And that's super fun, and he's into it, too."}, {"time": 4941, "text": "Like, when they first landed two SpaceX rockets at Tesla, we had a video projector in the big room, and like, 500 people came down, and when they landed, everybody cheered, and some people cried."}, {"time": 4952, "text": "It was so cool."}, {"time": 4954, "text": "All right, but how did you do that?"}, {"time": 4955, "text": "Well, it was super hard, and then people say, well, it's chaotic, really?"}, {"time": 4962, "text": "To get out of all your assumptions, you think that's not gonna be unbelievably painful?"}, {"time": 4967, "text": "And is Elon tough?"}, {"time": 4970, "text": "Do people look back on it and say, boy, I'm really happy I had that experience to go take apart that many layers of assumptions?"}, {"time": 4982, "text": "Sometimes super fun, sometimes painful."}, {"time": 4984, "text": "So it could be emotionally and intellectually painful, that whole process of just stripping away assumptions."}, {"time": 4990, "text": "Yeah, imagine 99% of your thought process is protecting your self conception, and 98% of that's wrong."}, {"time": 5000, "text": "Now you got the math right."}, {"time": 5002, "text": "How do you think you're feeling when you get back into that one bit that's useful, and now you're open, and you have the ability to do something different?"}, {"time": 5010, "text": "I don't know if I got the math right."}, {"time": 5013, "text": "It might be 99.9, but it ain't 50."}, {"time": 5018, "text": "Imagining it, the 50% is hard enough."}, {"time": 5024, "text": "Now, for a long time, I've suspected you could get better."}, {"time": 5028, "text": "Like you can think better, you can think more clearly, you can take things apart."}, {"time": 5032, "text": "And there's lots of examples of that, people who do that."}, {"time": 5036, "text": "And Nilan is an example of that, you are an example."}, {"time": 5042, "text": "I don't know if I am, I'm fun to talk to."}, {"time": 5046, "text": "Certainly."}, {"time": 5047, "text": "I've learned a lot of stuff."}, {"time": 5049, "text": "Well, here's the other thing, I joke, like I read books, and people think, oh, you read books."}, {"time": 5054, "text": "Well, no, I've read a couple of books a week for 55 years."}, {"time": 5060, "text": "Well, maybe 50, because I didn't learn to read until I was age or something."}, {"time": 5064, "text": "And it turns out when people write books, they often take 20 years of their life where they passionately did something, reduce it to 200 pages."}, {"time": 5076, "text": "That's kind of fun."}, {"time": 5077, "text": "And then you go online, and you can find out who wrote the best books and who liked, you know, that's kind of wild."}, {"time": 5083, "text": "So there's this wild selection process, and then you can read it, and for the most part, understand it."}, {"time": 5089, "text": "And then you can go apply it."}, {"time": 5091, "text": "Like I went to one company, I thought, I haven't managed much before."}, {"time": 5095, "text": "So I read 20 management books, and I started talking to them, and basically compared to all the VPs running around, I'd read 19 more management books than anybody else."}, {"time": 5105, "text": "It wasn't even that hard."}, {"time": 5108, "text": "And half the stuff worked, like first time."}, {"time": 5111, "text": "It wasn't even rocket science."}, {"time": 5113, "text": "But at the core of that is questioning the assumptions, or sort of entering the thinking, first principles thinking, sort of looking at the reality of the situation, and using that knowledge, applying that knowledge."}, {"time": 5129, "text": "So I would say my brain has this idea that you can question first assumptions."}, {"time": 5135, "text": "But I can go days at a time and forget that, and you have to kind of like circle back that observation."}, {"time": 5142, "text": "Because it is emotionally challenging."}, {"time": 5145, "text": "Well, it's hard to just keep it front and center, because you operate on so many levels all the time, and getting this done takes priority, or being happy takes priority, or screwing around takes priority."}, {"time": 5159, "text": "Like how you go through life is complicated."}, {"time": 5163, "text": "And then you remember, oh yeah, I could really think first principles."}, {"time": 5166, "text": "Oh shit, that's tiring."}, {"time": 5169, "text": "But you do for a while, and that's kind of cool."}, {"time": 5172, "text": "So just as a last question in your sense, from the big picture, from the first principles, do you think, you kind of answered it already, but do you think autonomous driving is something we can solve on a timeline of years?"}, {"time": 5188, "text": "So one, two, three, five, 10 years, as opposed to a century?"}, {"time": 5195, "text": "Just to linger on it a little longer, where's the confidence coming from?"}, {"time": 5200, "text": "Is it the fundamentals of the problem, the fundamentals of building the hardware and the software?"}, {"time": 5206, "text": "As a computational problem, understanding ballistics, roles, topography, it seems pretty solvable."}, {"time": 5216, "text": "And you can see this, like speech recognition, for a long time people are doing frequency and domain analysis, and all kinds of stuff, and that didn't work at all, right?"}, {"time": 5227, "text": "And then they did deep learning about it, and it worked great."}, {"time": 5231, "text": "And it took multiple iterations."}, {"time": 5233, "text": "And autonomous driving is way past the frequency analysis point."}, {"time": 5241, "text": "Use radar, don't run into things."}, {"time": 5243, "text": "And the data gathering's going up, and the computation's going up, and the algorithm understanding's going up, and there's a whole bunch of problems getting solved like that."}, {"time": 5252, "text": "The data side is really powerful, but I disagree with both you and Elon."}, {"time": 5255, "text": "I'll tell Elon once again, as I did before, that when you add human beings into the picture, it's no longer a ballistics problem."}, {"time": 5265, "text": "It's something more complicated, but I could be very well proven wrong."}, {"time": 5270, "text": "Cars are highly damped in terms of rate of change."}, {"time": 5273, "text": "Like the steering system's really slow compared to a computer."}, {"time": 5277, "text": "The acceleration of the acceleration's really slow."}, {"time": 5281, "text": "Yeah, on a certain timescale, on a ballistics timescale, but human behavior, I don't know."}, {"time": 5287, "text": "I shouldn't say."}, {"time": 5288, "text": "Human beings are really slow too."}, {"time": 5289, "text": "Weirdly, we operate half a second behind reality."}, {"time": 5293, "text": "Nobody really understands that one either."}, {"time": 5295, "text": "It's pretty funny."}, {"time": 5300, "text": "We very well could be surprised, and I think with the rate of improvement in all aspects on both the compute and the software and the hardware, there's gonna be pleasant surprises all over the place."}, {"time": 5314, "text": "Speaking of unpleasant surprises, many people have worries about a singularity in the development of AI."}, {"time": 5321, "text": "Forgive me for such questions."}, {"time": 5324, "text": "When AI improves the exponential and reaches a point of superhuman level general intelligence, beyond the point, there's no looking back."}, {"time": 5333, "text": "Do you share this worry of existential threats from artificial intelligence, from computers becoming superhuman level intelligent?"}, {"time": 5341, "text": "No, not really."}, {"time": 5344, "text": "We already have a very stratified society, and then if you look at the whole animal kingdom of capabilities and abilities and interests, and smart people have their niche, and normal people have their niche, and craftsmen have their niche, and animals have their niche."}, {"time": 5362, "text": "I suspect that the domains of interest for things that are astronomically different, like the whole something got 10 times smarter than us and wanted to track us all down because what?"}, {"time": 5374, "text": "We like to have coffee at Starbucks?"}, {"time": 5376, "text": "Like, it doesn't seem plausible."}, {"time": 5378, "text": "No, is there an existential problem that how do you live in a world where there's something way smarter than you, and you based your kind of self esteem on being the smartest local person?"}, {"time": 5388, "text": "Well, there's what, 0.1% of the population who thinks that?"}, {"time": 5392, "text": "Because the rest of the population's been dealing with it since they were born."}, {"time": 5396, "text": "So the breadth of possible experience that can be interesting is really big."}, {"time": 5403, "text": "And, you know, superintelligence seems likely, although we still don't know if we're magical, but I suspect we're not."}, {"time": 5416, "text": "And it seems likely that it'll create possibilities that are interesting for us, and its interests will be interesting for that, for whatever it is."}, {"time": 5426, "text": "It's not obvious why its interests would somehow want to fight over some square foot of dirt, or, you know, whatever the usual fears are about."}]}, {"title": "Steven Pressfield: The War of Art | Lex Fridman Podcast #102", "id": "PgtedwKGhXs", "quotes": [{"time": 334, "text": "In tribal society, back for however many, you know, hundreds of thousands, millions of years, which means that we're in the dynamic in our mind is a kind of an us versus them dynamic where our tribe is the people, and everybody else are whatever, you know?"}, {"time": 354, "text": "And I don't see that, I don't think that's changed one iota over the centuries."}, {"time": 361, "text": "It's just a question of how one might sublimate that urge to compete."}, {"time": 370, "text": "When you're a martial artist, you know, a great part of your day I'm sure is dedicated to reaching that place of total commitment and in the face of competition, in the face of adversity, et cetera, et cetera, which is, I think, natural and great for the human race on an individual basis."}, {"time": 421, "text": "So you think war was inevitable, it's a part of human nature as opposed to a force, a creative force in society that served a benefit."}, {"time": 461, "text": "And certainly in the days of Alexander the Great, let's say, there were, who knows, over the face of the earth, hundreds of little kingdoms, China, Japan, you know, Asia, Europe, wherever, and every prince that grew up dreamt of conquering his neighbor and conquering a neighbor after that."}, {"time": 484, "text": "That seems to be a universal human imperative, at least in the male of the species."}, {"time": 494, "text": "The war is just a realization of that imperative."}, {"time": 498, "text": "So you've written about Spartans in the Battle of Thermopylae, you've about Alexander the Great, about the Six Day War in 67 in Israel, against Egypt, Jordan, Syria."}, {"time": 510, "text": "What war, not just out of those, but in general, do you think has been most transformative for the world?"}, {"time": 518, "text": "Well, these are great questions, Lex."}, {"time": 520, "text": "Tough, easy ones, right?"}, {"time": 522, "text": "I mean, I wish I knew more about the Mongols, because I certainly, from what little I know, I think that was a very, their conquests were very transformative, bringing cultures in a horrible, bloody way together."}, {"time": 540, "text": "But gosh, what's then the most transformative?"}, {"time": 545, "text": "Maybe the Roman conquest, establishing the Roman Empire and bringing that culture."}, {"time": 550, "text": "Maybe Alexander the Great's wars that united east and west, at least for a minute."}, {"time": 559, "text": "So building of empire."}, {"time": 560, "text": "Do you have a sense, so there's wars, I mean, the Six Day War is not about building empires."}, {"time": 570, "text": "It's about deeply held religious, cultural conflict and holding the line, holding the border."}, {"time": 582, "text": "And then there is conquests, like the Mongols, that, what is it, some large percentage of the population is a descendant of Genghis Khan, I believe, right?"}, {"time": 592, "text": "So that has transformative effects."}, {"time": 594, "text": "And then World War II, I mean, personally, and my family and so on, had transformative effects."}, {"time": 599, "text": "Let me ask you this, Lex."}, {"time": 601, "text": "Why are you, what are you trying to get at with these questions?"}, {"time": 604, "text": "What is this kind of the theme that you're aiming at?"}, {"time": 609, "text": "Well, I talked to Eric Weinstein, and he said everything is great about war except the killing."}, {"time": 615, "text": "And there's a romantic notion of war."}, {"time": 621, "text": "Certainly there's a romantic notion of being a warrior, but there's a romantic notion of war that somehow there's a creative force to it, that because we fight, out of that fighting comes culture, comes music and art, and more and more desire to create with the societies that win."}, {"time": 645, "text": "And to me, war is not just, hey, I have a stick and I want your land."}, {"time": 653, "text": "It's some kind of, like it has echoes of the creative force that makes humans unique to other animals."}, {"time": 665, "text": "Like, war is, it can't be just four people or 10 people or 100 people."}, {"time": 671, "text": "You have to have thousands of people agreeing, usually thousands or more, for something so deeply that you would be willing to risk your own life."}, {"time": 682, "text": "And there's a romantic notion to that."}, {"time": 684, "text": "And because you've written so well and passionate about some of these, I wanted to see, because I don't have any answers, I wanted to untangle that."}, {"time": 692, "text": "If there is a reason we fight that's more than just anger and hate and a way to conquer."}, {"time": 703, "text": "Well, let me take it from a completely different side."}, {"time": 707, "text": "I don't think that I, in writing about war, am really that interested in war per se."}, {"time": 715, "text": "I'm more interested in the metaphor."}, {"time": 718, "text": "I think for me, I'm really writing about my own internal war and the war against myself and against my own resistance, my own negativity, all of those things that spirituality would be the opposite of."}, {"time": 740, "text": "So I'm not really an expert on war."}, {"time": 743, "text": "It's not like talking to Jim Mattis or to Victor Davis Hanson or whatever."}, {"time": 745, "text": "To me, the human being, we are spiritual beings in a physical envelope."}, {"time": 763, "text": "And there's an automatic terrible tension within that."}, {"time": 768, "text": "And which creates a war inside ourselves."}, {"time": 773, "text": "So the outer war, when I think about the Israeli army standing up to, whatever, 10 to one odds or whatever it was, that is a metaphor to me of the fight we're fighting inside ourselves."}, {"time": 790, "text": "For me, the six day war was, as you know, my feeling was it was about a return from exile."}, {"time": 795, "text": "It was sort of the culmination of the reestablishment of the state of Israel, which had never really been completed because the holiest places of the Jewish people were in the hands of their enemies."}, {"time": 854, "text": "So that would go along with what you're saying, Lex, of a certain creativity to it."}, {"time": 860, "text": "But again, that's not, for whatever, and I'm just realizing this as I'm answering this, that's not really what's interesting to me about these stories."}, {"time": 871, "text": "And the Spartans, what was a whole, at Thermopylae, that was a whole other kind of metaphor of war."}, {"time": 877, "text": "That was a sort of a willingly going to one's own death for a greater cause, just like, to me, the Spartans at Thermopylae enacted as a group what Jesus Christ enacted as an individual, a sacrifice of their lives for the greater good."}, {"time": 897, "text": "I don't know if that answers your question, but that's how I see it."}, {"time": 901, "text": "I do feel like, you know, I get invited to speak to Marine Corps groups and things like that all the time, and I decline because I don't really feel like I'm a spokesman for the warrior class or anything like that."}, {"time": 918, "text": "That's not what's interesting about it to me."}, {"time": 924, "text": "But didn't you just say, with war as a metaphor, that we're all essentially, in various ways, warriors?"}, {"time": 965, "text": "But at some point, that archetype, we move beyond that archetype, and we become fathers and teachers and so on and so forth."}, {"time": 974, "text": "And then there are many archetypes beyond that towards the end."}, {"time": 978, "text": "So I'm interested in the warrior archetype, but not to the be all and end all of everything else."}, {"time": 990, "text": "In my book, The Virtues of War, have you read that?"}, {"time": 994, "text": "Well, there's a character named Telamon, who's actually, it's a long story, but when he's with Alexander's army, and when they arrive in India, he becomes fascinated by the gymnosophists, the fakirs, the naked wise men, the yogis."}, {"time": 1015, "text": "And he says to Alexander that these guys are warriors beyond what we are, even though they do nothing because they are inside their own selves all day long."}, {"time": 1031, "text": "If we go to the Six Day War, you write about, in Lionsgate, you write about the Six Day War in Israel."}, {"time": 1042, "text": "I think of the wars you've written about as the one we're still in many ways in the midst of today."}, {"time": 1049, "text": "So what is at the core of that conflict in Israel?"}, {"time": 1055, "text": "The Israeli Palestinian conflict?"}, {"time": 1057, "text": "I mean, today it's the Israeli Palestinian conflict, but it echoes of the same conflict in that part of the world with Israel."}, {"time": 1067, "text": "What is, in your sense, the nature of that conflict?"}, {"time": 1073, "text": "What can we learn about society and human nature from that conflict?"}, {"time": 1077, "text": "That is one of the hottest conflicts that still goes on today."}, {"time": 1081, "text": "Well, when I was working on the Lionsgate about the Six Day War, I wrote in the introduction that this was not gonna be a multi sided story."}, {"time": 1094, "text": "I was taking it entirely, I'm a Jew, I identify with the Israeli people, I was gonna see it entirely from their side."}, {"time": 1103, "text": "So that's probably not what you're asking, but to me, the Six Day War and that whole, it's a piece of land that's holy to at least three religions and probably more."}, {"time": 1119, "text": "And from the Jewish point of view, it's where the state of Israel, it's where David founded Jerusalem, it's all where the 12 tribes were, et cetera, et cetera, where Moses came and brought the people."}, {"time": 1132, "text": "So to me, the Six Day War was about, as I said, a return from exile, from diaspora after 2000 years."}, {"time": 1143, "text": "Now, obviously, from the Palestinian point of view or the Saudi Arabian point of view or whatever, it's a whole other scenario."}, {"time": 1152, "text": "Religion is at the core of this conflict in some ways, but religious beliefs."}, {"time": 1155, "text": "Religion and racial slash ethnic tribal identity."}, {"time": 1160, "text": "I mean, again, what is a Jew?"}, {"time": 1163, "text": "Is a Jew somebody that believes in the religion or is it somebody of a certain race that race arose in a certain place?"}, {"time": 1171, "text": "Same thing as a Muslim."}, {"time": 1172, "text": "What is a Muslim?"}, {"time": 1173, "text": "Do they believe in Muhammad or whatever?"}, {"time": 1177, "text": "Or did they arise in a certain place and a certain ethnicity?"}, {"time": 1180, "text": "Because if we landed from Mars, we couldn't tell a Jew from a Palestinian, could we?"}, {"time": 1186, "text": "Just looking at them, you could easily mix them and you'd never know."}, {"time": 1190, "text": "And the specifics of the faith is not necessarily the thing that defines a person."}, {"time": 1196, "text": "So you could be, like many are, secular Jew living in Israel and still have a strong bond."}, {"time": 1204, "text": "Definitely, definitely."}, {"time": 1205, "text": "In fact, almost all of the Jews, the fighters that I spoke to from the Six Day War were secular and it really was not a religious thing with them as much as it was a national thing."}, {"time": 1222, "text": "So having spent time in Israel, how's the world where military conflict is directly felt as opposed to maybe if we look at the US where it's distant and far away?"}, {"time": 1235, "text": "How is that world different?"}, {"time": 1236, "text": "How are the people different?"}, {"time": 1237, "text": "It's very different, as you know."}, {"time": 1240, "text": "I've never been to Israel, actually."}, {"time": 1241, "text": "Oh, you haven't?"}, {"time": 1241, "text": "I haven't felt it."}, {"time": 1243, "text": "Ah, well, you should definitely go."}, {"time": 1246, "text": "I mean, here in the United States, where when an incident like Charlottesville comes up, where people are chanting, Jews will not replace us, blah, blah, blah, the impulse in the Jewish community is to think of, well, how can we reach out to the other side?"}, {"time": 1265, "text": "How can we show them that we are human beings like they are and show them that we care for them, et cetera, et cetera?"}, {"time": 1273, "text": "That's the sort of distant from war."}, {"time": 1276, "text": "From, if you're in Israel, like if you and I were Israeli citizens right now, you would be a fighter pilot or a tank commander or whatever."}, {"time": 1287, "text": "You would not just be working at MIT or whatever."}, {"time": 1290, "text": "And I would be in the army too."}, {"time": 1293, "text": "And so from their point of view, they say all those people who hate us, can I curse on this?"}, {"time": 1300, "text": "Can I curse on this thing?"}, {"time": 1301, "text": "Fuck them, we'll kill them."}, {"time": 1303, "text": "We'll kill them."}, {"time": 1304, "text": "If they dared to cross the line, and that's their whole different point of view."}, {"time": 1310, "text": "To me, it's actually a healthier point of view."}, {"time": 1313, "text": "So there's no, so let me ask the hard question is, well, maybe it's an impossible question is, how do we resolve that conflict?"}, {"time": 1322, "text": "In Israel and?"}, {"time": 1324, "text": "In Israel or?"}, {"time": 1325, "text": "Anywhere?"}, {"time": 1326, "text": "Anywhere where the instinct is to reach out in US and say, F you and the people, yeah."}, {"time": 1333, "text": "Here's my, I think that the only way that two warring sides or two sides that are opposed to one another can ever really come together is when there's mutual respect, we'll get just more water."}, {"time": 1346, "text": "I got it, I got this."}, {"time": 1347, "text": "When there's mutual respect and they can see each other as equals and when there's mutual fear, you know, where one side says, we don't dare cross the line with this other side, and the other side says the same thing."}, {"time": 1363, "text": "I think then you can kind of reach across that thing and say, okay, we'll stay here, you stay here."}, {"time": 1368, "text": "We'll mingle in cultural ways and we'll have interchange, you know, winter marriage, da, da, da, da, da, da."}, {"time": 1376, "text": "But as soon as one side has no power, as the Jewish people have had no power throughout the diaspora forever, right?"}, {"time": 1384, "text": "Then it's just a human nature."}, {"time": 1387, "text": "You can see it in Trump and what he does to any vulnerable minority, right?"}, {"time": 1395, "text": "And he's not alone."}, {"time": 1396, "text": "I'm not blaming him alone."}, {"time": 1398, "text": "That's human nature."}, {"time": 1399, "text": "So I do think that that idea of like, fuck you, if you cross the line, we'll kill you, is really a good way, is a good place to start from."}, {"time": 1408, "text": "Because now you can sit down on opposite sides of the table and say, you know, what do we have in common?"}, {"time": 1413, "text": "How can we, we want to raise our children."}, {"time": 1415, "text": "You want to raise your children."}, {"time": 1416, "text": "How can we do this in a way that we're not hurting each other?"}, {"time": 1422, "text": "So you kind of said that you need to arrive at a balance, some kind of balance of power."}, {"time": 1427, "text": "But you haven't spoken to the fact that there's deeply rooted hatred of the other."}, {"time": 1434, "text": "So is there no way to alleviate that hatred?"}, {"time": 1437, "text": "Or is that, I mean, what role does love and hate come?"}, {"time": 1443, "text": "I think that hatred can go away."}, {"time": 1444, "text": "I mean, if you look at even now that I haven't seen this in person, but they say that the Saudis and the Israelis are collaborating in certain things, you know, by their mutual fear of or antagonism to Iran."}, {"time": 1459, "text": "I do think that even really long, long, longstanding hatreds and animosities, thousands of years old, can go away under the right circumstances."}, {"time": 1470, "text": "In a, on what time scale?"}, {"time": 1474, "text": "I mean, for instance, I don't know if there's some, do people have to die?"}, {"time": 1479, "text": "Do generations have to die and pass away and new generations come up with less hate?"}, {"time": 1484, "text": "Or can a single individual learn to not hate?"}, {"time": 1487, "text": "I think a single individual can learn to not hate because it certainly doesn't seem to, over thousands of years, doesn't seem to work."}, {"time": 1492, "text": "You know, we keep thinking that that's gonna happen."}, {"time": 1495, "text": "But I think it's, we're in a real spiritual realm here when you're talking about that."}, {"time": 1502, "text": "You're in a realm of, you know, Buddha, Jesus, whatever, something like that, that where, you know, a true change of soul happens."}, {"time": 1513, "text": "But I do think that's possible."}, {"time": 1516, "text": "So what do you think is the future of warfare?"}, {"time": 1520, "text": "Especially with what many people see as the expansion of the military industrial conflict."}, {"time": 1527, "text": "To what, do you, I know you're not a military historian."}, {"time": 1532, "text": "I'm asking more as a metaphor."}, {"time": 1536, "text": "And do you see us as people continuing to fight?"}, {"time": 1541, "text": "You know, it's a really great question, Alex, because I think now with social media, TV, movies, all of these things that create empathy across cultures, it becomes harder and harder, I think, I think, to totally demonize the other, the way it was in previous wars."}, {"time": 1565, "text": "I also think, I don't really see an appetite for people wanting to go to war these days."}, {"time": 1572, "text": "And in a way, I don't know if that's good or bad."}, {"time": 1575, "text": "It's like everybody's so fat and lazy and so concerned with how many clicks they're getting that, you know, whereas I know at the start of World War I, both the younger generations were eager to go to war."}, {"time": 1590, "text": "You know, I think it was insane, but it was that sort of warrior archetype that we were talking about before that, that generational testosterone eros thing."}, {"time": 1603, "text": "Whereas nowadays, I don't know."}, {"time": 1608, "text": "I mean, it's hard to say there's not gonna be another war because there always are, but it's sort of hard to imagine people getting off their ass these days to do anything."}, {"time": 1619, "text": "Well, it's funny that you mentioned social media as a place for empathy, sure."}, {"time": 1623, "text": "But in a sense, it's a place for war as well."}, {"time": 1628, "text": "For hatred, yeah, true."}, {"time": 1628, "text": "For hatred."}, {"time": 1629, "text": "And perhaps the positive aspect of hatred on social media is that it's somewhat less harmful than murder."}, {"time": 1642, "text": "And so it kind of dissipates sort of the hatefuls."}, {"time": 1647, "text": "You get the hate out at a less, on a daily basis and thereby never boils up to a point where you want to kill."}, {"time": 1659, "text": "It's also a really weird thing that's going on that I don't know if anybody really understands, like with video games where kids are acting out these incredible horror things, right?"}, {"time": 1669, "text": "But you know that if they cut their finger, they would like freak out, you know?"}, {"time": 1675, "text": "And I also don't think that many of the people that are hateful on social media, if they were face to face with the person, they wouldn't."}, {"time": 1685, "text": "So there's a sort of two mental spheres happening at the same time."}, {"time": 1693, "text": "And I don't know how that plays out."}, {"time": 1695, "text": "Maps to the actual military, how that actually maps to military conflict."}, {"time": 1701, "text": "Like if you in the United States have a draft, for example, how the populace would respond different than they did in previous generations."}, {"time": 1709, "text": "Yeah, I think they certainly would."}, {"time": 1711, "text": "Another question, not sure if you've thought about it, but I work on building artificial intelligence systems."}, {"time": 1718, "text": "In our community, many people are worried about AI being used in war."}, {"time": 1721, "text": "So automating the killing process with drones and in general, it's being used more and more."}, {"time": 1729, "text": "I should recuse myself on that one."}, {"time": 1730, "text": "I really haven't thought about that one."}, {"time": 1731, "text": "You haven't thought about it."}, {"time": 1732, "text": "I'd rather ask you what you think about it."}, {"time": 1735, "text": "Well, it's interesting, I mean, because it's so fundamentally different from if you look at the Battle of Thermopylae."}, {"time": 1742, "text": "It means just if we talk about the difference between a gun and a sword."}, {"time": 1747, "text": "I'll tell you one little anecdote."}, {"time": 1749, "text": "There was a Spartan king, I don't know which one it was, but at one point they showed him a new invention and it could launch a bolt that would kill someone at a range of 200 yards."}, {"time": 1762, "text": "And the king wept and said, alas, valor is no more."}, {"time": 1767, "text": "Because their point of view of war, it was highly ritualized, as you know, and the code of honor was that you were not supposed to be able to kill another person unless you yourself were in equal danger of being killed."}, {"time": 1783, "text": "And any other way of doing that, even bow and arrow was considered less than manly and less than honorable."}, {"time": 1791, "text": "And maybe we should go back to that because at least it makes the stakes real and true."}, {"time": 1796, "text": "Not that we could."}, {"time": 1802, "text": "Not that's the point."}, {"time": 1804, "text": "You were in the Marine Corps, so we talk about the real, the bloody conflicts that you've written about, many of them."}, {"time": 1816, "text": "So let me ask a personal question."}, {"time": 1821, "text": "Have you, sort of as a writing and in general, have you thought about what it takes to kill a person if you yourself could do it in the war?"}, {"time": 1833, "text": "I have thought about it, yeah."}, {"time": 1834, "text": "And how that would make you feel?"}, {"time": 1837, "text": "Of course, one never knows."}, {"time": 1839, "text": "I certainly, I have not been in combat."}, {"time": 1841, "text": "I haven't killed anybody."}, {"time": 1843, "text": "But I would imagine in the real world that it would change you utterly forever."}, {"time": 1851, "text": "Because you can't help but identify with the person that you've just killed."}, {"time": 1861, "text": "And it's another human being."}, {"time": 1862, "text": "And I mean, I have a hard time killing a spider."}, {"time": 1867, "text": "So I would imagine that it's something that warriors understand and nobody else understands."}, {"time": 1875, "text": "And you've spoken with many."}, {"time": 1876, "text": "How, I mean, you've spoken with people who've seen military combat in Israel."}, {"time": 1883, "text": "What, have they been able to articulate the experience of killing?"}, {"time": 1888, "text": "It's sort of just what I said."}, {"time": 1891, "text": "I mean, I'm even thinking of one pilot that I interviewed over there who was strafing a tank in his Mustang and saw, at really low altitude, and saw what his bullets did to the guy and could see his face and everything like that, which is even one remove or more removes from an infantryman, what an infantryman does."}, {"time": 1919, "text": "And he said that same thing that I said, that it just changes you and you can never say it, never look at the world or look at anything the same way again."}, {"time": 1928, "text": "And when that happens at scale, it's thousands, tens of thousands, hundreds."}, {"time": 1933, "text": "That changes entire societies."}, {"time": 1934, "text": "I mean, that's what we've seen."}, {"time": 1936, "text": "At least it, but the problem is it doesn't change the politicians back home."}, {"time": 1942, "text": "How important is mortality, finiteness, the fact that this thing ends to the creative process?"}, {"time": 1952, "text": "So, killing and war really emphasizes that, but in general, the fact that this thing ends."}, {"time": 1962, "text": "It does?"}, {"time": 1963, "text": "It does, and uh."}, {"time": 1966, "text": "Shit."}, {"time": 1969, "text": "And on a serious note, do you think about your own mortality?"}, {"time": 1973, "text": "Do you meditate on your own mortality when you think about the work you do?"}, {"time": 1977, "text": "That's another great question, Lex."}, {"time": 1979, "text": "I actually, I'm 75, and I just was having, I had breakfast in New York a few months ago with a friend of mine who's like my exact same age."}, {"time": 1988, "text": "And I said to him, I said, Nick, do you ever think about mortality?"}, {"time": 1992, "text": "And he said, every fucking minute of every day."}, {"time": 1996, "text": "And I was kind of relieved to hear that because I do too."}, {"time": 2002, "text": "But actually, I always have, I think."}, {"time": 2004, "text": "And I think, you know, the fact of mortality gives meaning to life, you know?"}, {"time": 2012, "text": "I think that's why we want to create."}, {"time": 2016, "text": "That's why we want to make a mark of some kind."}, {"time": 2019, "text": "Or, and the other aspect of it is what's on the other side of that mortality?"}, {"time": 2026, "text": "I'm a believer in previous lives."}, {"time": 2029, "text": "So I sort of, and I, the question I've never been able to answer among many, many others is like, why are we even here?"}, {"time": 2038, "text": "Why are we in the flesh?"}, {"time": 2041, "text": "You know, I sort of, I like to believe that God or some force is, we're on some kind of journey, but I'm not sure why, why we were put in this world where the ground rules are, if you think about animal life, that you cannot live from one day to the next without killing and eating some other form of life."}, {"time": 2066, "text": "I mean, what a demented thing, you know?"}, {"time": 2069, "text": "Why couldn't we just have a solar panel on our head and, you know, be friends with everybody?"}, {"time": 2075, "text": "So I sort of, I don't get what that was all about, but that's sort of the big issue."}, {"time": 2082, "text": "Have you read to Ernest Becker's Denial of Death, for example?"}, {"time": 2086, "text": "Is Ernest Becker's a philosopher that said that the death, that the fear of death is really the primary driver of everything we do."}, {"time": 2098, "text": "So Freud had what the?"}, {"time": 2100, "text": "Right, I would agree with that."}, {"time": 2102, "text": "So to you, you've always thought about your, even your own mortality."}, {"time": 2107, "text": "And can you elaborate on the reincarnation aspect of what you were talking about?"}, {"time": 2114, "text": "Like that we kind of, what's your sense that we had previous lives?"}, {"time": 2120, "text": "In what, have you thought concretely or is it a lot of it kind of is?"}, {"time": 2124, "text": "No, I've thought concretely about it."}, {"time": 2127, "text": "I mean, it's very clear when you see children, young kids, or even dogs and cats, that they come into the world with personalities, you know, and three kids in a family are gonna be completely different and completely their own person."}, {"time": 2145, "text": "And that person that they are doesn't change over life."}, {"time": 2150, "text": "And I, you know, there's one of the things that I did in my book The Artist's Journey is that there were certain things where I tracked or just listed in order, like all of Bruce Springsteen's albums or all of Philip Roth's books, you know, kind of a body of work throughout over, you know, a period of 30, 40, 50 years, you know."}, {"time": 2173, "text": "And you can see that there's a theme running through all of those things, that it's completely unique to that person."}, {"time": 2182, "text": "Nobody else could have written Philip Roth's books or Bruce Springsteen's songs."}, {"time": 2188, "text": "And you can even see sort of a destiny there."}, {"time": 2191, "text": "So I ask myself, well, where did that come from?"}, {"time": 2196, "text": "What, it seems to be a continuation of something that was, that happened before, and that will lead to something else because it's not starting from scratch."}, {"time": 2207, "text": "It seems like there's a calling, a destiny in there already."}, {"time": 2213, "text": "This gets back to the muse and all that kind of thing."}, {"time": 2216, "text": "So yeah, it's almost like the, there's this, let's call it a God, it's passing, it's almost like sampling parts of a previous human that has lived and putting those into the new one."}, {"time": 2231, "text": "Sampling is probably a pretty good word."}, {"time": 2234, "text": "Taking some of the good, well, you can't take all the good parts because the bad parts is what makes the person."}, {"time": 2239, "text": "Let's say you're taking it all together."}, {"time": 2241, "text": "Okay, this is humans only, or does it pass around from animals in your view?"}, {"time": 2246, "text": "I don't know, that's above my pay grade, I don't know."}, {"time": 2249, "text": "So, okay, so you talk about the muse as the source of ideas maybe."}, {"time": 2259, "text": "Since you've gotten a few glimpses of her in your writing, tell me, what is it possible for you to tell me about her?"}, {"time": 2271, "text": "Where does she reside?"}, {"time": 2273, "text": "What does she look like?"}, {"time": 2274, "text": "I mean, you can look at it many different ways, right?"}, {"time": 2277, "text": "The Greeks did it in an anthropomorphic way, right?"}, {"time": 2280, "text": "They created gods that were like human beings."}, {"time": 2283, "text": "But if you look at it from a Kabbalistic Jewish perspective, Jewish mysticism, you could say that it's the soul, the neshama, right?"}, {"time": 2291, "text": "That the soul is above us on a higher plane, our own, your soul, my soul, and is trying to reach down to us and communicate with us."}, {"time": 2301, "text": "And we're trying simultaneously to reach up to it through prayer or through, if you're a writer or an artist, you know, when you sit down at the keyboard, you're entering into a kind of prayer."}, {"time": 2313, "text": "You're entering into a different state of an altered consciousness to some extent."}, {"time": 2319, "text": "You're opening yourself, opening the pipeline, or turning on the radio to tune into the cosmic radio station."}, {"time": 2326, "text": "And another way of looking at it, this is an, did you ever see the movie City of Angels?"}, {"time": 2333, "text": "The visual of the movie, it was Meg Ryan and Nicolas Cage."}, {"time": 2339, "text": "Yeah, yeah, I've seen it, yep."}, {"time": 2341, "text": "And right, the visual of the movie sort of was Meg Ryan is a heart surgeon."}, {"time": 2348, "text": "And as she's operating on somebody, suddenly Nicolas Cage in this long duster coat, like Jesse James, appears right next to her in the operating room, and he's an angel."}, {"time": 2359, "text": "And he's waiting to take out the soul of the patient on the operating table."}, {"time": 2367, "text": "And she doesn't see him, she's totally unaware of him."}, {"time": 2369, "text": "And so is everybody else in the operating room, except maybe the guy who's about to die, who suddenly sees him."}, {"time": 2375, "text": "But I kind of believe that there are beings like that, or if you don't like that, it's a force, it's a consciousness, it's something that are right here, right now."}, {"time": 2389, "text": "And they're trying to communicate to us."}, {"time": 2394, "text": "And like through a membrane, like tapping on that window over there, they're like right out there."}, {"time": 2400, "text": "And they carry the future."}, {"time": 2403, "text": "They are everything that is in potential."}, {"time": 2408, "text": "All the works that you will do, Lex, your startup, whatever else you're doing, they know that."}, {"time": 2417, "text": "And it's not really you that's coming up with those ideas, in my opinion."}, {"time": 2422, "text": "Those things are appearing, it's like somebody knocks on the door and puts it in."}, {"time": 2428, "text": "I mean, in the Iliad, where gods and goddesses appear, along with the human antagonists on the battlefield all the time, right?"}, {"time": 2437, "text": "There'll be, you know, Homer flashes to Olympus and then back to the real world."}, {"time": 2442, "text": "And there's a thing where one Aphrodite, let's say wants to help Paris."}, {"time": 2447, "text": "And so she says, well, I will appear to him in a dream."}, {"time": 2452, "text": "And I'll take the form of his brother and I'll say, bump, bump, bump, bump."}, {"time": 2457, "text": "So that's creatures, beings on one dimension, as the Greeks saw it, communicating with, and I believe that that's exactly what's going on, in one, whatever analogy you want to use."}, {"time": 2472, "text": "That communication, to which degree do you play the role in that communication?"}, {"time": 2480, "text": "As opposed to sitting at the computer, if you're a writer, and staring at the blank page and putting in the time and waiting."}, {"time": 2490, "text": "So if, in your view, are these creatures basically waiting to tell you about your future?"}, {"time": 2502, "text": "Or is there choice?"}, {"time": 2504, "text": "How many possible futures are there?"}, {"time": 2506, "text": "How many possible ideas are there?"}, {"time": 2509, "text": "I think there's basically, yes, there are alternatives, you know, degrees within it."}, {"time": 2516, "text": "But if you look at Bruce Springsteen's albums, how much could he have done really differently?"}, {"time": 2525, "text": "Yeah, he would, you can just see there's a whole impetus going through the whole thing."}, {"time": 2531, "text": "And nothing was going to shake him off that, you know?"}, {"time": 2534, "text": "And yeah, maybe the river could have been different, could have been called something else, but he was dealing with certain issues."}, {"time": 2543, "text": "His conscious self was dealing with certain issues that were really out of his control."}, {"time": 2548, "text": "He was drawn, he was called to it, right?"}, {"time": 2550, "text": "Nothing could stop him."}, {"time": 2552, "text": "And so it is sort of a partnership, I think, the creative process, between the creative impulse that's coming from some other place, or it's coming from deep within us is another way to look at it."}, {"time": 2568, "text": "You know, it's like if we are acorns and we're growing into oaks."}, {"time": 2573, "text": "So the conscious artist, who's sitting there at the keyboard or whatever, is applying his or her consciousness to that, but is also going into opening themselves to the unconscious or to this other realm, whatever that is."}, {"time": 2593, "text": "I mean, certainly songwriters for a million years have said, you know, a song just came into their head, right?"}, {"time": 2599, "text": "A poem, just all they had to do was write."}, {"time": 2601, "text": "But then, you ever see that thing where, of Keats's notes for a thing of beauty is a joy forever?"}, {"time": 2608, "text": "It's like covers an entire page, and it's like, you know, he's crossing this out and that out, and he has to go."}, {"time": 2613, "text": "His consciousness is, his conscious mind is working on it."}, {"time": 2616, "text": "But, so I do think it's a partnership."}, {"time": 2619, "text": "And I think that, I know when I was first starting out as a writer, I worked in advertising, and I tried to do novels that I could never do."}, {"time": 2629, "text": "I was like, really unskilled at getting to that, tuning into that station."}, {"time": 2636, "text": "I just, I beat my brains out and was unable to do it, you know, except in, because I was sort of trying too hard, it was sort of like a Zen monk or a monk of some kind trying to meditate and just like constantly thoughts driving you crazy."}, {"time": 2654, "text": "But over time, you know, knock wood, I've kind of gotten better at it."}, {"time": 2659, "text": "And I can sort of let go of those, that part of me that's trying so hard."}, {"time": 2665, "text": "And so these angels can speak a little more easily through the membrane."}, {"time": 2672, "text": "Can you put into words the process of letting go and clearing that channel of communication?"}, {"time": 2681, "text": "That's another great question."}, {"time": 2682, "text": "For me, it just took, it took probably 30 years."}, {"time": 2686, "text": "And I don't even, I guess I would liken it to meditation, even though I'm not a meditator."}, {"time": 2692, "text": "But it would seem to me to be one of the hardest things in the world to just sit still and stop thinking, right?"}, {"time": 2700, "text": "And so it's very hard to put into words."}, {"time": 2703, "text": "And I think that's why these teachers of meditation use tricks and koans and stuff like that."}, {"time": 2710, "text": "But for me, at least, I think it was just a process of years of years and years of trying, and finally beating my head in the wall."}, {"time": 2720, "text": "And finally, little by little giving up the beating of the head."}, {"time": 2726, "text": "But there doesn't seem to be any trick."}, {"time": 2728, "text": "Everybody wants a hack these days."}, {"time": 2730, "text": "And I don't think there is a hack."}, {"time": 2734, "text": "If you look at it in terms of the goddess, the muse, she's watching you down there, beating your head in the wall."}, {"time": 2740, "text": "You're like a Marine going through an obstacle course, or a martial artist trying to learn, like Uma Thurman doing the casket deal, trying to make that little four inch punch, you know?"}, {"time": 2754, "text": "The muse or the goddess is just sort of watching, going, it's Lex, he's trying, he's trying."}, {"time": 2759, "text": "I'm gonna come back in another couple of months and see if he's still there."}, {"time": 2763, "text": "And finally, she'll say, all right, he's had it, he's paid his dues, I'm gonna give it to him."}, {"time": 2769, "text": "So, the hard work and the suffering, yeah."}, {"time": 2773, "text": "But I'm also, being Russian, in wrestling and martial arts, we're big into drilling technique."}, {"time": 2781, "text": "I was also just even getting at, certainly there's no shortcut."}, {"time": 2786, "text": "But is there a process?"}, {"time": 2788, "text": "So you're, that can be, the process of practice."}, {"time": 2793, "text": "So you had two."}, {"time": 2795, "text": "One, you had an example of meditation."}, {"time": 2799, "text": "So it's essentially the practice of meditation."}, {"time": 2801, "text": "Is you sitting here?"}, {"time": 2802, "text": "I think a lot of drill, I think, is a good way to look at it too."}, {"time": 2805, "text": "But what are you drilling?"}, {"time": 2808, "text": "You're just sitting and?"}, {"time": 2810, "text": "You're writing, you know?"}, {"time": 2811, "text": "Just writing."}, {"time": 2812, "text": "You're writing, then you're looking at what you wrote, you know?"}, {"time": 2816, "text": "You're hitting moments when it flows, you know?"}, {"time": 2820, "text": "And then your other hitting moments where you just can't do anything."}, {"time": 2823, "text": "And you're trying to, from the moments where it flowed, you're trying to come back and look at it and say, what did I do?"}, {"time": 2829, "text": "How did that happen?"}, {"time": 2831, "text": "Where was my mind, you know?"}, {"time": 2833, "text": "But I think it's just a process of over and over and over and over until finally it gets a little bit easier."}, {"time": 2842, "text": "And did you always, when you read something you write, did you always have a pretty good radar for what's good and not after it's written?"}, {"time": 2853, "text": "I think I do now."}, {"time": 2857, "text": "But no, it was always really hard for me to know what was good."}, {"time": 2865, "text": "I mean, do you edit, the process of editing is the process of looking at what you've written and improving it."}, {"time": 2874, "text": "Are you a better writer or an editor?"}, {"time": 2876, "text": "How often do you edit?"}, {"time": 2880, "text": "Cause I do think that in writing, the real process of looking at it is the process that an editor does rather than what a writer does."}, {"time": 2888, "text": "The gentleman I was just talking to on the phone is my editor, Sean Coyne, who was the guy who bought Gates of Fire when he was an editor at Doubleday."}, {"time": 2896, "text": "And who basically when I finish a book, I give it to him."}, {"time": 2901, "text": "And he gives me, you know, editing doesn't really mean like crossing out commas."}, {"time": 2909, "text": "It really means looking at the overall work and saying, does it work?"}, {"time": 2916, "text": "And if it doesn't work, why doesn't it work?"}, {"time": 2919, "text": "Is there something wrong here?"}, {"time": 2921, "text": "You know, like if you were building the Golden Gate Bridge, you know, and one span was out of whack, you know, you could, and I think a really skilled editor, which Sean is, understands what makes a story tick."}, {"time": 2934, "text": "And he also has the perspective that I've lost in something I've wrote, cause I'm so close to it, to say, you know, this isn't working and that is working."}, {"time": 2946, "text": "What kind of advice has he given you?"}, {"time": 2947, "text": "Is it like layout?"}, {"time": 2949, "text": "Like this story doesn't flow correctly."}, {"time": 2952, "text": "Like you shouldn't start at this point."}, {"time": 2955, "text": "Or does he even sit back at a higher level and say, I see what you're doing, but you could do better."}, {"time": 2962, "text": "No, he doesn't do that."}, {"time": 2964, "text": "But a lot of it is about genre and kind of the defining what genre you're working in."}, {"time": 2972, "text": "And I'm gonna get up here to just bring something over here for the camera."}, {"time": 2979, "text": "This was one where Sean tore this down and made me start from scratch."}, {"time": 2984, "text": "And what the specifics of it were really, this is a supernatural thriller."}, {"time": 2990, "text": "That's the genre."}, {"time": 2991, "text": "Sort of like Rosemary's Baby or The Exorcist."}, {"time": 2995, "text": "And what he showed me was that I had violated certain conventions of the genre."}, {"time": 3005, "text": "And you just can't do that."}, {"time": 3008, "text": "It's gotta be, it has to be done the right way."}, {"time": 3012, "text": "And so he pointed out certain things to me."}, {"time": 3018, "text": "So he must be a prolific reader himself too, actually."}, {"time": 3022, "text": "That's such a tough job of editor."}, {"time": 3026, "text": "Again, he was sort of born to do that."}, {"time": 3028, "text": "He just kind of glommed onto it."}, {"time": 3031, "text": "But since he was his first job publishing cat thrillers, cat detective books, he studied how it works, what makes a story work, et cetera, et cetera."}, {"time": 3047, "text": "And so he really, he's great."}, {"time": 3048, "text": "And I think any really successful writer, unless they're utterly brilliant on their own, has gotta have a great editor behind them."}, {"time": 3057, "text": "But you yourself edit as well."}, {"time": 3060, "text": "I'm constantly trying to learn from him and teach myself."}, {"time": 3063, "text": "Everything you see in my blog posts that it's about the craft of writing is me trying to teach myself the rules so that, I'm sure it's the same in martial arts or anything else, right?"}, {"time": 3076, "text": "You try to not be dependent on that other person because it's so painful to make those mistakes."}, {"time": 3084, "text": "You really feel like, ah, I wish I could get it right the first time the next time I do it."}, {"time": 3089, "text": "Well, in research, we go through that."}, {"time": 3090, "text": "In research more than writing, so what you do is a little more solitary."}, {"time": 3095, "text": "In research, there's usually two, three, four people working on something together and we write a paper."}, {"time": 3101, "text": "And there's that painful process of where you write it down and then you share it with other."}, {"time": 3106, "text": "And not only do they criticize the writing, they criticize the fundamental aspects of the approach you've taken."}, {"time": 3114, "text": "I would think so."}, {"time": 3115, "text": "So it's exactly like they would say you're attacking, you're asking the wrong questions, right?"}, {"time": 3121, "text": "And that's extremely painful, especially when you, well, yes, painful and helpful, but there's disagreement and so on."}, {"time": 3129, "text": "And through that comes out a better product."}, {"time": 3132, "text": "And if you want to still have an ego, but you also want to silence it every once in a while, so there's a balance."}, {"time": 3139, "text": "In your book, The War of Art, you talk about resistance, what the capital R, as the invisible force in this universe of ours that finds a way to prevent you from starting or doing the work."}, {"time": 3156, "text": "Where do you think resistance comes from?"}, {"time": 3159, "text": "Why is there a force in our mind that's constantly trying to jeopardize our efforts with laziness, excuses, and so on?"}, {"time": 3168, "text": "I mean, in Jewish mysticism, in Kabbalistic thinking, it's called the yetzer hurrah, right?"}, {"time": 3175, "text": "And it's a force that if this up here is your soul of Neshama trying to talk to you, us down here, the yetzer hurrah is this negative force in the middle."}, {"time": 3186, "text": "So I'm not the only one that ever thought about this."}, {"time": 3188, "text": "But, and I don't know if anybody really knows the answer, but here's my answer."}, {"time": 3193, "text": "I think that there are two places where we as human beings can see our identity."}, {"time": 3201, "text": "One is the ego, the conscious ego, and the other is the greater self."}, {"time": 3207, "text": "And the self in the Jungian sense, the self in the Jungian sense includes the unconscious and butts up against what Jung called the divine ground, which what I would call the muse, the goddess, or whatever."}, {"time": 3220, "text": "And I think, and the ego is just this little dot inside this bigger self."}, {"time": 3225, "text": "And the ego has a completely different view of life from the self."}, {"time": 3233, "text": "The ego believes, I'm gonna give you a long answer here."}, {"time": 3236, "text": "No, perfect."}, {"time": 3237, "text": "The ego believes that death is real."}, {"time": 3241, "text": "The ego believes that time and space are real."}, {"time": 3245, "text": "The ego believes that each one of us is separate from the other."}, {"time": 3249, "text": "I'm separate from you."}, {"time": 3251, "text": "If I could punch you in the face and it wouldn't hurt me, it would only hurt you."}, {"time": 3256, "text": "And in the ego's world, the dominant emotion is fear because we were all made of flesh."}, {"time": 3263, "text": "We can all die."}, {"time": 3264, "text": "We can all be hurt."}, {"time": 3265, "text": "We can all be ruined."}, {"time": 3266, "text": "So we are protecting ourselves and even our desire to create, as we were talking about before, comes out of that fear of death."}, {"time": 3275, "text": "The self, on the other hand, the greater self that butts up against the divine ground believes that death is not real, that time and space are not real, that the gods travel swift as thought."}, {"time": 3288, "text": "And the ego also believes that, I mean, the self believes that there's no difference between you and me, that we're all one."}, {"time": 3295, "text": "If I hurt you, I hurt myself, karma, right?"}, {"time": 3300, "text": "And in the world of the self, of the greater self, the dominant emotion is love, not fear."}, {"time": 3307, "text": "Now, so I think that, I'll go farther back here, a long way to answer your question."}, {"time": 3314, "text": "When Jesus died on the cross, or when the 300 Spartans willingly sacrificed their lives at Thermopylae, they were acting according to the rules of the self."}, {"time": 3328, "text": "Death is not real."}, {"time": 3330, "text": "No difference between you and me."}, {"time": 3332, "text": "Time and space are not real."}, {"time": 3333, "text": "Predominant emotion is love."}, {"time": 3336, "text": "So, in my opinion, we as conscious human vessels are in a struggle between these two things, the ego and the self."}, {"time": 3348, "text": "To me, resistance is the voice of the ego saying, and it's a fearful voice, because if, when we identify with the self, we move our consciousness over to the self as artists or scientists opening ourselves up to the cosmic dimension, to the other forces, the ego is tremendously threatened by that."}, {"time": 3373, "text": "Because if we're in that space, that head space, we don't need the ego anymore."}, {"time": 3380, "text": "So I think resistance is a voice of the ego trying to keep control of us."}, {"time": 3387, "text": "In a way, I'll give you a bad example, Trump is the ego."}, {"time": 3391, "text": "That's probably a very good example, right?"}, {"time": 3395, "text": "It's a zero sum world for him, and for anybody that's in that."}, {"time": 3401, "text": "And the opposite of that would be somebody like Martin Luther King or Gandhi."}, {"time": 3406, "text": "Gandhi, yep."}, {"time": 3407, "text": "And that's, of course, why they all wind up getting assassinated."}, {"time": 3411, "text": "Because that voice, that ego, is hanging on to itself and feels so threatened by, I could talk more about this if you want to."}, {"time": 3421, "text": "No, for sure, that's fascinating."}, {"time": 3424, "text": "It's just, it's interesting why the fear is attached to the ego."}, {"time": 3428, "text": "I really like this dichotomy of ego and self and that struggle."}, {"time": 3434, "text": "It's just, ego has a, the self obsession of it."}, {"time": 3440, "text": "Why fear is such a predominant thing?"}, {"time": 3445, "text": "Why is resistance trying to undermine everything?"}, {"time": 3449, "text": "It's fear, it's out of fear."}, {"time": 3452, "text": "Let's think about the whole thing in terms of stories."}, {"time": 3454, "text": "In a story, the villain is always resistance, is always the ego."}, {"time": 3462, "text": "The hero is always, of course, always is not everything, but you know what I mean?"}, {"time": 3467, "text": "Pretty much represents kind of the self."}, {"time": 3470, "text": "If you think about the alien on the spaceship, that's like the ultimate kind of villain."}, {"time": 3475, "text": "It keeps changing form, right?"}, {"time": 3477, "text": "First it goes on the guy's face, then it pops out of his chest, but it always just has that one monomaniacal thing to destroy, you know?"}, {"time": 3487, "text": "And just like the ego, just like resistance."}, {"time": 3530, "text": "I don't know if that's clear, but in almost every story, the villain is the ego, is resistance, is fear, is that zero sum thing."}, {"time": 3541, "text": "And in almost every story, the hero is someone that is willing to make a sacrifice to help others."}, {"time": 3551, "text": "It's letting go of that fear is what leads to productivity and to success."}, {"time": 3558, "text": "Do you think there's a, this is probably the answer is either obvious or impossible, but do you think there's an evolutionary advantage to resistance?"}, {"time": 3571, "text": "Like, what would life look like without resistance?"}, {"time": 3578, "text": "I think, I also believe that resistance, like death, gives meaning to life."}, {"time": 3584, "text": "If we didn't have it, it's gonna be, you know, what would we be?"}, {"time": 3589, "text": "We'd be in the Garden of Eden, picking fruit and just happy and stupid, you know?"}, {"time": 3596, "text": "And I do think that that myth of the Garden of Eden is really about this kind of thing, you know, where Adam and Eve decide to sort of take matters into their own hands and acquire knowledge that until then, God had said, I'm the only one that's got that knowledge."}, {"time": 3614, "text": "And of course, once they have acquired that knowledge, they're cast out into the world you and I live in now, where they do have to deal with that fear and they do have to deal with all that stuff."}, {"time": 3626, "text": "The human condition."}, {"time": 3627, "text": "The human condition and the meaning and the purpose comes from the resistance being there and the struggle to overcome it."}, {"time": 3638, "text": "To overcome it, right."}, {"time": 3639, "text": "And also the other aspect of it is that it's not real at all."}, {"time": 3645, "text": "It's not even like it's an actual force."}, {"time": 3648, "text": "It's all here, right?"}, {"time": 3650, "text": "So the sort of, in a way, it's sort of a surrender to it, you know?"}, {"time": 3660, "text": "You know, or it's just a sort of like turning on the light in a dark thing."}, {"time": 3666, "text": "It's like, oh, it's gone."}, {"time": 3669, "text": "But not quite because it's never really."}, {"time": 3671, "text": "Because it comes back again tomorrow morning."}, {"time": 3674, "text": "So you have to keep changing light bulbs every day."}, {"time": 3677, "text": "So what's been, maybe recently, but in general, maybe in your life, what's been the most relentless or one of the more relentless sources of resistance to you personally?"}, {"time": 3688, "text": "I mean, it's always the same."}, {"time": 3690, "text": "It's about writing for me and evolving within my own body of work, you know?"}, {"time": 3698, "text": "It never goes away, it never gets any less."}, {"time": 3703, "text": "Do you have particular excuses, particular justifications that come out?"}, {"time": 3709, "text": "No, it's always the same."}, {"time": 3711, "text": "Well, I would say it's always the same, but it's really not because resistance is so protean, you know, it keeps changing form."}, {"time": 3718, "text": "And as you move to hopefully a higher level, resistance gets a little more nuanced and a little more subtle trying to fake you out."}, {"time": 3727, "text": "But I think you learn that it's always there and you're always gonna have to face it, so."}, {"time": 3734, "text": "I mean, your battle is sitting down and writing to some number of words to a blank page."}, {"time": 3743, "text": "Do you have a process there with this battle?"}, {"time": 3748, "text": "Do you have a number of hours that you put in?"}, {"time": 3751, "text": "Do you sit down?"}, {"time": 3752, "text": "Yeah, I'm definitely a believer that even though this battle is fought on the highest sort of spiritual level, that the way you fight it is on the most mundane, I'm sure it's like martial arts, must be the same way."}, {"time": 3766, "text": "I mean, I go to the gym first thing in the morning and I sort of am rehearsing myself."}, {"time": 3774, "text": "The gym is called resistance training, right?"}, {"time": 3777, "text": "You're working against resistance, right?"}, {"time": 3779, "text": "And I don't wanna go, I don't wanna get out of bed, I hate that, but I'm sort of fortifying myself to be ready for the day."}, {"time": 3789, "text": "And like I said, over Knockwood, over years, I've learned to sort of get into the right kind of mindset and it's not as hard for me as it used to be."}, {"time": 3800, "text": "The real resistance, I think, for me, and I think this is true for anybody, is the question of sort of what's the next idea?"}, {"time": 3807, "text": "What's the next book?"}, {"time": 3809, "text": "What's the next project that you're gonna work on?"}, {"time": 3811, "text": "And when I ask that question, I'm asking it of the muse."}, {"time": 3815, "text": "I'm kind of saying, what do you want me, or I'm asking it of my unconscious."}, {"time": 3820, "text": "If we're looking at Bruce Springsteen's albums, it's kind of, well, what's the next album?"}, {"time": 3825, "text": "Now he's on Broadway."}, {"time": 3826, "text": "That was a great idea, right?"}, {"time": 3829, "text": "Where'd that come from, you know?"}, {"time": 3831, "text": "But, and then for him, what's after that, you know?"}, {"time": 3835, "text": "Because that body of work is already alive."}, {"time": 3843, "text": "It already exists inside us, kind of like a woman's biological clock, and we have to serve it."}, {"time": 3852, "text": "And we have to, otherwise it'll give us cancer, you know?"}, {"time": 3857, "text": "I don't mean to say that if anybody has cancer that they're not, you know what I mean?"}, {"time": 3861, "text": "It'll take its revenge on us."}, {"time": 3864, "text": "So the next resistance to me is sort of, or a big aspect of it is, what's next?"}, {"time": 3870, "text": "You know, when I finish the book I'm working on now, I'm not sure what I'm gonna do next."}, {"time": 3873, "text": "And I see at the same time you have a kind of, you have a sense that there's a Bruce Springsteen single line of albums."}, {"time": 3885, "text": "So like, it's already known somewhere in the universe what you're going to do next, is the sense you have."}, {"time": 3891, "text": "In a sense, yes."}, {"time": 3893, "text": "I don't know if it's predetermined, you know?"}, {"time": 3895, "text": "But there's something like that."}, {"time": 3900, "text": "Yeah, I'd like to believe that there's, well, it's kind of like quantum mechanics, I guess."}, {"time": 3906, "text": "Once you observe it, maybe once you talk to the muse, it's one thing for sure."}, {"time": 3913, "text": "It was always going to be that one thing."}, {"time": 3915, "text": "But really, in reality, it's a distribution."}, {"time": 3919, "text": "It could be any number of things."}, {"time": 3921, "text": "There's alternate realities."}, {"time": 3922, "text": "Alternate realities, yeah."}, {"time": 3924, "text": "But they're not that far apart."}, {"time": 3925, "text": "I mean, Bruce Springsteen is not gonna write a Joni Mitchell song, you know?"}, {"time": 3930, "text": "No matter how hard he tries."}, {"time": 3931, "text": "But he still went on Broadway."}, {"time": 3932, "text": "I mean, he still did that, which is not a Bruce Springsteen thing to do."}, {"time": 3936, "text": "So I think you're being, in retrospect, it all makes sense."}, {"time": 3939, "text": "I think it is a Bruce Springsteen thing to do."}, {"time": 3941, "text": "It's a next sort of evolution for him."}, {"time": 3943, "text": "Why not take his music to there, you know?"}, {"time": 3946, "text": "In retrospect, it all makes perfect sense, I think."}, {"time": 3951, "text": "If you pull it off, especially."}, {"time": 3954, "text": "Do you visualize yourself completing the work?"}, {"time": 3957, "text": "Like, Olympic athletes visualize getting the gold medal."}, {"time": 3962, "text": "Do you, you know, they go through, I mean, that's actually a really, you can learn something from athletes on that, is years out, certainly two, three years out, some people do much longer, every day, you visualize how the day of the championship will go down to, I mean, everything, down to how will it feel to stand on the podium and so on."}, {"time": 3987, "text": "Do you do anything like that in how you approach writing?"}, {"time": 3992, "text": "Because it's."}, {"time": 3992, "text": "It's always in the moment."}, {"time": 3993, "text": "Because, yeah, it is in the moment, I think."}, {"time": 3995, "text": "Because it's such a mystery."}, {"time": 3996, "text": "You just don't know."}, {"time": 3997, "text": "I think it's different from sports."}, {"time": 4000, "text": "Because you don't know the destiny."}, {"time": 4001, "text": "There's no gold medal at the end."}, {"time": 4004, "text": "In fact, I would like to think that as soon as you finish one, the next day you're on the other."}, {"time": 4013, "text": "And in fact, hopefully you've already started the other."}, {"time": 4016, "text": "You're already, you know, 100 pages into the other when you finish the first one."}, {"time": 4023, "text": "But it is a, it is a, it's a journey, it's a process."}, {"time": 4030, "text": "I don't think it is a, in fact, I think it's very dangerous to think that way."}, {"time": 4034, "text": "To think, oh, this, I'm gonna win the Oscar, you know?"}, {"time": 4041, "text": "For the creative process, it might be dangerous."}, {"time": 4044, "text": "It's a, maybe you can, like, why is that dangerous?"}, {"time": 4049, "text": "Because I kind of know where you're coming from."}, {"time": 4050, "text": "Because it's the ego."}, {"time": 4052, "text": "It's the ego."}, {"time": 4053, "text": "Because you're giving yourself over to the ego."}, {"time": 4054, "text": "You know, I keep saying this myself."}, {"time": 4058, "text": "My job, I'm a servant of the muse."}, {"time": 4061, "text": "I'm there to do what she tells me to do."}, {"time": 4064, "text": "And if I suddenly think, oh, I'm really, I just wanna, you know, whatever, the muse doesn't like that."}, {"time": 4071, "text": "And, you know, and she's on another dimension from me."}, {"time": 4078, "text": "I'm trying to square that, because I agree."}, {"time": 4081, "text": "I'm trying to square that with the, I think there's a meditation to visualizing success in the athletic realm, to where it focuses, it removes everything else away, to where you focus on this particular battle."}, {"time": 4098, "text": "I mean, I think that you can do that in many kinds of ways."}, {"time": 4103, "text": "And in sports, the ego serves a more important role, I think, than it does in writing."}, {"time": 4111, "text": "And the ego, there's something."}, {"time": 4113, "text": "Well, let me, when you say that, I know what you mean, Lex, and I do think there is a sort of a, you know, it's interesting to watch interviews with Steph Curry, who's such, obviously such a nice guy, but he's got such tremendous self confidence, you know, that it, but it doesn't border on ego so much because he's worked so hard for it, you know?"}, {"time": 4141, "text": "But he knows, so he has visualized."}, {"time": 4144, "text": "He has visualized maybe not so much winning, you know, as just him being the best he can be, him being in the flow, you know, doing his thing that he knows he can do."}, {"time": 4158, "text": "And I do think in the creative world, yeah, there is a sort of a thing like that, where you, where, and, you know, a choreographer or a filmmaker or whatever might be, do an internal thing where they're saying, I can make an Oscar winning movie."}, {"time": 4176, "text": "I can direct this movie."}, {"time": 4178, "text": "You know, I'm banishing these thoughts that I'm not good enough."}, {"time": 4182, "text": "I can edit it."}, {"time": 4184, "text": "I can score it."}, {"time": 4185, "text": "I can, you know, bump it, bump it, bump."}, {"time": 4187, "text": "But, and I don't think that's really ego."}, {"time": 4189, "text": "I think that's part of the process in a good way, like an athlete does that."}, {"time": 4195, "text": "So extreme confidence is what some of the best athletes come with, and you think it's possible to, as a writer, to have extreme confidence in yourself?"}, {"time": 4204, "text": "I do think so, you know, that I'm sure when John Lennon sat down to write a song, he felt like, shit, I can do this, you know?"}, {"time": 4214, "text": "I'm not so sure."}, {"time": 4216, "text": "I think, because the great artists I've seen, and you're haunted by self doubt."}, {"time": 4223, "text": "It's that resist, I mean, the confidence."}, {"time": 4226, "text": "Yes, but I mean, I guess, but even beyond the self, within the self, above the self doubt."}, {"time": 4230, "text": "Oh, it's the bigger picture of the self belief, you know?"}, {"time": 4233, "text": "Yeah, I'm freaking out."}, {"time": 4235, "text": "Yeah, I'm worried that I'm not gonna be able to do it."}, {"time": 4236, "text": "But, you know, I know I can do this."}, {"time": 4238, "text": "Yeah, and when you look at, when you take a bigger picture of it."}, {"time": 4241, "text": "So the writing process, is it fundamentally lonely?"}, {"time": 4248, "text": "No, because you're with your characters."}, {"time": 4255, "text": "So you really put yourself in the world."}, {"time": 4258, "text": "Absolutely, you know, I've written about this before that I used to, my desk used to face a wall instead of seeing, and people would say, well, don't you wanna look out the window?"}, {"time": 4268, "text": "But I'm in here, I mean, I'm seeing, you know, the Spartans, I'm seeing, you know, whatever."}, {"time": 4274, "text": "And the characters that are on the page, or that you create, are not accidents, you know?"}, {"time": 4282, "text": "They're coming out of some issue, some deep issue that you have."}, {"time": 4287, "text": "Whether you realize it or not, you might not realize it till 20 years later, or somebody explains it to you."}, {"time": 4291, "text": "So your characters are kind of fascinating to you."}, {"time": 4295, "text": "And their dilemmas are fascinating to you."}, {"time": 4298, "text": "And you're also trying to come to grips with them, you know, you sort of see them through a glass darkly, you know, and you really wanna see them more clearly."}, {"time": 4309, "text": "So yeah, no, it's not lonely at all."}, {"time": 4312, "text": "In fact, I'm more lonely sometimes later, going out to dinner with some people and actually talking to people."}, {"time": 4319, "text": "Do you miss the characters after it's over?"}, {"time": 4323, "text": "Let's say I have affection for them, kind of like children that have gone off to college and now are, you know, you only see them at Thanksgiving."}, {"time": 4332, "text": "Definitely, I have affection for them, even the bad guys."}, {"time": 4338, "text": "Maybe especially the bad guys."}, {"time": 4342, "text": "Especially the bad guys."}, {"time": 4345, "text": "You've said that writers, even successful writers, are often not tough minded enough."}, {"time": 4352, "text": "I've read that in the post, that you have to be a professional in the way you handle your emotions."}, {"time": 4358, "text": "You have to be a bit of a warrior to be a writer."}, {"time": 4361, "text": "So what do you think makes a warrior?"}, {"time": 4367, "text": "Is a warrior born or trained in the realm, in the bigger realm, in the realm of writing, in the creative process?"}, {"time": 4375, "text": "I think they're born to some extent."}, {"time": 4377, "text": "You have the gift, like you might have the gift as a martial artist to do whatever martial artists do, but the training is the big thing."}, {"time": 4385, "text": "90% training, 10%, 10% genetics."}, {"time": 4389, "text": "And, you know, I use another analogy other than warrior as far as writer, and that's like to be a mother."}, {"time": 4396, "text": "If you think about, if you're a writer or any creative person, you're giving birth to something, right, you're carrying a new life inside you."}, {"time": 4403, "text": "And in terms of bravery, if your child, your two year old child is underneath a car that's coming down the street, the mother's gonna like stop a Buick, you know, with her bare hands."}, {"time": 4417, "text": "So that's another way to think about how a writer has to think about, or any creative person has to think about, I think, what they're doing, what this child, this new creation that they're bringing forth."}, {"time": 4433, "text": "Yeah, so the hard work that's underlying that."}, {"time": 4437, "text": "I've just, a couple weeks ago, talked to, just happened to be in the same room, both gave talks, Arianna Huffington."}, {"time": 4443, "text": "I did this conversation with her."}, {"time": 4448, "text": "I didn't know much about her before then, but she has recently been, she wrote a couple books and been promoting a lifestyle where she basically, she created the Huffington Post, and she gave herself like, I don't know, 20 hours a day just obsessed with her work."}, {"time": 4466, "text": "And then she fainted, passed out, and kind of, there was some health issues."}, {"time": 4471, "text": "And so she wrote this book saying that, you know, sleep, basically you wanna establish a lifestyle that doesn't sacrifice health, that's productive but doesn't sacrifice health."}, {"time": 4483, "text": "She thinks that you can have both, productivity and health."}, {"time": 4486, "text": "Criticizing Elon Musk, who I've also spoken with, for working too hard, and thereby sacrificing, you know, being less effective than he could be."}, {"time": 4499, "text": "So I'm trying to get this balance between health and obsessively working at something and really working hard."}, {"time": 4509, "text": "So what Arianna is talking about makes sense to me, but I'm a little bit torn."}, {"time": 4513, "text": "To me, passion and reason do not overlap much or at all sometimes."}, {"time": 4519, "text": "Maybe I'm being too Russian, but I feel madness and obsession does not care for health or sleep or diet or any of that."}, {"time": 4528, "text": "And hard work is hard work, and everything else can go to hell."}, {"time": 4534, "text": "So if you're really focused on whether it's writing a book, it should, everything should just go to hell."}, {"time": 4540, "text": "Where do you stand on this balance?"}, {"time": 4543, "text": "How important is health for productivity?"}, {"time": 4545, "text": "How important is it to sort of get sleep and so on?"}, {"time": 4549, "text": "I'm on the health side."}, {"time": 4552, "text": "I mean, there was a period of my life when I was just, I had no obligations and I was just living in a little house and just working nonstop, you know?"}, {"time": 4565, "text": "But even then I would get up in the morning and I would have liver and eggs for breakfast every day, and I would do my, you know, exercise, whatever it was."}, {"time": 4573, "text": "But although I was still doing like 18 hours a day, but I'm definitely, I kind of think of it sort of like an athlete does."}, {"time": 4582, "text": "I'm sure that like Steph Curry is totally committed to winning championships and stuff like that."}, {"time": 4589, "text": "But he has his family, he sees his family, you know, the family is always there."}, {"time": 4593, "text": "He, I'm sure he eats, you know, perfect, great stuff, gets his sleep, you know, gets the training, you know, the whatever a trainer does to him for his knees and his ankles and whatever."}, {"time": 4607, "text": "So I, or Kobe Bryant or anybody that's operating at a high level."}, {"time": 4612, "text": "So I do think I'm from that kind of the health school."}, {"time": 4615, "text": "The good thing about being a writer is you can't work very many hours a day."}, {"time": 4620, "text": "You know, four hours is like the maximum I can work."}, {"time": 4623, "text": "I've never been able to work more than that."}, {"time": 4625, "text": "I don't know how people do it."}, {"time": 4626, "text": "I've heard of people do 10, 12, I don't know how they do it."}, {"time": 4631, "text": "So that gives you a lot of other time to do it."}, {"time": 4634, "text": "Optimize your health."}, {"time": 4636, "text": "Yeah, to optimize your health."}, {"time": 4637, "text": "Because you need to, you're in training, you know?"}, {"time": 4639, "text": "You're really, you're burning up a lot of B vitamins when you're working here, aren't you?"}, {"time": 4647, "text": "Maybe it's a Russian thing with you, Lex."}, {"time": 4648, "text": "Well, it's not even a Russian thing."}, {"time": 4650, "text": "It also may be youth, you know?"}, {"time": 4652, "text": "At 35, you can be crazy."}, {"time": 4655, "text": "You know, that's the thing, they keep telling me, but I'm pretty sure I'll be added still at a later time too."}, {"time": 4664, "text": "I think it has to do with the career choice too."}, {"time": 4667, "text": "I think writing is almost, from everything I've heard, it's almost impossible to do it more than a few hours really well."}, {"time": 4676, "text": "When you start to get into certain disciplines, like with Elon Musk and me, engineering disciplines, that really there's a lot more non muse time needed."}, {"time": 4690, "text": "So the crazy hours that you often are talking about have to be done, and it doesn't."}, {"time": 4700, "text": "I think that's true."}, {"time": 4702, "text": "Yeah, so there's still the two, three hours of muse time needed for truly genius ideas, but it's something I certainly struggle with."}, {"time": 4714, "text": "But yeah, I hear you loud and clear on the health."}, {"time": 4719, "text": "So what does a perfect day look like for you if we're talking about writing?"}, {"time": 4726, "text": "An hour by hour schedule of a perfect day."}, {"time": 4731, "text": "I get up early, I go to the gym, I have breakfast with some friends of mine."}, {"time": 4737, "text": "What's early by the way?"}, {"time": 4738, "text": "Let's, like how early?"}, {"time": 4740, "text": "3.15."}, {"time": 4743, "text": "So we're talking really early."}, {"time": 4745, "text": "Really early."}, {"time": 4746, "text": "Now I'm crazy early, it's ridiculously early."}, {"time": 4748, "text": "But, and I haven't done that always, but that's kind of what I'm on now."}, {"time": 4755, "text": "So I'm in bed, like when I'm with my nephews that are like four years old and three years old, I'm in bed before them."}, {"time": 4762, "text": "Okay, you got a beat."}, {"time": 4765, "text": "You wake up, sorry, you said exercise first."}, {"time": 4769, "text": "And what does that look like?"}, {"time": 4770, "text": "What's exercise for you?"}, {"time": 4772, "text": "You go out to the gym?"}, {"time": 4772, "text": "I go to the gym."}, {"time": 4775, "text": "I have a trainer, I have a couple of guys that I work out with, and I'll, you know, it's maybe an hour, maybe a little more."}, {"time": 4783, "text": "I'll do a little warmup before stretching afterwards, take a shower, go have breakfast."}, {"time": 4789, "text": "But it's an intense kind of a thing that I definitely don't wanna do that's hard, you know?"}, {"time": 4795, "text": "So you feel like you've accomplished something, first thing."}, {"time": 4798, "text": "That's a big accomplishment of the day."}, {"time": 4800, "text": "At the same time, it's not like so hard that I'm completely exhausted, you know?"}, {"time": 4804, "text": "And then I'll come home and handle whatever correspondence and stuff has to be done, and then I work for maybe three hours, and then I just sort of crash."}, {"time": 4815, "text": "The office is closed, I turn the switch, I don't think about anything."}, {"time": 4821, "text": "I don't think about the work at all."}, {"time": 4823, "text": "Do you listen to, oh, you mean afterwards?"}, {"time": 4825, "text": "After work, once the office is closed."}, {"time": 4827, "text": "But during, so this was like 12 to three kind of thing?"}, {"time": 4831, "text": "Something like that, yeah."}, {"time": 4831, "text": "Something like that, okay."}, {"time": 4833, "text": "You listen to music?"}, {"time": 4835, "text": "Do you have anything?"}, {"time": 4836, "text": "But that's just me, I mean, I don't think, you know, but somebody could do it a million different ways."}, {"time": 4840, "text": "It's fascinating, you know, the, I mean, you've also, of most, of many writers, you've really, but like I've read Stephen Kington writing, you've optimized this conversation with the muse you're having."}, {"time": 4856, "text": "Not optimized, but you've at least thought about it."}, {"time": 4859, "text": "So what's, can you say a little bit more about the trivialities of that process, of the, like you said, facing the wall?"}, {"time": 4870, "text": "What's, do you have little rituals?"}, {"time": 4873, "text": "You mean like the granular aspect of it?"}, {"time": 4875, "text": "The granular aspects, yeah."}, {"time": 4880, "text": "I do have little rituals, I do have all kinds of, which I'm not even gonna tell you about."}, {"time": 4883, "text": "But the one thing, and I don't wanna like talk about this too much because it sort of jinxes things, I think, but the one thing I do try to do is when I sit down, I immediately get into it, first, second."}, {"time": 4901, "text": "I don't sit and fuck around with anything."}, {"time": 4903, "text": "I immediately try to get into it as quickly as I can."}, {"time": 4907, "text": "The other thing is that writing a book or screenplay or anything like that is a process of multiple drafts."}, {"time": 4914, "text": "And it's the first draft that's where you're most with the muse, where you're going through the blank page."}, {"time": 4920, "text": "Like right now I'm on, I don't know what, the fifth or sixth, seventh draft of the thing I'm working on."}, {"time": 4925, "text": "So I've got pages already written and I'm kind of reading them afresh as I go through the story."}, {"time": 4934, "text": "So it's not quite where I am now."}, {"time": 4937, "text": "It's not quite a deep muse scenario, partly it is, but it's also sort of bouncing back and forth between the different, between the right brain and the left brain."}, {"time": 4948, "text": "I'm kind of looking at it and trying to evaluate it."}, {"time": 4951, "text": "And then I'm going into it and try to change it a little bit."}, {"time": 4955, "text": "And when, do you know, sit down and get right into it, do you know the night before of what that starting point is?"}, {"time": 4963, "text": "I always try to stop."}]}, {"title": "Dan Carlin: Hardcore History | Lex Fridman Podcast #136", "id": "-k-ztNsBM54", "quotes": [{"time": 413, "text": "In other words, to glorify himself."}, {"time": 415, "text": "And if that's the case, does that make Alexander a worse person than Hitler because Hitler thought he was doing good, whereas Alexander, if you believe the interpretation, was simply trying to exalt Alexander."}, {"time": 428, "text": "So the motivations of the people doing these things, it seems to me, matter."}, {"time": 434, "text": "I don't think you can just sit there and go, the only thing that matters is the end result, because that might've been an unintentional byproduct, in which case, that person, had you been able to show them the future, might have changed what they were doing."}, {"time": 447, "text": "So were they evil or misguided or wrong or made the wrong?"}, {"time": 450, "text": "So, and I hate to do that because there's certain people like Hitler that I don't feel deserve the benefit of the doubt."}, {"time": 456, "text": "At the same time, if you're fascinated by the concept of evil and you delve into it deeply enough, you're going to want to understand why these evil people did what they did."}, {"time": 466, "text": "And sometimes it can confuse the hell out of you."}, {"time": 469, "text": "You know, who wants to sit there and try to see things from Hitler's point of view to get a better understanding and sort of commiserate with."}, {"time": 474, "text": "So, but I'm, obviously, first history show, I'm fascinated with the concept."}, {"time": 479, "text": "So do you think it's possible, if we put ourselves in the mindset of some of the people that have led, created so much suffering in the world, that all of them had their motivations were, had good intentions underlying them?"}, {"time": 495, "text": "No, I don't, it's simply because there's so many, I mean, the law of averages would suggest that that's not true."}, {"time": 501, "text": "I guess it is pure evil possible, meaning you, again, it's slippery, but you, the suffering is the goal."}, {"time": 511, "text": "Suffering, intentional suffering."}, {"time": 514, "text": "Yes, I think that, and I think that there's historical figures that one could point, but that gets to the deeper question of, are these people sane?"}, {"time": 522, "text": "Do they have something wrong with them?"}, {"time": 523, "text": "Are they twisted from something in their youth?"}, {"time": 528, "text": "You know, these are the kinds of things where you start to delve into the psychological makeup of these people."}, {"time": 533, "text": "In other words, is anybody born evil?"}, {"time": 536, "text": "And I actually believe that some people are."}, {"time": 538, "text": "I think the DNA can get scrambled up in ways."}, {"time": 541, "text": "I think the question of evil is important too, because I think it's an eye of the beholder thing."}, {"time": 545, "text": "I mean, if Hitler, for example, had been successful and we were today on the sixth or seventh leader of the Third Reich, since I think his entire history would be viewed through a different lens, because that's the way we do things, right?"}, {"time": 560, "text": "Genghis Khan looks different to the Mongolians than he does to the residents of Baghdad, right?"}, {"time": 565, "text": "And I think, so an eye of the beholder question, I think comes into all these sorts of things."}, {"time": 570, "text": "As you said, it's a very slippery question."}, {"time": 572, "text": "Where do you put, as somebody who's fascinated by military history, where do you put violence in terms of the human condition?"}, {"time": 583, "text": "Is it core to being human or is it just a little tool that we use every once in a while?"}, {"time": 589, "text": "So I'm gonna respond to your question with a question."}, {"time": 592, "text": "What do you see the difference being between violence and force?"}, {"time": 597, "text": "Let me go farther."}, {"time": 598, "text": "I'm not sure that violence is something that we have to put up with as human beings forever, that we must resign ourselves to violence forever."}, {"time": 609, "text": "But I have a much harder time seeing us able to abolish force."}, {"time": 615, "text": "And there's going to be some ground where if those two things are not the same, and I don't know that maybe they are, where there's certainly some crossover."}, {"time": 625, "text": "And I think force, you're an engineer, you'll understand this better than I did, but think about it as a physical law."}, {"time": 632, "text": "If you can't stop something from moving in a certain direction without pushing back in that same direction, I'm not sure that you can have a society or a civilization without the ability to use a counter force when things are going wrong, whether it's on an individual level, right?"}, {"time": 653, "text": "A person attacks another person, so you step in to save that person, or even at the highest levels of politics or anything else, a counter force to stop the inertia or the impetus of another movement."}, {"time": 667, "text": "So I think that force is a simple, almost law of physics in human interaction, especially at the civilizational level."}, {"time": 675, "text": "I think civilization requires a certain amount of, if not violence, then force."}, {"time": 682, "text": "And again, they've talked, I mean, it goes back into St. Augustine, all kinds of Christian beliefs about the proper use of force and people have philosophically tried to decide between can you have sort of an ahimsa, Buddhists sort of, we will be nonviolent toward everything and exert no force, or there's a reason to have force in order to create the space for good."}, {"time": 704, "text": "I think force is inevitable."}, {"time": 707, "text": "Now, we can talk, and I've not come up to the conclusion myself, if there is a distinction to be made between force and violence."}, {"time": 714, "text": "I mean, is a nonviolent force enough, or is violence when done for the cause of good a different thing than violence done either for the cause of evil, as you would say, or simply for random reasons?"}, {"time": 728, "text": "I mean, we humans lack control sometimes."}, {"time": 730, "text": "We can be violent for no apparent reason or goal."}, {"time": 735, "text": "I mean, you look at the criminal justice system alone and the way we interact with people who are acting out in ways that we as a society have decided is intolerable."}, {"time": 745, "text": "Can you deal with that without force and at some level violence?"}, {"time": 750, "text": "Can you maintain peacefulness without force?"}, {"time": 754, "text": "Just to be a little bit more specific about the idea of force, do you put force as general enough to include force in the space of ideas?"}, {"time": 765, "text": "So you mentioned Buddhism or religion or just Twitter."}, {"time": 773, "text": "I can think of no things farther apart than that."}, {"time": 778, "text": "Is the battles we do in the space of ideas of the great debates throughout history, do you put force into that?"}, {"time": 789, "text": "Or do you, in this conversation, are we trying to right now keep it to just physical force in saying that you have an intuition that force might be with us much longer than violence?"}, {"time": 805, "text": "I think the two bleed together."}, {"time": 807, "text": "So take, because it's always my go to example."}, {"time": 813, "text": "I'm afraid and I'm sure that the listeners all hate it, but take Germany during the 1920s, early 1930s, before the Nazis came to power."}, {"time": 822, "text": "And they were always involved in some level of force, beating up in the streets or whatever it might be."}, {"time": 826, "text": "But think about it more like an intellectual discussion until a certain point."}, {"time": 833, "text": "It would be difficult, I imagine, to keep the intellectual counter force of ideas from at some point degenerating into something that's more coercion, counter force, if we want to use the phrases we were just talking about."}, {"time": 849, "text": "So I think the two are intimately connected."}, {"time": 851, "text": "I mean, actions follow thought, right?"}, {"time": 854, "text": "And at a certain point, I think, especially when one is not achieving the goals that they want to achieve through a peaceful discussion or argumentation or trying to convince the other side, that sometimes the next level of operations is something a little bit more physically imposing, if that makes sense."}, {"time": 874, "text": "We go from the intellectual to the physical."}, {"time": 876, "text": "Yeah, so it too easily spills over into violence."}, {"time": 879, "text": "Yes, and one leads to the other often."}, {"time": 881, "text": "So you kind of implied perhaps a hopeful message."}, {"time": 885, "text": "Let me ask it in the form of a question."}, {"time": 891, "text": "I think it goes to the first question too."}, {"time": 892, "text": "So for example, what do you do?"}, {"time": 896, "text": "I mean, let's play with nation states now, although I don't know that nation states are something we should think of as a permanent construct forever."}, {"time": 906, "text": "But how is one nation state supposed to prevent another nation state from acting in ways that it would see as either detrimental to the global community or detrimental to the interest of their own nation state?"}, {"time": 920, "text": "I think we've had this question of going back to ancient times, but certainly in the 20th century, this has come up quite a bit."}, {"time": 927, "text": "I mean, the whole Second World War argument sometimes revolves around the idea of what the proper counterforce should be."}, {"time": 934, "text": "Can you create an entity, a league of nations, the United Nations, a one world entity maybe even that alleviates the need for counterforce involving mass violence and armies and navies and those things?"}, {"time": 947, "text": "I think that's an open discussion we're still having."}, {"time": 951, "text": "It's good to think through that because having something like a United Nations, there's usually a centralized control."}, {"time": 959, "text": "So there's humans at the top, there's committees and usually like leaders emerge as singular figures that then can become corrupted by power."}, {"time": 970, "text": "And it's just a really important, it feels like a really important thought experiment and something to really rigorously think through."}, {"time": 978, "text": "How can you construct systems of government that are stable enough to push us towards less and less war and less and less unstable and another tough word, another tough word which is unfair of application of force?"}, {"time": 999, "text": "You know, that's really at the core of the question that we're trying to figure out as humans, as our weapons get better and better and better destroying ourselves, it feels like it's important to think about how we minimize the over application or unfair application of force."}, {"time": 1017, "text": "There's other elements that come into play too."}, {"time": 1019, "text": "You and I are discussing this at the very high intellectual level of things, but there's also a tail wagging the dog element to this."}, {"time": 1025, "text": "So think of a society of warriors, a tribal society from a long time ago."}, {"time": 1031, "text": "How much do the fact that you have warriors in your society and that their reason for existing, what they take pride in, what they train for, what their status in their own civilization, how much does that itself drive the responses of that society, right?"}, {"time": 1048, "text": "How much do you need war to legitimize warriors?"}, {"time": 1053, "text": "That's the old argument that you get to and we've had this in the 20th century too, that the creation of arms and armies creates an incentive to use them, right?"}, {"time": 1062, "text": "And that they themselves can drive that incentive as a justification for their reasons for existence."}, {"time": 1070, "text": "That's where we start to talk about the interactivity of all these different elements of society upon one another."}, {"time": 1075, "text": "So when we talk about governments and war, well, you need to take into account the various things those governments have put into place in terms of systems and armies and things like that to protect themselves, right?"}, {"time": 1086, "text": "For reasons we can all understand, but they exert a force on your range of choices, don't they?"}, {"time": 1094, "text": "You're making me realize that in my upbringing and I think upbringing of many, warriors are heroes."}, {"time": 1101, "text": "To me, I don't know where that feeling comes from, but to sort of die fighting is an honorable way to die, it feels like that."}, {"time": 1114, "text": "I've always had a problem with this because as a person interested in military history, the distinction is important and I try to make it at different levels."}, {"time": 1122, "text": "So at base level, the people who are out there on the front lines doing the fighting, to me, those people can be compared with police officers and firemen and people, fire persons, but I mean, people that are involved in an ethical attempt to perform a task which ultimately one can see in many situations as being a saving sort of task, right?"}, {"time": 1152, "text": "Or if nothing else, a self sacrifice for what they see as the greater good."}, {"time": 1157, "text": "Now, I draw a distinction between the individuals and the entity that they're a part of, a military, and I certainly draw a distinction between the military and then the entire, for lack of a better word, military industrial complex that that service is a part of."}, {"time": 1172, "text": "I feel a lot less moral attachment to those upper echelons than I do the people on the ground."}, {"time": 1180, "text": "The people on the ground could be any of us and have been in a lot of, we have a very professional sort of military now where it's a very, a subset of the population, but in other periods of time, we've had conscription and drafts and it hasn't been a subset of the population, it's been the population, right?"}, {"time": 1198, "text": "And so it is the society oftentimes going to war and I make a distinction between those warriors and the entities either in the system that they're a part of the military or the people that control the military at the highest political levels."}, {"time": 1212, "text": "I feel a lot less moral attachment to them and I'm much harsher about how I feel about them."}, {"time": 1219, "text": "I do not consider the military itself to be heroic and I do not consider the military industrial complex to be heroic."}, {"time": 1228, "text": "I do think that is a tail wagging the dog situation."}, {"time": 1231, "text": "I do think that draws us into looking at military endeavors as a solution to the problem much more quickly than we otherwise might."}, {"time": 1241, "text": "And to be honest, to tie it all together, I actually look at the victims of this as the soldiers we were talking about."}, {"time": 1247, "text": "If you set a fire to send firemen into to fight, then I feel bad for the firemen."}, {"time": 1255, "text": "I feel like you've abused the trust that you give those people, right?"}, {"time": 1258, "text": "So when people talk about war, I always think that the people that we have to make sure that a war is really necessary in order to protect are the people that you're gonna send over there to fight that."}, {"time": 1270, "text": "The greatest victims in our society of war are often the warriors."}, {"time": 1274, "text": "So in my mind, when we see these people coming home from places like Iraq, a place where I would have made the argument and did at the time that we didn't belong."}, {"time": 1284, "text": "To me, those people are victims and I know they don't like to think about themselves that way because it runs totally counter to the ethos."}, {"time": 1291, "text": "But if you're sending people to protect this country's shores, those are heroes."}, {"time": 1297, "text": "If you're sending people to go do something that they otherwise probably don't need to do but they're there for political reasons or anything else you wanna put in that's not defense related, well then you've made victims of our heroes."}, {"time": 1308, "text": "And so I feel like we do a lot of talk about our troops and our soldiers and stuff but we don't treat them as valuable as the rhetoric makes them sound."}, {"time": 1319, "text": "Otherwise, we would be much more careful about where we put them."}, {"time": 1325, "text": "If you're gonna send my son, and I don't have a son, I have daughters, but if you're gonna send my son into harm's way, I'm going to demand that you really need to be sending him into harm's way and I'm going to be angry at you if you put him into harm's way if it doesn't warrant it."}, {"time": 1371, "text": "Yeah, and as my own family history, it would be nice if we could talk about there's a gray area in the places that you're talking about."}, {"time": 1381, "text": "There's a gray area in everything."}, {"time": 1385, "text": "But when that gray area is part of your own blood, as it is for me, it's worth shining a light on somehow."}, {"time": 1396, "text": "Sure, give me an example of what you mean."}, {"time": 1397, "text": "So you did a program of four episodes of Ghosts of the Ostfront."}, {"time": 1403, "text": "So I was born in the Soviet Union."}, {"time": 1406, "text": "I was raised in Moscow."}, {"time": 1407, "text": "My dad was born and raised in Kiev."}, {"time": 1410, "text": "My grandmother, who just recently passed away, was raised in Ukraine."}, {"time": 1418, "text": "A city."}, {"time": 1419, "text": "It's a small city on the border between Russia and Ukraine."}, {"time": 1424, "text": "I have a grandfather born in Kiev."}, {"time": 1425, "text": "In Kiev."}, {"time": 1426, "text": "The interesting thing about the timing of everything, as you might be able to connect, is she survived."}, {"time": 1432, "text": "She's the most badass woman I've ever encountered in my life and most of the warrior spirit I carry is probably from her."}, {"time": 1441, "text": "She survived Polar Mor, the Ukrainian starvation of the 30s."}, {"time": 1445, "text": "She was a beautiful teenage girl during the Nazi occupation of, so she survived all of that."}, {"time": 1454, "text": "And of course, family that everybody, and so many people died through that whole process."}, {"time": 1461, "text": "And one of the things you talk about in your program is that the gray area is, even with the warriors, it happened to them, just like as you're saying now, they didn't have a choice."}, {"time": 1475, "text": "So my grandfather on the other side, he was a machine gunner that was in Ukraine that."}, {"time": 1485, "text": "In the Red Army?"}, {"time": 1486, "text": "In the Red Army, yeah."}, {"time": 1488, "text": "And they threw, like the statement was that there's, I don't know if it's obvious or not, but the rule was there's no surrender."}, {"time": 1497, "text": "So you better die."}, {"time": 1499, "text": "So you, I mean, you're basically, the goal was when he was fighting and he was lucky enough, one of the only to survive by being wounded early on is there was a march of Nazis towards, I guess, Moscow."}, {"time": 1516, "text": "And the whole goal in Ukraine was to slow every, to slow them into the winter."}, {"time": 1523, "text": "I mean, I view him as such a hero and he believed that he's indestructible, which is survivor bias."}, {"time": 1533, "text": "And that, you know, bullets can't hurt him."}, {"time": 1537, "text": "And that's what everybody believed."}, {"time": 1539, "text": "And of course, basically everyone that, he quickly rose to the ranks, let's just put it this way, because everybody died."}, {"time": 1548, "text": "It was just bodies dragging these heavy machine guns, like always, you know, always slowly retreating, shooting and retreating, shooting and retreating."}, {"time": 1559, "text": "And I don't know, he was a hero to me, like I always, I grew up thinking that he was the one that sort of defeated the Nazis, right?"}, {"time": 1571, "text": "And, but the reality that there could be another perspective, which is all of this happened to him by the incompetence of Stalin, the incompetence and men of the Soviet Union being used like pawns in a shittily played game of chess, right?"}, {"time": 1590, "text": "So like the one narrative is of him as a victim, as you're kind of describing."}, {"time": 1597, "text": "And then somehow that's more paralyzing and that's more, I don't know, it feels better to think of him as a hero and as Russia, Soviet Union saving the world."}, {"time": 1612, "text": "I mean, that narrative also, is in the United States that the United States was key in saving the world from the Nazis."}, {"time": 1620, "text": "It feels like that narrative is powerful for people."}, {"time": 1623, "text": "I'm not sure, and I carry it still with me, but when I think about the right way to think about that war, I'm not sure if that's the correct narrative."}, {"time": 1634, "text": "Let me suggest something."}, {"time": 1635, "text": "There's a line that a Marine named Eugene Sledge had to say once and I keep it on my phone because it's, it makes a real distinction."}, {"time": 1645, "text": "And he said, the front line is really where the war is."}, {"time": 1650, "text": "And anybody, even a hundred yards behind the front line doesn't know what it's really like."}, {"time": 1656, "text": "Now, the difference is, is there are lots of people miles behind the front line that are in danger, right?"}, {"time": 1662, "text": "You can be in a medical unit in the rear and artillery could strike you, planes could strike me."}, {"time": 1666, "text": "You could be in danger, but at the front line, there are two different things."}, {"time": 1670, "text": "One is that, and at least, and I'm doing a lot of reading on this right now and reading a lot of veterans accounts."}, {"time": 1677, "text": "James Jones, who wrote books like From Here to Eternity, fictional accounts of the Second World War, but he based them on his own service."}, {"time": 1685, "text": "He was at Guadalcanal, for example, in 1942."}, {"time": 1688, "text": "And Jones had said that the evolution of a soldier in front line action requires a lot of front line action requires an almost surrendering to the idea that you're going to live, that you become accustomed to the idea that you're going to die."}, {"time": 1706, "text": "And he said, you're a different person simply for considering that thought seriously, because most of us don't."}, {"time": 1712, "text": "But what that allows you to do is to do that job at the front line, right?"}, {"time": 1716, "text": "If you're too concerned about your own life, you become less of a good guy at your job, right?"}, {"time": 1724, "text": "The other thing that the people in the 100 yards at the front line do that the people in the rear medical unit really don't, is you kill and you kill a lot, right?"}, {"time": 1734, "text": "You don't just, oh, there's a sniper back here so I shot him."}, {"time": 1736, "text": "It's we go from one position to another and we kill lots of people."}, {"time": 1741, "text": "Those things will change you."}, {"time": 1742, "text": "And what that tends to do, not universally, because I've read accounts from Red Army soldiers and they're very patriotic, right?"}, {"time": 1750, "text": "But a lot of that patriotism comes through years later as part of the nostalgia and the remembering."}, {"time": 1756, "text": "When you're down at that front 100 yards, it is often boiled down to a very small world."}, {"time": 1762, "text": "So your grandfather, was it your grandfather?"}, {"time": 1764, "text": "Grandfather."}, {"time": 1765, "text": "At the machine gun, he's concerned about his position and his comrades and the people who he owes a responsibility to."}, {"time": 1772, "text": "And those, it's a very small world at that point."}, {"time": 1775, "text": "And to me, that's where the heroism is, right?"}, {"time": 1777, "text": "He's not fighting for some giant world, civilizational thing."}, {"time": 1780, "text": "He's fighting to save the people next to him."}, {"time": 1783, "text": "And his own life at the same time because they're saving him too."}, {"time": 1786, "text": "And that there is a huge amount of heroism to that."}, {"time": 1789, "text": "And that gets to our question about force earlier."}, {"time": 1792, "text": "Why would you use force?"}, {"time": 1793, "text": "Well, how about to protect these people on either side of me, right?"}, {"time": 1796, "text": "Their lives."}, {"time": 1799, "text": "Now, is there hatred?"}, {"time": 1801, "text": "Yeah, I hated the Germans for what they were doing."}, {"time": 1803, "text": "As a matter of fact, I got a note from a poll not that long ago."}, {"time": 1807, "text": "And I have this tendency to refer to the Nazis, right?"}, {"time": 1810, "text": "The regime that was, and he said, why do you keep calling them Nazis?"}, {"time": 1814, "text": "He says, say what they were."}, {"time": 1815, "text": "They were Germans."}, {"time": 1817, "text": "And this guy wanted me to not absolve Germany by saying, oh, it was this awful group of people that took over your country."}, {"time": 1824, "text": "He said, the Germans did this."}, {"time": 1826, "text": "And there's that bitterness where he says, let's not forget what they did to us and what we had to do back, right?"}, {"time": 1833, "text": "So for me, when we talk about these combat situations, the reason I call these people heroic is because of, they're fighting to defend things we could all understand."}, {"time": 1842, "text": "I mean, if you come after my brother and I take a machine gun and shoot you and you're gonna overrun me, I mean, that becomes a situation where we talked about counterforce earlier."}, {"time": 1855, "text": "Much easier to call yourself a hero when you're saving people or you're saving this town right behind you."}, {"time": 1859, "text": "And you know, if they get through your machine gun, they're gonna burn these villages."}, {"time": 1863, "text": "They're gonna throw these people out in the middle of winter, these families."}, {"time": 1866, "text": "That to me is a very different sort of heroism than this amorphous idea of patriotism."}, {"time": 1873, "text": "And you know, patriotism is a thing that we often get used with, right?"}, {"time": 1877, "text": "People manipulate us through love of country and all this because they understand that this is something we feel very strongly, but they use it against us sometimes in order to whip up a war fever or to get people."}, {"time": 1889, "text": "I mean, there's a great line and I wish I could remember it in its entirety that Herman Goering had said about how easy it was to get the people into a war."}, {"time": 1897, "text": "He says, you know, you just appeal to their patriotism, you, I mean, there's buttons that you can push and they take advantage of things like love of country and the way we have a loyalty and an admiration to the warriors who put their lives on the line."}, {"time": 1910, "text": "These are manipulatable things in the human species that reliably can be counted on to move us in directions that in a more sober, reflective state of mind we would consider differently."}, {"time": 1925, "text": "It gets the, I mean, you get this war fever up and people wave flags and they start denouncing the enemy and they start signing, you know, we've seen it over and over and over again in ancient times this happened."}, {"time": 1934, "text": "But the love of country is also beautiful."}, {"time": 1937, "text": "So I haven't seen it in America as much."}, {"time": 1939, "text": "So people in America love their country, like this patriotism is strong in America, but it's not as strong as I remember, even with my sort of being younger, the love of the Soviet Union."}, {"time": 1953, "text": "Now, was it the Soviet Union this requires a distinction or was it mother Russia?"}, {"time": 1959, "text": "What it really was, was the communist party."}, {"time": 1961, "text": "Okay, so it was the system in place, okay."}, {"time": 1963, "text": "The system in place, like loving, I haven't quite deeply synchronized exactly what you love."}, {"time": 1969, "text": "I think you love that like populist message of the worker, of the common man, the common person."}, {"time": 1979, "text": "Let me draw the comparison then."}, {"time": 1981, "text": "And I often say this, that the United States like the Soviet Union is an ideological based society, right?"}, {"time": 1989, "text": "So you take a country like France, it doesn't matter which French government you're in now."}, {"time": 1996, "text": "The French have been the French for a long time, right?"}, {"time": 1999, "text": "It's not based on an ideology, right?"}, {"time": 2002, "text": "Whereas what unites the United States is an ideology, freedom, liberty, the constitution."}, {"time": 2008, "text": "This is what draws, you know, it's the e pluribus unum kind of the idea, right?"}, {"time": 2012, "text": "That out of many one, well, what binds all these unique different people?"}, {"time": 2017, "text": "The shared beliefs, this ideology."}, {"time": 2019, "text": "The Soviet Union was the same way."}, {"time": 2020, "text": "Cause as you know, the Soviet Union, Russia was merely one part of the Soviet Union."}, {"time": 2025, "text": "And if you believe the rhetoric until Stalin's time, everybody was going to be united under this ideological banner someday, right?"}, {"time": 2034, "text": "It was a global revolution."}, {"time": 2036, "text": "So ideological societies are different."}, {"time": 2039, "text": "And to be a fan of the ideological framework and goal, I mean, I'm a Liberty person, right?"}, {"time": 2045, "text": "I would like to see everybody in the world have my system of government, which is part of a bias, right?"}, {"time": 2052, "text": "Because they might not want that."}, {"time": 2054, "text": "But I think it's better for everyone cause I think it's better for me."}, {"time": 2057, "text": "At the same time, when the ideology, if you consider, and you know, this stems from ideas of the enlightenment and there's a bias there."}, {"time": 2066, "text": "So my bias are toward the, but you feel, and this is why you say, we're going to bring freedom to Iraq."}, {"time": 2070, "text": "We're going to bring freedom to here."}, {"time": 2071, "text": "We're going to bring freedom because we think we're spreading to you something that is just undeniably positive."}, {"time": 2077, "text": "We're going to free you and give you this."}, {"time": 2082, "text": "It's hard for me to wipe my own bias away from there, right?"}, {"time": 2087, "text": "Cause if I were in Iraq, for example, I would want freedom, right?"}, {"time": 2091, "text": "But if you then leave and let the Iraqis vote for whomever they want, are they going to vote for somebody that will, I mean, you know, you look at Russia now and I hear from Russians quite a bit because so much of my views on Russia and the Soviet Union were formed in my formative years."}, {"time": 2109, "text": "And, you know, we were not hearing from many people in the Soviet Union back then, but now you do."}, {"time": 2114, "text": "You hear from Russians today who will say, your views on Stalin are archaic and cold."}, {"time": 2118, "text": "You know, so you try to reorient your beliefs a little bit, but it goes to this idea of, if you gave the people in Russia a free and fair vote, will they vote for somebody who promises them a free and open society based on enlightenment democratic principles?"}, {"time": 2133, "text": "Or will they vote for somebody, we in the US would go, what are they doing?"}, {"time": 2136, "text": "They're voting for some strong man who's just good."}, {"time": 2138, "text": "You know, so I think it's very hard to throw away our own biases and preconceptions."}, {"time": 2145, "text": "And, you know, it's an all eye of the beholder kind of thing."}, {"time": 2148, "text": "But when you're talking about ideological societies, it is very difficult to throw off all the years of indoctrination into the superiority of your system."}, {"time": 2159, "text": "I mean, listen, in the Soviet Union, Marxism one way or another was part of every classrooms."}, {"time": 2164, "text": "You know, you could be studying geometry and they'll throw Marxism in there somehow, because that's what united the society."}, {"time": 2171, "text": "And that's what gave it a higher purpose."}, {"time": 2173, "text": "And that's what made it in the minds of the people who were its defenders, a superior, morally superior system."}, {"time": 2180, "text": "And we do the same thing here."}, {"time": 2181, "text": "In fact, most people do, but see, you're still French, no matter what the ideology or the government might be."}, {"time": 2188, "text": "So in that sense, it's funny that there would be a cold war with these two systems, because they're both ideologically based systems involving peoples of many different backgrounds who are united under the umbrella of the ideology."}, {"time": 2202, "text": "First of all, that's brilliantly put."}, {"time": 2205, "text": "I'm in a funny position that in my formative years, I came here when I was 13, is when I, you know, teenage is your first love or whatever, is I fell in love with the American set of ideas of freedom and individuals."}, {"time": 2220, "text": "They're compelling, aren't they?"}, {"time": 2221, "text": "They're compelling, yes."}, {"time": 2222, "text": "But I also remember, it's like you remember like maybe an ex girlfriend or something like that."}, {"time": 2227, "text": "I also remember loving as a very different human, the Soviet idea, like we had the national anthem, which is still, I think the most badass national anthem, which is the Soviet Union, like saying we're the indestructible nation."}, {"time": 2244, "text": "I mean, just the words are so, like Americans words are like, oh, we're nice."}, {"time": 2249, "text": "Like we're freedom, but like a Russian Soviet Union national anthem was like, we're bad motherfuckers."}, {"time": 2255, "text": "Nobody will destroy us."}, {"time": 2258, "text": "I just remember feeling pride in a nation as a kid, like dumb not knowing anything because we all had to recite the stuff."}, {"time": 2265, "text": "It was, there's a uniformity to everything."}, {"time": 2268, "text": "There's pride underlying everything."}, {"time": 2270, "text": "I didn't think about all the destructive nature of the bureaucracy, the incompetence, the, you know, all the things that come with the implementation of communism, especially around the eighties and nineties."}, {"time": 2286, "text": "But I remember what it's like to love that set of ideas."}, {"time": 2289, "text": "So I'm in a funny place of like, remember like switching the love because I'm, you know, I kind of joke around about being Russian, but you know, my longterm monogamous relationship is now with the idea, the American ideal."}, {"time": 2303, "text": "Like I'm stuck with it in my mind, but I remember what it was like to love it."}, {"time": 2308, "text": "And I think about that too, when people criticize China or they criticize the current state of affairs with how Stalin is remembered and how Putin is to know that the, you can't always wear the American ideal of individualism, radical individualism and freedom in analyzing the ways of the world elsewhere."}, {"time": 2334, "text": "Like in China, in Russia, that it does, if you don't take yourself too seriously, as Americans all do, as I do, it's kind of a beautiful love to have for your government, to believe in the nation, to let go of yourself and your rights and your freedoms, to believe in something bigger than yourself."}, {"time": 2358, "text": "That's actually, that's a kind of freedom."}, {"time": 2362, "text": "That's, you're actually liberating yourself."}, {"time": 2402, "text": "Not just that, let me add to what you're saying."}, {"time": 2404, "text": "And I'm very, I spend a lot of time trying to get out of my own biases."}, {"time": 2411, "text": "It is a fruitless endeavor longterm, but you try to be better than you normally are."}, {"time": 2416, "text": "One of the critiques that China, and I always, as an American, I tend to think about this as their government, right?"}, {"time": 2422, "text": "This is a rationale that their government puts forward."}, {"time": 2425, "text": "But what you just said is actually, if you can make that viewpoint beautiful is kind of a beautiful way of approaching it."}, {"time": 2432, "text": "The Chinese would say that what we call human rights in the United States and what we consider to be everybody's birthright around the world is instead Western rights."}, {"time": 2442, "text": "That's the words they use, Western rights."}, {"time": 2444, "text": "It's a fundamentally Western oriented, and I'll go back to the enlightenment based ideas, on what constitutes the rights of man."}, {"time": 2455, "text": "And they would suggest that that's not internationally and always applicable, right?"}, {"time": 2460, "text": "That you can make a case, and again, I don't believe this."}, {"time": 2463, "text": "This runs against my own personal views, but that you could make a case that the collective wellbeing of a very large group of people outweighs the individual needs of any single person, especially if those things are in conflict with each other, right?"}, {"time": 2478, "text": "If you cannot provide for the greater good because everyone's so individualistic, well then really what is the better thing to do, right?"}, {"time": 2487, "text": "Is suppress individualism so everybody's better off?"}, {"time": 2490, "text": "I think trying to recognize how someone else might see that is important if we want to, you know, you had talked about eliminating war."}, {"time": 2497, "text": "We talk about eliminating conflict."}, {"time": 2499, "text": "The first need to do that is to try to understand how someone else might view something differently than yourself."}, {"time": 2507, "text": "I'm famously one of those people who buys in to the ideas of traditional Americanism, right?"}, {"time": 2537, "text": "How could you have freedom and liberty and individualistic expression if you had an overriding military that was always fighting wars and the founders of this country looked to other examples like Europe, for example, and saw that standing militaries, for example, standing armies were the enemy of liberty."}, {"time": 2556, "text": "Well, we have a standing army now and one that is totally interwoven in our entire society."}, {"time": 2563, "text": "If you could go back in time and talk to John Quincy Adams, right, early president of the United States and show him what we have now, he would think it was awful and horrible and that somewhere along the line, the Americans had lost their way and forgotten what they were all about."}, {"time": 2581, "text": "But we have so successfully interwoven this modern military industrial complex with the traditional benefits of the American system and ideology so that they've become intertwined in our thinking, whereas 150 years ago, they were actually considered to be at opposite polarities and a threat to one another."}, {"time": 2602, "text": "So when you talk about the love of the nation, I tend to be suspicious of those things."}, {"time": 2609, "text": "I tend to be suspicious of government."}, {"time": 2611, "text": "I tend to try very hard to not be manipulated and I feel like a large part of what they do is manipulation and propaganda."}, {"time": 2620, "text": "And so I think a healthy skepticism of the nation state is actually 100% Americanism in the traditional sense of the word."}, {"time": 2630, "text": "But I also have to recognize, as you so eloquently stated, Americanism is not necessarily universal at all."}, {"time": 2638, "text": "And so I think we have to try to be more understanding."}, {"time": 2642, "text": "See, the traditional American viewpoint is that if a place like China does not allow their people individual human rights, then they're being denied something."}, {"time": 2652, "text": "They're being denied and 100 years ago, they would have said they're God given rights."}, {"time": 2657, "text": "Man is born free and if he's not free, it's because of something done to him, right?"}, {"time": 2662, "text": "The government has taken away his God given rights."}, {"time": 2665, "text": "I'm getting excited just listening to that."}, {"time": 2667, "text": "Well, but I mean, I think the idea that this is universal is in and of itself a bias."}, {"time": 2673, "text": "Now, do I want freedom for everybody else?"}, {"time": 2676, "text": "I sure do."}, {"time": 2676, "text": "But the people in the Soviet Union who really bought into that wanted the workers of the world to unite and not be exploited by the greedy blood sucking people who worked them to death and pocketed all of the fruits of their labor."}, {"time": 2691, "text": "If you frame it that way, that sounds like justice as well, you know?"}, {"time": 2695, "text": "So it is an eye of the beholder sort of thing."}, {"time": 2698, "text": "I'd love to talk to you about Vladimir Putin, sort of while we're in this feeling and wave of empathy and trying to understand others that are not like us."}, {"time": 2712, "text": "One of the reasons I started this podcast is because I believe that there's a few people I could talk to."}, {"time": 2718, "text": "Some of it is ego."}, {"time": 2721, "text": "Some of it is stupidity."}, {"time": 2724, "text": "Is there some people I could talk to that not many others can talk to?"}, {"time": 2729, "text": "The one person I was always thinking about was Vladimir Putin."}, {"time": 2733, "text": "Do you still speak the language?"}, {"time": 2735, "text": "I speak the language very well."}, {"time": 2736, "text": "That makes it even easier."}, {"time": 2737, "text": "I mean, you might be appointed for that job."}, {"time": 2741, "text": "That's the context in which I'm asking you this question."}, {"time": 2743, "text": "What are your thoughts about Vladimir Putin from a historical context?"}, {"time": 2751, "text": "Have you studied him?"}, {"time": 2752, "text": "Have you thought about him?"}, {"time": 2754, "text": "Yes, studied is a loaded word."}, {"time": 2759, "text": "And again, I find it hard sometimes to not filter things through an American lens."}, {"time": 2765, "text": "So as an American, I would say that the Russians should be allowed to have any leader that they want to have."}, {"time": 2772, "text": "But what an American would say is, but there should be elections, right?"}, {"time": 2777, "text": "So if the Russians choose Vladimir Putin and they keep choosing him, that's their business."}, {"time": 2783, "text": "Where as an American, I would have a problem is when that leader stops letting the Russians make that decision."}, {"time": 2790, "text": "And we would say, well, now you're no longer ruling by the consent of the governed."}, {"time": 2796, "text": "You've become the equivalent of a person who may be oppressing your people."}, {"time": 2800, "text": "You might as well be a dictator, right?"}, {"time": 2802, "text": "Now there's a difference between a freely elected and reelected and reelected and reelected dictator, right?"}, {"time": 2809, "text": "If that's what they want."}, {"time": 2810, "text": "And look, it would be silly to broad brush the Russians like it would be silly to broad brush anyone, right?"}, {"time": 2816, "text": "Millions and millions of people with different opinions amongst them all."}, {"time": 2819, "text": "But they seem to like a strong person at the helm."}, {"time": 2823, "text": "And listen, there's a giant chunk of Americans who do too in their own country."}, {"time": 2828, "text": "But an American would say, as long as the freedom of choice is given to the Russians to decide this and not taken away from them, right?"}, {"time": 2836, "text": "It's one thing to say he was freely elected, but a long time ago and we've done away with elections since then is a different story too."}, {"time": 2843, "text": "So my attitude on Vladimir Putin is if that's who the Russian people want and you give them the choice, right?"}, {"time": 2849, "text": "If he's only there because they keep electing him, that's a very different story."}, {"time": 2852, "text": "When he stops offering them the option of choosing him or not choosing him, that's when it begins to look nefarious to someone born and raised with the mindset and the ideology that is an integral part of yours truly."}, {"time": 2866, "text": "And that I can't, you can see gray areas and nuance all you like, but it's hard to escape."}, {"time": 2871, "text": "And you alluded to this too."}, {"time": 2872, "text": "It's hard to escape what was indoctrinated into your bones in your formative years."}, {"time": 2879, "text": "It's like, your bones are growing, right?"}, {"time": 2882, "text": "And you can't go back."}, {"time": 2883, "text": "So to me, this is so much a part of who I am that I have a hard time jettisoning that and saying, oh no, Vladimir Putin not being elected anymore, it's just fine."}, {"time": 2892, "text": "I'm too much of a product of my upbringing to go there."}, {"time": 2898, "text": "But of course there's, like we were saying, there's gray areas, which is, I believe, I have to think through this, but I think there is a point at which Adolf Hitler became the popular choice in Nazi Germany in the 30s."}, {"time": 2912, "text": "There's a, in the same way, from an American perspective, you can start to criticize some in a shallow way, some in a deep way."}, {"time": 2923, "text": "The way that Putin has maintained power is by controlling the press."}, {"time": 2928, "text": "So limiting one other freedom that we Americans value, which is the freedom of the press or freedom of speech that he, it is very possible."}, {"time": 2937, "text": "Now things are changing now, but for most of his presidency, he was the popular choice and sometimes by far."}, {"time": 2946, "text": "And I have, I actually don't have real family in Russia who don't love Putin."}, {"time": 2955, "text": "The only people who write to me about Putin and not liking him are like sort of activists who are young, right?"}, {"time": 2964, "text": "But like to me, they're strangers."}, {"time": 2966, "text": "I don't know anything about them."}, {"time": 2968, "text": "The people I do know who have a big family in Russia, they love Putin."}, {"time": 2974, "text": "They... Do they miss elections?"}, {"time": 2981, "text": "Would they want the choice to prove it at the ballot box?"}, {"time": 2985, "text": "And, or are they so in love with him that they wouldn't wanna take a chance that someone might vote him out?"}, {"time": 2994, "text": "No, they don't think of it this way."}, {"time": 2996, "text": "And they are aware of the incredible bureaucracy and corruption that is lurking in the shadows, which is true in Russia."}, {"time": 3007, "text": "But like, there's something about the Russian, it's a remnants, corruption is so deeply part of the Russian, so the Soviet system that even the overthrow of the Soviet, the breaking apart of the Soviet Union and Putin coming and reforming a lot of the system, it's still deeply in there."}, {"time": 3028, "text": "And they're aware of that."}, {"time": 3031, "text": "That's part of the, like the love for Putin is partially grounded in the fear of what happens when the corrupt take over, the greedy take over."}, {"time": 3042, "text": "And they see Putin as the stabilizer, as like a hard like force that says... A counter force."}, {"time": 3050, "text": "Counter force that get your shit together."}, {"time": 3053, "text": "Like basically, from the Western perspective, Putin is terrible, but from the Russian perspective, Putin is the only thing holding this thing together before it goes, if it collapses."}, {"time": 3067, "text": "Now, from the, like Gary Kasparov has been loud on this, a lot of people from the Western perspective say, well, if it has to collapse, let it collapse."}, {"time": 3077, "text": "You know, that's... That's easier said than done when you don't have to live through that."}, {"time": 3081, "text": "And so anyone worrying about their family about... And they also remember the inflation and the economic instability and the suffering and the starvation that happened in the 90s with the collapse of the Soviet Union."}, {"time": 3095, "text": "And they saw the kind of reform and the economic vibrancy that happened when Putin took power, that they think like, this guy's holding it together."}, {"time": 3103, "text": "And they see elections as potentially being mechanisms by which the corrupt people can manipulate the system unfairly, as opposed to letting the people speak with their voice."}, {"time": 3118, "text": "They somehow figure out a way to manipulate the elections, to elect somebody like one of them Western revolutionaries."}, {"time": 3128, "text": "And so I think one of the beliefs that's important to the American system is the belief in the electoral system that the voice of the people can be heard in the various systems of government, whether it's judicial, whether it's..."}, {"time": 3145, "text": "I mean, basically the assumption is that the system works well enough for you to be able to elect the popular choice."}, {"time": 3156, "text": "Okay, so there's a couple of things that come to mind on that."}, {"time": 3160, "text": "The first one has to do with the idea of oligarchs."}, {"time": 3165, "text": "There's a belief in political science, you know, it's not the overall belief, but that every society is sort of an oligarchy really, if you break it down, right?"}, {"time": 3175, "text": "So what you're talking about are some of the people who would form an oligarchic class in Russia, and that Putin is the guy who can harness the power of the state to keep those people in check."}, {"time": 3190, "text": "The problem, of course, in a system like that, a strong man system, right?"}, {"time": 3193, "text": "Where you have somebody who can hold the reins and steer the ship when the ship is violently in a storm, is the succession."}, {"time": 3201, "text": "So if you're not creating a system that can operate without you, then that terrible instability and that terrible future that you justify the strong man for is just awaiting your future, right?"}, {"time": 3217, "text": "I mean, unless he's actively building the system that will outlive him and allow successors to do what he's doing, then what you've done here is create a temporary, I would think, a temporary stability here, because it's the same problem you have in a monarchy, right?"}, {"time": 3291, "text": "Now, let me ask, because I'm curious, and ignorant, so is he doing that, do you think?"}, {"time": 3298, "text": "Is he setting it up so that when there is no Putin, the state is safe?"}, {"time": 3304, "text": "From the beginning, that was the idea, whether one of the fascinating things, now, I read every biography, English written biography on Putin, so I need to think more deeply, but one of the fascinating things is how did power change Vladimir Putin?"}, {"time": 3320, "text": "He was a different man when he took power than he is today."}, {"time": 3324, "text": "I actually, in many ways, admire the man that took power."}, {"time": 3329, "text": "I think he's very different than Stalin and then Hitler at the moment they took power."}, {"time": 3334, "text": "I think Hitler and Stalin were both, in our previous discussion, already on the trajectory of evil."}, {"time": 3344, "text": "I think Putin was a humble, loyal, honest man when he took power."}, {"time": 3350, "text": "The man he is today is worth thinking about and studying."}, {"time": 3354, "text": "I'm not sure that that."}, {"time": 3356, "text": "That's an old line, though, about absolute power corrupting, absolutely."}, {"time": 3359, "text": "But it's kind of a line."}, {"time": 3362, "text": "It's a beautiful quote, but you have to really think about it."}, {"time": 3367, "text": "Like, what does that actually mean?"}, {"time": 3370, "text": "Like, one of the things I still have to do, I've been focusing on securing the conversation, right?"}, {"time": 3375, "text": "So I haven't gone through a dark place yet because I feel like I can't do the dark thing for too long."}, {"time": 3381, "text": "So I really have to put myself in the mind of Putin leading up to the conversation."}, {"time": 3387, "text": "But for now, my sense is he took power when Yeltsin gave him, one of the big sort of acts of the new Russia was for the first time in its history, a leader could have continued being in power and chose to give away power."}, {"time": 3408, "text": "That was the George Washington."}, {"time": 3409, "text": "Right, we in the United States would look at that as absolute positive, yeah."}, {"time": 3412, "text": "A sign of good things, yes."}, {"time": 3414, "text": "And so that was a huge act."}, {"time": 3416, "text": "And Putin said that that was the defining thing that will define Russia for the 21st century, that act, and he will carry that flag forward."}, {"time": 3427, "text": "That's why in rhetoric, he, after two terms, he gave away power."}, {"time": 3433, "text": "To Medvedev, but it was a puppet, right?"}, {"time": 3435, "text": "Yeah, yes, but it was, but like still the story was being told."}, {"time": 3440, "text": "I think he believed it early on."}, {"time": 3443, "text": "I think he, I believe he still believes it, but I think he's deeply suspicious of the corruption that lurks in the shadows."}, {"time": 3453, "text": "And I do believe that, like as somebody who thinks clickbait journalism is broken, journalists annoy the hell out of me."}, {"time": 3460, "text": "Clickbait journalism's working perfectly."}, {"time": 3462, "text": "Journalism's broken."}, {"time": 3463, "text": "Journalism."}, {"time": 3464, "text": "Clickbait thing's working great."}, {"time": 3466, "text": "So I understand from Putin's perspective that journalism, journalists can be seen as the enemy of the state, because people think journalists write these deep, beautiful philosophical pieces about criticizing the structure of government and the proper policy where, you know, the steps that we need to take to make a greater nation."}, {"time": 3487, "text": "No, they, they're unfairly take stuff out of context."}, {"time": 3491, "text": "They, they're critical in ways that's like shallow and not interesting."}, {"time": 3496, "text": "They, they call you a racist or sexist, or they make up stuff all the time."}, {"time": 3502, "text": "So I can put myself in the mindset of a person that thinks that it is okay to remove that kind of shallow fake news voice from the system."}, {"time": 3514, "text": "The problem is, of course, that is a slippery slope to then you remove all the annoying people from the system, and then you change what annoying means, which annoying starts becoming a thing that like anyone who opposes the system."}, {"time": 3528, "text": "I mean, I get, I get the slippery, it's obvious that it becomes a slippery slope, but I can also put myself in the mindset of the people that see it's okay to remove the liars from the system, as long as it's good for Russia."}, {"time": 3544, "text": "And, okay, so herein lies, and this again, the traditional American perspective, because we've had yellow, so called yellow journalism since the founding of the Republic."}, {"time": 3552, "text": "That's nothing new."}, {"time": 3579, "text": "It's the fake news from the government, instead of the clickbait news, and oh yeah, maybe truth mixed into all that too, in some of the outlets."}, {"time": 3588, "text": "The problem I always have with our system here in the United States right now is trying to tease the truth out from all the falsehoods."}, {"time": 3595, "text": "And look, I've got 30 years in journalism."}, {"time": 3598, "text": "My job used to be to go through, before the internet, all the newspapers, and find the, I used to know all the journalists by name, and I could pick out, you know, who they were, and I have a hard time picking out the truth from the falsehoods, so I think constantly, how are people who don't have all this background, who have lives, or who are trained in other specialties, how do they do it?"}, {"time": 3620, "text": "But if the government is the only approved outlet for truth, a traditional American, and a lot of other traditional societies based on these ideas of the Enlightenment that I talked about earlier, would see that as a disaster waiting to happen, or a tyranny in progress."}, {"time": 3669, "text": "My belief was that freedom of speech results in a stable trajectory towards truth always."}, {"time": 3678, "text": "So like truth will emerge."}, {"time": 3679, "text": "That was my sort of faith and belief that yeah, there's going to be lies all over the place, but there'll be like a stable thing that is true, that's carried forward to the public."}, {"time": 3691, "text": "Now it feels like it's possible to go towards a world where nothing is true, where truth is something that groups of people convince themselves of, and there's multiple groups of people, and the idea of some universal truth, as I suppose is the better thing, is something that we can no longer exist under."}, {"time": 3717, "text": "Like some people believe that the Green Bay Packers is the best football team, and some people can think the Patriots, and they deeply believe it to where they call the other groups liars."}, {"time": 3730, "text": "Now that's fun for sports, that's fun for favorite flavors of ice cream, but they might believe that about science, about the various aspects of politics, various aspects of sort of different policies within the function of our government."}, {"time": 3750, "text": "And like, that's not just like some weird thing we'll complain about, but that'll be the nature of things, like truth is something we can no longer have."}, {"time": 3758, "text": "Well, and let me de romanticize the American history of this too, because the American press was often just as biased, just as, I mean, I always looked to the 1970s as the high watermark of the American journalistic, in the post Watergate era, where it was actively going after the abuses of the government and all these things."}, {"time": 3784, "text": "But there was a famous speech, very quiet though, very quiet, given by Katherine Graham, who was a Washington Post editor, I believe."}, {"time": 3791, "text": "And I actually, somebody sent it to me, we had to get it off of a journalism, like a J store kind of thing."}, {"time": 3796, "text": "And she, at a luncheon, assured to the government people at the luncheon, don't worry, this is not gonna be something that we make a trend."}, {"time": 3807, "text": "Because the position of the government is still something that was carried, that the newspapers were the water, and the newspapers were the big thing up until certainly the late 60s, early 70s."}, {"time": 3820, "text": "The newspapers were still the water carrier of the government, right?"}, {"time": 3823, "text": "And they were the water carriers of the owners of the newspaper."}, {"time": 3827, "text": "So let's not pretend there was some angelic, wonderful time."}, {"time": 3831, "text": "And I'm saying to me, cause I was the one who brought it up, let's not pretend there was any super age of truthful journalism and all that."}, {"time": 3838, "text": "And I mean, you go to the revolutionary period in American history, and it looks every bit as bad as today, right?"}, {"time": 3845, "text": "That's a hopeful message, actually."}, {"time": 3846, "text": "So things may not be as bad as they look."}, {"time": 3849, "text": "Well, let's look at it more like a stock market, and that you have fluctuations in the truthfulness or believability of the press."}, {"time": 3856, "text": "And there are periods where it was higher than other periods."}, {"time": 3859, "text": "The funny thing about the so called clickbait era, and I do think it's terrible, but I mean, it resembles earlier eras to me."}, {"time": 3867, "text": "So I always compare it to when I was a kid growing up, when I thought journalism was as good as it's ever gotten."}, {"time": 3873, "text": "It was never perfect."}, {"time": 3876, "text": "But it's also something that you see very rarely in other governments around the world."}, {"time": 3881, "text": "And there's a reason that journalists are often killed regularly in a lot of countries."}, {"time": 3886, "text": "And it's because they report on things that the authorities do not want reported on."}, {"time": 3890, "text": "And I've always thought that that was what journalism should do."}, {"time": 3892, "text": "But it's gotta be truthful, otherwise it's just a different kind of propaganda, right?"}, {"time": 3899, "text": "Can we talk about Genghis Khan?"}, {"time": 3901, "text": "Genghis Khan?"}, {"time": 3903, "text": "By the way, is it Genghis Khan or Genghis Khan?"}, {"time": 3905, "text": "It's not Genghis Khan."}, {"time": 3906, "text": "It's either Genghis Khan or Chinggis Khan."}, {"time": 3909, "text": "So let's go with Genghis Khan."}, {"time": 3911, "text": "That's the only thing I'll be able to say with any certain, last certain thing I'll say about it."}, {"time": 3916, "text": "It's like, I don't know, GIF versus GIF."}, {"time": 3920, "text": "I don't know if you know about those things."}, {"time": 3921, "text": "I don't know how it ever got started the wrong way."}, {"time": 3924, "text": "So first of all, your episodes on Genghis Khan for many people are the favorite."}, {"time": 3931, "text": "It's fascinating to think about events that had so much like in their ripples, had so much impact on so much of human civilization."}, {"time": 3940, "text": "In your view, was he an evil man?"}, {"time": 3945, "text": "Let's go start a discussion of evil."}, {"time": 3948, "text": "Another way to put it is I've read he's much loved in many parts of the world like Mongolia."}, {"time": 3956, "text": "And I've also read arguments that say that he was quite a progressive for the time."}, {"time": 3963, "text": "So where do you put him?"}, {"time": 3964, "text": "Is he a progressive or is he an evil destroyer of humans?"}, {"time": 3968, "text": "As I often say, I'm not a historian, which is why what I try to bring to the Hardcore History podcasts are these sub themes."}, {"time": 3977, "text": "So each show has, and they're not, I try to kind of soft pedal them."}, {"time": 3981, "text": "So they're not always like really right in front of your face."}, {"time": 3983, "text": "In that episode, the soft peddling sub theme had to do with what we referred to as a historical arsonist."}, {"time": 3992, "text": "And it's because some historians have taken the position that sometimes, and most of this is earlier stuff, historians don't do this very much anymore, but these were the wonderful questions I grew up with that blend, it's almost the intersection between history and philosophy."}, {"time": 4008, "text": "And the idea was that sometimes the world has become so overwhelmed with bureaucracy or corruption or just stagnation that somebody has to come in or some group of people or some force has to come in and do the equivalent of a forest fire to clear out all the dead wood so that the forest itself can be rejuvenated and society can then move forward."}, {"time": 4033, "text": "And there's a lot of these periods where the historians of the past will portray these figures who come in and do horrific things as creating an almost service for mankind, right?"}, {"time": 4045, "text": "Creating the foundations for a new world that will be better than the old one."}, {"time": 4049, "text": "And it's a recurring theme."}, {"time": 4051, "text": "And so this was the sub theme of the Khan's podcast, because otherwise you don't need me to tell you the story of the Mongols, but I'm gonna bring up the historical arsonist element."}, {"time": 4060, "text": "And, but this gets to how the Khan has been portrayed, right?"}, {"time": 4064, "text": "If you wanna say, oh yes, he cleared out the dead wood and made for, well, then it's a positive thing."}, {"time": 4069, "text": "If you say, my family was in the forest fire that he set, you're not gonna see it that way."}, {"time": 4075, "text": "Much of what Genghis Khan is credited with on the upside, right?"}, {"time": 4079, "text": "So things like religious toleration, and you'll say, well, he was religiously, the Mongols were religiously tolerant."}, {"time": 4088, "text": "And so this makes them almost like a liberal reformer kind of thing."}, {"time": 4091, "text": "But this needs to be seen within the context of their empire, which was very much like the Roman viewpoint, which is the Romans didn't care at a lot of time what your local people worshiped."}, {"time": 4102, "text": "They wanted stability."}, {"time": 4104, "text": "And if that kept stability and kept you paying taxes and didn't require the legionaries to come in, then they didn't care, right?"}, {"time": 4111, "text": "And the Khans were the same way."}, {"time": 4112, "text": "Like they don't care what you're practicing as long as it doesn't disrupt their empire and cause them trouble."}, {"time": 4117, "text": "But what I always like to point out is yes, but the Khan could still come in with his representatives to your town, decide your daughter was a beautiful woman that they wanted in the Khan's concubine, and they would take them."}, {"time": 4128, "text": "So how liberal an empire is this, right?"}, {"time": 4132, "text": "So many of the things that they get credit for as though there's some kind of nice guys may in another way of looking at it just be a simple mechanism of control, right?"}, {"time": 4141, "text": "A way to keep the empire stable."}, {"time": 4144, "text": "They're not doing it out of the goodness of their heart."}, {"time": 4147, "text": "They have decided that this is the best."}, {"time": 4149, "text": "And I love because the Mongols were what we would call a pagan people now."}, {"time": 4155, "text": "I love the fact that they, and I think we call it, I forgot the term we used, had to do with, like they were hedging their bets religiously, right?"}, {"time": 4162, "text": "They didn't know which God was the right one."}, {"time": 4164, "text": "So as long as you're all praying for the health of the Khan, we're maximizing the chances that whoever the gods are, they get the message, right?"}, {"time": 4172, "text": "So I think it's been portrayed as something like a liberal empire."}, {"time": 4176, "text": "And the idea of Mongol universality is more about conquering the world."}, {"time": 4183, "text": "And it's like saying, you know, we're gonna bring stability to the world by conquering it."}, {"time": 4186, "text": "Well, what if that's Hitler, right?"}, {"time": 4188, "text": "He could make the same case, or Hitler wasn't really the world conqueror like that because he wouldn't have been trying to make it equal for all peoples."}, {"time": 4195, "text": "But my point being that it kind of takes the positive moral slant out of it if their motivation wasn't a positive moral slant to the motivate, and the Mongols didn't see it that way."}, {"time": 4209, "text": "And I think the way that it's portrayed is like, and I always like to use this analogy, but it's like shooting an arrow and painting a bull's eye around it afterwards, right?"}, {"time": 4220, "text": "How do we justify and make them look good in a way that they themselves probably, and listen, we don't have the Mongol point of view per se."}, {"time": 4229, "text": "I mean, there's something called the secret history of the Mongols, and there's things written down by Mongolian overlords through people like Persian and Chinese scribes later."}, {"time": 4238, "text": "We don't have their point of view, but it sure doesn't look like this was an attempt to create some wonderful place where everybody was living a better life than they were before."}, {"time": 4248, "text": "I think that's later people putting a nice rosy spin on it."}, {"time": 4253, "text": "But there's an aspect to it, maybe you can correct me, because I'm projecting sort of my idea of what it would take to conquer so much land is the ideology is emergent."}, {"time": 4268, "text": "So if I were to guess, the Mongols started out as exceptionally, as warriors who valued excellence in skill of killing, not even killing, but like the actual practice of war."}, {"time": 4287, "text": "And you can start out small, and you can grow and grow and grow."}, {"time": 4290, "text": "And then in order to maintain the stability of the things over which of the conquered lands, you developed a set of ideas with which you can, like you said, establish control, but it was emergent."}, {"time": 4303, "text": "And it seems like the core first principle idea of the Mongols is just to be excellent warriors."}, {"time": 4312, "text": "That felt to me like the starting point."}, {"time": 4315, "text": "It wasn't some ideology."}, {"time": 4317, "text": "Like with Hitler and Stalin, with Hitler, there was an ideology that didn't have anything to do with war underneath it."}, {"time": 4326, "text": "It was more about conquering."}, {"time": 4328, "text": "It feels like the Mongols started out more organically, I would say, like this phenomenon started emergently, and they were just like similar to the Native Americans with the Comanches, like the different warrior tribes that Joe Rogan's currently obsessed with, that led me to look into it more."}, {"time": 4348, "text": "They seem to just start out just valuing the skill of fighting whatever the tools of war they had, which were pretty primitive, but just to be the best warriors they could possibly be, make a science out of it."}, {"time": 4360, "text": "Is that crazy to think that there was no ideology behind it in the beginning?"}, {"time": 4366, "text": "I'm gonna back up a second."}, {"time": 4367, "text": "I'm reminded of the line said about the Romans, that they create a wasteland and call it peace."}, {"time": 4372, "text": "That is, but there's a lot of conquerors like that, right?"}, {"time": 4377, "text": "Where you will sit there, and listen, historians forever have, it's the famous trade offs of empire, and they'll say, well, look at the trade that they facilitated, and look at the religion, all those kinds of things, but they come at the cost of all those peoples that they conquered forcibly and by force, integrated into their empire."}, {"time": 4398, "text": "The one thing we need to remember about the Mongols that makes them different than, say, the Romans, and this is complex stuff and way above my pay grade, but I'm fascinated with it, and it's more like the Comanches that you just brought up, is that the Mongols are not a settled society, okay?"}, {"time": 4413, "text": "They come from a nomadic tradition."}, {"time": 4416, "text": "Now, several generations later, when you have Kublai Khan as the emperor of China, it's beginning to be a different thing, right?"}, {"time": 4455, "text": "They're not some really super special people."}, {"time": 4459, "text": "They're just the latest confederacy in an area that saw nomadic confederacies going back to the beginning of recorded history."}, {"time": 4497, "text": "Every warrior society I've ever seen values that."}, {"time": 4502, "text": "What the nomads had of the Eurasian steppe was this relationship between human beings and animals that changed the equation."}, {"time": 4512, "text": "It was how they rode horses."}, {"time": 4515, "text": "And societies like the Byzantines, which would form one flank of the steppe and then all the way on the other side you had China, and below that you had Persia, these societies would all attempt to create mounted horsemen who used archery."}, {"time": 4530, "text": "And they did a good job, but they were never the equals of the nomads because those people were literally raised in the saddle."}, {"time": 4538, "text": "They compared them to centaurs."}, {"time": 4541, "text": "The Comanches, great example, considered to be the best horse riding warriors in North America."}, {"time": 4548, "text": "The Comanches, I always love watching, there's paintings."}, {"time": 4551, "text": "George Catlin, the famous painter who painted the Comanches, illustrated it."}, {"time": 4557, "text": "But the Mongols and the Scythians and the Avars and all these people did it too, where they would shoot from underneath the horse's neck, hiding behind the horse the whole way."}, {"time": 4569, "text": "You look at a picture of somebody doing that, and it's insane."}, {"time": 4573, "text": "This is what the Byzantines couldn't do and the Chinese couldn't do."}, {"time": 4577, "text": "It was a different level of harnessing a human animal relationship that gave them a military advantage that could not be copied, right?"}, {"time": 4588, "text": "It could be emulated, but they were never as good, right?"}, {"time": 4591, "text": "That's why they always hired these people."}, {"time": 4593, "text": "They hired mercenaries from these areas because they were incomparable, right?"}, {"time": 4598, "text": "It's the combination of people who were shooting bows and arrows from the time they were toddlers, who were riding from the time they were, who rode all the time."}, {"time": 4606, "text": "I mean, the Huns were bow legged, the Romans said, because they were never, they ate, slept, everything in the saddle."}, {"time": 4614, "text": "That creates something that is difficult to copy."}, {"time": 4617, "text": "And it gave them a military advantage."}, {"time": 4620, "text": "I enjoy reading actually about when that military advantage ended."}, {"time": 4624, "text": "So 17th and 18th century, when the Chinese on one flank and the Russians on the other are beginning to use firearms and stuff to break this military power of these various Khans."}, {"time": 4638, "text": "The Mongols were simply the most dominating and most successful of the Confederacies."}, {"time": 4643, "text": "But if you break it down, they really formed the nucleus at the top of the pyramid, of the apex of the food chain."}, {"time": 4650, "text": "And a lot of the people that were known as Mongols were really lots of other tribes, non Mongolian tribes, that when the Mongols conquer you, after they killed a lot of you, they incorporated you into their Confederacy and often made you go first."}, {"time": 4665, "text": "You're gonna fight somebody, we're gonna make these people go out in front and suck up all the arrows before we go in and finish the job."}, {"time": 4671, "text": "So to me, and I guess a fan of the Mongols would say that the difference and what made the Mongols different wasn't the weapon system or the fighting or the warriors or the armor or anything, it was Genghis Khan."}, {"time": 4685, "text": "And if you go look at the other really dangerous, from the outside world's perspective, dangerous step, nomadic Confederacies from past history was always when some great leader emerged that could unite the tribes."}, {"time": 4697, "text": "And you see the same thing in Native American history to a degree too."}, {"time": 4701, "text": "You had people like Attila, right?"}, {"time": 4704, "text": "Or there's one called Tumen."}, {"time": 4706, "text": "You go back in history and these people make the history books because they caused an enormous amount of trouble for their settled neighbors that normally, I mean, Chinese Byzantine and Persian approaches to the steppe people were always the same."}, {"time": 4719, "text": "They would pick out tribes to be friendly with, they would give them money, gifts, hire them, and they would use them against the other tribes."}, {"time": 4726, "text": "And generally Byzantine, especially in Chinese diplomatic history was all about keeping these tribes separated."}, {"time": 4734, "text": "Don't let them form confederations of large numbers of them because then they're unstoppable."}, {"time": 4739, "text": "Attila was a perfect example."}, {"time": 4741, "text": "The Huns were another large, the Turks, another large confederacy of these people."}, {"time": 4745, "text": "And they were devastating when they could unite."}, {"time": 4748, "text": "So the diplomatic policy was don't let them."}, {"time": 4750, "text": "That's what made the Mongols different is Genghis Khan united them."}, {"time": 4754, "text": "And then unlike most of the tribal confederacies, they were able to hold it together for a few generations."}, {"time": 4759, "text": "To linger on the little thread that you started pulling on this man, Genghis Khan, that was a leader."}, {"time": 4768, "text": "Temujin, yeah."}, {"time": 4769, "text": "What do you think makes a great leader?"}, {"time": 4772, "text": "Maybe if you have other examples throughout history and great, again, let's use that term loosely."}, {"time": 4781, "text": "Meaning."}, {"time": 4782, "text": "Now I was gonna ask for a definition."}, {"time": 4782, "text": "Great uniter of whether it's evil or good, it doesn't matter."}, {"time": 4789, "text": "Is there somebody who stands out to you, Alexander the Great talking about military or ideologies, some people bring up FDR or, I mean, you could be the founding fathers of this country, or we can go to, was he man of the century up there?"}, {"time": 4809, "text": "Hitler of the 20th century and Stalin and these people had really amassed the amount of power that probably has never been seen in the history of the world."}, {"time": 4822, "text": "Is there somebody who stands out to you by way of trying to define what makes a great uniter, great leader in one man or woman, maybe in the future?"}, {"time": 4835, "text": "And one I've thought a lot about, because let's take Alexander the Great as an example, because Alexander fascinated the world of his time, fascinated, ever since people have been fascinated with the guy."}, {"time": 4845, "text": "But Alexander was a hereditary monarch, right?"}, {"time": 4850, "text": "He was handed the kingdom."}, {"time": 4852, "text": "Which is fascinating."}, {"time": 4853, "text": "Right, but he did not need to rise from nothing to get that job."}, {"time": 4857, "text": "In fact, he reminds me of a lot of other leaders of Frederick the Great, for example, in Prussia."}, {"time": 4863, "text": "These are people who inherited the greatest army of their day."}, {"time": 4869, "text": "Alexander, unless he was an imbecile, was going to be great no matter what, because I mean, if you inherit the Wehrmacht, you're gonna be able to do something with it, right?"}, {"time": 4879, "text": "Alexander's father may have been greater, Philip."}, {"time": 4883, "text": "Philip II was the guy who literally did create a strong kingdom from a disjointed group of people that were continually beset by their neighbors."}, {"time": 4894, "text": "He's the one that reformed that army, took things that he had learned from other Greek leaders like the Theban leader at Paminondas, and then laboriously over his lifetime stabilized the frontiers, built this system."}, {"time": 4911, "text": "He lost an eye doing it."}, {"time": 4913, "text": "His leg was made lame."}, {"time": 4915, "text": "I mean, this was a man who looked like he built the empire and led from the front ranks."}, {"time": 4920, "text": "I mean, and then who may have been killed by his son, we don't know who assassinated Philip, but then handed the greatest army the world had ever seen to his son, who then did great things with it."}, {"time": 4932, "text": "You see this pattern many times."}, {"time": 4933, "text": "So in my mind, I'm not sure Alexander really can be that great when you compare him to people who arose from nothing."}, {"time": 4942, "text": "So the difference between what we would call in the United States the self made man or the one who inherits a fortune."}, {"time": 4949, "text": "There's an old line that, it's a slur, but it's about rich people."}, {"time": 4953, "text": "And it's like he was born on third base and thought he hit a triple, right?"}, {"time": 4959, "text": "Philip was born at home plate and he had to hit."}, {"time": 4962, "text": "Alexander started on third base."}, {"time": 4965, "text": "And so I try to draw a distinction between them."}, {"time": 4968, "text": "Genghis Khan is tough because there's two traditions."}, {"time": 4971, "text": "The tradition that we grew up with here in the United States and that I grew up learning was that he was a self made man."}, {"time": 4977, "text": "But there is a tradition, and it may be one of those things that's put after the fact because a long time ago, whether or not you had blue blood in your veins was an important distinction."}, {"time": 4988, "text": "And so the distinction that you'll often hear from Mongolian history is that this was a nobleman who had been deprived of his inheritance."}, {"time": 4996, "text": "So he was a blue blood anyway."}, {"time": 4998, "text": "I don't know which is true."}, {"time": 5000, "text": "There's certainly, I mean, when you look at a Genghis Khan, you have to go, that is a wicked amount of things to have achieved."}, {"time": 5008, "text": "He's very impressive as a figure."}, {"time": 5010, "text": "Attila is very impressive as a figure."}, {"time": 5013, "text": "Hitler's an interesting figure."}, {"time": 5015, "text": "He's one of those people, you know, the more you study about Hitler, the more you wonder where the defining moment was."}, {"time": 5023, "text": "Because if you look at his life, I mean, Hitler was a relatively common soldier in the First World War."}, {"time": 5031, "text": "I mean, he was brave."}, {"time": 5032, "text": "He got some decorations."}, {"time": 5034, "text": "In fact, the highest decoration he got in the First World War was given to him by a Jewish officer."}, {"time": 5039, "text": "And he often didn't talk about that decoration, even though it was the more prestigious one because it would open up a whole can of worms you didn't wanna get into."}, {"time": 5047, "text": "But Hitler's, I mean, if you said who was Hitler today, one of the top things you're gonna say is he was an anti Semite."}, {"time": 5054, "text": "Well, then you have to draw a distinction between general regular anti Semitism that was pretty common in the era and something that was a rabid level of anti Semitism."}, {"time": 5064, "text": "But Hitler didn't seem to show a rabid level of anti Semitism until after or at the very end of the First World War."}, {"time": 5071, "text": "So if this is a defining part of this person's character and much of what we consider to be his evil stems from that, what happened to this guy when he's an adult, right?"}, {"time": 5083, "text": "He's already fought in the war to change him so."}, {"time": 5085, "text": "I mean, it's almost like the old, there was always a movie theme."}, {"time": 5088, "text": "Somebody gets hit by something on the head and their whole personality changes, right?"}, {"time": 5092, "text": "I mean, it almost seems something like that."}, {"time": 5095, "text": "So I don't think I call that necessarily a great leader."}, {"time": 5098, "text": "To me, the interesting thing about Hitler is what the hell happened to a nondescript person who didn't really impress anybody with his skills."}, {"time": 5107, "text": "And then in the 1920s, it's all of a sudden, as you said, sort of the man of the hour, right?"}, {"time": 5112, "text": "So that to me is kind of, I have this feeling that Genghis Khan, and we don't really know, was an impressive human being from the get go."}, {"time": 5120, "text": "And then he was raised in this environment with pressure on all sides."}, {"time": 5123, "text": "So you start with this diamond and then you polish it and you harden it his whole life."}, {"time": 5127, "text": "Hitler seemed to be a very unimpressive gemstone most of his life, and then all of a sudden."}, {"time": 5133, "text": "So, I mean, I don't think I can label great leaders."}, {"time": 5136, "text": "And I'm always fascinated by that idea that, and I'm trying to remember who the quote was by that, that great men, oh, Lord Acton."}, {"time": 5143, "text": "So great men are often not good men."}, {"time": 5147, "text": "And that in order to be great, you would have to jettison many of the moral qualities that we normally would consider a Jesus or a Gandhi, or, you know, these qualities that one looks at as the good upstanding moral qualities that we should all aspire to as examples, right?"}, {"time": 5163, "text": "The Buddha, whatever it might be, those people wouldn't make good leaders because what you need to be a good leader often requires the kind of choices that a true philosophical diogenes moral man wouldn't make."}, {"time": 5175, "text": "So I don't have an answer to your question."}, {"time": 5177, "text": "How about that?"}, {"time": 5178, "text": "That's a long way of saying, I don't know."}, {"time": 5180, "text": "Just linger a little bit."}, {"time": 5182, "text": "It does feel like from my study of Hitler that the time molded the man versus Genghis Khan, where it feels like he, the man molded his time."}, {"time": 5193, "text": "Yes, and I feel that way about a lot of those nomadic Confederacy builders, that they really seem to be these figures that stand out as extraordinary in one way or another."}, {"time": 5205, "text": "Remembering, by the way, that almost all the history of them were written by the enemies that they so mistreated that they were probably never gonna get any good press."}, {"time": 5212, "text": "They didn't write themselves."}, {"time": 5213, "text": "That's a caveat."}, {"time": 5214, "text": "We should always add to basically all of human history."}, {"time": 5216, "text": "Nomadic or Native American peoples or tribal peoples anywhere generally do not get the advantage of being able to write the history of their heroes."}, {"time": 5224, "text": "Okay, I've recently almost done with the rise and the fall of the Third Reich."}, {"time": 5231, "text": "It's one of the historical descriptions of Hitler's rise to power, Nazi's rise to power."}, {"time": 5241, "text": "There's a few philosophical things I'd like to ask you to see if you can help."}, {"time": 5247, "text": "Like one of the things I think about is how does one be a hero in 1930s Nazi Germany?"}, {"time": 5257, "text": "What does it mean to be a hero?"}, {"time": 5261, "text": "What do heroic actions look like?"}, {"time": 5264, "text": "I think about that because I think about how I move about in this world today."}, {"time": 5276, "text": "That we live in really chaotic, intense times where I don't think you wanna draw any parallels between Nazi Germany and modern day in any of the nations we can think about."}, {"time": 5289, "text": "But it's not out of the realm of possibility that authoritarian governments take hold, authoritarian companies take hold."}, {"time": 5301, "text": "And I'd like to think that I could be in my little small way and inspire others to take the heroic action before things get bad."}, {"time": 5313, "text": "And I kind of try to place myself in what would 1930s Germany look like?"}, {"time": 5320, "text": "Is it possible to stop a Hitler?"}, {"time": 5324, "text": "Is it even the right way to think about it?"}, {"time": 5327, "text": "And how does one be a hero in it?"}, {"time": 5331, "text": "I mean, you often talk about that living through a moment in history is very different than looking at that history, looking when you look back."}, {"time": 5340, "text": "I also think about it, would it be possible to understand what's happening that the bells of war are ringing?"}, {"time": 5352, "text": "It seems that most people didn't seem to understand, you know, late into the 30s that war is coming."}, {"time": 5362, "text": "On the United States side, inside Germany, like the opposing figures, the German military didn't seem to understand this."}, {"time": 5370, "text": "Maybe the other countries, certainly France and England didn't seem to understand this."}, {"time": 5377, "text": "That kind of tried to put myself into 90s, 30s Germany as I'm Jewish, which is another little twist on the whole."}, {"time": 5386, "text": "Like what would I do?"}, {"time": 5388, "text": "What should one do?"}, {"time": 5391, "text": "Do you have interesting answers?"}, {"time": 5394, "text": "So earlier we had talked about Putin and we had talked about patriotism and love of country and those sorts of things."}, {"time": 5400, "text": "In order to be a hero in Nazi Germany by our views here, you would have had to have been anti patriotic to the average German's viewpoint in the 1930s, right?"}, {"time": 5416, "text": "You would have to have opposed your own government and your own country."}, {"time": 5421, "text": "And that's a very, it would be a very weird thing to go to people in Germany and say, listen, the only way you're gonna be seen as a good German and a hero to the country that will be your enemies is we think you should oppose your own government."}, {"time": 5436, "text": "It's a strange position to put the people in a government saying you need to be against your leader, you need to oppose your government's policies, you need to oppose your government, you need to hope and work for its downfall."}, {"time": 5449, "text": "That doesn't sound patriotic."}, {"time": 5451, "text": "It wouldn't sound patriotic here in this country if you made a similar argument."}, {"time": 5455, "text": "I will go away from the 1930s and go to the 1940s to answer your question."}, {"time": 5461, "text": "So there is movements like the White Rose Movement in Germany, which involved young people really, and from various backgrounds, religious backgrounds often, who worked openly against the Nazi government at a time when power was already consolidated, the Gestapo was in full force and they execute people who are against the government."}, {"time": 5484, "text": "And these young people would go out and distribute pamphlets and many of them got their heads cut off with guillotines for their trouble."}, {"time": 5492, "text": "And they knew that that was gonna be the penalty."}, {"time": 5495, "text": "That is a remarkable amount of bravery and sacrifice and willingness to die, and almost not even willingness because they were so open about it, it's almost a certainty, right?"}, {"time": 5509, "text": "That's incredibly moving to me."}, {"time": 5511, "text": "So when we talk, and we had talked earlier about sort of the human spirit and all that kind of thing, there are people in the German military who opposed and worked against Hitler, for example."}, {"time": 5524, "text": "But to me, that's almost cowardly compared to what these young people did in the White Rose Movement because those people in the Wehrmacht, for example, who were secretly trying to undermine Hitler, they're not really putting their lives on the line to the same degree."}, {"time": 5540, "text": "And so I think when I look at heroes, and listen, I remember once saying there were no conscientious objectors in Germany as a way to point out to people that you didn't have a choice, you know, you were gonna serve in there."}, {"time": 5552, "text": "And I got letters from Jehovah's Witnesses who said, yes, there were."}, {"time": 5556, "text": "And we got sent to the concentration camps."}, {"time": 5559, "text": "Those are remarkably brave things."}, {"time": 5562, "text": "It's one thing to have your own set of standards and values."}, {"time": 5567, "text": "It's another thing to say, oh no, I'm going to display them in a way that with this regime, that's a death sentence."}, {"time": 5574, "text": "And not just for me, for my family, right?"}, {"time": 5577, "text": "In these regimes, there was not a lot of distinction made between father and son and wives."}, {"time": 5583, "text": "That's a remarkable sacrifice to make."}, {"time": 5585, "text": "And far beyond what I think I would even be capable of."}, {"time": 5588, "text": "And so the admiration comes from seeing people who appear to be more morally profound than you are yourself."}, {"time": 5598, "text": "So when I look at this, I look at that kind of thing and I just say, wow."}, {"time": 5602, "text": "And the funny thing is if you'd have gone to most average Germans on the street in 1942 and said, what do you think of these people?"}, {"time": 5611, "text": "They're gonna think of them as traitors who probably got what they deserved."}, {"time": 5615, "text": "So that's the eye of the beholder thing."}, {"time": 5617, "text": "It's the power of the state to sow propagandize values and morality in a way that favors the state that you can turn people who today we look at as unbelievably brave and moral and crusading for righteousness and turn them into enemies of the people."}, {"time": 5638, "text": "So, I mean, in my mind, it would be people like that."}, {"time": 5640, "text": "See, I think, so hero is a funny word and we romanticize the notion, but if I could drag you back to 1930s Germany from 1940s."}, {"time": 5653, "text": "I feel like the heroic actions that doesn't accomplish much is not what I'm referring to."}, {"time": 5661, "text": "So there's many heroes I look up to that, like David Goggins, for example, the guy who runs crazy distances."}, {"time": 5671, "text": "He runs for no purpose except for the suffering in itself."}, {"time": 5675, "text": "And I think his willingness to challenge the limits of his mind is heroic."}, {"time": 5682, "text": "I guess I'm looking for a different term, which is how could Hitler have been stopped?"}, {"time": 5689, "text": "My sense is that he could have been stopped in the battle of ideas where people, millions of people were suffering economically or suffering because of the betrayal of World War I in terms of the love of country and how they felt they were being treated."}, {"time": 5707, "text": "And a charismatic leader that inspired love and unity that's not destructive could have emerged."}, {"time": 5715, "text": "And that's where the battle should have been fought."}, {"time": 5718, "text": "I would suggest that we need to take into account the context of the times that led to Hitler's rise of power and created the conditions where his message resonated."}, {"time": 5731, "text": "That is not a message that resonates at all times, right?"}, {"time": 5734, "text": "It is impossible to understand the rise of Hitler without dealing with the First World War and the aftermath of the First World War and the inflationary terrible depression in Germany and all these things and the dissatisfaction with the Weimar Republic's government, which was often seen as something put into, which it was put into place by the victorious powers."}, {"time": 5759, "text": "Hitler referred to the people that signed those agreements that signed the armistice as the November criminals."}, {"time": 5766, "text": "And he used that as a phrase which resonated with the population."}, {"time": 5770, "text": "This was a population that was embittered."}, {"time": 5772, "text": "And even if they weren't embittered, the times were so terrible."}, {"time": 5775, "text": "And the options for operating within the system in a non radical way seemed totally discredited, right?"}, {"time": 5784, "text": "You could work through the Weimar Republic, but they tried and it wasn't working anyway."}, {"time": 5787, "text": "And then the alternative to the Nazis who were bully boys in the street were communist agitators that to the average conservative Germans seem no better."}, {"time": 5796, "text": "So you have three options if you're an average German person."}, {"time": 5799, "text": "You can go with the discredited government put in power by your enemies that wasn't working anyway."}, {"time": 5806, "text": "You could go with the Nazis who seemed like a bunch of super patriots calling for the restoration of German authority, or you could go with the communists."}, {"time": 5815, "text": "And the entire thing seemed like a litany of poor options."}, {"time": 5820, "text": "And in this realm, Hitler was able to triangulate, if you will."}, {"time": 5827, "text": "He came off as a person who was going to restore German greatness at a time when this was a powerful message."}, {"time": 5833, "text": "But if you don't need German greatness restored, it doesn't resonate, right?"}, {"time": 5838, "text": "So the reason that your love idea and all this stuff, I don't think would have worked in the time period is because that was not a commodity that the average German was in search of then."}, {"time": 5850, "text": "Well, it's interesting to think about whether greatness can be restored through mechanisms, through ideas that are not so, from our perspective today, so evil."}, {"time": 5866, "text": "I don't know what the right term is."}, {"time": 5868, "text": "But the war continued in a way."}, {"time": 5870, "text": "So remember that when Germany, when Hitler is rising to power, the French are in control of parts of Germany, right?"}, {"time": 5878, "text": "The Ruhr, one of the main industrial heartlands of Germany, was occupied by the French."}, {"time": 5882, "text": "So there's never this point where you're allowed to let the hate dissipate, right?"}, {"time": 5887, "text": "Every time maybe things were calming down, something else would happen to stick the knife in and twist it a little bit more, from the average German's perspective, right?"}, {"time": 5896, "text": "The reparations, right?"}, {"time": 5898, "text": "So if you say, okay, well, we're gonna get back on our feet, the reparations were crushing."}, {"time": 5902, "text": "These things prevented the idea of love or brotherhood and all these things from taking hold."}, {"time": 5909, "text": "And even if there were Germans who felt that way, and there most certainly were, it is hard to overcome the power of everyone else."}, {"time": 5918, "text": "You know, what I always say when people talk to me about humanity is I believe on individual levels, we're capable of everything and anything, good, bad, or indifferent."}, {"time": 5928, "text": "But collectively, it's different, right?"}, {"time": 5931, "text": "And in the time period that we're talking about here, messages of peace on earth and love your enemies and all these sorts of things were absolutely deluged and overwhelmed and drowned out by the bitterness, the hatred, and let's be honest, the sense that you were continually being abused by your former enemies."}, {"time": 5951, "text": "There were a lot of people in the Allied side that realized this and said, we're setting up the next war."}, {"time": 5957, "text": "This is, I mean, they understood that you can only do certain things to collective human populations for a certain period of time before it is natural for them to want to."}, {"time": 5966, "text": "And there are, you can see German posters from the region, Nazi propaganda posters that show them breaking off the chains of their enemies."}, {"time": 5973, "text": "And I mean, Germany awake, right?"}, {"time": 5975, "text": "That was the great slogan."}, {"time": 5977, "text": "So I think love is always a difficult option."}, {"time": 5982, "text": "And in the context of those times, it was even more disempowered than normal."}, {"time": 5988, "text": "Well, this goes to the, just to linger on it for a little longer, the question of the inevitability of history."}, {"time": 5999, "text": "Do you think Hitler could have been stopped?"}, {"time": 6002, "text": "Do you think this kind of force that you're saying that there was a pain and it was building, there was a hatred that was building, do you think there was a way to avert?"}, {"time": 6015, "text": "I mean, there's two questions."}, {"time": 6017, "text": "Could have been a lot worse and could have been better in the trajectory of history in the 30s and 40s."}, {"time": 6025, "text": "The most logical, see, we had started this conversation, it brings a wonderful bow tie into the discussion and buttons it up nicely."}, {"time": 6032, "text": "We had talked about force and counter force earlier."}, {"time": 6035, "text": "The most obvious and much discussed way that Hitler could have been stopped has nothing to do with Germans."}, {"time": 6042, "text": "When he remilitarized the Rhineland, everyone talks about what a couple of French divisions would have done had they simply gone in and contested."}, {"time": 6052, "text": "And this was something Hitler was extremely, I mean, it might've been the most nervous time in his entire career because he was afraid that they would have responded with force and he was in no position to do anything about it if they did."}, {"time": 6064, "text": "So this is where you get the people who say, and Churchill's one of these people too, where they talk about that he should have been stopped militarily right at the very beginning when he was weak."}, {"time": 6076, "text": "I don't think..."}, {"time": 6080, "text": "Listen, there were candidates in the Catholic Center Party and others in the Weimar Republic that maybe could have done things and it's beyond my understanding of specific German history to talk about it intelligently."}, {"time": 6092, "text": "But I do think that had the French responded militarily to Hitler's initial moves into that area, that he would have been thwarted."}, {"time": 6100, "text": "And I think he himself believed, if I'm remembering my reading, that this would have led to his downfall."}, {"time": 6106, "text": "So the potential... See, what I don't like about this is that it almost legitimizes military intervention at a very early stage to prevent worse things from happening, but it might be a pretty clear cut case."}, {"time": 6118, "text": "But it shows we pointed out that there was a lot of sympathy on the part of the allies for the fact that the Germans probably should have Germany back and this is traditional German land."}, {"time": 6128, "text": "I mean, they were trying, in a funny way, it's almost like the love and the sense of justice on the allies part may have actually stayed their hand in a way that would have prevented much, much, much worse things later."}, {"time": 6142, "text": "But if the times were such that the message of a Hitler resonated, then simply removing Hitler from the equation would not have removed the context of the times."}, {"time": 6154, "text": "And that means one of two things, either you could have had another one or you could have ended up in a situation equally bad in a different direction."}, {"time": 6164, "text": "I don't know what that means because it's hard to imagine anything could be worse than what actually occurred, but history's funny that way."}, {"time": 6172, "text": "And Hitler's always everyone's favorite example of the difference between the great man theory of history and the trends and forces theories of history, right?"}, {"time": 6181, "text": "The times made a Hitler possible and maybe even desirable to some."}, {"time": 6186, "text": "If you took him out of the equation, those trends and forces are still in place, right?"}, {"time": 6193, "text": "If you take him out and the door is still open, does somebody else walk through it?"}, {"time": 6199, "text": "Yeah, it's mathematically speaking, the probability of charismatic leaders emerge."}, {"time": 6208, "text": "I'm so torn on that at this point."}, {"time": 6212, "text": "Here's another way to look at it."}, {"time": 6213, "text": "The institutional stability of Germany in that time period was not enough to push back."}, {"time": 6221, "text": "And there are other periods in German history."}, {"time": 6223, "text": "I mean, that Hitler arose in, arisen in 1913, he doesn't get anywhere because Germany's institutional power is enough to simply quash that."}, {"time": 6234, "text": "It's the fact that Germany was unstable anyway that prevented a united front that would have kept radicalism from getting out of hand."}, {"time": 6244, "text": "A tricky question on this, just to stay on this a little longer because I'm not sure how to think about it, is the World War II versus the Holocaust."}, {"time": 6258, "text": "We were talking just now about the way that history unrolls itself and could Hitler have been stopped?"}, {"time": 6266, "text": "And I don't quite know what to think about Hitler without the Holocaust."}, {"time": 6273, "text": "And perhaps in his thinking, how essential the antisemitism and the hatred of Jews was."}, {"time": 6284, "text": "It feels to me that, I mean, we were just talking about where did he pick up his hatred of the Jewish people?"}, {"time": 6294, "text": "There's stories in Vienna and so on that it almost is picking up the idea of antisemitism as a really useful tool, as opposed to actually believing it in its core."}, {"time": 6310, "text": "Do you think World War II as it turned out and Hitler as he turned out would be possible without antisemitism?"}, {"time": 6318, "text": "Could we have avoided the Holocaust?"}, {"time": 6321, "text": "Or was it an integral part of the ideology of fascism and the Nazis?"}, {"time": 6329, "text": "Not an integral part of fascism because Mussolini really, I mean, Mussolini did it to please Hitler, but it wasn't an integral part."}, {"time": 6336, "text": "What's interesting to me is that that's the big anomaly in the whole question because antisemitism didn't need to be a part of this at all, right?"}, {"time": 6345, "text": "Hitler had a conspiratorial view of the world."}, {"time": 6350, "text": "He was a believer that the Jews controlled things, right?"}, {"time": 6353, "text": "The Jews were responsible for both Bolshevism on one side and capitalism on the other, they ruled the banks."}, {"time": 6360, "text": "I mean, United States was a Jewified country, right?"}, {"time": 6363, "text": "Bolshevism was a Jewified sort of a political."}, {"time": 6369, "text": "In other words, he saw Jews everywhere and he had that line about it."}, {"time": 6372, "text": "The Jews of Europe force another war to Germany, they'll pay the price or whatever, but then you have to believe that they're capable of that."}, {"time": 6380, "text": "The Holocaust is a weird, weird sidebar to the whole thing."}, {"time": 6384, "text": "And here's what I've always found interesting."}, {"time": 6385, "text": "It's a sidebar that weakened Germany because look at the First World War."}, {"time": 6389, "text": "The Jews fought for Germany, right?"}, {"time": 6391, "text": "Who was the most important?"}, {"time": 6394, "text": "And this is a very arguable point, but it's just the first one that pops into my head."}, {"time": 6398, "text": "Who was the most important Jewish figure that would have maybe been on the German side had the Germans had a non antisemitic?"}, {"time": 6408, "text": "Well, listen, that whole part."}, {"time": 6409, "text": "Yes, it was Einstein, but the whole, I should point out that to say Germany or Europe or Russia or any of those things were not antisemitic is to do injustice to history, right?"}, {"time": 6420, "text": "Pogroms, I mean, it's standard operating procedure."}, {"time": 6424, "text": "What you see in the Hitlerian era is an absolute huge spike, right?"}, {"time": 6429, "text": "Cause the government has a conspiracy theory that the Jews have."}, {"time": 6432, "text": "It's funny because Hitler both thought of them as weak and super powerful at the same time, right?"}, {"time": 6437, "text": "And as an outsider people that weakened Germany, the whole idea of the blood and how that connects to Darwinism and all that sort of stuff is just weird, right?"}, {"time": 6446, "text": "A real outlier, but Einstein, let's just play with Einstein."}, {"time": 6451, "text": "If there's no antisemitism in Germany or none above the normal level, right?"}, {"time": 6458, "text": "The baseline level, does Einstein leave along with all the other Jewish scientists?"}, {"time": 6464, "text": "And what does Germany have as increased technological and intellectual capacity if they stay, right?"}, {"time": 6472, "text": "It's something that actually weakened that state."}, {"time": 6475, "text": "It's a tragic flaw in the Hitlerian worldview, but it was so, and let me, you had mentioned earlier, like maybe it was not integral to his character."}, {"time": 6486, "text": "Maybe it was a wonderful tool for power."}, {"time": 6490, "text": "Somewhere along the line, and really not at the beginning, this guy became absolutely obsessed with this."}, {"time": 6497, "text": "With the conspiracy theory."}, {"time": 6499, "text": "And Jews, and he surrounded himself with people and theorists."}, {"time": 6503, "text": "I'm gonna use that word really, really sort of loosely, who believed this too."}, {"time": 6508, "text": "And so you have a cabal of people who are reinforcing this idea that the Jews control the world."}, {"time": 6515, "text": "He called it international jewelry was a huge part of the problem."}, {"time": 6519, "text": "And because of that, they deserved to be punished."}, {"time": 6520, "text": "They were an enemy within all these kinds of things."}, {"time": 6523, "text": "It's a nutty conspiracy theory that the government of one of the most, I mean, the big thing with Germany was culture, right?"}, {"time": 6531, "text": "They were a leading figure in culture and philosophy and all these kinds of things."}, {"time": 6536, "text": "And that they could be overtaken with this wildly wickedly weird conspiracy theory and that it would actually determine things."}, {"time": 6545, "text": "I mean, Hitler was taking vast amounts of German resources and using it to wipe out this race when he needed them for all kinds of other things to fight a war of annihilation."}, {"time": 6554, "text": "So that is the weirdest part of the whole Nazi phenomenon."}, {"time": 6559, "text": "It's the darkest possible silver lining to think about is that the Holocaust may have been and the hatred of the Jewish people may have been the thing that avoided Germany getting the nuclear weapons first."}, {"time": 6578, "text": "Isn't that a wonderful historical ironic twist that if it weren't so overlaid with tragedy, a thousand years from now will be seen as something really kind of funny."}, {"time": 6586, "text": "Well, that's true."}, {"time": 6587, "text": "It's fascinating to think as you've talked."}, {"time": 6590, "text": "So the seeds of his own destruction, right?"}, {"time": 6592, "text": "The tragic flaw."}, {"time": 6595, "text": "And my hope is, this is a discussion I have with my dad as a physicist, is that evil inherently contains with it that kind of incompetence."}, {"time": 6612, "text": "So my dad's discussion, so he's a physicist and an engineer, his belief is that at this time in our history, the reason we haven't had nuclear like terrorist blow up a nuclear weapon somewhere in the world is that the kind of people that would be terrorists are simply not competent enough at their job of being a destructive."}, {"time": 6641, "text": "So like, there's a kind of, if you plot it, the more evil you are, the less able you are."}, {"time": 6647, "text": "And by evil, I mean, purely just like we said, if we were to consider the hatred of Jewish people as evil, because it's sort of detached from reality, it's like just this pure hatred of something that's grounded on things, conspiracy theories."}, {"time": 6667, "text": "If that's evil, then the more you sell yourself, the more you give into these conspiracy theories, the less capable you are at actually engineering, which is very difficult, engineering nuclear weapons and effectively deploying them."}, {"time": 6680, "text": "So that's a hopeful message that the destructive people in this world are by their worldview incompetent in creating the ultimate destruction."}, {"time": 6695, "text": "I straight up don't agree with that."}, {"time": 6697, "text": "So why are we still here?"}, {"time": 6699, "text": "Why haven't we destroyed ourselves?"}, {"time": 6701, "text": "Why haven't the terrorists blown, it's been many decades."}, {"time": 6705, "text": "Why haven't we destroyed ourself to this point?"}, {"time": 6709, "text": "Well, when you say it's been many decades, many decades, that's like saying in the life of 150 year old person, we've been doing well for a year."}, {"time": 6718, "text": "The problem with all these kinds of equations, and it was Bertrand Russell, right?"}, {"time": 6722, "text": "The philosopher who said so."}, {"time": 6724, "text": "He said, it's unreasonable to expect a man to walk on a tight rope for 50 years."}, {"time": 6732, "text": "I mean, the problem is that this is a long game."}, {"time": 6735, "text": "And let's remember that up until relatively recently, what would you say, 30 years ago, the nuclear weapons in the world were really tightly controlled."}, {"time": 6744, "text": "That was one of the real dangers in the fall of the Soviet Union."}, {"time": 6746, "text": "Remember the worry that all of a sudden you were gonna have bankrupt former Soviet Republic selling nuclear weapons to terrorists and whatnot."}, {"time": 6755, "text": "I would suggest, and here's another problem is that when we call these terrorists evil, it's easy for an American, for example, to say that Osama bin Laden is evil."}, {"time": 6764, "text": "Easy for me to say that."}, {"time": 6766, "text": "But one man's terrorist is another man's freedom fighter as the saying goes, and to other people, he's not."}, {"time": 6772, "text": "What Osama bin Laden did, and the people that worked with him, we would call evil genius."}, {"time": 6778, "text": "The idea of hijacking planes and flying them into the buildings like that, and that he could pull that off, and that still boggles my mind."}, {"time": 6787, "text": "I'm still, it's funny, I'm still stunned by that."}, {"time": 6790, "text": "And yet, the idea, here's the funny part, and I hesitate to talk about this because I don't wanna give anyone ideas, but you don't need nuclear weapons to do incredibly grave amounts of danger."}, {"time": 6806, "text": "I mean, what one can of gasoline and a BIC lighter can do in the right place and the right time, and over and over and over again can bring down societies."}, {"time": 6818, "text": "This is the argument behind the importance of the stability that a nation state provides."}, {"time": 6824, "text": "So when we went in and took out Saddam Hussein, one of the great counter arguments from some of the people who said, this is a really stupid thing to do, is that Saddam Hussein was the greatest anti terror weapon in that region that you could have because they were a threat to him."}, {"time": 6841, "text": "So he took that, and he did it in a way that was much more repressive than we would ever be, right?"}, {"time": 6847, "text": "And this is the old line about why we supported right wing death squad countries, because they were taking out people that would inevitably be a problem for us if they didn't, and they were able to do it in a way we would never be able to do, supposedly."}, {"time": 6861, "text": "We're pretty good at that stuff, just like the Soviet Union was behind the scenes and underneath the radar."}, {"time": 6867, "text": "But the idea that the stability created by powerful and strong centralized leadership allowed them, it's almost like outsourcing anti terror activities, allowed them to, for their own reasons."}, {"time": 6879, "text": "I mean, you see the same thing in the Syria situation with the Assads."}, {"time": 6882, "text": "I mean, you can't have an ISIS in that area because that's a threat to the Assad government who will take care of that for you, and then that helps us by not having an ISIS."}, {"time": 6891, "text": "So I would suggest one, that the game is still on on whether or not these people get nuclear weapons in their hands."}, {"time": 6900, "text": "I would suggest they don't need them to achieve their goals, really."}, {"time": 6905, "text": "The crazy thing is if you start thinking like the Joker in Batman, the terrorist ideas, it's funny, I guess I would be a great terrorist because I'm just full of those ideas."}, {"time": 6913, "text": "Oh, you could do this, you could, it's scary to think of how vulnerable we are."}, {"time": 6917, "text": "But the whole point is that you as the Joker wouldn't do the terrorist actions."}, {"time": 6924, "text": "That's the theory that's so hopeful to me with my dad, is that all the ideas, your ability to generate good ideas, forget nuclear weapons, how you can disrupt the power grid, how you can disrupt the, attack our psychology, attack like with a can of gasoline, like you said, somehow disrupt the American system of ideas."}, {"time": 6949, "text": "That coming up with good ideas there."}, {"time": 6953, "text": "Are we saying evil people can't come up with evil genius ideas?"}, {"time": 6958, "text": "We have this Hollywood story."}, {"time": 6960, "text": "I don't think history backs that up."}, {"time": 6962, "text": "I mean, I think you can say with the nuclear weapons, it does, but only because they're so recent."}, {"time": 6966, "text": "But I mean, evil genius, I mean, that's almost proverbial."}, {"time": 6970, "text": "But that's, okay, so to push back for the fun of it, or."}, {"time": 6973, "text": "And I don't mean to, I don't want you to leave this in a terrible mood because I push back on every hopeful idea you had, but I tend to be a little cynical about that stuff."}, {"time": 6982, "text": "But that goes to the definition of evil, I think, because I'm not so sure human history has a lot of evil people being competent."}, {"time": 6993, "text": "I do believe that they mostly, like in order to be good at doing what may be perceived as evil, you have to be able to construct an ideology around which you truly believe when you look in the mirror by yourself, that you're doing good for the world."}, {"time": 7011, "text": "And it's difficult to construct an ideology where destroying the lives of millions or disrupting the American system, I'm already contradicting myself as I'm saying."}, {"time": 7023, "text": "I was just gonna say, people have done this already, yes."}, {"time": 7025, "text": "So, but then it's the question of like, about aliens with the idea that if the aliens are all out there, why haven't they visited us?"}, {"time": 7040, "text": "The same question, if it's so easy to be evil, not easy, if it's possible to be evil, why haven't we destroyed ourselves?"}, {"time": 7049, "text": "And your statement is from the context of history, the game is still on."}, {"time": 7054, "text": "And it's just been a few years since we've found the tools to destroy ourselves."}, {"time": 7060, "text": "And one of the challenges of our modern time that we don't often think about this pandemic kind of revealed is how soft we've gotten in terms of our deep dependence on the system."}, {"time": 7073, "text": "So somebody mentioned to me, what happens if power goes out for a day?"}, {"time": 7079, "text": "What happens if power goes out for a month?"}, {"time": 7084, "text": "Oh, for example, the person that mentioned this was a Berkeley faculty that I was talking with."}, {"time": 7090, "text": "He's an astronomer who's observing solar flares."}, {"time": 7093, "text": "And it's very possible that a solar flare, they happen all the time to different degrees."}, {"time": 7099, "text": "To knock out your cell phones."}, {"time": 7100, "text": "Yeah, to knock out the power grid for months."}, {"time": 7105, "text": "So like, just as a thought experiment, what happens if just power goes out for a week in this country?"}, {"time": 7113, "text": "Like the electromagnetic pulses and the nuclear weapons and all those kinds of things, yeah."}, {"time": 7118, "text": "But maybe that's an act of nature."}, {"time": 7121, "text": "And even just the act of nature will reveal like a little."}, {"time": 7126, "text": "The fragility of it all."}, {"time": 7128, "text": "And then the evil can emerge."}, {"time": 7130, "text": "I mean, the kind of things that might happen when power goes out, especially during a divisive time."}, {"time": 7136, "text": "Well, you won't have food."}, {"time": 7137, "text": "At baseline level, that would mean that the entire supplies chain begins to break down."}, {"time": 7144, "text": "And then you have desperation."}, {"time": 7146, "text": "And desperation opens the door to everything."}, {"time": 7149, "text": "Can I ask a dark question?"}, {"time": 7150, "text": "As opposed to the other things we've been talking about?"}, {"time": 7153, "text": "There's always a thread, a hopeful message."}, {"time": 7156, "text": "I think there'll be a hopeful message on this one too."}, {"time": 7158, "text": "You may have the wrong guess."}, {"time": 7163, "text": "If you were to bet money on the way that human civilization destroys itself, or it collapses in some way that is, where the result would be unrecognizable to us as anything akin to progress, what would you say?"}, {"time": 7182, "text": "Is it nuclear weapons?"}, {"time": 7186, "text": "Is it some societal breakdown through just more traditional kinds of war?"}, {"time": 7191, "text": "Is it engineered pandemics, nanotechnology?"}, {"time": 7194, "text": "Is it artificial intelligence?"}, {"time": 7196, "text": "Is it something we can't even expect yet?"}, {"time": 7199, "text": "Do you have a sense of how we humans will destroy ourselves?"}, {"time": 7202, "text": "Or might we live forever?"}, {"time": 7204, "text": "I think what governs my view of this thing is the ability for us to focus ourselves collectively."}, {"time": 7213, "text": "And that gives me the choice of looking at this and saying, what are the odds we will do X versus Y, right?"}, {"time": 7220, "text": "So go look at the 62 Cuban Missile Crisis, where we looked at the potential of nuclear war and we stared right in the face of that."}, {"time": 7230, "text": "To me, I consider that to be, you wanna talk about a hopeful moment?"}, {"time": 7234, "text": "That's one of the rare times in our history where I think the odds were overwhelmingly that there would be a nuclear war."}, {"time": 7243, "text": "And I'm not the super Kennedy worshiper that, I grew up in an era where he was, especially amongst people in the Democratic Party, he was almost worshiped."}, {"time": 7252, "text": "And I was never that guy, but I will say something."}, {"time": 7254, "text": "John F. Kennedy by himself probably made decisions that saved a hundred million or more lives because everyone around him thought he should be taking the road that would have led to those deaths."}, {"time": 7268, "text": "And to push back against that is, when you look at it now, I mean, again, if you were a betting person, you would have bet against that."}, {"time": 7275, "text": "And that's rare, right?"}, {"time": 7277, "text": "So when we talk about how the world will end, the fact that one person actually had that in their hands meant that it wasn't a collective decision."}, {"time": 7289, "text": "It gave, remember I said, I trust people on an individual level, but when we get together, we're more like a herd and we devolved down to the lowest common denominator."}, {"time": 7296, "text": "That was something where the higher ethical ideas of a single human being could come into play and make the decisions that influence the events."}, {"time": 7306, "text": "But when we have to act collectively, I get a lot more pessimistic."}, {"time": 7310, "text": "So take what we're doing to the planet."}, {"time": 7313, "text": "And we talk about it always now in terms of climate change, which I think is far too narrow."}, {"time": 7319, "text": "Look at, and I always get very frustrated when we talk about these arguments about, is it happening?"}, {"time": 7324, "text": "Is it human?"}, {"time": 7325, "text": "Just look at the trash, forget climate for a second."}, {"time": 7329, "text": "We are destroying the planet because we're not taking care of it and because what it would do to take care of it would require collective sacrifices that would require enough of us to say, okay."}, {"time": 7341, "text": "And we can't get enough of us to say, okay, because too many people have to be on board."}, {"time": 7347, "text": "It's not John F. Kennedy making one decision from one man."}, {"time": 7350, "text": "We have to have 85% of us or something around the world."}, {"time": 7354, "text": "Not just, you can't say we're gonna stop doing damage to the world here in the United States if China does it."}, {"time": 7361, "text": "So the amount of people that have to get on board that train is hard."}, {"time": 7366, "text": "You get pessimistic hoping for those kinds of shifts unless it's right, you know, Krypton's about to explode."}, {"time": 7374, "text": "We have, and so I think if you're talking about a gambling man's view of this, that that's gotta be the odds on favorite because it requires such a UNAM."}, {"time": 7385, "text": "I mean, and the systems maybe aren't even in place, right?"}, {"time": 7389, "text": "The fact that we would need intergovernmental bodies that are completely discredited now on board and you would have to subvert the national interests of nation states, I mean, the amount of things that have to go right in a short period of time where we don't have 600 years to figure this out, right?"}, {"time": 7407, "text": "So to me, that looks like the most likely just because the things we would have to do to avoid it seem the most unlikely."}, {"time": 7415, "text": "I believe, call me naive, in just like you said with the individual, I believe that charismatic leaders, individual leaders will save us."}, {"time": 7426, "text": "What if you don't get them all at the same time?"}, {"time": 7428, "text": "What if you get a charismatic leader in one country but under, or what if you get a charismatic leader in a country that doesn't really matter that much?"}, {"time": 7434, "text": "Well, it's a ripple effect."}, {"time": 7435, "text": "So it starts with one leader and their charisma inspires other leaders."}, {"time": 7440, "text": "So it's like one ant queen steps up and then the rest of the ant starts behaving."}, {"time": 7447, "text": "And then there's like little other spikes of leaders that emerge."}, {"time": 7451, "text": "And then that's where collaboration emerges."}, {"time": 7453, "text": "I tend to believe that like when you heat up the system and shit starts getting really chaotic, then the leader, whatever this collective intelligence that we've developed, the leader will emerge."}, {"time": 7467, "text": "Like there."}, {"time": 7468, "text": "Don't you think there's just as much of a chance though that the leader would emerge and say, the Jews are the people who did all this."}, {"time": 7474, "text": "Is that the idea that they would come up, you have a charismatic leader and he's going to come up with the rights or she is going to come up with the right solution as opposed to totally coming up with the wrong solution."}, {"time": 7485, "text": "I mean, I guess what I'm saying is you could be right, but a lot of things have to go the right way."}, {"time": 7490, "text": "But my intuition about the evolutionary process that led to the creation of human intelligence and consciousness on earth results in the power of like, if we think of it, just the love in the system versus the hate in the system, that the love is greater."}, {"time": 7507, "text": "The human kindness potential in the system is greater than the human hatred potential."}, {"time": 7518, "text": "And so the leader that is in the time when it's needed, the leader that inspires love and kindness is more likely to emerge and will have more power."}, {"time": 7530, "text": "So you have the Hitlers of the world that emerge, but they're actually in a grand scheme of history are not that impactful."}, {"time": 7540, "text": "So it's weird to say, but not that many people died in World War II."}, {"time": 7545, "text": "If you look at the full range of human history, it's up to a hundred million, whatever that is, with natural pandemics too, you can have those kinds of numbers, but it's still a percentage."}, {"time": 7560, "text": "I forget what the percentage is, maybe three, 5% of the human population on earth."}, {"time": 7564, "text": "Maybe it's a little bit focused on a different region, but it's not destructive to the entirety of human civilization."}, {"time": 7571, "text": "So I believe that the charismatic leaders, when time is needed, that do good for the world in the broader sense of good are more likely to emerge than the ones that say, kill all the Jews."}, {"time": 7589, "text": "It's possible though, and this is just, I've thought about this all of 30 seconds, but I mean, it seems."}, {"time": 7596, "text": "We're betting money here on the 21st century, who's gonna win?"}, {"time": 7599, "text": "I think maybe you've divided this into too much of a black and white dichotomy, this love and good on one side and this evil on another."}, {"time": 7608, "text": "Let me throw something that might be more in the center of that linear balancing act, self interest, which may or may not be good."}, {"time": 7619, "text": "The good version of it we call enlightened self interest."}, {"time": 7622, "text": "The bad version of it we call selfishness."}, {"time": 7625, "text": "But self interest to me seems like something more likely to impact the outcome than either love on one side or evil on the other."}, {"time": 7634, "text": "Simply a question of what's good for me or what's good for my country or what's good from my point of view or what's good for my business."}, {"time": 7642, "text": "I mean, if you tell me, and maybe I'm a coal miner or maybe I own a coal mine."}, {"time": 7649, "text": "If you say to me, we have to stop using coal because it's hurting the earth, I have a hard time disentangling that greater good question from my right now good feeding my family question, right?"}, {"time": 7663, "text": "So I think maybe it's gonna be a much more banal thing than good and evil, much more a question of we're not all going to decide at the same time that the interests that we have are aligned."}, {"time": 7678, "text": "Totally, but I mean, I've looked at Ayn Rand and objectivism and kind of really thought like, how bad or good can things go when everybody's acting selfishly?"}, {"time": 7686, "text": "But I think we're just talking two aunts here with microphones talking about."}, {"time": 7693, "text": "But like the question is when this spreads, so what do I mean by love and kindness?"}, {"time": 7703, "text": "I think it's human flourishing on earth and throughout the cosmos."}, {"time": 7708, "text": "It feels like whatever the engine that drives human beings is more likely to result in human flourishing."}, {"time": 7717, "text": "And people like Hitler are not good for human flourishing."}, {"time": 7721, "text": "So that's what I mean by good is there's a, I mean, maybe it's an intuition that kindness is an evolutionary advantage."}, {"time": 7731, "text": "I hate those terms."}, {"time": 7732, "text": "I hate to reduce stuff to evolutionary biology always, but it just seems like for us to multiply throughout the universe, it's good to be kind to each other."}, {"time": 7743, "text": "And those leaders will always emerge to save us from the Hitlers of the world that wanna kind of burn the thing down with a flamethrower."}, {"time": 7751, "text": "That's the intuition."}, {"time": 7752, "text": "But let's talk about, you brought up evolution several times."}, {"time": 7754, "text": "Let me play with that for a minute."}, {"time": 7758, "text": "I think going back to animal times, we are conditioned to deal with overwhelming threats right in front of us."}, {"time": 7765, "text": "So I have quite a bit of faith in humanity when it comes to impending doom right outside our door."}, {"time": 7773, "text": "If Krypton's about to explode, I think humanity can rouse themselves to great, and would give power to the people who needed it and be willing to make the sacrifices."}, {"time": 7784, "text": "But that's what makes, I think, the pollution slash climate change slash screwing up your environment threat so particularly insidious is it happens slowly, right?"}, {"time": 7795, "text": "It defies fight and flight mechanisms."}, {"time": 7798, "text": "It defies the natural ability we have to deal with the threat that's right on top of us."}, {"time": 7803, "text": "And it requires an amount of foresight that while some people would be fine with that, most people are too worried and understandably, I think too worried about today's threat rather than next generation's threat or whatever it might be."}, {"time": 7818, "text": "So I mean, when we talk about when you had said, what do you think the greatest threat is?"}, {"time": 7823, "text": "I think with nuclear weapons, I think could we have a nuclear war?"}, {"time": 7826, "text": "We darn right could, but I think that there's enough of an inertia where against that because people understand instinctively, if I decide to launch this attack against China and I'm India, we're gonna have 50 million dead people tomorrow."}, {"time": 7841, "text": "Whereas if you say, we're gonna have a whole planet of dead people in three generations if we don't start now, I think the evolutionary way that we have evolved mitigates maybe against that."}, {"time": 7855, "text": "In other words, I think I would be pleasantly surprised if we could pull that off."}, {"time": 7862, "text": "I don't mean to be like, I'm the sight predicting doom."}, {"time": 7865, "text": "It's fun that way."}, {"time": 7866, "text": "I think we're both, maybe I'm over the top on the love thing."}, {"time": 7869, "text": "Maybe I'm over the top on the doom."}, {"time": 7871, "text": "So it makes for a fun chat, I think."}, {"time": 7874, "text": "So one guy that I've talked to several times is slowly becoming a friend is a guy named Elon Musk."}, {"time": 7882, "text": "He's a big fan of hardcore history, especially Genghis Khan series of episodes, but really all of it, him and his girlfriend Grimes listen to it, which is."}, {"time": 7894, "text": "I know Elon."}, {"time": 7895, "text": "Yeah, you know Elon?"}, {"time": 7897, "text": "So that's like relationship goals, like listen to hardcore history on the weekend with your loved one."}, {"time": 7904, "text": "So let me, if I were to look at the guy from a perspective of human history, it feels like he will be a little speck that's remembered."}, {"time": 7916, "text": "You think about like the people, what will we remember from our time?"}, {"time": 7921, "text": "Who are the people we'll remember, whether it's the Hitlers or the Einsteins, who's going to be?"}, {"time": 7929, "text": "It's hard to predict when you're in it, but it seems like Elon will be one of those people remembered."}, {"time": 7934, "text": "And if I were to guess what he's remembered for, it's the work he's doing with SpaceX and potentially being the person."}, {"time": 7943, "text": "Now we don't know, but the being the person who launched a new era of space exploration."}, {"time": 7951, "text": "If we look centuries from now, if we are successful as human beings surviving long enough to venture out into the, you know, toward the stars."}, {"time": 7963, "text": "It's weird to ask you this."}, {"time": 7964, "text": "I don't know what your opinions are, but do you think humans will be a multi planetary species in the long arc of history?"}, {"time": 7973, "text": "Do you think Elon will be successful in his dream?"}, {"time": 7976, "text": "And he doesn't shy away from saying it this way, right?"}, {"time": 7979, "text": "He really wants us to colonize Mars first and then colonize other Earth like planets in other solar systems throughout the galaxy."}, {"time": 7991, "text": "Do you have a hope that we humans will venture out towards the stars?"}, {"time": 7996, "text": "And this actually, again, dovetails to what we were talking about earlier."}, {"time": 7999, "text": "I actually, first of all, I toured SpaceX and it's hard to get your mind around because he's doing what it took governments to do before."}, {"time": 8010, "text": "So it's incredible that we're watching individual companies and stuff doing this."}, {"time": 8014, "text": "Doing it faster and cheaper."}, {"time": 8015, "text": "Well, and pushing the envelope, right?"}, {"time": 8018, "text": "Faster than the governments at the time we're moving."}, {"time": 8022, "text": "I mean, there's a lot of people who I think, who think Elon is overrated and you have no idea, right?"}, {"time": 8029, "text": "When you go see it, you have no idea."}, {"time": 8031, "text": "But that's actually not what I'm most impressed with."}, {"time": 8035, "text": "It's Tesla I'm most impressed with."}, {"time": 8037, "text": "And the reason why is because in my mind, we just talked about what I think is the greatest threat, the environmental stuff."}, {"time": 8044, "text": "And I talked about our inability maybe all at the same time to be willing to sacrifice our self interests in order for the goal."}, {"time": 8054, "text": "And I don't wanna put words in Elon's mouth, so you can talk to him if you want to."}, {"time": 8058, "text": "But in my mind, what he's done is recognize that problem."}, {"time": 8062, "text": "And instead of building a car that's a piece of crap, but it's good for the environment so you should drive it, he's trying to create a car that if you're only motivated by your self interest, you'll buy it anyway."}, {"time": 8075, "text": "And it will help the environment and help us transition away from one of the main causes of damage."}, {"time": 8080, "text": "I mean, one of the things this pandemic and the shutdown around the world has done is show us how amazingly quickly the earth can actually rejuvenate."}, {"time": 8089, "text": "We're seeing clear skies in places species come and you would have thought it would have taken decades for some of this stuff."}, {"time": 8095, "text": "So what if to name just one major pollution source, we didn't have the pollution caused by automobiles, right?"}, {"time": 8103, "text": "And if you had said to me, Dan, what do you think the odds of us transitioning away from that were 10 years ago, I would have said, well, people aren't gonna do it because it's inefficient, it's this, it's that, nobody wants to, but what if you created a vehicle that was superior in every way so that if you were just a self oriented consumer, you'd buy it because you wanted that car."}, {"time": 8121, "text": "That's the best way to get around that problem of people not wanting to, I think he's identified that."}, {"time": 8128, "text": "And as he's told me before, when the last time a car company was created that actually, blah, blah, blah, he's right."}, {"time": 8136, "text": "And so I happen to feel that even though he's pushing the envelope on the space thing, I think somebody else would have done that someday."}, {"time": 8143, "text": "I'm not sure because of the various things he's mentioned, how difficult it is to start there, I'm not sure that the industries that create vehicles for us would have gone where he's going to lead them if he didn't force them there through consumer demand by making a better car that people wanted anyway."}, {"time": 8160, "text": "They'll follow, they'll copy, they'll do all those things."}, {"time": 8163, "text": "And yet who was gonna do that?"}, {"time": 8166, "text": "So I hope he doesn't hate me for saying this, but I happen to think the Tesla idea may alleviate some of the need to get off this planet because the planet's being destroyed, right?"}, {"time": 8177, "text": "And we're gonna colonize Mars probably anyway if we live long enough."}, {"time": 8180, "text": "And I think the Tesla idea, not just Elon's version, but ones that follow from other people is the best chance of making sure we're around long enough to see Mars colonized."}, {"time": 8224, "text": "So it gives me hope as an individual that I can build something that can actually have impact that counteracts the Stalins and the Hitlers and all the threats that face that human civilization faces, that an individual has that power."}, {"time": 8246, "text": "I didn't believe that the individual has that power in the halls of government."}, {"time": 8252, "text": "Like, I don't feel like any one presidential candidate can rise up and help the world, unite the world."}, {"time": 8258, "text": "It feels like from everything I've seen and you're right with Tesla, it can bring the world together to do good."}, {"time": 8269, "text": "That's a really powerful mechanism of whatever you say about capitalism, that you can build companies that start, it starts with a single individual."}, {"time": 8279, "text": "Of course, there's a collective that grows around that, but the leadership of a single individual, their ideas, their dreams, their vision can catalyze something that takes over the world and does good for the entire world."}, {"time": 8294, "text": "But if I think, but again, I think the genius of the idea is that it doesn't require us to go head to head with human nature, right?"}, {"time": 8303, "text": "He's actually built human nature into the idea by basically saying, I'm not asking you to be an environmental activist."}, {"time": 8311, "text": "I'm not asking you to sacrifice to make it."}, {"time": 8313, "text": "I'm gonna sell you a car you're going to like better."}, {"time": 8316, "text": "And by buying it, you'll help the environment."}, {"time": 8318, "text": "That takes into account our foibles as a species and actually leverages that to work for the greater good."}, {"time": 8326, "text": "And that's the sort of thing that does turn off my little doom caster cynicism thing a little bit because you're actually hitting us where we live, right?"}, {"time": 8335, "text": "You're not, you can take somebody who doesn't even believe the environment's a problem, but they want a Tesla."}, {"time": 8340, "text": "So they're inadvertently helping anyway."}, {"time": 8343, "text": "I think that's the genius of the idea."}, {"time": 8345, "text": "Yeah, and I'm telling you, that's one way to make love a much more efficient mechanism of change than hate."}, {"time": 8353, "text": "Making it in your self interest to love somebody."}, {"time": 8355, "text": "Making it in your self interest, creating a product that leads to more love than hate."}, {"time": 8361, "text": "You're gonna wanna love your neighbor because you're gonna make a fortune."}, {"time": 8364, "text": "Right, okay, I get it."}, {"time": 8366, "text": "That's why he said."}, {"time": 8366, "text": "All right, I'm on board."}, {"time": 8367, "text": "That's why Elon said love is the answer."}, {"time": 8369, "text": "That's, I think, exactly what he meant."}, {"time": 8373, "text": "Okay, let's try something difficult."}, {"time": 8375, "text": "You've recorded an episode of Steering Into the Iceberg on your Common Sense program."}, {"time": 8384, "text": "That has started a lot of conversations."}, {"time": 8388, "text": "It's quite moving, it was quite haunting."}, {"time": 8391, "text": "Got me a lot of angry emails."}, {"time": 8395, "text": "I did something I haven't done in 30 years."}, {"time": 8397, "text": "I endorsed a political candidate from one of the two main parties and there were a lot of disillusioned people because of that."}, {"time": 8402, "text": "I guess I didn't hear it as an endorsement."}, {"time": 8405, "text": "I just heard it as the similar flavor of conversation as you have in hardcore history."}, {"time": 8414, "text": "It's almost the speaking about modern times in the same voice as you speak about when you talk about history."}, {"time": 8423, "text": "So it was just a little bit of a haunting view of the world today."}, {"time": 8430, "text": "I know we were just wearing our doom caster."}, {"time": 8433, "text": "Let me put that right back on, are you?"}, {"time": 8438, "text": "I like the term doom caster."}, {"time": 8444, "text": "How do we get love to win?"}, {"time": 8447, "text": "What's the way out of this?"}, {"time": 8449, "text": "Is there some hopeful line that we can walk to avoid something, and I hate to use the terminology, but something that looks like a civil war, not necessarily a war of force, but a division to a level where it doesn't any longer feel like a United States of America with an emphasis on United."}, {"time": 8480, "text": "Is there a way out?"}, {"time": 8483, "text": "I read a book a while back."}, {"time": 8484, "text": "I want to say George Friedman, the Stratfor guy wrote it."}, {"time": 8488, "text": "It was something called The Next Hundred Years, I think it was called."}, {"time": 8491, "text": "And I remember thinking, I didn't agree with any of it."}, {"time": 8495, "text": "And one of the things I think he said in the book was that the United States was going to break up."}, {"time": 8499, "text": "I'm going from memory here."}, {"time": 8500, "text": "He might not have said that at all, but something was stuck in my memory about that."}, {"time": 8502, "text": "And I remember thinking, but I think some of the arguments were connected to the differences that we had and the fact that those differences are being exploited."}, {"time": 8515, "text": "So we talked about media earlier and the lack of truth and everything."}, {"time": 8518, "text": "We have a media climate that is incentivized to take the wedges in our society and make them wider."}, {"time": 8528, "text": "And there's no countervailing force to do the opposite or to help."}, {"time": 8533, "text": "So there was a famous memo from a group called Project for a New American Century."}, {"time": 8541, "text": "And they took it down, but the Wayback Machine online still has it."}, {"time": 8544, "text": "And it happened before 9 11, spawned all kinds of conspiracy theories because it was saying something to the effect of, and I'm really paraphrasing here, but you know that the United States needs another Pearl Harbor type event because those galvanize a country that without those kinds of events periodically is naturally geared towards pulling itself apart."}, {"time": 8565, "text": "And it's those periodic events that act as the countervailing force that otherwise is not there."}, {"time": 8572, "text": "If that's true, then we are naturally inclined towards pulling ourselves apart."}, {"time": 8577, "text": "So to have a media environment that makes money off widening those divisions, which we do."}, {"time": 8587, "text": "I mean, I was in talk radio and it has those people, the people that used to scream at me cause I wouldn't do it."}, {"time": 8593, "text": "But I mean, we would have these terrible conversations after every broadcast where I'd be in there with the program director and they're yelling at me about heat."}, {"time": 8601, "text": "Heat was the word they create more heat."}, {"time": 8602, "text": "Well, what is heat, right?"}, {"time": 8604, "text": "Heat is division, right?"}, {"time": 8605, "text": "And they want the heat, not because they're political, they're not Republicans or Democrats either."}, {"time": 8612, "text": "We want listeners and we want engagement and involvement."}, {"time": 8616, "text": "And because of the constructs of the format, you don't have a lot of time to get it."}, {"time": 8620, "text": "So you can't have me giving you like on a podcast an hour and a half or two hours where we build a logical argument and you're with me the whole way, your audience is changing every 15 minutes."}, {"time": 8631, "text": "So whatever points you make to create interest and intrigue and engagement have to be knee jerk right now."}, {"time": 8638, "text": "Things, they told me once that the audience has to know where you stand on every single issue within five minutes of turning on your show."}, {"time": 8647, "text": "In other words, you have to be part of a linear set of political beliefs so that if you feel A about subject A, then you must feel D about subject D. And I don't even need to hear your opinion on it cause if you feel that way about A, you're gonna feel that way about D. This is a system that is designed to pull us apart for profit, but not because they wanna pull us apart, right?"}, {"time": 8669, "text": "It's a byproduct of the profit."}, {"time": 8672, "text": "That's one little example of 50 examples in our society that work in that same fashion."}, {"time": 8704, "text": "So in answer to your question about civil wars, we can't have the same kind of civil war because we don't have a geographical division that's as clear cut as the one we had before, right?"}, {"time": 8713, "text": "You had a basically north south line and some border states."}, {"time": 8716, "text": "It was set up for that kind of a split."}, {"time": 8718, "text": "Now we're divided within communities, within families, within gerrymandered voting districts and precincts, right?"}, {"time": 8725, "text": "So you can't disengage."}, {"time": 8728, "text": "We're stuck with each other."}, {"time": 8730, "text": "So if there's a civil war now, for lack of a better word, what it might seem like is the late 1960s, early 1970s, where you had the bombings and let's call it domestic terrorism and things like that, because that would seem to be something that once again, you don't even need a large chunk of the country pulling apart."}, {"time": 8752, "text": "10% of people who think it's the end times can do the damage."}, {"time": 8757, "text": "Just like we talked about terrorism before and a can of gas and a big lighter, I've lived in a bunch of places and I won't give anybody ideas where a can of gas and a big lighter would take a thousand houses down before you could blink."}, {"time": 8772, "text": "That terrorist doesn't have to be from the Middle East, doesn't have to have some sort of a fundamentalist or religious agenda."}, {"time": 8778, "text": "It could just be somebody really pissed off about the election results."}, {"time": 8782, "text": "So once again, if we're playing an odds game here, everybody has to behave for this to work right."}, {"time": 8788, "text": "Only a few people have to misbehave for this thing to go sideways."}, {"time": 8791, "text": "And remember, for every action, there is an equal and opposite reaction."}, {"time": 8796, "text": "So you don't even have to have those people doing all these things."}, {"time": 8799, "text": "All they have to do is start a tit for tat retribution cycle."}, {"time": 8803, "text": "And there's an escalation."}, {"time": 8805, "text": "And it creates a momentum of its own, which leads fundamentally, if you follow the chain of events down there to some form of dictatorial government as the only way to create stability, right?"}, {"time": 8817, "text": "You want to destroy the Republic and have a dictator, that's how you do."}, {"time": 8820, "text": "And there are parallels to Nazi Germany, the burning of the Reichstag, blah, blah, blah."}, {"time": 8825, "text": "I'm the doom caster again, aren't I?"}, {"time": 8827, "text": "And some of it could be manufactured by those seeking authoritarian power."}, {"time": 8832, "text": "Absolutely, like the Reichstag fire was or the Polish soldiers that fired over the border before the invasion in 1939."}, {"time": 8840, "text": "To fight the devil's advocate with an angel's advocate, I would say just as our conversation about Elon, it feels like individuals have power to unite us, to be that force of unity."}, {"time": 8853, "text": "So you mentioned the media."}, {"time": 8855, "text": "I think you're one of the great podcasters in history."}, {"time": 8860, "text": "Joe Rogan is like a long form, whatever."}, {"time": 8864, "text": "It's not podcasting, it's actually whatever the, yeah."}, {"time": 8867, "text": "Very infrequent is what it is, no matter what it is."}, {"time": 8870, "text": "But the basic process of it is you go deep and you stay deep and the listener stays with you for a long time."}, {"time": 8877, "text": "So I'm just looking at the numbers, like we're almost three hours in."}, {"time": 8885, "text": "And from previous episodes, I can tell you that about 300,000 people are still listening to the sound of our voice three hours in."}, {"time": 8895, "text": "So usually it's 300 to 500,000 people listen and they tune out."}, {"time": 8899, "text": "Congratulations, by the way, that's wonderful."}, {"time": 8900, "text": "Joe Rogan is like 10 times that."}, {"time": 8903, "text": "And so he has power to unite."}, {"time": 8910, "text": "You have power to unite."}, {"time": 8911, "text": "There's a few people with voices that it feels like they have power to unite."}, {"time": 8917, "text": "Even if you quote unquote endorse a candidate and so on, there's still, it feels to me that speaking of, I don't wanna keep saying love, but it's love and maybe unity more practically speaking that like sanity, that like respect for those you don't agree with or don't understand."}, {"time": 8944, "text": "So empathy, just a few voices of those can help us avoid the really importantly, not avoid the singular events, like you said, of somebody starting a fire and so on, but avoid the escalation of it."}, {"time": 8961, "text": "The preparedness of the populace to escalate those events, to turn a singular event and a single riot or a shooting or like even something much more dramatic than that, to turn that into something that creates like ripples that grow as opposed to ripples that fade away."}, {"time": 8983, "text": "And so like, I would like to put responsibility on somebody like you and on me in some small way."}, {"time": 8991, "text": "And Joe, being cognizant of the fact that a lot of very destructive things might happen in November."}, {"time": 9001, "text": "And a few voices can save us is the feeling I have."}, {"time": 9005, "text": "Not by saying who you should vote for or any of that kind of stuff, but really by being the voice of calm that like calms the seas from or whatever the analogy is from boiling up."}, {"time": 9022, "text": "Because I truly am worried about, this is the first time this year when I, I sometimes, I somehow have felt that the American project will go on forever."}, {"time": 9035, "text": "When I came to this country, I just believed, and I still think I'm young, but like, I have a dream of creating a company that will do a lot of good for the world."}, {"time": 9047, "text": "And I thought that America is the beacon of hope for the world and the ideas of freedom, but also the idea of empowering companies that can do some good for the world."}, {"time": 9058, "text": "And I'm just worried about this America that filled me, a kid that came from, our family came from nothing and from Russia as it was, Soviet Union as it was, to be able to do anything in this new country."}, {"time": 9075, "text": "I'm just worried about it."}, {"time": 9076, "text": "And it feels like a few people can still keep this project going."}, {"time": 9081, "text": "Like people like Elon, people like Joe."}, {"time": 9085, "text": "Is there, do you have a bit of that hope?"}, {"time": 9094, "text": "I'm watching this experiment with social media right now."}, {"time": 9098, "text": "And I don't even mean social media, really expand that out to, I mean, I feel like we're all guinea pigs right now, watching, you know, I have two kids and just watching, and there's a three year space between the two of them, one's 18, the other's 15."}, {"time": 9110, "text": "And just, you know, when I was a kid, a person who was 18 and 15 would not be that different, just three years difference, more maturity."}, {"time": 9118, "text": "But their life experiences, you would easily classify those two people as being in the same generation."}, {"time": 9147, "text": "Now, as that relates to your question, the most upsetting part about all that is reading how people treat each other online."}, {"time": 9156, "text": "And you know, there's lots of theories about this, the fact that some of it is just for trolling laughs, that some of it is just people are not interacting face to face, so they feel free to treat each other that way."}, {"time": 9166, "text": "And I, of course, I'm trying to figure out how, if this is how we have always been as people, right?"}, {"time": 9175, "text": "We've always been this way, but we've never had the means to post our feelings publicly about it, or if the environment and the social media and everything else has provided a change and changed us into something else."}, {"time": 9189, "text": "Either way, when one reads how we treat one another and the horrible things we say about one another online, which seems like it shouldn't be that big of deal, they're just words, but they have a cumulative effect."}, {"time": 9203, "text": "I mean, when you, I was reading Meghan Markle, who I don't know a lot about, because it's too much of the pop side of culture for me to pay lip, but I read a story the other day where she was talking about the abuse she took online and how incredibly overwhelming it was and how many people were doing it."}, {"time": 9220, "text": "And you think to yourself, okay, this is something that people who are in positions of what you were discussing earlier never had to deal with."}, {"time": 9228, "text": "Let me ask you something, and boy, this is the ultimate doomcaster thing of all time to say."}, {"time": 9233, "text": "When you think of historical figures that push things like love and peace and creating bridges between enemies, when you think of what happened to those people, first of all, they're very dangerous."}, {"time": 9250, "text": "Every society in the world has a better time, easier time dealing with violence and things like that than they do nonviolence."}, {"time": 9256, "text": "Nonviolence is really difficult for governments to deal with, for example."}, {"time": 9260, "text": "What happens to Gandhi and Jesus and Martin Luther King?"}, {"time": 9265, "text": "And you think about all those people, right?"}, {"time": 9267, "text": "When they're that, it's ironic, isn't it, that these people who push for peaceful solutions are so often killed, but it's because they're effective."}, {"time": 9276, "text": "And when they're killed, the effectiveness is diminished."}, {"time": 9280, "text": "Why are they killed?"}, {"time": 9281, "text": "Because they're effective, and the only way to stop them is to eliminate them, because they're charismatic leaders who don't come around every day, and if you eliminate them from the scene, the odds are you're not gonna get another one for a while."}, {"time": 9294, "text": "I guess what I'm saying is the very things you're talking about, which would have the effect you think it would, right?"}, {"time": 9298, "text": "They would destabilize systems in a way that most of us would consider positive, but those systems have a way of protecting themselves, right?"}, {"time": 9307, "text": "And so I feel like history shows, see, history's pretty pessimistic, I think, by and large."}, {"time": 9314, "text": "If only because we can find so many examples that just sound pessimistic."}, {"time": 9317, "text": "But I feel like people who are dangerous to the way things are tend to be removed."}, {"time": 9324, "text": "Yes, but there's two things to say."}, {"time": 9326, "text": "I feel like you're right, that history, I feel like the ripples that love leaves in history are less obvious to detect, but are actually more transformational."}, {"time": 9339, "text": "Like in this."}, {"time": 9339, "text": "Well, one could make a case about, I mean, if you wanna talk about the long term value of a Jesus, a Gandhi, but yeah, yes, those people's ripples are still affecting people today."}, {"time": 9349, "text": "And that's, you feel those ripples through the general improvement of the quality of life that we see throughout the generations."}, {"time": 9356, "text": "Like you feel the ripples through the growth."}, {"time": 9358, "text": "Yeah, okay, I'll go along with you on that, okay."}, {"time": 9359, "text": "But I would, even if that's not true, I tend to believe that, and by the way, the company that I'm working on as a competitor is exactly attacking this, which is a competitor to Twitter."}, {"time": 9375, "text": "I think I can build a better Twitter as a first step."}, {"time": 9377, "text": "There's a long story in there."}, {"time": 9378, "text": "I think a three year old child could build a better, and this is not to denigrate you, I'm sure yours would be better than a three year old, but Twitter is so, and listen, Facebook too, they're really awful platforms for intellectual discussion and meaningful discussion, and I'm on it."}, {"time": 9393, "text": "So let me just say, I'm part of the problem."}, {"time": 9394, "text": "We're new to this, so it wasn't obvious at the time how to do it, it's now, and now a three year old can do it."}, {"time": 9401, "text": "I tend to believe that we live in a time where the tools that people that are interested in providing love, like the weapons of love are much more powerful."}, {"time": 9414, "text": "So like the one nice thing about technology is it allows anyone to build a company that's more powerful than any government."}, {"time": 9424, "text": "So that could be very destructive, but it could be also very positive."}, {"time": 9429, "text": "And that's, I tend to believe that somebody like Elon that wants to do good for the world, somebody like me and many like me could have more power than any one government."}, {"time": 9440, "text": "And by power, I mean the power to effect change, which is different from Gandhi."}, {"time": 9445, "text": "What do you do with government, and I don't mean to interrupt you, but I'll forget my train of thought, I'm getting old."}, {"time": 9448, "text": "But I mean, how do you deal with the fact that already governments who are afraid of this are walling off their own internet systems as a way to create firewalls simply to prevent you from doing what you're talking about?"}, {"time": 9462, "text": "In other words, there's an old line that if voting really changed anything, they'd never allow it."}, {"time": 9466, "text": "If love through a modern day successor to Twitter would really do what you want it to do, and this would destabilize governments, do you think that governments would take countermeasures to squash that love before it got too dangerous?"}, {"time": 9483, "text": "There's several answers."}, {"time": 9484, "text": "One, first of all, I don't actually, to push back on something you said earlier, I don't think love is as much of an enemy of the state as one would think."}, {"time": 9494, "text": "Different states have different views."}, {"time": 9500, "text": "I think the states want power, and I don't always think that love is in tension with power."}, {"time": 9513, "text": "I think it's not just about love, it's about rationality, it's reason, it's empathy, all of those things."}, {"time": 9519, "text": "I don't necessarily think there always have to be by definition in conflict with each other."}, {"time": 9525, "text": "So that's one sense is I feel like basically you can Trojan horse love into behind, but you have to be good at it."}, {"time": 9536, "text": "This is the thing, is you have to be conscious of the way these states think."}, {"time": 9541, "text": "So the fact that China bans certain services and so on, that means the companies weren't eloquent, whoever the companies are, weren't actually good at infiltrating."}, {"time": 9556, "text": "I think, isn't that a song, like love is a battlefield?"}, {"time": 9559, "text": "I think it's all a cap editor."}, {"time": 9562, "text": "It's all a game, and you have to be good at the game."}, {"time": 9565, "text": "And just like Elon, we said with Tesla and saving the environment."}, {"time": 9572, "text": "I mean, that's not just by getting on a stage and saying it's important to save the environment, is by building a product that people can't help but love and then convincing Hollywood stars to love it."}, {"time": 9586, "text": "Like there's a game to be played."}, {"time": 9588, "text": "Okay, so let me build on that because I think there's a way to see this."}, {"time": 9593, "text": "And so it has to do with a story about the 1960s."}, {"time": 9597, "text": "In the vast scheme of things, the 1960s looks like a revival of neo romantic ideas, right?"}, {"time": 9603, "text": "I had a buddy of mine several years, well, two decades older than I was who was in the 60s, went to the protest, did all those kinds of things."}, {"time": 9611, "text": "And we were talking about it and I was romanticizing it."}, {"time": 9614, "text": "He said, don't romanticize it."}, {"time": 9615, "text": "He goes, let me tell you, most of the people that went to those protests and did all those things, all they were there was to meet girls and have a good time."}, {"time": 9621, "text": "And it wasn't so, but it became in vogue to have all, in other words, let's talk about your empathy and love."}, {"time": 9632, "text": "You're never gonna, in my opinion, grab that great mass of people that are only in it for their interest in whatever."}, {"time": 9638, "text": "But if meeting girls for a young teenage guy requires you to feign empathy, requires you to read deeper subjects because that's what people are into, you can almost, as a silly way to be trendy, you could make maybe empathy trendy, love trendy, solutions that are the opposite of that, the kind of things that people inherently will not put up with."}, {"time": 9667, "text": "In other words, the possibility exists to change the zeitgeist and reorient it in a way that even if most of the people aren't serious about it, the results are the same."}, {"time": 9681, "text": "Okay, so we've found a meeting of the moments."}, {"time": 9684, "text": "Creating incentives that encourage the best and the most beautiful aspects of human nature."}, {"time": 9692, "text": "Even against our will."}, {"time": 9693, "text": "It all boils down to meeting girls and boys."}, {"time": 9697, "text": "Once again, you're getting to the bottom of the evolutionary motivations and you're always on safe ground when you do that."}, {"time": 9703, "text": "That's a little difficult for me."}, {"time": 9706, "text": "And I'm sure it's actually difficult for you to listen to me say complimenting you, but it's difficult for both of us, okay?"}, {"time": 9717, "text": "So, but you and I, as I mentioned to you, I think off mic, been friends for a long time."}, {"time": 9723, "text": "It's just been one way."}, {"time": 9725, "text": "It's two way now."}, {"time": 9728, "text": "So that's the beauty of podcasting."}, {"time": 9730, "text": "Now, just been fortunate enough with this particular podcast that I see it in people's eyes when they meet me, that they've been friends with me for a few years now."}, {"time": 9740, "text": "And we become fast friends actually after we start talking."}, {"time": 9745, "text": "But it's one way in the vet in that first moment."}, {"time": 9750, "text": "You know, like there's something about the especially hardcore history that, you know, I do some crazy challenges and running and stuff."}, {"time": 9757, "text": "I remember in particular, probably don't have time."}, {"time": 9760, "text": "One of my favorite episodes, the painful tainment one."}, {"time": 9764, "text": "Some people hate that episode."}, {"time": 9766, "text": "Because it's too real."}, {"time": 9767, "text": "Yeah, they can't listen to it."}, {"time": 9769, "text": "It's my darkest one."}, {"time": 9770, "text": "We wanted to set a baseline."}, {"time": 9771, "text": "That's the baseline."}, {"time": 9773, "text": "But I remember listening to that when I ran 22 miles for me, that was a long distance."}, {"time": 9778, "text": "Holy cow, that's painful tainment right there."}, {"time": 9780, "text": "Yeah, and it just pulls you in."}, {"time": 9783, "text": "There's something so powerful about this particular creation that's bigger than you actually, that you've created."}, {"time": 9793, "text": "I think anything that is successful like that, like Elon's stuff too, it becomes bigger than you."}, {"time": 9797, "text": "And that's what you're hoping for, right?"}, {"time": 9799, "text": "Didn't mean to interrupt you, I apologize."}, {"time": 9800, "text": "I guess a question I have, if you look in the mirror, but you also look at me, what advice would you give to yourself and to me and to other podcasters, maybe to Joe Rogan, about this journey that we're on?"}, {"time": 9820, "text": "I feel like it's something special."}, {"time": 9821, "text": "I'm not sure exactly what's happening."}, {"time": 9824, "text": "But it feels like podcasting is special."}, {"time": 9828, "text": "What advice, and I'm relatively new to it, what advice do you have for people that are carrying this flame and traveling this journey?"}, {"time": 9839, "text": "Well, I'm often asked for advice by new podcasters, people just starting out."}, {"time": 9844, "text": "And so I have sort of a tried and true list of do's and don'ts."}, {"time": 9851, "text": "But I don't have advice or suggestions for you or for Joe."}, {"time": 9858, "text": "Joe doesn't need anything from me."}, {"time": 9859, "text": "Joe's figured it out, right?"}, {"time": 9861, "text": "I mean, he hasn't yet."}, {"time": 9862, "text": "He's still a confused kid, curious about the world."}, {"time": 9865, "text": "But that's the genius of it."}, {"time": 9866, "text": "That's what makes it work, right?"}, {"time": 9868, "text": "That's what Joe's brand is, right?"}, {"time": 9871, "text": "I guess what I'm saying is, by the time you reach the stage that you're at, or Joe's at, they don't need it."}, {"time": 9878, "text": "They have figured this out."}, {"time": 9879, "text": "The people that sometimes need help are brand new people trying to figure out what do I do with my first show and how do I talk into them?"}, {"time": 9884, "text": "And I have standard answers for that."}, {"time": 9887, "text": "But you found your niche."}, {"time": 9888, "text": "I mean, you don't need me to tell you what to do."}, {"time": 9891, "text": "As a matter of fact, I might ask you questions about how you do what you do, right?"}, {"time": 9895, "text": "Well, I guess there's specific things like we were talking offline about monetization."}, {"time": 9901, "text": "That's a fascinating one."}, {"time": 9903, "text": "Very difficult as an independent, yeah."}, {"time": 9905, "text": "And one of the things that Joe is facing with, I don't know if you're paying attention, but he joined Spotify with a $100 million deal for going exclusive on their platform."}, {"time": 9918, "text": "The idea of exclusivity that, one, I don't give a damn about money personally, but I'm single, and I like living in a shitty place."}, {"time": 9926, "text": "So I enjoy, so I guess it makes it easy."}, {"time": 9930, "text": "You get the freedom, right, to not care, yeah."}, {"time": 9932, "text": "Freedom."}, {"time": 9934, "text": "Not saving for anybody's college."}, {"time": 9937, "text": "Okay, so on that point, but I also, okay, maybe it's romanticization, but I feel like podcasting is pirate radio."}, {"time": 9946, "text": "And when I first heard about Spotify partnering up with Joe, I was like, you know, fuck the man."}, {"time": 9953, "text": "I said, I even, I drafted a few tweets and so on, just like attacking Spotify, then I calmed myself down that you can't lock up this special thing we have."}, {"time": 9964, "text": "But then I realized that maybe that these are vehicles for just reaching more people and actually respecting podcasters more and so on."}, {"time": 9975, "text": "So that's what I mean by it's unclear what the journey is because you also serve as beacon for, now there's like millions, one million plus podcasters."}, {"time": 9989, "text": "I wonder what the journey is."}, {"time": 9991, "text": "Do you have a sense, are you romantic in the same kind of way in feeling that, because you have a roots in radio too."}, {"time": 10001, "text": "Do you feel that podcasting is pirate radio or is the Spotify thing one possible avenue?"}, {"time": 10008, "text": "Are you nervous about Joe as a fan, as a friend of Joe or is this a good thing for us?"}, {"time": 10015, "text": "So my history of how I got involved in podcasting is interesting."}, {"time": 10021, "text": "I was in radio and then I started a company back in the era where the dot com boom was happening and everybody was being bought up and it just seemed like a great idea, right?"}, {"time": 10032, "text": "I did it with six other people and the whole goal of the company was, we had to invent the term."}, {"time": 10039, "text": "I'm sure everybody, there's other places that invented it at the same time."}, {"time": 10042, "text": "But what we were pitching to investors was something called amateur content."}, {"time": 10046, "text": "So this is before YouTube, before podcasting, before all this stuff."}, {"time": 10050, "text": "And my job was to be the evangelist."}, {"time": 10054, "text": "And I would go to these people and talk and sing the praises of all the ways that amateur content was gonna be great."}, {"time": 10062, "text": "And I never got a bite."}, {"time": 10065, "text": "And they all told me the same thing."}, {"time": 10066, "text": "This isn't gonna take off cause anybody who's good is already gonna be making money at this."}, {"time": 10071, "text": "And I kept saying, forget that."}, {"time": 10073, "text": "We're talking about scale here."}, {"time": 10075, "text": "If you have millions of pieces of content being made every week, a small percentage is gonna be good no matter what, right?"}, {"time": 10081, "text": "16 year olds will know what other 16 year olds like."}, {"time": 10083, "text": "I kept pushing this nobody bit."}, {"time": 10086, "text": "But the podcast grew out of that because if you're talking about amateur content in 1999, well then you're already, you're ahead of the game in terms of not seeing where it's gonna go financially but seeing where it's going to go technologically."}, {"time": 10103, "text": "And so when we started the podcast in 2005 and it was the political one, not hardcore history, which was an outgrowth of the old radio show, we didn't have any financial ideas."}, {"time": 10114, "text": "We were simply trying to get our handle on the technology and how you distribute it to people and all that."}, {"time": 10118, "text": "And it was years later that we tried to figure out, okay, how can we get enough money to just support us while we're doing this?"}, {"time": 10125, "text": "And the cheap and the easy way was just to ask listeners to donate like a PBS kind of model."}, {"time": 10129, "text": "And that was the original model."}, {"time": 10132, "text": "So then once we started down that, we figured out other models and there's the advertising thing and that we sell the old shows."}, {"time": 10138, "text": "And so all these became ways for us to support ourselves."}, {"time": 10143, "text": "But as podcasting matured and as more operating systems developed and phones were developed and all these kinds of things, every one of those developments, which actually made it easier for people to get the podcast actually made it more complex to make money off of them."}, {"time": 10162, "text": "So while our audience was building, the amount of time and effort we had to put into the monetization side began to skyrocket."}, {"time": 10169, "text": "So to get back to your Spotify question, to use just one example, there's a lot of people who are doing similar things."}, {"time": 10176, "text": "In this day and age, we used to just sell MP3 files."}, {"time": 10179, "text": "And all you had to have was an MP3 player, it's cheap and dirty."}, {"time": 10182, "text": "Now, every time there's an OS upgrade, something breaks for us."}, {"time": 10186, "text": "So we're having, I mean, my choices are at this point to start hiring staff, more staff, and then be a human resources manager."}, {"time": 10194, "text": "I mean, the pirate radio side of this was the pirate radio side of this because you didn't need anybody, but you know, you or you and another, I mean, you could just do this lean and mean, and it's becoming hard to do it lean and mean now."}, {"time": 10205, "text": "So if somebody like a Spotify comes in and says, hey, we'll handle that stuff for you."}, {"time": 10210, "text": "In the past, I would just say, F off, we don't need you, I don't mind."}, {"time": 10215, "text": "And I definitely am not making what we could make on this, but what we would have to do to make that is onerous to me."}, {"time": 10222, "text": "But it's becoming onerous to me day to day anyway."}, {"time": 10225, "text": "And so if somebody were to come in and say, hey, we'll pick that up for you, we will not interfere with your content at all, we won't, and in my case, you can't say, we need to show a month because that ain't happening, right?"}, {"time": 10236, "text": "So I mean, everybody's design is different, right?"}, {"time": 10240, "text": "So it doesn't, you know, there's not one size fits all, but I guess as a long time pirate podcaster, we've been looking to partner with people, but nobody's right for us to partner with."}, {"time": 10251, "text": "I mean, so I'm always looking for ways to take that side of it off my plate because I'm not interested in that side."}, {"time": 10259, "text": "All I wanna do is the shows, and it's really at this point, you shouldn't call yourself an artist because that's something to be decided by others."}, {"time": 10268, "text": "But I mean, we're trying to do art and there's something very satisfying in that."}, {"time": 10275, "text": "But the part that I can't stand is the increasing amount of time the monetization question takes upon us."}, {"time": 10282, "text": "So there's a case to be made, I guess is what I'm saying, that if a partnership with some outside firm enhances your ability to do the art without disenhancing your ability to do the art, it's, the word I'm looking for here is it's enticing."}, {"time": 10302, "text": "I don't like big companies."}, {"time": 10304, "text": "So I'm afraid of whatever strings might come with that."}, {"time": 10309, "text": "And if I'm Joe Rogan and I'm talking about subjects that can make public companies a little nervous, I would certainly be careful."}, {"time": 10317, "text": "But at the same time, people who are not in this game don't understand the problems that literally, I mean, just all the operating systems, all the podcatchers, every time some new podcatcher comes up, makes it easier to get the podcast, that's something we have to account for on the back end."}, {"time": 10334, "text": "And I'm not exactly the technological wizard of all time."}, {"time": 10337, "text": "So I think it is maybe, maybe the short answer is, is that as the medium develops, it's becoming something that you have to consider, not because you wanna sell out, but because you wanna keep going."}, {"time": 10350, "text": "And it's becoming harder and harder to be pirate like in this environment."}, {"time": 10355, "text": "The thing that convinced me, especially inside Spotify, is that they understand, so if you walk into this whole thing with some skepticism, as you're saying, of big companies, then it works because Spotify understands the magic that makes podcasting, or they appear to in part, at least they understand enough to respect Joe Rogan."}, {"time": 10380, "text": "And despite what, I don't know if you, so there's the internet and there's people with opinions on the internet."}, {"time": 10386, "text": "I've not heard about that."}, {"time": 10387, "text": "And they have opinions about Joe and Spotify."}, {"time": 10391, "text": "But the reality is, there's two things in private conversation with Joe, and in general, there's two important things."}, {"time": 10399, "text": "One, Spotify literally doesn't tell Joe anything."}, {"time": 10402, "text": "Like all the people that think that Spotify is somehow pushing Joe in this direction."}, {"time": 10408, "text": "It's a contractual, didn't he insist upon that?"}, {"time": 10410, "text": "It's in the contract."}, {"time": 10411, "text": "But also, companies have a way of, even with the contract."}, {"time": 10414, "text": "They sure do."}, {"time": 10416, "text": "To be marketing people, hey, I know we're not forcing you."}, {"time": 10419, "text": "I hate that."}, {"time": 10421, "text": "Yeah, I'm with you."}, {"time": 10422, "text": "You and Joe are the same, and Spotify is smart enough not to send a single email of that kind."}, {"time": 10428, "text": "That's really smart."}, {"time": 10429, "text": "And they leave them be."}, {"time": 10431, "text": "There is meetings inside Spotify that people complain, but those meetings never reach Joe."}, {"time": 10438, "text": "That's like company stuff."}, {"time": 10440, "text": "And the idea that Spotify is different than pirate radio, the difficult thing about podcasting is nobody gives a damn about your podcast."}, {"time": 10450, "text": "You're alone in this."}, {"time": 10451, "text": "I mean, there's fans and stuff, but nobody."}, {"time": 10454, "text": "Nobody's looking out for you."}, {"time": 10455, "text": "And the nice thing about Spotify is they want Joe's podcast to succeed even more."}, {"time": 10461, "text": "That's what Joe talked about is that's the difference between YouTube and Spotify."}, {"time": 10467, "text": "Spotify wants to be the Netflix of podcasting."}, {"time": 10470, "text": "And they, like what Netflix does is they don't want to control you in any way, but they want to create a platform where you can flourish."}, {"time": 10481, "text": "Because your interests are aligned."}, {"time": 10482, "text": "Interests are aligned."}, {"time": 10483, "text": "So let me bring up something that, let's make a distinction because not all companies who do this are the same."}, {"time": 10490, "text": "And you brought up YouTube and Spotify, but to me, YouTube is at least more like Spotify than some of these smaller."}, {"time": 10496, "text": "The term is walled garden, right?"}, {"time": 10498, "text": "You've heard the term walled garden?"}, {"time": 10500, "text": "So I've been around podcasting so long now that I've seen rounds of consolidation over the years and they come in waves and all of a sudden, so you'll get, and I'm not going to mention any names, but up until recently, the consolidation was happening with relatively small firms compared to people like Spotify."}, {"time": 10518, "text": "And the problem was, is that by deciding to consolidate your materials in a walled garden, you are walling yourself off from audience, right?"}, {"time": 10528, "text": "So your choice is I'm going to accept this amount of money from this company, but the loss is going to be a large chunk of my audience."}, {"time": 10533, "text": "And that's a catch 22 because you're negotiating power with that company is based on your audience size."}, {"time": 10539, "text": "So signing up with them diminishes your audience size, you lose negotiating power."}, {"time": 10543, "text": "But when you get to the level of the Spotify to just pick them out, there's other players, but you brought up Spotify specifically, these are people who can potentially, potentially enhance your audience over time."}, {"time": 10587, "text": "So it takes away some of the downside risk, which alleviates, and if you can write an agreement like Joe Rogan, I mean, where you've protected your freedom to put the content out the way you want."}, {"time": 10599, "text": "So, and if some of the downside risk is mitigated, and if you eliminate the problem of trying to monetize and stay up with the latest tech, then it might be worth it."}, {"time": 10609, "text": "You know, I'm scared of things like that, but at the same time, I'm trying to not be an idiot about it, and I can be an idiot about it."}, {"time": 10616, "text": "And when you've been doing it as independently for as long as I have, the inertia of that has a force all its own, but I'm inhibited enough in what I'm trying to do on this other end, that it's opened me at least to listening to people."}, {"time": 10634, "text": "But listen, at the same time, I love my audience, and it sounds like a cliche, but they're literally the reason I'm here."}, {"time": 10643, "text": "So I wanna make sure that whatever I do, if I can, is in keeping with a relationship that I've developed with these people over 15 years."}, {"time": 10654, "text": "But like you said, no matter what you do, you are, because see, here's the thing."}, {"time": 10658, "text": "If you don't sign up with one of those companies to make it easier for them to get your stuff on this hand, they might yell at you for how difficult it is, because the new operating system just updated, and you said, I can't get your stuff."}, {"time": 10669, "text": "So either way, you're opening yourself up to ridicule at this point."}, {"time": 10672, "text": "All of that makes it easier to go, well, if the right deal came along, and they weren't screwing me, and they weren't screwing my audience, and blah, blah, blah."}, {"time": 10680, "text": "I mean, again, in this business, when you're talking about cutting edge technology that is ever changing, and as you said, a million podcasts and growing, I think you have to try to maintain flexibility, and especially if they can mitigate the downside risk, I think you'd be an idiot to not at least try to stay up on the current trends."}, {"time": 10700, "text": "And look, I'm watching Joe."}, {"time": 10702, "text": "I'm going, okay, let's see how it goes for Joe."}, {"time": 10704, "text": "I mean, if he's like, ah, this is terrible, I'm getting out of this, you go, okay, those people are off the list."}, {"time": 10709, "text": "So Joe's put himself out as a guinea pig, and the rest of us guinea pigs appreciate it."}, {"time": 10714, "text": "As a huge, as a fan of your show, and as a fan of Netflix, the people there, I think I can speak for like millions of people in hope that hardcore history comes to Netflix, or if Spotify becomes the Netflix of podcasting, then to Spotify."}, {"time": 10730, "text": "There's something at its best that they bring out the, you said artists, so I can say it, is they bring out the best out of the artists."}, {"time": 10739, "text": "They remove some of the headache, and somehow like they put at their best, Netflix, for example, is able to enforce and find the beauty and the power in the creations that you make even better than you."}, {"time": 10757, "text": "Like they don't interfere with the creations, but they somehow, it's a branding thing probably too."}, {"time": 10764, "text": "Yeah, but interfering would be, that would be a no go for me."}, {"time": 10766, "text": "That's right, absolutely."}, {"time": 10768, "text": "That can't happen."}, {"time": 10768, "text": "But that's why Netflix is masterful."}, {"time": 10771, "text": "They seem to not interfere with the talent, as opposed to, I could throw other people under the bus, like Amazon."}, {"time": 10777, "text": "There's a lot of places under the bus that could be thrown, absolutely."}, {"time": 10779, "text": "So I would love, I know there's probably people screaming yes right now."}, {"time": 10783, "text": "In terms of hardcore history on Netflix, it would be awesome."}, {"time": 10786, "text": "And I don't love asking this question, but it's asked probably the most popular question that's unanswerable."}, {"time": 10797, "text": "So let me try to ask it in a way that you would actually answer it, which is, of course, you said you don't release shows very often."}, {"time": 10805, "text": "And the question is, or the requests and the questions is, well, can you tell Dan to do one on the Civil War?"}, {"time": 10811, "text": "Can you tell Dan to do one on the Napoleon Bonaparte?"}, {"time": 10814, "text": "Can you tell him to do one?"}, {"time": 10816, "text": "Every topic, and you've spoken to this."}, {"time": 10818, "text": "Actually, your answer about the Civil War is quite interesting."}, {"time": 10821, "text": "I didn't know you knew what my answer about the Civil War was."}, {"time": 10824, "text": "As a military historian, you enjoy, in particular, when there is differences in the armies, as opposed to contrasts."}, {"time": 10832, "text": "With the Civil War, which blew my mind when I heard you say there's not an interesting, a deep, intricate contrast between the two opposing sides."}, {"time": 10842, "text": "It's like the Roman Civil Wars, where it's legionary against legionary."}, {"time": 10845, "text": "And you've also said that the shows you work on are ones where you have some roots of fundamental understanding about that period."}, {"time": 10854, "text": "And so, when you work on a show, it's basically pulling at those strings further and refreshing your mind and learning."}, {"time": 10862, "text": "You have definitely done the research."}, {"time": 10864, "text": "Wow, these are words out of my mouth."}, {"time": 10867, "text": "But is there something like shower thoughts on Reddit?"}, {"time": 10872, "text": "Is there some ideas that are lingering in your head about possible future episodes?"}, {"time": 10879, "text": "Is there things that, whether you're not committing to anything, but whether you're gonna do it or not, is there something that makes you think, hmm, that'll be interesting to pull at that thread a little bit?"}, {"time": 10895, "text": "Oh yeah, we have things we keep in our back pocket for later."}, {"time": 10899, "text": "So, Blueprint for Armageddon, the first World War series we did, that was in my back pocket the whole time."}, {"time": 10904, "text": "And when the centennial of the war happened, it just seemed to be the likely time to bring out what was."}, {"time": 10910, "text": "That was a hell of a series."}, {"time": 10911, "text": "That's probably one of my favorite series."}, {"time": 10913, "text": "Take my rear end, man."}, {"time": 10914, "text": "I have to tell you."}, {"time": 10915, "text": "Psychologically, you mean?"}, {"time": 10916, "text": "Well, just, you know, when you get to these, I think, I'm guessing here, I think it's 26 hours, all pieces together."}, {"time": 10922, "text": "Think about, and we don't do scripts."}, {"time": 10925, "text": "It's improvised."}, {"time": 10926, "text": "So, think about what, I had somebody write on Twitter just yesterday saying, he said something like, I'm not seeing the dedication here."}, {"time": 10934, "text": "You're only getting 2.5 shows out a year."}, {"time": 10936, "text": "And I wanted to say, man, you have no idea what, the only people who understand really are other history podcasters."}, {"time": 10944, "text": "And even they don't generally do 26 hours."}, {"time": 10947, "text": "You know, that was a two year endeavor."}, {"time": 10949, "text": "As I said, the first show we ever did was like 15 minutes."}, {"time": 10952, "text": "I could crank out one of those a month."}, {"time": 10953, "text": "But when you're doing, I mean, the last show we did on the fall of the Roman Republic was five and a half hours."}, {"time": 10959, "text": "That's a book, right?"}, {"time": 10961, "text": "And it was part six or something."}, {"time": 10963, "text": "So, I mean, you just do the math."}, {"time": 10965, "text": "And it felt like you were, sorry to interrupt, on World War I, it felt like you were emotionally pulled in to it."}, {"time": 10973, "text": "Like, it felt taxing."}, {"time": 10975, "text": "I was gonna say, that's a good thing though, because that, you know, and I think we said during the show, that was the feeling that the people at the time have."}, {"time": 10981, "text": "And I think at one point we said, if this is starting to seem gruesomely repetitive, now you know how the people at the time felt."}, {"time": 10990, "text": "So in other words, that had sort of inadvertently, because when you improvise a show, some of these things are inadvertent, but it had inadvertently created the right climate for having a sense of empathy with the storyline."}, {"time": 11004, "text": "And to me, those are the serendipitous moments that make this art and not some sort of paint by the numbers kind of endeavor, you know?"}, {"time": 11012, "text": "And that's, to me, that wouldn't have happened had we scripted it out."}, {"time": 11016, "text": "So it's mostly, you just bring the tools of knowledge to the table and then in large part improvise, like the actual wording?"}, {"time": 11025, "text": "I always say we make it like they made things like spinal tap and some of those other things where the material, so I do have notes about things like on page 427 of this book, you have this quote, so that I know, aha, I'm at the point where I can drop that in."}, {"time": 11038, "text": "And sometimes I'll write notes saying, here's where you left off yesterday, so I remember."}, {"time": 11043, "text": "But in the improvisation, you end up throwing a lot out."}, {"time": 11047, "text": "And so like, but it allows us to go off on tangents, like we'll try things."}, {"time": 11051, "text": "Like I'll sit there and go, I wonder what this would sound like."}, {"time": 11054, "text": "And I'll spend two days going down that road and then I'll listen to it and go, it doesn't work."}, {"time": 11058, "text": "But that's, you know, like writers do this all the time."}, {"time": 11060, "text": "It's called killing your babies, right?"}, {"time": 11062, "text": "You got, can't, you know, but people go, so this guy goes, I'm not seeing the dedication."}, {"time": 11066, "text": "He has no idea how many things we're throwing out."}, {"time": 11068, "text": "I did an hour and a half, I had an hour and a half into The Current Show about two months ago."}, {"time": 11074, "text": "And I listened to it and I just went, you know what?"}, {"time": 11077, "text": "Boom, out the window."}, {"time": 11077, "text": "There goes six weeks of work, right?"}, {"time": 11081, "text": "But here's the problem."}, {"time": 11082, "text": "Do you trust your, sorry to interrupt, do you trust your judgment on that?"}, {"time": 11088, "text": "But here's the thing."}, {"time": 11091, "text": "Our show is a little different than other people's."}, {"time": 11094, "text": "Joe Rogan called it evergreen content."}, {"time": 11096, "text": "In other words, my political show is like a car you buy."}, {"time": 11099, "text": "And the minute you drive it off the lot, it loses half its value, right?"}, {"time": 11103, "text": "Cause it's not current anymore."}, {"time": 11104, "text": "These shows are just as good or just as bad five years from now as they are when we, although the standards on the internet changed."}, {"time": 11111, "text": "So when I listen to my old shows, I cringe sometimes cause the standards are so much higher now."}, {"time": 11115, "text": "But when you're creating evergreen content, you have two audiences to worry about."}, {"time": 11120, "text": "You have the audience that's waiting for the next show and they've already heard the other ones and they're impatient and they're telling you on Twitter, where is it?"}, {"time": 11126, "text": "But you have show, the show is also for people five years from now who haven't discovered it yet and who don't care a wit for how long it took cause they're gonna be able to download the whole, and all they care about is quality."}, {"time": 11136, "text": "And so what I always tell new podcasters is, they always say, I read all these things, it's very important you have a release schedule."}, {"time": 11144, "text": "Well, it's not more important than putting out a good piece of work."}, {"time": 11147, "text": "And the audience will forgive me if it takes too long, but it's really good when you get it."}, {"time": 11153, "text": "They will not forgive me if I rush it to get it out on time and it's a piece of crap."}, {"time": 11158, "text": "So for us, and this is why when you brought up a Spotify deal or anything else, they can't interfere with this at all because my job here, as far as I'm concerned is quality and everything else goes by the wayside because the only thing people care about longterm, the only thing that gives you longevity is how good is it?"}, {"time": 11175, "text": "How good is that book?"}, {"time": 11176, "text": "If you read J.R.R."}, {"time": 11176, "text": "Tolkien's work tomorrow, you don't care how long it took him to write it, all you care is how good is it today?"}, {"time": 11182, "text": "And that's what we try to think too."}, {"time": 11184, "text": "And I feel like if it's good, if it's really good, everything else falls into place and takes care of itself."}, {"time": 11190, "text": "And so sometimes to push back, sorry to interrupt."}, {"time": 11193, "text": "I've done it to you a thousand times, so you can get me back, please."}, {"time": 11196, "text": "Sometimes the deadline, some of the greatest movies and books have been, you think about like Dostoevsky, I forget which one, notes from underground or something."}, {"time": 11206, "text": "He needed the money, so he had to write it real quick."}, {"time": 11209, "text": "Sometimes the deadline creates is powerful at taking a creative mind of an artist and just like slapping it around to force some of the good stuff out."}, {"time": 11221, "text": "Now, the problem with history, of course, is there's different definitions of good that like it's not just about which you talk about, which is the storytelling, the richness of the storytelling."}, {"time": 11232, "text": "And I'm sure you're, again, not to compliment you too much, but you're one of the great storytellers of our time that I'm sure if you put in a jail cell and forced like somebody pointed a gun at you, you could tell one hell of a good story, but you still need the facts of history or not necessarily the facts, but like making sure you're painting the right full picture, not perfectly right."}, {"time": 11257, "text": "That's what I meant about the audience doesn't understand what a history podcast, you can't just riff and be wrong."}, {"time": 11261, "text": "So let me both oppose what you just said and back up what you just said."}, {"time": 11267, "text": "So I have a book that I wrote, right?"}, {"time": 11269, "text": "And in a book you have a hard deadline, right?"}, {"time": 11272, "text": "So Harper Collins had a hard deadline on that book."}, {"time": 11274, "text": "So when I released it, I was mad because I would have worked on it a lot longer, which is my style, right?"}, {"time": 11280, "text": "Get it right."}, {"time": 11282, "text": "But we had a chapter in that book entitled pandemic prologue question mark."}, {"time": 11287, "text": "And it was the book about the part about the black death and the 1918 flu and all that kind of stuff."}, {"time": 11293, "text": "And I was just doing an interview with a Spanish journalist this morning who said, did you ever think how lucky you got on that?"}, {"time": 11300, "text": "And first of all, lucky on a pandemic, it strikes you."}, {"time": 11304, "text": "But had I had my druthers, I would have kept that book working in my study for months more and the pandemic would have happened."}, {"time": 11314, "text": "And that would have looked like a chapter I wrote after the fact."}, {"time": 11317, "text": "I would have had to rewrite the whole thing."}, {"time": 11319, "text": "So that argues for what you said."}, {"time": 11322, "text": "At the same time, I would have spent months more working on it because to me, it didn't look the way I wanted it to look yet."}, {"time": 11329, "text": "Can you drop a hint of the things that you're keeping on the shelves?"}, {"time": 11333, "text": "Oh, the Alexander the Great podcast."}, {"time": 11335, "text": "I've talked around, I talked to somebody the other day, he said, do you know that the very first word in your very first podcast, in the title, the very first thing that anybody ever saw with hardcore history is the word Alexander."}, {"time": 11347, "text": "Because the show's entitled Alexander versus Hitler."}, {"time": 11350, "text": "I have talked around the career."}, {"time": 11352, "text": "I've done show after, I talked about his mother in one episode."}, {"time": 11354, "text": "I talked about the funeral games after his death."}, {"time": 11358, "text": "I've talked around this, I've specifically left this giant Alexandrian size hole in the middle, because we're gonna do that show one day and I'm going to lovingly enjoy talking about this crazily interesting figure of Alexander the Great."}, {"time": 11370, "text": "So that's one of the ones that's on the back pocket list."}, {"time": 11373, "text": "And what we try to do is whenever this, we're doing Second World War in Asia and the Pacific now, I'm on part five, whenever the heck we finish this, the tendency is to then pick a very different period because we've had it and the audience has had it."}, {"time": 11389, "text": "So it's time."}, {"time": 11389, "text": "So I will eventually get to the Alexander saga."}, {"time": 11393, "text": "What about just one last kind of little part of this is, what about the other half of that first 10 minute, 15 minute episode?"}, {"time": 11402, "text": "Which is, so you've done quite a bit about the World War."}, {"time": 11405, "text": "You've done quite a bit about Germany."}, {"time": 11407, "text": "Will you ever think about doing Hitler and the Man?"}, {"time": 11412, "text": "It's funny because I talked earlier about how I don't like to go back to the old shows cause our standards have changed so much."}, {"time": 11418, "text": "Well, a long time ago, one of my standards for not getting five hour podcasts done or not getting too deeply into them was to flip around the interesting points."}, {"time": 11429, "text": "We didn't realize we were gonna get an audience that wanted the actual history."}, {"time": 11434, "text": "We thought we could just go with, assume the audience knew the details and just talk about the weird stuff that only makes up one part of the show now."}, {"time": 11441, "text": "So we did a show called Nazi tidbits."}, {"time": 11444, "text": "And it was just little things about, you know, it's totally out of date now."}, {"time": 11447, "text": "Like, you know, you can still buy them, but they're out of date."}, {"time": 11451, "text": "Where we dealt a little with it."}, {"time": 11453, "text": "You know, it would be interesting, but I'll give you another example."}, {"time": 11456, "text": "I mean, history is not stagnant, as you know."}, {"time": 11459, "text": "And we had talked about Stalin earlier and Ghost of the Ostfront was done years ago."}, {"time": 11464, "text": "And people will write me from Russia now and say, well, your portrayal of Stalin is totally out of, out of, it's outdated because there's all this new stuff from the former Soviet Union."}, {"time": 11475, "text": "And you do, you turn around and you go, okay, they're right."}, {"time": 11478, "text": "And so when you talk about Hitler, it's very interesting to think about how I would do a Hitler show today versus how I did one 10 years ago."}, {"time": 11487, "text": "And you would think, well, what's new?"}, {"time": 11488, "text": "I mean, it happens a lot, but there's lots of new stuff and there's lots of new scholarship."}, {"time": 11491, "text": "And so, yeah, I would think that would be an interesting one to do someday."}, {"time": 11496, "text": "I haven't thought about that."}, {"time": 11497, "text": "That's not in the back pocket, but yeah, that'd be interesting."}, {"time": 11500, "text": "I have a disproportionate amount of power because I trapped you somehow in a room and, and thereby."}, {"time": 11507, "text": "During a pandemic."}, {"time": 11509, "text": "So like my hope will be stuck in your head, but after Alexander the Great, which would be an amazing podcast, I hope you do give a return to Hitler, The Rise and Fall of the Third Reich, which to me, It's a contemporary book, basically."}, {"time": 11527, "text": "And I, exactly."}, {"time": 11528, "text": "It's by a person who was there."}, {"time": 11530, "text": "Shira, yeah."}, {"time": 11531, "text": "I really loved that study of the man of Hitler."}, {"time": 11536, "text": "And I would love to hear your study of certain aspects of it."}, {"time": 11541, "text": "Perhaps even an episode that's like more focused on a very particular period."}, {"time": 11547, "text": "I just feel like you can tell a story that it's funny."}, {"time": 11550, "text": "Hitler is one of the most studied people."}, {"time": 11552, "text": "And I still feel like all the stories or most of the stories haven't been told."}, {"time": 11558, "text": "Oh, and there's, listen, I've got three books at home."}, {"time": 11560, "text": "I'm on all the publishers lists now."}, {"time": 11562, "text": "And they just, there's young Hitler, there's this Hitler, there's that."}, {"time": 11565, "text": "I mean, I've been reading these books and I've read about Hitler."}, {"time": 11567, "text": "I read The Rise and Fall of the Third Reich."}, {"time": 11568, "text": "My mother thought I needed to go to a psychologist because I read it when I was six."}, {"time": 11573, "text": "And she said, there's something wrong with the boy."}, {"time": 11575, "text": "And, but, but she was right."}, {"time": 11578, "text": "She was absolutely right."}, {"time": 11579, "text": "But, but you would think that, that something like that is pretty established fact."}, {"time": 11584, "text": "And yet there's new stuff coming out all the time."}, {"time": 11586, "text": "And needless to say, Germany's been investigating this guy forever."}, {"time": 11590, "text": "And sometimes it takes years to get the translations."}, {"time": 11593, "text": "I took five years of German in school."}, {"time": 11595, "text": "I can't read any of it."}, {"time": 11596, "text": "So, I mean, and he is, when you talk about fascinating figures, he's so, the whole thing is so twistedly weird."}, {"time": 11606, "text": "There was a, it came out a couple of years ago."}, {"time": 11608, "text": "Somebody found a tape of him talking to, I want to say it was General, the Finnish General Mannerheim, right?"}, {"time": 11616, "text": "And he's just in a very normal conversation of the sort we're having now."}, {"time": 11621, "text": "And, you know, the Hitler tapes, when you hear him normally he's ranting and raving."}, {"time": 11624, "text": "But this was a very sedate."}, {"time": 11626, "text": "And I wish I'd understood the German well enough to really get a feel, because I was reading what Germans said."}, {"time": 11631, "text": "And they say, wow, you can really hear the Southern accent."}, {"time": 11635, "text": "You know, little things that only a native speaker would hear."}, {"time": 11638, "text": "And I remember thinking, this is such a different side of this twisted character."}, {"time": 11642, "text": "And you would think you would always, you would think that this was information that was out in the rise and fall of the Third Reich, but it wasn't."}, {"time": 11649, "text": "And so this goes along with that stuff about new stuff coming out all the time."}, {"time": 11654, "text": "Alexander, new stuff coming out all the time."}, {"time": 11657, "text": "Well, at least interpretations rather than factual data."}, {"time": 11660, "text": "And those color your, those give depth to your understanding."}, {"time": 11663, "text": "Yes, and you want that because of the historiography."}, {"time": 11666, "text": "People love that."}, {"time": 11667, "text": "And that was a byproduct of my lack of credentials, where we thought we're gonna bring in the historians, and we call them audio footnotes, right away for me to say, listen, I'm not a historian, but I'll quote this guy who is so you can trust him."}, {"time": 11681, "text": "But then we would quote other people who had different views."}, {"time": 11684, "text": "And people didn't realize that, you know, if they're not history majors, that historians don't always agree on this stuff and that they have disagreements and they love that."}, {"time": 11692, "text": "So I love the fact that there's more stuff out there because it allows us to then bring in other points of view and sort of maybe three dimensionalize or flesh out the story a little bit more."}, {"time": 11704, "text": "Two last questions."}, {"time": 11705, "text": "One really simple, one absurdly ridiculous, and perhaps also simple."}, {"time": 11710, "text": "First, who has been and is he real?"}, {"time": 11714, "text": "I don't even know what you're talking about."}, {"time": 11717, "text": "Very well."}, {"time": 11718, "text": "How's that for an answer?"}, {"time": 11720, "text": "It's like asking me, is Harvey the White Rabbit real?"}, {"time": 11723, "text": "There's carrots all around the production room, but I don't know what that means."}, {"time": 11727, "text": "Well, a lot of people demanded that I prove, I somehow figure out a way to prove the existence."}, {"time": 11732, "text": "If I said he was real, people would say, no, he's not."}, {"time": 11735, "text": "And if I said he was, if he wasn't real, they would say, yes, he is."}, {"time": 11738, "text": "So it's a Santa Claus Easter bunny kind of vibe there."}, {"time": 11743, "text": "I mean, what is real anyway?"}, {"time": 11744, "text": "That's exactly what I told him if he exists."}, {"time": 11749, "text": "The most absurd question, I'm very sorry."}, {"time": 11751, "text": "Very sorry, but then again, I'm not."}, {"time": 11753, "text": "What's the meaning of it all?"}, {"time": 11755, "text": "You study history, human history."}, {"time": 11763, "text": "Have you been able to make sense of why the hell we're here on this spinning rock?"}, {"time": 11768, "text": "Does any of it even make sense?"}, {"time": 11773, "text": "What I look at sometimes that I find interesting is certain consistencies that we have over time."}, {"time": 11780, "text": "History doesn't repeat, but it has a constant, and the constant is us."}, {"time": 11786, "text": "Now we change."}, {"time": 11787, "text": "I mentioned earlier the wickedly weird time we live in with what social media is doing to us as guinea pigs, and that's a new element, but we're still people who are motivated by love, hate, greed, envy, sex."}, {"time": 11801, "text": "I mean, all these things that would have connected us with the ancients, right?"}, {"time": 11805, "text": "That's the part that always makes history sound like it rhymes, you know?"}, {"time": 11810, "text": "And when you put the constant, the human element, and you mix it with systems that are similar, so one of the reasons that the ancient Roman Republic is something that people point to all the time as something that seems like we're repeating history is because you have humans, just like you had then, and you have a system that resembles the one we have here."}, {"time": 11832, "text": "So you throw the constant in with a system that is somewhat similar, and you begin to see things that look like they rhyme a little."}, {"time": 11839, "text": "So for me, I'm always trying to figure out more about us, and when you show us in 500 years ago in Asia, and 800 years ago in Africa, and you look at all these different places that you put the guinea pig in, and you watch how the guinea pig responds to the different stimuli and challenges, I feel like it helps me flesh out a little bit more who we are in the long timeline."}, {"time": 11867, "text": "Not who we are today, specifically, but who we've always been."}]}, {"title": "Michael Littman: Reinforcement Learning and the Future of AI | Lex Fridman Podcast #144", "id": "c9AbECvRt20", "quotes": [{"time": 315, "text": "Maybe something that, you know, to walk that back a little bit, maybe something that others might be surprised by the three songs that you kind of enjoy."}, {"time": 328, "text": "That is a great question that I cannot answer."}, {"time": 328, "text": "But instead, let me tell you a story."}, {"time": 332, "text": "So pick a question you do want to answer."}, {"time": 332, "text": "I've been watching the presidential debates and vice presidential debates."}, {"time": 336, "text": "And it turns out, yeah, it's really, you can just answer any question you want."}, {"time": 339, "text": "So it's a related question."}, {"time": 339, "text": "Well said."}, {"time": 347, "text": "I really like pop music."}, {"time": 347, "text": "I've enjoyed pop music ever since I was very young."}, {"time": 347, "text": "So 60s music, 70s music, 80s music."}, {"time": 351, "text": "This is all awesome."}, {"time": 351, "text": "And then I had kids and I think I stopped listening to music and I was starting to realize that my musical taste had sort of frozen out."}, {"time": 361, "text": "And so I decided in 2011, I think, to start listening to the top 10 billboard songs each week."}, {"time": 368, "text": "So I'd be on the on the treadmill and I would listen to that week's top 10 songs so I could find out what was popular now."}, {"time": 371, "text": "And what I discovered is that I have no musical taste whatsoever."}, {"time": 377, "text": "I like what I'm familiar with."}, {"time": 377, "text": "And so the first time I'd hear a song is the first week that was on the charts, I'd be like, and then the second week, I was into it a little bit."}, {"time": 386, "text": "And the third week, I was loving it."}, {"time": 386, "text": "And by the fourth week is like, just part of me."}, {"time": 390, "text": "And so I'm afraid that I can't tell you the most my favorite song of all time, because it's whatever I heard most recently."}, {"time": 396, "text": "People have told me that there's an art to listening to music as well."}, {"time": 404, "text": "And you can start to, if you listen to a song, just carefully, like explicitly, just force yourself to really listen."}, {"time": 408, "text": "You start to, I did this when I was part of jazz band and fusion band in college."}, {"time": 414, "text": "You start to hear the layers of the instruments."}, {"time": 421, "text": "You start to hear the individual instruments and you start to, you can listen to classical music or to orchestra this way."}, {"time": 424, "text": "You can listen to jazz this way."}, {"time": 428, "text": "I mean, it's funny to imagine you now to walking that forward to listening to pop hits now as like a scholar, listening to like Cardi B or something like that, or Justin Timberlake."}, {"time": 436, "text": "Is he?"}, {"time": 436, "text": "No, not Timberlake, Bieber."}, {"time": 442, "text": "They've both been in the top 10 since I've been listening."}, {"time": 446, "text": "They're still up there."}, {"time": 446, "text": "Oh my God, I'm so cool."}, {"time": 449, "text": "If you haven't heard Justin Timberlake's top 10 in the last few years, there was one song that he did where the music video was set at essentially NeurIPS."}, {"time": 458, "text": "Oh, the one with the robotics."}, {"time": 458, "text": "Yeah, yeah, yeah, yeah, yeah."}, {"time": 462, "text": "It's like at an academic conference and he's doing a demo."}, {"time": 465, "text": "He was presenting, right?"}, {"time": 466, "text": "It was sort of a cross between the Apple, like Steve Jobs kind of talk and NeurIPS."}, {"time": 473, "text": "So, you know, it's always fun when AI shows up in pop culture."}, {"time": 476, "text": "I wonder if he consulted somebody for that."}, {"time": 476, "text": "So maybe on that topic, I've seen your celebrity multiple dimensions, but one of them is you've done cameos in different places."}, {"time": 488, "text": "I've seen you in a TurboTax commercial as like, I guess, the brilliant Einstein character."}, {"time": 496, "text": "And the point is that TurboTax doesn't need somebody like you."}, {"time": 496, "text": "It doesn't need a brilliant person."}, {"time": 504, "text": "Very few things need someone like me."}, {"time": 504, "text": "But yes, they were specifically emphasizing the idea that you don't need to be like a computer expert to be able to use their software."}, {"time": 512, "text": "How did you end up in that world?"}, {"time": 513, "text": "I think it's an interesting story."}, {"time": 513, "text": "So I was teaching my class."}, {"time": 513, "text": "It was an intro computer science class for non concentrators, non majors."}, {"time": 518, "text": "And sometimes when people would visit campus, they would check in to say, hey, we want to see what a class is like."}, {"time": 525, "text": "Can we sit on your class?"}, {"time": 528, "text": "So a person came to my class who was the daughter of the brother of the husband of the best friend of my wife."}, {"time": 542, "text": "Anyway, basically a family friend came to campus to check out Brown and asked to come to my class and came with her dad."}, {"time": 551, "text": "Her dad is, who I've known from various kinds of family events and so forth, but he also does advertising."}, {"time": 556, "text": "And he said that he was recruiting scientists for this ad, this TurboTax set of ads."}, {"time": 561, "text": "And he said, we wrote the ad with the idea that we get like the most brilliant researchers, but they all said no."}, {"time": 571, "text": "So can you help us find like B level scientists?"}, {"time": 576, "text": "And I'm like, sure, that's who I hang out with."}, {"time": 584, "text": "So that should be fine."}, {"time": 584, "text": "So I put together a list and I did what some people call the Dick Cheney."}, {"time": 589, "text": "So I included myself on the list of possible candidates, with a little blurb about each one and why I thought that would make sense for them to do it."}, {"time": 595, "text": "And they reached out to a handful of them, but then they ultimately, they YouTube stalked me a little bit and they thought, oh, I think he could do this."}, {"time": 603, "text": "And they said, okay, we're going to offer you the commercial."}, {"time": 607, "text": "I'm like, what?"}, {"time": 607, "text": "So it was such an interesting experience because they have another world, the people who do like nationwide kind of ad campaigns and television shows and movies and so forth."}, {"time": 621, "text": "It's quite a remarkable system that they have going because they have a set."}, {"time": 621, "text": "So I went to, it was just somebody's house that they rented in New Jersey."}, {"time": 628, "text": "But in the commercial, it's just me and this other woman."}, {"time": 635, "text": "In reality, there were 50 people in that room and another, I don't know, half a dozen kind of spread out around the house in various ways."}, {"time": 641, "text": "There were people whose job it was to control the sun."}, {"time": 646, "text": "They were in the backyard on ladders, putting filters up to try to make sure that the sun didn't glare off the window in a way that would wreck the shot."}, {"time": 653, "text": "So there was like six people out there doing that."}, {"time": 657, "text": "There was three people out there giving snacks, the craft table."}, {"time": 662, "text": "There was another three people giving healthy snacks because that was a separate craft table."}, {"time": 665, "text": "There was one person whose job it was to keep me from getting lost."}, {"time": 665, "text": "And I think the reason for all this is because so many people are in one place at one time."}, {"time": 672, "text": "They have to be time efficient."}, {"time": 672, "text": "They have to get it done."}, {"time": 676, "text": "The morning they were going to do my commercial."}, {"time": 676, "text": "In the afternoon, they were going to do a commercial of a mathematics professor from Princeton."}, {"time": 680, "text": "They had to get it done."}, {"time": 680, "text": "No wasted time or energy."}, {"time": 687, "text": "And so there's just a fleet of people all working as an organism."}, {"time": 687, "text": "And it was fascinating."}, {"time": 692, "text": "I was just the whole time just looking around like, this is so neat."}, {"time": 692, "text": "Like one person whose job it was to take the camera off of the cameraman so that someone else whose job it was to remove the film canister."}, {"time": 703, "text": "Because every couple's takes, they had to replace the film because film gets used up."}, {"time": 708, "text": "It was just, I don't know."}, {"time": 708, "text": "I was geeking out the whole time."}, {"time": 708, "text": "It was so fun."}, {"time": 713, "text": "How many takes did it take?"}, {"time": 713, "text": "It looked the opposite."}, {"time": 713, "text": "There was more than two people there."}, {"time": 713, "text": "It was very relaxed."}, {"time": 717, "text": "The person who I was in the scene with is a professional."}, {"time": 717, "text": "She's an improv comedian from New York City."}, {"time": 726, "text": "And when I got there, they had given me a script as such as it was."}, {"time": 726, "text": "And then I got there and they said, we're going to do this as improv."}, {"time": 731, "text": "I'm like, I don't know how to improv."}, {"time": 735, "text": "I don't know what you're telling me to do here."}, {"time": 735, "text": "She knows."}, {"time": 735, "text": "I'm like, okay."}, {"time": 741, "text": "I'll go see how this goes."}, {"time": 741, "text": "I guess I got pulled into the story because like, where the heck did you come from?"}, {"time": 746, "text": "I guess in the scene."}, {"time": 746, "text": "Like, how did you show up in this random person's house?"}, {"time": 752, "text": "Well, I mean, the reality of it is I stood outside in the blazing sun."}, {"time": 752, "text": "There was someone whose job it was to keep an umbrella over me because I started to sweat."}, {"time": 756, "text": "And so I would wreck the shot because my face was all shiny with sweat."}, {"time": 761, "text": "So there was one person who would dab me off, had an umbrella."}, {"time": 765, "text": "But yeah, like the reality of it, like, why is this strange stalkery person hanging around outside somebody's house?"}, {"time": 771, "text": "We're not sure when you have to look in, what the ways for the book, but are you, so you make, you make, like you said, YouTube, you make videos yourself, you make awesome parody, sort of parody songs that kind of focus on a particular aspect of computer science."}, {"time": 787, "text": "How much those seem really interesting to you?"}, {"time": 793, "text": "How much those seem really natural?"}, {"time": 793, "text": "How much production value goes into that?"}, {"time": 798, "text": "Do you also have a team of 50 people?"}, {"time": 798, "text": "The videos, almost all the videos, except for the ones that people would have actually seen, are just me."}, {"time": 802, "text": "I write the lyrics, I sing the song."}, {"time": 806, "text": "I generally find a, like a backing track online because I'm like you, can't really play an instrument."}, {"time": 814, "text": "And then I do, in some cases I'll do visuals using just like PowerPoint."}, {"time": 819, "text": "Lots and lots of PowerPoint to make it sort of like an animation."}, {"time": 824, "text": "The most produced one is the one that people might have seen, which is the overfitting video that I did with Charles Isbell."}, {"time": 829, "text": "And that was produced by the Georgia Tech and Udacity people because we were doing a class together."}, {"time": 835, "text": "It was kind of, I usually do parody songs kind of to cap off a class at the end of a class."}, {"time": 839, "text": "So that one you're wearing, so it was just a thriller."}, {"time": 844, "text": "You're wearing the Michael Jackson, the red leather jacket."}, {"time": 844, "text": "The interesting thing with podcasting that you're also into is that I really enjoy is that there's not a team of people."}, {"time": 861, "text": "It's kind of more, because you know, there's something that happens when there's more people involved than just one person that just the way you start acting, I don't know."}, {"time": 869, "text": "There's a censorship."}, {"time": 876, "text": "You're not given, especially for like slow thinkers like me, you're not."}, {"time": 876, "text": "And I think most of us are, if we're trying to actually think we're a little bit slow and careful, it kind of large teams get in the way of that."}, {"time": 890, "text": "And I don't know what to do with that."}, {"time": 890, "text": "Like that's the, to me, like if, yeah, it's very popular to criticize quote unquote mainstream media."}, {"time": 901, "text": "But there is legitimacy to criticizing them the same."}, {"time": 901, "text": "I love listening to NPR, for example, but every, it's clear that there's a team behind it."}, {"time": 906, "text": "There's a commercial, there's constant commercial breaks."}, {"time": 911, "text": "There's this kind of like rush of like, okay, I have to interrupt you now because we have to go to commercial."}, {"time": 916, "text": "Just this whole, it creates, it destroys the possibility of nuanced conversation."}, {"time": 920, "text": "Evian, which Charles Isbell, who I talked to yesterday told me that Evian is naive backwards, which the fact that his mind thinks this way is quite brilliant."}, {"time": 936, "text": "Anyway, there's a freedom to this podcast."}, {"time": 942, "text": "He's Dr."}, {"time": 942, "text": "Awkward, which by the way, is a palindrome."}, {"time": 942, "text": "That's a palindrome that I happen to know from other parts of my life."}, {"time": 946, "text": "And I just, well, you know, use it against Charles."}, {"time": 946, "text": "Awkward."}, {"time": 954, "text": "So what was the most challenging parody song to make?"}, {"time": 954, "text": "Was it the Thriller one?"}, {"time": 960, "text": "No, that one was really fun."}, {"time": 960, "text": "I wrote the lyrics really quickly and then I gave it over to the production team."}, {"time": 966, "text": "They recruited a acapella group to sing."}, {"time": 966, "text": "That went really smoothly."}, {"time": 966, "text": "It's great having a team because then you can just focus on the part that you really love, which in my case is writing the lyrics."}, {"time": 975, "text": "For me, the most challenging one, not challenging in a bad way, but challenging in a really fun way, was I did one of the parody songs I did is about the halting problem in computer science."}, {"time": 987, "text": "The fact that you can't create a program that can tell for any other arbitrary program whether it actually going to get stuck in infinite loop or whether it's going to eventually stop."}, {"time": 998, "text": "And so I did it to an 80's song because I hadn't started my new thing of learning current songs."}, {"time": 1006, "text": "And it was Billy Joel's The Piano Man."}, {"time": 1006, "text": "Which is a great song."}, {"time": 1006, "text": "Sing me a song."}, {"time": 1016, "text": "You're the piano man."}, {"time": 1016, "text": "So the lyrics are great because first of all, it rhymes."}, {"time": 1016, "text": "Not all songs rhyme."}, {"time": 1024, "text": "I've done Rolling Stones songs which turn out to have no rhyme scheme whatsoever."}, {"time": 1024, "text": "They're just sort of yelling and having a good time, which makes it not fun from a parody perspective because like you can say anything."}, {"time": 1034, "text": "But the lines rhymed and there was a lot of internal rhymes as well."}, {"time": 1038, "text": "And so figuring out how to sing with internal rhymes, a proof of the halting problem was really challenging."}, {"time": 1044, "text": "And I really enjoyed that process."}, {"time": 1044, "text": "What about, last question on this topic, what about the dancing in the Thriller video?"}, {"time": 1050, "text": "How many takes that take?"}, {"time": 1050, "text": "So I wasn't planning to dance."}, {"time": 1056, "text": "They had me in the studio and they gave me the jacket and it's like, well, you can't, if you have the jacket and the glove, like there's not much you can do."}, {"time": 1060, "text": "So I think I just danced around and then they said, why don't you dance a little bit?"}, {"time": 1066, "text": "There was a scene with me and Charles dancing together."}, {"time": 1069, "text": "They did not use it in the video, but we recorded it."}, {"time": 1069, "text": "No, it was pretty funny."}, {"time": 1075, "text": "And Charles, who has this beautiful, wonderful voice doesn't really sing."}, {"time": 1082, "text": "He's not really a singer."}, {"time": 1082, "text": "And so that was why I designed the song with him doing a spoken section and me doing the singing."}, {"time": 1087, "text": "It's very like Barry White."}, {"time": 1087, "text": "Smooth baritone."}, {"time": 1092, "text": "That was awesome."}, {"time": 1092, "text": "So one of the other things Charles said is that, you know, everyone knows you as like a super nice guy, super passionate about teaching and so on."}, {"time": 1099, "text": "What he said, don't know if it's true, that despite the fact that you're, you are."}, {"time": 1107, "text": "I will admit this finally for the first time."}, {"time": 1114, "text": "That was, that was me."}, {"time": 1114, "text": "It's the Johnny Cash song."}, {"time": 1114, "text": "Kill the Manorino just to watch him die."}, {"time": 1119, "text": "That you actually do have some strong opinions on some topics."}, {"time": 1119, "text": "So if this in fact is true, what strong opinions would you say you have?"}, {"time": 1126, "text": "Is there ideas you think maybe in artificial intelligence and machine learning, maybe in life that you believe is true that others might, you know, some number of people might disagree with you on?"}, {"time": 1142, "text": "So I try very hard to see things from multiple perspectives."}, {"time": 1148, "text": "There's this great Calvin and Hobbes cartoon where, do you know?"}, {"time": 1155, "text": "So Calvin's dad is always kind of a bit of a foil and he talked Calvin into, Calvin had done something wrong."}, {"time": 1161, "text": "The dad talks him into like seeing it from another perspective and Calvin, like this breaks Calvin because he's like, oh my gosh, now I can see the opposite sides of things."}, {"time": 1170, "text": "And so the, it's, it becomes like a Cubist cartoon where there is no front and back."}, {"time": 1175, "text": "Everything's just exposed and it really freaks him out."}, {"time": 1175, "text": "And finally he settles back down."}, {"time": 1175, "text": "It's like, oh good."}, {"time": 1179, "text": "No, I can make that go away."}, {"time": 1179, "text": "But like, I'm that, I'm that I live in that world where I'm trying to see everything from every perspective all the time."}, {"time": 1184, "text": "So there are some things that I've formed opinions about that I would be harder, I think, to disavow me of."}, {"time": 1188, "text": "One is the super intelligence argument and the existential threat of AI is one where I feel pretty confident in my feeling about that one."}, {"time": 1202, "text": "Like I'm willing to hear other arguments, but like, I am not particularly moved by the idea that if we're not careful, we will accidentally create a super intelligence that will destroy human life."}, {"time": 1213, "text": "Let's talk about that."}, {"time": 1213, "text": "Let's get you in trouble and record your video."}, {"time": 1217, "text": "It's like Bill Gates, I think he said like some quote about the internet that that's just going to be a small thing."}, {"time": 1224, "text": "It's not going to really go anywhere."}, {"time": 1224, "text": "And then I think Steve Ballmer said, I don't know why I'm sticking on Microsoft."}, {"time": 1229, "text": "That's something that like smartphones are useless."}, {"time": 1236, "text": "There's no reason why Microsoft should get into smartphones, that kind of."}, {"time": 1240, "text": "So let's get, let's talk about AGI."}, {"time": 1240, "text": "As AGI is destroying the world, we'll look back at this video and see."}, {"time": 1245, "text": "No, I think it's really interesting to actually talk about because nobody really knows the future."}, {"time": 1249, "text": "So you have to use your best intuition."}, {"time": 1249, "text": "It's very difficult to predict it, but you have spoken about AGI and the existential risks around it and sort of basing your intuition that we're quite far away from that being a serious concern relative to the other concerns we have."}, {"time": 1268, "text": "Can you maybe unpack that a little bit?"}, {"time": 1268, "text": "Yeah, sure, sure, sure."}, {"time": 1268, "text": "So as I understand it, that for example, I read Bostrom's book and a bunch of other reading material about this sort of general way of thinking about the world."}, {"time": 1282, "text": "And I think the story goes something like this, that we will at some point create computers that are smart enough that they can help design the next version of themselves, which itself will be smarter than the previous version of themselves and eventually bootstrapped up to being smarter than us."}, {"time": 1302, "text": "At which point we are essentially at the mercy of this sort of more powerful intellect, which in principle we don't have any control over what its goals are."}, {"time": 1316, "text": "And so if its goals are at all out of sync with our goals, for example, the continued existence of humanity, we won't be able to stop it."}, {"time": 1324, "text": "It'll be way more powerful than us and we will be toast."}, {"time": 1332, "text": "So there's some, I don't know, very smart people who have signed on to that story."}, {"time": 1332, "text": "And it's a compelling story."}, {"time": 1338, "text": "Now I can really get myself in trouble."}, {"time": 1338, "text": "I once wrote an op ed about this, specifically responding to some quotes from Elon Musk, who has been on this very podcast more than once."}, {"time": 1350, "text": "AI summoning the demon."}, {"time": 1350, "text": "But then he came to Providence, Rhode Island, which is where I live, and said to the governors of all the states, you know, you're worried about entirely the wrong thing."}, {"time": 1365, "text": "You need to be worried about AI."}, {"time": 1365, "text": "You need to be very, very worried about AI."}, {"time": 1369, "text": "And journalists kind of reacted to that and they wanted to get people's take."}, {"time": 1369, "text": "And I was like, OK, my my my belief is that one of the things that makes Elon Musk so successful and so remarkable as an individual is that he believes in the power of ideas."}, {"time": 1383, "text": "He believes that you can have you can if you know, if you have a really good idea for getting into space, you can get into space."}, {"time": 1392, "text": "If you have a really good idea for a company or for how to change the way that people drive, you just have to do it and it can happen."}, {"time": 1398, "text": "It's really natural to apply that same idea to AI."}, {"time": 1403, "text": "You see these systems that are doing some pretty remarkable computational tricks, demonstrations, and then to take that idea and just push it all the way to the limit and think, OK, where does this go?"}, {"time": 1415, "text": "Where is this going to take us next?"}, {"time": 1415, "text": "And if you're a deep believer in the power of ideas, then it's really natural to believe that those ideas could be taken to the extreme and kill us."}, {"time": 1427, "text": "So I think, you know, his strength is also his undoing, because that doesn't mean it's true."}, {"time": 1432, "text": "Like, it doesn't mean that that has to happen, but it's natural for him to think that."}, {"time": 1436, "text": "So another way to phrase the way he thinks, and I find it very difficult to argue with that line of thinking."}, {"time": 1444, "text": "So Sam Harris is another person from neuroscience perspective that thinks like that is saying, well, is there something fundamental in the physics of the universe that prevents this from eventually happening?"}, {"time": 1458, "text": "And Nick Bostrom thinks in the same way, that kind of zooming out, yeah, OK, we humans now are existing in this like time scale of minutes and days."}, {"time": 1464, "text": "And so our intuition is in this time scale of minutes, hours and days."}, {"time": 1472, "text": "But if you look at the span of human history, is there any reason you can't see this in 100 years?"}, {"time": 1479, "text": "And like, is there something fundamental about the laws of physics that prevent this?"}, {"time": 1487, "text": "And if it doesn't, then it eventually will happen or will we will destroy ourselves in some other way."}, {"time": 1492, "text": "And it's very difficult, I find, to actually argue against that."}, {"time": 1497, "text": "Yeah, me too."}, {"time": 1503, "text": "And not sound like."}, {"time": 1503, "text": "Not sound like you're just like rolling your eyes like I have like science fiction, we don't have to think about it, but even even worse than that, which is like, I don't have kids, but like I got to pick up my kids now like this."}, {"time": 1516, "text": "OK, I see there's more pressing short."}, {"time": 1516, "text": "Yeah, there's more pressing short term things that like stop over the next national crisis."}, {"time": 1520, "text": "We have much, much shorter things like now, especially this year, there's covid."}, {"time": 1525, "text": "So like any kind of discussion like that is like there's this, you know, this pressing things today is."}, {"time": 1530, "text": "And then so the Sam Harris argument, well, like any day the exponential singularity can can occur is very difficult to argue against."}, {"time": 1545, "text": "But part of his story is also he's not going to put a date on it."}, {"time": 1550, "text": "It could be in a thousand years, it could be in a hundred years, it could be in two years."}, {"time": 1550, "text": "It's just that as long as we keep making this kind of progress, it's ultimately has to become a concern."}, {"time": 1559, "text": "I kind of am on board with that."}, {"time": 1584, "text": "If you believe that you can just turn on a deep learning network and eventually give it enough compute and eventually get there."}, {"time": 1588, "text": "Well, sure, that seems really scary because we won't we won't be in the loop at all."}, {"time": 1592, "text": "We won't we won't be helping to design or target these kinds of systems."}, {"time": 1598, "text": "But I don't I don't see that."}, {"time": 1598, "text": "That feels like it is against the laws of physics, because these systems need help."}, {"time": 1603, "text": "They need they need to surpass the the the difficulty, the wall of complexity that happens in arranging something in the form that that will happen."}, {"time": 1615, "text": "Yeah, like I believe in evolution, like I believe that that that there's an argument."}, {"time": 1615, "text": "So there's another argument, just to look at it from a different perspective, that people say, why don't believe in evolution?"}, {"time": 1624, "text": "How could evolution?"}, {"time": 1624, "text": "It's it's sort of like a random set of parts assemble themselves into a 747."}, {"time": 1630, "text": "And that could just never happen."}, {"time": 1630, "text": "So it's like, OK, that's maybe hard to argue against."}, {"time": 1635, "text": "But clearly, 747 do get assembled."}, {"time": 1635, "text": "They get assembled by us."}, {"time": 1640, "text": "Basically, the idea being that there's a process by which we will get to the point of making technology that has that kind of awareness."}, {"time": 1646, "text": "And in that process, we're going to learn a lot about that process and we'll have more ability to control it or to shape it or to build it in our own image."}, {"time": 1657, "text": "It's not something that is going to spring into existence like that 747."}, {"time": 1657, "text": "And we're just going to have to contend with it completely unprepared."}, {"time": 1663, "text": "That's very possible that in the context of the long arc of human history, it will, in fact, spring into existence."}, {"time": 1675, "text": "But that springing might take like if you look at nuclear weapons, like even 20 years is a springing in in the context of human history."}, {"time": 1682, "text": "And it's very possible, just like with nuclear weapons, that we could have I don't know what percentage you want to put at it, but the possibility could have knocked ourselves out."}, {"time": 1693, "text": "The possibility of human beings destroying themselves in the 20th century with nuclear weapons."}, {"time": 1697, "text": "You can if you really think through it, you could really put it close to, like, I don't know, 30, 40 percent, given like the certain moments of crisis that happen."}, {"time": 1708, "text": "So, like, I think one, like, fear in the shadows that's not being acknowledged is it's not so much the A.I."}, {"time": 1718, "text": "will run away is is that as it's running away, we won't have enough time to think through how to stop it."}, {"time": 1724, "text": "Fast takeoff or FOOM."}, {"time": 1732, "text": "I mean, my much bigger concern, I wonder what you think about it, which is we won't know it's happening."}, {"time": 1735, "text": "So I kind of think that there's an A.G.I."}, {"time": 1735, "text": "situation already happening with social media that our minds, our collective intelligence of human civilization is already being controlled by an algorithm."}, {"time": 1751, "text": "And like we're we're already super like the level of a collective intelligence, thanks to Wikipedia, people should donate to Wikipedia to feed the A.G.I. . Man, if we had a super intelligence that that was in line with Wikipedia's values, that it's a lot better than a lot of other things I could imagine."}, {"time": 1771, "text": "I trust Wikipedia more than I trust Facebook or YouTube as far as trying to do the right thing from a rational perspective."}, {"time": 1781, "text": "Now, that's not where you were going."}, {"time": 1781, "text": "But it does strike me that there's sort of smarter and less smart ways of exposing ourselves to each other on the Internet."}, {"time": 1791, "text": "The interesting thing is that Wikipedia and social media have very different forces."}, {"time": 1795, "text": "I mean, Wikipedia, if A.G.I."}, {"time": 1795, "text": "was Wikipedia, it'd be just like this cranky, overly competent editor of articles."}, {"time": 1802, "text": "You know, there's something to that."}, {"time": 1802, "text": "But the social media aspect is not."}, {"time": 1808, "text": "So the vision of A.G.I."}, {"time": 1808, "text": "is as a separate system that's super intelligent."}, {"time": 1817, "text": "That's super intelligent."}, {"time": 1817, "text": "That's one key little thing."}, {"time": 1817, "text": "I mean, there's the paperclip argument that's super dumb, but super powerful systems."}, {"time": 1820, "text": "But with social media, you have a relatively like algorithms we may talk about today, very simple algorithms that when something Charles talks a lot about, which is interactive A.I., when they start like having at scale, like tiny little interactions with human beings, they can start controlling these human beings."}, {"time": 1840, "text": "So a single algorithm can control the minds of human beings slowly to what we might not realize."}, {"time": 1845, "text": "It could start wars."}, {"time": 1851, "text": "It could start."}, {"time": 1851, "text": "It could change the way we think about things."}, {"time": 1851, "text": "It feels like in the long arc of history, if I were to sort of zoom out from all the outrage and all the tension on social media, that it's progressing us towards better and better things."}, {"time": 1863, "text": "It feels like chaos and toxic and all that kind of stuff."}, {"time": 1871, "text": "It's chaos and toxic."}, {"time": 1871, "text": "But it feels like actually the chaos and toxic is similar to the kind of debates we had from the founding of this country."}, {"time": 1882, "text": "You know, there was a civil war that happened over that period."}, {"time": 1882, "text": "And ultimately it was all about this tension of like something doesn't feel right about our implementation of the core values we hold as human beings."}, {"time": 1893, "text": "And they're constantly struggling with this."}, {"time": 1893, "text": "And that results in people calling each other, just being shady to each other on Twitter."}, {"time": 1898, "text": "But ultimately the algorithm is managing all that."}, {"time": 1907, "text": "And it feels like there's a possible future in which that algorithm controls us into the direction of self destruction and whatever that looks like."}, {"time": 1919, "text": "So, all right."}, {"time": 1919, "text": "I do believe in the power of social media to screw us up royally."}, {"time": 1919, "text": "I do believe in the power of social media to benefit us too."}, {"time": 1925, "text": "I do think that we're in a, yeah, it's sort of almost got dropped on top of us."}, {"time": 1932, "text": "And now we're trying to, as a culture, figure out how to cope with it."}, {"time": 1936, "text": "There's a sense in which, I don't know, there's some arguments that say that, for example, I guess college age students now, late college age students now, people who were in middle school when social media started to really take off, may be really damaged."}, {"time": 1947, "text": "Like this may have really hurt their development in a way that we don't have all the implications of quite yet."}, {"time": 1954, "text": "That's the generation who, and I hate to make it somebody else's responsibility, but like they're the ones who can fix it."}, {"time": 1966, "text": "They're the ones who can figure out how do we keep the good of this kind of technology without letting it eat us alive."}, {"time": 1973, "text": "And if they're successful, we move on to the next phase, the next level of the game."}, {"time": 1981, "text": "If they're not successful, then yeah, then we're going to wreck each other."}, {"time": 1981, "text": "We're going to destroy society."}, {"time": 1986, "text": "So you're going to, in your old age, sit on a porch and watch the world burn because of the TikTok generation that..."}, {"time": 1991, "text": "I believe, well, so this is my kid's age, right?"}, {"time": 1997, "text": "And that's certainly my daughter's age."}, {"time": 1997, "text": "And she's very tapped in to social stuff, but she's also, she's trying to find that balance, right?"}, {"time": 2001, "text": "Of participating in it and in getting the positives of it, but without letting it eat her alive."}, {"time": 2006, "text": "And I think sometimes she ventures, I hope she doesn't watch this."}, {"time": 2013, "text": "Sometimes I think she ventures a little too far and is consumed by it."}, {"time": 2013, "text": "And other times she gets a little distance."}, {"time": 2019, "text": "And if there's enough people like her out there, they're going to navigate this choppy waters."}, {"time": 2026, "text": "That's an interesting skill actually to develop."}, {"time": 2026, "text": "I talked to my dad about it."}, {"time": 2032, "text": "I've now, somehow this podcast in particular, but other reasons has received a little bit of attention."}, {"time": 2041, "text": "And with that, apparently in this world, even though I don't shut up about love and I'm just all about kindness, I have now a little mini army of trolls."}, {"time": 2047, "text": "It's kind of hilarious actually, but it also doesn't feel good, but it's a skill to learn to not look at that, like to moderate actually how much you look at that."}, {"time": 2063, "text": "The discussion I have with my dad, it's similar to, it doesn't have to be about trolls."}, {"time": 2068, "text": "It could be about checking email, which is like, if you're anticipating, you know, there's a, my dad runs a large Institute at Drexel University and there could be stressful like emails you're waiting, like there's drama of some kinds."}, {"time": 2079, "text": "And so like, there's a temptation to check the email."}, {"time": 2085, "text": "If you send an email and you kind of, and that pulls you in into, it doesn't feel good."}, {"time": 2089, "text": "And it's a skill that he actually complains that he hasn't learned."}, {"time": 2096, "text": "I mean, he grew up without it."}, {"time": 2096, "text": "So he hasn't learned the skill of how to shut off the internet and walk away."}, {"time": 2101, "text": "And I think young people, while they're also being quote unquote damaged by like, you know, being bullied online, all of those stories, which are very like horrific, you basically can't escape your bullies these days when you're growing up."}, {"time": 2117, "text": "But at the same time, they're also learning that skill of how to be able to shut off the, like disconnect with it, be able to laugh at it, not take it too seriously."}, {"time": 2123, "text": "Like we're all trying to figure this out."}, {"time": 2129, "text": "Just like you said, it's been dropped on us and we're trying to figure it out."}, {"time": 2132, "text": "I think that's really interesting."}, {"time": 2132, "text": "And I guess I've become a believer in the human design, which I feel like I don't completely understand."}, {"time": 2137, "text": "Like how do you make something as robust as us?"}, {"time": 2142, "text": "Like we're so flawed in so many ways."}, {"time": 2142, "text": "And yet, and yet, you know, we dominate the planet and we do seem to manage to get ourselves out of scrapes eventually, not necessarily the most elegant possible way, but somehow we get, we get to the next step."}, {"time": 2162, "text": "And I don't know how I'd make a machine do that."}, {"time": 2162, "text": "Generally speaking, like if I train one of my reinforcement learning agents to play a video game and it works really hard on that first stage over and over and over again, and it makes it through, it succeeds on that first level."}, {"time": 2177, "text": "And then the new level comes and it's just like, okay, I'm back to the drawing board."}, {"time": 2177, "text": "And somehow humanity, we keep leveling up and then somehow managing to put together the skills necessary to achieve success, some semblance of success in that next level too."}, {"time": 2186, "text": "And, you know, I hope we can keep doing that."}, {"time": 2196, "text": "You mentioned reinforcement learning."}, {"time": 2196, "text": "So you've had a couple of years in the field."}, {"time": 2196, "text": "No, quite, you know, quite a few, quite a long career in artificial intelligence broadly, but reinforcement learning specifically, can you maybe give a hint about your sense of the history of the field?"}, {"time": 2218, "text": "And in some ways it's changed with the advent of deep learning, but as a long roots, like how is it weaved in and out of your own life?"}, {"time": 2225, "text": "How have you seen the community change or maybe the ideas that it's playing with change?"}, {"time": 2229, "text": "I've had the privilege, the pleasure of being, of having almost a front row seat to a lot of this stuff."}, {"time": 2236, "text": "And it's been really, really fun and interesting."}, {"time": 2236, "text": "So when I was in college in the eighties, early eighties, the neural net thing was starting to happen."}, {"time": 2249, "text": "And I was taking a lot of psychology classes and a lot of computer science classes as a college student."}, {"time": 2254, "text": "And I thought, you know, something that can play tic tac toe and just like learn to get better at it."}, {"time": 2258, "text": "That ought to be a really easy thing."}, {"time": 2258, "text": "So I spent almost, almost all of my, what would have been vacations during college, like hacking on my home computer, trying to teach it how to play tic tac toe and programming language."}, {"time": 2268, "text": "That's, that's, I was, I that's my first language."}, {"time": 2273, "text": "That's my native language."}, {"time": 2273, "text": "Is that when you first fell in love with computer science, just like programming basic on that?"}, {"time": 2277, "text": "Uh, what was, what was the computer?"}, {"time": 2277, "text": "I had, I had a TRS 80 model one before they were called model ones."}, {"time": 2282, "text": "Cause there was nothing else."}, {"time": 2282, "text": "Uh, I got my computer in 1979, uh, instead."}, {"time": 2288, "text": "So I was, I was, I would have been bar mitzvahed, but instead of having a big party that my parents threw on my behalf, they just got me a computer."}, {"time": 2303, "text": "Cause that's what I really, really, really wanted."}, {"time": 2303, "text": "I saw them in the, in the, in the mall and radio shack."}, {"time": 2306, "text": "And I thought, what, how are they doing that?"}, {"time": 2306, "text": "I would try to stump them."}, {"time": 2306, "text": "I would give them math problems like one plus and then in parentheses, two plus one."}, {"time": 2312, "text": "And I would always get it right."}, {"time": 2317, "text": "I'm like, how do you know so much?"}, {"time": 2317, "text": "Like I've had to go to algebra class for the last few years to learn this stuff and you just seem to know."}, {"time": 2322, "text": "So I was, I was, I was smitten and, uh, got a computer and I think ages 13 to 15."}, {"time": 2328, "text": "I have no memory of those years."}, {"time": 2328, "text": "I think I just was in my room with the computer, listening to Billy Joel, communing, possibly listening to the radio, listening to Billy Joel."}, {"time": 2339, "text": "That was the one album I had, uh, on vinyl at that time."}, {"time": 2339, "text": "And, um, and then I got it on cassette tape and that was really helpful because then I could play it."}, {"time": 2346, "text": "I didn't have to go down to my parents, wifi or hi fi sorry."}, {"time": 2349, "text": "Uh, and at age 15, I remember kind of walking out and like, okay, I'm ready to talk to people again."}, {"time": 2356, "text": "Like I've learned what I need to learn here."}, {"time": 2360, "text": "And, um, so yeah, so, so that was, that was my home computer."}, {"time": 2360, "text": "And so I went to college and I was like, oh, I'm totally going to study computer science."}, {"time": 2366, "text": "And I opted the college I chose specifically had a computer science major."}, {"time": 2370, "text": "The one that I really wanted the college I really wanted to go to didn't so bye bye to them."}, {"time": 2374, "text": "So I went to Yale, uh, Princeton would have been way more convenient and it was just beautiful campus and it was close enough to home."}, {"time": 2381, "text": "And I was really excited about Princeton."}, {"time": 2385, "text": "And I visited, I said, so computer science majors like, well, we have computer engineering."}, {"time": 2390, "text": "I'm like, Oh, I don't like that word engineering."}, {"time": 2390, "text": "I like computer science."}, {"time": 2395, "text": "I really, I want to do like, you're saying hardware and software."}, {"time": 2395, "text": "They're like, yeah."}, {"time": 2399, "text": "I'm like, I just want to do software."}, {"time": 2399, "text": "I couldn't care less about hardware."}, {"time": 2399, "text": "And you grew up in Philadelphia."}, {"time": 2402, "text": "I grew up outside Philly."}, {"time": 2402, "text": "Uh, so the, you know, local schools were like Penn and Drexel and, uh, temple."}, {"time": 2407, "text": "Like everyone in my family went to temple at least at one point in their lives, except for me."}, {"time": 2412, "text": "So yeah, Philly, Philly family, Yale had a computer science department."}, {"time": 2418, "text": "And that's when you, it's kind of interesting."}, {"time": 2418, "text": "You said eighties and neural networks."}, {"time": 2422, "text": "That's when the neural networks was a hot new thing or a hot thing period."}, {"time": 2422, "text": "Uh, so what is that in college when you first learned about neural networks or when she learned, like how did it was in a psychology class, not in a CS."}, {"time": 2431, "text": "Was it psychology or cognitive science or like, do you remember like what context it was?"}, {"time": 2436, "text": "So, so I was a, I've always been a bit of a cognitive psychology groupie."}, {"time": 2442, "text": "So like I'm, I studied computer science, but I like, I like to hang around where the cognitive scientists are."}, {"time": 2447, "text": "Cause I don't know brains, man."}, {"time": 2452, "text": "They're like, they're wacky."}, {"time": 2452, "text": "And they have a bigger picture view of things."}, {"time": 2452, "text": "They're a little less engineering."}, {"time": 2457, "text": "I would say they're more, they're more interested in the nature of cognition and intelligence and perception and how like the vision system work."}, {"time": 2463, "text": "Like they're asking always bigger questions."}, {"time": 2467, "text": "Now with the deep learning community there, I think more, there's a lot of intersections, but I do find that the neuroscience folks actually in cognitive psychology, cognitive science folks are starting to learn how to program, how to use neural, artificial neural networks."}, {"time": 2487, "text": "And they are actually approaching problems in like totally new, interesting ways."}, {"time": 2487, "text": "It's fun to watch that grad students from those departments, like approach a problem of machine learning."}, {"time": 2497, "text": "They come in with a different perspective."}, {"time": 2497, "text": "They don't care about like your image net data set or whatever they want, like to understand the, the, the, like the basic mechanisms at the, at the neuronal level and the functional level of intelligence."}, {"time": 2507, "text": "It's kind of, it's kind of cool to see them work, but yeah."}, {"time": 2513, "text": "So you always love, you're always a groupie of cognitive psychology."}, {"time": 2518, "text": "And so, so it was in a class by Richard Garrig."}, {"time": 2518, "text": "He was kind of like my favorite psych professor in college."}, {"time": 2524, "text": "And I took like three different classes with him and yeah."}, {"time": 2531, "text": "So they were talking specifically the class, I think was kind of a, there was a big paper that was written by Steven Pinker and Prince."}, {"time": 2537, "text": "I don't, I'm blanking on Prince's first name, but Prince and Pinker and Prince, they wrote kind of a, they were at that time kind of like, ah, I'm blanking on the names of the current people."}, {"time": 2548, "text": "The cognitive scientists who are complaining a lot about deep networks."}, {"time": 2556, "text": "Oh, Gary, Gary Marcus, Marcus and who else?"}, {"time": 2556, "text": "I mean, there's a few, but Gary, Gary's the most feisty."}, {"time": 2564, "text": "Gary's very feisty."}, {"time": 2564, "text": "And with this, with his coauthor, they, they, you know, they're kind of doing these kinds of take downs where they say, okay, well, yeah, it does all these amazing, amazing things, but here's a shortcoming."}, {"time": 2572, "text": "Here's a shortcoming."}, {"time": 2576, "text": "And so the Pinker Prince paper is kind of like the, that generation's version of Marcus and Davis, right?"}, {"time": 2581, "text": "Where they're, they're trained as cognitive scientists, but they're looking skeptically at the results in the, in the artificial intelligence, neural net kind of world and saying, yeah, it can do this and this and this, but low, it can't do that."}, {"time": 2596, "text": "And it can't do that."}, {"time": 2596, "text": "And it can't do that maybe in principle or maybe just in practice at this point."}, {"time": 2600, "text": "But, but the fact of the matter is you're, you've narrowed your focus too far to be impressed."}, {"time": 2606, "text": "You know, you're impressed with the things within that circle, but you need to broaden that circle a little bit."}, {"time": 2610, "text": "You need to look at a wider set of problems."}, {"time": 2614, "text": "And so, so we had, so I was in this seminar in college that was basically a close reading of the Pinker Prince paper, which was like really thick."}, {"time": 2620, "text": "There was a lot going on in there."}, {"time": 2620, "text": "And, and it, you know, and it talked about the reinforcement learning idea a little bit."}, {"time": 2631, "text": "I'm like, oh, that sounds really cool because behavior is what is really interesting to me about psychology anyway."}, {"time": 2635, "text": "So making programs that, I mean, programs are things that behave."}, {"time": 2640, "text": "People are things that behave."}, {"time": 2640, "text": "Like I want to make learning that learns to behave."}, {"time": 2645, "text": "And which way was reinforcement learning presented?"}, {"time": 2645, "text": "Is this talking about human and animal behavior or are we talking about actual mathematical construct?"}, {"time": 2652, "text": "Ah, that's right."}, {"time": 2652, "text": "So this is, I think it wasn't actually talked about as behavior in the paper that I was reading."}, {"time": 2657, "text": "I think that it just talked about learning."}, {"time": 2662, "text": "And to me, learning is about learning to behave, but really neural nets at that point were about learning like supervised learning."}, {"time": 2667, "text": "So learning to produce outputs from inputs."}, {"time": 2671, "text": "So I kind of tried to invent reinforcement learning."}, {"time": 2671, "text": "When I graduated, I joined a research group at Bellcore, which had spun out of Bell Labs recently at that time because of the divestiture of the long distance and local phone service in the 1980s, 1984."}, {"time": 2682, "text": "And I was in a group with Dave Ackley, who was the first author of the Boltzmann machine paper."}, {"time": 2690, "text": "So the very first neural net paper that could handle XOR, right?"}, {"time": 2696, "text": "So XOR sort of killed neural nets."}, {"time": 2696, "text": "The very first, the zero with the first winter."}, {"time": 2702, "text": "Um, the, the perceptrons paper and Hinton along with his student, Dave Ackley, and I think there was other authors as well showed that no, no, no, with Boltzmann machines, we can actually learn nonlinear concepts."}, {"time": 2714, "text": "And so everything's back on the table again."}, {"time": 2719, "text": "And that kind of started that second wave of neural networks."}, {"time": 2719, "text": "So Dave Ackley was, he became my mentor at, at Bellcore and we talked a lot about learning and life and computation and how all these things fit together."}, {"time": 2730, "text": "Now Dave and I have a podcast together."}, {"time": 2730, "text": "So, so I get to kind of enjoy that sort of his, his perspective once again, even, even all these years later."}, {"time": 2742, "text": "And so I said, so I said, I was really interested in learning, but in the concept of behavior and he's like, oh, well that's reinforcement learning here."}, {"time": 2748, "text": "And he gave me Rich Sutton's 1984 TD paper."}, {"time": 2752, "text": "So I read that paper."}, {"time": 2752, "text": "I honestly didn't get all of it, but I got the idea."}, {"time": 2758, "text": "I got that they were using, that he was using ideas that I was familiar with in the context of neural nets and, and like sort of back prop."}, {"time": 2764, "text": "But with this idea of making predictions over time, I'm like, this is so interesting, but I don't really get all the details I said to Dave."}, {"time": 2773, "text": "And Dave said, oh, well, why don't we have him come and give a talk?"}, {"time": 2778, "text": "And I was like, wait, what, you can do that?"}, {"time": 2778, "text": "Like, these are real people."}, {"time": 2778, "text": "I thought they were just words."}, {"time": 2783, "text": "I thought it was just like ideas that somehow magically seeped into paper."}, {"time": 2783, "text": "He's like, no, I, I, I know Rich like, we'll just have him come down and he'll give a talk."}, {"time": 2788, "text": "And so I was, you know, my mind was blown."}, {"time": 2795, "text": "And so Rich came and he gave a talk at Bellcore and he talked about what he was super excited, which was they had just figured out at the time Q learning."}, {"time": 2801, "text": "So Watkins had visited the Rich Sutton's lab at, at UMass or Andy Bartow's lab that Rich was a part of."}, {"time": 2815, "text": "And, um, he was really excited about this because it resolved a whole bunch of problems that he didn't know how to resolve in the, in the earlier paper."}, {"time": 2820, "text": "And so, um, For people who don't know TD, temporal difference, these are all just algorithms for reinforcement learning."}, {"time": 2830, "text": "And TD, temporal difference in particular is about making predictions over time."}, {"time": 2830, "text": "And you can try to use it for making decisions, right?"}, {"time": 2835, "text": "Cause if you can predict how good a future action or an action outcomes will be in the future, you can choose one that has better and, or, but the thing that's really cool about Q learning is it was off policy, which meant that you could actually be learning about the environment and what the value of different actions would be while actually figuring out how to behave optimally."}, {"time": 2853, "text": "So that was a revelation."}, {"time": 2858, "text": "And the proof of that is kind of interesting."}, {"time": 2858, "text": "I mean, that's really surprising to me when I first read that paper."}, {"time": 2861, "text": "I mean, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's interesting."}, {"time": 2871, "text": "I mean, that's really surprising to me when I first read that and then in Richard, Rich Sutton's book on the matter, it's, it's kind of a beautiful that a single equation can capture all one line of code and like, you can learn anything."}, {"time": 2881, "text": "Like enough time."}, {"time": 2886, "text": "So equation and code, you're right."}, {"time": 2886, "text": "Like you can the code that you can arguably, at least if you like squint your eyes can say, this is all of intelligence is that you can implement that in a single one."}, {"time": 2902, "text": "I think I started with Lisp, which is a shout out to Lisp with like a single line of code, key piece of code, maybe a couple that you could do that."}, {"time": 2912, "text": "It's kind of magical."}, {"time": 2913, "text": "It's feels too good to be true."}, {"time": 2917, "text": "Well, and it sort of is."}, {"time": 2918, "text": "Yeah, kind of."}, {"time": 2920, "text": "It seems to require an awful lot of extra stuff supporting it."}, {"time": 2923, "text": "But nonetheless, the idea is really good."}, {"time": 2926, "text": "And as far as we know, it is a very reasonable way of trying to create adaptive behavior, behavior that gets better at something over time."}, {"time": 2936, "text": "Did you find the idea of optimal at all compelling that you could prove that it's optimal?"}, {"time": 2942, "text": "So like one part of computer science that it makes people feel warm and fuzzy inside is when you can prove something like that a sorting algorithm worst case runs and N log N, and it makes everybody feel so good."}, {"time": 2956, "text": "Even though in reality, it doesn't really matter what the worst case is, what matters is like, does this thing actually work in practice on this particular actual set of data that I enjoy?"}, {"time": 2966, "text": "So here's a place where I have maybe a strong opinion, which is like, you're right, of course, but no, no."}, {"time": 2974, "text": "Like, so what makes worst case so great, right?"}, {"time": 2977, "text": "If you have a worst case analysis so great is that you get modularity."}, {"time": 2981, "text": "You can take that thing and plug it into another thing and still have some understanding of what's gonna happen when you click them together, right?"}, {"time": 2989, "text": "If it just works well in practice, in other words, with respect to some distribution that you care about, when you go plug it into another thing, that distribution can shift, it can change, and your thing may not work well anymore."}, {"time": 3000, "text": "And you want it to, and you wish it does, and you hope that it will, but it might not, and then, ah."}, {"time": 3006, "text": "So you're saying you don't like machine learning."}, {"time": 3013, "text": "But we have some positive theoretical results for these things."}, {"time": 3017, "text": "You can come back at me with, yeah, but they're really weak, and yeah, they're really weak."}, {"time": 3022, "text": "And you can even say that sorting algorithms, like if you do the optimal sorting algorithm, it's not really the one that you want, and that might be true as well."}, {"time": 3031, "text": "But it is, the modularity is a really powerful statement."}, {"time": 3034, "text": "I really like that."}, {"time": 3035, "text": "If you're an engineer, you can then assemble different things, you can count on them to be, I mean, it's interesting."}, {"time": 3042, "text": "It's a balance, like with everything else in life, you don't want to get too obsessed."}, {"time": 3047, "text": "I mean, this is what computer scientists do, which they tend to get obsessed, and they overoptimize things, or they start by optimizing, and then they overoptimize."}, {"time": 3056, "text": "So it's easy to get really granular about this thing, but like the step from an n squared to an n log n sorting algorithm is a big leap for most real world systems."}, {"time": 3070, "text": "No matter what the actual behavior of the system is, that's a big leap."}, {"time": 3074, "text": "And the same can probably be said for other kind of first leaps that you would take on a particular problem."}, {"time": 3082, "text": "Like it's picking the low hanging fruit, or whatever the equivalent of doing the, not the dumbest thing, but the next to the dumbest thing."}, {"time": 3092, "text": "Picking the most delicious reachable fruit."}, {"time": 3094, "text": "Yeah, most delicious reachable fruit."}, {"time": 3096, "text": "I don't know why that's not a saying."}, {"time": 3099, "text": "Okay, so then this is the 80s, and this kind of idea starts to percolate of learning."}, {"time": 3107, "text": "At that point, I got to meet Rich Sutton, so everything was sort of downhill from there, and that was really the pinnacle of everything."}, {"time": 3115, "text": "But then I felt like I was kind of on the inside."}, {"time": 3118, "text": "So then as interesting results were happening, I could like check in with Rich or with Jerry Tesaro, who had a huge impact on kind of early thinking in temporal difference learning and reinforcement learning and showed that you could do, you could solve problems that we didn't know how to solve any other way."}, {"time": 3136, "text": "And so that was really cool."}, {"time": 3137, "text": "So as good things were happening, I would hear about it from either the people who were doing it, or the people who were talking to the people who were doing it."}, {"time": 3143, "text": "And so I was able to track things pretty well through the 90s."}, {"time": 3148, "text": "So what wasn't most of the excitement on reinforcement learning in the 90s era with, what is it, TD Gamma?"}, {"time": 3157, "text": "Like what's the role of these kind of little like fun game playing things and breakthroughs about exciting the community?"}, {"time": 3166, "text": "Was that, like what were your, because you've also built across, or part of building across a puzzle solver, solving program called proverb."}, {"time": 3180, "text": "So you were interested in this as a problem, like in forming, using games to understand how to build intelligence systems."}, {"time": 3192, "text": "So like, what did you think about TD Gamma?"}, {"time": 3194, "text": "Like what did you think about that whole thing in the 90s?"}, {"time": 3196, "text": "Yeah, I mean, I found the TD Gamma result really just remarkable."}, {"time": 3200, "text": "So I had known about some of Jerry's stuff before he did TD Gamma and he did a system, just more vanilla, well, not entirely vanilla, but a more classical back proppy kind of network for playing backgammon, where he was training it on expert moves."}, {"time": 3215, "text": "So it was kind of supervised, but the way that it worked was not to mimic the actions, but to learn internally an evaluation function."}, {"time": 3224, "text": "So to learn, well, if the expert chose this over this, that must mean that the expert values this more than this."}, {"time": 3230, "text": "And so let me adjust my weights to make it so that the network evaluates this as being better than this."}, {"time": 3236, "text": "So it could learn from human preferences, it could learn its own preferences."}, {"time": 3242, "text": "And then when he took the step from that to actually doing it as a full on reinforcement learning problem, where you didn't need a trainer, you could just let it play, that was remarkable, right?"}, {"time": 3253, "text": "And so I think as humans often do, as we've done in the recent past as well, people extrapolate."}, {"time": 3262, "text": "It's like, oh, well, if you can do that, which is obviously very hard, then obviously you could do all these other problems that we wanna solve that we know are also really hard."}, {"time": 3271, "text": "And it turned out very few of them ended up being practical, partly because I think neural nets, certainly at the time, were struggling to be consistent and reliable."}, {"time": 3282, "text": "And so training them in a reinforcement learning setting was a bit of a mess."}, {"time": 3286, "text": "I had, I don't know, generation after generation of like master students who wanted to do value function approximation, basically reinforcement learning with neural nets."}, {"time": 3299, "text": "And over and over and over again, we were failing."}, {"time": 3303, "text": "We couldn't get the good results that Jerry Tesaro got."}, {"time": 3306, "text": "I now believe that Jerry is a neural net whisperer."}, {"time": 3309, "text": "He has a particular ability to get neural networks to do things that other people would find impossible."}, {"time": 3318, "text": "And it's not the technology, it's the technology and Jerry together."}, {"time": 3322, "text": "Which I think speaks to the role of the human expert in the process of machine learning."}, {"time": 3328, "text": "Right, it's so easy."}, {"time": 3330, "text": "We're so drawn to the idea that it's the technology that is where the power is coming from that I think we lose sight of the fact that sometimes you need a really good, just like, I mean, no one would think, hey, here's this great piece of software."}, {"time": 3342, "text": "Here's like, I don't know, GNU Emacs or whatever."}, {"time": 3344, "text": "And doesn't that prove that computers are super powerful and basically gonna take over the world?"}, {"time": 3349, "text": "It's like, no, Stalman is a hell of a hacker, right?"}, {"time": 3352, "text": "So he was able to make the code do these amazing things."}, {"time": 3355, "text": "He couldn't have done it without the computer, but the computer couldn't have done it without him."}, {"time": 3359, "text": "And so I think people discount the role of people like Jerry who have just a particular set of skills."}, {"time": 3367, "text": "On that topic, by the way, as a small side note, I tweeted Emacs is greater than Vim yesterday and deleted the tweet 10 minutes later when I realized it started a war."}, {"time": 3381, "text": "I was like, oh, I was just kidding."}, {"time": 3384, "text": "I was just being, and I'm gonna walk back and forth."}, {"time": 3389, "text": "So people still feel passionately about that particular piece of good stuff."}, {"time": 3392, "text": "Yeah, I don't get that because Emacs is clearly so much better, I don't understand."}, {"time": 3397, "text": "But why do I say that?"}, {"time": 3398, "text": "Because I spent a block of time in the 80s making my fingers know the Emacs keys and now that's part of the thought process for me."}, {"time": 3409, "text": "Like I need to express, and if you take that, if you take my Emacs key bindings away, I become..."}, {"time": 3417, "text": "I can't express myself."}, {"time": 3418, "text": "I'm the same way with the, I don't know if you know what it is, but it's a Kinesis keyboard, which is this butt shaped keyboard."}, {"time": 3425, "text": "Yes, I've seen them."}, {"time": 3426, "text": "They're very, I don't know, sexy, elegant?"}, {"time": 3430, "text": "They're just beautiful."}, {"time": 3431, "text": "Yeah, they're gorgeous, way too expensive."}, {"time": 3434, "text": "But the problem with them, similar with Emacs, is once you learn to use it."}, {"time": 3443, "text": "It's harder to use other things."}, {"time": 3444, "text": "It's hard to use other things."}, {"time": 3446, "text": "There's this absurd thing where I have like small, elegant, lightweight, beautiful little laptops and I'm sitting there in a coffee shop with a giant Kinesis keyboard and a sexy little laptop."}, {"time": 3456, "text": "It's absurd, but I used to feel bad about it, but at the same time, you just kind of have to, sometimes it's back to the Billy Joel thing."}, {"time": 3464, "text": "You just have to throw that Billy Joel record and throw Taylor Swift and Justin Bieber to the wind."}, {"time": 3471, "text": "So... See, but I like them now because again, I have no musical taste."}, {"time": 3475, "text": "Like now that I've heard Justin Bieber enough, I'm like, I really like his songs."}, {"time": 3479, "text": "And Taylor Swift, not only do I like her songs, but my daughter's convinced that she's a genius."}, {"time": 3484, "text": "And so now I basically have signed onto that."}, {"time": 3488, "text": "So yeah, that speaks to the, back to the robustness of the human brain."}, {"time": 3491, "text": "That speaks to the neuroplasticity that you can just like a mouse teach yourself to, or probably a dog teach yourself to enjoy Taylor Swift."}, {"time": 3501, "text": "I'll try it out."}, {"time": 3503, "text": "I try, you know what?"}, {"time": 3505, "text": "It has to do with just like acclimation, right?"}, {"time": 3508, "text": "Just like you said, a couple of weeks."}, {"time": 3510, "text": "That's an interesting experiment."}, {"time": 3511, "text": "I'll actually try that."}, {"time": 3512, "text": "Like I'll listen to it."}, {"time": 3513, "text": "That wasn't the intent of the experiment?"}, {"time": 3513, "text": "Just like social media, it wasn't intended as an experiment to see what we can take as a society, but it turned out that way."}, {"time": 3519, "text": "I don't think I'll be the same person on the other side of the week listening to Taylor Swift, but let's try."}, {"time": 3524, "text": "No, it's more compartmentalized."}, {"time": 3525, "text": "Don't be so worried."}, {"time": 3526, "text": "Like it's, like I get that you can be worried, but don't be so worried because we compartmentalize really well."}, {"time": 3531, "text": "And so it won't bleed into other parts of your life."}, {"time": 3533, "text": "You won't start, I don't know, wearing red lipstick or whatever."}, {"time": 3537, "text": "Like it's fine."}, {"time": 3539, "text": "It changed fashion and everything."}, {"time": 3540, "text": "But you know what?"}, {"time": 3541, "text": "The thing you have to watch out for is you'll walk into a coffee shop once we can do that again."}, {"time": 3545, "text": "And recognize the song?"}, {"time": 3546, "text": "And you'll be, no, you won't know that you're singing along until everybody in the coffee shop is looking at you."}, {"time": 3551, "text": "And then you're like, that wasn't me."}, {"time": 3556, "text": "Yeah, that's the, you know, people are afraid of AGI."}, {"time": 3558, "text": "I'm afraid of the Taylor Swift."}, {"time": 3561, "text": "The Taylor Swift takeover."}, {"time": 3562, "text": "Yeah, and I mean, people should know that TD Gammon was, I get, would you call it, do you like the terminology of self play by any chance?"}, {"time": 3571, "text": "So like systems that learn by playing themselves."}, {"time": 3575, "text": "Just, I don't know if it's the best word, but."}, {"time": 3578, "text": "So what's the problem with that term?"}, {"time": 3582, "text": "So it's like the big bang, like it's like talking to a serious physicist."}, {"time": 3586, "text": "Do you like the term big bang?"}, {"time": 3587, "text": "And when it was early, I feel like it's the early days of self play."}, {"time": 3591, "text": "I don't know, maybe it was used previously, but I think it's been used by only a small group of people."}, {"time": 3597, "text": "And so like, I think we're still deciding is this ridiculously silly name a good name for potentially one of the most important concepts in artificial intelligence?"}, {"time": 3607, "text": "Okay, it depends how broadly you apply the term."}, {"time": 3609, "text": "So I used the term in my 1996 PhD dissertation."}, {"time": 3612, "text": "Wow, the actual terms of self play."}, {"time": 3614, "text": "Yeah, because Tesoro's paper was something like training up an expert backgammon player through self play."}, {"time": 3621, "text": "So I think it was in the title of his paper."}, {"time": 3624, "text": "If not in the title, it was definitely a term that he used."}, {"time": 3627, "text": "There's another term that we got from that work is rollout."}, {"time": 3629, "text": "So I don't know if you, do you ever hear the term rollout?"}, {"time": 3632, "text": "That's a backgammon term that has now applied generally in computers, well, at least in AI because of TD gammon."}, {"time": 3641, "text": "So how is self play being used now?"}, {"time": 3643, "text": "And like, why is it, does it feel like a more general powerful concept is sort of the idea of, well, the machine's just gonna teach itself to be smart."}, {"time": 3650, "text": "Yeah, so that's where maybe you can correct me, but that's where the continuation of the spirit and actually like literally the exact algorithms of TD gammon are applied by DeepMind and OpenAI to learn games that are a little bit more complex that when I was learning artificial intelligence, Go was presented to me with artificial intelligence, the modern approach."}, {"time": 3673, "text": "I don't know if they explicitly pointed to Go in those books as like unsolvable kind of thing, like implying that these approaches hit their limit in this, with these particular kind of games."}, {"time": 3686, "text": "So something, I don't remember if the book said it or not, but something in my head, or if it was the professors instilled in me the idea like this is the limits of artificial intelligence of the field."}, {"time": 3698, "text": "Like it instilled in me the idea that if we can create a system that can solve the game of Go we've achieved AGI."}, {"time": 3706, "text": "That was kind of, I didn't explicitly like say this, but that was the feeling."}, {"time": 3711, "text": "And so from, I was one of the people that it seemed magical when a learning system was able to beat a human world champion at the game of Go and even more so from that, that was AlphaGo, even more so with AlphaGo Zero than kind of renamed and advanced into AlphaZero beating a world champion or world class player without any supervised learning on expert games."}, {"time": 3741, "text": "We're doing only through by playing itself."}, {"time": 3744, "text": "So that is, I don't know what to make of it."}, {"time": 3749, "text": "I think it would be interesting to hear what your opinions are on just how exciting, surprising, profound, interesting, or boring the breakthrough performance of AlphaZero was."}, {"time": 3765, "text": "Okay, so AlphaGo knocked my socks off."}, {"time": 3768, "text": "That was so remarkable."}, {"time": 3770, "text": "Which aspect of it?"}, {"time": 3772, "text": "That they got it to work, that they actually were able to leverage a whole bunch of different ideas, integrate them into one giant system."}, {"time": 3781, "text": "Just the software engineering aspect of it is mind blowing."}, {"time": 3784, "text": "I don't, I've never been a part of a program as complicated as the program that they built for that."}, {"time": 3789, "text": "And just the, like Jerry Tesaro is a neural net whisperer, like David Silver is a kind of neural net whisperer too."}, {"time": 3797, "text": "He was able to coax these networks and these new way out there architectures to do these, solve these problems that, as you said, when we were learning from AI, no one had an idea how to make it work."}, {"time": 3812, "text": "It was remarkable that these techniques that were so good at playing chess and that could beat the world champion in chess couldn't beat your typical Go playing teenager in Go."}, {"time": 3826, "text": "So the fact that in a very short number of years, we kind of ramped up to trouncing people in Go just blew me away."}, {"time": 3835, "text": "So you're kind of focusing on the engineering aspect, which is also very surprising."}, {"time": 3840, "text": "I mean, there's something different about large, well funded companies."}, {"time": 3845, "text": "I mean, there's a compute aspect to it too."}, {"time": 3847, "text": "Like that, of course, I mean, that's similar to Deep Blue, right, with IBM."}, {"time": 3854, "text": "Like there's something important to be learned and remembered about a large company taking the ideas that are already out there and investing a few million dollars into it or more."}, {"time": 3866, "text": "And so you're kind of saying the engineering is kind of fascinating, both on the, with AlphaGo is probably just gathering all the data, right, of the expert games, like organizing everything, actually doing distributed supervised learning."}, {"time": 3882, "text": "And to me, see the engineering I kind of took for granted, to me philosophically being able to persist in the face of like long odds, because it feels like for me, I would be one of the skeptical people in the room thinking that you can learn your way to beat Go."}, {"time": 3905, "text": "Like it sounded like, especially with David Silver, it sounded like David was not confident at all."}, {"time": 3911, "text": "So like it was, like not, it's funny how confidence works."}, {"time": 3918, "text": "It's like, you're not like cocky about it, like, but."}, {"time": 3924, "text": "Right, because if you're cocky about it, you kind of stop and stall and don't get anywhere."}, {"time": 3928, "text": "But there's like a hope that's unbreakable."}, {"time": 3931, "text": "Maybe that's better than confidence."}, {"time": 3933, "text": "It's a kind of wishful hope and a little dream."}, {"time": 3936, "text": "And you almost don't want to do anything else."}, {"time": 3938, "text": "You kind of keep doing it."}, {"time": 3940, "text": "That's, that seems to be the story and."}, {"time": 3943, "text": "But with enough skepticism that you're looking for where the problems are and fighting through them."}, {"time": 3948, "text": "Cause you know, there's gotta be a way out of this thing."}, {"time": 3951, "text": "And for him, it was probably, there's a bunch of little factors that come into play."}, {"time": 3955, "text": "It's funny how these stories just all come together."}, {"time": 3957, "text": "Like everything he did in his life came into play, which is like a love for video games and also a connection to, so the nineties had to happen with TD Gammon and so on."}, {"time": 3969, "text": "In some ways it's surprising, maybe you can provide some intuition to it that not much more than TD Gammon was done for quite a long time on the reinforcement learning front."}, {"time": 3979, "text": "Is that weird to you?"}, {"time": 3981, "text": "I mean, like I said, the students who I worked with, we tried to get, basically apply that architecture to other problems and we consistently failed."}, {"time": 3990, "text": "There were a couple of really nice demonstrations that ended up being in the literature."}, {"time": 3995, "text": "There was a paper about controlling elevators, right?"}, {"time": 3998, "text": "Where it's like, okay, can we modify the heuristic that elevators use for deciding, like a bank of elevators for deciding which floors we should be stopping on to maximize throughput essentially."}, {"time": 4010, "text": "And you can set that up as a reinforcement learning problem and you can have a neural net represent the value function so that it's taking where all the elevators, where the button pushes, you know, this high dimensional, well, at the time high dimensional input, you know, a couple of dozen dimensions and turn that into a prediction as to, oh, is it gonna be better if I stop at this floor or not?"}, {"time": 4030, "text": "And ultimately it appeared as though for the standard simulation distribution for people trying to leave the building at the end of the day, that the neural net learned a better strategy than the standard one that's implemented in elevator controllers."}, {"time": 4044, "text": "So that was nice."}, {"time": 4046, "text": "There was some work that Satyendra Singh et al did on handoffs with cell phones, you know, deciding when should you hand off from this cell tower to this cell tower."}, {"time": 4058, "text": "Oh, okay, communication networks, yeah."}, {"time": 4059, "text": "Yeah, and so a couple of things seemed like they were really promising."}, {"time": 4064, "text": "None of them made it into production that I'm aware of."}, {"time": 4066, "text": "And neural nets as a whole started to kind of implode around then."}, {"time": 4070, "text": "And so there just wasn't a lot of air in the room for people to try to figure out, okay, how do we get this to work in the RL setting?"}, {"time": 4078, "text": "And then they found their way back in 10 plus years."}, {"time": 4083, "text": "So you said AlphaGo was impressive, like it's a big spectacle."}, {"time": 4086, "text": "Is there, is that?"}, {"time": 4087, "text": "Right, so then AlphaZero."}, {"time": 4089, "text": "So I think I may have a slightly different opinion on this than some people."}, {"time": 4092, "text": "So I talked to Satyendra Singh in particular about this."}, {"time": 4095, "text": "So Satyendra was like Rich Sutton, a student of Andy Bartow."}, {"time": 4099, "text": "So they came out of the same lab, very influential machine learning, reinforcement learning researcher."}, {"time": 4106, "text": "Now at DeepMind, as is Rich."}, {"time": 4109, "text": "Though different sites, the two of them."}, {"time": 4111, "text": "He's in Alberta."}, {"time": 4113, "text": "Rich is in Alberta and Satyendra would be in England, but I think he's in England from Michigan at the moment."}, {"time": 4119, "text": "But the, but he was, yes, he was much more impressed with AlphaGo Zero, which is didn't get a kind of a bootstrap in the beginning with human trained games."}, {"time": 4131, "text": "It just was purely self play."}, {"time": 4133, "text": "Though the first one AlphaGo was also a tremendous amount of self play, right?"}, {"time": 4138, "text": "They started off, they kickstarted the action network that was making decisions, but then they trained it for a really long time using more traditional temporal difference methods."}, {"time": 4148, "text": "So as a result, I didn't, it didn't seem that different to me."}, {"time": 4151, "text": "Like, it seems like, yeah, why wouldn't that work?"}, {"time": 4155, "text": "Like once you, once it works, it works."}, {"time": 4157, "text": "So what, but he found that removal of that extra information to be breathtaking."}, {"time": 4163, "text": "Like that's a game changer."}, {"time": 4165, "text": "To me, the first thing was more of a game changer."}, {"time": 4167, "text": "But the open question, I mean, I guess that's the assumption is the expert games might contain within them a humongous amount of information."}, {"time": 4179, "text": "But we know that it went beyond that, right?"}, {"time": 4181, "text": "We know that it somehow got away from that information because it was learning strategies."}, {"time": 4185, "text": "I don't think AlphaGo is just better at implementing human strategies."}, {"time": 4190, "text": "I think it actually developed its own strategies that were more effective."}, {"time": 4194, "text": "And so from that perspective, okay, well, so it made at least one quantum leap in terms of strategic knowledge."}, {"time": 4202, "text": "Okay, so now maybe it makes three, like, okay."}, {"time": 4205, "text": "But that first one is the doozy, right?"}, {"time": 4207, "text": "Getting it to work reliably and for the networks to hold onto the value well enough."}, {"time": 4213, "text": "Like that was a big step."}, {"time": 4216, "text": "Well, maybe you could speak to this on the reinforcement learning front."}, {"time": 4219, "text": "So starting from scratch and learning to do something, like the first like random behavior to like crappy behavior to like somewhat okay behavior."}, {"time": 4234, "text": "It's not obvious to me that that's not like impossible to take those steps."}, {"time": 4241, "text": "Like if you just think about the intuition, like how the heck does random behavior become somewhat basic intelligent behavior?"}, {"time": 4251, "text": "Not human level, not superhuman level, but just basic."}, {"time": 4255, "text": "But you're saying to you kind of the intuition is like, if you can go from human to superhuman level intelligence on this particular task of game playing, then so you're good at taking leaps."}, {"time": 4267, "text": "So you can take many of them."}, {"time": 4268, "text": "That the system, I believe that the system can take that kind of leap."}, {"time": 4272, "text": "Yeah, and also I think that beginner knowledge in go, like you can start to get a feel really quickly for the idea that being in certain parts of the board seems to be more associated with winning, right?"}, {"time": 4288, "text": "Cause it's not stumbling upon the concept of winning."}, {"time": 4292, "text": "It's told that it wins or that it loses."}, {"time": 4294, "text": "Well, it's self play."}, {"time": 4295, "text": "So it both wins and loses."}, {"time": 4296, "text": "It's told which side won."}, {"time": 4299, "text": "And the information is kind of there to start percolating around to make a difference as to, well, these things have a better chance of helping you win."}, {"time": 4308, "text": "And these things have a worse chance of helping you win."}, {"time": 4310, "text": "And so it can get to basic play, I think pretty quickly."}, {"time": 4314, "text": "Then once it has basic play, well now it's kind of forced to do some search to actually experiment with, okay, well what gets me that next increment of improvement?"}, {"time": 4324, "text": "How far do you think, okay, this is where you kind of bring up the Elon Musk and the Sam Harris, right?"}, {"time": 4330, "text": "How far is your intuition about these kinds of self play mechanisms being able to take us?"}, {"time": 4336, "text": "Cause it feels, one of the ominous but stated calmly things that when I talked to David Silver, he said, is that they have not yet discovered a ceiling for Alpha Zero, for example, in the game of Go or chess."}, {"time": 4352, "text": "Like it keeps, no matter how much they compute, they throw at it, it keeps improving."}, {"time": 4357, "text": "So it's possible, it's very possible that if you throw, you know, some like 10 X compute that it will improve by five X or something like that."}, {"time": 4368, "text": "And when stated calmly, it's so like, oh yeah, I guess so."}, {"time": 4374, "text": "But like, and then you think like, well, can we potentially have like continuations of Moore's law in totally different way, like broadly defined Moore's law, not the exponential improvement, like, are we going to have an Alpha Zero that swallows the world?"}, {"time": 4393, "text": "But notice it's not getting better at other things."}, {"time": 4395, "text": "It's getting better at Go."}, {"time": 4396, "text": "And I think that's a big leap to say, okay, well, therefore it's better at other things."}, {"time": 4402, "text": "Well, I mean, the question is how much of the game of life can be turned into."}, {"time": 4407, "text": "Right, so that I think is a really good question."}, {"time": 4410, "text": "And I think that we don't, I don't think we as a, I don't know, community really know the answer to this, but so, okay, so I went to a talk by some experts on computer chess."}, {"time": 4423, "text": "So in particular, computer chess is really interesting because for, of course, for a thousand years, humans were the best chess playing things on the planet."}, {"time": 4432, "text": "And then computers like edged ahead of the best person."}, {"time": 4436, "text": "And they've been ahead ever since."}, {"time": 4437, "text": "It's not like people have overtaken computers."}, {"time": 4441, "text": "But computers and people together have overtaken computers."}, {"time": 4447, "text": "So at least last time I checked, I don't know what the very latest is, but last time I checked that there were teams of people who could work with computer programs to defeat the best computer programs."}, {"time": 4457, "text": "In the game of Go?"}, {"time": 4458, "text": "In the game of chess."}, {"time": 4460, "text": "Right, and so using the information about how, these things called ELO scores, this sort of notion of how strong a player are you."}, {"time": 4470, "text": "There's kind of a range of possible scores."}, {"time": 4472, "text": "And you increment in score, basically if you can beat another player of that lower score 62% of the time or something like that."}, {"time": 4481, "text": "Like there's some threshold of if you can somewhat consistently beat someone, then you are of a higher score than that person."}, {"time": 4488, "text": "And there's a question as to how many times can you do that in chess, right?"}, {"time": 4492, "text": "And so we know that there's a range of human ability levels that cap out with the best playing humans."}, {"time": 4497, "text": "And the computers went a step beyond that."}, {"time": 4500, "text": "And computers and people together have not gone, I think a full step beyond that."}, {"time": 4505, "text": "It feels, the estimates that they have is that it's starting to asymptote."}, {"time": 4509, "text": "That we've reached kind of the maximum, the best possible chess playing."}, {"time": 4513, "text": "And so that means that there's kind of a finite strategic depth, right?"}, {"time": 4518, "text": "At some point you just can't get any better at this game."}, {"time": 4521, "text": "Yeah, I mean, I don't, so I'll actually check that."}, {"time": 4525, "text": "I think it's interesting because if you have somebody like Magnus Carlsen, who's using these chess programs to train his mind, like to learn about chess."}, {"time": 4537, "text": "To become a better chess player, yeah."}, {"time": 4538, "text": "And so like, that's a very interesting thing because we're not static creatures."}, {"time": 4543, "text": "We're learning together."}, {"time": 4545, "text": "I mean, just like we're talking about social networks, those algorithms are teaching us just like we're teaching those algorithms."}, {"time": 4551, "text": "So that's a fascinating thing."}, {"time": 4552, "text": "But I think the best chess playing programs are now better than the pairs."}, {"time": 4558, "text": "Like they have competition between pairs, but it's still, even if they weren't, it's an interesting question, where's the ceiling?"}, {"time": 4566, "text": "So the David, the ominous David Silver kind of statement is like, we have not found the ceiling."}, {"time": 4572, "text": "Right, so the question is, okay, so I don't know his analysis on that."}, {"time": 4576, "text": "My, from talking to Go experts, the depth, the strategic depth of Go seems to be substantially greater than that of chess."}, {"time": 4585, "text": "That there's more kind of steps of improvement that you can make, getting better and better and better and better."}, {"time": 4590, "text": "But there's no reason to think that it's infinite."}, {"time": 4592, "text": "Infinite, yeah."}, {"time": 4593, "text": "And so it could be that what David is seeing is a kind of asymptoting that you can keep getting better, but with diminishing returns."}, {"time": 4601, "text": "And at some point you hit optimal play."}, {"time": 4603, "text": "Like in theory, all these finite games, they're finite."}, {"time": 4607, "text": "They have an optimal strategy."}, {"time": 4609, "text": "There's a strategy that is the minimax optimal strategy."}, {"time": 4611, "text": "And so at that point, you can't get any better."}, {"time": 4614, "text": "You can't beat that strategy."}, {"time": 4616, "text": "Now that strategy may be, from an information processing perspective, intractable."}, {"time": 4622, "text": "Right, you need, all the situations are sufficiently different that you can't compress it at all."}, {"time": 4628, "text": "It's this giant mess of hardcoded rules."}, {"time": 4632, "text": "And we can never achieve that."}, {"time": 4634, "text": "But that still puts a cap on how many levels of improvement that we can actually make."}, {"time": 4639, "text": "But the thing about self play is if you put it, although I don't like doing that, in the broader category of self supervised learning, is that it doesn't require too much or any human input."}, {"time": 4651, "text": "Human labeling, yeah."}, {"time": 4652, "text": "Yeah, human label or just human effort."}, {"time": 4654, "text": "The human involvement passed a certain point."}, {"time": 4657, "text": "And the same thing you could argue is true for the recent breakthroughs in natural language processing with language models."}, {"time": 4665, "text": "Oh, this is how you get to GPT3."}, {"time": 4667, "text": "Yeah, see how that did the."}, {"time": 4669, "text": "That was a good transition."}, {"time": 4671, "text": "Yeah, I practiced that for days leading up to this now."}, {"time": 4676, "text": "But like that's one of the questions is, can we find ways to formulate problems in this world that are important to us humans, like more important than the game of chess, that to which self supervised kinds of approaches could be applied?"}, {"time": 4736, "text": "So what's your intuition, like trying to stitch all of it together about our discussion of AGI, the limits of self play, and your thoughts about maybe the limits of neural networks in the context of language models."}, {"time": 4753, "text": "Is there some intuition in there that might be useful to think about?"}, {"time": 4757, "text": "So first of all, the whole Transformer network family of things is really cool."}, {"time": 4766, "text": "It's really, really cool."}, {"time": 4768, "text": "I mean, if you've ever, back in the day you played with, I don't know, Markov models for generating texts, and you've seen the kind of texts that they spit out, and you compare it to what's happening now, it's amazing, it's so amazing."}, {"time": 4781, "text": "Now, it doesn't take very long interacting with one of these systems before you find the holes, right?"}, {"time": 4787, "text": "It's not smart in any kind of general way."}, {"time": 4793, "text": "It's really good at a bunch of things."}, {"time": 4795, "text": "And it does seem to understand a lot of the statistics of language extremely well."}, {"time": 4799, "text": "And that turns out to be very powerful."}, {"time": 4801, "text": "You can answer many questions with that."}, {"time": 4804, "text": "But it doesn't make it a good conversationalist, right?"}, {"time": 4806, "text": "And it doesn't make it a good storyteller."}, {"time": 4808, "text": "It just makes it good at imitating of things that is seen in the past."}, {"time": 4812, "text": "The exact same thing could be said by people who are voting for Donald Trump about Joe Biden supporters, and people voting for Joe Biden about Donald Trump supporters is, you know."}, {"time": 4822, "text": "That they're not intelligent, they're just following the."}, {"time": 4825, "text": "Yeah, they're following things they've seen in the past."}, {"time": 4827, "text": "And it doesn't take long to find the flaws in their natural language generation abilities."}, {"time": 4837, "text": "So we're being very."}, {"time": 4839, "text": "Critical of AI systems."}, {"time": 4841, "text": "Right, so I've had a similar thought, which was that the stories that GPT3 spits out are amazing and very humanlike."}, {"time": 4852, "text": "And it doesn't mean that computers are smarter than we realize necessarily."}, {"time": 4857, "text": "It partly means that people are dumber than we realize."}, {"time": 4860, "text": "Or that much of what we do day to day is not that deep."}, {"time": 4864, "text": "Like we're just kind of going with the flow."}, {"time": 4867, "text": "We're saying whatever feels like the natural thing to say next."}, {"time": 4870, "text": "Not a lot of it is creative or meaningful or intentional."}, {"time": 4877, "text": "But enough is that we actually get by, right?"}, {"time": 4880, "text": "We do come up with new ideas sometimes, and we do manage to talk each other into things sometimes."}, {"time": 4884, "text": "And we do sometimes vote for reasonable people sometimes."}, {"time": 4889, "text": "But it's really hard to see in the statistics because so much of what we're saying is kind of rote."}, {"time": 4895, "text": "And so our metrics that we use to measure how these systems are doing don't reveal that because it's in the interstices that is very hard to detect."}, {"time": 4907, "text": "But is your, do you have an intuition that with these language models, if they grow in size, it's already surprising when you go from GPT2 to GPT3 that there is a noticeable improvement."}, {"time": 4919, "text": "So the question now goes back to the ominous David Silver and the ceiling."}, {"time": 4923, "text": "Right, so maybe there's just no ceiling."}, {"time": 4924, "text": "We just need more compute."}, {"time": 4926, "text": "Now, I mean, okay, so now I'm speculating."}, {"time": 4931, "text": "As opposed to before when I was completely on firm ground."}, {"time": 4933, "text": "All right, I don't believe that you can get something that really can do language and use language as a thing that doesn't interact with people."}, {"time": 4944, "text": "Like I think that it's not enough to just take everything that we've said written down and just say, that's enough."}, {"time": 4949, "text": "You can just learn from that and you can be intelligent."}, {"time": 4952, "text": "I think you really need to be pushed back at."}, {"time": 4955, "text": "I think that conversations, even people who are pretty smart, maybe the smartest thing that we know, maybe not the smartest thing we can imagine, but we get so much benefit out of talking to each other and interacting."}, {"time": 4968, "text": "That's presumably why you have conversations live with guests is that there's something in that interaction that would not be exposed by, oh, I'll just write you a story and then you can read it later."}, {"time": 4978, "text": "And I think because these systems are just learning from our stories, they're not learning from being pushed back at by us, that they're fundamentally limited into what they can actually become on this route."}, {"time": 4988, "text": "They have to get shut down."}, {"time": 4992, "text": "Like we have to have an argument, they have to have an argument with us and lose a couple of times before they start to realize, oh, okay, wait, there's some nuance here that actually matters."}, {"time": 5003, "text": "Yeah, that's actually subtle sounding, but quite profound that the interaction with humans is essential and the limitation within that is profound as well because the timescale, like the bandwidth at which you can really interact with humans is very low."}, {"time": 5023, "text": "So it's costly."}, {"time": 5024, "text": "So you can't, one of the underlying things about self plays, it has to do a very large number of interactions."}, {"time": 5033, "text": "And so you can't really deploy reinforcement learning systems into the real world to interact."}, {"time": 5038, "text": "Like you couldn't deploy a language model into the real world to interact with humans because it was just not getting enough data relative to the cost it takes to interact."}, {"time": 5049, "text": "Like the time of humans is expensive, which is really interesting."}, {"time": 5053, "text": "That takes us back to reinforcement learning and trying to figure out if there's ways to make algorithms that are more efficient at learning, keep the spirit in reinforcement learning and become more efficient."}, {"time": 5066, "text": "In some sense, that seems to be the goal."}, {"time": 5068, "text": "I'd love to hear what your thoughts are."}, {"time": 5071, "text": "I don't know if you got a chance to see the blog post called Bitter Lesson."}, {"time": 5077, "text": "By Rich Sutton that makes an argument, hopefully I can summarize it."}, {"time": 5081, "text": "Perhaps you can."}, {"time": 5083, "text": "Yeah, but do you want?"}, {"time": 5085, "text": "So I mean, I could try and you can correct me, which is he makes an argument that it seems if we look at the long arc of the history of the artificial intelligence field, he calls 70 years that the algorithms from which we've seen the biggest improvements in practice are the very simple, like dumb algorithms that are able to leverage computation."}, {"time": 5108, "text": "And you just wait for the computation to improve."}, {"time": 5111, "text": "Like all of the academics and so on have fun by finding little tricks and congratulate themselves on those tricks."}, {"time": 5117, "text": "And sometimes those tricks can be like big, that feel in the moment like big spikes and breakthroughs, but in reality over the decades, it's still the same dumb algorithm that just waits for the compute to get faster and faster."}, {"time": 5131, "text": "Do you find that to be an interesting argument against the entirety of the field of machine learning as an academic discipline?"}, {"time": 5141, "text": "That we're really just a subfield of computer architecture."}, {"time": 5144, "text": "We're just kind of waiting around for them to do their next thing."}, {"time": 5146, "text": "Who really don't want to do hardware work."}, {"time": 5149, "text": "I really don't want to think about it."}, {"time": 5150, "text": "We're procrastinating."}, {"time": 5151, "text": "Yes, that's right, just waiting for them to do their jobs so that we can pretend to have done ours."}, {"time": 5155, "text": "So yeah, I mean, the argument reminds me a lot of, I think it was a Fred Jelinek quote, early computational linguist who said, we're building these computational linguistic systems and every time we fire a linguist performance goes up by 10%, something like that."}, {"time": 5173, "text": "And so the idea of us building the knowledge in, in that case was much less, he was finding it to be much less successful than get rid of the people who know about language as a, from a kind of scholastic academic kind of perspective and replace them with more compute."}, {"time": 5192, "text": "And so I think this is kind of a modern version of that story, which is, okay, we want to do better on machine vision."}, {"time": 5198, "text": "You could build in all these, motivated part based models that, that just feel like obviously the right thing that you have to have, or we can throw a lot of data at it and guess what we're doing better with a lot of data."}, {"time": 5212, "text": "So I hadn't thought about it until this moment in this way, but what I believe, well, I've thought about what I believe."}, {"time": 5220, "text": "What I believe is that, you know, compositionality and what's the right way to say it, the complexity grows rapidly as you consider more and more possibilities, like explosively."}, {"time": 5236, "text": "And so far Moore's law has also been growing explosively exponentially."}, {"time": 5241, "text": "And so it really does seem like, well, we don't have to think really hard about the algorithm design or the way that we build the systems, because the best benefit we could get is exponential."}, {"time": 5252, "text": "And the best benefit that we can get from waiting is exponential."}, {"time": 5255, "text": "So we can just wait."}, {"time": 5258, "text": "It's got, that's gotta end, right?"}, {"time": 5259, "text": "And there's hints now that, that Moore's law is starting to feel some friction, starting to, the world is pushing back a little bit."}, {"time": 5268, "text": "One thing that I don't know, do lots of people know this?"}, {"time": 5270, "text": "I didn't know this, I was trying to write an essay and yeah, Moore's law has been amazing and it's enabled all sorts of things, but there's also a kind of counter Moore's law, which is that the development cost for each successive generation of chips also is doubling."}, {"time": 5287, "text": "So it's costing twice as much money."}, {"time": 5289, "text": "So the amount of development money per cycle or whatever is actually sort of constant."}, {"time": 5294, "text": "And at some point we run out of money."}, {"time": 5297, "text": "So, or we have to come up with an entirely different way of doing the development process."}, {"time": 5302, "text": "So like, I guess I always a bit skeptical of the look, it's an exponential curve, therefore it has no end."}, {"time": 5308, "text": "Soon the number of people going to NeurIPS will be greater than the population of the earth."}, {"time": 5312, "text": "That means we're gonna discover life on other planets."}, {"time": 5315, "text": "No, it doesn't."}, {"time": 5316, "text": "It means that we're in a sigmoid curve on the front half, which looks a lot like an exponential."}, {"time": 5322, "text": "The second half is gonna look a lot like diminishing returns."}, {"time": 5326, "text": "Yeah, I mean, but the interesting thing about Moore's law, if you actually like look at the technologies involved, it's hundreds, if not thousands of S curves stacked on top of each other."}, {"time": 5336, "text": "It's not actually an exponential curve, it's constant breakthroughs."}, {"time": 5341, "text": "And then what becomes useful to think about, which is exactly what you're saying, the cost of development, like the size of teams, the amount of resources that are invested in continuing to find new S curves, new breakthroughs."}, {"time": 5354, "text": "And yeah, it's an interesting idea."}, {"time": 5359, "text": "If we live in the moment, if we sit here today, it seems to be the reasonable thing to say that exponentials end."}, {"time": 5369, "text": "And yet in the software realm, they just keep appearing to be happening."}, {"time": 5374, "text": "And it's so, I mean, it's so hard to disagree with Elon Musk on this."}, {"time": 5381, "text": "Because it like, I've, you know, I used to be one of those folks, I'm still one of those folks that studied autonomous vehicles, that's what I worked on."}, {"time": 5392, "text": "And it's like, you look at what Elon Musk is saying about autonomous vehicles, well, obviously, in a couple of years, or in a year, or next month, we'll have fully autonomous vehicles."}, {"time": 5403, "text": "Like there's no reason why we can't."}, {"time": 5404, "text": "Driving is pretty simple, like it's just a learning problem and you just need to convert all the driving that we're doing into data and just having you all know with the trains on that data."}, {"time": 5414, "text": "And like, we use only our eyes, so you can use cameras and you can train on it."}, {"time": 5420, "text": "And it's like, yeah, that should work."}, {"time": 5426, "text": "And then you put that hat on, like the philosophical hat, and but then you put the pragmatic hat and it's like, this is what the flaws of computer vision are."}, {"time": 5433, "text": "Like, this is what it means to train at scale."}, {"time": 5435, "text": "And then you put the human factors, the psychology hat on, which is like, it's actually driving us a lot, the cognitive science or cognitive, whatever the heck you call it, it's really hard, it's much harder to drive than we realize, there's a much larger number of edge cases."}, {"time": 5453, "text": "So building up an intuition around this is, around exponentials is really difficult."}, {"time": 5459, "text": "And on top of that, the pandemic is making us think about exponentials, making us realize that like, we don't understand anything about it, we're not able to intuit exponentials, we're either ultra terrified, some part of the population and some part is like the opposite of whatever the different carefree and we're not managing it very well."}, {"time": 5484, "text": "Blase, well, wow, is that French?"}, {"time": 5488, "text": "I assume so, it's got an accent."}, {"time": 5489, "text": "So it's fascinating to think what the limits of this exponential growth of technology, not just Moore's law, it's technology, how that rubs up against the bitter lesson and GPT three and self play mechanisms."}, {"time": 5513, "text": "Like it's not obvious, I used to be much more skeptical about neural networks."}, {"time": 5518, "text": "Now I at least give a slither of possibility that we'll be very much surprised and also caught in a way that like, we are not prepared for."}, {"time": 5534, "text": "Like in applications of social networks, for example, cause it feels like really good transformer models that are able to do some kind of like very good natural language generation of the same kind of models that can be used to learn human behavior and then manipulate that human behavior to gain advertisers dollars and all those kinds of things through the capitalist system."}, {"time": 5561, "text": "And they arguably already are manipulating human behavior."}, {"time": 5566, "text": "But not for self preservation, which I think is a big, that would be a big step."}, {"time": 5572, "text": "Like if they were trying to manipulate us to convince us not to shut them off, I would be very freaked out."}, {"time": 5578, "text": "But I don't see a path to that from where we are now."}, {"time": 5581, "text": "They don't have any of those abilities."}, {"time": 5585, "text": "That's not what they're trying to do."}, {"time": 5587, "text": "They're trying to keep people on the site."}, {"time": 5590, "text": "But see the thing is, this is the thing about life on earth is they might be borrowing our consciousness and sentience like, so like in a sense they do because the creators of the algorithms have, like they're not, if you look at our body, we're not a single organism."}, {"time": 5608, "text": "We're a huge number of organisms with like tiny little motivations were built on top of each other."}, {"time": 5613, "text": "In the same sense, the AI algorithms that are, they're not like."}, {"time": 5617, "text": "It's a system that includes companies and corporations, because corporations are funny organisms in and of themselves that really do seem to have self preservation built in."}, {"time": 5625, "text": "And I think that's at the design level."}, {"time": 5628, "text": "I think they're designed to have self preservation to be a focus."}, {"time": 5633, "text": "In that broader system that we're also a part of and can have some influence on, it is much more complicated, much more powerful."}, {"time": 5644, "text": "Yeah, I agree with that."}, {"time": 5646, "text": "So people really love it when I ask, what three books, technical, philosophical, fiction had a big impact on your life?"}, {"time": 5654, "text": "Maybe you can recommend."}, {"time": 5656, "text": "We went with movies, we went with Billy Joe and I forgot what music you recommended, but."}, {"time": 5664, "text": "I didn't, I just said I have no taste in music."}, {"time": 5666, "text": "I just like pop music."}, {"time": 5667, "text": "That was actually really skillful the way you avoided that question."}, {"time": 5670, "text": "Thank you, thanks."}, {"time": 5671, "text": "I'm gonna try to do the same with the books."}, {"time": 5673, "text": "So do you have a skillful way to avoid answering the question about three books you would recommend?"}, {"time": 5679, "text": "I'd like to tell you a story."}, {"time": 5682, "text": "So my first job out of college was at Bellcore."}, {"time": 5685, "text": "I mentioned that before, where I worked with Dave Ackley."}, {"time": 5688, "text": "The head of the group was a guy named Tom Landauer."}, {"time": 5690, "text": "And I don't know how well known he's known now, but arguably he's the inventor and the first proselytizer of word embeddings."}, {"time": 5699, "text": "So they developed a system shortly before I got to the group that was called latent semantic analysis that would take words of English and embed them in multi hundred dimensional space and then use that as a way of assessing similarity and basically doing reinforcement learning, I'm sorry, not reinforcement, information retrieval, sort of pre Google information retrieval."}, {"time": 5723, "text": "And he was trained as an anthropologist, but then became a cognitive scientist."}, {"time": 5729, "text": "So I was in the cognitive science research group."}, {"time": 5732, "text": "Like I said, I'm a cognitive science groupie."}, {"time": 5734, "text": "At the time I thought I'd become a cognitive scientist, but then I realized in that group, no, I'm a computer scientist, but I'm a computer scientist who really loves to hang out with cognitive scientists."}, {"time": 5743, "text": "And he said, he studied language acquisition in particular."}, {"time": 5748, "text": "He said, you know, humans have about this number of words of vocabulary and most of that is learned from reading."}, {"time": 5755, "text": "And I said, that can't be true because I have a really big vocabulary and I don't read."}, {"time": 5760, "text": "He's like, you must."}, {"time": 5761, "text": "I'm like, I don't think I do."}, {"time": 5763, "text": "I mean like stop signs, I definitely read stop signs, but like reading books is not a thing that I do a lot of."}, {"time": 5769, "text": "It might be just visual, maybe the red color."}, {"time": 5772, "text": "Do I read stop signs?"}, {"time": 5774, "text": "No, it's just pattern recognition at this point."}, {"time": 5775, "text": "I don't sound it out."}, {"time": 5779, "text": "So now I do."}, {"time": 5781, "text": "I wonder what that, oh yeah, stop the guns."}, {"time": 5787, "text": "So you don't."}, {"time": 5788, "text": "So I don't read very, I mean, obviously I read and I've read plenty of books, but like some people like Charles, my friend Charles and others, like a lot of people in my field, a lot of academics, like reading was really a central topic to them in development and I'm not that guy."}, {"time": 5805, "text": "In fact, I used to joke that when I got into college, that it was on kind of a help out the illiterate kind of program because I got to, like in my house, I wasn't a particularly bad or good reader, but when I got to college, I was surrounded by these people that were just voracious in their reading appetite."}, {"time": 5823, "text": "And they would like, have you read this?"}, {"time": 5824, "text": "Have you read this?"}, {"time": 5826, "text": "And I'm like, no, I'm clearly not qualified to be at this school."}, {"time": 5830, "text": "Like there's no way I should be here."}, {"time": 5831, "text": "Now I've discovered books on tape, like audio books."}, {"time": 5834, "text": "And so I'm much better."}, {"time": 5837, "text": "I'm more caught up."}, {"time": 5838, "text": "I read a lot of books."}, {"time": 5840, "text": "The small tangent on that, it is a fascinating open question to me on the topic of driving."}, {"time": 5847, "text": "Whether, you know, supervised learning people, machine learning people think you have to like drive to learn how to drive."}, {"time": 5855, "text": "To me, it's very possible that just by us humans, by first of all, walking, but also by watching other people drive, not even being inside cars as a passenger, but let's say being inside the car as a passenger, but even just like being a pedestrian and crossing the road, you learn so much about driving from that."}, {"time": 5876, "text": "It's very possible that you can, without ever being inside of a car, be okay at driving once you get in it."}, {"time": 5884, "text": "Or like watching a movie, for example."}, {"time": 5886, "text": "I don't know, something like that."}, {"time": 5888, "text": "Have you taught anyone to drive?"}, {"time": 5891, "text": "No, except myself."}, {"time": 5893, "text": "I have two children."}, {"time": 5895, "text": "And I learned a lot about car driving because my wife doesn't want to be the one in the car while they're learning."}, {"time": 5901, "text": "So that's my job."}, {"time": 5902, "text": "So I sit in the passenger seat and it's really scary."}, {"time": 5907, "text": "You know, I have wishes to live and they're figuring things out."}, {"time": 5912, "text": "Now, they start off very much better than I imagine like a neural network would, right?"}, {"time": 5919, "text": "They get that they're seeing the world."}, {"time": 5921, "text": "They get that there's a road that they're trying to be on."}, {"time": 5924, "text": "They get that there's a relationship between the angle of the steering, but it takes a while to not be very jerky."}, {"time": 5931, "text": "And so that happens pretty quickly."}, {"time": 5932, "text": "Like the ability to stay in lane at speed, that happens relatively fast."}, {"time": 5936, "text": "It's not zero shot learning, but it's pretty fast."}, {"time": 5940, "text": "The thing that's remarkably hard, and this is I think partly why self driving cars are really hard, is the degree to which driving is a social interaction activity."}, {"time": 5949, "text": "And that blew me away."}, {"time": 5950, "text": "I was completely unaware of it until I watched my son learning to drive."}, {"time": 5954, "text": "And I was realizing that he was sending signals to all the cars around him."}, {"time": 5959, "text": "And those in his case, he's always had social communication challenges."}, {"time": 5965, "text": "He was sending very mixed confusing signals to the other cars."}, {"time": 5969, "text": "And that was causing the other cars to drive weirdly and erratically."}, {"time": 5972, "text": "And there was no question in my mind that he would have an accident because they didn't know how to read him."}, {"time": 5979, "text": "There's things you do with the speed that you drive, the positioning of your car, that you're constantly like in the head of the other drivers."}, {"time": 5987, "text": "And seeing him not knowing how to do that and having to be taught explicitly, okay, you have to be thinking about what the other driver is thinking, was a revelation to me."}, {"time": 5997, "text": "I was stunned."}, {"time": 5998, "text": "So creating kind of theories of mind of the other."}, {"time": 6002, "text": "Theories of mind of the other cars."}, {"time": 6005, "text": "Which I just hadn't heard discussed in the self driving car talks that I've been to."}, {"time": 6009, "text": "Since then, there's some people who do consider those kinds of issues, but it's way more subtle than I think there's a little bit of work involved with that when you realize like when you especially focus not on other cars, but on pedestrians, for example, it's literally staring you in the face."}, {"time": 6027, "text": "So then when you're just like, how do I interact with pedestrians?"}, {"time": 6032, "text": "Pedestrians, you're practically talking to an octopus at that point."}, {"time": 6034, "text": "They've got all these weird degrees of freedom."}, {"time": 6036, "text": "You don't know what they're gonna do."}, {"time": 6037, "text": "They can turn around any second."}, {"time": 6038, "text": "But the point is, we humans know what they're gonna do."}, {"time": 6042, "text": "Like we have a good theory of mind."}, {"time": 6043, "text": "We have a good mental model of what they're doing."}, {"time": 6046, "text": "And we have a good model of the model they have a view and the model of the model of the model."}, {"time": 6052, "text": "Like we're able to kind of reason about this kind of, the social like game of it all."}, {"time": 6059, "text": "The hope is that it's quite simple actually, that it could be learned."}, {"time": 6064, "text": "That's why I just talked to the Waymo."}, {"time": 6066, "text": "I don't know if you know that company."}, {"time": 6067, "text": "It's Google South Africa."}, {"time": 6069, "text": "They, I talked to their CTO about this podcast and they like, I rode in their car and it's quite aggressive and it's quite fast and it's good and it feels great."}, {"time": 6080, "text": "It also, just like Tesla, Waymo made me change my mind about like, maybe driving is easier than I thought."}, {"time": 6087, "text": "Maybe I'm just being speciest, human centric, maybe."}, {"time": 6093, "text": "It's a speciest argument."}, {"time": 6095, "text": "Yeah, so I don't know."}, {"time": 6096, "text": "But it's fascinating to think about like the same as with reading, which I think you just said."}, {"time": 6103, "text": "You avoided the question, though I still hope you answered it somewhat."}, {"time": 6107, "text": "You avoided it brilliantly."}, {"time": 6108, "text": "It is, there's blind spots as artificial intelligence, that artificial intelligence researchers have about what it actually takes to learn to solve a problem."}, {"time": 6119, "text": "Have you had Anca Dragan on?"}, {"time": 6122, "text": "She's one of my favorites."}, {"time": 6123, "text": "So much energy."}, {"time": 6124, "text": "She's right."}, {"time": 6125, "text": "She's amazing."}, {"time": 6127, "text": "And in particular, she thinks a lot about this kind of, I know that you know that I know kind of planning."}, {"time": 6132, "text": "And the last time I spoke with her, she was very articulate about the ways in which self driving cars are not solved."}, {"time": 6140, "text": "Like what's still really, really hard."}, {"time": 6142, "text": "But even her intuition is limited."}, {"time": 6143, "text": "Like we're all like new to this."}, {"time": 6146, "text": "So in some sense, the Elon Musk approach of being ultra confident and just like plowing."}, {"time": 6150, "text": "Put it out there."}, {"time": 6151, "text": "Putting it out there."}, {"time": 6152, "text": "Like some people say it's reckless and dangerous and so on."}, {"time": 6155, "text": "But like, partly it's like, it seems to be one of the only ways to make progress in artificial intelligence."}, {"time": 6161, "text": "So it's, you know, these are difficult things."}, {"time": 6165, "text": "You know, democracy is messy."}, {"time": 6169, "text": "Implementation of artificial intelligence systems in the real world is messy."}, {"time": 6173, "text": "So many years ago, before self driving cars were an actual thing you could have a discussion about, somebody asked me, like, what if we could use that robotic technology and use it to drive cars around?"}, {"time": 6184, "text": "Like, isn't that, aren't people gonna be killed?"}, {"time": 6186, "text": "And then it's not, you know, blah, blah, blah."}, {"time": 6188, "text": "I'm like, that's not what's gonna happen."}, {"time": 6189, "text": "I said with confidence, incorrectly, obviously."}, {"time": 6193, "text": "What I think is gonna happen is we're gonna have a lot more, like a very gradual kind of rollout where people have these cars in like closed communities, right, where it's somewhat realistic, but it's still in a box, right?"}, {"time": 6206, "text": "So that we can really get a sense of what, what are the weird things that can happen?"}, {"time": 6210, "text": "How do we, how do we have to change the way we behave around these vehicles?"}, {"time": 6215, "text": "Like, it's obviously requires a kind of co evolution that you can't just plop them in and see what happens."}, {"time": 6222, "text": "But of course, we're basically popping them in and see what happens."}, {"time": 6225, "text": "So I was wrong, but I do think that would have been a better plan."}, {"time": 6227, "text": "So that's, but your intuition, that's funny, just zooming out and looking at the forces of capitalism."}, {"time": 6234, "text": "And it seems that capitalism rewards risk takers and rewards and punishes risk takers, like, and like, try it out."}, {"time": 6243, "text": "The academic approach to let's try a small thing and try to understand slowly the fundamentals of the problem."}, {"time": 6254, "text": "And let's start with one, then do two, and then see that."}, {"time": 6258, "text": "And then do the three, you know, the capitalist like startup entrepreneurial dream is let's build a thousand and let's."}, {"time": 6267, "text": "Right, and 500 of them fail, but whatever, the other 500, we learned from them."}, {"time": 6270, "text": "But if you're good enough, I mean, one thing is like, your intuition would say like, that's gonna be hugely destructive to everything."}, {"time": 6277, "text": "But actually, it's kind of the forces of capitalism, like people are quite, it's easy to be critical, but if you actually look at the data at the way our world has progressed in terms of the quality of life, it seems like the competent good people rise to the top."}, {"time": 6294, "text": "This is coming from me from the Soviet Union and so on."}, {"time": 6298, "text": "It's like, it's interesting that somebody like Elon Musk is the way you push progress in artificial intelligence."}, {"time": 6308, "text": "Like it's forcing Waymo to step their stuff up and Waymo is forcing Elon Musk to step up."}, {"time": 6317, "text": "It's fascinating, because I have this tension in my heart and just being upset by the lack of progress in autonomous vehicles within academia."}, {"time": 6329, "text": "So there's a huge progress in the early days of the DARPA challenges."}, {"time": 6335, "text": "And then it just kind of stopped like at MIT, but it's true everywhere else with an exception of a few sponsors here and there is like, it's not seen as a sexy problem, Thomas."}, {"time": 6350, "text": "Like the moment artificial intelligence starts approaching the problems of the real world, like academics kind of like, all right, let the..."}, {"time": 6360, "text": "They get really hard in a different way."}, {"time": 6361, "text": "In a different way, that's right."}, {"time": 6363, "text": "I think, yeah, right, some of us are not excited about that other way."}, {"time": 6367, "text": "But I still think there's fundamentals problems to be solved in those difficult things."}, {"time": 6372, "text": "It's not, it's still publishable, I think."}, {"time": 6374, "text": "Like we just need to, it's the same criticism you could have of all these conferences in Europe, CVPR, where application papers are often as powerful and as important as like a theory paper."}, {"time": 6387, "text": "Even like theory just seems much more respectable and so on."}, {"time": 6391, "text": "I mean, machine learning community is changing that a little bit."}, {"time": 6393, "text": "I mean, at least in statements, but it's still not seen as the sexiest of pursuits, which is like, how do I actually make this thing work in practice as opposed to on this toy data set?"}, {"time": 6407, "text": "All that to say, are you still avoiding the three books question?"}, {"time": 6410, "text": "Is there something on audio book that you can recommend?"}, {"time": 6414, "text": "Oh, yeah, I mean, yeah, I've read a lot of really fun stuff."}, {"time": 6418, "text": "In terms of books that I find myself thinking back on that I read a while ago, like that stood the test of time to some degree."}, {"time": 6426, "text": "I find myself thinking of program or be programmed a lot by Douglas Roschkopf, which was, it basically put out the premise that we all need to become programmers in one form or another."}, {"time": 6441, "text": "And it was an analogy to once upon a time we all had to become readers."}, {"time": 6446, "text": "We had to become literate."}, {"time": 6447, "text": "And there was a time before that when not everybody was literate, but once literacy was possible, the people who were literate had more of a say in society than the people who weren't."}, {"time": 6457, "text": "And so we made a big effort to get everybody up to speed."}, {"time": 6459, "text": "And now it's not 100% universal, but it's quite widespread."}, {"time": 6464, "text": "Like the assumption is generally that people can read."}, {"time": 6468, "text": "The analogy that he makes is that programming is a similar kind of thing, that we need to have a say in, right?"}, {"time": 6477, "text": "So being a reader, being literate, being a reader means you can receive all this information, but you don't get to put it out there."}, {"time": 6484, "text": "And programming is the way that we get to put it out there."}, {"time": 6486, "text": "And that was the argument that he made."}, {"time": 6487, "text": "I think he specifically has now backed away from this idea."}, {"time": 6491, "text": "He doesn't think it's happening quite this way."}, {"time": 6494, "text": "And that might be true that it didn't, society didn't sort of play forward quite that way."}, {"time": 6500, "text": "I still believe in the premise."}, {"time": 6502, "text": "I still believe that at some point, the relationship that we have to these machines and these networks has to be one of each individual can, has the wherewithal to make the machines help them."}, {"time": 6514, "text": "Do the things that that person wants done."}, {"time": 6517, "text": "And as software people, we know how to do that."}, {"time": 6520, "text": "And when we have a problem, we're like, okay, I'll just, I'll hack up a Pearl script or something and make it so."}, {"time": 6524, "text": "If we lived in a world where everybody could do that, that would be a better world."}, {"time": 6529, "text": "And computers would be, have, I think less sway over us."}, {"time": 6533, "text": "And other people's software would have less sway over us as a group."}, {"time": 6537, "text": "In some sense, software engineering, programming is power."}, {"time": 6540, "text": "Programming is power, right?"}, {"time": 6543, "text": "Yeah, it's like magic."}, {"time": 6544, "text": "It's like magic spells."}, {"time": 6545, "text": "And it's not out of reach of everyone."}, {"time": 6549, "text": "But at the moment, it's just a sliver of the population who can commune with machines in this way."}, {"time": 6555, "text": "So I don't know, so that book had a big impact on me."}, {"time": 6558, "text": "Currently, I'm reading The Alignment Problem, actually by Brian Christian."}, {"time": 6562, "text": "So I don't know if you've seen this out there yet."}, {"time": 6563, "text": "Is this similar to Stuart Russell's work with the control problem?"}, {"time": 6567, "text": "It's in that same general neighborhood."}, {"time": 6568, "text": "I mean, they have different emphases that they're concentrating on."}, {"time": 6572, "text": "I think Stuart's book did a remarkably good job, like just a celebratory good job at describing AI technology and sort of how it works."}, {"time": 6584, "text": "It was really cool to see that in a book."}, {"time": 6586, "text": "I think he has some experience writing some books."}, {"time": 6589, "text": "You know, that's probably a possible thing."}, {"time": 6592, "text": "He's maybe thought a thing or two about how to explain AI to people."}, {"time": 6596, "text": "Yeah, that's a really good point."}, {"time": 6597, "text": "This book so far has been remarkably good at telling the story of sort of the history, the recent history of some of the things that have happened."}, {"time": 6608, "text": "I'm in the first third."}, {"time": 6609, "text": "He said this book is in three thirds."}, {"time": 6610, "text": "The first third is essentially AI fairness and implications of AI on society that we're seeing right now."}, {"time": 6618, "text": "And that's been great."}, {"time": 6619, "text": "I mean, he's telling the stories really well."}, {"time": 6621, "text": "He went out and talked to the frontline people whose names were associated with some of these ideas and it's been terrific."}, {"time": 6628, "text": "He says the second half of the book is on reinforcement learning."}, {"time": 6630, "text": "So maybe that'll be fun."}, {"time": 6633, "text": "And then the third half, third third, is on the super intelligence alignment problem."}, {"time": 6639, "text": "And I suspect that that part will be less fun for me to read."}, {"time": 6646, "text": "Yeah, it's an interesting problem to talk about."}, {"time": 6648, "text": "I find it to be the most interesting, just like thinking about whether we live in a simulation or not, as a thought experiment to think about our own existence."}, {"time": 6658, "text": "So in the same way, talking about alignment problem with AGI is a good way to think similar to like the trolley problem with autonomous vehicles."}, {"time": 6666, "text": "It's a useless thing for engineering, but it's a nice little thought experiment for actually thinking about what are like our own human ethical systems, our moral systems to by thinking how we engineer these things, you start to understand yourself."}, {"time": 6685, "text": "So sci fi can be good at that too."}, {"time": 6687, "text": "So one sci fi book to recommend is Exhalations by Ted Chiang, bunch of short stories."}, {"time": 6693, "text": "This Ted Chiang is the guy who wrote the short story that became the movie Arrival."}, {"time": 6698, "text": "And all of his stories just from a, he was a computer scientist, actually he studied at Brown."}, {"time": 6704, "text": "And they all have this sort of really insightful bit of science or computer science that drives them."}, {"time": 6712, "text": "And so it's just a romp, right?"}, {"time": 6714, "text": "To just like, he creates these artificial worlds with these by extrapolating on these ideas that we know about, but hadn't really thought through to this kind of conclusion."}, {"time": 6724, "text": "And so his stuff is, it's really fun to read, it's mind warping."}, {"time": 6728, "text": "So I'm not sure if you're familiar, I seem to mention this every other word is I'm from the Soviet Union and I'm Russian."}, {"time": 6737, "text": "Way too much to see us."}, {"time": 6738, "text": "My roots are Russian too, but a couple generations back."}]}, {"title": "Diana Walsh Pasulka: Aliens, Technology, Religion & the Nature of Belief | Lex Fridman Podcast #149", "id": "iqBh7G4uDR8", "quotes": [{"time": 285, "text": "What's funny is that for each one of them, I'm convinced each time."}, {"time": 289, "text": "They all say different things, but they're so convincing."}, {"time": 291, "text": "I'm like, yes, hire that one, right?"}, {"time": 293, "text": "Is it like historical philosophy, like a particular talk?"}, {"time": 296, "text": "Or do they have an actual belief?"}, {"time": 299, "text": "They're practicing metaphysicians."}, {"time": 301, "text": "Metaphysicians, yes."}, {"time": 303, "text": "So, what they do is they come and they're usually excellent philosophers from Harvard or USC or whatever."}, {"time": 311, "text": "They come and they give what's called a job talk."}, {"time": 313, "text": "That's what every academic does a job talk in order to get it."}, {"time": 318, "text": "They talk to us about a department about what they do."}, {"time": 321, "text": "And so, it so happens that we need a metaphysician and now we're hiring again for one."}, {"time": 327, "text": "And so, I've learned a lot about metaphysics in the last year."}, {"time": 331, "text": "And this is what I've learned that they use physics as a basis for understanding what we can know about what is real."}, {"time": 339, "text": "And what is real is really difficult to pin down."}, {"time": 342, "text": "And so, your question is, what is belief?"}, {"time": 345, "text": "Well, belief, does it correspond to reality?"}, {"time": 348, "text": "That's the question I would ask."}, {"time": 350, "text": "And first, we don't even know what is real."}, {"time": 352, "text": "So, the table, they would say, how do we know that the table even exists?"}, {"time": 355, "text": "Well, how do we differentiate it from the floor, for example?"}, {"time": 359, "text": "So, these are the questions that philosophers are asking."}, {"time": 361, "text": "No one else is, of course."}, {"time": 362, "text": "But philosophers are asking these questions and they have different answers for it."}, {"time": 366, "text": "So, I would say that it's very difficult to know what is real."}, {"time": 370, "text": "And in fact, what I do usually is I paraphrase my friend and colleague, Brother Guy Consolmagno."}, {"time": 377, "text": "He's a Jesuit priest who's also an astronomer and he's the director of the Vatican Observatory."}, {"time": 383, "text": "And so, he says this, he's a very smart person."}, {"time": 385, "text": "He says, well, truth is a moving target."}, {"time": 390, "text": "So, basically, to know what is real out there, like gravity or something like that, you've got to approximate it."}, {"time": 398, "text": "And as human beings, we have senses to tell us what, at least so we don't get hurt."}, {"time": 405, "text": "We're not going to fall off a building or something like that."}, {"time": 408, "text": "We have eyes to see and things like that."}, {"time": 410, "text": "So, we can approximate what reality is, but we're never going to get to it unless we develop better senses, okay?"}, {"time": 418, "text": "And I think that that is what we are in the process of doing."}, {"time": 421, "text": "We're developing better senses."}, {"time": 423, "text": "We have telescopes, we have microscopes, we have extensions of ourselves, which are now called technology."}, {"time": 429, "text": "And we can get to a better understanding of what reality is and what the objective world is."}, {"time": 435, "text": "And therefore, our beliefs can be honed."}, {"time": 438, "text": "So, we can get better beliefs, more accurate beliefs."}, {"time": 440, "text": "But can we get beliefs that actually correspond to reality?"}, {"time": 444, "text": "Not in any precise way, but in approximate ways."}, {"time": 448, "text": "So, I hope that's not like too big an answer to your question."}, {"time": 451, "text": "Well, do you think beliefs are in themselves can become reality?"}, {"time": 455, "text": "I mean, so you've now adapted the, in this little bit of a conversation, adapted the metaphysician view of reality, which is the physics."}, {"time": 466, "text": "But, you know, we humans kind of operate in the space of ideas very much so."}, {"time": 471, "text": "Like we've kind of in the collective intelligence of human beings, have come up with a set of ideas that persist in the minds of these many people."}, {"time": 479, "text": "And they become quite strong and powerful."}, {"time": 482, "text": "Like in terms of like impact on our lives, they can have sometimes more impact than this table does than the physics."}, {"time": 492, "text": "And in that sense, is there some sense in which our beliefs are reality, even if they're not connected to the physics?"}, {"time": 502, "text": "Yes, even if they're not real."}, {"time": 503, "text": "Yeah, even if, okay."}, {"time": 505, "text": "So, yes, absolutely."}, {"time": 506, "text": "So, our beliefs are tremendously, they create social effects, absolutely."}, {"time": 514, "text": "There was a belief that, I'm going to use this example."}, {"time": 518, "text": "There was a belief back in the day, and we're talking about, when I say back in the day, I'm a historian, so I'm talking about like 1000 years ago, right?"}, {"time": 525, "text": "That women had no souls, okay?"}, {"time": 527, "text": "So, look, I don't know if human beings have souls."}, {"time": 529, "text": "I can tell you this, though, that if human beings have souls, probably animals do too."}, {"time": 534, "text": "That's my own personal belief."}, {"time": 535, "text": "That's not a professor belief there."}, {"time": 538, "text": "But there was this belief among the Catholic magisterium, which runs Europe, that women had no souls."}, {"time": 545, "text": "So, they had to have this big meeting about it, you know, did women have souls?"}, {"time": 548, "text": "But that belief had consequences for women."}, {"time": 553, "text": "I mean, women were treated and have been treated as if they didn't have souls."}, {"time": 558, "text": "Okay, so there's... And the soul was really the essence of the human being."}, {"time": 562, "text": "It's called the animus, right?"}, {"time": 564, "text": "It's what is the essence of what is eternal, you know, when women weren't eternal."}, {"time": 569, "text": "Here's another example, okay?"}, {"time": 571, "text": "This is an example from my own research."}, {"time": 574, "text": "So, in the Catholic tradition, there's this idea of purgatory, hell, and heaven."}, {"time": 580, "text": "And these are three destinations that people can go to when they die."}, {"time": 585, "text": "And if you're great, you go to heaven automatically and you're considered a saint."}, {"time": 589, "text": "If you're okay, you go to purgatory, right?"}, {"time": 592, "text": "And you suffer for a time and then get back into heaven."}, {"time": 595, "text": "If you're terrible, you go to hell, right?"}, {"time": 598, "text": "Well, there was a place that the Catholics determined, and this was a belief for a long time, like a thousand years or more, and it was called limbo, all right?"}, {"time": 609, "text": "And limbo comes from the Latin limbus, and it means edge."}, {"time": 613, "text": "And it was either on the edge of hell or on the edge of heaven."}, {"time": 616, "text": "No one really could determine which it was."}, {"time": 618, "text": "No historians are like, well, this person says it was on the edge of heaven."}, {"time": 622, "text": "Well, listen, this was a terrible... First of all, there is no limbo anymore."}, {"time": 626, "text": "In 2007, Benedict, the then Pope, got rid of the idea that there was limbo, okay?"}, {"time": 632, "text": "So Catholics kind of went crazy because they didn't really know."}, {"time": 635, "text": "They forgot that limbo existed and they thought it was purgatory."}, {"time": 638, "text": "And they said, how could you get rid of purgatory?"}, {"time": 640, "text": "But actually, he just got rid of this idea of limbo."}, {"time": 643, "text": "Oh, so that's a distinct thing from purgatory."}, {"time": 645, "text": "And by the way, people should know they have a book on purgatory that came before... American Cosmic."}, {"time": 650, "text": "Yes, I wrote a book on purgatory, yeah."}, {"time": 652, "text": "Anyway, so limbo is a distinct thing from purgatory?"}, {"time": 656, "text": "And the types of people who go to limbo happen to be virtuous pagans, okay?"}, {"time": 664, "text": "Like Socrates or somebody like that."}, {"time": 667, "text": "And children who weren't baptized."}, {"time": 669, "text": "So think of this."}, {"time": 671, "text": "Think of for like more than a thousand years, mothers and fathers gave birth to babies who weren't baptized and couldn't be buried with their family in these burial... And then they couldn't be reunited with them in heaven."}, {"time": 686, "text": "Think of the pain and suffering that that caused."}, {"time": 688, "text": "And that was nothing."}, {"time": 690, "text": "Limbo's nothing."}, {"time": 692, "text": "Yet the belief in it caused untold suffering."}, {"time": 695, "text": "And that's just a small example."}, {"time": 697, "text": "And that was as real to them?"}, {"time": 699, "text": "It was absolutely real."}, {"time": 700, "text": "I mean, the effects were real, let's put it that way."}, {"time": 702, "text": "The place itself, not real."}, {"time": 704, "text": "But the families themselves, do you think they really believed it?"}, {"time": 707, "text": "They totally believed it."}, {"time": 708, "text": "As much as the table is real?"}, {"time": 711, "text": "I've read, listen, we have trigger warnings today, right?"}, {"time": 714, "text": "So don't read this, it's gonna make you upset, okay?"}, {"time": 717, "text": "History, primary sources, no trigger warnings, okay?"}, {"time": 721, "text": "So you're going through like somebody's diary from 1400 and you hear the suffering and pain that they went through."}, {"time": 728, "text": "There were times in my research where I'd have to put my primary source down and just basically go outside and take a walk because it was so horrific."}, {"time": 738, "text": "I knew it was true because they wouldn't write something, they're not gonna write in their diary something that's not true and it was horrible."}, {"time": 744, "text": "So yes, these people went through untold suffering for nothing because they had an erroneous belief."}, {"time": 750, "text": "But they didn't know it was erroneous."}, {"time": 752, "text": "So it was real to them?"}, {"time": 754, "text": "So I don't know if you're familiar with Donald Hoffman."}, {"time": 757, "text": "He has this idea that in terms of the distance we are from being able to know the reality, which is there, the physics reality, is we're actually really, really, really, really far away from that."}, {"time": 772, "text": "So like it's, I think his ideas that were basically like completely detached from it."}, {"time": 781, "text": "What's your sense, how close are we to the reality?"}, {"time": 784, "text": "We'll talk about a bunch of ideas about our beliefs in technology and beyond, but in terms of what is actually real from a physical sense, how close are we to understanding that?"}, {"time": 798, "text": "Pretty far."}, {"time": 799, "text": "I'm gonna use examples from what I do."}, {"time": 801, "text": "Okay, so this idea that we're suspicious of what we actually think is real is not new."}, {"time": 809, "text": "Of course, it goes back a long time, thousands of years, in fact."}, {"time": 813, "text": "And philosophers, I'm not actually technically a philosopher, but I was one."}, {"time": 819, "text": "I'm a professor of religious studies."}, {"time": 822, "text": "Yeah, what do you introduce yourself at, like at a bar when the bartender asks, what do you do?"}, {"time": 827, "text": "I never tell people what I do, especially on airplanes."}, {"time": 832, "text": "It's a bad idea."}, {"time": 833, "text": "So generally if they push though, I say, I'm the chair of philosophy and religion, although I stepped down last year, so I'm no longer the chair."}, {"time": 840, "text": "But I have like a master's degree in philosophy and I was a philosophy major and I still study philosophy, so I integrate it into my research."}, {"time": 849, "text": "All right, so this idea that we can't know, we're suspicious of what we know, it's called external world skepticism."}, {"time": 858, "text": "That's the official philosophical name for it."}, {"time": 861, "text": "Our faculties and our senses don't give us accurate perceptions of what is there, okay, especially at a quantum level or a molecular level."}, {"time": 870, "text": "I mean, that's just obvious."}, {"time": 872, "text": "So yeah, so I think that the person you mentioned is correct in that."}, {"time": 876, "text": "I think we're far away from it."}, {"time": 877, "text": "I think you're talking about our direct senses, but you know, we have tools, measurement tools from microscopes to all the tools of astronomy, cosmology that gives us a sense of the big universe and also the sense of the very small."}, {"time": 894, "text": "Do you think there's some other things that are completely sort of other dimensions or there's ideas of panpsychism, that consciousness permeates all matter, that there's like fundamental forces of physics we're not even aware of yet?"}, {"time": 914, "text": "I do think, and this is why I write about technology and I mean, that's actually what I specialize in is belief in technology with respect to religion."}, {"time": 925, "text": "So in my opinion, thank goodness for technology because where would we be without it?"}, {"time": 932, "text": "I mean, frankly, I think that it's like Marshall McLuhan was the person who said technology is like an extension of our senses and I absolutely believe that to be true."}, {"time": 944, "text": "I think that we're lucky that Prometheus gave us technology, okay, and that we use it and we're making it better and better and better and better."}, {"time": 954, "text": "And that makes us more efficient."}, {"time": 957, "text": "It makes us more efficient as a species."}, {"time": 960, "text": "And like my point is that I think that our instruments, I mean, I don't want to be a religious technologist, you know, but our instruments will save us."}, {"time": 976, "text": "I mean, they're already making life better for us."}, {"time": 978, "text": "You think it's important that they also help us understand reality more directly, more deeply?"}, {"time": 984, "text": "I think directly is better than deeply."}, {"time": 986, "text": "I think directly, more directly is probably a more accurate term for what you're trying to, I think, ask me, you know, can we actually, I mean, I think you're asking me that question that Kant basically was trying to get at was can we know the thing in itself?"}, {"time": 1000, "text": "Can we know that?"}, {"time": 1001, "text": "Can we have like some kind of like intense knowing of it?"}, {"time": 1005, "text": "It's almost mystical."}, {"time": 1007, "text": "And I would say that that's where religion comes in, okay?"}, {"time": 1012, "text": "That's where we talk about religion."}, {"time": 1014, "text": "And if I may also go back to Immanuel Kant."}, {"time": 1018, "text": "This idea that he, just before he died, just as he died, he was working on, he did this critique of reason where basically he believed, he basically talks about can we know what's real?"}, {"time": 1032, "text": "He basically has this long, you know, that question, can we know what's real?"}, {"time": 1035, "text": "And then, you know, a thousand pages later, no."}, {"time": 1039, "text": "I'll just give you the rundown."}, {"time": 1042, "text": "So, okay, yeah, yeah, exactly."}, {"time": 1045, "text": "Then he does this other critique and okay, so he does like three critiques."}, {"time": 1049, "text": "Then he does this critique of judgment."}, {"time": 1052, "text": "Well, judgment is this other thing altogether."}, {"time": 1054, "text": "And I think that that's what you're getting at."}, {"time": 1056, "text": "So how do we know things?"}, {"time": 1057, "text": "How can we know things really intensely and intimately?"}, {"time": 1061, "text": "And I think that he thought that judgment was the idea that we can actually know the thing in itself."}, {"time": 1069, "text": "And he was working on that as he died and then he never finished it."}, {"time": 1072, "text": "Hannah Arendt, another philosopher of the 20th century, took it up, took up the critique of judgment and tried to finish it."}, {"time": 1081, "text": "Why the word judgment?"}, {"time": 1083, "text": "Because judgment, think about it, when you see a work of art, who judges that to be decent?"}, {"time": 1089, "text": "So there is a group of people who come to the decision that that's rotten or, you know, that's pretty good."}, {"time": 1098, "text": "You know, like, I noticed that you like to play guitar."}, {"time": 1101, "text": "Well, you choose music that I happen to like too."}, {"time": 1104, "text": "So you and I both have a sense of judgment."}, {"time": 1107, "text": "It's a sense."}, {"time": 1108, "text": "So he said, there's a sense that some people have."}, {"time": 1112, "text": "Why do certain communities have a similar sense?"}, {"time": 1117, "text": "What dictates that?"}, {"time": 1118, "text": "And so he was working on that."}, {"time": 1119, "text": "He thought it had something to do with the knowledge, the intimate knowledge of the thing in itself."}, {"time": 1124, "text": "Yeah, so another philosopher that philosophers actually don't like at all, but religious studies people do, is Martin Heidegger."}, {"time": 1131, "text": "So Martin Heidegger has some great essays."}, {"time": 1134, "text": "One is called What is a Work of Art?"}, {"time": 1136, "text": "And again, he gets to, you know, he talks about Van Gogh and Van Gogh's shoes."}, {"time": 1140, "text": "You know, that picture, the painting Van Gogh's shoes, it's really a really intense picture."}, {"time": 1146, "text": "It's just shoes."}, {"time": 1147, "text": "It's, you know, it's an amazing painting of shoes."}, {"time": 1152, "text": "And I think everybody can agree that's a cool picture of shoes, right?"}, {"time": 1156, "text": "And so why, you know, the question is, why is that a cool picture of shoes?"}, {"time": 1160, "text": "You know, what kind of knowledge are we accessing to determine that indeed that works, right?"}, {"time": 1167, "text": "And in fact, we still like it."}, {"time": 1168, "text": "So basically the nature of knowledge and what does it represent?"}, {"time": 1172, "text": "It can operate in the space of, that's detached from reality or can it ultimately represent reality?"}, {"time": 1179, "text": "I guess that's the, is that, that's the space of metaphysics?"}, {"time": 1183, "text": "Is that the, is that the... Yeah."}, {"time": 1185, "text": "So what can we know is actually called epistemology."}, {"time": 1187, "text": "Epistemology."}, {"time": 1188, "text": "But metaphysics is, is basically what is the nature of reality."}, {"time": 1193, "text": "And those intersect."}, {"time": 1196, "text": "A lot of things intersect in philosophy."}, {"time": 1198, "text": "We just have fancy names for them."}, {"time": 1200, "text": "Another non philosopher that may be considered a philosopher, since we're talking about reality is Ayn Rand and her philosophy of objectivism."}, {"time": 1212, "text": "What are your thoughts on her sense of taking this idea of reality, calling her philosophy objectivism, and kind of starting at the idea that you really could know everything, and it's pretty obvious, and then from that, you can derive an ethics about how to live life, like what is the, what is the good ethical life and all the virtue of selfishness, all that kind of stuff."}, {"time": 1242, "text": "So you talked to a lot of academic philosophers."}, {"time": 1244, "text": "So I'd be curious to see from the perspective of like, is she somebody that's taken seriously at all?"}, {"time": 1255, "text": "Why is she dismissed as I see from my distant perspective by serious philosophers, and also like your own personal thoughts of like, is there some interesting bits that you find inspiring in her work or not?"}, {"time": 1270, "text": "Okay, so Ayn Rand, I've had so many exceedingly intelligent students basically give me her books, and basically say, please, Dr. Basilka, read this book."}, {"time": 1285, "text": "And I'll tell them, yes, thank you, I've read this book before."}, {"time": 1289, "text": "And then want to engage in, let me put it this way, they're religious about Ayn Rand."}, {"time": 1295, "text": "Okay, so to them, Ayn Rand represents some type of way of life, her objectivism."}, {"time": 1303, "text": "Now, why is she not taken seriously by philosophers in general?"}, {"time": 1308, "text": "Well, let me put it this way, philosophers in general tend to get pretty, I guess you could call it, they're kind of scientists, but with words."}, {"time": 1321, "text": "I always call philosophy, when I describe it to someone who's going to take a philosophy class, I say, it's basically math problems, like word math problems, okay?"}, {"time": 1330, "text": "So that's basically what it is."}, {"time": 1331, "text": "So they take words very seriously, and they're very formal."}, {"time": 1334, "text": "And definitions very seriously, yeah."}, {"time": 1336, "text": "So they all want to get on the same page, so there is no confusion."}, {"time": 1340, "text": "So for Ayn Rand to basically say, you can know everything, and you know, it's like, okay, and establish ethics from that, I think philosophers automatically say no."}, {"time": 1350, "text": "Now, that doesn't mean I say no."}, {"time": 1353, "text": "In fact, we have at my university a wonderful business school."}, {"time": 1358, "text": "And when you walk into the dean of the business school's office, Ayn Rand is everywhere."}, {"time": 1365, "text": "So I want to say that not all academics are anti Ayn Rand."}, {"time": 1371, "text": "And in fact, I don't think philosophers are either, except that they don't teach Ayn Rand, okay?"}, {"time": 1376, "text": "So in one sense, you could say that because they don't teach her, they're being exclusive in what they teach, or very particular, perhaps, is another way to put it."}, {"time": 1386, "text": "Yeah, it's hard to know where to place people like her, because, you know, do you put Albert Camus as a philosopher?"}, {"time": 1393, "text": "So I guess, what's the good term for that?"}, {"time": 1395, "text": "Like literary philosophers, or whatever the term is, it's annoying to me that the academic philosophers get to own the word philosophy, because like, it's just like people who think deeply about life is what I think about as philosophy."}, {"time": 1410, "text": "And like, to me, it's like, all right, so I know Nietzsche is another person that's probably not respected in the philosophy circles, because he is, you know, full of contradictions, full of..."}, {"time": 1422, "text": "I love Nietzsche."}, {"time": 1423, "text": "Nietzsche is my favorite philosopher."}, {"time": 1427, "text": "Yes, I absolutely love Nietzsche."}, {"time": 1429, "text": "So he's definitely, you know, I love people that are full of ideas, even if they're full of contradictions, and Nietzsche is certainly that."}, {"time": 1435, "text": "And Ayn Rand is also that."}, {"time": 1438, "text": "I'm able to look past the obvious ego that's there on the page, and the fact that she actually has, in my view, a lot of wrong ideas."}, {"time": 1448, "text": "But there's a lot of interesting tidbits to pick up, and the same goes with Nietzsche."}, {"time": 1454, "text": "And I'm weirded out by the religious aspect here, on both the people who like worship Ayn Rand, and people who completely dismiss her."}, {"time": 1463, "text": "I just kind of see it as, oh, can we just read a few interesting things and get inspired by it and move on, as opposed to... No."}, {"time": 1471, "text": "...have a diplomatic conversation."}, {"time": 1473, "text": "Is there something you find about her work that's interesting to you?"}, {"time": 1476, "text": "Or her personality, or any of that?"}, {"time": 1479, "text": "Oh, I think she's fascinating."}, {"time": 1481, "text": "I don't dismiss her."}, {"time": 1483, "text": "She was a woman who reached a level of success with her mind at a time when that was difficult."}, {"time": 1490, "text": "So, I mean, she's definitely worth looking at for even that reason."}, {"time": 1496, "text": "But also, her idea, I guess, part of the situation with Rand, first of all, I think that she her work is, you have to, it's misinterpreted, okay?"}, {"time": 1508, "text": "And I think that's the same with Nietzsche."}, {"time": 1510, "text": "A lot of people think that, I mean, in fact, it is the case that Nietzsche's writing before the 20th century, so he's got the, he's somewhat, his rhetoric is sexist and racist and of the time period, right?"}, {"time": 1527, "text": "He was a educated philosopher of that time period."}, {"time": 1536, "text": "However, his books are amazing, and Nietzsche's philosophy is incredible."}, {"time": 1544, "text": "And I think that's what you're saying about Rand, too."}, {"time": 1549, "text": "And I agree."}, {"time": 1549, "text": "I mean, I think that we get caught up."}, {"time": 1553, "text": "I mean, likely we should, and we should contextualize these thinkers in the time period within which they are."}, {"time": 1560, "text": "We should not forgive their, you know, because there were people during Nietzsche's time that were, you know, feminist and not racist and things like that."}, {"time": 1569, "text": "And, you know, so, but each has merit."}, {"time": 1575, "text": "I mean, I would say Nietzsche is, and you did ask me to talk about some of the books that made the largest impact on me, and Nietzsche's Gay Science is one of them."}, {"time": 1585, "text": "It's one of the best books ever, in my opinion."}, {"time": 1588, "text": "I do think Nietzsche was, I don't know about exactly sexist."}, {"time": 1593, "text": "He certainly was sexist, but it felt like he didn't get laid much in his life."}, {"time": 1600, "text": "It felt like he was extra sexist."}, {"time": 1603, "text": "I was like, his theories on women are like, all right."}, {"time": 1606, "text": "He's pretty angry."}, {"time": 1607, "text": "He seems frustrated."}, {"time": 1609, "text": "He's like, all right, calm down, buddy."}, {"time": 1613, "text": "The fate of philosophers."}, {"time": 1615, "text": "I just ignore everything Nietzsche says about women."}, {"time": 1620, "text": "So can we talk about myth and religion a little bit?"}, {"time": 1624, "text": "I mean, can we start at the beginning, which is like myths, how are they born?"}, {"time": 1630, "text": "There's this collective intelligence amongst us human beings, and we seem to create these beautiful ideas that captivate the minds of millions."}, {"time": 1639, "text": "How is such a myth born?"}, {"time": 1643, "text": "So that brings us to terminology again."}, {"time": 1645, "text": "And in my field, we definitely, I think, try not to distinguish between religion."}, {"time": 1653, "text": "I guess it's going to be controversial, I think, between religion and myth, because we call other cultures, religions, myths, right?"}, {"time": 1663, "text": "And then we call our myths, religions."}, {"time": 1666, "text": "And I guess myth has a bad connotation to it, that it's not somehow real."}, {"time": 1671, "text": "Now, what's interesting is that people like Plato, who lived thousands of years ago, 2500 about, basically made this distinction himself within his own culture, which was Greek, right?"}, {"time": 1685, "text": "So Plato is a very famous Greek philosopher."}, {"time": 1688, "text": "And he would say things like this."}, {"time": 1689, "text": "He would say that he would make a distinction between the reality of the one God, or the one, he would call it, he didn't use the word God, but he's referencing a divinity, and he believes in the soul."}, {"time": 1707, "text": "But he would also say that the gods and goddesses of the Greeks are just myths."}, {"time": 1713, "text": "So even he would make that distinction."}, {"time": 1715, "text": "Again, he would say the population is not too bright, so they believe in these gods and goddesses."}, {"time": 1722, "text": "But he himself is talking to his students, and he's basically talking about forms, so that seem to live in these other dimensions."}, {"time": 1732, "text": "Like this table, let's go back to this table that we're talking around right now."}, {"time": 1736, "text": "He would say that this table is the instantiation of the form table, and that there is this table that actually exists somewhere."}, {"time": 1743, "text": "It's this place where numbers exist, like the number two, okay?"}, {"time": 1747, "text": "So we use the number two mathematically, therefore it exists."}, {"time": 1751, "text": "But have you ever seen a real one?"}, {"time": 1753, "text": "Have you ever seen the real two?"}, {"time": 1756, "text": "So but where does it exist?"}, {"time": 1757, "text": "So he says that tables..."}, {"time": 1758, "text": "So he was also talking about things that he says are real, making a distinction between the people, and by the way, he got this from Socrates, his mentor, who was killed by Athens because he would say such things."}, {"time": 1774, "text": "People don't like to be told that what they believe in is not real, right?"}, {"time": 1779, "text": "By the way, his idea of forms, you're just making me realize how incredible was that somebody like that was able to come up with that."}, {"time": 1787, "text": "I mean, that idea became a myth, the idea of forms, right?"}, {"time": 1791, "text": "That permeated probably the most influential set of ideas in the history of philosophy, in the history of ideas."}, {"time": 1801, "text": "I mean, Plato, we know him for a reason, right?"}, {"time": 1804, "text": "So let's say that it's a gray area between religious and myths, and maybe not even..."}, {"time": 1810, "text": "It is gray, yeah."}, {"time": 1812, "text": "So how's that idea with little Plato start and permeate through all of society?"}, {"time": 1818, "text": "Oh, how does it happen?"}, {"time": 1819, "text": "Okay, so there are different ways that religions work."}, {"time": 1822, "text": "So a lot of people would call the UFO narrative today, and this is what I talk about in my book, like a myth, right, the UFO myth."}, {"time": 1831, "text": "But a lot of people believe in it, okay?"}, {"time": 1833, "text": "So how do these things work?"}, {"time": 1835, "text": "Well, what I did was I took..."}, {"time": 1838, "text": "There's a Ann Taves at UC Santa Barbara."}, {"time": 1842, "text": "She's a pretty well known academic who studies religion, and she has this building block definition of religion, like it builds, okay?"}, {"time": 1850, "text": "And so she says there are no religious experiences or mythic experiences."}, {"time": 1856, "text": "There are experiences."}, {"time": 1859, "text": "And then they get interpreted as religious or mythic, okay?"}, {"time": 1863, "text": "And so I use that with the UFO narrative."}, {"time": 1868, "text": "So I take and I compare it to the religious narrative."}, {"time": 1872, "text": "So basically what happens?"}, {"time": 1874, "text": "What happens is this, is that a person generally has a very intense experience."}, {"time": 1880, "text": "It could be with something that they see in the sky, a being that they see, like Moses in the burning bush or something like that."}, {"time": 1888, "text": "They tell other people, okay?"}, {"time": 1890, "text": "And those other people believe them because they say, that guy, let's take you."}, {"time": 1894, "text": "Okay, Lex."}, {"time": 1895, "text": "Okay, so you're playing some of your music."}, {"time": 1899, "text": "Jimi Hendrix shows up out of the blue."}, {"time": 1901, "text": "So Jimi Hendrix, who does Electric Church stuff, right?"}, {"time": 1904, "text": "The Electric Church movement."}, {"time": 1906, "text": "So he shows up."}, {"time": 1907, "text": "I was, sorry for the small tension."}, {"time": 1910, "text": "I'm not aware of, I apologize if I should be."}, {"time": 1913, "text": "I just know how to play all of the songs, Electric Church."}, {"time": 1919, "text": "Is this a thing?"}, {"time": 1920, "text": "Yeah, it's Jimi Hendrix's thing."}, {"time": 1923, "text": "That was like a philosophy of his or what?"}, {"time": 1925, "text": "Yes, yes, yes."}, {"time": 1926, "text": "So he thought it was like a mission for him, like he was a missionary."}, {"time": 1930, "text": "And he was like doing the Electric Church."}, {"time": 1933, "text": "It was through his mission of music that he was actually impacting people spiritually."}, {"time": 1938, "text": "And I think you have to agree that his music is really spiritual, yeah."}, {"time": 1941, "text": "Wow, that's so cool to know that there's like a philosophy there."}, {"time": 1944, "text": "I wonder if he's ever written anything."}, {"time": 1946, "text": "He's spoken about it many times."}, {"time": 1949, "text": "I need to actually do some research here."}, {"time": 1951, "text": "Wow, that adds another level of depth."}, {"time": 1955, "text": "Okay, so say Lex is playing one of his songs."}, {"time": 1960, "text": "He shows up."}, {"time": 1961, "text": "What's your favorite Hendrix song by the way?"}, {"time": 1963, "text": "Oh, that's a hard one."}, {"time": 1964, "text": "I like Castles in the Sand."}, {"time": 1965, "text": "It's a sad one, but I like it."}, {"time": 1968, "text": "So I'm playing something and they show up."}, {"time": 1970, "text": "And all of a sudden, boom, just like Elvis does for people."}, {"time": 1974, "text": "Hendrix shows up, all right?"}, {"time": 1976, "text": "And then you're amazed and he tells you something that's very, very significant."}, {"time": 1980, "text": "And he says, you need to tell other people this, okay?"}, {"time": 1983, "text": "So then like, okay."}, {"time": 1984, "text": "I go on social media."}, {"time": 1986, "text": "Yes, and you start."}, {"time": 1987, "text": "And because people believe you and because you are a person of credibility, people believe you."}, {"time": 1995, "text": "And so all of a sudden a movement starts, okay?"}, {"time": 1997, "text": "And it's the Hendrix movement."}, {"time": 1999, "text": "It's Hendrix 2 or something like that."}, {"time": 2001, "text": "You know, we call it something, the next iteration of Hendrix, right?"}, {"time": 2005, "text": "Hendrix lives, but he lives as this vibration."}, {"time": 2008, "text": "And only Lex can manifest this vibration, okay?"}, {"time": 2012, "text": "So this is how religions start."}, {"time": 2016, "text": "Excuse your audience who are religious."}, {"time": 2017, "text": "I'm actually a practicing Catholic."}, {"time": 2019, "text": "So this is how religion starts."}, {"time": 2020, "text": "They start with, first off, a contact experience."}, {"time": 2025, "text": "Not all of them, but a good portion of them."}, {"time": 2027, "text": "And some person has an experience that's transcendent, sacred to them."}, {"time": 2032, "text": "And they go and they tell other people."}, {"time": 2034, "text": "And then those people tell other people."}, {"time": 2036, "text": "And then something gets written about it, okay?"}, {"time": 2039, "text": "And then it becomes, because it's a charismatic movement, people become affected by it."}, {"time": 2044, "text": "And if too many people are affected by it, an institution steps in and tries to control the narrative."}, {"time": 2050, "text": "So this is what you'd call the beginning of a religion or a myth, a very powerful myth."}, {"time": 2056, "text": "And so it's almost like a star, right?"}, {"time": 2059, "text": "A star is born."}, {"time": 2061, "text": "When you say institution, do you mean some other organization that's already powerful?"}, {"time": 2066, "text": "Doesn't want to become overpowered by this new movement?"}, {"time": 2070, "text": "Is this usually governments?"}, {"time": 2071, "text": "It's usually, yeah."}, {"time": 2072, "text": "So I have a couple of examples."}, {"time": 2074, "text": "I use the example of the Christian church in my book, because I'm most familiar with the history of Christianity."}, {"time": 2080, "text": "And Christianity was started by this Jewish man."}, {"time": 2085, "text": "And it was a movement that he was a very powerful, charismatic person."}, {"time": 2090, "text": "Other people believed in him."}, {"time": 2092, "text": "And then his followers talked about him."}, {"time": 2094, "text": "And then usually early Christians before the 300s were generally people who were disenfranchised, because he had a pretty radical idea that humans should have dignity."}, {"time": 2110, "text": "And this was pretty radical during that time."}, {"time": 2112, "text": "So women who didn't have dignity and slaves who didn't have dignity at the time converged to Christianity in droves."}, {"time": 2120, "text": "And so what happened was that all of a sudden it became this belief system that was undercurrent."}, {"time": 2127, "text": "And then Constantine, who was an elite, had an experience and made Christianity a state religion."}, {"time": 2137, "text": "By that time, there were different forms of Christianity, probably hundreds of them."}, {"time": 2141, "text": "Well, most likely."}, {"time": 2143, "text": "And Constantine and the people who were powerful with him decided that their idea, this is the Council of Nicaea now, decided that there was one form, and they called it universal."}, {"time": 2156, "text": "It's the one form of Christianity, and this should be it."}, {"time": 2160, "text": "And so they kind of took out all the other denominations of Christianity and different forms of it."}, {"time": 2165, "text": "So you can see that a very, very powerful set of beliefs put a culture on fire, right?"}, {"time": 2175, "text": "And so they had to deal with that fire somehow."}, {"time": 2179, "text": "And so they narrativized it."}, {"time": 2180, "text": "They decided, how do we interpret this?"}, {"time": 2182, "text": "And they interpreted it as they wished."}, {"time": 2185, "text": "But that wasn't the only interpretation of Christianity."}, {"time": 2187, "text": "I have another example."}, {"time": 2189, "text": "In the Catholic Church, a lot of times, and I'm going to use the example of Faustina."}, {"time": 2199, "text": "She's a nun, and she's Polish."}, {"time": 2201, "text": "And I think it was in the early 20th century, if not the 1800s, that she had a very powerful, many experiences, actually, of Jesus."}, {"time": 2212, "text": "And she saw Jesus with rays coming out of his heart."}, {"time": 2217, "text": "And basically, she called this his divine mercy, and it became a devotion in Poland, and it spread."}, {"time": 2224, "text": "The Catholic Church was not into this at all, okay?"}, {"time": 2227, "text": "And so they did everything they could to try to suppress Faustina's influence, which was growing and growing and growing and growing, okay?"}, {"time": 2236, "text": "And so they were very successful in trying to keep her quiet, and she died, okay?"}, {"time": 2240, "text": "Years later, John Paul II, Polish, sainted her and created the divine mercy devotion, which is worldwide now, and millions and millions of people."}, {"time": 2252, "text": "But do you see how they completely controlled it there?"}, {"time": 2255, "text": "So fascinating that it just starts with a single, like you said, contact experience."}, {"time": 2261, "text": "Experience is the key word."}, {"time": 2262, "text": "And is your sense that those experiences are legitimate, so it's not..."}, {"time": 2268, "text": "Yes, for the most part."}, {"time": 2270, "text": "Somehow artificially constructed?"}, {"time": 2272, "text": "I think for the most part, they're legitimate experiences that people have."}, {"time": 2276, "text": "Why would someone want to put themselves through what they go through?"}, {"time": 2278, "text": "Like, why would Jesus want to get crucified?"}, {"time": 2280, "text": "I mean, that's a pretty nasty way to die."}, {"time": 2283, "text": "Why would Faustina bring this upon herself?"}, {"time": 2288, "text": "The people that I meet who said that they've seen UFOs, that most of them don't want to be known because of the ridicule that goes along with it."}, {"time": 2295, "text": "So I honestly think that there are people who are maybe not stable and would like the attention, but for the most part, normal people don't want this attention."}, {"time": 2305, "text": "So you mentioned building blocks."}, {"time": 2308, "text": "You didn't mention the word God or sort of the afterlife."}, {"time": 2313, "text": "Are those essential to the myth?"}, {"time": 2316, "text": "So there's a contact experience."}, {"time": 2318, "text": "Is there some other aspects of myth and religion which makes them viral?"}, {"time": 2323, "text": "Which makes them spread and captivate the imagination of people?"}, {"time": 2330, "text": "Is there a pattern to them?"}, {"time": 2333, "text": "I think that for each era, it's different and people have... First, let's talk about the definition of religion, if that's okay, because most people assume the definitions that we in the West are familiar with, which is that, you know, that of Christianity, Islam, Judaism, you know, monotheistic religions."}, {"time": 2351, "text": "And those are just some religions."}, {"time": 2356, "text": "There are so many different types of religions."}, {"time": 2358, "text": "Some religions have no God at all."}, {"time": 2361, "text": "Zen Buddhism, for example, is a religion that asks you to take away your belief structures, like to kind of like..."}, {"time": 2369, "text": "In fact, I would call that a Kantian type religion, right?"}, {"time": 2372, "text": "In that it's basically telling you to get rid of your concepts of what you think about things so that you can actually have the experience, like you were talking about earlier, of the thing in itself."}, {"time": 2383, "text": "And they call that Satori."}, {"time": 2385, "text": "So there are people who believe, you know, they try to..."}, {"time": 2389, "text": "They call it meditation, Zen meditation, and it's fairly radical, actually."}, {"time": 2395, "text": "In some monasteries, I don't know if they still do this, but they'll whack you on the head if you appear to be not focusing and, you know, that kind of thing."}, {"time": 2406, "text": "You know, they do things to basically take you away from your conceptions of reality and bring you into a state of all that is, which is what they call Satori."}, {"time": 2419, "text": "And that has nothing to do with God."}, {"time": 2422, "text": "I like this religion."}, {"time": 2423, "text": "And anything that involves sticks and whacking in order for you to focus better, I'm gonna have to join a monastery."}, {"time": 2430, "text": "So, okay, so digging into definitions of religion."}, {"time": 2434, "text": "So like, what do you think is the scope that defines a religion?"}, {"time": 2441, "text": "So in my field, we have a few different definitions of religion, as you can imagine, just like philosophers have different definitions of what is real."}, {"time": 2450, "text": "So I take this definition and it comes from John Livingston."}, {"time": 2454, "text": "And it's, religion is that set of beliefs and practices that is inspired by a transformative, what is perceived actually to be a transformative and sacred power."}, {"time": 2469, "text": "So religion is a set of, it's not just belief, it's also practices."}, {"time": 2473, "text": "It's both belief and practices, because you won't have the practices without the belief."}, {"time": 2477, "text": "So you have those together, okay, and it's inspired by what is perceived, because we don't know if it's real or not, what is perceived to be of sacred and transforming power."}, {"time": 2488, "text": "So perceived by the followers, or is this connected to the original sort of experience?"}, {"time": 2493, "text": "No, no, well, it's perceived by the followers."}, {"time": 2497, "text": "So, and that's the governing idea is that there's something of great power, perceived to be of great power, which you can connect yourself either emotionally or intellectually somehow in order to explore the world that is beyond your own capabilities."}, {"time": 2516, "text": "And is there communication also involved?"}, {"time": 2518, "text": "Generally, yeah."}, {"time": 2520, "text": "That's a great definition."}, {"time": 2522, "text": "So within that falls everything that we've talked about so far, including technology and alien life and so on."}, {"time": 2532, "text": "Do you think ultimately religion is good for human civilization?"}, {"time": 2539, "text": "Let me maybe phrase it differently is what's religion good for?"}, {"time": 2545, "text": "Okay, yeah, that's a great question."}, {"time": 2547, "text": "Thanks for asking that."}, {"time": 2548, "text": "Most people don't ask that."}, {"time": 2550, "text": "And I think it's the question to ask, why do we still have religion?"}, {"time": 2554, "text": "That's the question, right?"}, {"time": 2556, "text": "Because scientists and others, scholars, humanists even thought that there's this thing called the secularization thesis, and it's this idea that the more we progress rationally and we have better instruments for understanding our reality, the less religious we will be."}, {"time": 2577, "text": "But that's been found to be untrue."}, {"time": 2580, "text": "We're still very religious, okay?"}, {"time": 2582, "text": "Why is it around?"}, {"time": 2583, "text": "Well, it's adaptive in some way, in my opinion."}, {"time": 2586, "text": "Many people would not agree with me, but I kind of see it as an evolutionary adaptation."}, {"time": 2592, "text": "Now, think about religions, okay?"}, {"time": 2597, "text": "Think about Christianity again, for one."}, {"time": 2600, "text": "Here comes this idea when you have this ruthless empire called the Roman Empire, which litters its roads with crucified bodies to let you know, don't mess with us, okay?"}, {"time": 2613, "text": "Here all of a sudden you have this guy saying, God is love, okay?"}, {"time": 2617, "text": "All right, well, that's weird."}, {"time": 2619, "text": "Okay, so why?"}, {"time": 2620, "text": "Why does this take off?"}, {"time": 2621, "text": "Well, it takes off because we're becoming a colonial power."}, {"time": 2627, "text": "That means we're going into other countries, we're conquering them."}, {"time": 2634, "text": "How do we survive together as cultures that don't clash?"}, {"time": 2640, "text": "Well, we have to have a belief structure that allows us to, and I think religions function that way, frankly."}, {"time": 2645, "text": "So religions help us, so Richard Dawkins's meme idea, it allows us to explore a space of ideas, and that in itself is the, so it's like evolution of ideas, and religion is a powerful tool for us to explore ideas."}, {"time": 2665, "text": "Because if I believe that men have souls."}, {"time": 2671, "text": "Yes, they do, okay."}, {"time": 2676, "text": "I'm still trying to figure that out."}, {"time": 2679, "text": "Well, I still, in terms of souls, do believe cats don't have souls, but we'll never be able to confirm that."}, {"time": 2689, "text": "Maybe if we get better instruments, the soul instrument, you need to come up with that one, please."}, {"time": 2694, "text": "For cats?"}, {"time": 2695, "text": "Yeah, not just for cats, but for all animals and people in general."}, {"time": 2698, "text": "For sure, you could put them in like a little, you know, soul machine and find out what's the status of their soul."}, {"time": 2708, "text": "I hope we'll become a scientific discipline of consciousness, and consciousness is in some sense connected to maybe what the meaning of the word soul used to be."}, {"time": 2718, "text": "And I think it's a fascinating open question, like what is consciousness and so on that maybe we'll touch on in a little bit."}, {"time": 2726, "text": "But yeah, anyway, back to our..."}, {"time": 2728, "text": "Religions being adaptive."}, {"time": 2730, "text": "I think that Christianity probably helped us become better people to each other as we moved into a more global society."}, {"time": 2740, "text": "And I also, it goes along with my book, which is basically making the argument that belief in nonhuman intelligence or ETs or UFOs, UAPs, whatever you want to call them, is a new form of religion."}, {"time": 2752, "text": "And how does that work with the scientific method?"}, {"time": 2758, "text": "Do you think there's always this role of religion as being, in its broad definition of religion, as being a complement to our sort of very rigorous empirical pursuit of understanding reality?"}, {"time": 2770, "text": "There's always going to be this coupling."}, {"time": 2772, "text": "We'll always define, redefine new eras of civilization of what that religion actually looks like."}, {"time": 2779, "text": "So you talk about technology and so on being the modern set of religious beliefs around that."}, {"time": 2786, "text": "So is that always going to... Is religion always going to kind of cover the space of things we can't quite understand with science yet, but we still want to be thinking about?"}, {"time": 2797, "text": "Oh, I see what you're saying."}, {"time": 2799, "text": "When you say religion, I would use the word religiosity because I think that we're moving out of the dogmatic types of religions into more of a, I hate to put it this way, but an X Files type religion where we can say, I want to believe, or the truth is out there, but we don't know that it's out there, or we don't know yet what it is, but we know it's out there."}, {"time": 2821, "text": "So there's this kind of built in capacity for belief in something that we don't have evidence for yet, and that's a sort of faith."}, {"time": 2831, "text": "So I would say yes to that question, absolutely."}, {"time": 2835, "text": "I think it's adaptive in that way."}, {"time": 2836, "text": "We're moving into a new..."}, {"time": 2837, "text": "I mean, heck, we've already moved into this culture."}, {"time": 2840, "text": "Most people have not caught up with it yet."}, {"time": 2842, "text": "I see that in the school systems, and I think that I'm hoping we can catch up fast because really it's moving faster than we are."}, {"time": 2853, "text": "So I mentioned to you offline that I'm finishing up on the rise and fall of the Third Reich."}, {"time": 2861, "text": "I'm not sure if you have anything in your exploration, interesting to say, but the use of religion by dictators or the lack of the use of religion by dictators, whether we're talking about Stalin, which is mostly secular, I apologize if I'm historically incorrect on this, but I believe it's secular."}, {"time": 2882, "text": "And Hitler, I think there's some controversy about how much religion played a role in his own personal life and in general in terms of influencing the... using it to manipulate the public, but definitely the church played a role."}, {"time": 2905, "text": "Do you have a sense of the use of religion by governments to control the populations, by dictators, for example, or is that outside of your little explorations as a religious scholar?"}, {"time": 2919, "text": "It's not outside of my framework, absolutely not."}, {"time": 2923, "text": "I think that it's done routinely."}, {"time": 2926, "text": "Propaganda is done routinely, especially there's nothing more powerful than religion to get people to act, I think."}, {"time": 2940, "text": "My mother's Jewish and my father was Roman Catholic, okay, from Irish extraction."}, {"time": 2946, "text": "And so, both great grandparents came here under duress because they were being, what would you call it, there was an act of genocide on both sides being done by other cultures, okay?"}, {"time": 2962, "text": "So, on the one hand, obviously, we know about the Holocaust, okay?"}, {"time": 2966, "text": "So, they came, the great grandparents came here to avoid that and they made it."}, {"time": 2970, "text": "On the other hand, there was an English genocide, we just have to say it, of the Irish, it was called a famine, but it wasn't fun, it was a staged thing."}, {"time": 2982, "text": "And so, millions of Irish left Ireland on coffin ships is what they called them because they usually wouldn't get here, mine happened to get here, okay?"}, {"time": 2992, "text": "So, that's the context that I'm coming from."}, {"time": 2995, "text": "So, in each case, for one thing, Irish weren't considered, Catholics weren't considered, they were considered to be terrible and there was a lot of anti Catholic rhetoric here in the United States, which is kind of strange because one of the, in fact, the most wealthy colonial family were the Carrolls in Maryland and they were Catholic."}, {"time": 3017, "text": "So, when you look at the United States, at our history, and you see the separation of church and state, do you wanna know where that came from?"}, {"time": 3024, "text": "That came from those guys, they convinced George Washington and Thomas Jefferson, I mean, they couldn't vote, yet they have their names on the constitution, is that not a strange contradiction?"}, {"time": 3040, "text": "So, here you can see how propaganda works, there was anti Catholic propaganda, there was anti Jewish propaganda and a lot of it was that these people weren't human, they weren't human beings."}, {"time": 3055, "text": "Another thing I'd like to say is that when the Irish did come here, they were indentured, a lot of times indentured servants, but that's terminology, what is an indentured servant?"}, {"time": 3070, "text": "Slave."}, {"time": 3072, "text": "So, in that sense, religion can be used derogatorily as a useful grouping mechanism of saying, this is the other."}, {"time": 3082, "text": "And it's powerful too, because behind it is a force of what people contend to be sacred, a sacred force, right?"}, {"time": 3091, "text": "So, it's up to God to decide who's, so you have to go along with what God says, of course."}, {"time": 3098, "text": "Well, that's basically, that's not the contact event."}, {"time": 3102, "text": "The contact event is usually some type of very specific, legitimate event that a person has with something that is non human or considered divine."}, {"time": 3114, "text": "But when religions become narrativized, I would call it, by different institutions, that's when you're in danger of getting propaganda."}, {"time": 3124, "text": "You said Nietzsche, one of your favorite philosophers."}, {"time": 3127, "text": "He said, famously, one of the many famous things he said is that God is dead."}, {"time": 3134, "text": "What do you think he meant?"}, {"time": 3136, "text": "Do you think he was right?"}, {"time": 3139, "text": "I love this question."}, {"time": 3140, "text": "No one asks me about Nietzsche."}, {"time": 3144, "text": "And I love Nietzsche."}, {"time": 3145, "text": "Okay, so first, actually, I do think, and I could be corrected and probably will be in all the comments, but I think that's a good question."}, {"time": 3153, "text": "Well, first, Nietzsche, it's true, wasn't the first to say God is dead."}, {"time": 3158, "text": "I think Hegel said it, okay?"}, {"time": 3160, "text": "No one reads Hegel."}, {"time": 3161, "text": "He's like so difficult to read that it's impossible."}, {"time": 3164, "text": "Same with Heidegger, as you mentioned."}, {"time": 3166, "text": "I love him, but yeah, he's really hard to read."}, {"time": 3168, "text": "So Nietzsche basically said God is dead."}, {"time": 3171, "text": "And let me give you the context for him saying that."}, {"time": 3173, "text": "He also said this."}, {"time": 3174, "text": "He said there was only one Christian."}, {"time": 3176, "text": "He died on the cross, okay?"}, {"time": 3178, "text": "So he despised Christianity."}, {"time": 3182, "text": "And he said that... And the people who practice it."}, {"time": 3186, "text": "But again, he believed in Jesus, and he believed Jesus was..."}, {"time": 3189, "text": "He didn't believe He was a divinity."}, {"time": 3190, "text": "He believed Jesus was a good man, and he died on the cross, okay?"}, {"time": 3194, "text": "So he believed in the morality of Jesus."}, {"time": 3196, "text": "Yeah, he absolutely did."}, {"time": 3198, "text": "And Nietzsche basically was making a historical statement about God is dead."}, {"time": 3204, "text": "And he was right."}, {"time": 3205, "text": "He was basically saying that in the century in which he lived, and he died, I think, in 1900."}, {"time": 3211, "text": "Again, I could be wrong about that."}, {"time": 3214, "text": "So I just want to say that I believe he died in 1900."}, {"time": 3216, "text": "Okay, so he's writing in the 1800s."}, {"time": 3219, "text": "And he's basically saying God is dead, and we killed Him, okay?"}, {"time": 3224, "text": "So he's making a historical statement that at that point in time, with science just kind of getting better and industrialization happening, the idea of this thing beyond what we know as material reality is dead."}, {"time": 3245, "text": "So the substrate of Western civilization is dead."}, {"time": 3250, "text": "That's what Nietzsche is saying, if that makes sense."}, {"time": 3260, "text": "And he says there aren't many of them."}, {"time": 3262, "text": "He says, but they're going to come."}, {"time": 3263, "text": "And he also talks about the philosophers of the future."}, {"time": 3266, "text": "And he's speaking and writing to them, is my belief."}, {"time": 3269, "text": "So he's basically telling you and me, because we're now the philosophers of his future."}, {"time": 3276, "text": "He's basically telling us this is what's happening now, and look what it has done."}, {"time": 3281, "text": "He says now everything is possible, all manner of terrible evil, because no one has the belief in God anymore, the belief that there is an afterlife."}, {"time": 3293, "text": "You asked about an afterlife."}, {"time": 3294, "text": "So with this kind of belief in a morality comes this belief, you can have morals without God, okay, people do."}, {"time": 3301, "text": "But Christianity is this idea that you will reap what you sow."}, {"time": 3308, "text": "So if people don't believe that anymore, what will happen?"}, {"time": 3310, "text": "And so that's what he's basically saying, is that the basic anchor for Western society is now gone."}, {"time": 3319, "text": "Absolutely, absolutely right."}, {"time": 3321, "text": "But then again, what do you think if we brought him back to life and he read American Cosmic, your book, and he wrote, he tweeted about it, writing a review maybe for the, I don't know what they post, for New York Times."}, {"time": 3338, "text": "He'd be an editorial writer with a blue check mark on Twitter."}, {"time": 3343, "text": "What do you think he would say about this idea that you present that's a grander idea of religion and, you know."}, {"time": 3352, "text": "Like religiosity, like this new form."}, {"time": 3354, "text": "Yeah, wouldn't that kind of reverse the idea that God is dead?"}, {"time": 3359, "text": "Yeah, because it would bring up this idea of external intelligences that are not human, which is basically a lot of religions talk about that, right?"}, {"time": 3368, "text": "There are bodhisattvas, there are angels, there are demons, you know, there's all these types of non human intelligences that religion makes space for."}, {"time": 3380, "text": "So what I'm basically saying in American Cosmic is these new things are within the realm of UFOs and UAPs."}, {"time": 3388, "text": "So no, I think that, well, I think Nietzsche would say that that's a progressive adaptation of religion is what I would hope he would say."}, {"time": 3398, "text": "Nietzsche, however, is unpredictable, I think."}, {"time": 3401, "text": "I couldn't predict him."}, {"time": 3403, "text": "So I would say that it would be my hope that he would say this is an accurate representation of a move into a new type of religion."}, {"time": 3414, "text": "And it's adaptive, therefore, progressive."}, {"time": 3417, "text": "He would probably be uncomfortable reading a book by a brilliant female professor."}, {"time": 3422, "text": "Who happens also to be short."}, {"time": 3426, "text": "I don't know if you read that."}, {"time": 3427, "text": "He said some pretty nasty things about short women."}, {"time": 3432, "text": "Oh, my God."}, {"time": 3436, "text": "He should be canceled."}, {"time": 3438, "text": "No, no, please don't cancel Nietzsche."}, {"time": 3440, "text": "You have to take people in the context of their time."}, {"time": 3443, "text": "Although I'm pretty sure in his time he was also an asshole."}, {"time": 3448, "text": "But assholes are people too."}, {"time": 3451, "text": "Just bad ones."}, {"time": 3452, "text": "You wrote the book, American Cosmic UFOs, Religion, Technology."}, {"time": 3461, "text": "What was the goal of writing this book?"}, {"time": 3463, "text": "What, maybe we'll mention it."}, {"time": 3466, "text": "We have already mentioned it many times, but in this little space of a conversation, can you say maybe what is the key insight that you found that lingers with you to this day from the process, the long process of putting this book together?"}, {"time": 3485, "text": "Just like with my book on purgatory, I went into the research thinking that it would be something that it was entirely not."}, {"time": 3493, "text": "It ended up being something completely different."}, {"time": 3495, "text": "And I think that's good."}, {"time": 3496, "text": "I think that people who do research are very excited actually when their research surprises them."}, {"time": 3503, "text": "So I was happily surprised by my purgatory book to learn that it was a place."}, {"time": 3510, "text": "And so I went into American Cosmic being a nonbeliever in UFOs entirely."}, {"time": 3519, "text": "And I came out being agnostic."}, {"time": 3524, "text": "Kind of believer."}, {"time": 3529, "text": "But agnostic, sort of open to the mysteries of the world."}, {"time": 3535, "text": "And I didn't think that, first of all, I knew that the government was part of the situation."}, {"time": 3544, "text": "I just didn't know how much."}, {"time": 3546, "text": "And so I learned that quickly and acclimated to it, accepted it, and noted that, indeed, Horatio, the world is much more mysterious than we think it is."}, {"time": 3568, "text": "There are more mysteries in this life than your philosophy provides for."}, {"time": 3573, "text": "So is the sense American Cosmic is about the mysteries of the modern life as encapsulated by the realm of technology and the realm of alien intelligences?"}, {"time": 3592, "text": "I'd have to go off record as a professor and talk personally."}, {"time": 3596, "text": "As a person, I do think that there are mysteries of which we have an inkling."}, {"time": 3606, "text": "And if it's something as powerful as nonhuman intelligence, whether or not it's from another planet, extraterrestrial, or it happens to be from another dimension or something else, I think that this is going to get the attention of institutions of power."}, {"time": 3626, "text": "And indeed, I think that's what has happened."}, {"time": 3629, "text": "And although probably people have had interactions with these things, it appears to me historically for a long time, as long as humans have existed, I would imagine that indeed this is something that's quite powerful and could change the belief structures of our entire societies, our civilization, basically."}, {"time": 3658, "text": "So it's the same way that you're talking the belief structures were strongly affected by religious beliefs throughout history in the same way this has the potential."}, {"time": 3668, "text": "It serves as a source of concern for the powerful because it can have very significant effects on the populace."}, {"time": 3680, "text": "Is there some broader understanding of how we should think about alien intelligences than like little green men that you can maybe elaborate on and talk about?"}, {"time": 3694, "text": "This comes directly out of my research in Catholic history."}, {"time": 3698, "text": "What I found was that let's take, for instance, this idea of an angel."}, {"time": 3703, "text": "Okay, so we all think we know what an angel looks like."}, {"time": 3705, "text": "Well, we've been told what an angel looks like."}, {"time": 3707, "text": "We see what an angel looks like."}, {"time": 3709, "text": "Throughout history, people have painted angels and they all look pretty much the same."}, {"time": 3713, "text": "But actually, if you go to the primary sources on either in Hebrew or in Greek or in whatever language and in Latin, and you look at experiences that people have talked about where they've written down their experiences about angels, angels don't at all look like what we think they look like."}, {"time": 3736, "text": "They don't look like little cherubs with wings."}, {"time": 3738, "text": "They don't look like tall, strong, anthropomorphic, human looking things."}, {"time": 3747, "text": "They look really weird."}, {"time": 3748, "text": "And sometimes they don't look at all humanoid."}, {"time": 3753, "text": "They look like strange spinning things with eyes and things like that."}, {"time": 3759, "text": "They communicate telepathically with us."}, {"time": 3762, "text": "Okay, so what does that mean for the idea of extraterrestrials or what we consider to be aliens?"}, {"time": 3768, "text": "Like, I do think that they're first, if we are, listen, I'm not the first to say this."}, {"time": 3778, "text": "If we're in contact with nonhuman intelligence, we're most likely in contact with its technology."}, {"time": 3786, "text": "Because think about us."}, {"time": 3788, "text": "Do we send human beings to Mars yet?"}, {"time": 3791, "text": "Some people would say yes, but let's put that aside."}, {"time": 3794, "text": "So no, we don't."}, {"time": 3795, "text": "We use our technology."}, {"time": 3796, "text": "We send our rovers to Mars, okay?"}, {"time": 3799, "text": "Okay, so if there's an extraterrestrial civilization, are they coming by themselves?"}, {"time": 3806, "text": "Are they coming to see us?"}, {"time": 3808, "text": "Or are they sending their technology?"}, {"time": 3809, "text": "Most likely they either are technology or they are sending their technology."}, {"time": 3814, "text": "Yeah, there might be a gray area between what is technology and what the aliens are."}, {"time": 3817, "text": "Yeah, so but you're saying like basically a robotic probe that would be the equivalent of us, our human civilization created technology."}, {"time": 3826, "text": "Way more advanced than what we could believe to be a probe, all right?"}, {"time": 3832, "text": "It's kind of funny to think about like if whatever sort of extraterrestrial creations have visited Earth that we're interacting with some like dumb crappy drone technology."}, {"time": 3849, "text": "Yeah, it's true."}, {"time": 3851, "text": "And we're like building these like myths and so on from like an experience with some like crappy drone made by some crappy startup somewhere."}, {"time": 3865, "text": "When the actual intelligence is like something much grander."}, {"time": 3869, "text": "Yeah, that's the more likely situation I describe."}, {"time": 3874, "text": "That's what I like to tell people."}, {"time": 3875, "text": "I'm like, no, it's probably a lot weirder than you think."}, {"time": 3878, "text": "Yeah, oh boy."}, {"time": 3880, "text": "So but what forms can it possibly take?"}, {"time": 3884, "text": "So like I really love this idea that I tend to be humble in the face of all that we don't know and I tend to believe that the form alien life forms would take."}, {"time": 3897, "text": "And the way they would communicate is much more likely to be of a form that we can't even comprehend or perhaps can't even perceive directly."}, {"time": 3908, "text": "So like, you know, it could be in the space of, you know, we don't understand most of how our mind works."}, {"time": 3916, "text": "It could be in the space of whatever the heck consciousness is."}, {"time": 3919, "text": "Like maybe consciousness itself is communication with aliens."}, {"time": 3925, "text": "Or like, I don't know, it could be just our own thoughts is actually the alien life forms communicating."}, {"time": 3937, "text": "Like, I know all that sounds crazy, but I'm saying like, I'm just trying to come up with the craziest possible thing that doesn't make any sense that could very well be true."}, {"time": 3945, "text": "And you can't say it's not true, because we don't understand basically anything about our mind."}, {"time": 3950, "text": "So it could be all of those things, everything from hallucinations, all the things that are explored through the different drugs that we've talked about in this podcast in general."}, {"time": 3965, "text": "Joe Rogan loves to talk about DMT and all those kinds of hallucinogenic drugs."}, {"time": 3969, "text": "All of it, including love and fear, all those things that could be aliens communicating with us, memes on the internet that could be pretty sure here."}, {"time": 3980, "text": "Pretty sure humor is alien communication."}, {"time": 3984, "text": "But is there some way that's helpful for you to think about beyond the little green men?"}, {"time": 3991, "text": "It accords exactly with how I think, actually."}, {"time": 3995, "text": "So I'll explain."}, {"time": 3998, "text": "I liked in American Cosmic, I attained the status of full professor."}, {"time": 4003, "text": "So I was like, OK, I can pretty much write this book like I want to do it."}, {"time": 4007, "text": "So I used a lot of quotes from cool artists like David Bowie."}, {"time": 4012, "text": "So David Bowie opens the book, and he basically says, and so does Nietzsche, by the way."}, {"time": 4016, "text": "David Bowie and Nietzsche, boom, two awesome quotes right together."}, {"time": 4020, "text": "That's how I opened my book."}, {"time": 4021, "text": "No better opener."}, {"time": 4022, "text": "Do you remember the quotes?"}, {"time": 4024, "text": "So the first quote by David Bowie, and that's what I'm going to concentrate on in response to what you just said, which I think is absolutely correct."}, {"time": 4032, "text": "David Bowie said, the internet is an alien life form."}, {"time": 4035, "text": "OK, and if you've not seen David Bowie's interview where he says that, I highly recommend it."}, {"time": 4041, "text": "He's so brilliant."}, {"time": 4042, "text": "OK, so David Bowie is actually quite brilliant about the idea of UFOs."}, {"time": 4047, "text": "He's also brilliant about the idea of technology."}, {"time": 4049, "text": "OK, and most people wouldn't think that, but I mean, he's pretty darn smart."}, {"time": 4054, "text": "OK, so all right."}, {"time": 4056, "text": "So I started to think about it."}, {"time": 4061, "text": "OK, so he's a technologist."}, {"time": 4062, "text": "He has a Ph.D. in information technology from computer science, basically, from Northwestern."}, {"time": 4068, "text": "And he got that back in the day."}, {"time": 4069, "text": "You know, when I say back in the day, I'm not talking a thousand years ago."}, {"time": 4072, "text": "I'm talking like in the 60s."}, {"time": 4073, "text": "OK, so he's back when computer science wasn't really even the field you can get a degree."}, {"time": 4078, "text": "Yeah, he has a Ph.D. in it."}, {"time": 4080, "text": "And he's French."}, {"time": 4081, "text": "He's from France, but he lives in Silicon Valley."}, {"time": 4083, "text": "And he worked on ARPANET, which is the proto internet."}, {"time": 4086, "text": "He mapped Mars."}, {"time": 4087, "text": "He's also an astronomer."}, {"time": 4088, "text": "I mean, he's just this all around brilliant guy, right?"}, {"time": 4091, "text": "And he's also interested in UFOs."}, {"time": 4093, "text": "And most people take those two interests of his as separate interests."}, {"time": 4098, "text": "And I remember being at a very small conference and listening to him, being in awe, of course, because he's an awe inspiring person, and then thinking, wait a minute, why do people compartmentalize those two things about him?"}, {"time": 4110, "text": "They're one in the same."}, {"time": 4112, "text": "OK, so when we talk about UFOs and UAPs and stuff, we have to talk about digital technology and things like that."}, {"time": 4120, "text": "And things like that."}, {"time": 4121, "text": "Now, if we're going back to what I so if I were to say what if I were to believe in and I like I said earlier, I was agnostic bordering on belief, most likely a believer in these this extraterrestrial or not extraterrestrial, let me put it another way, nonhuman intelligence that's communicating with us."}, {"time": 4140, "text": "I'm going to tell you how I think they communicate with us."}, {"time": 4142, "text": "And I go back to the Greeks again."}, {"time": 4144, "text": "OK, and the Greeks had this idea of muses, you know, the muses."}, {"time": 4149, "text": "So, OK, so there are these things called muses and we tend to think of them as metaphors."}, {"time": 4154, "text": "But what if they're not?"}, {"time": 4156, "text": "What if they're actually nonhuman intelligence trying to communicate with us, but we're so stupid?"}, {"time": 4161, "text": "We can't like understand."}, {"time": 4162, "text": "Like, so only people with like, you know, in super amazing capacities, like poetic, creative, you know, intelligent, mathematical, whatever, you know, because they tend to do this symbolically."}, {"time": 4175, "text": "They tend to communicate with us in symbols form."}, {"time": 4178, "text": "And so music, you know, symbols, we've got math that are, you know, it's a symbolic language."}, {"time": 4183, "text": "And so what?"}, {"time": 4183, "text": "So, OK, so muses are probably a good idea for me of what this would be."}, {"time": 4189, "text": "Now, would muses have spaceships, you know, or those things that we call physical counterparts to what they are?"}, {"time": 4198, "text": "That's another question altogether."}, {"time": 4199, "text": "But if, you know, I know why would I think this?"}, {"time": 4202, "text": "Because if you look at the history, there are space programs, both Russian and American, you're going to find some pretty weird stuff, pretty weird history there, Lex."}, {"time": 4212, "text": "So you want to get an idea, go back to Tchaikovsky and read a little bit about what he has to say."}, {"time": 4218, "text": "If you look back at the history of our space programs, the viable space programs are both Russian and American, and each has an amazingly strange history because the founders of the calculations that got us up into space, the rocket scientists, basically, were doing some pretty weird rituals and doing religious things, right?"}, {"time": 4240, "text": "They weren't necessarily, like, Jack Parsons on our side was out in the desert with people like L. Ron Hubbard and doing really intense rituals, believing that they were opening stargates and things like that, OK?"}, {"time": 4253, "text": "And they were really doing that, OK?"}, {"time": 4255, "text": "So then you go to the Russian side, and they had a very specific non dogmatic, according to Catholics or Orthodox Christianity, idea of what Christianity was, and they believed that they were interacting with angels, nonhuman intelligences."}, {"time": 4273, "text": "So if you look back and you see muses, you can contextualize them within this tradition."}, {"time": 4279, "text": "And so when I started to talk to people who were actually in the space program and who were in these programs that now the government has said, oh, yeah, we do have these programs, they have the same belief structures."}, {"time": 4290, "text": "They believe that they were also in contact with these nonhuman intelligences, and they were getting what they called downloads of information and creating, sometimes with Tyler Dee in my book, creating technologies that were real, and they were selling them on NASDAQ for a lot of money, like, say, $100 million or something like that, undisclosed amounts, but a lot."}, {"time": 4312, "text": "And these things are viable technologies that we use now, and they make our lives better, and we progress as a species because of them."}, {"time": 4320, "text": "Now, that has nothing to do with the scientific method."}, {"time": 4324, "text": "As much as I know, as much as anybody's going to get angry at me for saying that, but sorry, those were strange encounters that created our ability to go into space."}, {"time": 4336, "text": "I don't know if they're real or not, but these people believe they were real."}, {"time": 4339, "text": "YARO Right, so they have a power in actually having an impact on this world, in inspiring humans to create technology, which enables us to do things we haven't been able to do before."}, {"time": 4353, "text": "KATE Yeah."}, {"time": 4354, "text": "YARO And these, I like how we're putting angels, alien life forms, aliens, and technology all in the nonhuman intelligence camp, which I really like that because that's very true."}, {"time": 4373, "text": "It's this other source of wisdom, intelligence, maybe a connection to the mysterious."}, {"time": 4381, "text": "KATE Yes, I was really surprised by it."}, {"time": 4405, "text": "Why did you come to believe that they are one and the same, or at least part of the same intellectual journey?"}, {"time": 4416, "text": "KATE Thanks for asking that again, because nobody asks me that question, and it's central to my project."}, {"time": 4426, "text": "So Jacques was a huge influence, is a huge influence on me."}, {"time": 4431, "text": "He taught me a lot."}, {"time": 4434, "text": "He gave me access to some of his information that he keeps."}, {"time": 4440, "text": "But a lot of his information is actually there out there for everyone to read."}, {"time": 4444, "text": "He has an academia.edu page, so he didn't have this, unfortunately, when I was doing my research in 2012 and 2013."}, {"time": 4453, "text": "So I had to go back and do microfiche type stuff."}, {"time": 4456, "text": "What I did was I began to read everything that he wrote, and he actually gave me a lot of his books too."}, {"time": 4461, "text": "And he told me, I remember, he dropped me off from, this is actually quite interesting if you'll allow me to tell you a little story, and it also includes ayahuasca."}, {"time": 4471, "text": "SIMON Great, every story that includes ayahuasca is a great story."}, {"time": 4476, "text": "KATE Okay, so I was at a conference, and it was a small conference of very interesting people in California, on the Pacific Ocean."}, {"time": 4485, "text": "And Jacques was there."}, {"time": 4486, "text": "And this actually opens my book."}, {"time": 4489, "text": "This is the, I go, it's the preface to my book."}, {"time": 4493, "text": "I go on this ride."}, {"time": 4494, "text": "He takes me through Silicon Valley."}, {"time": 4496, "text": "I've lived there, right?"}, {"time": 4498, "text": "My grandparents grew up in the same place that he raised his children, in Belmont."}, {"time": 4503, "text": "And so, but we were there with Robbie Graham, who's a great ufologist in his own right, and film theorist."}, {"time": 4512, "text": "I highly recommend his work."}, {"time": 4514, "text": "So we were together, and he was taking us to San Francisco, where I was going to meet my brother, who was going to take me home."}, {"time": 4520, "text": "And so he took us on this long journey, and he talked to us."}, {"time": 4524, "text": "And as we got out of the car, he gave me several of his books."}, {"time": 4529, "text": "And one in particular he gave me, and he said, read this first."}, {"time": 4534, "text": "And I was like, okay, I definitely will read that first."}, {"time": 4537, "text": "Okay, so this is how the ayahuasca figures in."}, {"time": 4539, "text": "So we were, I didn't take it, nor have I taken it."}, {"time": 4543, "text": "Okay, so we were at this place in California, and Alex Gray and his wife were there."}, {"time": 4549, "text": "And they were talking about their experiences with psychedelics."}, {"time": 4553, "text": "He's an amazing visionary artist, okay?"}, {"time": 4556, "text": "So he believes that there's a place that you can enter, and he and his wife would enter this space with either ayahuasca or LSD or something like that."}, {"time": 4566, "text": "And they would not talk to each other, but they would be having the same exact experience."}, {"time": 4571, "text": "So it was almost like having the same dream, right?"}, {"time": 4574, "text": "Okay, so somehow that whole event with Jacques there, and them talking about their experiences in these realms, of which religious studies people are quite familiar, by the way, because visionary experiences are what we study."}, {"time": 4590, "text": "So all of this seems super familiar to me, and I recognized that immediately that Jacques, that it hit me like, you know, very obvious that UFOs and these experiences and technology all seemed, they were all meshed together."}, {"time": 4610, "text": "And I knew that I had to take them, I knew I had to read everything Jacques ever wrote."}, {"time": 4614, "text": "And the best stuff he's written, by the way, is his little essays that he wrote in the 1970s, and they were peer reviewed essays about the beginning of the internet and how a lot of it was based on basically neural connection with the internet, like somehow psychic connection through the internet with others and things like that."}, {"time": 4635, "text": "So the brain is a biological neural network, there's this connection between visual neurons and so on, and that's what ultimately is able to have memories and has cognitive ability and is able to perceive the world and generate ideas."}, {"time": 4651, "text": "And those ideas are then spread on the internet, even from the very early days to other humans."}, {"time": 4657, "text": "So it gets injected or travels into the brains of other humans and that goes around in there and then spits out other stuff and it goes back and forth."}, {"time": 4665, "text": "So it's nice to think of the network that's in our mind, individual mind as, I mean, very much even deeply connected to the network that is the connection between humans through the internet."}, {"time": 4680, "text": "And so in that sense, Jacques saw the internet as this powerful, as a source of power and wisdom that is beyond our own."}, {"time": 4691, "text": "Exactly, that's external to us, like if you could call it autonomous AI, right?"}, {"time": 4697, "text": "It's nonhuman intelligence in a sense, even though humans are a part of it."}, {"time": 4701, "text": "Yes, or we're invaded by it or whatever you want to call it."}, {"time": 4704, "text": "Yeah, whoever, right, it's the chicken and the egg, right."}, {"time": 4708, "text": "So if I can go on, I don't want to experience things, I'm not done with that."}, {"time": 4713, "text": "So this is where I come to this idea that we're in this space, we're in now a new space of religion, of religiosity."}, {"time": 4723, "text": "So what happens is then, and it's like a biosphere and I'll talk about that in a minute."}, {"time": 4728, "text": "So Jacques takes us back, we get to San Francisco and my brother, who is your straight lace person, army guy and everything like that, I get into his car and the first thing he tells me is, I took ayahuasca and I was like, what?"}, {"time": 4744, "text": "And he goes, it's going to save humanity."}, {"time": 4747, "text": "As I mentioned to you offline, I talked to Matthew Johnson, he's a Hopkins professor and he's really a scholar of most, he's studied most drugs, he's also really deeply studied cocaine and all those stuff and negative effects and he's focused on a lot of positive effects of the different psychedelics."}, {"time": 4771, "text": "So I'm very much interested in exploring the science of what these things do to the human mind and also personally exploring it."}, {"time": 4783, "text": "Although it's like this weird gray area, which he's masterful at, which is he's a professor at John Hopkins, one of the most prestigious universities in the world and doing large scale studies of this stuff and until he got a lot of money for these studies, even in Hopkins itself, there's not much respect."}, {"time": 4805, "text": "It's not even respect, it was like people just didn't want to talk about it as a legitimate field of inquiry."}, {"time": 4813, "text": "It's kind of fascinating how hesitant we are as a little human civilization to legitimize the exploration of the mysterious, of whatever the definition of the mysterious is for that particular period of time."}, {"time": 4829, "text": "So for us now, there's like little groups of things."}, {"time": 4832, "text": "I would say consciousness in the space of computer science research is something that's still like, I don't know, maybe let philosophers kick it around for a little longer."}, {"time": 4843, "text": "And then certainly extraterrestrial life forms in most formulations of that problem space is still the other, it's still the source of the mysterious, except maybe like SETI, which is like, how can we detect signals from far away alien intelligences that we'll be able to perceive?"}, {"time": 4870, "text": "And psychedelics is another one of those that's like, we're starting to see, okay, well, can we try to see if there's some medical applications of like helping you get, like he does studies of help you quit smoking or help you in some kind of treatment of some disease."}, {"time": 4887, "text": "And he's sneaking into that, I mean, it's like openly sneaking into it, he's doing studies on it of like, how can you expand the mind with these tools and what can the mind discover through psychedelics and so on."}, {"time": 4902, "text": "And we're like slowly creeping into the space of being able to explore these mysterious questions."}, {"time": 4908, "text": "But it's like, it sucks that sometimes a lot of people have to die, meaning, sorry, they have to age out."}, {"time": 4918, "text": "Like it's like faculty have, and people have a fixed set of ideas and they stick by them."}, {"time": 4926, "text": "In order for new ideas to come in, then the young folks have to be born with an open mind, the possibility of those ideas, and then they have to become old enough and get A's in school and whatever to then carry those ideas forward."}, {"time": 4941, "text": "So the acceptance of the exploration of the mysterious takes time."}, {"time": 4948, "text": "It is sad."}, {"time": 4951, "text": "Maybe to go into my source of passion, which is artificial intelligence."}, {"time": 4958, "text": "What's your sense about the possibility, like Pamela McCordick has this quote that I like, I talked to her a couple of years ago, I guess already on this podcast, that artificial intelligence began with the ancient wish to forge the gods."}, {"time": 4980, "text": "So do you think artificial intelligence may become the very kind of gods that were at the center of our, the religions of most of our history?"}, {"time": 4997, "text": "Yeah, there's a lot there."}, {"time": 4999, "text": "So I'm going to start by addressing this idea of artificial intelligence being separate from human beings."}, {"time": 5007, "text": "So I don't think that's actually, that might happen."}, {"time": 5014, "text": "I mean, it's already happened, but let's put it this way."}, {"time": 5016, "text": "You're talking about super artificial intelligence, like autonomous, conscious artificial intelligence?"}, {"time": 5024, "text": "Something with artificial consciousness."}, {"time": 5025, "text": "First of all, I think she's correct, but also there's an awesome quote."}, {"time": 5032, "text": "I'd also like to bring up this writer of fiction, actually, Ted Chiang, and one of his essays, he writes short essays."}, {"time": 5041, "text": "One of them was The Basis for the Movie Arrival, which if you haven't seen it, it's a really great movie about UFOs, and it has a very creative way of proposing an idea of how they might be able to communicate, first of all, how they appear to us, and second of all, how they may be communicating with us humans."}, {"time": 5065, "text": "The author Ted Chiang has a lot, I recommend his writings, his short stories."}, {"time": 5072, "text": "One is very short, and it appeared in Nature about 20 years ago, and it is called, I think it's called Eating the Crumbs from the Table or something like that, and it's basically this short essay, and I hate to do a spoiler here, but if you don't want to know what it's about, don't listen right now for five minutes."}, {"time": 5094, "text": "Yeah, spoiler alert."}, {"time": 5097, "text": "So this is what it's about."}, {"time": 5098, "text": "So basically it's about human beings becoming two different species, okay?"}, {"time": 5103, "text": "And one of them is created, they're called metahumans, and they start biohacking themselves with tech."}, {"time": 5111, "text": "Sound familiar?"}, {"time": 5112, "text": "So they do this, and they become metahumans and another species, right, and just kind of another fork, such that humans can barely understand them because they're so far removed."}, {"time": 5128, "text": "So in a sense, are they gods, right?"}, {"time": 5132, "text": "No, they're metahumans, they're superhumans, they're enhanced humans, okay?"}, {"time": 5135, "text": "I see that hopefully on the horizon, frankly."}, {"time": 5139, "text": "Not that we have two species, but that we can use our technology or we can become so integrated with our technology that we can survive, okay?"}, {"time": 5150, "text": "We can survive the radiation in space."}, {"time": 5153, "text": "We can't go places now because of the radiation in space."}, {"time": 5156, "text": "Perhaps we can develop our bodies such that we can survive the radiation in space."}, {"time": 5161, "text": "So there's this idea of these metahumans."}, {"time": 5163, "text": "Now, there's also this idea that technology is just another form of humans."}, {"time": 5169, "text": "We've created it, right?"}, {"time": 5171, "text": "And so maybe it is bent on surviving, thereby using us kind of as a meme or a team."}, {"time": 5178, "text": "Some people are calling them teams now, these self generating, they're replicating themselves through us, okay?"}, {"time": 5184, "text": "I see that also, and I don't think that's terribly bad."}, {"time": 5189, "text": "Maybe it's just the way that we are evolving."}, {"time": 5192, "text": "It doesn't mean that we're evolving all the time, like we're taller than we used to be, we have different skills."}, {"time": 5200, "text": "So I don't see that as a bad thing."}, {"time": 5203, "text": "I think a lot of people see it as if we're not how we are now, it's a tragedy."}, {"time": 5207, "text": "But it's not a tragedy."}, {"time": 5208, "text": "How we are now is actually a tragedy for most people alive."}, {"time": 5211, "text": "Yeah, and we might be evolving in ways we can't possibly perceive."}, {"time": 5214, "text": "Like you said, that humans have created Twitter and Twitter may be changing us in ways that we can't even understand now, currently."}, {"time": 5226, "text": "From a perspective, if you look at the entirety of the network of Twitter, that might be an organism that the organism understands what's happening from its level of perception."}, {"time": 5240, "text": "But we humans are just like the cells of the human body, we're interacting individually, but we're not actually aware of the big picture that's happening."}, {"time": 5249, "text": "And we naturally somehow, or whatever the force that's creating the entirety of this, whatever one version of it is the evolutionary process, like biological evolution, whatever force that is, is just creating these greater and greater level of complexity, and maybe somehow not other kinds of non human intelligence are involved that we're calling alien intelligences."}, {"time": 5275, "text": "So just to step back, and we'll come back to AI, because I love the topic, but through American Cosmic and in general, you've interacted with much of the UFO community, you mentioned ufologists."}, {"time": 5286, "text": "By the way, is it ufologists or is it ufologists?"}, {"time": 5292, "text": "It's ufologists."}, {"time": 5293, "text": "Ufologists."}, {"time": 5295, "text": "So first of all, what is a ufologist?"}, {"time": 5297, "text": "And second of all, what have you learned about this community of ufologists?"}, {"time": 5303, "text": "Or also as you refer to them as the invisibles, or the members of the invisible college, or just in general, people who study UFOs from the different, all the different kinds of groups that study UFOs?"}, {"time": 5317, "text": "Generally, what I found is that they are okay, so people who are interested in UFOs from like being a kid, you know, and seeing some cool movie like Star Wars or something, and then they become interested, and then they study it as best they can, UFOs, or UAPs."}, {"time": 5334, "text": "They're generally an honest group of people who are using their tools, and they're generally two types of them."}, {"time": 5343, "text": "There are those who believe in the nuts and bolts, like the physical craft, and they believe in that these are things from other planets, okay?"}, {"time": 5350, "text": "So that's like the ETH hypothesis, you know."}, {"time": 5355, "text": "I'm sorry, ETH hypothesis, ETH is what we call it."}, {"time": 5360, "text": "Sorry about that."}, {"time": 5361, "text": "So this is like there's an actual spaceship, like something akin, but much more advanced than the rockets we use now."}, {"time": 5369, "text": "And there's some kind of, not necessarily biological, but something like biological organisms that travel on these spaceships."}, {"time": 5378, "text": "So this would be like what, to the Star Academy, is trying to decipher, like how, you know, how do they do it?"}, {"time": 5384, "text": "You know, maybe we could use that technology, the propulsion and things like that."}, {"time": 5388, "text": "They look at the rocket technology."}, {"time": 5390, "text": "Okay, so there are those, and then there are people who believe that it's more consciousness based, okay?"}, {"time": 5395, "text": "So these are your two types of ufologists who are known, and these are people who we know about."}, {"time": 5429, "text": "And so they had to be really careful."}, {"time": 5431, "text": "So he called it the invisible college."}, {"time": 5433, "text": "So Hynek took that term and reused it, or what do you call it, repurposed it."}, {"time": 5439, "text": "So he repurposed it."}, {"time": 5441, "text": "So they were still talking to each other, though."}, {"time": 5444, "text": "So what I found to be the case was that there was a group of people who were scientists but were not on the internet."}, {"time": 5451, "text": "You know, people today, and students of mine in particular, and my own kids, actually, they think that you only exist if you're on the internet or something only exists if it's on the internet."}, {"time": 5462, "text": "And that's, of course, untrue."}, {"time": 5464, "text": "And so what I found was that most people who are the most powerful people of our society and are doing things are not on the internet."}, {"time": 5470, "text": "You're not going to find any trace of them."}, {"time": 5472, "text": "So a lot of these people are what I call invisibles, people who are studying, at least their work is invisible."}, {"time": 5479, "text": "You might find them on the internet, but you're going to find that they're part of the bowling league or something like that."}, {"time": 5484, "text": "You will not find that they are actually engaged in research about this topic."}, {"time": 5490, "text": "And so I called them the invisibles because I was surprised to find them."}, {"time": 5493, "text": "And I thought, well, this is no longer the invisible college because these people are not even talking to each other."}, {"time": 5499, "text": "And that's why I reference this movie Fight Club."}, {"time": 5502, "text": "In it, you have an invisible, and his name is Tyler Durden, and he's incredible."}, {"time": 5509, "text": "He does incredible things."}, {"time": 5512, "text": "He's like a person who should not exist because he does so many things that are amazing."}, {"time": 5518, "text": "And so I found a person like that, and he's a real person."}, {"time": 5522, "text": "He's partially on the internet, but nothing that he does around that topic of UFOs is on the internet."}, {"time": 5528, "text": "So I decided to call him Tyler D after Tyler Durden."}, {"time": 5531, "text": "And so these people, I've termed the UFO Fight Club because they work together, but they don't know, in fact, his boss doesn't know what he does."}, {"time": 5540, "text": "They don't talk to each other because, you know, the first rule of Fight Club."}, {"time": 5545, "text": "Same as the second, yeah."}, {"time": 5547, "text": "You don't talk about people."}, {"time": 5548, "text": "No, you don't do it."}, {"time": 5550, "text": "Why do you have a sense that there's such a, I don't want to say fear, but a principle of staying out of the limelight?"}, {"time": 5559, "text": "I think there's something real, and I think that the use of it could be dangerous for people."}, {"time": 5565, "text": "Oh, sorry, you mean like something real, like there's actual, I don't know, what's the right terminology here to use it?"}, {"time": 5573, "text": "Alien technology, ideas about technology that are being explored that are dangerous have made public, that may become dangerous have made public."}, {"time": 5585, "text": "So that's the word."}, {"time": 5586, "text": "You don't have to call it alien technology."}, {"time": 5589, "text": "You can call it ideas about alien technology because I don't know if it's actual alien technology or not."}, {"time": 5594, "text": "I honestly don't know."}, {"time": 5596, "text": "But I do know for a fact, because it's a historical fact, that Jack Parsons and Konstantin Tchaikovsky, who's Russian, believed in these things and believed that they were downloading this information."}, {"time": 5609, "text": "Whether or not they were, I don't, I mean, they definitely created the rocket technologies."}, {"time": 5616, "text": "How they did and whether their process was exactly what they said it was, I don't know."}, {"time": 5621, "text": "So this is the same thing today."}, {"time": 5622, "text": "So we've got some powerful technologies going on here."}, {"time": 5626, "text": "And of course we have a military and we have a military for a reason."}, {"time": 5630, "text": "Almost every government who needs a military has one."}, {"time": 5633, "text": "And so they're going to keep these the way they should be kept, in my interpretation."}, {"time": 5641, "text": "Everybody accepts the fact that we have a military."}, {"time": 5643, "text": "Almost everybody does."}, {"time": 5644, "text": "Why are they so upset then that the military keeps secrets?"}, {"time": 5649, "text": "Well, that's the nature of things."}, {"time": 5651, "text": "We can get into that whole thing."}, {"time": 5653, "text": "I tend to, I've spoken with the CTO Lockheed Martin on this, I obviously read and think about war a lot."}, {"time": 5663, "text": "It's such a difficult question because this space, this particular space of technology, there's a gray area that I think is evolving over time."}, {"time": 5674, "text": "I think nuclear weapons change the game in terms of what should and shouldn't be secret."}, {"time": 5680, "text": "I think there's already technology that will enable us to destroy each other."}, {"time": 5685, "text": "And so there's some sense in which some technology should be made public."}, {"time": 5689, "text": "This is the same discussion of, you know, between companies, which part of your technology should you make public through like, for example, academic publications and all that kind of stuff."}, {"time": 5702, "text": "Like how the Google search engine works, PageRank algorithm, or how the different deep learning, like there's pretty vibrant machine learning research communities within Google, Facebook and so on."}, {"time": 5713, "text": "And they release a lot of different ideas."}, {"time": 5716, "text": "It's an interesting question, like how dangerous is it to release some of the ideas?"}, {"time": 5720, "text": "I think it's a gray area that's constantly changing."}, {"time": 5724, "text": "I do also think it's super interesting."}, {"time": 5727, "text": "I wonder if you could elaborate on a little bit that there's this gray area between what's actually real in terms of alien technology and the belief of it when held in the minds of really brilliant people that they ultimately may produce the same kind of result in terms of being able to create new technologies that are human usable."}, {"time": 5756, "text": "Like is there, in your mind, they're one in the same as like believing in alien craft and actually being in possession of an alien craft?"}, {"time": 5772, "text": "I don't think they're the same, no."}, {"time": 5774, "text": "Belief is powerful, okay?"}, {"time": 5777, "text": "In new age communities, you know, people think thoughts are things, okay?"}, {"time": 5782, "text": "That's been said, you know, thoughts are things."}, {"time": 5784, "text": "You can make them happen kind of thing, believe in them enough."}, {"time": 5787, "text": "It is true that if I believe I can run a 540 mile, I'll do it, okay, and I probably will do it."}, {"time": 5795, "text": "And I've done it before actually, much younger, but I did it."}, {"time": 5801, "text": "But my coach is the one that instilled that belief in me, right?"}, {"time": 5804, "text": "And so, but can I run like a one minute mile?"}, {"time": 5810, "text": "So I guess, does that answer your question?"}, {"time": 5811, "text": "Like there's only so far belief goes in generating reality."}, {"time": 5830, "text": "I could be wrong, but this is what I think Jacques getting at."}, {"time": 5833, "text": "There are other ways to access places in reality other than what we consider to be physical."}, {"time": 5840, "text": "There's consciousness, okay?"}, {"time": 5843, "text": "So like I said, so religious studies is, among other things, it's looking at visionary experiences, all right?"}, {"time": 5851, "text": "So people do have visionary experiences."}, {"time": 5853, "text": "They did without drugs, they did with drugs, they do with drugs, they do, many have them without drugs today."}, {"time": 5860, "text": "And oftentimes those visionary experiences correspond to each other."}, {"time": 5866, "text": "Now how do we make sense of that?"}, {"time": 5868, "text": "So do these places actually exist?"}, {"time": 5872, "text": "In a sense, I think they do."}, {"time": 5874, "text": "And so I think that, let's take that very famous case of a Virgin Mary apparition in Fatima where I think there was like a lot of people, thousands and thousands, if not like I think 50,000 or something like that, a lot of people gathered to see what's now called the miracle of Fatima, which was the spinning of the sun."}, {"time": 5894, "text": "Well, a lot of people saw different things, but they all saw some kind of thing, okay?"}, {"time": 5900, "text": "So they all saw different things, but it was, something happened, okay?"}, {"time": 5905, "text": "So I guess the question is, what are these places where we access what I'd call like nonphysical realities, okay?"}, {"time": 5918, "text": "Where we actually do get information, like who could say that Jack Parsons didn't get information from doing these rituals and accessing these?"}, {"time": 5925, "text": "We have to say that he actually did because we see the results, the physical results."}, {"time": 5930, "text": "The same thing with Tyler, and that's why I put Tyler in this camp with this tradition with Jack Parsons."}, {"time": 5936, "text": "I say that Tyler is getting these, what he calls downloads, and you can see the results of them physically."}, {"time": 5945, "text": "He sells them on the Nasdaq."}, {"time": 5946, "text": "He makes millions of dollars from them."}, {"time": 5948, "text": "They help people."}, {"time": 5949, "text": "I've seen people who they've helped, okay?"}, {"time": 5954, "text": "Do you think psychedelics that I just mentioned earlier have a possibility of going to these kind of, same kind of places of exploring ideas that are outside of our more commonplace understanding of the world?"}, {"time": 5977, "text": "In my, yeah, I think so, absolutely, however, I think we have to be really careful about those because young people or people in general, I should say, absolutely can get hurt by them."}, {"time": 5988, "text": "I mean, but we get hurt by alcohol, you know, we drive our cars and we kill each other."}, {"time": 5993, "text": "But psychedelics are really interesting because I know that within the history of our country, we have used psychedelics in various capacities for our military in order to try to stimulate ideas and access places and information that can't be accessed normally."}, {"time": 6013, "text": "This is all fact."}, {"time": 6015, "text": "I talked to Matt for like four hours, so we ran out of time being able to talk, but I wanted to talk to him about MK Alter and Ted Kaczynski."}, {"time": 6025, "text": "There's so many mysterious things there."}, {"time": 6027, "text": "There's like layers of what's known or what's not known, it's fascinating."}, {"time": 6031, "text": "But I think what is interesting is psychedelics were used or were attempted to be used as tools of different kinds."}, {"time": 6041, "text": "So like we think of technology as tools to enable us to do things in that same way that psychedelics, like many drugs could be used as tools, some more effective than others."}, {"time": 6055, "text": "I'm not sure what you can do effectively with alcohol, although I think somebody commented somewhere on social media that, I don't know why everyone is so negative about alcohol because I think the person said that it's given me some of the most incredible, it enabled me to let go and have some of the most incredible experiences with friends in my life."}, {"time": 6083, "text": "And it's true."}, {"time": 6084, "text": "People sometimes say alcohol is dangerous, it can make you do horrible."}, {"time": 6088, "text": "But the reality is it's also a fascinating tool for letting go of trying to be somebody maybe that you're not and allowing you to be yourself fully in whatever crazy form that is and allow you to have really deep and interesting experiences with those you love."}, {"time": 6106, "text": "So yeah, even alcohol can be used as an effective tool for exploring experiences and becoming expanding your mind and becoming a better person."}, {"time": 6117, "text": "So what the hell was I talking about?"}, {"time": 6122, "text": "So yes, so psychedelics and MK Ultra, is there something interesting to say in our historical use of psychedelics?"}, {"time": 6132, "text": "I mean, think about it, when did we start doing that?"}, {"time": 6135, "text": "When did we start using those?"}, {"time": 6138, "text": "It's quite a long time ago, right?"}, {"time": 6140, "text": "But okay, but true, but when did our government start experimenting with them with us?"}, {"time": 6146, "text": "Our government is the United States government."}, {"time": 6150, "text": "So that happened in around the 1950s."}, {"time": 6153, "text": "After quote unquote, the 1940s, where we have 47 and we have this Roswell type stuff going on, like crash sites and things like that."}, {"time": 6165, "text": "So I think that there might be a correlation there."}, {"time": 6170, "text": "I don't know what it is."}, {"time": 6172, "text": "But I do think... That's fascinating actually."}, {"time": 6175, "text": "A lot of interesting things started around that time period."}, {"time": 6179, "text": "And so Aldous Huxley would say, we opened the doors of perception, okay, and what flew in."}, {"time": 6185, "text": "Oh man, that was beautifully put."}, {"time": 6190, "text": "It'd be interesting to get your opinions on certain more concrete sightings that are sort of monumental sightings with alien intelligences in the history, in the recent history that at least I'm aware of, I'm not very much aware of this history."}, {"time": 6212, "text": "But the most recent one, I've spoken with David Fravor on this podcast, I really like him as a person."}, {"time": 6219, "text": "He's a fun guy, but also he's gotten a chance to..."}, {"time": 6224, "text": "He's described his account of having an experience with what he and others now term the TikTok UFO."}, {"time": 6231, "text": "What do you think of that particular sighting, which has captivated the imagination of many in particular because there's been videos released of it, of these UFOs."}, {"time": 6241, "text": "But I find the videos to be way too blurry and grainy to be of interest to me personally, to me the most fascinating thing is the first person account from David and others about that experience."}, {"time": 6256, "text": "But what are your thoughts?"}, {"time": 6258, "text": "Those videos have been out for a while, actually much, I think in the mid 2000s they were out."}, {"time": 6264, "text": "But what you have is you have kind of like this corroboration from a group and also the New York Times involvement in 2017."}, {"time": 6274, "text": "My opinion about the TikToks is that first, I believe the people who have had the experiences, I know some of them, like some of the radar people and things like that, they'd saw them and they're not..."}, {"time": 6286, "text": "I don't believe they're making it up, okay."}, {"time": 6288, "text": "I do think that this is being used as a spin, okay, and I'm just gonna say that."}, {"time": 6295, "text": "And the reason I think that is this is because at the time it was released, I was still in touch with many people who were among the UFO Fight Club."}, {"time": 6304, "text": "And so they had intimate knowledge of these things."}, {"time": 6307, "text": "And the first thing they said was, we have satellites that can read the news on your phone when you're reading it."}, {"time": 6314, "text": "So we've got better footage than this and this is not good footage at all."}, {"time": 6319, "text": "Therefore they believe that it was authentic footage that had been doctored up."}, {"time": 6324, "text": "Now, why?"}, {"time": 6329, "text": "So I honestly don't know if it's accurate or not."}, {"time": 6331, "text": "I mean, I believe the people, absolutely, but was this something out there to fool these people?"}, {"time": 6339, "text": "Is it spun?"}, {"time": 6341, "text": "The people who I know who are part of the UFO Fight Club believed it was real, okay, and said, this is badly done, but real."}, {"time": 6350, "text": "But so there's some kind of..."}, {"time": 6351, "text": "When you say spinning, there's some parties involved that are trying to leverage it from the... For funds, probably."}, {"time": 6358, "text": "For funds, for financial interests."}, {"time": 6361, "text": "Nevertheless, it has inspired a conversation and just a lot of people in the world that there's something mysterious out there that we're not fully informed about."}, {"time": 6376, "text": "And I was certainly grateful that the New York Times ran the story right before my book came out."}, {"time": 6381, "text": "Well, see, but there's the financial interest that to me, as a person who doesn't give a damn about money, actually, I don't like money, except for when it's used in the context of a company to build cool things."}, {"time": 6397, "text": "But personally, I don't know, I find the financial interest side off putting, especially when we're talking about the exploration of some of the most... Money is a silly creation of human beings."}, {"time": 6412, "text": "And it's used to provide temporary..."}, {"time": 6418, "text": "The unfortunate thing with money is that it helps you buy things that too easily allow you to forget the important things in life and also to forget the difficult aspects of life, to do the difficult intellectual work of being cognizant of your mortality, of fully engaging in life, in a life of reason too, of thinking deeply about the world, all those kinds of things."}, {"time": 6446, "text": "If you get a nice car or something like that and just, I don't know, all the different things you can do with money, it can make you forget that."}, {"time": 6454, "text": "Anyway, there's a long way to say that, yes, yes, it's very nice that it coincided nicely with the book."}, {"time": 6462, "text": "But also, I think it, like I said, I think it inspired quite a lot of people that maybe there's a lot of things out there that were..."}, {"time": 6473, "text": "It reminded a lot of people, there's things out there we don't know about."}, {"time": 6476, "text": "Lex, I can agree with you on that, but can I push back on two things?"}, {"time": 6484, "text": "The first one is that I was happy to receive money from the book because of the New York Times article."}, {"time": 6487, "text": "That's absolutely false."}, {"time": 6489, "text": "So I published my book with Oxford, which is an academic press, and you don't get paid with an academic press."}, {"time": 6496, "text": "So money was not it for me."}, {"time": 6498, "text": "What it was, was recognition that my research was being validated."}, {"time": 6501, "text": "So because then people called me and said, well, maybe it's more than interesting."}, {"time": 6507, "text": "And they did."}, {"time": 6509, "text": "The other thing about money is just as you say that, now I agree with you, I'm upset about money too."}, {"time": 6516, "text": "I think there should be universal health care, a universal income."}, {"time": 6520, "text": "I don't think people should be in poverty, especially because we are so wealthy as a species, frankly."}, {"time": 6526, "text": "That said, think about this, if you don't have money, you can't have a life of the mind either."}, {"time": 6536, "text": "So I'm not espousing that money is the devil."}, {"time": 6537, "text": "I just think that money can be a drug."}, {"time": 6544, "text": "Or I would compare it to like food or something like that, where like you really should have enough to nourish yourself."}, {"time": 6553, "text": "And too much can be a huge problem."}, {"time": 6557, "text": "So that's where I come from with money."}, {"time": 6559, "text": "And I'm just aware, I'm fortunate enough to have the skills and the health to be able to earn a living in whatever way, like I wish of having being in the United States and being able to speak English."}, {"time": 6571, "text": "So the very least I could work with McDonald's and my standards are, I told Joe, I made a mistake."}, {"time": 6578, "text": "I told Joe Rogan that I've always had a few money and people are like, oh, Lex was always rich."}, {"time": 6586, "text": "I was always broke."}, {"time": 6587, "text": "What I mean by I've always had a few monies, my standard, what it takes to have a few is always very little."}, {"time": 6595, "text": "I'm just happy with very little."}, {"time": 6597, "text": "But yes, it's true that money for many people, including for myself, it's just a different level for different people, is freedom."}, {"time": 6607, "text": "Freedom to think, freedom to pursue your passions."}, {"time": 6611, "text": "It just so happens I am very fortunate that many of my passions often come with a salary if I wished."}, {"time": 6620, "text": "So everything like me, I love programming."}, {"time": 6623, "text": "So even just like working as a basic level software engineer will be a source of a lot of joy for me."}, {"time": 6630, "text": "And that happens in this modern world to come with a salary."}, {"time": 6634, "text": "So yeah, it's definitely true."}, {"time": 6636, "text": "I just mean that it can become a dangerous drug."}, {"time": 6638, "text": "So I'm glad you are in this pursuit that you are in for the love of knowledge."}, {"time": 6649, "text": "People should definitely buy your book."}, {"time": 6651, "text": "I won't be making money off of it."}, {"time": 6653, "text": "Oh yeah, it's true actually."}, {"time": 6656, "text": "Maybe my next book."}, {"time": 6660, "text": "Your sense is there's some groups of people that may be trying to leverage this for financial gains."}, {"time": 6673, "text": "And you know, probably good financial, I mean, they may have good reasons for this too."}, {"time": 6677, "text": "Like, okay, let's take the study of UFOs, okay?"}, {"time": 6680, "text": "Maybe many people in government that decide who dole out the money, let's put it that way, they think UFOs aren't real."}, {"time": 6687, "text": "So they're not going to give these programs money."}, {"time": 6690, "text": "So how do these programs make money?"}, {"time": 6693, "text": "They're going to have to find a way to do it."}, {"time": 6694, "text": "So maybe that's how they do it."}, {"time": 6697, "text": "So I... That's fascinating."}, {"time": 6699, "text": "This is a way to raise money for science."}, {"time": 6702, "text": "Doing the research."}, {"time": 6704, "text": "So let's take a step back to Roswell, we talked about it a little bit."}, {"time": 6709, "text": "What's your sense about that whole time, Roswell and just Area 51, and the sightings, and also the follow on mythology around those sightings?"}, {"time": 6722, "text": "That's with us today."}, {"time": 6725, "text": "So... Where do I get started?"}, {"time": 6727, "text": "Well, I mean, it is a mythology here, right?"}, {"time": 6730, "text": "The mythology of Roswell, it's very religious like in the sense that there's a pilgrimage to Roswell people make and they go to, there's a festival there as well, like a religious festival."}, {"time": 6743, "text": "You can get little kitschy stuff like you can get at a religious festival there."}, {"time": 6746, "text": "So it's very much like a place of pilgrimage where a herophany occurred and a herophany is basically contact with nonhuman intelligence."}, {"time": 6755, "text": "So nonhuman intelligence is thought to have contacted humans or crashed at this place in Roswell, New Mexico."}, {"time": 6762, "text": "Now what's fascinating is that I begin my book by going out to a crash site in New Mexico."}, {"time": 6768, "text": "I have to get blindfolded with my, well, to tell you the truth, the story is that I'm with Tyler, who's an invisible, and he wants to show me a place in New Mexico where a crash happened."}, {"time": 6782, "text": "And he says that he thinks that I need to see physical evidence because I don't believe."}, {"time": 6788, "text": "And so I said, I'll go, but I'm going to bring a friend of mine."}, {"time": 6791, "text": "And he said, no, you have to go alone."}, {"time": 6792, "text": "He goes, it's a place that is on government owned property and it's a no fly zone."}, {"time": 6799, "text": "And when you go, you'll be blindfolded."}, {"time": 6802, "text": "And I said, I definitely need to bring a friend."}, {"time": 6807, "text": "So he said, well, who do you want to bring?"}, {"time": 6809, "text": "I just had met this university scientist who's very well known and I call him James in my book."}, {"time": 6816, "text": "And I asked, and I had a feeling James would definitely want to do this."}, {"time": 6820, "text": "And I asked James and he said, I'll go tomorrow."}, {"time": 6823, "text": "So I suggested this to Tyler and Tyler said, absolutely not."}, {"time": 6828, "text": "And I thought, I know he's going to look up James and he's going to say yes, because if anybody can figure out what this material is that you're going to go look for, it's going to be James."}, {"time": 6837, "text": "He has the instruments."}, {"time": 6839, "text": "And so Tyler did, in fact, look him up and finally said, okay, you can go."}, {"time": 6844, "text": "So we both head out there and we get blindfolded and Tyler takes us out there."}, {"time": 6847, "text": "It takes about 40 minutes outside of a certain place in New Mexico."}, {"time": 6851, "text": "So in terms of Roswell, this is what I can say is that according to Tyler, there were about seven crashes out in the 1940s in New Mexico in various places."}, {"time": 6865, "text": "We went to one of them according to Tyler."}, {"time": 6869, "text": "At the time I was completely an atheist with regard to anything that had to do with UFOs."}, {"time": 6873, "text": "So we were out there, we had specially configured metal detectors for these metals."}, {"time": 6881, "text": "And we did find these, okay."}, {"time": 6884, "text": "And they've since been studied by various scientists, material scientists, so forth."}, {"time": 6889, "text": "And I believe Jacques talked about not those particular ones, but others on the Joe Rogan show."}, {"time": 6898, "text": "They're anomalies, so there are scientists, I'm not a scientist, so I can't weigh in on whether, I just believe the people, these people I believe because they're well known scientists."}, {"time": 6913, "text": "What do you mean they're not anomalies?"}, {"time": 6914, "text": "No, they are anomalous."}, {"time": 6915, "text": "Oh, anomalous in terms of the materials that are naturally occurring on earth."}, {"time": 6924, "text": "Okay, so there's some kind of inklings of evidence that something happened in Roswell in terms of crashes of alien technology."}, {"time": 6940, "text": "What else is there to the mythology?"}, {"time": 6942, "text": "So there's some crashes, right?"}, {"time": 6946, "text": "I mean, that's kind of epic."}, {"time": 6947, "text": "It's pretty epic, yeah."}, {"time": 6950, "text": "And what else, like what are we supposed to take away from this?"}, {"time": 6956, "text": "So it's weird."}, {"time": 6957, "text": "Okay, so there's this, okay, so in religious studies, like I said, we call it a herophany, which is the meeting of a nonhuman intelligent thing, whatever it is, an angel, a god, whatever, a goddess with, or an alien, with humans."}, {"time": 6972, "text": "And that's the place, okay, so the place is New Mexico."}, {"time": 6976, "text": "So New Mexico becomes folded into the mythology of this new religion, is what I call a new type of religion, of the UFO."}, {"time": 6986, "text": "And it becomes ground zero for this new mythology."}, {"time": 6990, "text": "Just like Mecca is the place where Muslims go, they have to go, right, at least once in their lives, it's a pilgrimage place now."}, {"time": 6998, "text": "So in my book, that's how I tell it."}, {"time": 7001, "text": "Now what about Roswell in the public imagination?"}, {"time": 7005, "text": "Really according to Annie Jacobson, who's good, she's a great author, investigative journalist, she's written about Roswell too."}, {"time": 7013, "text": "I don't agree with all of what she comes up with, but part of it is that there's a lot of military stuff going on there that is classified, and there's a reason why you can't get in, and nor would you want to, right?"}, {"time": 7027, "text": "So there's a lot of experimentation going on there."}, {"time": 7030, "text": "I don't believe that it has to do with ETs, frankly, but in the imaginations of Americans, Roswell is that place, but I went to a different place, and apparently there are several places in New Mexico."}, {"time": 7043, "text": "Now, strangely enough, I traveled back to New Mexico at the very end chapter of my book, but I don't go there physically."}, {"time": 7053, "text": "I go there through the story of a Catholic nun who actually believes that she bilocated to New Mexico in the, gosh, in the 1600s."}, {"time": 7067, "text": "So yeah, it was very strange."}, {"time": 7068, "text": "And I was at the Vatican at the Space Observatory when I made that connection that she probably went to the very, well, she believed she went to this very place that I had gone."}, {"time": 7079, "text": "Can you elaborate a little bit?"}, {"time": 7081, "text": "What does it mean to go to that place?"}, {"time": 7083, "text": "For her?"}, {"time": 7085, "text": "For her."}, {"time": 7086, "text": "What does it mean, so we're kind of breaking down the barrier between what it means to be in a place and time, right?"}, {"time": 7097, "text": "This is the field of religious studies."}, {"time": 7099, "text": "So, and again, I don't say it's true in my book."}, {"time": 7103, "text": "I just say it's a very strange coincidence that I'm at the Vatican Observatory."}, {"time": 7108, "text": "In fact, I'd finished my book, but while I was at the Vatican Observatory, I was there with Tyler, and we were looking at the records."}, {"time": 7117, "text": "They're called the trial records, but they're the canonization records of these two saints."}, {"time": 7122, "text": "Each was said to have done amazing things."}, {"time": 7124, "text": "One was Joseph of Cupertino, who levitated, okay, or is said to have levitated."}, {"time": 7130, "text": "The other was Maria of Agrida from Spain, their contemporaries in the 1600s, who was said to have been able to bilocate, which is to be in two places at once, okay?"}, {"time": 7140, "text": "So this is a belief in Catholicism that certain very holy people can do these kinds of things like levitate, which, by the way, is also associated with UFO abductions."}, {"time": 7151, "text": "People get levitated out of their beds and things like that."}, {"time": 7153, "text": "So we were sent there by a billionaire who was interested in levitation and bilocation."}, {"time": 7161, "text": "And since I could get into the Vatican and I knew the director of the Vatican Observatory, both Tyler and I were able to go to the secret archives and look at the canonization records and then go to Castle Gandolfo, which is about an hour from the Vatican where the first observatory, the space observatory of the Vatican is."}, {"time": 7184, "text": "The second one is in Arizona and it has a much larger telescope."}, {"time": 7188, "text": "So we went and Brother Guy gave me the keys to the archive and said, look at anything you want."}, {"time": 7194, "text": "And I got to see a lot of stuff by Carl Sagan, by the way."}, {"time": 7196, "text": "I know he talked about, yeah, it was awesome."}, {"time": 7198, "text": "So they have a whole section on the search for extraterrestrial life."}, {"time": 7203, "text": "And they don't, by the way."}, {"time": 7204, "text": "How awesome is that?"}, {"time": 7207, "text": "So we got to stay there."}, {"time": 7208, "text": "They have a scholars quarters."}, {"time": 7209, "text": "And so they had two."}, {"time": 7211, "text": "And so Tyler stayed in one and I stayed in the other."}, {"time": 7213, "text": "And Brother Guy probably shouldn't have been so nice to me and given me the keys because when I got home, we were there for two weeks, when I got home, I got this frantic phone call from him and he basically said, Diana, he goes, do you remember where you put the original Kepler?"}, {"time": 7230, "text": "And so I had this Kepler, right?"}, {"time": 7233, "text": "And so I misplaced it."}, {"time": 7236, "text": "Luckily I remembered where it went."}, {"time": 7239, "text": "I was like, oh gosh, thank goodness I found it."}, {"time": 7242, "text": "But he'll probably change the rules of the Vatican observatory after my visit."}, {"time": 7247, "text": "So Maria, she's actually in the history of our country in that she first wrote a cosmography of what she said was the spinning earth."}, {"time": 7259, "text": "And this was in the 1600s."}, {"time": 7261, "text": "And that's her first book."}, {"time": 7263, "text": "And she wrote that."}, {"time": 7264, "text": "And then she said that she was transported on the wings of angels to the new world."}, {"time": 7271, "text": "And she said that she met a culture of people and she basically told them about the faith of Catholicism."}, {"time": 7281, "text": "And then what happened was that the people that, and she described the fauna, she described the people and everything like that."}, {"time": 7289, "text": "And so there were actually missionaries there."}, {"time": 7292, "text": "And when they went to try to convert some of the people who already lived there, apparently they already knew a bunch of stuff."}, {"time": 7302, "text": "And they said, how did you know all this stuff?"}, {"time": 7303, "text": "And they said, this lady in blue came and told us, and they said, did it look like this?"}, {"time": 7308, "text": "And they showed them, they obviously didn't have a photograph, but they had a picture of a sister, a nun."}, {"time": 7316, "text": "And they said, yeah, she wore similar clothes, but she was much younger."}, {"time": 7322, "text": "And these guys thought that was weird."}, {"time": 7324, "text": "But when they went back to Spain, they found that this woman had been doing that in her mind, had been traveling."}, {"time": 7331, "text": "I mean, I don't know what to make of it."}, {"time": 7332, "text": "There's so many things that are sort of forcing you to kind of go outside of, you know, I'm of many minds."}, {"time": 7339, "text": "I have a very, most of my days spent with very rigorous scientific kind of things and even engineering kind of things."}, {"time": 7347, "text": "And then I'm also open minded and just the entirety of the idea of extraterrestrial life forces you to think outside of conventional boundaries of thought, scientific, current scientific thought."}, {"time": 7364, "text": "And your story right now."}, {"time": 7365, "text": "It's freaking you out."}, {"time": 7368, "text": "That's a nice way to put it."}, {"time": 7370, "text": "What do you, just another person that seems to be a key figure in this, in the mythology of this is Bob Lazar."}, {"time": 7379, "text": "It'd be interesting."}, {"time": 7381, "text": "Maybe there's others you can tell me about, but Bob, who's also been on Joe Rogan, but his story has been told quite a bit that he's got, I think he said that he witnessed some of the work being done on the spacecraft that was, you know, that was captured and so on in order to try to reverse engineer some of the technology in terms of the propulsion and so on."}, {"time": 7411, "text": "What are your thoughts about his story, how it fits into the mythology of this whole thing and broader ufologist community?"}, {"time": 7421, "text": "So regarding Bob Lazar, with respect to his claims, again, I have no way to adjudicate whether or not he actually encountered this."}, {"time": 7435, "text": "I do have friends who are."}, {"time": 7439, "text": "And the people that I know who know his story, some know him, believe him."}, {"time": 7448, "text": "And they have said to me that the most important thing that they think he has said, in fact, one of them I think made a meme out of it or something like that was basically he said, maybe the public, you know, I regret making it public."}, {"time": 7468, "text": "Maybe the public isn't ready for this kind of information."}, {"time": 7470, "text": "And basically they've, they emphasize that to me and they emphasized it so much that they wanted me to know, right?"}, {"time": 7479, "text": "So that is somewhat creepy to me."}, {"time": 7483, "text": "So I think, okay, this poor guy, Bob Lazar, so many people, you know, this is what happens to people who have experiences like this."}, {"time": 7492, "text": "They're questioned, their reputations are put on the line, in some instances their reputations are manipulated on purpose to make them look uncredible."}, {"time": 7504, "text": "To me, as a scientist, it's just inspiring that it kind of gives this kind of, I'm not even thinking of it, is there an actual spacecraft being hidden somewhere and studied and so on?"}, {"time": 7520, "text": "But I think of it like, I don't know, it's a thing that gives you a spark of a dream, you know, as a reminder that we don't understand most of how this world works."}, {"time": 7532, "text": "And then we can build technologies that aren't here today that will allow us to understand much more."}, {"time": 7539, "text": "And it's kind of like, almost like a feeling that it provides and that it inspires and makes you dream."}, {"time": 7545, "text": "That's the way I see the Bob Lazar story."}, {"time": 7547, "text": "I don't necessarily, people ask me, because I'm at MIT, people ask me, did Bob Lazar actually go to MIT and so on?"}, {"time": 7553, "text": "I don't know, and I personally don't care."}, {"time": 7557, "text": "That's not what's interesting to me about that story."}, {"time": 7561, "text": "To me, the myth is more interesting, not interesting actually, but inspiring."}, {"time": 7566, "text": "Yes, because inspiring, you're suggesting that the myth inspires you to create reality."}, {"time": 7575, "text": "So even if it's not real, in some sense, just like you said, it does in some sense, it doesn't."}, {"time": 7585, "text": "So a lot of people know how much I love 2001 Space Odyssey."}, {"time": 7588, "text": "So I got a lot of these emails asking like, hey bro, do you know what's up with the monoliths in the middle of the desert or whatever it was?"}, {"time": 7601, "text": "I haven't been actually paying attention, I apologize, but you kind of mentioned offline that this is kind of cool and interesting."}, {"time": 7609, "text": "What do you make of these monoliths and in general, are you a fan of 2001 Space Odyssey where monoliths showed up?"}, {"time": 7618, "text": "Do you have any thoughts about either the science fiction, the mythology of it or the reality of it?"}, {"time": 7627, "text": "And please say more."}, {"time": 7630, "text": "So first of all, Kubrick's films are not ever easy for me because they're so weird, right?"}, {"time": 7638, "text": "And I don't actually enjoy watching them, but it doesn't take away from their incredible brilliance though and their visionary merit."}, {"time": 7649, "text": "So 2001 Space Odyssey is incredibly visionary and of course, all those things that people say, I don't have to restate them."}, {"time": 7660, "text": "In terms of what I have, it's a subtext to my book, by the way."}, {"time": 7663, "text": "I didn't mean it to be, but it's almost a character in my book, 2001 Space Odyssey."}, {"time": 7669, "text": "And when the monoliths started to appear, again, everything went crazy with my everything, internet, social media, phone."}, {"time": 7677, "text": "What's up?"}, {"time": 7678, "text": "What's going on, right?"}, {"time": 7679, "text": "Is this disclosure?"}, {"time": 7680, "text": "And I thought, well, I'll tell you one thing, is let's look at the timing of it."}, {"time": 7685, "text": "It's a cool, it isn't art and then copy art and things like that."}, {"time": 7689, "text": "It's actually happening at a really interesting time when all of us are forced to go online."}, {"time": 7695, "text": "When all of us are forced, because of COVID, right?"}, {"time": 7697, "text": "We're completely now invaded by the screen or we're invading the screen."}, {"time": 7702, "text": "Our infrastructure now is completely changed."}, {"time": 7705, "text": "So the monolith, basically, if art is supposed to show us life, it certainly has."}, {"time": 7711, "text": "If that's an art project, somebody did an awesome job with it."}, {"time": 7713, "text": "But apparently that monolith was there for a long time, right?"}, {"time": 7716, "text": "I mean, that's the thing."}, {"time": 7717, "text": "It's been there for a couple of years, so they said, okay, all right."}, {"time": 7721, "text": "That said, if your audience is interested, I think the best theory about the meaning of the monolith is Robert Ager or Robert Ayer."}, {"time": 7734, "text": "I think it's Robert Ager."}, {"time": 7736, "text": "He's got a website where he does analyses of films and it's called Collative Learning or Collative Learning, and he does the meaning of the monolith."}, {"time": 7745, "text": "Everyone should go look at that because I fully agree with him."}, {"time": 7749, "text": "I studied different meanings of the monolith in 2001 A Space Odyssey."}, {"time": 7753, "text": "I was fascinated."}, {"time": 7754, "text": "Okay, so what is this about?"}, {"time": 7757, "text": "I accepted as soon as I listened to it and watched it."}, {"time": 7761, "text": "So basically, he says that the monolith is, okay, can you pick up your phone here?"}, {"time": 7769, "text": "It looks awfully a lot like a monolith."}, {"time": 7774, "text": "So basically, that's what he was saying was that Kubrick was basically, the monolith was technology or the screen in particular, and he basically was saying that the cinema screen, we're being completely... And if you think about it, look at all this, we live in a screen culture."}, {"time": 7790, "text": "We have computer screens, iPhone screens, there's phone screens, we have TV screens, everything is something... And now that COVID has come, we're forced to go into these screens and we're forced to live a different material existence than we have lived before."}, {"time": 7806, "text": "So in my sense, I think that if it's an art project, it's a really good one for that."}, {"time": 7812, "text": "So I like that meaning of it, it's a screen and a screen could take all kinds of forms."}, {"time": 7820, "text": "I mean, our perception system in a sense is a screen between reality and our mind."}, {"time": 7827, "text": "The screen of the computer is a screen, the virtual reality worlds that we might be one day living in, there'll be an interface, I mean, ultimately it's about the interface."}, {"time": 7840, "text": "It's an interface to another world of ideas."}, {"time": 7846, "text": "It's also a material change."}, {"time": 7849, "text": "It's a change in our material..."}, {"time": 7850, "text": "I mean, when people talk about augmented reality, I say we already live in augmented reality, don't we?"}, {"time": 7856, "text": "I mean, this isn't our grandparents existence."}, {"time": 7861, "text": "I sometimes, you have to pause and remind yourself how weirdly different this reality is than just even like, I mean, 30 years ago."}, {"time": 7871, "text": "The internet changed so much and social media has changed so much about actually just the space of our thinking."}, {"time": 7881, "text": "Wikipedia changed so much about the offloading of our knowledge."}, {"time": 7885, "text": "The way we interact with knowledge."}, {"time": 7888, "text": "I mean, it offloaded our longterm memory about facts onto a digital format."}, {"time": 7895, "text": "So in the sense that expanded our mind, it's kind of interesting."}, {"time": 7900, "text": "I'd be curious to see if he has just one interpretation."}, {"time": 7904, "text": "I wonder if there's others."}, {"time": 7905, "text": "I've corresponded with him, yes."}, {"time": 7906, "text": "So over the years he and I have corresponded."}, {"time": 7910, "text": "And I told him, I said, look, I'm going to be using this in my book."}, {"time": 7913, "text": "So I think you should read what I say."}, {"time": 7915, "text": "And he was, he of course wanted to see it."}, {"time": 7918, "text": "What do you think about your book?"}, {"time": 7919, "text": "Did he get a chance to read it?"}, {"time": 7923, "text": "So he is a nonbeliever in alien intelligence and UFOs, but he, and that's fine, but I still agree with him that the meaning of the monolith was the screen, but that doesn't mean the screen isn't like what David Bowie said, right?"}, {"time": 7940, "text": "So it's not exclusive."}, {"time": 7942, "text": "So I could still use his theory, but differ from the conclusions."}, {"time": 7946, "text": "In terms of nonbeliever and believer, there's, when you say believer, you also are kind of implying this, the idea that aliens have visited or had made direct contact with humans in some form."}, {"time": 7965, "text": "There's also the exploration and the idea of just alien intelligence is out there in the universe."}, {"time": 7976, "text": "You know, the Drake equation estimating how many intelligent civilizations may be out there."}, {"time": 7982, "text": "How many have ever existed?"}, {"time": 7983, "text": "How many are about to communicate with us?"}, {"time": 7985, "text": "I mean, when you just zoom out from our own little selfish perspective of earth and look at the entirety, let's say the Milky Way galaxy, but maybe even the universe, does the idea that there are intelligent civilizations out there, something that you're excited about or something that you're terrified about?"}, {"time": 8008, "text": "So basically I would say I'm not so keen on it."}, {"time": 8015, "text": "I think that our relationship with technology as it is and as it, as I hope it will go will help us survive, okay?"}, {"time": 8026, "text": "I don't think we're equipped to do it as we stand now, but I think that if we can up our game or let's just put it this way, if technology is an extension of ourselves, which it actually is, it will help us because it'll probably be smarter than us, okay?"}, {"time": 8044, "text": "It'll help us survive in the ways in which it determines best, okay?"}, {"time": 8047, "text": "So with that said, if there are nonhuman intelligences out there and they have more advanced, you know, obviously technologies than us and they actually come, the history of human engagement with, you know, other cultures has not gone well for cultures that are less aggressive."}, {"time": 8074, "text": "So you see what I'm saying?"}, {"time": 8075, "text": "Like, it's not a good idea."}, {"time": 8077, "text": "Well, I wonder where we stand on the, where humans stand in the full spectrum of aggression."}, {"time": 8083, "text": "Well, heck, where are we now, Lex?"}, {"time": 8085, "text": "I mean, we're not too great here."}, {"time": 8087, "text": "We're still aggressing against each other."}, {"time": 8089, "text": "No, I know, but that will give us a benefit, right?"}, {"time": 8092, "text": "Like, oh, you're saying, I thought, okay, I see."}, {"time": 8097, "text": "I just have a sense that there may be a lot of intelligences out there that are less aggressive because they've evolved past it."}, {"time": 8106, "text": "We can't assume that."}, {"time": 8107, "text": "No, I know we can't assume that, but like."}, {"time": 8110, "text": "If we can't assume it, then I'm going to assume the worst."}, {"time": 8114, "text": "Well, that's, despite the fact that I am a Russian and think that life is suffering, I tend to assume, not the best, but I tend to assume that there is a best core to creatures, to people and to creatures that ultimately wins out."}, {"time": 8135, "text": "I think there's an evolutionary advantage to being good to other living creatures."}, {"time": 8143, "text": "And so, ultimately, I think that if there's intelligent civilizations out there that prosper sufficiently to be able to travel across the great spans of space, that they've evolved past silly aggression, that it's more likely in my mind to be deeply cooperative."}, {"time": 8168, "text": "So like growth over destruction, like growth does not require destruction, I think."}, {"time": 8176, "text": "But if you see the universe as ultimately a place where it's highly constrained in resources that are necessary for traveling across space and time, then perhaps aggression is necessary in order to aggress against others that are desiring to get access to those resources."}, {"time": 8197, "text": "I tend to try to be optimistic on that front."}, {"time": 8201, "text": "I think I'm emotionally optimistic and intellectually nonoptimistic."}, {"time": 8206, "text": "Yeah, I guess I'm there with you."}, {"time": 8211, "text": "I tend to believe that the happiness and deep fulfillment in life is found in that emotional place."}, {"time": 8218, "text": "The intellectual place is really useful for building cool new technologies and ideas and so on."}, {"time": 8228, "text": "But happiness is in the emotional place."}, {"time": 8230, "text": "And there it pays off to be optimistic, I think."}, {"time": 8235, "text": "You said that technology might be able to save us."}, {"time": 8239, "text": "That's also kind of optimistic, too."}, {"time": 8242, "text": "It might kill us."}, {"time": 8243, "text": "But there's, talking to you offline a little bit, there was a sense that we humans are facing existential risks, that it's not obvious that we will survive for long."}, {"time": 8258, "text": "Is there things that you worry about in terms of ways we may destroy ourselves or deeply damage the fabric of human civilization that technology may allow us to avoid or alleviate?"}, {"time": 8275, "text": "Yes, I think that you can choose anything, actually."}, {"time": 8281, "text": "And it could destroy us, pollution."}, {"time": 8288, "text": "Here we're in a pandemic, a meteor."}, {"time": 8292, "text": "So we can use technology, or the thing is, is that we say we use technology, but actually that's not a correct way of putting it, in my opinion."}, {"time": 8304, "text": "So there is a term used by others, coined by somebody I don't know, and I'm sorry to not give credit where credit's due, but it's called technogenesis."}, {"time": 8315, "text": "And it's this idea, Heidegger actually had this idea, but he didn't use that term."}, {"time": 8319, "text": "And it's this idea that we coevolve with technology, that we don't actually use it."}, {"time": 8324, "text": "Most people think it's like a tool we use, okay, let's use technology to do this."}, {"time": 8329, "text": "Well, actually when we engage with technology, we actually engage with it and it engages back with us and we engage with it."}, {"time": 8337, "text": "So it's this coevolution that's happening."}, {"time": 8339, "text": "And in that sense, I think that as we create more autonomous, intelligent AI, it will help us survive because if we coevolve with it, it will need us as much as we need it, is my opinion."}, {"time": 8363, "text": "How that happens or if that bears out to be true, we'll see, but I don't think the idea that we use technology is a correct way to put it."}, {"time": 8374, "text": "I think that technology is something so strange, the way it is today, like digital technology, I'm not talking about hammers or things like that, those kinds of tools, okay, is technology is so far removed from that and our environment is so now conditioned by our technology and the infrastructure we live within, the material structure."}, {"time": 8395, "text": "I think that it's going to, I don't think it's going to be a Frankenstein."}, {"time": 8401, "text": "I think it's actually going, like a Mary Shelley type idea of technology."}, {"time": 8405, "text": "I think it's actually going to be more Promethean in the sense of, think about it, we create children and then we get old and we rely upon our children to help us, okay?"}, {"time": 8418, "text": "Well, I feel like that about technology."}, {"time": 8420, "text": "We've created, well, we've created it, right?"}, {"time": 8423, "text": "And so it's kind of growing up now."}, {"time": 8428, "text": "Or maybe it's in its teenage years and we'll see."}, {"time": 8434, "text": "What do you think about in terms of this coevolution of the work around brain computer interfaces and maybe Neuralink and Elon seeing Neuralink in particular as its longterm mission as a symbiosis with artificial intelligence."}, {"time": 8457, "text": "So like giving a greater bandwidth channel of communication between technology, AI systems and the biological neural networks of our human mind."}, {"time": 8474, "text": "What do you think about this idea of connecting directly to the brain in AI systems?"}, {"time": 8480, "text": "I mean, okay, I've listened to your podcast with Elon."}, {"time": 8485, "text": "I've listened to Elon before, he's very intelligent, obviously super smart guy."}, {"time": 8489, "text": "I think this is already, I mean, not in the specific ways that he is doing it, but I think we are already doing that, okay?"}, {"time": 8497, "text": "And I can give you some examples."}, {"time": 8501, "text": "And there are really trivial examples, but they do make the point and this is one of them."}, {"time": 8505, "text": "So before he started this research on UFOs and UAPs and technology, I actually was looking at the effects of technology and in particular media on religion."}, {"time": 8521, "text": "And what I did was I was lucky to be asked to be a consultant for various movies and one in particular I learned a lot from and that was The Conjuring."}, {"time": 8533, "text": "So I was a history consultant for The Conjuring."}, {"time": 8537, "text": "It happens to be my field, it's Catholic studies, right?"}, {"time": 8541, "text": "And you've got these people who are real people and they're, you know, exercising demons and things like that."}, {"time": 8546, "text": "Okay, so I thought, wow, this is a great example for me."}, {"time": 8548, "text": "You know, I didn't do it for the money."}, {"time": 8550, "text": "It doesn't pay well, but I did it to learn, right?"}, {"time": 8553, "text": "So I work closely with the screenwriters who I work with now all the time."}, {"time": 8557, "text": "I work with them all the time now."}, {"time": 8560, "text": "And what I found was this, I found that as the most interesting part of the creation of this movie was the editing process because it would go through editing and they would use test audiences and a lot of the test audiences would be like, you know, there's like these things where they test their flicker rates and things like that, the eye flicker rates."}, {"time": 8582, "text": "And so, and when it goes really intense, they go to UC Irvine and they do this thing called cognitive consumption, which is basically, or I'm sorry, cognitive consumerism, where they basically hook test audiences up to EKGs and they read their brains and they figure out which scenes create the most."}, {"time": 8605, "text": "Arousal."}, {"time": 8607, "text": "And then they cut out all the other scenes."}, {"time": 8610, "text": "So what we're getting is we're getting like this drug when we go to the movies or when we do video games or when we watch, we're literally physiologically responding to our technologies."}, {"time": 8621, "text": "So we're already there."}, {"time": 8622, "text": "We're already interfacing with them physiologically."}, {"time": 8624, "text": "So that's my example."}, {"time": 8625, "text": "Now, the kind of thing that he's doing, Musk is doing with Neuralink, I say, go for it."}, {"time": 8633, "text": "I hope he does it."}, {"time": 8634, "text": "You know, I'm fascinated."}, {"time": 8635, "text": "I want it to happen."}, {"time": 8637, "text": "Why do I want it to happen?"}, {"time": 8639, "text": "Because I think that, well, first it's inevitable that it's going to happen."}, {"time": 8649, "text": "He was writing papers about, in fact, the ARPANET, the ProtoInternet was called Augmentation of the Human Intellect."}, {"time": 8659, "text": "So we've been doing this for a while."}, {"time": 8662, "text": "So props to Elon Musk, but we've been thinking about this for a good time."}, {"time": 8667, "text": "We've even been visioning it."}, {"time": 8670, "text": "So there was a really interesting Jesuit priest, he was French, Tellur de Chardin."}, {"time": 8679, "text": "If not, he's fascinating."}, {"time": 8681, "text": "He was actually a soldier before he became a priest."}, {"time": 8685, "text": "And so he believed, he also saw what he called a biosphere."}, {"time": 8689, "text": "Now this guy is talking in like the early 20th century, like the 1917, 19, you know, that time period."}, {"time": 8696, "text": "And so basically he said and wrote about this thing called the noosphere."}, {"time": 8701, "text": "And he basically said, there will be a point when we merge with our technology and it's going to be somewhat like some kind of a biosphere."}, {"time": 8708, "text": "We have this atmosphere and then we have the stratosphere and it's going to be this biosphere and we're all going to be hooked into it mentally."}, {"time": 8716, "text": "So we'll be able to communicate in a way in which we don't communicate now."}, {"time": 8720, "text": "So you know, that sounds so similar to the singularity."}, {"time": 8723, "text": "So after I've read him many, many years ago, but when I read the Kurzweil's book about the singularity, to me, it read just like religious language."}, {"time": 8736, "text": "Like it read like, you know, cause he, in fact, it's so much like revelation to me when I read it that I even assign it to my students in my classes."}, {"time": 8746, "text": "I'm like, this is, this is it."}, {"time": 8748, "text": "You know, this is like a really great book of the singularity, you know, the coming singularity."}, {"time": 8753, "text": "And this religious event, because it seems like it, when he writes about it, he says, I felt it before I even understood it."}, {"time": 8762, "text": "He, I mean Kurzweil."}, {"time": 8763, "text": "Kurzweil, yeah, Kurzweil."}, {"time": 8764, "text": "So what, I mean, what are your feelings about, not feelings, thoughts, feelings too, about the idea of the singularity?"}, {"time": 8772, "text": "Do you think it's ultimately the thing that echoes throughout the history of ideas is this like moment of a revelation, like this, this almost mythological religious moment?"}, {"time": 8823, "text": "I don't think it's going to leave us behind."}, {"time": 8825, "text": "I think it's going to take us along."}, {"time": 8828, "text": "But it will be, I mean, I guess the idea of the singularity, first of all, isn't the idea of the singularity is like, we can't possibly predict what's on the other side of the singularity."}, {"time": 8836, "text": "These are the senses like, this is like the world will be fundamentally transformed."}, {"time": 8844, "text": "And then it was, you know, this was characterized in various movies like Lucy and stuff like that."}, {"time": 8849, "text": "You know, Lucy being the first human that, right, we, so kind of replicating that this is going to be the next iteration of humans is the singularity."}, {"time": 8858, "text": "I actually don't believe that."}, {"time": 8861, "text": "I'm frankly, however, and the reason I don't believe it is because we're material beings and technology has to have a host."}, {"time": 8869, "text": "So we're not going to, you know, become something super abstract."}, {"time": 8874, "text": "Like there's, it's just impossible to do."}, {"time": 8877, "text": "Well, people will be listening to this podcast a hundred years from now and laughing at it because they'll be all existing in a virtual reality where it will be all information as opposed to material, meaning connected to some kind of concept of physical, physical reality."}, {"time": 8898, "text": "I don't even know the right words to use here."}, {"time": 8899, "text": "You see, that's because there are none because there's no place from, there's no view from nowhere."}, {"time": 8905, "text": "There's no non material, like we have thoughts, but they're connected to us, right?"}, {"time": 8912, "text": "They're in our, you know, they're somehow, okay."}, {"time": 8915, "text": "As far as, as far as you know."}, {"time": 8917, "text": "Listen, platonic forms, I think is about as, as, you know, close to what we're talking about as possible."}, {"time": 8925, "text": "Like this place where these things exist and then there's like a physical instantiation of it."}, {"time": 8931, "text": "No, but see we're, the question is from the perspective of the platonic form, what does our physical world look like?"}, {"time": 8941, "text": "Like, you know, if, if, if say you're a creature existing in a virtual reality, like if you grew up your whole life in a virtual reality game, like what is it?"}, {"time": 8953, "text": "And somebody in that virtual reality world tells you that there actually exists this physical world and in fact your own, you think you're in this virtual world, but it's actually you're in a body and this is just your mind putting yourself and there's a piece of technology."}, {"time": 8971, "text": "Like how will they, how will they be able to think of that physical world?"}, {"time": 8975, "text": "Would they, would they sound exactly like you just sounded a minute ago saying like, well, that's silly."}, {"time": 8981, "text": "Who cares if there's a physical world?"}, {"time": 8984, "text": "It's the, the entirety of the perception and my memories and all of that is in this other realm of, of like information."}, {"time": 8997, "text": "It's just all just information."}, {"time": 8998, "text": "Why do I need some kind of weird meat bag to contain?"}, {"time": 9002, "text": "So there's a great, again, I always, you know, return to something for your audience to read or you, there's a great, very short article online for free by David Chalmers."}, {"time": 9014, "text": "Do you know him?"}, {"time": 9015, "text": "He's the philosopher of consciousness."}, {"time": 9017, "text": "Interviewed him on this podcast."}, {"time": 9021, "text": "He's cool."}, {"time": 9022, "text": "I used to, I was friends with his best friend for a while when, in, when I was in grad school."}, {"time": 9027, "text": "He probably has some weird friends."}, {"time": 9030, "text": "He's a philosopher."}, {"time": 9033, "text": "So, I like his fashion choice and his style too and hang out with him a little bit."}, {"time": 9039, "text": "It's a great guy."}, {"time": 9041, "text": "So he wrote this article, which I use a lot."}, {"time": 9044, "text": "I love it because it's accessible to undergraduates and it's called Matrix as Metaphysics."}, {"time": 9051, "text": "And basically it's, it's an answer to external world skepticism, which is basically how do we know there's an external world, right?"}, {"time": 9058, "text": "How do we know that we're not in a matrix right now?"}, {"time": 9061, "text": "And so basically he's using, he's also, he even references, he uses a religious reference even."}, {"time": 9070, "text": "He says, you could think of the Matrix of the movie as a new, as the new book of Genesis for our new world, right?"}, {"time": 9081, "text": "And I thought, yeah, that's absolutely correct because, you know, we don't know and we don't, we won't know for sure or for certain, therefore what we know is what is real to us."}, {"time": 9094, "text": "And so he goes through these scenarios and within philosophy it's called, there's a, this is different from that, but it's like this brain in a vat, right?"}, {"time": 9103, "text": "If you're a brain in a vat and some not so kind scientist is like recreating this world for you just to see, you know, and you think you're this awesome rock star, right?"}, {"time": 9114, "text": "And you're living this awesome existence, but you're actually just this brain in this vat."}, {"time": 9119, "text": "But there's still a brain in a vat, okay?"}, {"time": 9121, "text": "So his idea in The Matrix as metaphysics kind of takes out the brain in a vat like this."}, {"time": 9128, "text": "I don't know if this is possible."}, {"time": 9130, "text": "So I've read critiques of this that, you know, what you're talking about is a non dualism, like there's like, you know, or it's not necessarily a non dualism."}, {"time": 9144, "text": "I just, I mean, information in and of itself has to have some kind of material component to it."}, {"time": 9153, "text": "I mean, it's that when taking it outside of the realm of human beings, because dualism is kind of talking about humans in a sense, it's just possible to me that there could be creatures that exist in a very different form, perhaps rely on very different set of materials that may perhaps not even look like materials to us."}, {"time": 9177, "text": "Yes, I agree."}, {"time": 9178, "text": "Which is why like information, it could be, even in computers, the information that's traveling inside a computer is connected to actual material movement, right?"}, {"time": 9195, "text": "So like it is ultimately connected to material movement, but it's less and less about the material and more and more about the information."}, {"time": 9204, "text": "So I just mean that there's, it's possible that... You think the singularity is basically like sloughing off our material existence?"}, {"time": 9212, "text": "Because I can tell you that this has been the hope of philosophers and theologians forever."}, {"time": 9218, "text": "Yeah, well, I don't, I think we're living in a, through a singularity."}, {"time": 9223, "text": "I don't think, I think this world, just like, as you've said already, has been already transformed significantly and keeps continually being transformed."}, {"time": 9234, "text": "And we're just riding this big, beautiful wave of transformation."}, {"time": 9239, "text": "And that's why it's both exciting and terrifying from a scientific perspective that like we're so bad at predicting the future and the future is always so amazing in terms of the things that has brought us."}, {"time": 9256, "text": "I mean, I don't know if it's always will be this exciting in terms of the rate of innovation, but it seems to be increasing still."}, {"time": 9263, "text": "And it's really exciting."}, {"time": 9268, "text": "It's terrifying because obviously we're building better and better tools for destroying ourselves."}, {"time": 9272, "text": "But I, on the optimistic side, believe that we're also can build better and better tools to defend against all the ways we can destroy ourselves."}, {"time": 9281, "text": "And it's kind of this interesting race of innovation."}, {"time": 9287, "text": "Books are great."}, {"time": 9288, "text": "Of course, the greatest book of all time, two of the greatest books of all time are yours."}, {"time": 9294, "text": "But besides those, what books, technical, fiction or philosophical, had an impact on your life or possibly you think others might want to read and get some insights from?"}, {"time": 9310, "text": "And what ideas did you pick up from them?"}, {"time": 9314, "text": "Okay, I really enjoy Nietzsche."}, {"time": 9317, "text": "So anything by Nietzsche, Friedrich Nietzsche."}, {"time": 9320, "text": "I actually hated him when I first read him in my early twenties."}, {"time": 9325, "text": "That's like the opposite of most people's experience, right?"}, {"time": 9328, "text": "They usually love them in their twenties and then they throw them to the curb."}, {"time": 9332, "text": "Later."}, {"time": 9334, "text": "I think he's totally misrepresented and misinterpreted."}, {"time": 9338, "text": "He grew on you."}, {"time": 9339, "text": "Well, it happened in one night."}, {"time": 9341, "text": "So let me just describe it because it's kind of funny."}, {"time": 9346, "text": "Happened on New Year's."}, {"time": 9347, "text": "So I had friends when I was in my twenties and they kept telling me, you have to read Nietzsche, you have to read Nietzsche."}, {"time": 9352, "text": "And I tried."}, {"time": 9354, "text": "But again, you know, no, I was not into how he described the philosophical concepts he was trying to get across."}, {"time": 9364, "text": "But they weren't giving up, I have very persistent friends."}, {"time": 9369, "text": "So one of them gave me The Gay Science and I had it on my bookstand and it was New Year's Eve and I'm actually not a big part, I'm actually an introvert."}, {"time": 9382, "text": "I'm a geeky introvert, okay?"}, {"time": 9384, "text": "So I don't go out and party a lot."}, {"time": 9386, "text": "It was New Year's Eve, even that couldn't get me out to go party."}, {"time": 9389, "text": "So I just wanted to go to bed and New Year's Eve hit and everybody went out and I was asleep and they woke me up and I was like, darn, they woke me up, eh, might as well read this book by Nietzsche."}, {"time": 9400, "text": "So I picked it up and lo and behold, I turned to a page that was exactly about, it was called Sanctus Januarius, which is basically St. January and it was about New Year's Eve."}, {"time": 9410, "text": "And I thought, whoa, what a weird coincidence."}, {"time": 9413, "text": "And it was also super Catholic and it was a really beautiful little aphorism."}, {"time": 9419, "text": "It's actually a book of aphorisms, which are kind of religious, right?"}, {"time": 9423, "text": "And so it's religious, the genre is religious, let's put it that way, but he's not."}, {"time": 9428, "text": "So basically he says, today's the day when people are supposed to make these resolutions, right?"}, {"time": 9434, "text": "And he says, from here on out, I will never say no, I will only say yes."}, {"time": 9441, "text": "I look away, if something's horrible, I'll just look away from it, I won't get angry at it."}, {"time": 9445, "text": "And then he also says, I will be like St. January."}, {"time": 9448, "text": "And St. January is actually the saint whose blood is in this place in Italy."}, {"time": 9453, "text": "I think it's in Italy, and every year it turns to blood again."}, {"time": 9459, "text": "So it's like it's desiccated, so it's this miracle, it says, my blood is now, it flows again."}, {"time": 9467, "text": "And I was like, wow, that's really beautiful."}, {"time": 9468, "text": "And I said, and a strange coincidence because it just turned 12th."}, {"time": 9474, "text": "So it's like New Year's Eve, I pick up the book, I read this aphorism and I said, strange coincidence that."}, {"time": 9480, "text": "And then I turned the page, and the page is about coincidences."}, {"time": 9483, "text": "And I was like, I shut it, and I thought, this is weird."}, {"time": 9487, "text": "And I felt like it was alive, I felt like the book was alive and Nietzsche was speaking to me, right?"}, {"time": 9492, "text": "I had a experience and engagement with Nietzsche."}, {"time": 9495, "text": "And so after that, I couldn't put his stuff down, it was engaging, fascinating, everything."}, {"time": 9501, "text": "So yeah, so that's one book, The Gay Science."}, {"time": 9503, "text": "What did you pick up from The Gay Science or from Nietzsche in general?"}, {"time": 9507, "text": "Because there's some ideas that just kind of... Yeah, the idea is basically that truth, he's got awesome one liners."}, {"time": 9515, "text": "So truth is a woman."}, {"time": 9519, "text": "So okay, what does he mean by that?"}, {"time": 9522, "text": "Truth is a woman."}, {"time": 9523, "text": "Basically, she's going to lie to you."}, {"time": 9525, "text": "She looks real attractive, but she's not going to tell you the truth."}, {"time": 9532, "text": "So okay, so basically, I'm not saying that that's true about women."}, {"time": 9536, "text": "I'm obviously a woman."}, {"time": 9538, "text": "So basically what he's saying is that truth is like what I said, Brother Guy said, it's a moving target, okay?"}, {"time": 9546, "text": "We started this whole conversation with what's real, right?"}, {"time": 9549, "text": "So I should have just gone straight to Nietzsche."}, {"time": 9551, "text": "Haven't you heard truth is a woman?"}, {"time": 9553, "text": "Okay, so truth is a woman."}, {"time": 9557, "text": "All right, so that and also, and Foucault, this other philosopher, French philosopher actually takes up this idea and creates his own framework called genealogy from it."}, {"time": 9568, "text": "So the genealogy of morals, so that we only believe certain things and we sediment them into truth."}, {"time": 9575, "text": "So we say a truth told, who said that?"}, {"time": 9578, "text": "Was it Lenin or Stalin?"}, {"time": 9580, "text": "A truth told enough times, I mean, a lie told enough times becomes the truth."}, {"time": 9586, "text": "So that's basically Nietzschean right there, okay?"}, {"time": 9588, "text": "So that's Nietzsche."}, {"time": 9589, "text": "So Nietzsche also is a huge critic of Christianity, which I'm actually Catholic, I'm a practicing Catholic."}, {"time": 9597, "text": "So I appreciated his critique, I thought it was actually quite accurate."}, {"time": 9602, "text": "He's a critique of religion in general and he's fascinating."}, {"time": 9606, "text": "And also I find that he talks about altered states of consciousness and he calls them elevated states."}, {"time": 9614, "text": "And I think through his book, you can actually experience elevated states."}, {"time": 9618, "text": "So yeah, Nietzsche, thumbs up."}, {"time": 9623, "text": "So what other books?"}, {"time": 9625, "text": "So Hannah Rent, she is a philosopher that not a lot of people know about, but she was a Jewish woman during the Holocaust and she was interned at Bergen Belsen, which was basically Auschwitz for women and she escaped."}, {"time": 9642, "text": "She came to the United States and she had worked with Heidegger, even though he's supposed to be anti Semitic and a Nazi and everything, but they were lovers, okay?"}, {"time": 9650, "text": "So she comes out and she's at Columbia University and she teaches philosophy there."}, {"time": 9655, "text": "And she writes two books, which I'll recommend."}, {"time": 9658, "text": "One is called Eichmann in Jerusalem, where she attends the Nuremberg trials."}, {"time": 9663, "text": "And she basically makes this really astute observation about evil."}, {"time": 9667, "text": "And she says, Eichmann is one of the people who sent the Jews to the concentration camps who ran the trains, okay?"}, {"time": 9674, "text": "And she said, the thing about Eichmann was that he didn't seem particularly evil."}, {"time": 9679, "text": "Actually, he seemed to be quite a nice guy."}, {"time": 9683, "text": "She said, what was interesting about him was he seemed incredibly thoughtless and stupid."}, {"time": 9688, "text": "And she said, and he used a lot of stereotypes like memes."}, {"time": 9691, "text": "So she actually wrote about memes before we had them."}, {"time": 9694, "text": "And now people just use memes and they're actually used against us even."}, {"time": 9698, "text": "There's even a segments of warfare called memetic warfare, all right?"}, {"time": 9702, "text": "So memes are something that can sway a whole population of people."}, {"time": 9707, "text": "So she wrote about memes before they were even in existence."}, {"time": 9710, "text": "And that's Eichmann in Jerusalem."}, {"time": 9711, "text": "And I think she also has some really amazing things to say about evil is that when people remain thoughtless, she has another book called The Life of the Mind, which is gigantic."}, {"time": 9722, "text": "And I don't think anybody will read it, but frankly, it's one of the best books I've ever read."}, {"time": 9728, "text": "And I've read it many times."}, {"time": 9729, "text": "And basically, The Life of the Mind, in The Life of the Mind, she asks a very simple question."}, {"time": 9733, "text": "She says, why do people do bad things?"}, {"time": 9735, "text": "Why are they evil?"}, {"time": 9737, "text": "And what she says is she wonders if it's, she says that bad people sleep well at night contrary to, you know how the saying, how do you sleep at night?"}, {"time": 9745, "text": "Well, that's only because you're a good person that you're asking that question because you actually have a conscience and a conscience is this dual kind of, you fight with yourself about the consequences of your actions."}, {"time": 9756, "text": "And she says, bad people don't seem to have a conscience."}, {"time": 9759, "text": "Do they actually sleep well at night?"}, {"time": 9761, "text": "And so she goes through a whole history of philosophy about evil, and that's really a good one too."}, {"time": 9766, "text": "But I also have to recommend this one too."}, {"time": 9769, "text": "There's one more."}, {"time": 9770, "text": "So I know I recommended two, but just from the same philosopher."}, {"time": 9773, "text": "My friend Jeffrey Kreipel, he's at Rice University and he's in my field, religious studies."}, {"time": 9778, "text": "He's written several books."}, {"time": 9779, "text": "I mean, he's written a heck of a lot of books, let's put it that way."}, {"time": 9782, "text": "But I think his best book or the one that impacted me the most is called Authors of the Impossible."}, {"time": 9789, "text": "And his book, his writing is very much like Nietzsche's writing in the sense that he, it's almost as if he reaches out of the pages and he grabs you and he kind of slaps you around and says, think about this, you know, and you can't help but be changed after you've read it."}, {"time": 9807, "text": "Oh, so he covers a bunch of different thinkers and authors that somehow are, what is it?"}, {"time": 9817, "text": "Some aspect of revolutionism aspect."}, {"time": 9819, "text": "They're thinking the impossible."}, {"time": 9822, "text": "There's a great one he's written called Mutants and Mystics, where he talks about the comic strips, the, gosh, why can't I remember the name of the person?"}, {"time": 9832, "text": "He just died, Stan Lee."}, {"time": 9833, "text": "He talks about the history of the comics by Stan Lee and they're all paranormal."}, {"time": 9838, "text": "They all start off super paranormal and it's fascinating."}, {"time": 9843, "text": "On the topic of Hannah Arendt, so I haven't read her work, but I've vaguely touched upon sort of like commentary of her work and it seems like some people think her work is dangerous in some aspect."}, {"time": 9861, "text": "I don't know if you can comment on why that is."}, {"time": 9867, "text": "It feels like similar with Ayn Rand or something like that, where like this is, I should say not dangerous, but controversial."}, {"time": 9875, "text": "Yes, they think it's controversial."}, {"time": 9876, "text": "This is the reason I believe, I've heard of the controversy."}, {"time": 9880, "text": "The controversy is that she didn't, first of all, she is Jewish and she did escape a concentration camp and yet she's called, she's been called anti Jewish."}, {"time": 9894, "text": "And I think part of that was that she basically was saying something that I believe that a lot of normal people are like Eichmann and evil things are done by people who just follow the rules and they don't think about what they're doing."}, {"time": 9912, "text": "And that's one of the most pernicious forms of evil of our time."}, {"time": 9918, "text": "So we talked quite a bit about the definitions of religion and what are the different building blocks of religion."}, {"time": 9961, "text": "So what are your thoughts in the context of religion or maybe in the context of your own mind about the role of death in life or fear of death in life and are you afraid of death?"}, {"time": 9979, "text": "We cover everything in this podcast."}, {"time": 9982, "text": "Every single topic is covered."}, {"time": 9987, "text": "I so happen to have benefited perhaps from living with an older brother who seemingly had no fear of death while growing up and he did everything, okay?"}, {"time": 10002, "text": "So he climbed mountains, he was a rock climber, he jumped out of airplanes."}, {"time": 10009, "text": "Of course, he had to be a Green Beret and go into the special forces where that type of thing is a requirement, right?"}, {"time": 10017, "text": "And so because of that, I did a lot of things outside of my comfort zone and which probably I shouldn't have done and hope to goodness, my kids don't do them, okay?"}, {"time": 10030, "text": "So do I fear death?"}, {"time": 10032, "text": "I think about death a lot actually."}, {"time": 10034, "text": "You may not know this about me, but in my field, I was the head, I was the co chair of the death panel."}, {"time": 10042, "text": "It's called the death panel."}, {"time": 10043, "text": "No, it's like it's the panel to think about death in religious studies and I was that for many years."}, {"time": 10052, "text": "So you've thought about it a bit."}, {"time": 10055, "text": "Let's see, I think that people are a little too confident, I think about life in general that they're gonna kind of live all the time and not die."}, {"time": 10063, "text": "I happen to, I mean, I hate to say it, I'm super positive and most people would consider me to be too happy almost, right?"}, {"time": 10072, "text": "And so it's odd then that I spend a lot of time thinking about death, but I wonder if there's a connection there."}, {"time": 10078, "text": "I'm happy to be alive, right?"}, {"time": 10081, "text": "That's kind of what the thinking about death does is it makes you appreciate the days that you do have."}, {"time": 10086, "text": "It's a weird controversy."}, {"time": 10087, "text": "I tend to believe that the fact that this life ends gives each day a significant amount of meaning."}, {"time": 10099, "text": "So I don't know, it seems like an important feature of life."}, {"time": 10103, "text": "It's not like a bug, it seems like a feature that it ends, but it's a strange feature because I wish it, like all the good stuff you wish it wouldn't end."}, {"time": 10112, "text": "Well, you know what's interesting, Lex, and I do point this out to my students because we cover in a lot of the basic studies courses I teach, we cover all religions or as many as we can, like the major religions."}, {"time": 10123, "text": "And so take Hinduism, for example."}, {"time": 10126, "text": "Now this is an ancient religion, okay?"}, {"time": 10128, "text": "So you and I are here talking about how we enjoy living and life and things like that."}, {"time": 10132, "text": "Well, the goal of Hinduism is basically never to get reincarnated again, is basically to not live, okay?"}, {"time": 10139, "text": "And to get off samsara, which is the wheel of life and death."}, {"time": 10143, "text": "Escape the whole thing."}, {"time": 10145, "text": "Think of that."}, {"time": 10146, "text": "Conditions are so different that you and I and my students are happy to be alive."}, {"time": 10151, "text": "But back in the day, thousands of years ago, when they wrote, they actually didn't write it, they spoke the Vedas, which were the sacred traditions of India."}, {"time": 10161, "text": "They wanted off."}, {"time": 10162, "text": "They didn't want to come back."}, {"time": 10164, "text": "Life was terrible."}, {"time": 10165, "text": "That's what people don't have the adequate understanding of history, that for the majority of people, life is really hard, right?"}, {"time": 10174, "text": "And you and I are, and your audience, among the lucky."}, {"time": 10179, "text": "Yeah, we actually like life."}, {"time": 10182, "text": "We want to live."}, {"time": 10185, "text": "Most of the time."}, {"time": 10186, "text": "Yeah, most of the time."}, {"time": 10187, "text": "What do you think the biggest, since we're covering every single possible topic, let me ask the biggest one, the unanswerable one."}, {"time": 10194, "text": "From the perspective of alien intelligence, or from the perspective of religious studies, or from the perspective of just Diana, what do you think is the meaning of this existence of this life of ours?"}, {"time": 10210, "text": "So, well, of course I have to, my philosophical training as an undergrad always makes me think about like, what's the assumption in your question?"}, {"time": 10224, "text": "There's an assumption there."}, {"time": 10225, "text": "It's like, there is a meaning."}, {"time": 10227, "text": "That's the assumption."}, {"time": 10228, "text": "What do you mean by meaning?"}, {"time": 10229, "text": "What do you mean by life?"}, {"time": 10231, "text": "Can you define the terms?"}, {"time": 10233, "text": "But listen."}, {"time": 10235, "text": "I'll answer your question."}, {"time": 10236, "text": "I'm just going to say that there's this assumption that we should have meaning to life."}, {"time": 10238, "text": "Well, maybe we shouldn't."}, {"time": 10239, "text": "Maybe it's just all random."}, {"time": 10241, "text": "However, I believe that it's not."}, {"time": 10242, "text": "And in my opinion, the meaning of life, in my opinion, is intrinsic."}, {"time": 10246, "text": "I enjoy living."}, {"time": 10248, "text": "I want to live."}, {"time": 10249, "text": "Sometimes I don't enjoy living."}, {"time": 10250, "text": "And when I don't enjoy living, I change my circumstances."}, {"time": 10253, "text": "So it's intrinsic."}, {"time": 10254, "text": "And I think that certain things are intrinsic and like love, love of your children is kind of, well, it's actually physiological, but it's also intrinsic."}, {"time": 10264, "text": "You know, there's something about it that is intrinsically desirable."}, {"time": 10272, "text": "So I think the meaning of life is like that, intrinsically desirable."}, {"time": 10277, "text": "So it's something that just is born inside you based on what makes you feel good?"}, {"time": 10285, "text": "No, that's hedonism."}, {"time": 10287, "text": "That's about what a wordy place, love, love, love of your children."}]}, {"title": "Avi Loeb: Aliens, Black Holes, and the Mystery of the Oumuamua | Lex Fridman Podcast #154", "id": "plcc6E-E1uU", "quotes": [{"time": 396, "text": "If you are inferior, there is a risk if you speak too loudly, something bad may happen to you."}, {"time": 403, "text": "You mentioned, we should be humble also in the sense, with the analogy to ants, that they might be better than us."}, {"time": 410, "text": "So there's a kind of scale that we're talking about."}, {"time": 418, "text": "And in the question, you mentioned the word sentient."}, {"time": 418, "text": "So sentience, or maybe the more basic formulation is consciousness."}, {"time": 423, "text": "Do you think that this thing within us humans in terms of the typical life form of consciousness is the essential element that permeates other, if there's other alien civilizations out there, that they have something like consciousness as well?"}, {"time": 445, "text": "Or is this, I guess I'm asking, can you try to untangle the word sentient?"}, {"time": 451, "text": "I think what is most abundant, depending on how long it survives."}, {"time": 458, "text": "So if you look at us, as an example, we are now, we do have consciousness and we do have technology."}, {"time": 466, "text": "But the technologies that we are developing are also means for our own destruction, as we can tell."}, {"time": 473, "text": "You know, we can change the climate if we are not careful enough."}, {"time": 478, "text": "We can go into nuclear wars."}, {"time": 478, "text": "So we are developing means for our own destruction through self inflicted wounds."}, {"time": 485, "text": "And it might well be that creatures like us are not long lived, that crocodiles on other planets live for billions of years."}, {"time": 493, "text": "They don't destroy themselves, they live naturally."}, {"time": 500, "text": "And so if you look around, the most common thing would be dumb animals that live for long times, you know, not those that have conscious."}, {"time": 506, "text": "But in terms of changing the environment, I think since, I mean, humans develop tools, they develop the ability to construct technologies that would lift us from this planet that we were born in."}, {"time": 524, "text": "And that's something animals without a conscious, consciousness cannot really do."}, {"time": 528, "text": "And so I, you know, in terms of looking for things that are new, that went beyond the circumstances they were born into, I would think that even if they're short lived, these are the creatures that made the biggest difference to their environment."}, {"time": 550, "text": "And we can search for them, you know, even if they're short lived, and most of the civilizations are dead by now."}, {"time": 555, "text": "Even if that's the case."}, {"time": 555, "text": "That's sad to think about, by the way."}, {"time": 559, "text": "Well, but if you look on Earth, that, you know, there are lots of cultures that existed throughout time, and they're dead by now."}, {"time": 564, "text": "The Mayan culture was very sophisticated, died."}, {"time": 564, "text": "But we can find evidence for it and learn about it just by archaeology, digging into the ground, looking."}, {"time": 575, "text": "And so we can do the same thing in space, look for dead civilizations."}, {"time": 575, "text": "And perhaps we can learn a lesson why they died and behave better so that we will not share the same fate."}, {"time": 581, "text": "So I think, you know, there is a lesson to be learned from the sky."}, {"time": 588, "text": "And by the way, I should also say, if we find a technology that we have not dreamed of, that we can import to Earth, that may be a better strategy for making a fortune than going to Silicon Valley or going to Wall Street."}, {"time": 601, "text": "Because you make a jump start into something of the future."}, {"time": 607, "text": "So that's one way to do the leap is actually to find, to literally discover versus come up with the idea in our own limited human capacity, like a cognitive capacity."}, {"time": 620, "text": "It would look like, it would feel like cheating in an exam where you look over the shoulder of a student next to you."}, {"time": 625, "text": "But it's not good on an exam, but it is good when you're coming up with technology that could change the fabric of human civilization."}, {"time": 635, "text": "But there is, you know, in my neck of the woods of artificial intelligence, there's a lot of trajectories one can imagine of creating very powerful beings, the technology that's essentially, you know, you can call super intelligence that could achieve space exploration, all those kinds of things without consciousness, without something that to us humans looks like consciousness."}, {"time": 661, "text": "And there, you know, there is a sad feeling I have that consciousness too, in terms of us being humble, is a thing we humans take too seriously."}, {"time": 669, "text": "That it's, we think it's special just because we have it."}, {"time": 677, "text": "But it could be a thing that's actually holding us back in some kind of way."}, {"time": 681, "text": "It may well be."}, {"time": 681, "text": "I should say something about AI, because I do think it offers a very important step into the future."}, {"time": 686, "text": "If you look at the Old Testament, the Bible, there is this story about Noah's Ark that you might know about."}, {"time": 693, "text": "Noah knew about a great flood that is about to endanger all life on earth."}, {"time": 701, "text": "So he decided to build an ark."}, {"time": 709, "text": "And the Bible actually talks about specifically what the size of this ark was, what the dimensions were."}, {"time": 715, "text": "Turns out it was quite similar to Oumuamua that we will discuss in a few minutes."}, {"time": 715, "text": "But at any event, he built this ark and he put animals on it so that they were saved from the great flood."}, {"time": 728, "text": "Now, you can think about doing the same on earth, because there are risks for future catastrophes."}, {"time": 736, "text": "You know, we could have the self inflicted wounds that we were talking about, like nuclear war, changing the climate."}, {"time": 740, "text": "Or there could be an asteroid impacting us, just like the dinosaurs died."}, {"time": 746, "text": "The dinosaurs didn't have science, astronomy."}, {"time": 746, "text": "They couldn't have a warning system."}, {"time": 752, "text": "But there was this big stone, big rock that approached them."}, {"time": 752, "text": "It must have been a beautiful sight."}, {"time": 757, "text": "Just when it was approaching, it got very big and then smashed them and killed them."}, {"time": 757, "text": "So you could have a catastrophe like that."}, {"time": 764, "text": "Or in a billion years, the sun will basically boil off all the oceans on earth."}, {"time": 768, "text": "And currently all our eggs are in one basket, but we can spread them."}, {"time": 777, "text": "It's sort of like the printing press, if you think about it."}, {"time": 777, "text": "The revolution that Gutenberg brought is there were very few copies of the Bible at the time, and each of them was precious because it was handwritten."}, {"time": 787, "text": "But once the printing press produced multiple copies, you know, if something bad happened to one of the copies, it wasn't a catastrophe."}, {"time": 793, "text": "You know, it wasn't disaster because you had many more copies."}, {"time": 797, "text": "And so if we have copies of life here on earth elsewhere, then we avoid the risk of it being eliminated by a single point breakdown, catastrophe."}, {"time": 812, "text": "So the question is, can we build NOx spaceship that will carry life as we know it?"}, {"time": 812, "text": "Now, you might think we have to put elephants and whales and birds on a big spaceship, but that's not true because all you need to know is the DNA making, the genetic making of these animals, put it on a computer system that has AI plus a 3D printer so that this CubeSat, which is rather small, can go with this information to another planet and use the raw materials there to produce synthetic life."}, {"time": 849, "text": "And that would be a way of producing copies, just like the Gutenberg printing press."}, {"time": 856, "text": "Yeah, and it doesn't have to be exact copies of the humans, it could just contain some basic elements of life and then have enough life on board that it could reproduce the process of evolution on another place."}, {"time": 869, "text": "So I mean, that also makes you sad, of course, because you confront the mortality of your own little precious consciousness and all your own memories and knowledge and all that stuff."}, {"time": 878, "text": "I care about mine, right?"}, {"time": 878, "text": "And you care about yours."}, {"time": 884, "text": "No, no, I actually don't."}, {"time": 884, "text": "If you're an astronomer, one thing that you learn from the universe is to be modest because you're not so significant."}, {"time": 890, "text": "I mean, think about it, all these emperors and kings that conquered a piece of land on Earth and were extremely proud."}, {"time": 896, "text": "You see these images of kings and emperors that usually are alpha males and they stand strong and they're very proud of themselves."}, {"time": 910, "text": "But if you think about it, there are 10 to the power 20 planets like the Earth in the observable volume of the universe."}, {"time": 915, "text": "And this view of conquering a piece of land and even conquering all of Earth is just like an ant hugging a single grain of sand on the landscape of a huge beach."}, {"time": 929, "text": "That's not very impressive."}, {"time": 929, "text": "So you can't be arrogant."}, {"time": 929, "text": "If you see the big picture, you have to be humble."}, {"time": 935, "text": "Also, we are short lived."}, {"time": 935, "text": "Within 100 years, that's it."}, {"time": 935, "text": "So what does it teach you?"}, {"time": 944, "text": "First to be humble, modest."}, {"time": 944, "text": "You never have significant powers relative to the big scheme of things."}, {"time": 949, "text": "And second, you should appreciate every day that you live and learn about the world."}, {"time": 956, "text": "Humble and still grateful."}, {"time": 956, "text": "Well, let's talk about probably the most interesting object I've heard about and also the most fun to pronounce."}, {"time": 967, "text": "Oumuamua."}, {"time": 967, "text": "Can you tell me the story of this object and why it may be an important event in human history?"}, {"time": 973, "text": "And is it possibly a piece of alien technology?"}, {"time": 981, "text": "So this is the first object that was spotted close to Earth from outside the solar system."}, {"time": 989, "text": "And it was found on October 19th, 2017."}, {"time": 989, "text": "And at that time, it was receding away from us."}, {"time": 998, "text": "And at first, astronomers thought it must be a piece of rock, you know, just like all the asteroids and comets that we have seen from within the solar system."}, {"time": 1009, "text": "And it just came from another star."}, {"time": 1009, "text": "I should say that the actual discovery of this object was surprising to me because a decade earlier, I wrote the first paper together with Ed Turner and Amaya Moro Martin that tried to predict whether the same telescope that was surveying the sky, PanSTARRS from Hawaii, would find anything from interstellar space, given what we know about the solar system."}, {"time": 1032, "text": "So if you assume that other planetary systems have similar abundance of rocks and you just calculate how many should be ejected into interstellar space, the conclusion is no, we shouldn't find anything with PanSTARRS."}, {"time": 1043, "text": "To me, I apologize for probably revealing my stupidity, but it was surprising to me that so few interstellar objects from outside this whole system have ever been detected."}, {"time": 1056, "text": "None has been."}, {"time": 1056, "text": "You do maybe talk about it that there has been one or two rocks since then."}, {"time": 1064, "text": "Well, since then, there was one called the Borisov."}, {"time": 1070, "text": "It was discovered by an amateur Russian astronomer, Gennady Borisov."}, {"time": 1070, "text": "And that one looked like a comet."}, {"time": 1078, "text": "And just like a comet from within the solar system."}, {"time": 1078, "text": "But this is a really important point."}, {"time": 1085, "text": "Sorry to interrupt it."}, {"time": 1085, "text": "You showed that it's unlikely that a rock from another solar system would arrive to ours."}, {"time": 1090, "text": "And so the actual detection of this one was surprising by itself to me."}, {"time": 1096, "text": "But then, so at first they thought maybe it's a comet or an asteroid, but then it didn't look like anything we've seen before."}, {"time": 1104, "text": "Borisov did look like a comet."}, {"time": 1104, "text": "So people asked me afterwards and said, you know, doesn't it convince you if Borisov looks like a comet, doesn't it convince you that Oumuamua is also natural?"}, {"time": 1118, "text": "And I said, you know, when I went on the first date with my wife, she looked special to me."}, {"time": 1124, "text": "And since then I met many women."}, {"time": 1124, "text": "That didn't change my opinion of my wife."}, {"time": 1130, "text": "So, you know, that's not an argument."}, {"time": 1130, "text": "Anyway, so why did the Oumuamua look weird?"}, {"time": 1139, "text": "Let me explain."}, {"time": 1139, "text": "So first of all, astronomers monitored the amount of light, sunlight that it reflects."}, {"time": 1145, "text": "And it was tumbling, spinning every eight hours."}, {"time": 1145, "text": "And as it was spinning, the brightness that we saw from that direction, we couldn't resolve it because it's tiny."}, {"time": 1153, "text": "It's about a hundred meters, a few hundred feet, size of a football field."}, {"time": 1158, "text": "And we cannot, from Earth, with existing telescopes, we cannot resolve it."}, {"time": 1164, "text": "The only way to actually get a photograph of it is to send a camera close to it."}, {"time": 1169, "text": "And that was not possible at the time that Oumuamua was discovered because it was already moving away from us faster than any rocket we can send."}, {"time": 1178, "text": "It's sort of like a guest that appeared for dinner."}, {"time": 1183, "text": "And then by the time we realized that it's weird, the guest is already out the front door into the dark street."}, {"time": 1189, "text": "What we would like to find is an object like it approaching us, because then you can send the camera irrespective of how fast it moves."}, {"time": 1196, "text": "And if we were to find it in July 2017, that would have been possible because it was approaching us at that time."}, {"time": 1207, "text": "Actually, I was visiting Mount Haleakala in Maui, Hawaii with my family for vacation at that time in July 2017, but nobody knew at the observatory that the Oumuamua is very close."}, {"time": 1223, "text": "That's sad to think about that we had the opportunity at that time to send up a camera."}, {"time": 1228, "text": "But don't worry."}, {"time": 1228, "text": "I mean, there will be more."}, {"time": 1228, "text": "There will be more because I operate by the Copernican principle, which says we don't live at a special place and we don't live at a special time."}, {"time": 1235, "text": "And that means if we surveyed the sky for a few years and we had sensitivity to this region between us and the sun, and we found this object with PanStars, there should be many more that we will find in the future with surveys that might be even better."}, {"time": 1255, "text": "And actually, in three years timescale, there would be the so called LSST."}, {"time": 1261, "text": "That's a survey of the Vera Rubin Observatory that would be much more sensitive and could potentially find an Oumuamua like object every month."}, {"time": 1274, "text": "OK, so I'm just waiting for that."}, {"time": 1274, "text": "And the main reason for me to alert everyone to the unusual properties of Oumuamua is with the hope that next time around, when we see something as unusual, we would take a photograph or we would get as much evidence as possible because science is based on evidence, not on prejudice."}, {"time": 1292, "text": "And we will get back to that theme."}, {"time": 1297, "text": "So anyway, let me let me point out some of the properties, actually, the elongated nature, all those kinds of things."}, {"time": 1302, "text": "So the light curve, the amount of light, sunlight that was reflected from it was changing over eight hours by a factor of 10, meaning that the area of this object, even though we can't resolve it, the area on the sky that reflects sunlight was bigger by a factor of 10 in some phases as it was tumbling around than in other phases."}, {"time": 1329, "text": "So even if you take a piece of paper that is razor thin, you know, there is a very small likelihood that it's exactly edge on and getting a factor of 10 change in the area that you see on the sky is huge."}, {"time": 1340, "text": "It's much more than any."}, {"time": 1340, "text": "It means that the object has an unusual geometry."}, {"time": 1347, "text": "It's at least a factor of a few more than any of the comets or asteroids that we have seen before."}, {"time": 1352, "text": "You mentioned reflectivity."}, {"time": 1352, "text": "So it's not just the geometry, but the properties of the surface of that thing."}, {"time": 1355, "text": "Well, if you assume the reflectivity is the same, then it's just geometry."}, {"time": 1362, "text": "If you assume the reflectivity may change, then it could be a combination of the area that you see and the reflectivity because different directions may reflect differently."}, {"time": 1372, "text": "But the point is that it's very extreme."}, {"time": 1372, "text": "And actually the best fit to the light curve that we saw was of a flat object."}, {"time": 1380, "text": "Unlike all the cartoons that you have seen of a cigar shape, a flat object at the 90% confidence gives a better model for the way that the light varied."}, {"time": 1393, "text": "So like flat meaning like a pancake."}, {"time": 1397, "text": "Like a pancake."}, {"time": 1397, "text": "And so that's, you know, the very first unusual property."}, {"time": 1397, "text": "But to me, it was not unusual enough to think that it might be artificial."}, {"time": 1405, "text": "It was not significant enough."}, {"time": 1412, "text": "Then there was no cometary tail, you know, no dust, no gas around this object."}, {"time": 1412, "text": "And the Spitzer Space Telescope really searched very deeply for carbon based molecules."}, {"time": 1418, "text": "There was nothing."}, {"time": 1425, "text": "So it's definitely not a comet the way people expected it to be."}, {"time": 1429, "text": "Can you maybe briefly mention what properties a comet that you're referring to usually has?"}, {"time": 1435, "text": "So a comet is a rock that has some water ice on the surface."}, {"time": 1435, "text": "So you can think of it as an icy rock."}, {"time": 1442, "text": "Actually comets were discovered a long time ago, but the first model that was developed for them was by Fred Whipple, who was at Harvard."}, {"time": 1452, "text": "And I think the legend goes that he got the idea from walking through Harvard Square and seeing during a winter day and seeing these icy rocks, you know."}, {"time": 1466, "text": "So a comet is icy and an asteroid is not."}, {"time": 1470, "text": "It's just a rock."}, {"time": 1472, "text": "So when you have ice on the surface, when the rock gets close to the sun, the sunlight warms it up and the ice sublimates, evaporates."}, {"time": 1478, "text": "Because the one thing about ice, water ice, is it doesn't become liquid if you warm it up in vacuum, you know, without an external pressure."}, {"time": 1493, "text": "It just goes straight into gas."}, {"time": 1493, "text": "And that's what you see as the tail of a comet."}, {"time": 1499, "text": "The only way to get liquid water is to have an atmosphere like on Earth that has an external pressure."}, {"time": 1507, "text": "Only then you get liquid."}, {"time": 1507, "text": "And that's why it's essential to have an atmosphere to a planet in order to have liquid water and the chemistry of life."}, {"time": 1513, "text": "So if you look at Mars, Mars lost its atmosphere and therefore no liquid water on the surface anymore."}, {"time": 1519, "text": "I mean, there may have been early and that's what the Perseverance survey, you know, the Perseverance mission will try to find out whether it had liquid water, whether there was life perhaps on it at the time, but at some point it lost its atmosphere and then the liquid water was gone."}, {"time": 1537, "text": "So the only reason that we can live on Earth is because of the atmosphere."}, {"time": 1544, "text": "But a comet is in vacuum pretty much."}, {"time": 1544, "text": "And then when it gets warmed up on the surface, the water becomes, the water ice becomes gas and then you see this cometary tail behind it."}, {"time": 1558, "text": "In addition to water, there are all kinds of carbon based molecules or dust that comes off the surface."}, {"time": 1565, "text": "And those are detectable."}, {"time": 1565, "text": "Yeah, it's easy to detect."}, {"time": 1565, "text": "It's very prominent."}, {"time": 1571, "text": "You see these cometary tails that look very prominent because they reflect sunlight and you can see them."}, {"time": 1576, "text": "In fact, it's sometimes difficult to see the nucleus of the comet because it's surrounded and shrouded with, and in this case, there was no trace of anything."}, {"time": 1586, "text": "Now you might say, okay, it's not a comet."}, {"time": 1586, "text": "So that's what the community said."}, {"time": 1590, "text": "Okay, it's not a, no problem."}, {"time": 1590, "text": "It's still a rock, you know, it's not a comet, but it's just a rock, bare rock."}, {"time": 1594, "text": "You know, okay, no problem."}, {"time": 1594, "text": "Then, and that's the thing that convinced me to write about it."}, {"time": 1600, "text": "And then in June 2018, you know, significantly later, there was a report that in fact the object exhibited an excess push in addition to the force of gravity."}, {"time": 1615, "text": "So the sun acts on it by gravity, but then there was an extra push on this object that was figured out from the orbit that you can trace."}, {"time": 1620, "text": "And the question was, what is this excess push?"}, {"time": 1626, "text": "So for comets, you get the rocket effect."}, {"time": 1626, "text": "When you evaporate gas, you know, just like a jet engine on an airplane, you throw, a jet engine is very simple."}, {"time": 1632, "text": "You throw the gas back and it pushes the airplane forward."}, {"time": 1638, "text": "That's how the jet."}, {"time": 1638, "text": "So in a case of a comet, you throw gas in the direction of the sun because it, and then you get a push."}, {"time": 1649, "text": "So in the case of comets, you can get a push, but there was no cometary tail."}, {"time": 1649, "text": "So then people say, oh, wait a second."}, {"time": 1654, "text": "Is it an asteroid?"}, {"time": 1654, "text": "No, but it behaves like a comet, but it doesn't look like a comet."}, {"time": 1660, "text": "So what, well, forget about it."}, {"time": 1660, "text": "Business as usual."}, {"time": 1660, "text": "So that's what they mean by a non gravitation acceleration."}, {"time": 1665, "text": "So like the primary force acting on something like just a rock, like an asteroid would be like, you can predict the trajectory based on the gravity, based on gravity."}, {"time": 1677, "text": "And so here there's detected movement that's not, cannot be accounted purely by the gravity of the sun."}, {"time": 1682, "text": "And if it was a comet, you would need about a 10th of the mass of this comet, the weight of this comet to be evaporated in order to give it."}, {"time": 1694, "text": "And there was no sign of that."}, {"time": 1694, "text": "No sign."}, {"time": 1694, "text": "10% of the mass evaporating."}, {"time": 1699, "text": "A hundred meter size object losing 10% of its mass."}, {"time": 1699, "text": "You can't miss that."}, {"time": 1705, "text": "So that's super weird."}, {"time": 1707, "text": "It's super weird."}, {"time": 1708, "text": "Is there a good explanation, is there in your mind a possible explanation for this?"}, {"time": 1712, "text": "So I operated just like Sherlock Holmes in a way."}, {"time": 1712, "text": "I said, okay, what are the possibilities?"}, {"time": 1712, "text": "And the only thing I could think, so I ruled out everything else."}, {"time": 1717, "text": "And I said, it must be the sunlight reflected off it."}, {"time": 1722, "text": "So the sunlight reflects off the surface and gives it a push, just like you get a push on a sail on a boat, you know, from the wind reflecting off it."}, {"time": 1736, "text": "Now, in order for this to be effective, it turns out the object needs to be extremely thin."}, {"time": 1743, "text": "It turns out it needs to be less than a millimeter thick."}, {"time": 1743, "text": "Nature does not produce such things."}, {"time": 1748, "text": "But we produce it because it's called the technology of a light sail."}, {"time": 1748, "text": "So we are, for space exploration, we are exploring this technology because it has the benefit of not needing to carry the fuel with the spacecraft."}, {"time": 1761, "text": "So you don't have the fuel, you just have a sail and it's being pushed either by sunlight or by a laser beam or whatever."}, {"time": 1768, "text": "So perhaps this is the light sail."}, {"time": 1777, "text": "So this is actually the same technology with the Starshot project."}, {"time": 1782, "text": "So people afterwards say, okay, you work on this project, you imagine."}, {"time": 1782, "text": "No, that's a pretty good explanation, right?"}, {"time": 1789, "text": "Obviously, my imagination is limited by what I know."}, {"time": 1789, "text": "So I would not deny that working on light sails expanded my ability to imagine this possibility."}, {"time": 1797, "text": "But let me offer another interesting anecdote."}, {"time": 1803, "text": "In September this year, 2020, there was another object found, and it was given the name 2020SO by the Minor Planet Center."}, {"time": 1813, "text": "This is an organization actually in Cambridge, Massachusetts, that gives names to astronomical objects found in the solar system."}, {"time": 1828, "text": "And they gave it that name 2020SO because, you know, it looked like an object in the solar system and it moved in an orbit that is similar to the orbit of the Earth, but not the same exactly."}, {"time": 1842, "text": "And therefore it was bound to the Sun, but it also exhibited a deviation from what you expect based on gravity."}, {"time": 1849, "text": "So the astronomers that found it extrapolated back in time and found that in 1966, it intercepted the Earth."}, {"time": 1855, "text": "And then they went to the history books and they realized, oh, there was a mission called Lunar Lander Surveyor 2 that had a rocket booster."}, {"time": 1863, "text": "It was a failed mission, but there was a rocket booster that was kicked into space."}, {"time": 1872, "text": "And presumably this is the rocket booster that we're seeing."}, {"time": 1878, "text": "Now, this rocket booster was sufficiently hollow and thin for us to recognize that it's pushed by sunlight."}, {"time": 1883, "text": "So here is my point."}, {"time": 1883, "text": "We can tell from the orbit of an object, obviously this object didn't have any cometary tail."}, {"time": 1890, "text": "It was artificially made."}, {"time": 1890, "text": "We know that it was made by us and it did deviate from an orbit of a rock."}, {"time": 1896, "text": "So just by seeing something that doesn't have cometary tail and deviates from an orbit shaped by gravity, we can tell that it's artificial."}, {"time": 1909, "text": "In the case of Oumuamua, it couldn't have been sent by humans because it just passed near us for a few months."}, {"time": 1915, "text": "We know exactly what we were doing at that time."}, {"time": 1921, "text": "And also it was moving faster than any object that we can launch."}, {"time": 1921, "text": "And so obviously it came from outside the solar system."}, {"time": 1926, "text": "And the question is who produced it?"}, {"time": 1926, "text": "Now, I should say that when I walk on vacation on the beach, I often see natural objects like seashells that are beautiful and I look at them."}, {"time": 1941, "text": "And every now and then I stumble on a plastic bottle that was artificially produced."}, {"time": 1949, "text": "And my point is that maybe Oumuamua was a message in a bottle."}, {"time": 1949, "text": "And this is simply another window into searching for artifacts from other civilizations."}, {"time": 1957, "text": "Where do you think it could have come from?"}, {"time": 1963, "text": "And if it's so, okay, from a scientific perspective, the narrow minded view, as we'll probably talk about throughout, is, you know, you kind of want to stick to the things that, to naturally originating objects like asteroids and comets."}, {"time": 1980, "text": "Okay, that's the space of possible hypotheses."}, {"time": 1986, "text": "And then if we expand beyond that, you start to think, okay, these are artificially constructed."}, {"time": 1992, "text": "Like you just said, it could be by humans."}, {"time": 1992, "text": "It could be by whatever that means, by some kind of extraterrestrial alien civilizations."}, {"time": 1999, "text": "If it's the alien civilization variety, what is this object then?"}, {"time": 2006, "text": "And let me lay out, I mean, we don't have enough evidence to tell."}, {"time": 2014, "text": "If we had a photograph, perhaps we would have more information."}, {"time": 2018, "text": "But there is one other peculiar fact about Oumuamua."}, {"time": 2018, "text": "Well, other than it was very shiny, that I didn't mention, you know, we didn't detect any heat from it."}, {"time": 2027, "text": "And that implies that it's rather small and shiny."}, {"time": 2033, "text": "But the other peculiar fact is that it came from a very special frame of reference."}, {"time": 2040, "text": "So it's sort of like finding a car in a parking lot, in a public parking lot, that, you know, you can't really tell where it came from."}, {"time": 2048, "text": "So there is this frame of reference where you average over the motions of all the stars in the neighborhood of the Sun."}, {"time": 2053, "text": "So you find the so called local standard of rest of the galaxy."}, {"time": 2060, "text": "And that's a frame of reference that is obtained by averaging the random motions of all the stars."}, {"time": 2068, "text": "And the Sun is moving relative to that frame at some speed."}, {"time": 2074, "text": "But this object was at rest in that frame."}, {"time": 2074, "text": "And only one in 500 stars is so much at rest in that frame."}, {"time": 2081, "text": "And that's why I was saying it's like a parking lot."}, {"time": 2081, "text": "It was parked there, and we bumped into it."}, {"time": 2086, "text": "So the relative speed between the solar system and this object is just because we are moving."}, {"time": 2092, "text": "It was sitting still."}, {"time": 2092, "text": "Now you ask yourself, why is it so unusual in that context?"}, {"time": 2099, "text": "Because if it was expelled from another planetary system, most likely it will carry the speed of the host star that it came from."}, {"time": 2106, "text": "Because it was, you know, the most loosely bound objects are in the periphery of the planetary system, and they move very slowly relative to the star."}, {"time": 2119, "text": "And so they carry the, when they are ripped apart from the planetary system, most of the objects will have the residual motion of the star roughly relative to the local star."}, {"time": 2124, "text": "But this one was at rest in the local star."}, {"time": 2130, "text": "Now, one thing I can think of, if there is a grid of road posts, you know, like for navigation system, so that you can find your way in the local frame, then that would be one possibility."}, {"time": 2144, "text": "These are like little sensors of, that's fascinating to think about."}, {"time": 2144, "text": "So there could be, I mean, not necessarily literally a grid, but just evenly, in some definition of evenly spread out set of objects like these that are just out there."}, {"time": 2155, "text": "A lot of them."}, {"time": 2155, "text": "Another possibility is that these are relay stations, you know, for communication."}, {"time": 2161, "text": "You might think, in order to communicate, you need a huge beacon, a very powerful beacon."}, {"time": 2166, "text": "But it's not true."}, {"time": 2166, "text": "Because even on Earth, you know, we have these relay stations."}, {"time": 2172, "text": "So you have a not so powerful beacon."}, {"time": 2177, "text": "So it can be heard only out to a limited distance, but then you relay the message."}, {"time": 2182, "text": "And it could be one of those."}, {"time": 2182, "text": "Now, after it collided with the solar system, of course, it got a kick."}, {"time": 2188, "text": "So it's just like a billiard ball, you know, we gave it a kick by colliding with, but most of them are not colliding with stars."}, {"time": 2193, "text": "And so that's one possibility."}, {"time": 2193, "text": "And there should be numerous, lots of them, if that's the case."}, {"time": 2198, "text": "The other possibility is that it's a probe, you know, that was sent in the direction of the habitable region around the Sun to find out if there is life."}, {"time": 2214, "text": "Now, it takes tens of thousands of years for such a probe to traverse the solar system from the outer edge of the Oort cloud, all the way to where we are."}, {"time": 2220, "text": "And, you know, it's a long journey."}, {"time": 2226, "text": "So when it started the journey from the edge of the solar system to get to us now, you know, we were rather primitive back then, you know, we still didn't have any technology, there was no reason to visit, you know, there was grass around and so forth."}, {"time": 2235, "text": "But, you know, maybe it is a probe."}, {"time": 2240, "text": "So you said 10,000 years, that's faster."}, {"time": 2240, "text": "So it takes that long."}, {"time": 2245, "text": "Tens of thousands, yes."}, {"time": 2245, "text": "Tens of thousands of years."}, {"time": 2245, "text": "And the other thing I should say is, you know, it could be just an outer layer of something else, like, you know, something that was ripped apart, like a surface of an instrument."}, {"time": 2258, "text": "And you can have lots of these pieces, you know, if something breaks, lots of these pieces spread out, like space junk."}, {"time": 2265, "text": "And, you know, that..."}, {"time": 2271, "text": "It could be just space junk from an alien civilization."}, {"time": 2276, "text": "So it's kind of..."}, {"time": 2279, "text": "I should tell you about space junk."}, {"time": 2281, "text": "What do you mean by space junk?"}, {"time": 2283, "text": "So, I think, you know, you might ask, why aren't they looking for us?"}, {"time": 2283, "text": "One possibility is that we are not interesting, like we were talking about ants."}, {"time": 2289, "text": "Another possibility, you know, if there are millions or billions of years into their technological development, they created their own habitat, their own cocoon, where they feel comfortable, they have everything they need."}, {"time": 2308, "text": "And it's risky for them to establish communication with other..."}, {"time": 2308, "text": "So they have their own cocoon and they close off."}, {"time": 2316, "text": "They don't care about anything else."}, {"time": 2316, "text": "Now, in that case, you might say, oh, so how can we find about them if they are closed off?"}, {"time": 2321, "text": "The answer is they still have to deposit trash, right?"}, {"time": 2327, "text": "That is something from the law of thermodynamics."}, {"time": 2327, "text": "There must be some production of trash."}, {"time": 2333, "text": "And, you know, we can still find about them just like investigative journalists going through the trash cans of celebrities in Hollywood, you know."}, {"time": 2340, "text": "You can learn about the private lives of those celebrities by looking at the trash."}, {"time": 2349, "text": "It's fascinating to think, you know, if we are the ants in this picture, if this thing is a water bottle, or if it's like a smartphone, like where on the spectrum of possible objects of space, because there's a lot of interesting trash."}, {"time": 2361, "text": "How interesting is this trash?"}, {"time": 2368, "text": "But imagine a caveman seeing a cell phone."}, {"time": 2368, "text": "The caveman would think, since the caveman played with rocks all of his life, he would say, it's a rock, just like my fellow astronomers said."}, {"time": 2379, "text": "Actually, as a scientist, do you hope it's a water bottle or a smartphone?"}, {"time": 2386, "text": "Because I hope it's even more than a smartphone."}, {"time": 2386, "text": "I hope that it's something that is really sophisticated."}, {"time": 2392, "text": "See, I'm the opposite."}, {"time": 2392, "text": "I feel like I hope it's a water bottle because at least we have a hope with our current set of skills to understand it."}, {"time": 2397, "text": "A caveman has no way of understanding the smartphone."}, {"time": 2403, "text": "It's like, it will be like, I feel like a caveman has more to learn from the plastic water bottle than they do from the smartphone."}, {"time": 2411, "text": "But suppose we figure it out."}, {"time": 2411, "text": "If we, for example, come close to it and learn what it's made of."}, {"time": 2417, "text": "And I guess a smartphone is full of like thousands of different technologies that we could probably pick at."}, {"time": 2422, "text": "Do you have a sense of where a hypothesis of where is the cocoon that it might have come from?"}, {"time": 2433, "text": "No, because, okay, so first of all, you know, the solar system, the outermost edge of the solar system is called the Oort cloud."}, {"time": 2440, "text": "It's a cloud of icy rocks of different sizes that were left over from the formation of the solar system."}, {"time": 2449, "text": "And it's thought to be roughly a ball or a sphere."}, {"time": 2457, "text": "And it's halfway, the extent of it is roughly halfway to the nearest star."}, {"time": 2457, "text": "Okay, so you can imagine each planetary system basically touching the Oort clouds of those stars that are near us are touching each other."}, {"time": 2474, "text": "Space is full of these billiard balls that are very densely packed."}, {"time": 2482, "text": "And what that means is any object that you see, irrespective of whether it came from the local standard."}, {"time": 2488, "text": "So we said that this object is special because it came from a local standard of rest."}, {"time": 2492, "text": "But even if it didn't, you would never be able to trace where it came from because all these Oort clouds overlap."}, {"time": 2498, "text": "So if you take some direction in the sky, you will cross as many stars as you have in that direction."}, {"time": 2506, "text": "Like, there is no way to tell which Oort cloud it came from."}, {"time": 2512, "text": "So yes, I didn't realize how densely packed everything was from the perspective of the Oort cloud."}, {"time": 2517, "text": "So yeah, it could be nearby, it could be very far away."}, {"time": 2521, "text": "Yeah, we have no clue."}, {"time": 2523, "text": "You said cocoon."}, {"time": 2523, "text": "And you kind of paint, I think in the book, I've read a lot of your articles too on the Scientific American, which are brilliant."}, {"time": 2533, "text": "So I'm kind of mixing things up in my head a little bit."}, {"time": 2536, "text": "But what does that cocoon look like?"}, {"time": 2536, "text": "What does a civilization that's able to harness the power of multiple suns, for example, look like?"}, {"time": 2544, "text": "When you imagine possible civilizations that are a million years more advanced than us, what do you think that actually looks like?"}, {"time": 2556, "text": "I think it's very different than we can imagine."}, {"time": 2556, "text": "By the way, I should start from the point that even biological life, just without technology getting into the game, could look like something we have never seen before."}, {"time": 2570, "text": "Take, for example, the nearest star, which is Proxima Centauri."}, {"time": 2575, "text": "It's four and a quarter light years away."}, {"time": 2575, "text": "So they will know about the results of the 2016 elections only next month, in February 2021."}, {"time": 2583, "text": "It's very far away."}, {"time": 2583, "text": "But if you think about it, this star is a dwarf star, and it's twice as cold as the sun."}, {"time": 2596, "text": "And it emits mostly infrared radiation."}, {"time": 2596, "text": "So if there are any creatures on the planet close to it that is habitable, which is called Proxima B, there is a planet in the habitable zone, in the zone just at the right distance where, in principle, liquid water can be on the surface."}, {"time": 2619, "text": "If there are any animals there, they have infrared eyes because our eyes were designed to be sensitive to where most of the sunlight is in the visible range."}, {"time": 2631, "text": "But Proxima Centauri emits mostly infrared."}, {"time": 2631, "text": "So in the nearest star system, these animals would be quite strange."}, {"time": 2640, "text": "They would have eyes that are detectors of infrared, very different from ours."}, {"time": 2646, "text": "Moreover, this planet, Proxima B, faces the star always with the same side."}, {"time": 2646, "text": "So it has a permanent day side and a permanent night side."}, {"time": 2652, "text": "And obviously the creatures that would evolve on the permanent day side, which is much warmer, would be quite different than those on the permanent night side."}, {"time": 2664, "text": "Between them, there would be a permanent sunset strip."}, {"time": 2664, "text": "And my daughters said that that's the best opportunity for high value real estate because you will see the sunset throughout your life, right?"}, {"time": 2677, "text": "The sun never sets on this trip."}, {"time": 2677, "text": "So these worlds are out of our imagination."}, {"time": 2686, "text": "Just even the individual creatures, the sensor suite that they're operating with might be very different."}, {"time": 2690, "text": "Very different."}, {"time": 2690, "text": "So I think when we see something like that, we would be shocked not to speak about seeing technology."}, {"time": 2693, "text": "So I don't even dare to imagine."}, {"time": 2701, "text": "And I think obviously we can bury our head in the sand and say, it's never aliens, like many of my colleagues say."}, {"time": 2707, "text": "And it's a self fulfilling prophecy."}, {"time": 2707, "text": "If you never look, you will never find."}, {"time": 2713, "text": "If you're not ready to find wonderful things, you will never discover them."}, {"time": 2719, "text": "And the other thing I would like to say is reality doesn't care whether you ignore it or not."}, {"time": 2725, "text": "You can ignore reality, but it's still there."}, {"time": 2725, "text": "So we can all agree, based on Twitter, that aliens don't exist."}, {"time": 2732, "text": "That Umuamua was a rock."}, {"time": 2732, "text": "We can all agree."}, {"time": 2732, "text": "And you will get a lot of likes, we will have a big crowd of supporters, and everyone will be happy and give each other awards and honors and so forth."}, {"time": 2744, "text": "But Umuamua might still be an alien artifact."}, {"time": 2744, "text": "Who cares what humans agree on?"}, {"time": 2751, "text": "There is a reality out there."}, {"time": 2751, "text": "And we have to be modest enough to recognize that we should make our statements based on evidence."}, {"time": 2759, "text": "Science is not about ourselves."}, {"time": 2759, "text": "It's not about glorifying our image."}, {"time": 2766, "text": "It's not about getting honors, prizes."}, {"time": 2766, "text": "A lot of the academic activity is geared towards creating your echo chamber where you have students, postdocs, repeating your mantras so that your voice is heard loudly so that you can get more honors, prizes, recognition."}, {"time": 2785, "text": "That's not the purpose of science."}, {"time": 2785, "text": "The purpose is to figure out what nature is."}, {"time": 2791, "text": "And in the process of doing that, it's a learning experience."}, {"time": 2791, "text": "Einstein made three mistakes at the end of his career."}, {"time": 2797, "text": "He argued that in the 1930s, he argued that black holes don't exist, gravitational waves don't exist, and quantum mechanics doesn't have spooky action at a distance."}, {"time": 2812, "text": "And all three turned out to be wrong."}, {"time": 2812, "text": "So the point is that if you work at the frontier, then you make mistakes."}, {"time": 2818, "text": "It's inevitable because you can't tell what is true or not."}, {"time": 2824, "text": "And avoiding making mistakes in order to preserve your image makes you extremely boring."}, {"time": 2824, "text": "You will get a prize, but you will be a boring scientist because you will keep repeating things we already know."}, {"time": 2836, "text": "If you want to make progress, if you want to innovate, you have to take risks and you have to look at the evidence."}, {"time": 2842, "text": "It's a dialogue with nature."}, {"time": 2842, "text": "You don't know the truth in advance."}, {"time": 2842, "text": "You let nature tell you, educate you, and then you realize that what you thought before is incorrect."}, {"time": 2855, "text": "And a lot of my colleagues prefer to be in a state where they have a monologue."}, {"time": 2855, "text": "You know, if you look at these people that work on string theory, they have a monologue."}, {"time": 2860, "text": "They know what, and in fact, their monologue is centered on anti de Sitter space, which we don't live in now."}, {"time": 2873, "text": "To me, it's just like the Olympics."}, {"time": 2873, "text": "You define a hundred meters and you say, whoever runs these hundred meters is the best athlete, the fastest."}, {"time": 2877, "text": "And it's completely arbitrary."}, {"time": 2883, "text": "You could have decided it would be 50 meters or 20 meters."}, {"time": 2883, "text": "You just measure the ability of people this way."}, {"time": 2889, "text": "So you define anti de Sitter space as a space where you do your mathematical gymnastics, and then you find who can do it the best."}, {"time": 2894, "text": "And you give jobs based on that."}, {"time": 2899, "text": "You give prizes."}, {"time": 2899, "text": "But as we said before, you know, nature doesn't care about, you know, the prizes that you give to each other."}, {"time": 2905, "text": "It cares, you know, it has its own reality and we should figure it out."}, {"time": 2912, "text": "And it's not about us."}, {"time": 2912, "text": "The scientific activity is about figuring out nature."}, {"time": 2912, "text": "And sometimes we may be wrong."}, {"time": 2917, "text": "Our image will not be preserved."}, {"time": 2917, "text": "But that's the fun, you know."}, {"time": 2917, "text": "Kids explore the world out of curiosity."}, {"time": 2926, "text": "And I always want to maintain my childhood curiosity."}, {"time": 2926, "text": "And I don't care about the labels that I have."}, {"time": 2932, "text": "In fact, having tenure is exactly the opportunity to behave like a child because you can make mistakes."}, {"time": 2939, "text": "And I was asked by the Harvard Gazette, you know, the Pravda of Harvard, what is the one thing that you would like to change about the world?"}, {"time": 2954, "text": "And I said, I would like my colleagues to behave more like kids."}, {"time": 2954, "text": "That's the one thing I would like them to do."}, {"time": 2961, "text": "Because something bad happens to these kids when they become tenured professors."}, {"time": 2967, "text": "They start to worry about their ego and about themselves more than about the purpose of science, which is, you know, curiosity driven, figuring out from evidence."}, {"time": 2973, "text": "Evidence is the key."}, {"time": 2973, "text": "So when an object shows anomalies like Oumuamua, what's the problem discussing, you know, whether it's artificial or not?"}, {"time": 2984, "text": "You know, so there was, I should tell you, there was a mainstream paper in Nature published saying it must be natural."}, {"time": 2989, "text": "It's unusual, but it must be natural, period."}, {"time": 2996, "text": "And then at the same time, some other mainstream scientists tried to explain the properties."}, {"time": 3004, "text": "And they came up with interpretations like it's a dust bunny, you know, the kind that you find in a household, a collection of dust particles pushed by sunlight, something we have never seen before."}, {"time": 3016, "text": "Or it's a hydrogen iceberg."}, {"time": 3016, "text": "It actually evaporates like a comet, but hydrogen is transparent."}, {"time": 3021, "text": "And that's why we don't see the cometary tail."}, {"time": 3026, "text": "Again, we have never seen something like that."}, {"time": 3026, "text": "In both cases, the objects would not survive the long journey."}, {"time": 3031, "text": "We discussed it in a paper that I wrote afterwards."}, {"time": 3031, "text": "But my point is, those that tried to explain the unusual properties went into great length at discussing things that we have never seen before."}, {"time": 3044, "text": "So even when you think about a natural origin, you have to come up with scenarios of things that were never seen before."}, {"time": 3050, "text": "And by the way, they look less plausible to me personally."}, {"time": 3057, "text": "But my point is, if we discuss things that were never seen before, why not discuss, why not contemplate an artificial origin?"}, {"time": 3063, "text": "What's the problem?"}, {"time": 3067, "text": "Why do people have this pushback?"}, {"time": 3067, "text": "You know, I worked on dark matter, and we don't know what most of the matter in the universe is."}, {"time": 3076, "text": "It's called dark matter."}, {"time": 3076, "text": "It's just an acronym because we have no clue."}, {"time": 3082, "text": "We simply don't know."}, {"time": 3082, "text": "So it could be all kinds of particles."}, {"time": 3082, "text": "And over the years, people suggested weakly interacting massive particles, axions, all kinds of particles."}, {"time": 3086, "text": "And experiments were made."}, {"time": 3092, "text": "They cost hundreds of millions of dollars."}, {"time": 3092, "text": "They put upper limits, constraints that ruled out many of the possibilities that were proposed as natural initially."}, {"time": 3098, "text": "The mainstream community regarded it as a mainstream activity to search the nature of the dark matter."}, {"time": 3110, "text": "And nobody complained that it's speculative to consider weakly interacting massive particles."}, {"time": 3116, "text": "Now, I ask you, why is it speculative to consider extraterrestrial technologies?"}, {"time": 3116, "text": "We have a proof that it exists here on Earth."}, {"time": 3124, "text": "We also know that the conditions of Earth are reproduced in billions of systems throughout the Milky Way galaxy."}, {"time": 3130, "text": "So what's more conservative than to say, if you arrange for similar conditions, you get the same outcome."}, {"time": 3136, "text": "How can you imagine this to be speculative?"}, {"time": 3142, "text": "It's not speculative at all."}, {"time": 3142, "text": "And nevertheless, it's regarded the periphery."}, {"time": 3142, "text": "And at the same time, you have physicists, theoretical physicists, working on extra dimensions, super symmetry, super string theory, the multiverse."}, {"time": 3152, "text": "Maybe we live in a simulation."}, {"time": 3152, "text": "All of these ideas that have no grounding in reality, some of which sound to me like, you know, just like what someone would say."}, {"time": 3167, "text": "Science fiction, basically."}, {"time": 3167, "text": "Because you have no way to test it, you know, through experiments."}, {"time": 3174, "text": "And experiments really are key."}, {"time": 3174, "text": "It's not just the nuance."}, {"time": 3174, "text": "You say, okay, forget about experiments."}, {"time": 3179, "text": "As some philosophers try to say, you know, if there is a consensus, what's the problem?"}, {"time": 3184, "text": "The point is, it's key."}, {"time": 3184, "text": "Then that's what Galileo found."}, {"time": 3184, "text": "It's key to have feedback from reality."}, {"time": 3190, "text": "You know, you can think that you have a billion dollars or that you are more rich than, you know, Elon Musk."}, {"time": 3196, "text": "You can feel very happy about it."}, {"time": 3196, "text": "You can talk about it with your friends and all of you will be happy and think about what you can do with the money."}, {"time": 3202, "text": "Then you go to an ATM machine and you make an experiment."}, {"time": 3206, "text": "You check how much money you have in your checking account."}, {"time": 3211, "text": "And if it turns out that, you know, you don't have much, you can't materialize your dreams."}, {"time": 3219, "text": "So you realize, you have a reality check."}, {"time": 3219, "text": "And my point is, without experiments giving you a reality check, without the ATM machine showing you whether your ideas are bankrupt or not, without putting skin in the game."}, {"time": 3229, "text": "And by skin in the game, I mean, don't just talk about theoretical ideas."}, {"time": 3235, "text": "Make them testable."}, {"time": 3235, "text": "If you don't make them testable, they're worthless."}, {"time": 3241, "text": "They're just like theology that is not testable."}, {"time": 3241, "text": "By the way, theology has some tests."}, {"time": 3241, "text": "Let me give you three examples."}, {"time": 3249, "text": "It turns out that my book already inspired a PhD student at Harvard in the English department to pursue a PhD in that direction."}, {"time": 3257, "text": "And she invited me to the PhD exam a couple of months ago."}, {"time": 3265, "text": "And in the exam, one of the examiners, a professor, asked her, do you know why Giordano Bruno was burnt at the stake?"}, {"time": 3274, "text": "And she said, no, I think it's because he was an obnoxious guy and irritated a lot of people, which is true."}, {"time": 3282, "text": "But the professor said, no, it's because Giordano Bruno said that other stars are just like the sun, and they could have a planet like the Earth around them that could host life."}, {"time": 3296, "text": "And that was offensive to the church."}, {"time": 3303, "text": "Why was it offensive?"}, {"time": 3303, "text": "Because there is the possibility that this life sinned."}, {"time": 3309, "text": "And if that life sinned on planets around other stars, it should have been saved by Christ."}, {"time": 3318, "text": "And then you need multiple copies of Christ."}, {"time": 3318, "text": "And that's unacceptable."}, {"time": 3318, "text": "How can you have duplicates of Christ?"}, {"time": 3325, "text": "And so they burned the guy."}, {"time": 3325, "text": "I'm just like loading this all in because that's kind of brilliant."}, {"time": 3334, "text": "So he was actually already, it's not just about the stars, it's anticipating that there could be other life forms."}, {"time": 3339, "text": "Like why, if this star, if there's other stars, why would it be special?"}, {"time": 3346, "text": "Why would our star be special?"}, {"time": 3346, "text": "He was making the right argument."}, {"time": 3346, "text": "And he would just follow that all along to say like, there should be other Earth like places, there should be other life forms."}, {"time": 3356, "text": "And then there needs to be copies of Christ."}, {"time": 3356, "text": "Yeah, so that was offensive."}, {"time": 3356, "text": "So I said to that professor, I said, great, I wanted to introduce some scientific tone to the discussion."}, {"time": 3362, "text": "And I said, this is great because now you basically laid the foundation for an experimental test of this theology."}, {"time": 3373, "text": "What is the test?"}, {"time": 3373, "text": "We now know that other stars are like the sun and we know they have planets like the Earth around them."}, {"time": 3380, "text": "So suppose we find life there and we figure out that they sinned, then we ask them, did you witness Christ?"}, {"time": 3386, "text": "And if they say no, it means that this theology is ruled out."}, {"time": 3393, "text": "So there is an experimental test."}, {"time": 3393, "text": "So this is experimental test number one."}, {"time": 3398, "text": "Another experimental test, in the Bible, in the Old Testament, Abraham was heard the voice, the voice of God to sacrifice his son, right?"}, {"time": 3406, "text": "Only son."}, {"time": 3406, "text": "And that's what the story says."}, {"time": 3416, "text": "Now, suppose Abraham, my name, by the way, had a voice memo up on his cell phone."}, {"time": 3416, "text": "He could have pressed this up and recorded the voice of God."}, {"time": 3424, "text": "And that would have been experimental evidence that God exists, right?"}, {"time": 3430, "text": "Fortunately, he didn't, but it's an experimental test, right?"}, {"time": 3438, "text": "There is a third example I should tell, and that is Elie Wiesel attributed this story to Martin Buber, but it's not clear whether it's true or not."}, {"time": 3444, "text": "At any event, the story goes that Martin Buber, you know, he was a philosopher and he said, you know, the Christians, you know, the Messiah arrived already and will come back again in the future."}, {"time": 3456, "text": "The Jews argue the Messiah never came and will arrive in the future."}, {"time": 3464, "text": "So he said, why argue?"}, {"time": 3464, "text": "Both sides agree that the Messiah will arrive in the future."}, {"time": 3474, "text": "When the Messiah arrives, we can ask whether he or she will arrive in the future."}, {"time": 3481, "text": "When the Messiah arrives, we can ask whether he or she came before, you know, like visited us and then figure it out."}, {"time": 3489, "text": "And one side."}, {"time": 3489, "text": "So again, experimental test of a theology."}, {"time": 3489, "text": "So even theology, if it puts a skin in the game, you know, if it makes a prediction, could be tested, right?"}, {"time": 3502, "text": "So why can't string theories test themselves?"}, {"time": 3502, "text": "Or why can't, you know, even cosmic inflation?"}, {"time": 3502, "text": "That's a model that, you know, one of the inventors from MIT, Alan Guth, argues that it's not falsifiable."}, {"time": 3515, "text": "My point is a theory that cannot be falsified is not helpful because it means that you can't make progress."}, {"time": 3521, "text": "You cannot improve your understanding of nature."}, {"time": 3521, "text": "The only way for us to learn about nature is by making hypotheses that are testable, doing the experiments and learning whether we are correct or not."}, {"time": 3533, "text": "So B, and coupled that with a curiosity and open mindedness that allows us to explore all kinds of possible hypotheses, but always the pursuit of those, the scientific rigor around those hypotheses is ultimately get evidence."}, {"time": 3546, "text": "Knowledge of what nature is should be a dialogue with nature."}, {"time": 3555, "text": "Rather than a monologue."}, {"time": 3555, "text": "Monologue, beautifully put."}, {"time": 3560, "text": "Can we talk a little bit about the Drake equation?"}, {"time": 3560, "text": "Another framework from which to have this kind of discussion about possible civilizations out there."}, {"time": 3565, "text": "So let me ask, within the context of the Drake equation or maybe bigger, how many alien civilizations do you think are out there?"}, {"time": 3577, "text": "Well, it's hard to tell because the Drake equation is again quantifying our ignorance."}, {"time": 3577, "text": "It's just a set of factors."}, {"time": 3582, "text": "The only one that we know, or actually two that we know quite well is the rate of star formation in the Milky Way galaxy, which we measured by now, and the frequency of planets like the Earth around stars and at the right distance to have life."}, {"time": 3596, "text": "But other than that, there are lots of implicit assumptions about all the other factors that will enable us to detect the signal."}, {"time": 3608, "text": "Now, I should say the Drake equation has a very limited validity just for signals from civilizations that are transmitting at the time that you're observing them."}, {"time": 3615, "text": "However, we can do much better than that."}, {"time": 3622, "text": "We can look for artifacts that they left behind."}, {"time": 3622, "text": "Even if they are dead, you can look for industrial pollution in the atmosphere of planets."}, {"time": 3629, "text": "Why do I bring this up?"}, {"time": 3635, "text": "Again, to show you the conservatism of the mainstream in astronomy."}, {"time": 3640, "text": "And by the way, I have leadership positions."}, {"time": 3640, "text": "I was chair of the astronomy department for nine years, the longest serving chair at Harvard."}, {"time": 3645, "text": "And I'm the chair of the board on physics and astronomy of the National Academies."}, {"time": 3651, "text": "It's a primary board."}, {"time": 3651, "text": "And I'm director of two centers at Harvard and so forth."}, {"time": 3659, "text": "So I do represent the community in various ways."}, {"time": 3659, "text": "But at the same time, I'm a little bit disappointed by the conservatism that people have."}, {"time": 3666, "text": "And so let me give you an illustration of that."}, {"time": 3671, "text": "So the astronomy community actually is going right now through the process of defining its goals for the next decade."}, {"time": 3678, "text": "And there are proposals for telescopes that would cost billions of dollars and whose goal is to find evidence for oxygen in the atmosphere of planets around other stars, with the idea that this would be a marker, a signature of life."}, {"time": 3693, "text": "Now, the problem with that is Earth didn't have much oxygen in its atmosphere for the first two billion years."}, {"time": 3700, "text": "Roughly half of its life, it didn't have much oxygen."}, {"time": 3707, "text": "But it had life."}, {"time": 3707, "text": "It had microbial life."}, {"time": 3707, "text": "It's not it's not clear yet as of yet what the origin is for the rise in the oxygen level after two billion years, about 2.4 billion years ago."}, {"time": 3721, "text": "But we know that a planet can have life without oxygen in the atmosphere because Earth did it."}, {"time": 3730, "text": "The second problem with this approach is that you can have oxygen from natural processes."}, {"time": 3736, "text": "You can break water molecules and make oxygen."}, {"time": 3736, "text": "So even if you find it, it will never tell you that for sure life exists there."}, {"time": 3743, "text": "And so even with these billions of dollars, the mainstream community will never be confident whether there is life."}, {"time": 3750, "text": "Now, how can it be confident?"}, {"time": 3757, "text": "There is actually a way."}, {"time": 3757, "text": "If instead of looking with the same instruments, if you look for molecules that indicate industrial pollution, for example, CFCs that are produced by refrigerating systems or industries here on Earth, that they do the ozone layer, you can search for that."}, {"time": 3770, "text": "And I wrote a paper five years ago suggesting that."}, {"time": 3775, "text": "Now, what's the problem?"}, {"time": 3775, "text": "You can just tell NASA, I want to build this telescope to search for oxygen, but also for industrial pollution."}, {"time": 3788, "text": "Nobody would say that because it sounds like on the periphery of the field."}, {"time": 3788, "text": "And I ask you, why would?"}, {"time": 3796, "text": "Hilarious."}, {"time": 3796, "text": "Because that's exactly, I mean, that would be saying is quite brilliant."}, {"time": 3796, "text": "I mean, because it's a really strong signal."}, {"time": 3802, "text": "And if life, if there's alien civilizations out there, then they're probably going to be many of them."}, {"time": 3809, "text": "And they're probably going to be more advanced than us."}, {"time": 3814, "text": "And they're probably going to have something like industrial pollution, which would be a much stronger signal than some basic gas, which could have a lot of different explanations."}, {"time": 3824, "text": "So like something like oxygen or, I mean, we could talk about signs of life on Venus and so on."}, {"time": 3832, "text": "But if you want a strong signal, it would be pollution."}, {"time": 3832, "text": "I love how garbage is."}, {"time": 3838, "text": "No, but the pollution, you have to understand, we think of pollution as a problem, but on a planet that was too cold, for example, to have a comfortable life on it, you can imagine terraforming it and putting a blanket of polluting gases such that it will be warmer."}, {"time": 3849, "text": "And that would be a positive change."}, {"time": 3856, "text": "So if an industrial or a technological civilization wants to terraform a planet that otherwise is too cold for them, they will do it."}, {"time": 3865, "text": "So what's the problem of defining it as a search goal using the same technologies?"}, {"time": 3871, "text": "The problem is that there is a taboo."}, {"time": 3871, "text": "We're not supposed to discuss extraterrestrial intelligence."}, {"time": 3879, "text": "There is no funding for this subject, not much, very little."}, {"time": 3885, "text": "And young people, because of the bullying on Twitter, you know, all the social media and elsewhere, young people with talent that are curious about these questions do not enter this field of study."}, {"time": 3898, "text": "And obviously, if you step on the grass, it will never grow, right?"}, {"time": 3898, "text": "So if you don't give funding, obviously, you know, the mainstream community says, look, nothing was discovered so far."}, {"time": 3910, "text": "Obviously, nothing would be discovered."}, {"time": 3910, "text": "If talented people go to other districts, you never search for it well enough, you will never find anything."}, {"time": 3915, "text": "I mean, look at gravitational wave astrophysics."}, {"time": 3921, "text": "It's a completely new window into the universe, pioneered by Ray Weiss at MIT."}, {"time": 3926, "text": "And at first, it was ridiculed."}, {"time": 3926, "text": "And thanks to some administrators at the National Science Foundation, it received funding, despite the fact that the mainstream of the astronomy community was very resistant to it."}, {"time": 3939, "text": "And now it's considered a frontier."}, {"time": 3939, "text": "So all these people that I remember as a young postdoc, these people that bashed this field and said bad things about people, you know, said nothing will come out of it."}, {"time": 3951, "text": "Now they say, oh, yeah, of course, you know, the Nobel Prize was given to the LIGO collaboration."}, {"time": 3957, "text": "Of course, now they are supportive of it."}, {"time": 3966, "text": "But my point is, if you suppress innovation early on, there are lots of missed opportunities."}, {"time": 3975, "text": "The discovery of exoplanets is one example."}, {"time": 3975, "text": "You know, in 1952, there was an astronomer called the name Otto Struve."}, {"time": 3981, "text": "And he wrote a paper saying, why don't we search for Jupiter like planets close to their host star?"}, {"time": 3991, "text": "Because if they're close enough, they would move the star back and forth, and we can detect the signal."}, {"time": 3996, "text": "And so astronomers on time allocation committees of telescopes for 40 years argued, this is not possible because we know why Jupiter resides so far from the Sun."}, {"time": 4013, "text": "You cannot have Jupiter so close because there is this region where ice forms far from the Sun."}, {"time": 4019, "text": "And beyond that region is where Jupiter like planets can form."}, {"time": 4019, "text": "There was a theory behind it which ended up being wrong by today's standards."}, {"time": 4023, "text": "But anyway, they did not give time on telescopes to search for such systems until the first system was discovered four decades after Otto Struve's paper."}, {"time": 4034, "text": "And the Nobel Prize was awarded to that just a couple of years ago."}, {"time": 4040, "text": "And then you ask yourself, okay, so science still made progress."}, {"time": 4046, "text": "The problem is that this baby came out barely, and there was a delay of four decades."}, {"time": 4053, "text": "So the progress was delayed."}, {"time": 4053, "text": "And I wonder how many babies were not born because of this resistance."}, {"time": 4059, "text": "So there must be ideas that are as good as this one that were suppressed because they were bullied, because people ridiculed them, that were actually good ideas."}, {"time": 4064, "text": "And these are missed opportunities, babies that were never born."}, {"time": 4071, "text": "And I'm willing to push this frontier of the search for technologies or technological signatures of other civilizations."}, {"time": 4078, "text": "Because when I was young, I was in the military in Israel."}, {"time": 4084, "text": "It's obligatory to serve."}, {"time": 4084, "text": "And there was this saying that one of the soldiers sometimes has to put his body on the barbed wire so that others can go through."}, {"time": 4098, "text": "And I'm willing to suffer the pain so that younger people in the future will be able to speak freely about the possibility that some of the anomalies we find in the sky are due to technological signatures."}, {"time": 4110, "text": "And it's quite obvious."}, {"time": 4110, "text": "This is why I like the folks in artificial intelligence space, Elon Musk and a few others speak about this."}, {"time": 4115, "text": "And they look at the long arc."}, {"time": 4115, "text": "They say like, what, you know, this kind of, you know, you can call it like first principles thinking, or you can call it anything really is like, if we just zoom out from our current bickering and our current, like discussions in the what science is doing, look at the long arc of the trajectory we're headed at."}, {"time": 4139, "text": "Which questions are obviously fundamental to science?"}, {"time": 4139, "text": "And it should be asked, and which is the space of hypothesis we should be exploring?"}, {"time": 4147, "text": "And like exoplanets is a really good example of one that was like an obvious one."}, {"time": 4152, "text": "I recently talked to Sarah Seager, and it was very taboo when she was starting out to work on an exoplanet."}, {"time": 4158, "text": "And that was even in the 90s."}, {"time": 4158, "text": "And like it's obvious should not be a taboo subject."}, {"time": 4164, "text": "And to me, I mean, I'm probably ignorant, but to me, exoplanets seems like it's ridiculous that that would ever be a taboo subject to not fund, to not explore."}, {"time": 4176, "text": "That's very, but even for her, it's now taboo to say, like what, you know, to look for industrial pollution, right?"}, {"time": 4186, "text": "And I find that ridiculous."}, {"time": 4186, "text": "I'll tell you why."}, {"time": 4186, "text": "She can't take the next step."}, {"time": 4191, "text": "It's ridiculous for another reason."}, {"time": 4191, "text": "Not because of just the scientific benefits that we might have by exploring it, but because the public cares about these questions."}, {"time": 4196, "text": "And the public funds science."}, {"time": 4203, "text": "So how dare the scientists shy away from addressing these questions, if they have the technology to do it."}, {"time": 4209, "text": "It's like saying, I don't want to look through Galileo's telescope."}, {"time": 4214, "text": "It's exactly the same."}, {"time": 4214, "text": "You have the technology to explore this question, to find the evidence and you shy away from it."}, {"time": 4219, "text": "You might ask, why do people shy away from it?"}, {"time": 4225, "text": "And perhaps it's because of the fact that there is science fiction."}, {"time": 4225, "text": "I'm not a fan of science fiction, because it has an element to it that violates the laws of physics in many of the books and the films."}, {"time": 4236, "text": "And I cannot enjoy these things when I see the laws of physics violated."}, {"time": 4236, "text": "But who cares that the, you know, the fact that there is science fiction."}, {"time": 4243, "text": "I mean, if you have the scientific methodology to address the same subject, I don't care that other people, you know, spoke nonsense about this subject or said things that make no sense."}, {"time": 4253, "text": "You do your scientific work, just like you explore the dark matter."}, {"time": 4259, "text": "You explore the possibility that umuamua is an artifact."}, {"time": 4265, "text": "You just look for evidence and try to deduce what it means."}, {"time": 4265, "text": "And I have no problem with doing that."}, {"time": 4273, "text": "To me, it sounds like any other scientific question that we have."}, {"time": 4273, "text": "And given the public's interest, we have an obligation to do that."}, {"time": 4278, "text": "By the way, science to me is not an occupation of the elite."}, {"time": 4284, "text": "It doesn't allow me to feel superior to other humans that are unable to understand the math."}, {"time": 4289, "text": "To me, it's a way of life."}, {"time": 4289, "text": "You know, if there is a problem in the faucet or in the pipe at home, I try to figure out what the problem is."}, {"time": 4295, "text": "And with a plumber, we figure it out and we look at the clues."}, {"time": 4301, "text": "And the same thing in science."}, {"time": 4301, "text": "You look at the evidence, you try to figure out what it means."}, {"time": 4307, "text": "It's common sense in a way."}, {"time": 4307, "text": "And it shouldn't be regarded as something removed from the public."}, {"time": 4314, "text": "It should be a reflection of the public's interest."}, {"time": 4314, "text": "And I think it's actually a crime to resist the public."}, {"time": 4319, "text": "If the public says, I care about this, and you say, no, no, no, that's not sophisticated enough for me."}, {"time": 4325, "text": "I want to do intellectual gymnastics on anti the sitter space."}, {"time": 4329, "text": "To me, that's a crime."}, {"time": 4329, "text": "Yes, I 100% agree."}, {"time": 4329, "text": "So it's hilarious that the very, not hilarious, it's sad, that people who are trained in the scientific community to have the tools to explore this world, to be children, to be the most effective at being children, are the ones that resist being children the most."}, {"time": 4351, "text": "But there is a large number of people that embrace the childlike wonder about the world and may not necessarily have the tools to do it."}, {"time": 4364, "text": "That's the more general public."}, {"time": 4364, "text": "And so, I wonder if I could ask you and talk to you a little bit about UFO sightings."}, {"time": 4371, "text": "That there's people, quote unquote believers, there's hundreds of thousands of UFO sightings."}, {"time": 4380, "text": "And I've consumed some of the things that people have said about it."}, {"time": 4380, "text": "And one thing I really like about it is how excited they are by the possibility."}, {"time": 4392, "text": "It's almost like this childlike wonder about the world out there."}, {"time": 4401, "text": "It's not a fear, it's an excitement."}, {"time": 4401, "text": "Do you think, because we're talking about this possibly extraterrestrial object that visited, that flew by Earth, do you think it's possible that out of those hundreds of thousands of UFO sightings, one is an actual, one or some number is an actual sighting of a nonhuman, some alien technology."}, {"time": 4432, "text": "And that we're not, we did not, we're too close minded to look and to see."}, {"time": 4444, "text": "I think to answer this question, we need better evidence."}, {"time": 4444, "text": "My starting point, as I said, out of modesty is that we are not particularly interesting."}, {"time": 4451, "text": "And therefore I would be hard pressed to imagine that someone wants to really spy on us."}, {"time": 4457, "text": "So I would think, as a starting point, that we don't deserve attention and we shouldn't expect someone, but who knows."}, {"time": 4470, "text": "Now, the problem that I have with UFO sighting reports is that 50 years ago, there were some reports of fuzzy images, saucer like things."}, {"time": 4477, "text": "By now, our technologies are much better."}, {"time": 4477, "text": "Our cameras are much more sensitive."}, {"time": 4485, "text": "These fuzzy images should have turned into crisp, clear images of things that we are confident about."}, {"time": 4492, "text": "And they haven't turned that way."}, {"time": 4492, "text": "It's always on the border line of believability."}, {"time": 4498, "text": "And because of that, I believe that it might be most likely artifacts of our instruments or some natural phenomena that we are unable to understand."}, {"time": 4504, "text": "Now, of course, the reason you must examine those, if, for example, pilots report about them or the military finds evidence for them, is because it may pose a national security threat."}, {"time": 4517, "text": "If another country has technologies that we don't know about and they're spying on us, we need to know about it."}, {"time": 4528, "text": "And therefore we should examine everything that looks unusual."}, {"time": 4528, "text": "But to associate it with an alien life is a little too far for me until we have evidence that stands up to the level of scientific credence, that we are 100% sure that from multiple detectors and through a scientific process."}, {"time": 4553, "text": "Now, again, if the scientific community shies away from these reports, we will never have that."}, {"time": 4558, "text": "It's like saying, I don't want to take photographs of something because I know what it is, then you will never know what it is."}, {"time": 4564, "text": "But I think if some scientist, if grants, let's put it this way, if funding will be given to scientists to follow on some of these reports and use scientific instruments that are capable of detecting those sightings with much better resolution, with much better information, that would be great because it will clarify the matter."}, {"time": 4584, "text": "These are not, as you said, hundreds of thousands, these are not once in a lifetime events."}, {"time": 4589, "text": "So it's possible to take scientific instrumentation and explore, go to the ocean where someone reported that there are frequent events that are unusual and check it out, do a scientific experiment."}, {"time": 4602, "text": "Why only do experiments deep into the ocean and look at the oceanography or do other things."}, {"time": 4610, "text": "We can do scientific investigation of these sightings and figure out what they mean."}, {"time": 4617, "text": "I'm very much in favor of that, but until we have the evidence, I would be doubtful as to what they actually mean."}, {"time": 4629, "text": "Yeah, we'll have to be humble and acknowledge that we're not that interesting."}, {"time": 4669, "text": "This is exactly what you're talking about."}, {"time": 4669, "text": "It's like the scientific community is afraid of a topic that inspires millions of people."}, {"time": 4675, "text": "But if you put blinders on your eyes, you don't see it."}, {"time": 4681, "text": "I should say that we do have meteors that we see."}, {"time": 4681, "text": "These are rocks that by chance happen to collide with the earth and they, if they're small, they burn up in the atmosphere."}, {"time": 4694, "text": "But if they're big enough, tens of meters or more, hundreds of meters, the outer layer burns up, but then the core of the object makes it through."}, {"time": 4701, "text": "And this is our chance of putting our hands around an object if this meteor came from interstellar space."}, {"time": 4709, "text": "So one path of discovery is to search for interstellar meteors."}, {"time": 4717, "text": "And with a student of mine, we actually looked through the record and we thought that we found one example of a meteor that was reported that might have come from interstellar space."}, {"time": 4730, "text": "And then another approach is, for example, to look at the moon."}, {"time": 4730, "text": "The moon is different from the earth in the sense that it doesn't have an atmosphere."}, {"time": 4737, "text": "So objects do not burn up on their way to it."}, {"time": 4742, "text": "It's sort of like a museum."}, {"time": 4742, "text": "It collects everything."}, {"time": 4742, "text": "Of rocks from out there in deep space."}, {"time": 4747, "text": "And there is no geological activity on the moon."}, {"time": 4747, "text": "So on earth, every hundred million years, you know, we could have had computer terminals on earth that could have been a civilization like ours with electronic equipment."}, {"time": 4757, "text": "More than a hundred million years ago."}, {"time": 4763, "text": "And it's completely lost."}, {"time": 4763, "text": "You cannot excavate and find it, evidence for it, because in archaeological digs, because the earth is being mixed on these timescales."}, {"time": 4769, "text": "And everything that was on the surface more than a hundred million years ago is buried deep inside the earth right now because of geological activity."}, {"time": 4779, "text": "Fascinating to think about, by the way."}, {"time": 4779, "text": "But on the moon, this doesn't happen."}, {"time": 4784, "text": "The only thing that happens on the moon is you have objects impacting the moon and they go 10 meters deep."}, {"time": 4789, "text": "So they produce some dust, but the moon keeps everything."}, {"time": 4789, "text": "It's like a museum."}, {"time": 4795, "text": "It keeps everything on the surface."}, {"time": 4795, "text": "So if we go to the moon, I would highly recommend regarding it as an archaeological site."}, {"time": 4801, "text": "And looking for objects that are strange."}, {"time": 4801, "text": "Maybe it collected some trash, you know, from interstellar space."}, {"time": 4807, "text": "If we could just linger on the Drake equation for a little bit."}, {"time": 4813, "text": "We kind of talked about there's a lot of uncertainty in the parameters and the Drake equation itself is very limited."}, {"time": 4818, "text": "But I think the parameters are interesting in themselves, even if it's limited, because I think each one is within the reach of science, right?"}, {"time": 4831, "text": "Did you get the evidence for it?"}, {"time": 4831, "text": "I mean, a few I find really interesting, could be interesting to get your comment on."}, {"time": 4836, "text": "So the one with the most variance, I would say, from my perspective, is the length that civilizations last."}, {"time": 4843, "text": "However you define it."}, {"time": 4843, "text": "In the Drake equation, it's the length of how long you're communicating."}, {"time": 4848, "text": "Yeah, transmitting."}, {"time": 4852, "text": "Transmitting."}, {"time": 4852, "text": "Just like you said, that's a wrong way to think about it, because we can be detecting some other outputs of the civilizations, etc."}, {"time": 4859, "text": "But if we just define broadly how long those civilizations last, do you have a sense of how long they might last?"}, {"time": 4864, "text": "Like what are the great filters that might destroy civilizations that we should be thinking about?"}, {"time": 4872, "text": "And how can science give us more hints on this topic?"}, {"time": 4879, "text": "So I, as I mentioned before, operate by the Copernican principle, meaning that we are not special."}, {"time": 4885, "text": "We don't live in a special place and not in a special time."}, {"time": 4891, "text": "And by the way, it's just modesty encapsulated in scientific terms, right?"}, {"time": 4898, "text": "You're saying, I'm not special, you know, I find conditions here, they exist everywhere."}, {"time": 4903, "text": "So if you adopt the Copernican principle, you basically say, our civilization transmitted radio signals for a hundred years, roughly, so probably it would last another hundred or a few hundred and that's it."}, {"time": 4917, "text": "Because we don't live at a special time."}, {"time": 4922, "text": "So that's, you know, well, of course, if we get our act together and we somehow start to cooperate rather than fighting each other, killing each other, you know, wasting a lot of resources on things that would destroy our planet, maybe we can lengthen that period if we get smarter."}, {"time": 4943, "text": "But the most natural assumption is to say that we will live into the future as much as we lived from the time that we start to develop the means for our own destruction, the technologies we have, which is quite pessimistic, I must say."}, {"time": 4955, "text": "So several centuries, that's what I would give, unless we get our act, unless we become more intelligent than the newspapers report every day."}, {"time": 4965, "text": "Point number one."}, {"time": 4965, "text": "Second, and by the way, this is relevant, I should say, because there was a report about perhaps a radio signal detected from Proxima Centauri."}, {"time": 4978, "text": "What do you make of that signal?"}, {"time": 4978, "text": "Oh, I think it's some Australian guy with a cell phone next to the observatory or something like that, because it was the Parkes Telescope in Australia."}, {"time": 4989, "text": "So it's human created noise."}, {"time": 4989, "text": "Which is always the worry because actually the same observatory, the Parkes Observatory, detected a couple of years ago some signal and then they realized that it comes back at lunchtime."}, {"time": 5002, "text": "And they said, okay, what could it be?"}, {"time": 5009, "text": "And then they figured out that it must be the microwave oven in the observatory because someone was opening it before it finished and it was creating this radio signal that they detected with a telescope every lunchtime."}, {"time": 5020, "text": "So just a cautionary remark."}, {"time": 5020, "text": "But the reason I think it's human made, without getting to the technical details, is because of this very short window by which we were transmitting radio signals out of the lifetime of the Earth."}, {"time": 5034, "text": "As I said, 100 years out of four and a half billion years that the Earth existed."}, {"time": 5038, "text": "So what's the chance that another civilization, a twin civilization of ours, is transmitting radio signals exactly at the time that we are looking with our radio telescopes?"}, {"time": 5050, "text": "10 to the minus 7."}, {"time": 5050, "text": "And the other argument I have is that they detected it in a very narrow band of frequencies and that makes it cannot be through natural processes, very narrow band, just like some radio transmissions that we produce."}, {"time": 5074, "text": "But if it were to come from the habitable zone, from a transmitter on the surface of Proxima b, this is the planet that orbits Proxima Centauri, then I calculated that the frequency would drift through the Doppler effect."}, {"time": 5088, "text": "Just like when you hear a siren on the street, when the car approaches you, it has a different pitch than when it recedes away from you, that's the Doppler effect."}, {"time": 5102, "text": "And when the planet orbits the star, Proxima Centauri, you would see or detect a different frequency when the planet approaches us as compared to when it recedes."}, {"time": 5110, "text": "So there should be a frequency drift just because of the motion of the planet."}, {"time": 5114, "text": "And I calculated that it must be much bigger than observed."}, {"time": 5122, "text": "So it cannot just be a transmitter sitting on the planet and sending in our direction a radio signal unless they want to cancel the Doppler effect."}, {"time": 5129, "text": "But then they need to know about us because in a different direction, it will not be cancelled."}, {"time": 5136, "text": "Only in our direction, they can cancel it perfectly."}, {"time": 5140, "text": "So there is this direction of Proxima Centauri, but I have a problem imagining a transmitter on the surface of a planet in the habitable zone emitting it."}, {"time": 5153, "text": "But my main issue is really with the likelihood, given what we know about ourselves."}, {"time": 5161, "text": "In terms of the duration of the civilization."}, {"time": 5163, "text": "The Copernican principle."}, {"time": 5166, "text": "So nevertheless, this particular signal is likely to be a human interference, perhaps."}, {"time": 5166, "text": "But do you find Proxima be interesting?"}, {"time": 5172, "text": "Or the more general question is, do you think we humans will venture out into outside our solar system and potentially colonize other habitable planets?"}, {"time": 5190, "text": "Actually, I am involved in a project whose goal is to develop the technology that would allow us to leave the solar system and visit the nearest stars."}, {"time": 5195, "text": "And that is called the Star Shot."}, {"time": 5195, "text": "In 2015, May 2015, an entrepreneur from Silicon Valley, Yuri Milner, came to my office at Harvard and said, would you be interested in leading a project that would do that in our lifetime?"}, {"time": 5211, "text": "Because as we discussed before, to traverse those distances with existing rockets would take tens of thousands of years."}, {"time": 5225, "text": "And that's too long."}, {"time": 5225, "text": "For example, to get to Proxima Centauri with the kind of spacecrafts that we already sent, like New Horizons or Voyager 1, Voyager 2, you needed to send them when the first humans left Africa, so that they would arrive there now."}, {"time": 5242, "text": "And that's a long time to wait."}, {"time": 5249, "text": "So Yuri wanted to do it within a lifetime, 10, 20 years, meaning it has to move at a fraction of the speed of light."}, {"time": 5256, "text": "So can we send a spacecraft that would be moving at the fraction of the speed of light?"}, {"time": 5262, "text": "And I said, let me look into that for six months."}, {"time": 5262, "text": "And with my students and postdocs, we arrived to the conclusion that the only technology that can do that is the light sail technology, where you basically produce a very powerful laser beam on Earth."}, {"time": 5272, "text": "So you can collect sunlight with photovoltaic cells or whatever and then convert it into stored energy and then produce a very powerful laser beam that is 100 gigawatts and focus it on a sail in space that is roughly the size of a person, a couple of meters or a few meters, that weighs only a gram or a few grams, very thin."}, {"time": 5310, "text": "And through the math, you can show that you can propel such a sail, if you shine on it for a few minutes, it will traverse the distance that is five times the distance to the moon, and it will get to a fifth of the speed of light."}, {"time": 5323, "text": "Sounds crazy."}, {"time": 5323, "text": "But I've talked to a bunch of people and they're like, I know it sounds crazy, but it's actually, it will work."}, {"time": 5334, "text": "This is one of those, it's beautiful."}, {"time": 5334, "text": "I mean, this is science."}, {"time": 5339, "text": "And the point is, people didn't get excited about space since the Apollo era."}, {"time": 5339, "text": "And it's about time, you know, for us to go into space."}, {"time": 5348, "text": "A couple of months ago, I was asked to participate in a debate organized by IBM and Bloomberg News."}, {"time": 5355, "text": "And the discussion centered on the question, is the space race between the US and China good for humanity?"}, {"time": 5362, "text": "And all the other debaters were worried about the military threats."}, {"time": 5368, "text": "And I just couldn't understand what they're talking about, because military threats come from hovering above the surface of the Earth, right?"}, {"time": 5381, "text": "And we live on a two dimensional surface, we live on the surface of the Earth."}, {"time": 5381, "text": "But space is all about the third dimension, getting far from Earth."}, {"time": 5387, "text": "So if you go to Mars, or you go to a star, another star, there is no military threat."}, {"time": 5392, "text": "Space is all about, you know, feeling that, you know, we are one civilization, in fact, not fighting each other, just going far, and having aspirations for something that goes beyond military threats."}, {"time": 5410, "text": "So why would we be worried that the space race will lead?"}, {"time": 5414, "text": "That's actually brilliant."}, {"time": 5414, "text": "I didn't, you know, there's something in our discourse about it, the space race is sometimes made synonymous with like the Cold War or something like that."}, {"time": 5424, "text": "Or with wars."}, {"time": 5424, "text": "But really, yeah, there was a lot of ego tied up in that."}, {"time": 5424, "text": "I remember, I mean, it's still to this day, there's a lot of pride that Russians, Soviet Union was the first to space."}, {"time": 5432, "text": "And there's a lot of pride in the American side that was the first on the moon."}, {"time": 5436, "text": "But yeah, you're exactly right."}, {"time": 5436, "text": "Like, there's no aggression, there's no wars."}, {"time": 5442, "text": "And beyond that, if you think about the global economy, right now, there is a commercial interest."}, {"time": 5447, "text": "That's why Jeff Bezos and Elon Musk are interested about, you know, Mars and so on."}, {"time": 5452, "text": "There is a commercial interest, which is international."}, {"time": 5452, "text": "It's driven by money, not by pride."}, {"time": 5457, "text": "And, you know, nations can sign treaties."}, {"time": 5457, "text": "First of all, there are lots of treaties that were signed even before the First World War and the Second World War and the World War took place."}, {"time": 5468, "text": "So who cares, you know, like humans, treaties do not safeguard anything, you know."}, {"time": 5475, "text": "But beyond that, even if nations sign treaties about space exploration, you might still find commercial entities that will find a way to get their launches."}, {"time": 5481, "text": "And, you know, so I think we should rethink space."}, {"time": 5487, "text": "It has nothing to do with national pride."}, {"time": 5487, "text": "Once again, nothing to do with our egos."}, {"time": 5493, "text": "It's about exploration."}, {"time": 5493, "text": "And the biggest problem, I think, in human history is that humans tend to think about egos and about their own personal image rather than, look at the big picture, you know."}, {"time": 5513, "text": "We will not be around for long."}, {"time": 5513, "text": "We are just occupying a small space right now."}, {"time": 5518, "text": "Now, let's move out of this, you know, the way that Oscar Wilde said, I think is the best."}, {"time": 5518, "text": "He said, all of us are in the gutters, but some of us are looking at the stars."}, {"time": 5531, "text": "Yeah, and the more of us are looking at the stars, the likelier we are to, for this thing, this little experiment we have going on to last a while as opposed to end too quickly."}, {"time": 5538, "text": "I mean, it's not just about science of being humble."}, {"time": 5545, "text": "It's about the survival of the human species as being humble."}, {"time": 5549, "text": "To me, it's incredibly inspiring, the Starshot project of, I mean, there's something magical about being able to go to another habitable planet and take a picture even."}, {"time": 5561, "text": "I mean, within our lifetime, I mean, that, with crazy technology too, which is..."}, {"time": 5569, "text": "I should tell you how it was conceived."}, {"time": 5569, "text": "So, I was at the time, so after six months passed, after the visit of Yuri Miller, I was, usually I go in December during the winter break, I go to Israel."}, {"time": 5582, "text": "I used to go to see my family and I get a phone call just before the weekend started."}, {"time": 5591, "text": "I get a phone call, Yuri would like you to present your concept in two weeks at his home."}, {"time": 5599, "text": "And I said, well, thank you for letting me know because I'm actually out of the door of the hotel to go to a goat farm in the Negev, in the southern part of Israel, because my wife wanted to have to go to a place that is removed from civilization, so to speak."}, {"time": 5619, "text": "So, we went to that goat farm and I need to make the presentation and there was no internet connectivity except in the office of the goat farm."}, {"time": 5627, "text": "So, the following morning at 6am, I sit with my back to the office of that goat farm, looking at goats that were newly born and typing into my laptop, the presentation, the PowerPoint presentation about our ambitions for visiting the nearest star."}, {"time": 5646, "text": "And that was very surreal to me."}, {"time": 5646, "text": "Like our origins in many ways, this very primitive origins and our dreams of looking out that is brilliant."}, {"time": 5656, "text": "So that is incredibly inspiring to me, but it's also inspiring of putting humans onto other moons or planets."}, {"time": 5672, "text": "I still find going to the moon really exciting."}, {"time": 5672, "text": "I don't know, maybe I'm just a sucker for it, but it's really exciting."}, {"time": 5678, "text": "And Mars, which is a new place, a new planet, another planet that might have life."}, {"time": 5684, "text": "I mean, there's something magical to that or some traces of previous life."}, {"time": 5689, "text": "You might think that humans cannot really survive and there are risks by going there."}, {"time": 5689, "text": "But my point is, we started from Africa and we got to apartment buildings in Manhattan, right?"}, {"time": 5695, "text": "It's a very different environment from the jungles to live in an apartment building in a small cubicle."}, {"time": 5709, "text": "And it took tens of thousands of years, but humans adapted, right?"}, {"time": 5713, "text": "So why couldn't humans also make the leap and adapt to a habitat in space?"}, {"time": 5720, "text": "Now you can build a platform that would look like an apartment building in the Bronx or somewhere, but have inside of it everything that humans need."}, {"time": 5726, "text": "And just like the space station, but bigger."}, {"time": 5734, "text": "And it will be a platform in space."}, {"time": 5734, "text": "And the advantage of that is if something bad happens on Earth, you have that complex where humans live."}, {"time": 5740, "text": "And you can also move it back and forth depending on how bright the sun gets."}, {"time": 5747, "text": "Because within a billion years, the sun would be too hot and it will boil off all the oceans on Earth."}, {"time": 5756, "text": "So we cannot stay here for more than a billion years."}, {"time": 5761, "text": "So that's a billion years from now."}, {"time": 5761, "text": "I prefer shorter term deadlines."}, {"time": 5767, "text": "And so there's a lot of threats that we're facing currently."}, {"time": 5767, "text": "Do you find it exciting the possibility of landing on Mars and starting little like building a Manhattan style apartment building on Mars and humans occupying it?"}, {"time": 5782, "text": "Do you think from a scientific or an engineering perspective, that's a worthy pursuit?"}, {"time": 5787, "text": "I think it's worthy."}, {"time": 5787, "text": "But the real issue that is often underplayed is the risk to the human body from cosmic rays."}, {"time": 5795, "text": "These are energetic particles and we are protected from them by the magnetic field around the Earth that blocks them."}, {"time": 5803, "text": "But if you go to Mars, where there is no such magnetic field to block them, then, you know, a significant fraction of the brain cells in your head will be damaged within a year."}, {"time": 5817, "text": "And the consequences of that are not clear."}, {"time": 5824, "text": "I mean, it's quite possible that humans cannot really survive on the surface."}, {"time": 5832, "text": "Now, it may mean that we need to dig tunnels, go underground or create some protection."}, {"time": 5839, "text": "This is something that can be engineered."}, {"time": 5839, "text": "And, you know, we can start from the Moon and then move to Mars."}, {"time": 5843, "text": "That would be a natural progression."}, {"time": 5843, "text": "But it's a big issue that needs to be dealt with."}, {"time": 5849, "text": "I don't think, you know, it's a showstopper."}, {"time": 5849, "text": "I think we can overcome it."}, {"time": 5855, "text": "But, you know, just like anything in science and technology, you have to work on it for a while, figure out solutions."}, {"time": 5860, "text": "But it's not as rosy as Elon Musk talks about."}, {"time": 5860, "text": "I mean, Elon Musk can obviously be optimistic."}, {"time": 5867, "text": "I think eventually it will boil down to figuring out how to cope with this risk, the health risk."}, {"time": 5873, "text": "Yeah, I mean, in defense of optimism, I find that there's at least a correlation, if not their best friends, is optimism and open mindedness."}, {"time": 5879, "text": "It's a necessary precondition to try crazy things."}, {"time": 5890, "text": "And in that sense, the sense I have about going to Mars, if we use today's logic of what kind of benefits we'll get from that, we're never going to go."}, {"time": 5908, "text": "And like most decisions we make in life, most decisions we've made as a human species are irrational if you look at just today."}, {"time": 5914, "text": "But if you look at the long arc and the possibilities that it might bring, just like humans, Europe and destroyed everybody."}, {"time": 5931, "text": "But it was a commercial interest that drove that for trade."}, {"time": 5931, "text": "And, you know, it might happen again, in this context, you have people like Jeff Bezos and Elon Musk that are commercially driven to go to space."}, {"time": 5942, "text": "But it doesn't mean that what we will ultimately find is not new worlds that have nothing, you know, have much more to offer than just commercial interest."}, {"time": 5950, "text": "And as a side effect, almost."}, {"time": 5956, "text": "And then that's why I think, you know, we should be open minded and explore."}, {"time": 5962, "text": "And, however, at the same time, because of the reasons you pointed out, I'm not optimistic that we will survive more than a few centuries into the future, because people do not think long term."}, {"time": 5974, "text": "And that means that we will only survive for the short term."}, {"time": 5974, "text": "I don't know if you have thoughts about this, but what are the things that worry you the most about, from the great perspective of the universe, which is the great filters that destroys intelligent civilizations, but for our own species here?"}, {"time": 5989, "text": "Like, what are the things that worry you the most?"}, {"time": 5995, "text": "Yeah, the thing that worries me the most is that people pay attention to how many likes they have on Twitter."}, {"time": 5999, "text": "And rather than, you know, basketball coaches tell the team players, keep your eyes on the ball, not on the audience."}, {"time": 6010, "text": "The problem is we keep our eyes on the audience most of the time."}, {"time": 6017, "text": "Let's keep our eyes on the ball."}, {"time": 6017, "text": "First of all, in the context of science, it means pay attention to the evidence."}, {"time": 6021, "text": "When the evidence looks strange, then we should figure it out."}, {"time": 6026, "text": "You know, I went to a seminar about Umuamua at Harvard, and a colleague of mine that is mainstream, conservative, would never say anything that would deviate from what everyone else is thinking, said to me after the seminar, I wish this object never existed."}, {"time": 6048, "text": "Now, to me, I mean, I just couldn't hear that."}, {"time": 6048, "text": "What do you mean, nature is whatever it is, you have to pay attention to it."}, {"time": 6056, "text": "You cannot say, you know, you cannot bury your head in this."}, {"time": 6056, "text": "I mean, you should bless nature for giving you clues about things that you haven't expected."}, {"time": 6066, "text": "And I think that's the biggest fault that we are looking for confirmations of things we already know, so that we can maintain our pride that we already knew it, and maintain our image, not make mistakes, because we already knew it, therefore we expected the right thing."}, {"time": 6085, "text": "But science is a learning experience, and sometimes you're wrong."}, {"time": 6085, "text": "And let's learn from those mistakes."}, {"time": 6090, "text": "And what's the problem about that?"}, {"time": 6090, "text": "Why do we have to get, you know, prizes, and why do we get to be honored and maintain our image, when the actual objective of science is learning about nature?"}, {"time": 6103, "text": "And like you've talked about, anomalies in this case are actually are not things that are unfortunate and to be ignored are, in fact, gifts and should be the focus of science."}, {"time": 6114, "text": "Exactly, because that's the way for us to improve our understanding."}, {"time": 6114, "text": "If you look at quantum mechanics, nobody dreamed about it."}, {"time": 6119, "text": "And it was revolutionary, and we still don't fully understand it."}, {"time": 6125, "text": "It's a pain for us to figure out."}, {"time": 6127, "text": "So I understand from the perspective that's holding our science back, why do you have a sense that that's also something that might be a problem for us in terms of the survival of human civilization?"}, {"time": 6142, "text": "Because when you look at society, it operates by the same principles."}, {"time": 6142, "text": "People look for affirmation by groups, and they, you know, people segregate into herds that think like them, especially these days when social media is so strong, you can find your support group."}, {"time": 6159, "text": "And if you don't look for evidence for what you're saying, you can say crazy things as long as there are enough people supporting what you say."}, {"time": 6169, "text": "You can even have your newspapers, you can have everything to support your view, and then, you know, bad things will happen to society."}, {"time": 6179, "text": "Because we're detaching ourselves from reality."}, {"time": 6179, "text": "And if we detach ourselves from reality, all the destructive things that naturally can occur in the real world, whether from nuclear weapons, all the kinds of threats that we're facing, even we're living through a pandemic, the supposed, you know, a much, much worse pandemic could happen."}, {"time": 6193, "text": "And then we could sadly, like we did this one, politicize it in some kind of way and have bickering in the space of Twitter and politics, as opposed to there's an actual thing that can destroy the human species."}, {"time": 6212, "text": "So the only way for us to maintain, to stay modest and learn about what really happens is by looking for evidence."}, {"time": 6217, "text": "Again, I'm saying, it's not about ourself, you know, it's about figuring out what's around us."}, {"time": 6224, "text": "And if you close yourself by surrounding yourself with people that are like minded, that refuse to look at the evidence, you can do bad things."}, {"time": 6237, "text": "And throughout human history, that's the origin of all the bad things that happen."}, {"time": 6243, "text": "And I think it's a key."}, {"time": 6243, "text": "It's a key to be modest and to look at evidence."}, {"time": 6243, "text": "And it's not a nuance."}, {"time": 6247, "text": "Now, you might say, Oh, okay, the uneducated person might operate."}, {"time": 6247, "text": "No, it's the scientific community operates this way."}, {"time": 6255, "text": "My problem is not with people that don't have an academic pedigree."}, {"time": 6261, "text": "It's included everywhere in society."}, {"time": 6264, "text": "On the topic of the discovery of evidence of alien civilizations, which is something you touch on in your book, what that idea would do to societies, to the human psyche and in general, do you think, and you talk about the, I still have trouble pronouncing, but a Muamua wager, right?"}, {"time": 6286, "text": "What do you think is, can you explain it?"}, {"time": 6286, "text": "And what do you think in general is the effect that such knowledge might have on human civilization?"}, {"time": 6298, "text": "So Pascal had this wager about God."}, {"time": 6298, "text": "And by the way, there are interesting connections between theology and the search for extraterrestrial life."}, {"time": 6304, "text": "It's possible that we were planted on this planet by another civilization."}, {"time": 6311, "text": "We attribute to God powers that belong really to the technological civilization."}, {"time": 6319, "text": "But putting that aside, Pascal basically said, there are two possibilities, there are two possibilities, either God exists or not."}, {"time": 6326, "text": "And if God exists, the consequences are quite significant."}, {"time": 6334, "text": "And therefore, we should consider that possibility differently than equal weight to both possibilities."}, {"time": 6342, "text": "And I suggest that we do the same with Muamua or other technological signatures, that we keep in mind the consequences and therefore pay more attention to that possibility."}, {"time": 6358, "text": "Now, some people say extraordinary claims require extraordinary evidence."}, {"time": 6365, "text": "My point is that the term extraordinary is really subjective."}, {"time": 6365, "text": "For one person, a black hole is extraordinary."}, {"time": 6374, "text": "For another, it's just a consequence of Einstein's theory of gravity."}, {"time": 6374, "text": "It's nothing extraordinary."}, {"time": 6380, "text": "The same about the type of dark matter, anything."}, {"time": 6380, "text": "So we should leave the extraordinary part of that sentence."}, {"time": 6387, "text": "Just keep evidence, okay?"}, {"time": 6387, "text": "So let's be guided by evidence."}, {"time": 6395, "text": "And even if we have extraordinary claims, let's not dismiss them because the evidence is not extraordinary enough."}, {"time": 6402, "text": "Because if we have an image of something and it looks really strange and we say, oh, the image is not sufficiently sharp, therefore, we should not even pay attention to this image or not even consider."}, {"time": 6411, "text": "I think that's a mistake."}, {"time": 6411, "text": "What we should do is say, look, there is some evidence for something unusual."}, {"time": 6417, "text": "Let's try and build instruments that will give us a better image."}, {"time": 6422, "text": "And if you just dismiss extraordinary claims, because you consider them extraordinary, you avoid discovering things that you haven't expected."}, {"time": 6429, "text": "And so I believe that along the history of astronomy, there are many missed opportunities."}, {"time": 6437, "text": "And I speak about astronomy, but I'm sure in other fields, it's also true."}, {"time": 6441, "text": "I mean, this is my expertise."}, {"time": 6441, "text": "For example, you know, the Astrophysical Journal, which is the main primary publication in astrophysics."}, {"time": 6447, "text": "If you go before the 1980s, there are images that were posted in the Astrophysical Journal of giant arcs, you know, arcs of light surrounding clusters of galaxies."}, {"time": 6461, "text": "And, you know, you can find it in printed versions of the Astrophysical Journal."}, {"time": 6469, "text": "People just ignore it."}, {"time": 6469, "text": "They put the image, they see the arc, they say, who knows what it is and just ignore it."}, {"time": 6474, "text": "And then in the 1980s, the subject of gravitational lensing became popular."}, {"time": 6480, "text": "And the idea is that you can deflect light by the force of gravity."}, {"time": 6480, "text": "And then you can put a source behind the cluster of galaxies, and then you will get these arcs."}, {"time": 6491, "text": "And actually, Einstein predicted it in 1940."}, {"time": 6496, "text": "And, you know, so these things were expected, but people just had them in the images, didn't pay attention."}, {"time": 6503, "text": "So I'm sure there are lost opportunities sometimes."}, {"time": 6508, "text": "Even in existing data, you have things that are unusual and exceptional and are not being addressed."}, {"time": 6516, "text": "Yeah, you actually, I think you have an article, the data is not enough from quite a few years ago, where you talk, you know, we can go back to the 70s and 80s, but we can go also to the Mayan civilization."}, {"time": 6528, "text": "Right, the Mayan civilization basically believed in astrology that you can forecast the outcome of a war based on the position of the planets."}, {"time": 6533, "text": "And they had, you know, astronomers in their culture had the highest social status."}, {"time": 6540, "text": "They were priests, they were elevated."}, {"time": 6548, "text": "And the reason was that they helped politicians decide when to go to war, because they would tell the politicians, you know, the planets would be in this configuration, it's a better chance for you to win the war, go to war."}, {"time": 6558, "text": "And in retrospect, they collected wonderful data, but misinterpreted it, because we now know that the position of Venus or Jupiter or whatever has nothing to do with the outcome of World War I, World War II, you know, has nothing to do."}, {"time": 6573, "text": "And so we can have a prejudice and collect data without actually doing the right thing with it."}, {"time": 6580, "text": "That's such a Pisces thing to say."}, {"time": 6587, "text": "I looked up what your astrological sign is."}, {"time": 6592, "text": "Well, so you mentioned Einstein predicted that black holes don't exist, or just didn't, or thought."}, {"time": 6598, "text": "Don't exist in nature."}, {"time": 6600, "text": "When Einstein came up with his theory of gravity in 1915, November 1915, a few months later, another physicist, Karl Schwarzschild, he was the director of the Potsdam Observatory, but he was a patriot, a German patriot."}, {"time": 6613, "text": "So he went into the First World War fighting for Germany."}, {"time": 6618, "text": "But while he was at the front, he sent a postcard to Einstein saying, you know, a few months after the theory was developed, saying, actually, I found a solution to your equations."}, {"time": 6627, "text": "And that was a black hole solution."}, {"time": 6627, "text": "And then he died a few months later."}, {"time": 6627, "text": "And Einstein was a pacifist, and he survived."}, {"time": 6634, "text": "So the lesson from this story is that if you want to work out the consequences of a theory, you better be a pacifist."}, {"time": 6640, "text": "But the point is that this solution was known shortly after Einstein came up with his theory."}, {"time": 6647, "text": "But in 1939, Einstein wrote a paper in the Annals of Mathematics saying, even though the solution exists, I don't think it's realized in nature."}, {"time": 6660, "text": "And his argument was, if you imagine a star collapsing, stars often spin, and the spin will prevent them from making a black hole, collapsing to a point."}, {"time": 6671, "text": "So, I mean, can you maybe, one of the many things you have worked on, you're an expert in, is black holes."}, {"time": 6680, "text": "Can you first say, what are black holes?"}, {"time": 6680, "text": "And second, how do we know that they exist?"}, {"time": 6686, "text": "So black holes are the ultimate prison."}, {"time": 6686, "text": "You know, you can check in, but you can never check out."}, {"time": 6693, "text": "You can never check out."}, {"time": 6693, "text": "Even light cannot escape from them."}, {"time": 6693, "text": "So there are extreme structures of space and time."}, {"time": 6700, "text": "And there is this so called Schwarzschild radius or the event horizon of a black hole."}, {"time": 6708, "text": "Once you enter into it with a spaceship, you would never be able to tweet back to your friends and tell them, by the way, I asked the students in my class, freshman seminar at Harvard, I said, let me give you two possible journeys that you can take."}, {"time": 6719, "text": "I said, suppose aliens come to Earth and suggest that you would board their spaceship, would you do it?"}, {"time": 6726, "text": "And the second is, suppose you could board a spaceship that will take you into a black hole, would you do it?"}, {"time": 6740, "text": "So all of them said to the first question, yes, under one condition, that I'll be able to maintain my social media contacts and report back, share the experience with them."}, {"time": 6748, "text": "Personally, I have no footprint on social media."}, {"time": 6756, "text": "Yeah, which is as a matter of principle."}, {"time": 6759, "text": "Yeah, my wife asked me when we got married, and I honor that."}, {"time": 6764, "text": "And I told you offline, I need to get married to such a woman."}, {"time": 6764, "text": "She truly is a special agent."}, {"time": 6769, "text": "Well, she was wise enough to recognize the risk."}, {"time": 6769, "text": "But it saves me time."}, {"time": 6769, "text": "And it also keeps me away from crowds."}, {"time": 6776, "text": "I don't have the notion of what a lot of other people think, so I can think independently."}, {"time": 6784, "text": "Crowd think, exactly."}, {"time": 6784, "text": "So I was surprised to hear that for students, it's extremely important to share experiences."}, {"time": 6791, "text": "Even if they go on a spaceship with aliens, they still want to brag about it rather than look around and see what's going on."}, {"time": 6799, "text": "This is not an option when you go to the black hole, is exactly the point."}, {"time": 6802, "text": "So for the black hole, they said no, because obviously you can find your death after you get into it, you crash into singularity."}, {"time": 6809, "text": "There is this singularity in the center."}, {"time": 6809, "text": "So inside the event horizon, we know that all the matter collects at a point."}, {"time": 6815, "text": "Now, we can't really predict what happens at the singularity because Einstein's theory breaks down."}, {"time": 6824, "text": "And we know why it breaks down, because it doesn't have quantum mechanics that talks about small distances."}, {"time": 6829, "text": "We don't have a theory that unifies quantum mechanics and gravity so that it will predict what happens near a singularity."}, {"time": 6842, "text": "And in fact, a couple of years ago, I had a flood in my basement."}, {"time": 6842, "text": "And I invited a plumber to come over and figure out and we found that the sewer was clogged because of tree roots that got into it."}, {"time": 6860, "text": "And we solved the problem."}, {"time": 6860, "text": "But then I thought to myself, well, isn't that what happens at the singularity of a black hole?"}, {"time": 6868, "text": "Because the question is, where does the matter go?"}, {"time": 6873, "text": "In the case of a home, I never thought about it, but the water, all the water that we use, goes in through the sewer to some reservoir somewhere."}, {"time": 6879, "text": "And the question is, what happens inside a black hole?"}, {"time": 6886, "text": "And one possibility is that there is an object in the middle, just like a star, and everything collects there."}, {"time": 6891, "text": "And the object has the maximum density that we can imagine, like Planck density."}, {"time": 6896, "text": "It's the ultimate density that you can have, where gravity is as strong as all the other forces."}, {"time": 6903, "text": "So you can imagine this object, very dense object at the center that collects all the matter."}, {"time": 6911, "text": "Another possibility is that there is some tunnel just like the sewer."}, {"time": 6915, "text": "It takes the matter into another place."}, {"time": 6915, "text": "And we don't know the answer."}, {"time": 6915, "text": "But I wrote a Scientific American essay about it, admitting our ignorance."}, {"time": 6922, "text": "What happens to the matter that goes into a black hole?"}, {"time": 6928, "text": "I actually recommend it to some of my colleagues that work on string theory."}, {"time": 6932, "text": "At the closing of a conference, I'm the founding director of the Black Hole Initiative at Harvard, which brings together astronomers, physicists, philosophers, and mathematicians."}, {"time": 6942, "text": "And we have a conference once a year."}, {"time": 6942, "text": "And at the end of one of them, since I'm the director, I had to summarize."}, {"time": 6949, "text": "And I said that I wish we could go on a field trip to a black hole nearby."}, {"time": 6956, "text": "And I highly recommend to my colleagues that work on string theory to enter into that black hole, because then they can test their theory when they get inside."}, {"time": 6963, "text": "But one of the string theorists in the audience, Nimar Khani Hamad, immediately raised his voice and said, you have an ulterior motive for sending us into a black hole, which I didn't deny, but at any event."}, {"time": 6981, "text": "Can you say why we know that black holes exist?"}, {"time": 6992, "text": "So it's an interesting question because black holes were considered a theoretical construct."}, {"time": 6998, "text": "And Einstein even denied their existence in 1939."}, {"time": 6998, "text": "But then in the mid 1960s, quasars were discovered."}, {"time": 7011, "text": "These are very bright sources of light, 100 times brighter than their host galaxy, which are point like at the center of galaxies."}, {"time": 7019, "text": "And it was immediately suggested by Ed Salpeter in the West and by Yakov Zeldovich in the East, that these are black holes that accrete gas, collect gas from their host galaxy that are being fed with gas."}, {"time": 7036, "text": "And they shine very brightly because as the gas falls towards the black holes, just like water running down the sink, the gas swirls and then rubs against itself and heats up and shines very brightly because it's very hot close to the black hole."}, {"time": 7061, "text": "By viscosity, it heats up."}, {"time": 7061, "text": "And in the case of black holes, it's the turbulence, the turbulent viscosity that causes it to heat up."}, {"time": 7069, "text": "So we get these very bright sources of light just from black holes that are supposed to be dark, nothing but black holes."}, {"time": 7081, "text": "You know, nothing escapes from them, but they create a violent environment where gas moves close to the speed of light and therefore shines very brightly, much more than any other source in the sky."}, {"time": 7092, "text": "And we can see these quasars all the way to the edge of the universe."}, {"time": 7097, "text": "So we have evidence now that when the universe was, you know, about 7% of its present age, you know, infant, already back then you had black holes of a billion times the mass of the sun, which is quite remarkable."}, {"time": 7110, "text": "It's like finding giant babies in a nursery, you know, like how can these black holes grow so fast?"}, {"time": 7118, "text": "You know, less than a billion years after the Big Bang, you already have a billion times the mass of the sun in these black holes."}, {"time": 7123, "text": "And the answer is presumably there are very quick processes that build them up."}, {"time": 7128, "text": "They build quickly."}, {"time": 7128, "text": "And so we see those black holes, and that was found in the mid 1960s."}, {"time": 7138, "text": "But in 2015, exactly 100 years after Einstein came up with his theory of gravity, the LIGO observatory detected gravitational waves."}, {"time": 7148, "text": "And these are just ripples in space and time."}, {"time": 7156, "text": "So according to Einstein's theory, the innovation, the ingenuity of Einstein's theory of gravity that was formulated in November 1915 was to say that space and time are not rigid."}, {"time": 7170, "text": "You know, they respond to matter."}, {"time": 7170, "text": "So, for example, if you have two black holes and they collide, it's just like a stone being thrown on the surface of a pond."}, {"time": 7180, "text": "They generate waves, disturbances in space and time that propagate out at the speed of light."}, {"time": 7188, "text": "These are gravitational waves."}, {"time": 7193, "text": "They create a space time storm around them, and then the waves go all the way through the universe and reach us."}, {"time": 7199, "text": "And if you have a sensitive enough detector like LIGO, you can detect these waves."}, {"time": 7205, "text": "And so it was not just the message that we received for the first time, gravitational waves, but it was the messenger."}, {"time": 7211, "text": "So there are two aspects to it."}, {"time": 7211, "text": "One is the messenger which is gravitational wave for the first time were detected directly."}, {"time": 7216, "text": "And the second was the message, which was a collision of two black holes, because we could see the pattern of the ripples in space and time."}, {"time": 7227, "text": "And it was fully consistent with the prediction that Schwarzschild made for how the space time around the black hole is, because when two black holes collide, you can sort of map from the message that you get, you can reconstruct what really happened and it's fully consistent."}, {"time": 7249, "text": "And in 2017 and 2020, there's two Nobel prizes."}, {"time": 7249, "text": "That had to do with the black holes."}, {"time": 7260, "text": "Can you maybe describe in the same masterful way that you've already been doing what the 2017 was given for the LIGO collaboration for discovering gravitation waves from collisions of black holes?"}, {"time": 7273, "text": "And the 2020 Nobel prize in physics was given for two things."}, {"time": 7273, "text": "One was theoretical work that was done by Roger Penrose in the 1960s, demonstrating that black holes are inevitable when stars collapse."}, {"time": 7292, "text": "And it was mostly mathematical work."}, {"time": 7292, "text": "And actually, Stephen Hawking also contributed significantly to that frontier."}, {"time": 7301, "text": "And unfortunately, he is not alive, so he could not be honored."}, {"time": 7308, "text": "So Penrose received it on his own."}, {"time": 7308, "text": "And then two other astronomers received it as well, Andrea Ghez and Reinhard Genzel, and they provided conclusive evidence that there is a black hole at the center of the Milky Way galaxy that weighs about 4 million times the mass of the sun."}, {"time": 7323, "text": "And they found the evidence from the motion of stars very close to the black hole."}, {"time": 7330, "text": "Just like we see the planets moving around the sun, there are stars close to the center of the galaxy and they are orbiting at very high speeds of other thousands of kilometers per second or thousands of miles per second per second."}, {"time": 7347, "text": "Which can only be induced at those distances if there is a 4 million solar mass object that is extremely compact."}, {"time": 7357, "text": "And the only thing that is compatible with the constraints is a black hole."}, {"time": 7366, "text": "And they actually made a movie of the motion of these stars around the center."}, {"time": 7374, "text": "One of them moves around the center over a decade, over timescales that we can monitor."}, {"time": 7380, "text": "And it was a breakthrough in a way."}, {"time": 7380, "text": "So combining LIGO with the detection of a black hole at the center of the Milky Way and in many other galaxies like quasars, now I would say black hole research is vogue."}, {"time": 7400, "text": "It's very much in fashion."}, {"time": 7400, "text": "We saw it back in 2016 when we established the black hole initiative."}, {"time": 7408, "text": "You kind of saw that there's this excitement about in breakthroughs and discoveries around black holes which are probably one of the most fascinating objects in the universe."}, {"time": 7422, "text": "It's up there."}, {"time": 7422, "text": "They're both terrifying and beautiful and they capture the entirety of the physics that we know about this universe."}, {"time": 7429, "text": "I should say the question is where is the nearest black hole?"}, {"time": 7433, "text": "Can we visit it?"}, {"time": 7433, "text": "And I wrote a paper with my undergraduate student, Amir Siraj, suggesting that perhaps if there is one in the solar system, we can detect it."}, {"time": 7449, "text": "I don't know if you heard, but there is a claim that maybe there is a planet nine in the solar system because we see some anomalies at the outer parts of the solar system."}, {"time": 7460, "text": "So some people suggested maybe there is a planet out there that was not yet detected."}, {"time": 7460, "text": "So people searched for it, didn't find it."}, {"time": 7466, "text": "It weighs roughly five times the mass of the earth."}, {"time": 7466, "text": "And we said, okay, maybe you can't find it because it's a black hole that was formed early in the universe."}, {"time": 7479, "text": "Where do you stand on that?"}, {"time": 7480, "text": "It could be that the dark matter is made of black holes of this mass."}, {"time": 7480, "text": "We don't know what the dark matter is made of."}, {"time": 7484, "text": "It could be the black holes."}, {"time": 7484, "text": "So we said, but there is an experimental way to test it."}, {"time": 7490, "text": "And the way to do it is because there is the Oort cloud of icy rocks in the outer solar system."}, {"time": 7499, "text": "And if you imagine a black hole there, every now and then a rock will pass close enough to the black hole to be disrupted by the very strong gravity close to the black hole."}, {"time": 7506, "text": "And that would produce a flare that you can observe."}, {"time": 7512, "text": "And we calculated how frequently these flares should occur."}, {"time": 7517, "text": "And with LSST on the Vera Rubin Observatory, we found that you can actually test this hypothesis."}, {"time": 7523, "text": "And if you don't see flares, then you can put limits on the existence of a black hole in the solar system."}, {"time": 7529, "text": "It would be extremely exciting if there was a black hole, if planet nine was a black hole, because we could visit it and we can examine it."}, {"time": 7533, "text": "And it will not be a matter of an object that is very removed from us."}, {"time": 7541, "text": "Another thing I should say is it's possible that the black hole affected life on Earth."}, {"time": 7547, "text": "The black hole at the center of the Milky Way."}, {"time": 7553, "text": "That black hole right now is dormant."}, {"time": 7553, "text": "It's very faint."}, {"time": 7553, "text": "But we know that it flares."}, {"time": 7564, "text": "When a star like the sun comes close to it, the star will be spaghettified, basically become a stream of gas, like a spaghetti."}, {"time": 7570, "text": "And then the gas would fall into the black hole and there would be a flare."}, {"time": 7576, "text": "And this process happens once every 10,000 years or so."}, {"time": 7576, "text": "So we expect that these flares to occur every 10,000 years."}, {"time": 7582, "text": "But we also see evidence for the possibility that gas clouds were disrupted by the black hole, because the stars that are close to the black hole are residing in a single or two planes."}, {"time": 7596, "text": "And the only way you can get that is if they formed out of a disk of gas, just like the planets in the solar system formed."}, {"time": 7602, "text": "So there is evidence that gas fell into the black hole and powered possibly a flare."}, {"time": 7608, "text": "And these flares produce x rays and ultraviolet radiation that could damage life if the Earth was close enough to the center of the galaxy."}, {"time": 7622, "text": "Where we are right now, it's not very risky for us."}, {"time": 7622, "text": "But there is a theoretical argument that says the solar system, the sun, was closer to the galactic center early on, and then it migrated outwards."}, {"time": 7637, "text": "So maybe in the early stage of the solar system, the conditions were affected, shaped by these flares of the black hole at the center of the galaxy."}, {"time": 7647, "text": "And that's why for the first two billion years, there wasn't any oxygen in the atmosphere, who knows."}, {"time": 7651, "text": "But it's just interesting to think that from a theoretical concept that Einstein resisted in 1939, it may well be that black holes have influence on our life."}, {"time": 7664, "text": "And that it's just like discovering that some stranger affected your family and in a way your life."}, {"time": 7671, "text": "And if that happens to be the case, a second Nobel Prize should be given, not for just the discovery of this black hole at the center of the galaxy, but perhaps for the Nobel Prize in chemistry, for the effect that it had."}, {"time": 7695, "text": "For the effect for the interplay that resulted in some kind of, yeah, the chemical effect, biology, I mean, all those kinds of things in terms of the emergence of life and the creation of a habitable environment."}, {"time": 7710, "text": "And of course, like you said, dark matter, like black holes have some..."}, {"time": 7715, "text": "They could be the dark matter in principle, yes."}, {"time": 7715, "text": "We don't know what the dark matter is at the moment."}, {"time": 7721, "text": "Does it make you sad?"}, {"time": 7721, "text": "So you've had an interaction and perhaps a bit of a friendship with Stephen Hawking."}, {"time": 7726, "text": "Does it make you sad that he didn't win the Nobel?"}, {"time": 7732, "text": "Well, all together, I don't assign great importance to prizes because, you know, Jean Paul Sartre, who I admired as a teenager, because I was interested in philosophy."}, {"time": 7738, "text": "When I grew up on a farm in Israel, I used to collect eggs every afternoon and I would drive the tractor to the hills of our village and just think about philosophy, read philosophy books."}, {"time": 7751, "text": "And Jean Paul Sartre was one of my favorites."}, {"time": 7756, "text": "And he was honored with a Nobel Prize in literature."}, {"time": 7756, "text": "He was a philosopher primarily, existentialist."}, {"time": 7762, "text": "And he said, the hell with it."}, {"time": 7762, "text": "Why should I give special attention to this committee of people that get their self importance from awarding me the prize?"}, {"time": 7776, "text": "Why does that merit my attention?"}, {"time": 7776, "text": "So he gave up on the Nobel Prize."}, {"time": 7776, "text": "And you know, there are two benefits to that."}, {"time": 7784, "text": "One, that you're not working your entire life in the direction that would satisfy the will of other people."}, {"time": 7792, "text": "You work independently, you're not after these honors."}, {"time": 7797, "text": "Just for the same reason that if you're not living your life for making a profit or money, you can live a more fulfilling life because you're not being swayed by the wind, you know, of how to make money and so forth."}, {"time": 7850, "text": "And that's the natural way that science is, you know, it's a learning experience."}, {"time": 7854, "text": "So if you give the public an image by which scientists are always right, you know, and you know, some of my colleagues say we must do that, because otherwise the public will never believe us that global warming is really taking place."}, {"time": 7870, "text": "But that's not true, because the public would really believe you if you show the evidence."}, {"time": 7870, "text": "So the point is, you should be sincere."}, {"time": 7875, "text": "When the evidence is not absolutely clear, or where there are disputes about the interpretation of the evidence, we should show ourselves."}, {"time": 7879, "text": "You know, the king is naked, okay?"}, {"time": 7883, "text": "There is no point in pretending that the king is dressed, saying that scientists are always right."}, {"time": 7890, "text": "Scientists are wrong, frequently."}, {"time": 7890, "text": "And the only way to make progress is by evidence, giving us the support that we need to make airtight arguments."}, {"time": 7896, "text": "So when you say global warming is taking place, if the evidence is fully supportive, there are no holes in the argument, then people will be convinced, because you're not trying to fool them."}, {"time": 7909, "text": "When the evidence was not complete, you also show them that the evidence is not complete."}, {"time": 7918, "text": "And when there's holes, you show that there's holes, and here's the methodology we're using to try to close those holes."}, {"time": 7922, "text": "Let's be sincere."}, {"time": 7922, "text": "Why pretend?"}, {"time": 7922, "text": "So if there were no, in a world where there were no prizes, no honours, we would act like kids, as I said before."}, {"time": 7933, "text": "We would really be focusing on the ball and not on the audience."}, {"time": 7933, "text": "Yeah, the prizes get in the way, and it's so powerful."}, {"time": 7939, "text": "Do you think, in some sense, the few people that have turned down the prize made a much more powerful statement?"}, {"time": 7946, "text": "I don't know if you're familiar in the space of mathematics with the Fields Medal and Google Perlman turned down the prize."}, {"time": 7951, "text": "One of the reasons I started this podcast is I'm going to definitely talk to Putin, I'm definitely talking to Perlman, and people keep telling me it's impossible."}, {"time": 7966, "text": "I love hearing that, because I'll talk to both."}, {"time": 7972, "text": "Anyway, but do you have a sense of why he turned down the prize, and is that a powerful statement to you?"}, {"time": 7980, "text": "Well, what I read is that he was disappointed by the response of the community, the mainstream community, the mathematicians, to his earlier work, where they dismissed it, they didn't attend to the details, and didn't treat him with proper respect, because he was not considered one of them."}, {"time": 8004, "text": "And I think that speaks volumes about the current scientific culture, which is based on groupthink and on social interaction, rather than on the merit of the argument, and on the evidence in the context of physics."}, {"time": 8022, "text": "So in mathematics there is no empirical basis, you're exploring ideas that are logically consistent, but nevertheless there is this groupthink."}, {"time": 8034, "text": "And I think he was so frustrated with his past experience that he didn't even bother to publish his papers, he just posted them on the archive, and in a way saying, you know, I know what the answer is, go look at it."}, {"time": 8049, "text": "And then again, in the long arc of history, his work on archive will be remembered, and all the prizes, most of the prizes will be forgotten, that's what people don't kind of think about."}, {"time": 8063, "text": "When you look at Roger Penrose, for example, is another fascinating figure, you know, it's possible, and forgive me if this, I'm sure, my ignorance, but he's also did some work on consciousness."}, {"time": 8075, "text": "He's been one of the only people who spoke about consciousness, which for the longest time, and is still arguably outside the realm of the sciences."}, {"time": 8087, "text": "It's still seen as a taboo subject, and he was brave enough to explore it from a physics perspective, from just a philosophical perspective, but like with the rigor, like proposing different kind of hypotheses of how consciousness might be able to emerge in the brain, and it's possible that that is the thing he's remembered for if you look 100 years from now, right?"}, {"time": 8111, "text": "As opposed to the work in the black holes, which fits into what the current scientific community allows to be the space of what is and isn't science."}, {"time": 8122, "text": "Yeah, it's really interesting to look at people that are innovators, where in some phases of their career, their ideas fit into the social structure that is around them, but in other phases, it doesn't."}, {"time": 8137, "text": "And when you look at them, they just operated the same way throughout, and it says more about their environment than about them."}, {"time": 8151, "text": "Well, yeah, and I don't know if you know who Max Tegmark is, I just recently talked to him."}, {"time": 8155, "text": "He's a friend of mine."}, {"time": 8156, "text": "I just recently talked to him again, and he, I mean, he was a little bit more explicit about saying, you know, being aware, which is something I also recommend, is like being aware where the scientific community stands, and doing enough to get, like move along into your career, in your career."}, {"time": 8171, "text": "And it's the necessary evil, I suppose, if you are one of those out of the box thinkers that just naturally have this childlike curiosity, which Max definitely is one of them, is sometimes you have to do some stuff that fits in, you publish and you get tenure and all those kinds of things."}, {"time": 8187, "text": "But the tenure is a great privilege because it allows you to, in principle, explore things that are not accepted by others."}, {"time": 8192, "text": "And unfortunately, it's not being taken advantage of by most people, and it's a waste of a very precious resource."}, {"time": 8203, "text": "The space that you kind of touched on that's full of theories and is perhaps detached from appreciation of empirical evidence, or longing for empirical evidence, or grounding in empirical evidence, is the theoretical physics community and the interest in unifying the laws of physics and with the theory of everything."}, {"time": 8227, "text": "I'm not sure from which direction to approach this question, but how far away are we from arriving at a theory of everything, do you think?"}, {"time": 8235, "text": "And how would we, how important is it to try to arrive at it, at this kind of goal of this beautiful simple theory that unlocks the very, you know, fundamental basis of our nature as we know it?"}, {"time": 8253, "text": "And, you know, and how, what are the kinds of approaches we need to take to get there?"}, {"time": 8270, "text": "Yeah, so in physics, the biggest challenge is to unify quantum mechanics with gravity."}, {"time": 8276, "text": "And I believe that once we have experimental evidence for how this happens in nature, in systems that have quantum mechanical effects, but also gravity is important, then the theory will fall into our lap, okay?"}, {"time": 8289, "text": "But the mistake that is made by the community right now is to come up with the right theory from scratch."}, {"time": 8297, "text": "And, you know, Einstein gave the illusion that you can just sit in your office and understand nature, you know, when he came up with his general theory of relativity."}, {"time": 8310, "text": "But, you know, first of all, perhaps he was lucky, but it's not a rule."}, {"time": 8318, "text": "The rule is that you need evidence to guide you, especially when dealing with quantum mechanics, which is really not intuitive."}, {"time": 8322, "text": "And so there are two places where the two theories meet."}, {"time": 8332, "text": "One is black holes, and there is a puzzle there."}, {"time": 8332, "text": "It's called the information paradox."}, {"time": 8338, "text": "In principle, you can throw the Encyclopedia Britannica into a black hole."}, {"time": 8338, "text": "It's a lot of information."}, {"time": 8342, "text": "And then it will be gone because a black hole carries only three properties or qualities, the mass, the charge, and the spin, according to Einstein."}, {"time": 8352, "text": "But then when Hawking tried to bring in quantum mechanics to the game, he realized that black holes have a temperature and they radiate."}, {"time": 8366, "text": "This is called Hawking radiation."}, {"time": 8366, "text": "It was sort of anticipated by Jacob Bekenstein before him, and Hawking wanted to prove Bekenstein wrong and then figure this out."}, {"time": 8382, "text": "And so what it means is black holes eventually evaporate."}, {"time": 8382, "text": "And they evaporate into radiation that doesn't carry this information, according to Hawking's calculation."}, {"time": 8388, "text": "And then the question is, according to quantum mechanics, information must be preserved."}, {"time": 8393, "text": "So where did the information go if a black hole is gone?"}, {"time": 8400, "text": "And where is the information that was encoded in the Encyclopedia when it went into the black hole?"}, {"time": 8406, "text": "And to that question, we don't have an answer yet."}, {"time": 8406, "text": "It's one of those puzzles about black holes."}, {"time": 8412, "text": "And it touches on the interplay between quantum mechanics and gravity."}, {"time": 8417, "text": "Another important question is what happened at the beginning of the universe?"}, {"time": 8424, "text": "What happened before the Big Bang?"}, {"time": 8424, "text": "And by the way, on that, I should say, you know, there are some conjectures."}, {"time": 8431, "text": "In principle, if we figure it out, if we have a theory of quantum gravity, it's possible to imagine that we will figure out how to create a universe in the laboratory."}, {"time": 8443, "text": "And by irritating the vacuum, you might create a baby universe."}, {"time": 8443, "text": "And if we do that, it will offer a solution to what happened before the Big Bang."}, {"time": 8450, "text": "Perhaps the Big Bang emerged from the laboratory of another civilization."}, {"time": 8455, "text": "So it's like baby universes are being born out of laboratories."}, {"time": 8461, "text": "And inside the baby universe, you have a civilization that brings to existence a new baby universe."}, {"time": 8467, "text": "So just like humans, right?"}, {"time": 8467, "text": "We have babies and they make babies."}, {"time": 8467, "text": "So in principle, that would solve the problem of why there was a Big Bang and also what happened before the Big Bang."}, {"time": 8479, "text": "So we came, our umbilical cord is connected to a laboratory of a civilization that produced our universe once it figured out quantum gravity, you know."}, {"time": 8486, "text": "It's baby Big Bangs all the way down."}, {"time": 8496, "text": "So if we collect data about how the universe started, we could potentially test theories of, or it can educate us about how to unify quantum mechanics and gravity."}, {"time": 8505, "text": "If we get any information about what happens near the singularity of a black hole, you know, if we get a sense of, you know, somehow we learn what happens at the same, that would educate."}, {"time": 8516, "text": "So there are places where we can search for evidence, but it's very challenging, I should say."}, {"time": 8523, "text": "And my point is, you know, the string theorists, they decided that they know how to approach the problem, that they don't have a single theory."}, {"time": 8528, "text": "There is a multitude of theories and it's not tightly constrained and they cannot make predictions about black holes or about the beginning of the universe."}, {"time": 8541, "text": "So at the moment I say we're at a loss."}, {"time": 8541, "text": "And the way I feel about this concept of the theory of everything, we should wait until we get enough evidence to guide us."}, {"time": 8552, "text": "And until then, you know, there are many important problems that we can address, you know."}, {"time": 8556, "text": "Why bang our head against the wall on a problem for which we have no guidance?"}, {"time": 8563, "text": "We don't have a good dance partner in terms of evidence."}, {"time": 8563, "text": "There's not."}, {"time": 8567, "text": "I mean, it'd be interesting, just like you said, I mean, the lab is one place to create universes or black holes, but it'd be fascinating if there is indeed a black hole in our solar system that you can interact with."}, {"time": 8578, "text": "So the problem with the origin of the universe is all you can do is collect data about it, right?"}, {"time": 8583, "text": "You can't interact with it."}, {"time": 8587, "text": "Well, you can, for example, detect gravitational waves that emerged from that."}, {"time": 8587, "text": "And, you know, there is an effort to do that and that could potentially tell us something."}, {"time": 8593, "text": "But yeah, it's a challenge and that's why we're stuck."}, {"time": 8598, "text": "So I should say, despite what physicists portray, that, you know, we live through an exceptional growth in our understanding of the universe, we're actually pretty much stuck, I would say, because we don't know the nature of the dark matter."}, {"time": 8616, "text": "Most of the matter in the universe, we don't know what it is."}, {"time": 8616, "text": "And we don't know how the universe started."}, {"time": 8620, "text": "We don't know what happens in the interior of a black hole."}, {"time": 8625, "text": "Because you've thought quite a bit about dark matter as well."}, {"time": 8625, "text": "Do you have any kind of hypothesis, interesting hypothesis?"}, {"time": 8630, "text": "We already mentioned a few about what is dark matter and what are the possible paths that we could take to unlock the mystery of dark?"}, {"time": 8635, "text": "What is dark matter?"}, {"time": 8641, "text": "So what we need is some anomalies that would hint what the nature of the dark matter is, or to detect it in the laboratory."}, {"time": 8647, "text": "There are lots of laboratory experiments searching, but it's like searching for a needle in a haystack, because there are so many possibilities for the type of particle that it may be."}, {"time": 8655, "text": "But maybe at some point, you know, we'll find either a particle or black holes as the dark matter, or something else."}, {"time": 8661, "text": "But at the moment... Can you also maybe, sorry to interrupt, comment about what is dark matter?"}, {"time": 8670, "text": "Like what, it's just a name we assign to what?"}, {"time": 8673, "text": "So most of the community believes that it's a particle that we haven't yet detected."}, {"time": 8673, "text": "It doesn't interact with light, so it's dark."}, {"time": 8680, "text": "But the question is, what does it interact with, and how can we find it?"}, {"time": 8686, "text": "And for many years, physicists were guided by the idea that it's some extension of the standard model of particle physics."}, {"time": 8692, "text": "But then they said, oh, we will find some clues from the Large Hadron Collider about its nature."}, {"time": 8697, "text": "Or maybe it's related to supersymmetry, which is a new symmetry that we haven't found any evidence for."}, {"time": 8707, "text": "In both cases, the Large Hadron Collider did not give us any clues."}, {"time": 8707, "text": "And other people search for specific types of particles in the laboratory and didn't find any."}, {"time": 8713, "text": "A couple of years ago, actually, around the time that I worked on Oumuamua, I also worked on the possibility that the dark matter particles may have a small electric charge, which is a speculation, but nobody complained about it."}, {"time": 8732, "text": "And, you know, it was published and I regarded it more as of a speculation than the artificial origin of Oumuamua."}, {"time": 8738, "text": "And to me, I apply, you know, as far as I'm concerned, I apply the same scientific tools in both cases."}, {"time": 8744, "text": "There is an anomaly that led me to that discussion, which has to do with hydrogen being cold in the early universe more than we expected."}, {"time": 8755, "text": "So we suggested maybe the dark matter particles have some small charge."}, {"time": 8759, "text": "But then you deal with anomalies by exploring possibilities."}, {"time": 8759, "text": "That's the only way to do it, and then collecting more data to check those."}, {"time": 8765, "text": "And searching for technological signatures is the same as any other part of our scientific endeavor."}, {"time": 8774, "text": "We make hypotheses and we collect data, and I don't see any reason for having a taboo on this subject."}, {"time": 8787, "text": "In your childlike, open minded excitement and approach to science, you're, I think, to anyone listening to this, truly inspiring."}, {"time": 8793, "text": "I mean, the question I think is useful to ask is by way of advice for young people."}, {"time": 8798, "text": "A lot of young people listen to this, whether from all over the world, and teenagers, undergraduate students, even graduate students, even young faculty, even older faculty, they're all young at heart."}, {"time": 8813, "text": "Like there's many of them young at heart."}, {"time": 8818, "text": "Do you have advice for, but let's focus on the traditionally defined sort of young folks that kind of graduate."}, {"time": 8824, "text": "Do you have advice to give to young people like that today about life, maybe in general, maybe a life of curiosity in the sciences?"}, {"time": 8834, "text": "Well, first, I should confess that I enjoy working with young people much more than with senior people."}, {"time": 8840, "text": "And the reason is they don't carry a baggage of prejudice."}, {"time": 8840, "text": "They're not so self centered."}, {"time": 8846, "text": "They're open to exploration."}, {"time": 8846, "text": "My advice, I mean, one of the lessons that took me a while to learn, and I should say I lost important opportunities as a result of that."}, {"time": 8854, "text": "So I would regard it as a mistake on my behalf, was to believe experts."}, {"time": 8860, "text": "So, quote unquote."}, {"time": 8860, "text": "So on a on a number of occasions, I would come up with an original idea and then suggest it to an expert, someone that works in the same field for a while."}, {"time": 8877, "text": "And the expert would dismiss it most of the time because it's new and was not explored, not because of the merit."}, {"time": 8884, "text": "And then what happened to me several times is that someone else would listen to the conversation or would hear me suggesting it."}, {"time": 8897, "text": "And I would give up because the expert said no."}, {"time": 8897, "text": "And then that someone else would develop it so that it becomes the hottest thing in this field."}, {"time": 8905, "text": "And once it happened to me multiple times, I then realized the hell with the experts."}, {"time": 8911, "text": "They don't know what they're doing."}, {"time": 8911, "text": "They're just repeating them."}, {"time": 8916, "text": "They don't think creatively."}, {"time": 8916, "text": "They are being threatened by innovation."}, {"time": 8916, "text": "And it's the natural reaction of someone that cares about their ego more than about the matter that we are discussing."}, {"time": 8932, "text": "And so I said, I don't care how many likes I have on Twitter."}, {"time": 8932, "text": "I don't care whether the experts say one thing or another."}, {"time": 8937, "text": "I will basically exercise my judgment and do the best I can."}, {"time": 8943, "text": "Turns out that I'm wrong."}, {"time": 8943, "text": "I made a mistake."}, {"time": 8943, "text": "That's part of the scientific endeavor."}, {"time": 8950, "text": "And it took me a while to recognize that."}, {"time": 8950, "text": "And it was a lot of wasted opportunities."}, {"time": 8950, "text": "So to the young people, I would recommend don't listen to experts."}, {"time": 8956, "text": "Carve your own path."}, {"time": 8956, "text": "Now, of course, you will be wrong."}, {"time": 8964, "text": "You should learn from experience, just like kids do."}, {"time": 8964, "text": "But do it yourself."}, {"time": 8970, "text": "Your father died in 2017."}, {"time": 8970, "text": "Your mother died in 2019."}, {"time": 8970, "text": "Do you miss them?"}, {"time": 8982, "text": "Is there a memory, that fond memory that stands out?"}, {"time": 8982, "text": "Or maybe what have you learned from them?"}, {"time": 8990, "text": "From my mother, I mean, she was very much my inspiration for pursuing intellectual work, because she studied at the university."}, {"time": 9000, "text": "And then because of the Second World War, after the Second World War, she was born in Bulgaria."}, {"time": 9008, "text": "They immigrated to Israel."}, {"time": 9008, "text": "And she and she left university to work on a farm."}, {"time": 9015, "text": "And later in life, when all the kids left home, she went back to the university and finished the PhD."}, {"time": 9024, "text": "But she planted in me the intellectual curiosity and valuing learning or acquiring knowledge as a very important element in life."}, {"time": 9041, "text": "And my love with philosophy came from attending classes that she took at the university."}, {"time": 9050, "text": "When I was a teenager, I was fortunate to go to some of these and they inspired me later on."}, {"time": 9050, "text": "And I'm very different than my colleagues, as you can tell, because my upbringing was quite different."}, {"time": 9063, "text": "And the only reason I'm doing physics or astrophysics is because of circumstances."}, {"time": 9068, "text": "At age 18, I was asked to serve in the military."}, {"time": 9068, "text": "And the only way for me to pursue intellectual work was to work on physics, because that was the closest to philosophy."}, {"time": 9077, "text": "And I was good at physics."}, {"time": 9085, "text": "So they admitted me to an elite program called LPO that allowed me to finish my PhD at age 24 and to actually propose the first international project that was funded by the Star Wars initiative of Ronald Reagan."}, {"time": 9098, "text": "And that brought me to the US to visit Washington, DC, where we were funded from."}, {"time": 9105, "text": "And then on one of the visits, I went to the Institute for Advanced Study at Princeton and met John Bacall that later offered me a five year fellowship there."}, {"time": 9111, "text": "Under the under the condition that I'll switch to astrophysics."}, {"time": 9119, "text": "At which point, you know, I said, OK, I cannot give up on this opportunity."}, {"time": 9123, "text": "I'll do it."}, {"time": 9123, "text": "Switch to astrophysics."}, {"time": 9123, "text": "It felt like a forced marriage, kind of arranged marriage."}, {"time": 9130, "text": "And then I was offered the position at Harvard because nobody wanted that."}, {"time": 9135, "text": "They first selected someone else."}, {"time": 9135, "text": "And that someone said, I don't want to become a junior faculty at the Harvard Astronomy Department because the chance for being promoted are very small."}, {"time": 9147, "text": "So he took another job."}, {"time": 9147, "text": "And then I was second in line."}, {"time": 9147, "text": "They gave it to me."}, {"time": 9147, "text": "I didn't care much because I could go back to the farm any day, you know."}, {"time": 9153, "text": "And after three years, I was tenured."}, {"time": 9159, "text": "And eventually, a decade later, became the chair of this department and served for nine years as the chair of the astronomy department at Harvard."}, {"time": 9166, "text": "But at that point, it became clear to me that I'm actually married to the love of my life, even though it was an arranged marriage."}, {"time": 9176, "text": "There are many philosophical questions in astrophysics that we can address."}, {"time": 9176, "text": "But I'm still very different than my colleagues, you know, that were focusing on technical skills in getting to this job."}, {"time": 9187, "text": "So my mother was really extremely instrumental in planting the seeds of thinking about the big picture in me."}, {"time": 9197, "text": "Then my father, he was, you know, he was working in the farm."}, {"time": 9204, "text": "And we didn't speak much because we sort of understood each other without speaking."}, {"time": 9210, "text": "But what he gave me is a sense of, you know, that it's more important to do things than to talk about them."}, {"time": 9219, "text": "I love the, I mean, my apologies, but MIT mind and hand."}, {"time": 9219, "text": "I love that there's that the root of philosophy that you gain from your mom and the hand, that action is all that ultimately in the end matters from your dad."}, {"time": 9234, "text": "That's really powerful."}, {"time": 9234, "text": "If we could take a small detour into philosophy, is there by chance any books, authors, whether philosophical or not, you mentioned Sartre, that stand out to you that were formative in some small or big way, that perhaps you would recommend to others, maybe when you were very young or maybe later on in life?"}, {"time": 9260, "text": "Well, actually, yeah, I, you know, I read the number of existentialists that appealed to me because they were authentic."}, {"time": 9267, "text": "You know, Sartre, you know, he declined the Nobel Prize, as we discussed, but he also was mocking people that pretend to be something better than they are."}, {"time": 9279, "text": "You know, he was living an authentic life that is sincere."}, {"time": 9279, "text": "And that's what appealed to me."}, {"time": 9285, "text": "And Albert Camus was another French philosopher that advocated existentialism."}, {"time": 9285, "text": "You know, that really appealed to me."}, {"time": 9293, "text": "That's probably my favorite existentialist, Camus."}, {"time": 9293, "text": "And he died at a young age in an accident, unfortunately."}, {"time": 9298, "text": "And then, you know, people like Nietzsche that, you know, broke conventions."}, {"time": 9307, "text": "And I noticed that Nietzsche is still extremely popular."}, {"time": 9307, "text": "You know, that's quite surprising."}, {"time": 9316, "text": "He appeals to the young people of today."}, {"time": 9316, "text": "It's the childlike wonder about the world."}, {"time": 9325, "text": "And he was unapologetic."}, {"time": 9325, "text": "You know, it's like most philosophers have a very strict adherence to terminology and to the practices, academic philosophers."}, {"time": 9330, "text": "And Nietzsche was full of contradictions."}, {"time": 9336, "text": "And he just, I mean, he was just this big kid with opinions and thought deeply about this world."}, {"time": 9344, "text": "And people are really attracted to that."}, {"time": 9344, "text": "And surprisingly, there's not enough people like that throughout history of philosophy."}, {"time": 9349, "text": "And that's why I think he's still drawn to them."}, {"time": 9355, "text": "To me, what stands out is his statement that the best way to corrupt the mind of young people is to tell them that they should agree with the common view, you know."}, {"time": 9363, "text": "And, you know, it goes back to the thread that went throughout discussion."}, {"time": 9371, "text": "You've kind of suggested that we ought to be humble about our very own existence and that our existence lasts only a short time."}, {"time": 9378, "text": "We talked about you losing your father and your mother."}, {"time": 9394, "text": "I'm not afraid."}, {"time": 9394, "text": "You know what, Epicurus, actually Epicurus was a very wise person."}, {"time": 9401, "text": "According to Lucretius, Epicurus didn't leave anything in writing."}, {"time": 9401, "text": "But he said that he's never afraid of death because as long as he's around, death is not around."}, {"time": 9408, "text": "And when death will be around, he will not be around."}, {"time": 9416, "text": "So he will never meet death."}, {"time": 9416, "text": "So why should you be worried about something you will never meet?"}, {"time": 9421, "text": "You know, and it's an interesting philosophy of life."}, {"time": 9421, "text": "You know, you shouldn't be afraid of something that you will never encounter, right?"}, {"time": 9429, "text": "But there's a finiteness to this experience."}, {"time": 9429, "text": "We live every day."}, {"time": 9433, "text": "I mean, I think if we're being honest, we live every day as if it's going to last forever."}, {"time": 9440, "text": "We often kind of don't contemplate the fact that it ends."}, {"time": 9440, "text": "You kind of have plans and goals and you have these possibilities."}, {"time": 9446, "text": "You have a kind of lingering thought, especially as you get older and older and older, that this is, especially when you lose friends, then you start to realize, you know, it does end."}, {"time": 9458, "text": "But I don't know if you really are cognizant of that."}, {"time": 9458, "text": "I mean, because..."}, {"time": 9463, "text": "But you have to be careful not to be depressed by it, because otherwise you lose the vitality, right?"}, {"time": 9468, "text": "So I think the most important thing to draw from knowing that you are short lived is a sense of appreciation that you're alive."}, {"time": 9476, "text": "But more importantly, a sense of modesty, because how can anyone be arrogant if they kept at the same time this notion that they are short lived?"}, {"time": 9489, "text": "I mean, you cannot be arrogant, because anything that you advocate for, you know, you will not be around to do that in a hundred years."}, {"time": 9494, "text": "So people will just forget and move on, you know."}, {"time": 9499, "text": "And if you keep that in mind, you know, the Caesars in ancient Rome, they had a person next to them telling them, don't forget that you are mortal."}, {"time": 9506, "text": "You know, there was a person with that duty because the Caesars thought that they are all powerful, you know."}, {"time": 9517, "text": "And they had, for a good reason, someone they hired to whisper in their ear, don't forget that you are mortal."}, {"time": 9527, "text": "Well, you're somebody, one of the most respected, famous scientists in the world, sitting on a farm, gazing up at the stars."}, {"time": 9535, "text": "So you seem like an appropriate person to ask the completely inappropriate question of, what do you think is the meaning of it all?"}, {"time": 9545, "text": "And if we ever find an alien that we can converse with, I would like to answer this."}, {"time": 9551, "text": "I would like to ask for an answer to this question because... Would they have a different opinion, you think?"}, {"time": 9556, "text": "Well, they might be wiser because they lived around for a while, but I'm afraid they will be silent."}]}]